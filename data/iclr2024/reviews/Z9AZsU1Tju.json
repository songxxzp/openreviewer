[
    {
        "id": "yXpNkavRWV",
        "forum": "Z9AZsU1Tju",
        "replyto": "Z9AZsU1Tju",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_JgMF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_JgMF"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an Information-Theoretic Hierarchical Perception (ITHP) model, based on the concept of information bottleneck, for effective multimodal fusion."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The proposed Information-Theoretic Hierarchical Perception model looks novel to me; This stands in contrast to mainstream multimodal fusion where different modalities are treated equally, and the final prediction is usually acquired by concatenating the features from each modality. The concept of designating a prime modality and using the other modalities to guide the flow of information looks interesting, and makes sense to me --- In many multimodal tasks, modalities do not contribute equally to the final prediction.\n\n+ The experimental results are strong. The analysis about varying Lagrange multiplier in Sec. 3.1 provides good insight.\n\n+ Many design choices (e.g. latent state size, order of modalities) are thoroughly evaluated in the appendix."
            },
            "weaknesses": {
                "value": "+ As the authors already point out in Section 5, the proposed approach requires a predefined order of modalities, which could be a problem when there are > 3 modalities and we do not have prior information about the multimodal task.\n\n+ Would the proposed hierarchical architecture introduce some inference latency compared with the standard non-hierarchical approaches (Take Figure 3 as an example, say compared to concatenation of $X_0$, $X_1$ and $X_2$ and then passed to an MLP head)?\n\n+ It seems in the current framework, feature extraction from raw video, audio & text & the proposed ITHP are separate (first feature extraction then use the encoded features in the hierarchical information flow). The temporal nature of these data is not utilized. I wonder if the authors could briefly comment on the potential of extending the ITHP model to handle sequence data (that naturally comes with a temporal order)."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6883/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698617476311,
        "cdate": 1698617476311,
        "tmdate": 1699636800419,
        "mdate": 1699636800419,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "knTYo4aLf9",
        "forum": "Z9AZsU1Tju",
        "replyto": "Z9AZsU1Tju",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_4bfy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_4bfy"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a neuro-inspired sequential and hierarchical processing model for multi-modality data. The key is to balance the minimization of mutual information between the latent state and the input modal state, and the maximization of mutual information between the latent states and the remaining modal states. The paper presents the theory formulation of the processing steps and evaluate on two multimodality tasks, sarcasm detection and sentiment analysis."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe paper provided detailed formulation of the perception process and deduction of the loss function.\n2.\tThe paper conducted detailed experiments on the ablation of hyperparameters."
            },
            "weaknesses": {
                "value": "1.\tThe inspiration from neuroscience research seems simple, and unnecessary to the main processing pipeline of the main work, making the main work distracting.\n2.\tThe order of the modality in processing the data seems quite important, which highly impacts the performance. For such an importance factor, it is better to provide further theoretical analysis or practical guidance on it.\n3.\tThe paper should include some recent SOTA works, at lease works in 2022, on comparing the sentiment analysis."
            },
            "questions": {
                "value": "1.\tWhy sequential processing is good? Except for inspiration from neural inspirations. This operation introduces the extra problem of the order of modality. \n2.\tDoes the best beta and gamma share across different tasks? Or it is needed to balance for different tasks, making this method quite cumbersome."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6883/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6883/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6883/Reviewer_4bfy"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6883/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698675728029,
        "cdate": 1698675728029,
        "tmdate": 1700729312252,
        "mdate": 1700729312252,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cGDdoifyTz",
        "forum": "Z9AZsU1Tju",
        "replyto": "Z9AZsU1Tju",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_uxTC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_uxTC"
        ],
        "content": {
            "summary": {
                "value": "The authors develop a new Information-Theoretic Hierarchical Perception (ITHP) model that designates a prime modality and regards the remaining modalities as detectors in the information pathway, serving to distill the flow of information. The primary modality yields the highest degree of information extraction, with subsequent modalities contributing information in a sequentially ordered manner.  To address the challenge of high dimensionality of multimodal data, they construct \"Information bottlenecks.\" These bottlenecks function as compressed latent representations of the data, with each bottleneck responsible for compressing a single modality while retaining  the relevant information of other modalities. \n\nThe method shows impressive performance on the CMU-MOSI dataset surpassing human-level performance for sentiment analysis."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The fundamental premise of the research paper is interesting. It employs the concept of hierarchical information flow in a multi-modal context which was shown to be useful for downstream tasks like sentiment analysis and sarcasm detection.  \n\nThe paper is well written and easy to understand."
            },
            "weaknesses": {
                "value": "Comparison with other methods in Table 1 for sarcasm detection is insufficient. The authors need to provide comparison results on either additional datasets [3] or other existing methods in literature [4].  \n \n[3] Cai Y, Cai H, Wan X. Multi-modal sarcasm detection in twitter with hierarchical fusion model. InProceedings of the 57th annual meeting of the association for computational linguistics 2019 Jul (pp. 2506-2515). \n \n[4] Wen C, Jia G, Yang J. DIP: Dual Incongruity Perceiving Network for Sarcasm Detection. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2023 (pp. 2540-2550). \n\nThe paper is specific to the task sentiment analysis whereas the title and presentation of the paper refers to downstream tasks in multimodal learning as a whole. To support the claim the authors should report the method\u2019s performance on some general tasks like visual question answering.  \n\nThe literature survey needs to be updated. They are several recent methods of multimodal fusion and representation learning: \n \n[1] Xue Z, Marculescu R. Dynamic multimodal fusion. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2023 (pp. 2574-2583). \n\n \n\n \n\nMissing table 5 and 10 on page 9 which were referred to in text."
            },
            "questions": {
                "value": "The authors have established a direct quantitative association between the embedding size of modality X and its corresponding priority order for the task. However, the embedding size can be contingent upon the model's architectural characteristics. Does changing the model which provides the embedding has any effect on the priority order?  \n\nHow is embedding size related to the amount of context information present in a modality?  \n\nFor experiments in table 1, is there any effect of changing the audio and text priority, when all three of the modalities are present?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6883/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6883/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6883/Reviewer_uxTC"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6883/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698931897398,
        "cdate": 1698931897398,
        "tmdate": 1699636800176,
        "mdate": 1699636800176,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XjWuFPM9RZ",
        "forum": "Z9AZsU1Tju",
        "replyto": "Z9AZsU1Tju",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_Qqaa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_Qqaa"
        ],
        "content": {
            "summary": {
                "value": "- This paper introduces the Information-theoretic Hierarchical Perception (ITHP) model, which aims to integrate and process information from multiple modalities effectively. The authors show inspiring motivation corresponding neuroscience research to a model that designates a prime modality and utilizes the concept of the information bottleneck to construct compact and informative latent states, which enable to balance between preserving relevant information and reducing noise in the latent states.\n\n- This paper tries to justify the validity of design philosophy and the effectiveness of the proposed models experimentally with the performance comparison of two tasks such as (1) sarcasm detection from videos and (2) multimodal sentiment analysis. They seem to show better scores in both tasks. (note that seems not to pursue state-of-the-art performances)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper presents interesting connections between neuroscience and proposed models. It provides good motivations for designing the proposed models.\ufeff This integration of neuroscience principles into the design of the models adds a novel perspective to the field of multimodal learning.\n\n- The authors demonstrate the effectiveness with competitive performances of the proposed models in the two tasks."
            },
            "weaknesses": {
                "value": "- Even though this paper shows interesting modeling design and experimental results, there is a gap between state-of-the-art methods such as UniMSE and SPECTRA, for example, with respect to performances. What kinds of criteria to choose the model configuration and comparative methods in the paper?\n\n- This paper seems not to present enough information on experimental setting and implementation to achieve reproducibility.\n\n- It lacks justification for the component choices. Which points should be clarified through experiments? Why BERT and DeBERTa are utilized as language models? \n\n\n* References\n\n  - UniMSE : G. Hu, et al., UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition, EMNLP 2022\n\n  - SPECTRA : T. Yu, et al., Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment, ACL 2023"
            },
            "questions": {
                "value": "See the Weaknesses above and answer, please."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6883/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699382476822,
        "cdate": 1699382476822,
        "tmdate": 1699636800070,
        "mdate": 1699636800070,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uzOrvfKXMd",
        "forum": "Z9AZsU1Tju",
        "replyto": "Z9AZsU1Tju",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_mWBz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6883/Reviewer_mWBz"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes ITHP, a brain-inspired hierarchical information perception model that fuses information from different modalities. ITHP employs the information bottleneck framework to extract relevant information from different modalities in a hierarchical/sequential manner. Extensive experiments on MUStARD, CMU-MOSI, and CMU-MOSEI demonstrate the effectiveness of ITHP."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- the paper is clear and well-organized.\n- the proposed ITHP is intuitive and well-grounded in information theory and provides a novel view of information fusing in multi-modal learning.\n- extensive experiments demonstrate the effectiveness of ITHP."
            },
            "weaknesses": {
                "value": "- ITHP extracts commonly encoded information from different modalities; however, would this procedure be called \"fusion\" appropriately?\n    - suppose the primary modality is $M_p$ and a secondary modality be $M_1$. ITHP cannot capture information encoded in $M_1$ but not $M_p$. In this sense, ITHP would be an information distillation rather than a fusion method.\n    - when talking about \"fusion,\" one expects to integrate information of **different** types.\n    - in addition, when both modalities contain similar information, if the one in $M_1$ is noisy, would ITHP be affected? Can ITHP correctly identify the noise in $M_1$ and mainly use the information from $M_p$ instead?\n    - as the main idea of ITHP is to distill relevant information from different modalities, the starting point would be important. However, the experiments do not show results with different primary modalities."
            },
            "questions": {
                "value": "- how do you choose the primary modality? And how would different choices of primary modality affect the performance of ITHP?\n- how would ITHP perform in the presence of noise in some of the modalities (the primary or the secondary ones)?\n- how can ITHP accommodate tasks that require combining complementary information from different modalities?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6883/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699428627617,
        "cdate": 1699428627617,
        "tmdate": 1699636799940,
        "mdate": 1699636799940,
        "license": "CC BY 4.0",
        "version": 2
    }
]