[
    {
        "id": "iDTbHt92YO",
        "forum": "mRw9BuNO9i",
        "replyto": "mRw9BuNO9i",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7420/Reviewer_g8nh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7420/Reviewer_g8nh"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses the performance of advanced neural video codecs in comparison to traditional codecs, highlighting the role of entropy models in achieving high compression efficiency. However, it points out that cross-platform scenarios often lead to inconsistencies in probability distribution estimations due to platform-dependent floating-point computation errors, which can hinder decoding. To address this, the paper proposes a cross-platform video compression framework based on codebooks, eliminating autoregressive entropy modeling. It also introduces a conditional cross-attention module for context alignment between frames, resulting in a more efficient framework. This approach avoids the need for distribution estimation modules, making it less dependent on consistent computations across platforms."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The structure of this paper is well organized, with clear and concise explanations of the concepts. This paper addresses a significant issue in video compression by tackling the challenges of cross-platform consistency."
            },
            "weaknesses": {
                "value": "The experimental results do not effectively validate the method's effectiveness.\n\n1.\tWhy were tests conducted only on 1080p videos? To validate the method's generality, the authors should test it on videos of different resolutions. Typically, in video compression tasks, testing is done on classes like B, C, D, and E, but the authors have provided results for only class B. To ensure the method's effectiveness across various resolutions, the authors should supplement the results on these different video classes. Additionally, what issues arise from center-cropping input images to multiples of 128? Why not consider the original image dimensions?\n\n2.\tThe proposed method is trained on V100 FP32 and tested on both V100 FP32 and P40 FP16. I agree that different precision platforms can impact results. However, when testing with the lower precision platform, it's customary to convert FP32 to FP16 for comparison. Have the authors provided such comparisons, particularly with traditional methods like H.265 and H.264?\n\n3.\tHow was the codebook generated? It is mentioned that Zhu et al.'s method is used. Could they provide specific details on the training process, or did they directly employ pre-trained codebook? If that, how can we guarantee that this codebook can adapt to the testing dataset?\n\n4.\tWhy wasn't bitrate considered during training? Would joint optimization potentially yield better results?\n\n5.\tCould the authors provide an explanation for the design of codebook sizes as mentioned here? \u201cWhile for predicted frames, we use three different groups of codebook sizes to achieve different video compression ratios as {8192, 2048, 512}, {64, 2048, 512} and {8, 2048, 512}.\u201d\n\n6.\tI believe that using codebooks for compression is not only cross-platform but also an efficient approach. Why haven't the authors compared their method with more recent approaches like VVC and DCVC-DC?\n\n7.\tThe authors used GOP=12 for H.264 and H.265 configurations, but the model in the paper used GOP=32. Setting H.264/H.265 configurations to GOP=32 would ensure a fairer comparison.\n\n8.\tH.264 and H.265 compression configurations seem a little different from the common test configuration. Could you provide specific instructions for H.264 and H.265 compression configurations?\n\n9.\tIn Sec 2.1, \u201cConsequently, To avoid\u2026.\u201d here 'T' should be lowercase."
            },
            "questions": {
                "value": "Please refer to the Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Reviewer_g8nh"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7420/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698766990773,
        "cdate": 1698766990773,
        "tmdate": 1699636890349,
        "mdate": 1699636890349,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vCsMj2VaIC",
        "forum": "mRw9BuNO9i",
        "replyto": "mRw9BuNO9i",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7420/Reviewer_6Bc6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7420/Reviewer_6Bc6"
        ],
        "content": {
            "summary": {
                "value": "The paper examines video decoding errors in cross-platform scenarios. Inconsistent probability distribution estimations may arise from platform-specific floating point computation errors, which can result in decoding failures for compressed bitstreams. The paper suggests a video compression framework that employs codebooks to represent temporal and spatial redundancy. This framework utilizes a WCA-based context model instead of autoregressive modeling and optical flow alignment."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper focuses on an important and practical issue of neural video compression. And it proposes one reasonable solution.\n2. The design of the multi-stage codebook and window-based cross-attention successfully replaces the common motion compensation and autoregressive modules.\n3. The performance of its proposed method is acceptable, which is higher than two common traditional codecs H.265 and H.264."
            },
            "weaknesses": {
                "value": "1. The novelty of this paper may be limited as the overall framework bears resemblance to Mentzer et al.'s (2022) approach, which avoids explicit motion estimation by employing a transform-like architecture. Additionally, the use of vector quantization for compression is not new and may have been inspired by Zhu's work in image compression. Furthermore, the windows-based cross attention appears similar to SwinTransformer. Consequently, the major architecture and designs lack sufficient novelty.\n\n2. The experimental results are unconvincing as they only provide data on 1080p videos without including other resolutions such as Class C/D/E. Moreover, the authors solely compare their approach with traditional video codecs like H.265; however, it would be beneficial to include comparisons with learned video codecs that can also be utilized on CPU platforms to reduce decoding errors. These methods should be incorporated into the study.\n\n3. In the experiment section, it is important to set an equal Group of Pictures (GoP) size when comparing the author's model with traditional codecs. Therefore, both H.265 and H.264 GoP sizes should be set at 32 for a fair comparison. Additionally, regarding the proposed codebook method, there might be concerns about error propagation if a larger GoP size is used; thus, it would be valuable for the authors to address this issue in their discussion."
            },
            "questions": {
                "value": "How do you calculate the bitrate? And how do you compress the index in the proposed framework? The authors don't provide many details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Reviewer_6Bc6"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7420/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816101284,
        "cdate": 1698816101284,
        "tmdate": 1699636890225,
        "mdate": 1699636890225,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "l7z1lDbt52",
        "forum": "mRw9BuNO9i",
        "replyto": "mRw9BuNO9i",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7420/Reviewer_z95x"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7420/Reviewer_z95x"
        ],
        "content": {
            "summary": {
                "value": "1. In this paper authros proposed a cross-platform videocompression framework based on codebooks, which avoids autoregressive entropy\nmodeling and achieves video compression by transmitting the index sequence of the codebooks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.Novelity of the paper is good.\n2. Encourging results."
            },
            "weaknesses": {
                "value": "1.Related work should be updated."
            },
            "questions": {
                "value": "1.Include the recent papers in references.\n2.Mention the future scope.\n3.Detailed analysis of figure 5 results is required."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Reviewer_z95x"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7420/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699068540722,
        "cdate": 1699068540722,
        "tmdate": 1699636890032,
        "mdate": 1699636890032,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MaNJzrL0wl",
        "forum": "mRw9BuNO9i",
        "replyto": "mRw9BuNO9i",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7420/Reviewer_iHcA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7420/Reviewer_iHcA"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a video compression framework that facilitates cross-platform compatibility by avoiding the need for entropy modeling in probability distribution estimation. To achieve this, this paper leverages codebook-based approaches and proposes window-based cross-attention that avoids the use of optical flow for context alignments. The paper demonstrates the effectiveness of the proposed method compared to existing traditional video codecs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and flows smoothly.\n- The motivation for the proposed method seems intriguing in the context of neural video compression."
            },
            "weaknesses": {
                "value": "1. **More RD-performance comparison with existing neural video compression methods**: The paper primarily made a comparison with traditional codecs like H.264 and H.265. While Figure 1 demonstrates the artifacts induced by entropy models in cross-platform settings, the paper does not conclusively establish if this issue is prevalent across all neural video compression methods. To strengthen the paper's claims, a more comprehensive RD-performance comparison with a variety of neural methods in similar cross-platform scenarios is necessary. Moreover, the paper should include both qualitative and quantitative results. Given that metrics like PSNR and MS-SSIM might not fully represent the artifacts seen in decompressed frames, the inclusion of perceptual similarity metrics such as LPIPS [1] or FLIP [2] is recommended for a more comprehensive evaluation.\n\n2. **Decoding efficiency**: The paper should also report on decoding efficiency relative to existing neural video compression methods, extending beyond the ablation studies of the proposed modules.\n\n3. **More consideration of cross-platform scenario when encoding/decoding**: The paper presents the scenarios where encoding is done using an NVIDIA Tesla V100 and decoding with a Tesla P40, as detailed in Table 5 of the Appendix. However, this scenario is limited. More examination of diverse scenarios including a broader range of encoding/decoding machines should be included to verify the robustness of the proposed method regardless of the systematic errors across different platforms. \n\n4. **More comparison with existing calibration methods**:\nThe paper should incorporate a detailed comparison with existing calibration methods. This is crucial for contextualizing the results presented in Table 2 and Table 5. The inclusion of performance comparison with existing calibration methods will significantly enhance the paper's comprehensiveness and the validity of its conclusions.\n\n\n\n[1] Zhang et al., The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\n\n[2] Andersson et al., A Difference Evaluator for Alternating Images"
            },
            "questions": {
                "value": "The proposed WCA-based context model is intriguing. However, the presented modules, including the codebook approach and the keyframe and prediction frame categorization, appear as already well-established techniques in the field of neural data compression. While the focus on cross-platform scenarios is an interesting aspect that underscores the effectiveness of your proposed method, it also requires a deeper investigation to distinguish this paper from existing methods. Therefore, to strengthen the claim of the paper, a more comprehensive comparison as mentioned in the weakness section seems crucial. Without them, my evaluation of the paper may be lower."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7420/Reviewer_iHcA"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7420/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699185786636,
        "cdate": 1699185786636,
        "tmdate": 1700723416515,
        "mdate": 1700723416515,
        "license": "CC BY 4.0",
        "version": 2
    }
]