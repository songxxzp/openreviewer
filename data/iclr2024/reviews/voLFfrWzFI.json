[
    {
        "id": "rjPhuruIi6",
        "forum": "voLFfrWzFI",
        "replyto": "voLFfrWzFI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8165/Reviewer_g5nG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8165/Reviewer_g5nG"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed two methods aimed at improving the generalization performance of the state-of-the-art Decision-Focused Learning (DFL) method SPO. The first proposed method, SPOImplGen, trains the model on different tasks sampled from a task space rather than a task. The second proposed method, SPOExplGen, combines the GNN model with SPOImplGen to acquire a robust task representation, resulting in improved generalization performance. In the experimental section, it is demonstrated that both methods outperform SPO across three different problems in terms of generalization performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- S1 The paper is well-written and addresses an important topic.\n- S2 The proposed methods improve the generalization performance of the SPO, especially on the shortest path problem.\n- S3 The paper conducts a thorough analysis of the experiment's results."
            },
            "weaknesses": {
                "value": "- W1 The settings in this paper need further justification, although they have been adopted in other existing works.\n  - W1-1 Given the primal-dual relationship for LP, $c$ and $A$ serve a similar role but only $c$ is assumed to be unknown.\n  - W1-2 Since c is assumed to be unknown, in which sense we may assume that they are known in the training data? Is there any real-world application that can support such a setting?\n\n- W2 The proposed method is reasonable but not very significant. On the one hand, it is not clear in theory why samples from multiple tasks can improve the generalization performance. On the other hand, while being more complex, SPOExplGen does not demonstrate a significant improvement in generalization performance when compared to SPOImplGen.\n\n- W3 The experiments could be improved in the following ways.\n  - W3-1 Since the paper considers samples from multiple tasks, it would be interesting to explore the generalization performance between different instance sizes.\n  - W3-2 The problem sizes are relatively small: item size 40 in the knapsack problem, and the 10 customers and 5 facilities in the facility location problem."
            },
            "questions": {
                "value": "What are the theoretical advantages of the proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8165/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698178618701,
        "cdate": 1698178618701,
        "tmdate": 1699637012156,
        "mdate": 1699637012156,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oTGtUTtWC4",
        "forum": "voLFfrWzFI",
        "replyto": "voLFfrWzFI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8165/Reviewer_nLem"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8165/Reviewer_nLem"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the task generalization problem in decision-focused learning (DFL) methods. It focuses on the case of integer linear programs (ILPs) and formulates different tasks as variations of the coefficient matrix A and vector b in the constraints. The main technical contribution is to propose two methods to address task generalization in DFL: 1) implicit method which works by simply training DFL on different tasks sampled at training time, and 2) explicit method which maps the A and b to embeddings using GNNs, which are then to be concatenated with the problem features x. The empirical results show that the proposed task generalization methods can improve regular DFL methods on unseen tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) Task generalization seems to be an important aspect of DFL methods (the motivation has not been clearly stated, though)\n\n2) The two methods to do task generalization are heuristic but make sense. In particular, representing tasks as bipartite graphs and then using GNNs to extract the information sounds reasonable. One potential disadvantage is that it introduces a lot more parameters to be learned together with the DFL process. \n\n3) The empirical results seem promising (explicit methods don't have a large edge, though)."
            },
            "weaknesses": {
                "value": "1) The motivation is task generalization is not clear -- why do we care about task generalization in DFL settings? If we have a new task, why don't we start training from scratch? Task generalization in prediction tasks makes more sense, e.g., when you have zero-shot or few-shot data. But here in DFL we don't have such issues. \n\n2) The two methods of task generalization are mostly heuristic, and there is no guarantee or in-depth analysis of whether/why they can work. Task representation using GNNs is not new, either. \n\n3) The empirical results are not entirely convincing and is not reproducible with important setting description missing. \n- Not sure if I missed anything, but I did not see where you described how many sampled tasks you need to have to train? Beyond reproduction, this is also very important to understand if the comparison is fair, and to understand what computational overhead is required. \n- For the base task, the generalized methods are even better than those trained on the specific base task. This is a bit counter-intuitive. Is it because the generalization takes in more training data? If so, this does not appear a fair comparison. \n- The advantage of the explicit generalization is very small compared to the implicit method in Tables 1 and 3. It is not clear how the proposed task representation method works. \n \n4) The writing needs a lot of improvement. E.g., \n- The abstract and introduction spend the majority of the space explaining the motivation/challenges of DFL, which has been there in existing DFL papers. However, it rarely touches on the motivation to do task generalization in DFL, which is the FOCUS of this paper. \n- The references are a bit messy. Also, on page 3, Niepart et al. 2021 is mentioned twice under two different ways of handling integer variables. \n- Typos. E.g., \nPage 2: Given is; \nPage 6, in Figure 2 is are; \nPage 7, the caption of Table 1: on the both the base \n\n5) The paper does not have a related work section, and many important DFL papers are not discussed, not even the two earlier and classic DFL papers (where the majority of the ideas discussed in the Introduction are from!): \n- Donti et al 2017, Task-based end-to-end model learning in stochastic optimization\n- Amos et al 2017, Optnet: Differentiable optimization as a layer in neural networks"
            },
            "questions": {
                "value": "1) In the GNN training, is it trained together with the decision loss and the linear prediction layer? If so, it introduces considerable amount of new parameters and may make the training even more challenging. \n\n2) See my other questions in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8165/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698678433379,
        "cdate": 1698678433379,
        "tmdate": 1699637011984,
        "mdate": 1699637011984,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UBnT8Xhx5t",
        "forum": "voLFfrWzFI",
        "replyto": "voLFfrWzFI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8165/Reviewer_jrAx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8165/Reviewer_jrAx"
        ],
        "content": {
            "summary": {
                "value": "While the majority of prior research has primarily concentrated on minimizing regret in DFL problems, this paper takes a distinctive approach by emphasizing the crucial aspect of generalization capability, particularly in the context of different tasks. To achieve this, the authors conduct a thorough examination of the well-established method for DFL, namely SPO.\n\nThe evaluation of generalization is undertaken by introducing variations in task-specific inputs (e.g. altering source or destination nodes within a graph), and subsequently assessing the performance of the DFL method. The findings reveal a noteworthy observation: while SPO excels in terms of normalized regret, its performance experiences a decline when tasked with adapting to different tasks.\n\nIn response to this observation, the paper introduces two highly effective mechanisms to address this issue. Firstly, an implicit strategy involves the random sampling of distinct task instances at each update. Secondly, an explicit approach entails encoding I(LP) instance using a graph neural network, seamlessly integrating it into the DFL training pipeline. These adaptations significantly enhances the generalization performance, as demonstrated in the experiments section."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The experiments conducted in this study provide compelling evidence. They demonstrate that the state-of-the-art SPO approach exhibits exceptional performance on the specific task for which it was trained. However, a noteworthy observation emerges: this performance rapidly deteriorates when confronted with a change in task. This meticulous analysis of SPO's generalization capabilities represents a commendable and significant contribution to the field. To the best of my knowledge, this facet has not been extensively explored in prior research.\n\nFurthermore, the proposed mechanisms designed to enhance generalization stand out as a pivotal advancement in the field. They fortify the adaptability and resilience of Decision focused learning (DFL) across a spectrum of task settings. The rationale behind the effectiveness of both mechanisms is articulated clearly and substantiated with empirical evidence, as vividly elucidated in Section 4."
            },
            "weaknesses": {
                "value": "- There has been recent advance in the area of parametric surrogate learning [1,2]. Authors in those papers also capitalize on generalization property of the learned surrogates. I'd appreciate authors' discussion and analysis on this matter, possibly including some comparison.\n\n[1] S. Shah, K. Wang, B. Wilder, A. Perrault, and M. Tambe. Decision-focused learning without decision-making: Learning locally optimized decision losses. In NeurIPS 2022.\n\n[2] A. Zharmagambetov, B. Amos, A. Ferber, T. Huang, B. Dilkina, and Y. Tian. Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information. ArXiv: 2307.08964"
            },
            "questions": {
                "value": "- Although this is not necessarily a weakness, but I'm just curious how this analysis will extend to other DFL methods, such as [3,4]. Could be potential direction for future research.\n\n- What kind of specific data augmentation was performed for the first mechanism? Is it just randomly drawing A,b or some specific data augmentation techniques were applied? If yes, what was their effect?\n\n\n[3] Marin Vlastelica Pogan\u02c7ci \u0301c, Anselm Paulus, Vit Musil, Georg Martius, and Michal Rolinek. Differentiation of blackbox combinatorial solvers. In International Conference on Learning Representations, 2020.\n\n[4] Subham S. Sahoo, Marin Vlastelica, Anselm Paulus, V \u0301\u0131t Musil, Volodymyr Kuleshov, and Georg Martius. Backpropagation through combinatorial algorithms: Identity with projection works. In International Conference on Learning Representations, 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8165/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698706060095,
        "cdate": 1698706060095,
        "tmdate": 1699637011830,
        "mdate": 1699637011830,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IRWMzGirrh",
        "forum": "voLFfrWzFI",
        "replyto": "voLFfrWzFI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8165/Reviewer_xQeo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8165/Reviewer_xQeo"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the capability of decision-focused learning\nmethods to generalize to tasks beyond the training task(s).\n\nSection 2 overviews the DFL setup where there is a dataset of\n(x,c) pairs and a model m is learned to predict the linear\ncoefficient (c) of equation 1 from x.\nThis paper defines the task to be (A,b) defining the\nconstraints in equation 1.\nThe motivation for this paper is that if a model is trained on one task,\nthe most important parts of the c prediction may differ from other\ntasks that the model is evaluated on.\n\nSection 3 moves on to show that a model could be trained\non multiple tasks at once (in equation 5), and then suggests\nthat the model can be conditional (implicit, S3.1) or\nunconditional (explicit, S3.2) on the task.\nWhen conditioning on the task, the authors propose to run\na GNN on the constraints for the task to obtain a\ntask embedding.\n\nSection 4 shows experimental results on knapsack,\ncapacitated facility location, and shortest path\nproblems, showing that generally the model conditional\non task information performs the best."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Understanding the models learned with DFL/SPO methods\n   is an important research topic for the community.\n2. The idea of learning task embeddings/features via a\n   GNN on the constraints is interesting and novel\n   as far as I am aware.\n3. The experiments in Tables 1/2/3 were clearly set up\n   and show the results of varying task parameters.\n   Often the SPOExplGen model that explicitly conditions\n   on the task performs the best. This makes sense and\n   is good to experimentally demonstrate.\n4. The experimental settings have the potential to become\n   a benchmark for multi-task generalization in SPO methods\n   (but on the other hand, are a straightforward generalization\n   of existing small-scale DFL settings)"
            },
            "weaknesses": {
                "value": "1. The experimental setup in section 3 is a staightforward generalization\n   of existing techniques, such as Tang & Khalil (2022a).\n   The beginning of section 3 states that they differ from\n   Tang & Khalil (2022a) because they consider a distribution\n   over tasks rather than a fixed set of tasks, but this difference\n   just makes equation 5 an expectation over tasks rather than a sum.\n2. Because the methodology is similar to Tang & Khalil (2022a),\n   it would have been insightful to compare directly to\n   a) their method on the experimental settings here,\n   and/or b) the SPOImplGen and SPOExplGen methods on\n   the experimental settings there.\n   If possible, this could add an insightful bridge between\n   the existing works, and if not possible it could be insightful\n   to discuss more why not.\n   (I acknowledge comparisons to their models/settings may\n   not make sense if they assume more contextual information\n   is available.)\n3. While the experimental results through section 4 are\n   scientifically well-executed and documented, I do not\n   find them especially insightful or surprising.\n   The problems are relatively standard for DFL and I would\n   not expect methods to generalize between tasks.\n   Between models, it is also unsurprising the SPOExplGen\n   model conditional on the task information performs\n   the best as it has the most information."
            },
            "questions": {
                "value": "I do not see any significant weaknesses in the paper\nand think the paper presents an interesting scientific\ninvestigation and experimental study of task generalization for DFL.\nI lean towards rejection due to the cumulation of the smaller\nweaknesses in my response. I would be especially open to re-evaluating\nmy score if the authors could 1) further clarify the positioning w.r.t.\nrelated work such as Tang & Khalil (2022a), and if it's possible to compare\nwith their method or experiments and 2) re-emphasize any surprising\nexperimental results worth spreading to the community."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8165/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807249073,
        "cdate": 1698807249073,
        "tmdate": 1699637011699,
        "mdate": 1699637011699,
        "license": "CC BY 4.0",
        "version": 2
    }
]