[
    {
        "id": "JhDRy14AEy",
        "forum": "8HCARN2hhw",
        "replyto": "8HCARN2hhw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission365/Reviewer_SbcL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission365/Reviewer_SbcL"
        ],
        "content": {
            "summary": {
                "value": "This work is about learning an abstract latent representation $\\mathbf{r}_t$ for navigation based on end-to-end learning, without a metric map.\nThe representation is inferred by a recurrent neural network from past RGB-D images and PointGoal-task information.\nA policy outputs actions based on this representation.\n\nThe main contribution is in how the representation is learned: instead of training it through the main policy directly, the authors use an auxiliary \"blind\" policy.\nIn training, the auxiliary policy has to navigate to randomly picked subgoals branching off of the main policy path, but it has to do so using only the last inferred representation $\\mathbf{r}_t$ from the main policy loop, with no access to new RGB-D observations.\nIt is argued that this would force the representation to be better suited for navigation in unseen environments (which is debatable, see my comments about this below).\n\nThe approach is trained and evaluated in simulation (Habitat, Gibson scenes), and sim2real transfer is studied on a small scale (11 runs on a real robot)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The method appears sound on the whole, and most design choices are motivated.\n\n- The presentation was easy to follow, but there is some room for improvement (e.g. see comment on missing environment examples below).\n\n- The results indicate the method works in the considered environments, with success rates of ca. 90% in simulation and 80% in sim2real. To the best of my knowledge this is reasonable, compared to the prior art on end-to-end learned navigation. \n\n- Ablations of the main method aspects are included, which is appreciated.\n\n- There is some indication of improved sim2real transfer (e.g. compared to PPO), but there are also limitations of the evaluation (see weaknesses)."
            },
            "weaknesses": {
                "value": "- The number of real-world experiments is rather low (11 episodes). While I can see how three baselines + the method itself add up in terms of workload, with only 11 runs I cannot tell if the sim2real results are statistically significant. I understand that it is unlikely this can be corrected on a short term during the review process, but it is an important point to consider for future revisions.\n- Related to the previous point, the paper is currently missing information about the complexity of the environments and the length of the evaluated navigation runs in them. Some qualitative examples in 2D would be nice, particularly of the real office environment. I am primarily concerned about this because navigation success metrics depend very much on a) the geodesic length of the navigation trajectory and b) how maze-like the layout of the scene is. Revealing the complexity of the considered navigation tasks will make the paper stronger.\n- I am not certain if the blindness property (a forefront contribution of the paper) is as useful compared to data augmentation:\n    - The results seem to support that subgoal spawning is beneficial. However, I am not convinced that the removal of observations in the auxiliary policy matters a lot. Simple behavior cloning + the subgoal data augmentation ((c) in Table 1) performs very well both in Sim and in NoisySim, better than plain navigability training ((d) in Table 1).\n    - I understand that the number of RGB-D observations with the proposed method is reduced, but this is a choice. The number of env interactions remains the same, so the comparison is on even terms.\n    - In the sim2real experiment, was the BC baseline ((c) in Table2) trained with the data augmentation regime, or regular? I believe sim2real results with BC + subgoal augmentation compared against the proposed method would have been ideal here.\n- The main text should specify the exact data fed into the networks clearly, this would make it much easier to assess the applicability of the solution. If I understand appendix A.2 correctly, the representation GRU takes both RGB-D images (not just RGB) and positional data (GPS + compass orientation), whereas the main text only talks about visual observations. This is somewhat misleading, navigation based on RGB data alone is very different from navigation with RGB-D images (from which collision information is easy to extract) with known poses.\n- The probing network is not directly related to the policy, so I am skeptical about the interpretation of the probing results at the very end of sec. 5. I think the paper would be better off by highlighting that this investigation is speculative, and should be taken with a grain of salt.\n\nOverall, I find that some of the main claims are stronger than what the experiments show (e.g. sec. 4) and that the evaluation could have been more precise. Note that I understand and can agree with the intuitive arguments in sec. 4, but these need to be supported better by the results. Still, the proposed training scheme does have some merit and the method seems to work, so I am leaning slightly positive in my assessment."
            },
            "questions": {
                "value": "- In the sim2real experiments, which BC variant was used as a baseline? With augmentation (i.e. subgoals) or without?\n- I am not sure I agree with the interpretation of the probing experiments. Sure, they indicate the reconstructed occupancy grids from the navigability representation are more optimistic, but then again can this be interpreted at all? There is no indication that the policy uses the representation in the same way, not to mention that absolute optimism w.r.t. collisions is not a desirable property per se."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission365/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission365/Reviewer_SbcL"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698674296779,
        "cdate": 1698674296779,
        "tmdate": 1700663597435,
        "mdate": 1700663597435,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JMLPqKpT3z",
        "forum": "8HCARN2hhw",
        "replyto": "8HCARN2hhw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission365/Reviewer_hBzC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission365/Reviewer_hBzC"
        ],
        "content": {
            "summary": {
                "value": "This work presents an approach to learn an actionable representation of the scene without optimizing for the reconstruction objective. The key idea is to use the learned representation to navigate on multiple short sub-episodes without any direct visual observations. The learned representation is optimized by this blind auxiliary agent for navigability and not reconstruction. Extensive experiments in both simulation and real world demonstrate the effectiveness of the proposed approach over several baselines, eg. BC, PPO, Map+Plan, especially in noisy settings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The learned representation is optimized for its usability in navigation rather than reconstruction objective. This makes it suitable for any downstream task involving navigation.\n- The latent cognitive map can be learned via a blind auxiliary agent without the use of direct visual observations.\n- The paper is well written. The related work section is quite comprehensive and provides a good overview of the literature. Sec. 4 provides a good discussion on the importance of blindness and differences with data augmentation.\n- Extensive experiments (Table 1) in simulation and NoisySim settings show the benefits of Navigability when combined with policy learning approaches, eg. BC and PPO. Sim2real performance (Table 2) on a physical robot shows its effectiveness over BC, PPO & mapping+planning in real world.\n- Ablation study on the continuity of hidden state (Table 3), connection between the representation and blind policy (Table 4), and reconstruction performance (Fig. 6) provide valuable insights into the capabilities of the proposed approach."
            },
            "weaknesses": {
                "value": "- Sec. 4 reasoning makes sense for GRUs & LSTMs since the gating mechanism in GRUs & LSTMs explicitly encourages the specified behavior. Would this also hold for other architectures, eg. transformer? It'd be useful to provide some insights into this.\n- Sec. 4 argues that the training will prioritize learning `r1` and neglect `r2` and provides two reasons. Is there any empirical evidence for this in the context of navigation?\n- For BC(L)(S)(data augm.) baseline in Table 1, when training on the short routes, is the hidden state copied from the long trajectory or initialized separately?\n- How are the c.1 & c.3 variants in Fig. 6 different from Table 3? The c.3 variant in Fig. 6 is worse than other baselines but it works the best in Table 3. It seems like `Always continue` works well with navigability but not with BC. It'd be helpful to clarify why the performances are so different.\n- What does `sym-SPL` represent? why is the minimum of the two ratios taken?"
            },
            "questions": {
                "value": "The questions are mentioned in the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698710418887,
        "cdate": 1698710418887,
        "tmdate": 1699635963478,
        "mdate": 1699635963478,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jfe8XqAsw7",
        "forum": "8HCARN2hhw",
        "replyto": "8HCARN2hhw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission365/Reviewer_sYMN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission365/Reviewer_sYMN"
        ],
        "content": {
            "summary": {
                "value": "The authors address the task or learning an informative latent state representation for downstream tasks. Instead of a conventional scene reconstruction loss they opt to learn a representation that optimizes navigability by introducing a time-series behavior cloning loss for a blind auxiliary policy (with no future timestep observations or reconstructions) on generated short-term sub-goals (section 3-4, page 4).\n\nThe authors discuss the importance of the \u201cblindness property\u201d with a toy example in section 4 (Figures 4 and 5) where they explain that the conventional behavior cloning method may learn to adopt a memory-less latent representation whereas their approach involving future timestep predictions based on past observations encourages memory in the latent representation.\n\nThe method is evaluated in simulation and real-world experiments. They report raw navigation success rate and SPL (success weighted by the optimality of planned paths) versus variants of behavior cloning and PPO (Table 1 and 2) where they method outperforms baselines. They further examine how to continue the latent state at the end of short sub-goal episodes (Table 3) and how to set the initial latent for the auxiliary blind policy (Table 4). The authors also examine the representative ability of their latent state by training a scene map reconstruction network and doing subsequent path planning with it (Figure 6 and Table 5). Although other baselines obtain a better raw map reconstruction, their method generally outperforms others in the navigation planning score (especially in noisy environments)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Discussion and experiments are detailed and analyze the different components of the method. Experiments test many ablations and variants of baselines to illustrate the impacts of their additions.\n- Both simulation and real-world results.\n- The work is well written and clear."
            },
            "weaknesses": {
                "value": "I feel the prediction of future labels without reconstruction is not a very novel architecture. I am also not sure if the improvement in results is because of the \u201cblindness property\u201d in the navigability loss (equation 5) or simply the addition of training data from generated sub-goals. There is an experimental discussion section addressing this concern (\u201cIs navigability reduced to data augmentation?\u201d, page 8) where they compare against a behavior cloning agent with added sub-goals. However, the difference in performance ((c) versus (e) in Table 1) seems relatively small (about 1% for success rate and even smaller point margins for SPL) and there is no reported confidence intervals or variance for these results over repeated seeds or trials. Thus, I am unsure how convincing these results are.\n\n__Minor Criticisms:__\n- Table 2 seemed to be discussed in detail before Table 1 in the experimental section which I found a bit disorienting for readability purposes.\n- I believe the methods relation to a mole is only explained in appendix  A.2. (The auxiliary agent \u03c1 (a.k.a. the \u201cmole\u201d)) and so I was initially a bit confused by the title."
            },
            "questions": {
                "value": "- On page 8, \u201cImpact of navigability\u201d, the text reads: \u201cWe see that PPO (a) outperforms classical BC (b), which corroborates known findings in the literature.\u201d However, the results in Table 1 appear to indicate the opposite, with BC (b) having a higher success rate. Is this a typo or a misunderstanding on my part?\n\n- In Table 3, the \u201cc.3. Always continue\u201d variant performs best. However, in Figure 6, now c.1 outperforms c.3. Is there any intuition behind this result?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission365/Reviewer_sYMN",
                    "ICLR.cc/2024/Conference/Submission365/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828270200,
        "cdate": 1698828270200,
        "tmdate": 1700518901117,
        "mdate": 1700518901117,
        "license": "CC BY 4.0",
        "version": 2
    }
]