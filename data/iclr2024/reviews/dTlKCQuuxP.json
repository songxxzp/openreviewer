[
    {
        "id": "WYvmxpUbmh",
        "forum": "dTlKCQuuxP",
        "replyto": "dTlKCQuuxP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission405/Reviewer_NjSx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission405/Reviewer_NjSx"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on macro motion analysis, which involves collecting all visually observable motions in dynamic scenes. The traditional filtering-based methods typically pay attention to local and tiny motions, while recent dynamic neural representations can represent motions faithfully, but cannot be directly applied to motion analysis. The authors propose Phase-based neural polynomial Gabor fields (Phase-PGF) to represent scene dynamics with low-dimensional time-varying phases. Phase-PGF has several properties suitable for macro motion analysis, and it can be used for various dynamic scene editing tasks, such as motion loop detection, motion separation, motion smoothing, and motion magnification. It further implements the Phase-PGF using an innovative neural architecture and a refined training approach to enhance the quality of dynamic scene representation and editing.\n\nThe main contributions of this paper are as follows:\n1) formulate the macro motion analysis problem \n2) provides a novel phase-based neural polynomial Gabor fields (Phase-PGF) approach to tackle the motion analysis problem\n3) demonstrates the effectiveness of the Phase-PGF approach on both 2D and 3D scenes\n\n---------------------------------------------------------------------------------------------------------------------------------------\nAfter reviewed the author's rebuttal, I have increased my score."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The main strengths of this paper are as follows:\n1. Originality: The paper proposes a novel approach called Phase-based neural polynomial Gabor fields (Phase-PGF) for representing and analyzing dynamic scenes. This approach addresses the gap in the field of computer vision, where traditional methods focus on local and tiny motions, while recent dynamic neural representations lack direct applicability for macro motion analysis. The paper's originality lies in its focus on macro motion analysis and the introduction of Phase-PGF as a suitable representation for this purpose.\n2. Quality: The paper presents a detailed analysis of the proposed approach, discussing its theoretical properties and demonstrating its ability to handle various macro motion analysis tasks such as motion separation, motion smoothing, and motion magnification. The experiments conducted showcase the effectiveness of Phase-PGF in representing and editing dynamic scenes, making the paper's contributions of high quality.\n3. Clarity: The paper is well-structured and clear. The authors formulate the problem of macro motion analysis, explain the theoretical properties of Phase-PGF, and discuss the implementation and training of the approach. The experiments are described in sufficient detail, making it easy for readers to understand and replicate the proposed method.\n4. Significance: The paper addresses a key challenge in the field of computer vision, motion analysis, and dynamic scene representation. By focusing on macro motion analysis, the proposed approach has the potential to impact various applications, such as motion tracking, generation, virtual reality, and other computer vision tasks. The paper's contributions are significant in providing a novel solution to representing and analyzing large motions and 3D scenes, which has been a largely underexplored area in the field.\n\nIn summary, the main strengths of the paper are its originality, quality, clarity, and significance. The paper presents a novel and effective approach to representing and analyzing macro motions in videos (both 2D and 3D), discusses its theoretical properties, and demonstrates its practical applicability through experiments, making it a valuable contribution to computer vision and related domains."
            },
            "weaknesses": {
                "value": "Weaknesses of the paper:\n1. Slight artifacts in boldly magnifying large motions: The paper acknowledges that when magnifying large motions, there are slight artifacts in Phase-PGF. The cause of these artifacts may stem from the neural network architecture or the way motion is represented. To reduce these artifacts, additional investigation and optimization of the model may be necessary. \n \n2. Limited scalability to complex large-scale 3D dynamic scenes: The paper acknowledges that Phase-PGF might not perform well in complex large-scale 3D scenes due to computational efficiency issues. As the paper's focus is on macro motion analysis, addressing this issue is crucial to improving the applicability of the proposed method, especially for complex scenes. A possible solution could be the use of a spatially adaptive Gabor basis as mentioned in the paper. \n\n3. Insufficient experimental evaluation: Although the paper presents some experimental results, it would be beneficial to include more comprehensive evaluations with various datasets and tasks. For example, additional experiments could be conducted on larger and more diverse datasets, varying scene conditions, and different motion types (e.g. human motion). This would help establish the robustness and generalizability of the proposed method.\n\n4. Neural network architecture: The paper uses a neural network to instantiate the Phase-PGF representation. However, the choice of the neural network architecture could be further optimized for the specific task of macro motion analysis. Including the details of the architecture may help to improve the reproducibility of the proposed work."
            },
            "questions": {
                "value": "1. In the related work section, the authors discuss concurrent works on tiny motion editing. How does Phase-PGF differ from these methods in terms of addressing macro motion analysis?\n\n2. The authors mention that Phase-PGF may present slight artifacts when magnifying large motions. Could they provide further insights on the reasons for these artifacts and potential solutions to address this issue?\n\n3. Are there plans to improve Phase-PGF's scalability for large-scale 3D dynamic scenes?\n\n4. In the experimental section, it would be helpful to know more about the datasets used and the evaluation metrics employed for assessing the performance of Phase-PGF. For example, for the human preference study, how many ratings are obtained for each video, and how many videos are being used in the study? \n\n5. Can the authors discuss the potential applications of Phase-PGF beyond the mentioned motion analysis and editing tasks, such as object tracking, motion generation, or other real-world scenarios?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Reviewer_NjSx"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission405/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698576678859,
        "cdate": 1698576678859,
        "tmdate": 1700654490967,
        "mdate": 1700654490967,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "goKlF8hNu2",
        "forum": "dTlKCQuuxP",
        "replyto": "dTlKCQuuxP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission405/Reviewer_WSr6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission405/Reviewer_WSr6"
        ],
        "content": {
            "summary": {
                "value": "This paper formulates and studies a new task of macro motion analysis. To perform macro motion analysis, the authors propose to learn an implicit function with respect to point coordinate x and time t, composed of Gabor functions and phase functions, namely Phase-PGF. By studying and adjusting the phase function of the Phase-PGF, one can infer periodic motion detection, motion separation, motion smoothing and motion intensity adjustment. Additionally, in order for the Phase-PGF to be able to extrapolate to unseen motions, which is needed for motion intensity adjustment, a discriminator on decoded images is used for adversarial training. Experiments on 2D video and 3D dynamic scenes are performed. Both human preference and visual results show its effectiveness and correctness on several motion analyses tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Overall, a new problem of macro motion analysis is properly formulated and approached with reasonable method, proven effective by adequate experiments.\n2. Using phase functions to model dynamic scenes has advantages for motion analysis compared with other dynamic scene representations.\n3. I appreciate authors experimenting with some real-captured data and the efforts of increasing image rendering quality."
            },
            "weaknesses": {
                "value": "1. It would be better to design some automatic metrics other than human preference. For example, trackers can be put on moving objects to obtain ground truth motions, which can be used to compare with predicted motions. For the motion intensity adjustment experiment, to evaluate the visual quality, some metrics designed for generation tasks, e.g., FID, KID, can be used.\n2. Currently, the examples in paper and supplementary website show very simple movements, mostly periodic. I wonder how would the method apply to more complex, dynamic scenes. Not necessarily dynamic 3D scenes, more complex 2D video can also do the work. If so, can the method separate more than two motions in the scene? And can some algorithm be designed to automatically find the moving object?"
            },
            "questions": {
                "value": "1. Currently, the extracted motion phase is agnostic of the motion direction. Is there a way to decompose motion phases, for example, to x and y directions.\n2. How, in practice, are the motion representation, e.g., Figure. 2(a), extracted from learned implicit function?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission405/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698630186448,
        "cdate": 1698630186448,
        "tmdate": 1699635967282,
        "mdate": 1699635967282,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ofGbE5DnUv",
        "forum": "dTlKCQuuxP",
        "replyto": "dTlKCQuuxP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission405/Reviewer_no8y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission405/Reviewer_no8y"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to represent scene dynamics with low-dimensional time-varying phases. The representation is learned using Phase-based neural polynomial Gabor fields (Phase-PGF). The paper argues that Phase-PGF has several properties which make it suitable for motion analysis task like motion loop detection, motion factorization,  and motion magnification."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper addresses an interesting application and is nicely written and easy to read.  \n- The paper proposes a novel formulation (Phase-PGF) for scene motion.\n- Phase-PGF several properties which make it suitable for motion analysis. Two properties I found interesting are :Periodicity correlation and motion separation.\n- The paper show several interesting motion analysis applications like motion separation, motion factorization, motion magnifications\n- The results shown seems to surpass previous work"
            },
            "weaknesses": {
                "value": "- Although the method is novel, I think the supporting experiments are insufficient to validate the method.\n- Not enough results in the supplementary webpage. All the results, except one, are visualizing the phase. Only one result show a generated video. This is insufficient to judge the quality of the results. I would have liked to see a video of the motion separation experiment and more videos for the motion intensity adjustment. \n- Motion editing results display visual artifact\n- Most of the experiments are on toy examples with simple objects or simple motion."
            },
            "questions": {
                "value": "- sometimes it is hard to say which phase is right. Maybe participants are just biased towards more periodic-looking signal even if it does not really match the scene motion. I wonder if there is more systematic way to evaluate this? For example, we can detect the periodicity of a given motion and then compare its frequency with the predicted frequency."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Reviewer_no8y"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission405/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698790566842,
        "cdate": 1698790566842,
        "tmdate": 1699635967205,
        "mdate": 1699635967205,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "F13LFoh08N",
        "forum": "dTlKCQuuxP",
        "replyto": "dTlKCQuuxP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission405/Reviewer_EQJi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission405/Reviewer_EQJi"
        ],
        "content": {
            "summary": {
                "value": "This paper delves into the exploration of motion analysis through the use of phase-based representation, with an emphasis on large-scale, rigid-body movements, also known as macro motion. In contrast to localized and small-scale motion, macro motion operates on a broader scale, encompassing extensive spatial and temporal transitions that are easily perceptible by humans. Traditional methods often fall short in accurately capturing such features because the filter operations are primarily designed to handle low-level features.\n\nTo overcome this limitation, this paper introduces a novel approach that utilizes phase-oriented neural Gabor fields as input embedding to reconstruct the original images or 3D scenes. By a reverse optimization process, the optimized phase input can encode some useful information while keeping the periodic. As the fundamental element in the real world, some good properties of phase can be also useful in further analysis. To enhance this reconstruction and reverse optimization, various training strategies like multi-stage, deep latent, and adversarial training have been proposed. Despite the lack of extensive evaluation, these methods are expected to deliver promising results.\n\nIn the experimental section, through some examples, it shows the method can outperform some baseline methods in extracting more reliable alignment. Moreover, the properties of the phase support the smoothing and separation of motions, which can be beneficial in specific applications like magnification."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The story is clear, the reader can easily understand the importance of the phase and the effectiveness of the proposed method.\n\nThe idea is interesting and novel. Using the phase as the fundamental feature to describe the motion can help to understand the motion better. \n\nI do like the inverse optimization with the Gabor field for locating the best-aligned phase feature; the theoretical exposition is clear, straightforward, and logical; and the proofs are also clear. \n\nThe employed coarse-to-fine generation framework and strategy effectively facilitate the learning of priors.\nThe results provide some evidence to support the central thesis of the paper."
            },
            "weaknesses": {
                "value": "While I appreciate the innovative concept presented in this paper, I believe the current version exhibits some weaknesses that need to be addressed:\n\nSome of the exposition needs to be improved. Some details and properties are not clearly clarified. Some points need more in-depth discussion:\n\n1. The input phase space and the details of the Phase Generator are not elaborated. As the central element in this model, it\u2019s not clear how to initialize the number of phases, and how the current framework adapts to the diverse scene. The full phase space can be much more complex than that in those demonstrated examples. Hence the potential of this method is unclear.\n\n2. The manipulation of the phase has been mentioned a few times, but it hasn't been detailed and demonstrated further in the paper. If the phase space is manipulatable, it will be important in the model interpretability. \n\n3. The implementation of using Phase-PGF in the deep neural network is not described clearly enough. \n\t\nThe contribution is unclear with insufficient evaluation. A more comprehensive evaluation is needed to demonstrate the boundaries of working examples, and provide more insights:\n1. Quantitative evaluation: Some of the test videos are artificial. In this case, we may want to synthesize more videos that contain varying motion complexities, for a more extensive evaluation.\n2. Ablation study: An ablation study for each network module would be beneficial.\n3. Evaluation metrics: A metric to measure if the phase meets the requirements would be useful.\n\nLast, some existing methods use different formulations to perform similar motion analysis, it is strongly recommended to add the comparison with them. For example, some point tracking methods can also extract rigid body movements as sparse points, and using these predictions it's also possible to extract interpretable features of the motion, such as phase or other high-level descriptions. While I don't question the novelty of this paper as it employs a *unique* methodology, it would be beneficial to add more experiments and discussions on these approaches."
            },
            "questions": {
                "value": "Where is the boundary of the phase space this method can support? There can be highly varied frequencies in the real world, but the working range of the proposed method is unclear. It would be useful to explore these boundaries by conducting experiments with various artificial videos.\n\nHow to determine the number of phases? In some cases, there appears to be one phase, while in others there are multiple. Is it possible to use an excessive number of phases to overfit a scene? Conversely, what would be the outcome if we used a single phase for a scene with multiple objects?\n\nThe extracted phases seem to care about the frequency more compared to the amplitude variations. In the second video of Fig.2, different balls do have different spatial transitions, but they seem to share the same peak. \n\nThere is an option to use point tracking to extract the phase from the tracking path. How does this method complement them, and in what ways does it offer unique advantages compared to other methods?\n\nAre the extracted phases open to manipulation? For example, if we multiply the phase by a coefficient A, will the corresponding recovered image or video be amplified? It is claimed in the paper that we can manipulate, but the results seem to be missing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission405/Reviewer_EQJi"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission405/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698827048039,
        "cdate": 1698827048039,
        "tmdate": 1700732662471,
        "mdate": 1700732662471,
        "license": "CC BY 4.0",
        "version": 2
    }
]