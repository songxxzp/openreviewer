[
    {
        "id": "dPVoLkgxCr",
        "forum": "nnicaG5xiH",
        "replyto": "nnicaG5xiH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes an approach CAMEL for the adaptation to new tasks by first learning a shared neural network feature extractor together with separate linear heads for each training task, then at test time perform least square regression to compute the linear head weights given a new task\u2019s labelled data. The authors show this formulation can allow physical parameters identification for linearly parameterized systems under certain conditions. Experimentally, the authors show that their approach can outperform meta-learning baseline methods (MAML, ANIL, CODA) in terms of generalization, computational speed, and interpretability."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The interpretability and physical parameter identification aspects this paper focuses on are important and often overlooked by existing meta-learning methods."
            },
            "weaknesses": {
                "value": "- **The proposed method lacks novelty and are not situated in the right context**. The authors claim to propose a novel \u201cmodel agnostic meta-learning architecture.\" However, the proposed approach is not model agnostic (because it requires specifying the width of the last layer dimension) and more importantly is not novel and not situated in the most relevant context.\n    - **Novelty**: It could be argued that the proposed method is not meta-learning but applying multi-task representation learning in a learning-to-learn problem. A more general version of the authors\u2019 proposed approach have been theoretically studied in terms of its generalization performance by Maurer et al  in 2016 (page 7, section 2.2 Bounding the Excess Risk for Learning-to-learn). More recently, Wang et al 2021 have proposed almost exactly the same approach by first multi-task learning a shared feature extractor with linear heads and then performing last linear layer fine-tuning over a new task\u2019s data at test time (section 3.4 Fine-tuning for Test Task Adaption). Besides, Wang et al has also studied the computational time savings of this MTL approach compared to last-layer MTL methods. Thus it is not correct for the authors to claim their methods as a novel approach.\n    - **Context**: In the background section, the authors situate their methods among Gradient-based Meta-learning methods. However as the authors have shown in Table 1, CAMEL doesn\u2019t perform gradient adaptation, so it\u2019s not a gradient-based method. Instead, because CAMEL adapts only the last layer of the learned model, a more appropriate way to situate the current method is to compare it among last-layer meta-learning methods, which includes not only ANIL (which the authors have compared against) but more importantly MetaOptNet (Lee et al 2019) and R2D2 (Bertinetto et al., 2019). Here both MetaOptNet and R2D2 solve the last linear layer exactly (using a convex solver or closed-form expression) and use implicit function theorem to propagate the gradients to the earlier feature extractors. Because this paper focuses on the regression task, the authors should compare additionally against R2D2 in the experiments. (One can think of R2D2 roughly as ANIL where the last layer adaptation are solved exactly instead of using a fixed number of gradient descent steps.)\n    \n    Maurer, A., Pontil, M., and Romera-Paredes, B. The bene\ufb01t of multitask representation learning. The Journal of Machine Learning Research, 2016.\n    \n    Wang, H., Zhao, H., & Li, B. Bridging multi-task learning and meta-learning: Towards efficient training and effective adaptation. In\u00a0International conference on machine learning, 2021\n    \n    Bertinetto, L., Henriques, J. F., Torr, P., and Vedaldi, A. Meta-learning with differentiable closed-form solvers. In International Conference on Learning Representations, 2019.\n    \n    Lee, K., Maji, S., Ravichandran, A., and Soatto, S. Metalearning with differentiable convex optimization. In CVPR, 2019\n    \n- **Notation needs to be more consistent and clearer.** For example, both $f_t(x; \\pi)$ (page 3) and $f_t(x)$ (page 4) are used. Besides, the ground truth function is denoted $v_{\\star}$. However, it has $n$ output dimensions, while the function $v$ has $r$ output dimensions.\n\n- **Proposition 1** are stated without all the assumptions of the relationships between $r$, $n$, $T$, and $N$ (some of these relationships are scattered in earlier parts of the paper), making the statement difficult to parse. Besides, the assumption that $c = c_{\\star} = 0$ to me seems a bit restrictive as the ground truth $c_{\\star}$ are inherent to the physical process and could be nonzero. However, I\u2019m not sure if the authors can make the same type of guarantees for the cases when these values are non-zero (and possibly unequal).\n- In the computational benefit section, the authors mention \u201cadaptation at test time \u2026 is guaranteed to converge if the number of samples is greater than $r$.\u201d This statement is a bit confusing, as the optimization is an ordinary least square which can be solved analytically without a notion of convergence. Maybe the authors mean to say when the number of samples is greater than $r$, the ordinary least squares is likely to be fully specified, thus admitting one unique solution. If this is the case, the authors should also discuss how to pick the solution when the ordinary least squares is underspecified."
            },
            "questions": {
                "value": "- How many steps of gradient adaption is used for ANIL? It is important to note that one can apply more steps of adaptation during evaluation than training as it can potentially improve ANIL's performance.\n- Can the authors explain for example 1 and 4, what is the learning goal here? I saw the authors mention $x=(q, \\dot q, \\ddot q)$ and $y=u$, but can the authors explain why do we want to predict $u$ (which I'm assuming is a function of time) in the first place?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1935/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z",
                    "ICLR.cc/2024/Conference/Submission1935/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1935/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722610862,
        "cdate": 1698722610862,
        "tmdate": 1700688885692,
        "mdate": 1700688885692,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ocFyfzbbiU",
        "forum": "nnicaG5xiH",
        "replyto": "nnicaG5xiH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates meta-learning physical systems via\nassociating every task with a linear embedding/task weight\nw that impacts the predictions: this is shown in equation 3.2\nwhere the prediction involves a global prediction\nfollowed by a modification from the linear part.\nAt test-time, the task weight of a new task is found\nby gradient descent on the task loss.\nSection 4 goes on to describe many settings where it is\nreasonable to have this linear part of the model,\nand prop 1 shows that the task weights can recover\nthe true dynamics of the system, which leads to the\nan interpretability of what the task weights are.\nThe experimental result show a number of settings\nfrom physics and reinforcement learning where\nthe method is able to learn better meta-dynamics models\nthan MAML, ANIL, and CoDA."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This is a reasonable model when there is some reason to believe\n   the true model follows the formulation of equation 3.2.\n   It could be interesting to further speculate about the\n   representation capacity or universality of this model.\n   (Section 4 is perhaps a good start to this)\n2. The experimental results clearly demonstrate the\n   capability of the model, especially in how well CAMEL\n   is able to attain a low identification error in Fig 2.\n3. CoDA is a great baseline method to compare against,\n   in addition to MAML/ANIL, and Table 1 clearly summarizes\n   the modeling differences."
            },
            "weaknesses": {
                "value": "1. Every experimental meta-learning setting in this paper\n   seems to be newt\n   This would have been helpful to help better-ground the results\n   in the community, as otherwise it is difficult\n   to understand if the performance improvements are coming\n   from improper implementations of other methods\n   or from a fundamental modeling advancement.\n   For example, MAML with a training step size of 30 and\n   adaptation size of 10 in Table 2 is very arbitrary and\n   unlikely to be the best MAML hyper-parameters here.\n\n   The paper would be significantly more convincing\n   if the CAMEL model was evaluated in the exact experimental settings\n   from CoDA or [Wang et al., NeurIPS 2022](https://arxiv.org/abs/2102.10271),\n   which also meta-learn physical systems with varying amounts of\n   contextual information.\n2. There is a significant amount of omitted related work on\n   meta-reinforcement learning that is also adapting controlled\n   MDP dynamics and policies to multi-task RL settings,\n   e.g., [Nagabandi et al., ICLR 2019](https://arxiv.org/abs/1803.11347)\n   and the citation graph around it.\n3. The term \"interpretable meta-learning\" in the title and\n   throughout the rest of the paper is a big statement without\n   the right qualifications. The paper gets to defining what\n   interpretability means here in proposition 1 of recovering\n   true parameters when they exist and fit into the modeling\n   structure they have set up, but I this is not what I had\n   in mind when I first saw the term \"interpretability\".\n   It also seems like there is still a large amount of\n   uninterpretability in the system, as the model in\n   equation 3.2 still has 2 neural networks."
            },
            "questions": {
                "value": "Overall I think this is a well-executed paper with some\ngood modeling ideas and experimental insights.\nI gave the paper a weak reject due to the experimental settings\nnot being directly comparable to the related work and the\nbaselines not being tuned as much as they could have been,\nand I am especially open to re-evaluating this assessment\nafter hearing the author's perspective on this."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1935/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1935/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1935/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812950335,
        "cdate": 1698812950335,
        "tmdate": 1700153968196,
        "mdate": 1700153968196,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Skunu13TWU",
        "forum": "nnicaG5xiH",
        "replyto": "nnicaG5xiH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1935/Reviewer_rUF2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1935/Reviewer_rUF2"
        ],
        "content": {
            "summary": {
                "value": "This article presents a new meta-learning method, CAMEL, which uses affine task-specific parameters. It is motivated by the application of modelling physical systems, many of which are described in the article. CAMEL is demonstrated on these modelling examples and a robotic control task, with comparisons to state-of-the-art meta-learning methods MAML, ANIL, and CoDA. The interpretability of the method as a means of discover physical parameters is discussed."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The article is well-motivated and well-written. Both the motivation towards interpretable data-driven modelling of physical systems, and the motivation of simplifying meta-learning approaches like MAML, are well justified.\n\nThe proposed CAMEL method appears to be a simple but effective method for meta-learning. The overview of meta-learning approaches, comparing MAML, CoDA, and CAMEL, in section 2.2 provides a useful overview of the different methods. The use of different $w_t$ vectors for different environments is motivated in the text and suitable for physical applications, especially as $w_t$ can be learned used least squares.\n\nThe experimental evaluation of CAMEL is convincing, with a number of different physical modelling systems used for demonstration. CAMEL appears to match or outperform other meta-learning approaches on all tasks, although further details could improve the experimental evaluation (as detailed below). The code is provided and is simple to understand, using PyTorch for single-file implementations of CoDA, MAML/ANIL, and CAMEL."
            },
            "weaknesses": {
                "value": "The experimental results rely heavily on Table 2, however the experimental conditions for these results are not made clear. Specifically, the training details for MAML, ANIL, CoDA, and CAMEL are not fully detailed. The \"Training\" and \"Adaptation\" columns are not described, nor are their units present. The caption states that the table presents the \"Average adaptation mean squared error and computational time,\" but the number of trials over which an average is taken, the standard deviation, the units of computational time, and how computational time was measured are not given. Statistical tests on the significance of values presented in Table 2 would be helpful.\n\nThe argument that CAMEL is an interpretable method relies on the idea that the weight vector $w_t$ learned on the training meta-dataset can correspond to physical parameters of a system. This is explained in Proposition 1, which assumes that the training loss is taken to 0. The authors do point out that identifying the meaning of each parameter, in other words, interpreting the parameters, is out of reach for black-box meta-learning architectures. However, the argument that CAMEL allows for such interpretation is not sufficiently demonstrated in my opinion. The example of learning an electric point charge system is given in section 5.1 and expanded in section B.5, however it relies heavily on the fact that CAMEL is able to learn the dynamics of the system, and not on the interpretability of the resultant parameters. Demonstrating how the learned physical parameters allow for an interpretation of the model and physical system, beyond the performance of CAMEL, would help make this argument. Physics informed neural networks (PINNs) share the same motivation and have been used to present interpretable results; their inclusion in this section and discussion would further improve the interpretability argument. \n\nLastly, the authors appear to only study the case in which $c = c_* = 0$. This is a large simplification. If Equation 3.1 is valid, I believe this means that $h(x;\\theta_0) = 0$, which is quite a departure from other meta-learning methods. If this is the case, the authors should further justify it and potentially explore the case where $c \\neq 0$. If it is not the case, then clarification is needed in section 4.3 as to when this simplification is made.\n\nWhile the article is well-written, it suffers from two minor presentation weaknesses. The first is a reliance on popularity as justification; the popularity of a method does not justify its use. The sentence \"Given the popularity and expressiveness of neural networks, incorporating multi-task learning into their gradient descent training algorithms is a major challenge\" (2.2) is an example. The challenge of multi-task learning is not dependent on the popularity of neural networks, so why is it used as an opening clause? The second formatting issue is minor: works are cited in text when they should be cited in parentheses (although there are also proper uses of in-text citations). See, for example, this paragraph in section 4, where the Ljung citation is correct but the Nelles citation isn't:\n\"System identification and model identifiability are key issues when learning a system (Ljung, 1998). Although deep neural networks are becoming increasingly popular for modeling physical systems, their complex structure makes them impractical for parameter identification in general Nelles (2001).\""
            },
            "questions": {
                "value": "How many trials were used to compute the averages in Table 2?\n\nWhat do the \"Training\" and \"Adaptation\" columns correspond to in Table 2?\n\nHow many gradient steps were used in the various benchmarks?\n\nWere the hyperparameters of the Adam optimizer the same for all benchmarks?\n\nCould common physical parameters be learned in $v_*(x)$? What guarantees that $v_*(x)$ is task-agnostic?\n\nDo the authors consider that their experimental results validate the hypothesis of equation 3.1?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1935/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698847177800,
        "cdate": 1698847177800,
        "tmdate": 1699636124364,
        "mdate": 1699636124364,
        "license": "CC BY 4.0",
        "version": 2
    }
]