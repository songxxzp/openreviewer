[
    {
        "id": "DK6q6TwR7p",
        "forum": "SnlDQ5pL6L",
        "replyto": "SnlDQ5pL6L",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4481/Reviewer_c6gb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4481/Reviewer_c6gb"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a knowledge distillation mechanism for sleep staging. The authors extract the temporal and spatial features based on multi-channel signals.\n\nMeanwhile, a mutual distillation framework is proposed to update teacher and student model. The method was evaluated on two public datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1)The question is interesting. The paper adopts Sleep Knowledge Distillation to decrease the size and computational costs of the existing multi-channel sleep stage\nclassification models;\n2)The paper proposes a spatial-temporal relationship knowledge module to fully extract spatial-temporal knowledge from multi-channel sleep signals\n3) This seems to be the first time that spatiotemporal knowledge distillation has been applied to the classification of sleep stages."
            },
            "weaknesses": {
                "value": "The experiments are not sufficient enough. The authors should compare their KD method with more popular sleep models. In fact, there are some sleep staging model consisting of a less number of model parameters, e.g. TinySleepNet. 3. \u201cAs a result, based on the inspiration of classical sleep models such as DeepSleepNet, we design a CNN and RNN based teacher-student model \u201d . When compared to DeepSleepNet which is a CNN-LSTM based model, TinySleepNet is both more Reviewer #3 lightweight and shares the same structure, so why not design the teacher-student model based on TinySleepNet.\n\nThe main purpose of this paper is to achieve student model lightweighting through knowledge distillation. However, as shown in Tab.2, only the computational costs of teacher and student models are listed. It lacks the comparison with other classical sleep staging models.\n\nIt lacks the comparison with other multi-channel sleep staging model, such as SalientSleepNet"
            },
            "questions": {
                "value": "See Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4481/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698393088627,
        "cdate": 1698393088627,
        "tmdate": 1699636424113,
        "mdate": 1699636424113,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iDtNNnjDiS",
        "forum": "SnlDQ5pL6L",
        "replyto": "SnlDQ5pL6L",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4481/Reviewer_xpJP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4481/Reviewer_xpJP"
        ],
        "content": {
            "summary": {
                "value": "Taking into account spatial knowledge in sleep staging can help improve the model prediction's accuracy. Yet increasing the number of channels can also lead to high computational costs. The authors propose a method to reduce the size of the trained model using knowledge distillation. The paper proposes a new way of extracting spatial and temporal knowledge and an effective knowledge transfer. This new approach is tested over sleep data from two different datasets: MASS-SS3 and ISRUC-III."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper explained the relative work and their method very clearly thanks to good writing and very readable plots.\n\nThe authors propose a new way to deal with spatial information and a new transfer strategy between teacher and student called mutual distillation. This new way of transfer allows for a proper exchange of spatial-temporal knowledge between the two models. This new distillation's importance is proved in complete experimental results comprising a comparison between SOTA knowledge distillation methods and ablation study."
            },
            "weaknesses": {
                "value": "The new mutual distillation needs weight setting. The authors only say that they fixed the weight to 1:5:1 without explaining why this choice was made. The results should be sensitive to the variation of these parameters. Did you try to see the sensitivity of the model to this parameter? How do you select them?\n\nThe authors choose only to use six channels comprising EEG and EOG. In classical sleep staging papers, one usually uses 2 EEGs (like Fpz-Cz and Pz-Cz) and possibly EOG (helping to predict the REM stage) and even EMG (helping to predict the wake stage). How was the number of channels chosen? Why six and not all the available channels? The paper shows in the appendix that using the six available EEG channels in ISTUC-III gives better results.\n\nRecent paper, such as Usleep or RobustSleepNet\n\nThere is no access to the authors' code for reproducibility; maybe it will be available for the potential final version."
            },
            "questions": {
                "value": "To characterize the divergence between the two graphs, you chose to use KL divergence. Do you try other divergences such as TV, MMD, or Wasserstein distance?\n\nDo you try to visualize the graph you obtain at the end of the training or even during training? Do we retrieve a graph base of the Euclidean distance between the channels?\n\nRecent architectures, such as Usleep (https://www.nature.com/articles/s41746-021-00440-5) or RobustSleepNet (https://arxiv.org/abs/2101.02452), train their model on several datasets and give good results on an unseen dataset. Distillation learning proposes to have a smaller model for inference, but I am afraid that your student model will be dataset-specific. It will be interesting to see if such a model can be generalized over a new dataset. With maybe more variability in training set (several dataset)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4481/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4481/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4481/Reviewer_xpJP"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4481/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698412266217,
        "cdate": 1698412266217,
        "tmdate": 1699636424017,
        "mdate": 1699636424017,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "O9YaMlCqZM",
        "forum": "SnlDQ5pL6L",
        "replyto": "SnlDQ5pL6L",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4481/Reviewer_kX3p"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4481/Reviewer_kX3p"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates how to **effectively apply** knowledge distillation (KD) in the spatiotemporal sleep-stage classification task, motivated by the requirement of model efficiency. \n\nThis paper proposes a specific KD solution **tightly combined with the characteristics of sleep signals** by mainly addressing two unique challenges in this task: \n(1) **what knowledge types** related to spatiotemporal signals are useful; and \n(2) **how to transfer** the spatial-temporal knowledge."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper studies an interesting and practical research topic: how to efficiently and effectively transfer knowledge for spatiotemporal signals/models?\n\n2. This paper has its novelty--it proposes a specific KD solution tightly combined with the characteristics of sleep signals.\n\nThere are two technical contributions:\n- **Novel knowledge types for sleep signal:** Channel-to-channel pairwise distances are treated as spatial knowledge type. Epoch-to-epoch pairwise similarities are treated as temporal knowledge type. \n- The paper uses a combination of Mutual Distillation [1] and Relational KD [2] to perform the teacher-student knowledge **transfer**.\n\n[1] Zhang, Ying, et al. \"Deep mutual learning.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.\n[2] Park, Wonpyo, et al. \"Relational knowledge distillation.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.\n\n3. The paper conducted comprehensive experiments to justify the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. Despite its novelty in the sleep classification domain. The technical contributions of this paper might be relatively incremental in the ML/AI community.\n\nFor example, the second contribution (\"how to transfer\") is just a combination of [1] and [2]. \n\n2. The paper has missing discussions on the existing Spatiotemporal Machine Learning works that is not limited to Sleep Analysis field. Spatiotemporal Machine Learning is already a large research area, and a lot of KD-related works emerge in this field.\n \n3. The paper has missing discussions on why the proposed knowledge types are reasonable.\n\nThis paper encodes spatial & temporal knowledge in a separate manner. However, is it not true that spatiotemporal knowledge should be jointly modeled as they are hight entangled?\n\nGiven this awareness, the proposed knowledge types (\"Channel-to-channel distances\" and \"Epoch-to-epoch similarities\") might be outdated, unless the authors can provide the evidence why the separate knowledge types are better than the jointly encoded knowledge."
            },
            "questions": {
                "value": "In Eq.(11-12), shouldn't the Loss terms are gradient? \n\nAlso, Eq.(13-14) never appear in objectives. Where should they belong to?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4481/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698849038264,
        "cdate": 1698849038264,
        "tmdate": 1699636423920,
        "mdate": 1699636423920,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OUF5j3GkeU",
        "forum": "SnlDQ5pL6L",
        "replyto": "SnlDQ5pL6L",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4481/Reviewer_8oup"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4481/Reviewer_8oup"
        ],
        "content": {
            "summary": {
                "value": "The author proposes a distillation framework to mutually transfer both spatial and temporal knowledge from a teacher model to smaller student model."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is easy to follow and presents the goal of the proposed method clearly."
            },
            "weaknesses": {
                "value": "The experimental section of the paper is very unclear. It is unclear what is meant to be the primary models compared against. Simply comparing distillation is not useful as sleep staging is not a task where it is very important. The processing is performed after completion. There is no necessity of real-time processing and complexity is not a big issue. Moreover there is no real analysis of model complexitySimply training a smaller network can be more beneficial than performing distillation even if we want to reduce complexity. There are other papers which use spatial-temporal relationships in sleep staging such as BSTT [1] and GraphSleepNet [2]. At a minimum this process should be compared with these methods. The results presented in Table 4 also does not make sense based on the relative positions of these positions in other papers. ISRUC-III has only 10 subjects so was the evaluation performed on only one subject? That is very unreliable.\n\n\n[1] Liu, Y., & Jia, Z. (2022, September). Bstt: A bayesian spatial-temporal transformer for sleep staging. In The Eleventh International Conference on Learning Representations.\n[2] Jia, Z., Lin, Y., Wang, J., Zhou, R., Ning, X., He, Y., & Zhao, Y. (2021, January). GraphSleepNet: adaptive spatial-temporal graph convolutional networks for sleep stage classification. In Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence (pp. 1324-1330)."
            },
            "questions": {
                "value": "Please address the weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4481/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699052293708,
        "cdate": 1699052293708,
        "tmdate": 1699636423859,
        "mdate": 1699636423859,
        "license": "CC BY 4.0",
        "version": 2
    }
]