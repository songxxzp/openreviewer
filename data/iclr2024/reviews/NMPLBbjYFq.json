[
    {
        "id": "d7dx0snd8Z",
        "forum": "NMPLBbjYFq",
        "replyto": "NMPLBbjYFq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_xNRn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_xNRn"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose to evaluate LLM using two standard games: second-price auctions and beauty games. The author measure the performances using the distance to their canonical Nash equilibria. The author also provide experimental results."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The idea of using games to using LLMs is promising."
            },
            "weaknesses": {
                "value": "There are certain flaws of the approach. Particularly on the point of using stage Nash equilibrium to evaluate LLMs in a repeated game setting."
            },
            "questions": {
                "value": "While I like the idea of using game to evaluate LLMs, I think there are certain flaws of this paper's approach. Particularly, the author claim the distances to Nash equilibria in these games are reasonable measures. While for a one-shot version of these game it does make sense to some extent, I believe this is no longer true for repeated version of these games. The folk theorem in repeated games indicates the set of Nash may far more larger than stage-Nash. For example in the iterated Prisoners' dillemma, the stage-Nash is (defect, defect), but people may usually regard tit-for-tat as a rational strategy. So for repeated games, the problem of equilibrium selection becomes harder.\n\n\nAnother question is about the choices of games. While these two games are very classical, this definitely limited the settings. Furthermore, isn't it possible that the LLMs may already knows like the optimal strategies in these games, given that they are very famous?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2817/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2817/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2817/Reviewer_xNRn"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2817/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698185691633,
        "cdate": 1698185691633,
        "tmdate": 1699636225076,
        "mdate": 1699636225076,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UUm3zEpRXv",
        "forum": "NMPLBbjYFq",
        "replyto": "NMPLBbjYFq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_xpxk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_xpxk"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to assess the strategic reasoning and rationality of large language models (LLMs) in competitive games, specifically focusing on the second price auction and beauty contest game. The paper compares the performance of various versions of GPT-4 and GPT-3.5."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The paper is well-written and organized, making it easy to follow.\n2. Investigating the capability of strategic reasoning in LLMs is important.\n3. The choice of using the second price auction and beauty contest game as an evaluation arena for LLMs is novel."
            },
            "weaknesses": {
                "value": "1. The significance of this paper appears to fall short of the standard of ICLR. As acknowledged by the authors, there are already a few related works that explore the performance of LLMs in economic games with different settings, including various game classes and information provided to LLMs. It is already known that LLMs can exhibit some degree of rationality and strategic reasoning. Although this paper evaluates LLMs under specific new settings, it does not significantly advance our understanding of LLMs in economic games.\n\n2. As a paper that selects \"dataset and benchmark\" as the primary area, the experiments are not thorough enough to support the main claims and reproducibility is questionable. Most importantly, the prompts which are central for reproducibility are not presented.  Moreover, only multiple versions of GPT are considered, neglecting other commonly used LLMs (e.g., Claude 2 or LLama 2) which have been shown to have quite different performances in games compared to GPT, and only the results of average values are reported (e.g., Figure 2 and Figure 4).  Additionally, the paper claims that they have varied the prompts to show the robustness of their results, but these experiments are not presented."
            },
            "questions": {
                "value": "What is the reason for choosing the second-price auction and beauty contest game rather than other zero-sum games, such as matching pennies and rock paper scissors?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2817/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698467189594,
        "cdate": 1698467189594,
        "tmdate": 1699636224880,
        "mdate": 1699636224880,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "APQU7InhH6",
        "forum": "NMPLBbjYFq",
        "replyto": "NMPLBbjYFq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_8dxE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_8dxE"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed to explore competitive games as an evaluation of the rationality and strategic reasoning ability of LLMs. By varying the game history revealed to LLMs-based players, they found that most LLMs are rational in the sense of playing strategies that can increase their payoffs, but not the most rational strategies, i.e., Nash Equilibria (NEs). Moreover, when game history is available, certain types of LLMs can converge faster to the NE strategies. Other abilities of LLMs were tested."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This paper proposed to explore competitive games as an evaluation of the rationality and strategic reasoning ability of LLMs. They can be used to test the abilities of LLMs, i.e., rationality, strategic reasoning ability, and instruction-following capability."
            },
            "weaknesses": {
                "value": "Competitive games exist in the literature. This paper just shows how to design experiments to test the ability of LLMs. That is, this paper did not provide any dataset or benchmark, and then it should not be added to the primary area of datasets and benchmarks as well. \n\nThis paper is not a technical paper on learning representation. Thus, it is not related to ICLR."
            },
            "questions": {
                "value": "."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2817/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698660112572,
        "cdate": 1698660112572,
        "tmdate": 1699636224650,
        "mdate": 1699636224650,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "glv7J3ivSt",
        "forum": "NMPLBbjYFq",
        "replyto": "NMPLBbjYFq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_HCDQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_HCDQ"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates the strategic reasoning abilities of Large Language Models (LLMs) by employing them as rational agents in competitive economic games. The study focuses on the second-price auction and beauty-contest games. It also includes a variation, the self-computing beauty contest game, to analyze the LLMs' ability to adapt strategies based on other agents' behaviors when those agents are instances of the same model. GPT-4, among other models, is highlighted for its capacity to quickly converge to the Nash Equilibrium, demonstrating a strong capability for strategic adjustment and reasoning in this specific case."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Arguing about metrics that associate with the Nash Gap is a systematic approach. This is indeed a straightforward metric to evaluate rationality.\n* The use of self-computing beauty contest games to assess LLMs is an interesting one, compared to having different models in the same auction.\n* The methodology includes running multiple runs and account for the LLMs not responding correctly, an inherent pitfall of their architecture."
            },
            "weaknesses": {
                "value": "* The paper acknowledges the importance of prompt sensitivity but fails to provide a detailed account of prompt structures, limiting the reproducibility of the experiments. It does not investigate different methods of prompting or incorporating historical data into prompts.\n* There is no discussion on whether the stability of outputs in the homogeneous model setting correlates with a consistent strategy distribution between all agents, nor is there an exploration of how the model's temperature setting influences strategy uniformity.\n* The methodology is unclear on whether different rounds were obtained by a chat-based model instantiation, where there are affecting subsequent decisions, or if the models were independently assessed in varied historical contexts, simulating different rounds.\n* The experiments lack scenarios where LLMs interact with actual strategic agents, which would test the models in more realistic strategic environments.\n\nMiscellaneous:\n* The font size in Figure 1 is difficult to read."
            },
            "questions": {
                "value": "* How does the variation in prompt structure affect the strategic decision-making of LLMs, and what would be a good prompt structure to accurately assess their performance?\n* Is the sample size of rounds (e.g., 10 rounds) statistically significant enough to establish the rate at which GPT-4 converges to the optimal strategy? Could one argue that gpt-4 is learning with some arbitrary learning rate over time?\n* What role did the temperature parameter play in the stability of output in games where all models were the same? The paper argues about gpt-4 facing the inconsistency other models. For a given temperature parameter there would also be self-inconsistency. Also, as LLMs are rolled out into ever more realistic scenarios, the assumption of competing with the same agent is not realistic.\n* How were the answers considered? Was it the next token in the generation process, or a number found after allowing the LLM to complete the sentence until reaching the <eos> token?\n* What are the effective ways to prompt LLMs to account for historical information, and how can this be standardized to assess performance sensitivity to prompt phrasing? Since there is sensitivity in the prompt and as the history becomes larger, how is the information of the history compressed into the prompt?\n* Can the strategic behaviors observed in LLMs within the confines of the study be generalized to other forms of competitive games or economic models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2817/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699053771260,
        "cdate": 1699053771260,
        "tmdate": 1699636224576,
        "mdate": 1699636224576,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8GcX7szGS6",
        "forum": "NMPLBbjYFq",
        "replyto": "NMPLBbjYFq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_JmK9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2817/Reviewer_JmK9"
        ],
        "content": {
            "summary": {
                "value": "The authors consider the problem of quantifying the degree of rationality that Large Language Models can exhibit in economic settings. To this end, the authors present a set of economic games in which the authors measure the ratio of the payoff achieved by the LLMs with Nash equilibrium payoffs."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This is a really great direction, and I am very excited about the direction of this paper which seeks to bring game-theoretic tools to the study of LLMs. I hope the authors pursue these directions further!"
            },
            "weaknesses": {
                "value": "The main assumption of the paper, namely that rational agents play a Nash equilibrium, is in my opinion incorrect. More generally, rational agents play a rationalizable action, i.e., the solution concept of interest is rationalizability [1]. In fact, rational agents might not be compelled to play a Nash equilibrium as summarized by following quote from Luce and Raiffa [2, page 63] regarding Nash equilibrium and rationality here is relevant:\n\n> Even if we were tempted at first to call a (Nash) non-conformist 'irrational', we would have to admit that (his opponent) might be 'irrational' in which case it would be 'rational' for (him) to be 'irrational'-to be a (Nash) non-conformist. \n\nThe set of experimental settings are relatively standard, and do not add significantly to the existing literature."
            },
            "questions": {
                "value": "Comments and questions: The measure of rationality provided by the authors seems to become ill-defined if Nash equilibria are not unique, since the equilibrium payoffs are not unique, what do the authors do in such settings?\n\nThe definition of the rationality metric involves time, should I be thinking of this as time-step of a repeated-game? \n\n\n[1] Bernheim, B. Douglas. \"Rationalizable strategic behavior.\" Econometrica: Journal of the Econometric Society (1984): 1007-1028.\n\n[2] Luce, R. Duncan, and Howard Raiffa. Games and decisions: Introduction and critical survey. Courier Corporation, 1989."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2817/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2817/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2817/Reviewer_JmK9"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2817/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699170202061,
        "cdate": 1699170202061,
        "tmdate": 1699636224508,
        "mdate": 1699636224508,
        "license": "CC BY 4.0",
        "version": 2
    }
]