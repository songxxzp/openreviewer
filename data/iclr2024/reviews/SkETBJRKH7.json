[
    {
        "id": "pHEszcOgdw",
        "forum": "SkETBJRKH7",
        "replyto": "SkETBJRKH7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6323/Reviewer_i64f"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6323/Reviewer_i64f"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an architecture that combines multiple Large Language Models (LLMs) by drawing inspiration from the coordination observed in different sub-regions of the prefrontal cortex. The paper demonstrates the ability of the LLM-PFC architecture to successfully solve complex planning tasks when provided with prompts that correspond to the role of each sub-region of the PFC, along with a few in-context examples. This paper shows that this combined approach outperforms zero-shot and in-context learning baselines on both the graph traversal tasks and the Tower of Hanoi (ToH) tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- An interesting and innovative exploration of leveraging insights from neurobiology to enhance the performance of LLMs\n- The prompt engineering efforts are non-trivial"
            },
            "weaknesses": {
                "value": "- The paper lacks a quantitative comparison with other approaches for enhancing LLM performance, such as some of the approaches discussed in the related work section\n- The motivation and contribution of this work are a bit unclear. If the intention is to propose a method for solving planning problems, an analysis of the efficiency and the computational cost would be helpful. If the goal is to connect to the brain, more discussions about the implications of the results on brain research are expected. For example, do we observe more active coordination of sub-regions of the PFC when the subject is solving more difficult tasks? If behaviors exhibited in the PFC-LLM diverge from biological evidence, it may also be helpful to point out the distinctions."
            },
            "questions": {
                "value": "- I am a bit confused about the results shown in the middle panel of Figures 4 and 5: The PFC-LLM architecture produced zero invalid action proposals in both tasks. Does this imply that the Monitor module is unnecessary, given that its role is to identify invalid action proposals? However, this contradicts the ablation study, which demonstrates a significant drop in PFC-LLM performance without the Monitor module. Could the authors provide a little more detailed explanation of this inconsistency?\n- Is it necessary to modularize each step of the planning process? Can some of the steps be combined into a single LLM for efficiency and simplicity?\n- What would be some real-world applications that could benefit from this architecture?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6323/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6323/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6323/Reviewer_i64f"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6323/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811192831,
        "cdate": 1698811192831,
        "tmdate": 1699636695869,
        "mdate": 1699636695869,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "a9vkV4CSkJ",
        "forum": "SkETBJRKH7",
        "replyto": "SkETBJRKH7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6323/Reviewer_upo6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6323/Reviewer_upo6"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces LLM-PFC, a novel method utilizing black box large language models (LLMs) to address planning problems. Inspired by the prefrontal cortex, LLM-PFC consists of a task decomposer, actor, monitor, predictor, evaluator, and task coordinator submodules for decomposing planning problems. The method demonstrates impressive proficiency in multi-step planning, particularly in graph traversal and Tower of Hanoi tasks."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- LLM-PFC outperforms a GPT-4 baseline in several planning problems. Furthermore, the paper analyzes the importance of the components of LLM-PFC. \n- LLM-PFC helps overcome hallucinations in planning problems, demonstrated by the method not outputting invalid actions for either of the considered domains. \n- The paper clearly describes the LLM-PFC submodules and how they interact.\n- The method is easily reproducible since the paper describes the prompts and hyperparameters for the submodules."
            },
            "weaknesses": {
                "value": "- LLM-PFC is a general reasoning and planning method. However, the work only evaluates LLM-PFC in three problems (Valuepath, Steppath, and Tower of Hanoi). Results on additional domains are needed to confirm the usefulness of the method. Even within the domain of the CogEval protocol, the paper states, \"there are more challenging planning tasks (including shortcuts and detour).\" Why does the paper exclude these harder problems, especially given that LLM-PFC is a zero-shot method? Even if LLM-PFC doesn't perform as well in these harder problems, these results would still provide valuable insight into where LLM-PFC fails. \n- The related work section describes several related approaches that use intermediate computations with black box LLMs, such as scratchpads, chain-of-thought, tree-of-thoughts, reflexion, Society of Mind, and Describe-Explain-Plan-Select. The paper does not compare to these methods in the experiments section, even though it appears these methods are directly comparable to LLM-PFC. This makes it difficult to assess the empirical strengths of LLM-PFC over these prior works. \n- The paper needs a more precise characterization of how LLM-PFC relates to prior work. Section 5 states that LLM-PFC shares some components with prior black box approaches but introduces new components and combines components in a novel way. Which components are shared by which prior works? How does LLM-PFC combine these components in a novel manner? \n- While LLM-PFC achieves near-perfect results on Valuepath and Steppath, and outperforms baselines in ToH, what types of failures does it encounter in ToH? The paper should analyze the LLM-PFC failure modes and which components are responsible for failures.\n- Minor: I suggest including y-axis lines in the result figures (Fig 4, 5) to easier see what values the bars correspond to (even with the full values in Appendix A.1).\n\nThe lack of experimental domains demonstrating the applicability of LLM-PFC, along with missing baselines from prior work, are the primary reasons for my final score selection."
            },
            "questions": {
                "value": "- In Fig. 4, is there any insight into why baselines and LLM-PFC achieve similar step counts for successful trajectories?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6323/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817871950,
        "cdate": 1698817871950,
        "tmdate": 1699636695748,
        "mdate": 1699636695748,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0Ldlo4q1oy",
        "forum": "SkETBJRKH7",
        "replyto": "SkETBJRKH7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6323/Reviewer_PrdT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6323/Reviewer_PrdT"
        ],
        "content": {
            "summary": {
                "value": "LLMs often struggle with tasks that require multi-step reasoning and planning. To address this, the authors propose an architecture composed of multiple interacting LLM-based modules inspired by the prefrontal cortex. Each individual module in this architecture is an instance of an LLM constructed through a combination of prompting and in-context learning and has a dedicated role (e.g., the task decomposer breaks down the high-level goal into a sequence of sub-goals). This combined architecture is evaluated on two planning tasks: graph traversal and Tower of Hanoi."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper introduces a new approach that combines multiple LLM instances to tackle problems requiring multi-step reasoning and planning. This architecture, which leverages insights from neuroscience, is interesting. The presentation is clear and ensures that the paper is easily comprehensible."
            },
            "weaknesses": {
                "value": "The experimental evaluation and results are not entirely convincing. In the Valuepath task, GPT-4 ICL performs nearly as well as LLM-PFC. In the Steppath task, the performance of GPT-4 ICL is comparable, except in the 4-step case. \n\nTower of Hanoi is a harder problem, yet ICL achieves approximately 50% success in the 3-disk case. In the 4-disk case, both zero-shot and ICL performance is nearly 0, but even the combined architecture only reaches about ~25% success. The authors do acknowledge this in their conclusion. \n\nMinor: \n- The y-axis tick labels for plots showing %solved (/invalid) should range from 0 to 100, rather than 0 to 1\n- Typo on line 1 of introduction - Devlin et al., 2090"
            },
            "questions": {
                "value": "- What prompts were used for GPT-4 zero-shot and ICL settings? To what extent does performance rely on the specific prompts used, and how much contextual information did these prompts provide in each case?\n- If a greater number of ICL examples were utilized, would performance improvements potentially allow for a match with the combined architecture in at least a subset of the tasks?\n- It appears that the problem descriptions in the prompts for each module are identical. What would be the impact on performance if these descriptions were slightly rephrased for each module?\n- In the evaluation of the Tower of Hanoi task, have you experimented with prompts that incorporate different lists (e.g., X,Y,Z) and numbers than those used in constructing the individual modules?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6323/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698952689762,
        "cdate": 1698952689762,
        "tmdate": 1699636695641,
        "mdate": 1699636695641,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ep1GzAGYiV",
        "forum": "SkETBJRKH7",
        "replyto": "SkETBJRKH7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6323/Reviewer_t84f"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6323/Reviewer_t84f"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a structure of interacting LLMs. The particular structure is organised to match the believed roles of different parts of PFC. The LLMs are wrapped in an overall algorithm that prescribes the role of each LLM, how they talk to each other, and when to stop searching for an answer etc. The way each LLM knows its role is via a specific prompt, and communications from the other LLMs are appended to the prompt. The aim is that the particular structure of interacting LLMs can inherit some of the multi-step planning abilities of PFC. Two tasks are presented - a graph traversal task and a tower of hanoi task - that are hard for individual LLMs to solve. The LLM-PFC improves performance on both tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is very clearly presented. The model is an interesting attempt at integrating our understanding from cognitive and neuroscience into LLMs. The results on the two tasks improve upon GPT on its own."
            },
            "weaknesses": {
                "value": "Only two tasks are presented. These are a fair distance from a wide range of tasks that a general learner can solve. Given the huge computational resources to train GPT and the giant model that it is, these are really very tiny tasks to tackle with such big models. There would need to be a *much* more impressive demonstration of this technique. It\u2019s just way too early to claim this as anything close to a general mechanism, or show that the LLM-PFC is a sensible approach\n\nThe baselines are really quite hindered compared to the proposed model. What happens when you prompt a simple GPT with the whole PFC setup? I.e. tell it that it is a PFC with all these components etc. I.e. can we tease apart the role of a prompt versus the role of the actual architecture of interacting LLMs\u2026"
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6323/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6323/Reviewer_t84f",
                    "ICLR.cc/2024/Conference/Submission6323/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6323/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699246387855,
        "cdate": 1699246387855,
        "tmdate": 1700700706535,
        "mdate": 1700700706535,
        "license": "CC BY 4.0",
        "version": 2
    }
]