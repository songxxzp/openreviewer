[
    {
        "id": "CwBlQYLmoC",
        "forum": "6SNyuiph3F",
        "replyto": "6SNyuiph3F",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9220/Reviewer_uV1v"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9220/Reviewer_uV1v"
        ],
        "content": {
            "summary": {
                "value": "This work proposes an approach to swiftly equip the chat capability to a LLM of a new language, by leveraging the \"chat vector\" based on the concept of \"task vector\" proposed by Ilharco et al., 2023. Specifically, \"chat vector\" is simply the weight difference between a plain LLM and its chat-finetuned version (on English LLaMA), which represents the acquired chat ability of the LLM, and can be synergized through vector addition on a new LLM. The authors conduct experiments primarily on Traditional Chinese, examining the instruction following, multi-turn dialogue and toxicity after applying \"chat vector\" on Traditional Chinese LLaMA."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This works presents an interesting perspective to adapt chat capability to LLMs by directly applying the idea of \"task vector\", which is extremely simple and does not require any training. This can be a direction to further investigate in future research, complementary to the SFT/RLHF training.\n- A new dataset for SFT in Traditional Chinese is also introduced through \"self-instruct\", which can be a good resource for community if it is released."
            },
            "weaknesses": {
                "value": "I found the evaluation has certain flaws as follows:\n\n- The evaluation on the instruction following adopts GPT4 to provide a score on how close the LLM's response is to the GPT4's response. This process could have large variance, and a low score does not necessarily mean a bad response (since only one reference from GPT4 is being compared). To the extreme extend, if we ask GPT4 to generate a new response, and compare with its old response, the score might also be low. Without showing the variance, I don't think this protocol could evaluate the response reliably. It is mentioned in Section 4.3 that this decision is to avoid calling GPT4 n^2 times (n being the number of models to compare); however, I would suggest to at least compare these two models in this way: \"llama2 \u2192 CP \u2192 FT\" and \"llama2 \u2192 CP + chat vector\", to better evaluate the performance of adding \"chat vector\".\n  \n- Obtaining the chat capability by simply adding \"chat vector\" on a new LLM seems too good to be true, and it would be good to provide some qualitative responses, providing more insights on its effect. However, the paper did not show any responses by adding \"chat vector\" alone. The only example shown in Figure 2 is when combining SFT with chat vector together. It is not directly convincing that by adding chat vector, \"llama2 \u2192 CP + chat vector\" is able to perform better than \"llama2 \u2192 CP \u2192 FT\" according to human standards; more evidence needs to be shown in addition to Table 1."
            },
            "questions": {
                "value": "See weaknesses.\n\nAlso, for the same example shown in Figure 2, is it possible to also provide the response from the version \"llama2 \u2192 CP + chat vector\"?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9220/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9220/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9220/Reviewer_uV1v"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698724068368,
        "cdate": 1698724068368,
        "tmdate": 1700808124282,
        "mdate": 1700808124282,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YRb8nVsLve",
        "forum": "6SNyuiph3F",
        "replyto": "6SNyuiph3F",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9220/Reviewer_PhbB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9220/Reviewer_PhbB"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to adopt a the difference vector between LLAMA2 and LLAMA2-Chat as a Chat Vector and achieves computational efficient linguistic transfer on other languages, e.g. Traditional Chinese. The method is incredibly easy and might bring some potential to achieve efficient linguistic transfer for Large Language Models. The authors conduct experiments on three languages across various task completion benchmarks to demonstrate the effectiveness of the method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method is incredibly easy. If it is solid, the linguistic transfer from high-quality LLAMA to other LLMs will be incredibly efficient and easy.\n\n2. The paper focuses on developing LLMs for people using minor-languages, which is huge contributions."
            },
            "weaknesses": {
                "value": "1. The theoretical basis for Chat Vector is too weak. The task vector which motivates this paper is reasonable in its hypothesis. The task vector can be regarded as a kind of meta-learning setting, in which the pre-trained LLM is close to a near-convergence and general point in the meta-learning space and the task-specific fine-tuning can drive the model to the task-specific convergence. In this way, such task vector can be regarded as a vector pointing from the general LLM point to the task-specific point. However, if we transfer the task vector to your chat vector, your task is a multi-task learning manner to align LLM with human preference. In this way, what is the meaning or physical representation of such chat vector?\n\n2. The evaluation is not sufficient to demonstrate the effectiveness. Please also consider to add MT-Bench, MMLU, which are more commonly used to evaluate the performance of LLMs.\n\n3. I have some concerns with the fairness of the experiments. Considering that the CP process only involves 3.1B tokens, the model after CP is less likely to be trained well to the Traditional Chinese domain. (The pre-training of LLAMA involves 2.4T tokens, 3.1B is only 0.13%). In this way, your baseline CP+FT is underfitting and has not converged, making it as a weak baseline. It is easy to demonstrate this hypothesis that the gap between CP+FT and CP+FT+Chat Vector on Chinese-LLAMA is much less than that on Traditional Chinese LLAMA you trained. This is because that the pre-training for Chinese-LLAMA is 120GB corpus, which is much sufficient to adapt LLAMA to the new language. Chinese-LLAMA is also not trained well but the performance improvement is not remarkable compared with the improvement on Traditional Chinese. I guess there might be some scaling law here. If your CP is sufficient and scaled up, you might finally found that the Chat Vector's contribution is less."
            },
            "questions": {
                "value": "1. Why you did not translate your fine-tuning dataset to Korean and Simplified Chinese? In this way, you can start with Chinese-LLAMA and Korean-LLAMA to do the same fine-tuning process, which makes the comparisons across different languages much more fair.\n\n2. What is the evaluation benchmark reported in Table 1? Is it Vicuna Benchmark?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9220/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9220/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9220/Reviewer_PhbB"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698823056988,
        "cdate": 1698823056988,
        "tmdate": 1699637160234,
        "mdate": 1699637160234,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "V6CUfoGhzq",
        "forum": "6SNyuiph3F",
        "replyto": "6SNyuiph3F",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9220/Reviewer_ERju"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9220/Reviewer_ERju"
        ],
        "content": {
            "summary": {
                "value": "What is this paper about, what contributions does it make?\nThis paper focuses on developing Large Language Models (LLMs) for non-English languages, emphasizing alignment with human preferences. The method  leverages chat vector to synergize pre-existing knowledge and behaviors in LLMs. It  enables Large Language Models (LLMs) to exhibit conversational skills by incorporating the chat vector into the model. The method is evaluated on toxicity, ability of instruction following, and multi-turn dialogue. \n\nWhat contributions does it make: \nThe paper introduces an approach to enable Large Language Models(LLMs) to exhibit conversational skills and operate in accordance with human expectations in a target language by incorporating the chat vector into the model with the same architecture."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.The method can can be used for multiple languages. \n2.The chat vector proposed by the paper simplifies the traditional training paradigm."
            },
            "weaknesses": {
                "value": "1.It is not intuitive that a chat vector can represents the parameter difference between a chat model and PLM. More interpretable experiments are needed here. \n2.The novelty of this paper is limited as the idea stems from Ilharco et al. (2023). \n3.The paper does not mention the details of parameters setting, which is not easy for others to reproduce and use.\n4.The experiment is built on LLaMA as well as the baselines. Other base LLMs are encouraged to be included.\n5.The text in the picture is too small."
            },
            "questions": {
                "value": "What is distinct contribution of this paper comparing with Ilharco et al. (2023)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698937204993,
        "cdate": 1698937204993,
        "tmdate": 1699637160104,
        "mdate": 1699637160104,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VoQLVUgpbN",
        "forum": "6SNyuiph3F",
        "replyto": "6SNyuiph3F",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9220/Reviewer_X3rn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9220/Reviewer_X3rn"
        ],
        "content": {
            "summary": {
                "value": "This manuscript presents an innovative concept that focuses on transferring the chat functionalities of large language models (LLMs) to an additional linguistic domain. The rationale is based on leveraging the \"task vector\" inherent within pre-trained models, viewing conversation as a distinct task. The empirical study utilizes the LLaMA2 framework, aiming to extract and apply the conversational task vector from LLMs trained on Simplified Chinese and Korean to a Traditional Chinese setting."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The subject matter of extending the utility of LLMs to encompass a broader range of languages is of significant relevance, and the authors approach this with a methodology that is both novel and straightforward.\n\n2. The manuscript is well-structured, particularly in the introduction, review of related literature, and methodological explanation, allowing for clear comprehension of the proposed ideas.\n\n3. The paper addresses a pertinent area of LLM research, offering insights that I recommend for review by fellow researchers in the field."
            },
            "weaknesses": {
                "value": "1. The methodological framework introduced appears to be in its nascent stages and could benefit from a more robust theoretical underpinning. The authors' approach of utilizing the entirety of the chat vector from the model warrants further exploration. A more granular analysis, such as the selective use of model parameters (for instance, only the feedforward neural network layers), may enhance the efficacy of the transfer and minimize unintended model behaviors. This suggestion is not to imply that the simplicity of the method is a drawback; rather, a more in-depth investigation could yield richer contributions to the field.\n\n2. The experimental design, while based on an appealing premise, is somewhat limited in scope. The paper's evaluation focuses solely on Traditional Chinese as the new language, with Simplified Chinese as the source. Given the linguistic similarities between these two variants of Chinese, the challenge for the LLMs may be less pronounced, which in turn affects the persuasiveness of the results. It is recommended that subsequent iterations of the research consider a more diverse set of language pairs to strengthen the validity of the experimental findings.\n\n3. There is room for improvement in the clarity and presentation of the data, especially in the main results table (referred to as Table 1 in the manuscript). For instance, if all experimental configurations require continual pretraining (CP), it may be redundant to list this in the table. A more streamlined presentation could assist readers in readily identifying the critical findings of the study.\n\nIn conclusion, while the paper introduces a compelling avenue for research within the field of LLMs and language transferability, I encourage the authors to address the identified areas of weakness to reinforce the overall impact and scientific contribution of their work."
            },
            "questions": {
                "value": "Refer to the above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9220/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699273426261,
        "cdate": 1699273426261,
        "tmdate": 1699637159944,
        "mdate": 1699637159944,
        "license": "CC BY 4.0",
        "version": 2
    }
]