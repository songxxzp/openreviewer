[
    {
        "id": "vf1vSFHRO6",
        "forum": "hQ28OHX2sv",
        "replyto": "hQ28OHX2sv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7411/Reviewer_m6gj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7411/Reviewer_m6gj"
        ],
        "content": {
            "summary": {
                "value": "This paper shows that transformers can approximate gradient descent on 2-layer and n-layer neural networks. It uses the capabilities of neural networks as a bridge to understand the in-context abilities of transformers"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The expressive power of transformers for performing gradient descent on n-layer neural networks is a novel result."
            },
            "weaknesses": {
                "value": "1. The writing of the paper is very poor, and the paper's readability should be improved. Just to point out a bit, \nin def 3, statements are introduced with many notations unspecified, e.g. Sobolev space, m, n;  \n2. The paper seems to have a strong connection with Bai et al, 2023, in. notations and results, their result naturally extends to the multi-layer setting. The novelty and contribution of the paper compared to Bai et al, 2023 is not clear to me. \n3. The methodology of this paper is to first connect the transformer's expressive ability and neural networks, and then use the well-established approximation ability of neural networks, both of these two parts look not novel enough.\n\n\n\n[1] Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection. Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, Song Mei, 2023"
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7411/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7411/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7411/Reviewer_m6gj"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7411/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698441674944,
        "cdate": 1698441674944,
        "tmdate": 1699636888463,
        "mdate": 1699636888463,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pqzFOg1seC",
        "forum": "hQ28OHX2sv",
        "replyto": "hQ28OHX2sv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7411/Reviewer_Ah1w"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7411/Reviewer_Ah1w"
        ],
        "content": {
            "summary": {
                "value": "This paper studies how transformers approximate n-layer neural networks by gradient descent and its variants. The theoretical results characterize the required number of heads, hidden dimensions, and layers of transformers. The authors also provide a comparison between deep, narrow networks with shallow, wide networks in terms of computational resources.\n\n\n----------------------------\n\n**After rebuttal**: Thank you for your response, and sorry for the late reply. I am sorry that I will keep the rating of 3. There are several reasons. (1) Weaknesses 1, 2, and 3 are not answered. (2) It is not a good reason to say other papers don't do experiments. First, I always feel that no experiment is a disadvantage. Second, I think other papers without experiments have their own originality and contributions such that they get accepted. I am not satisfied with the contributions in this paper, so experiments could be a complement."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem to be solved is significant and interesting to the community. \n2. This work extends the analysis to deep neural networks and makes a comparison between shallow networks and deep networks."
            },
            "weaknesses": {
                "value": "1. The biggest concern is the technical contributions of this work. I treat this work as a follow-up work of [Bai et al., 2023]. Therefore, it is very important to state the contribution beyond this existing work. I am not sure of the difficulty and the novelty of proving Theorem 2.\n\n2. This work lacks empirical justification. \n\n3. The complete proof of Theorem 1,3,4 are not provided\n\n[Bai et al., 2023]: Transformers as statisticians: Provable in-context learning with in-context algorithm selection."
            },
            "questions": {
                "value": "1. Can you show the comparison between deep, narrow networks and shallow, wide networks by experiments?\n\n2. What is the definition of $\\mathcal{W}$, the domain of $\\bf{w}$? I do feel Assumption 2 is too strong. Is the existence of the MLP layer in Assumption 2 provable rather than assumed?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7411/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7411/Reviewer_Ah1w",
                    "ICLR.cc/2024/Conference/Submission7411/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7411/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698680617549,
        "cdate": 1698680617549,
        "tmdate": 1700786903624,
        "mdate": 1700786903624,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HK9vFTRe4c",
        "forum": "hQ28OHX2sv",
        "replyto": "hQ28OHX2sv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7411/Reviewer_SDBk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7411/Reviewer_SDBk"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the in-context learning capabilities of Transformer-based models. It is shown by construction that Transformer can approximately implement gradient descent steps on the parameters of certain neural networks, where the upper bounds on the required number of heads, hidden size, and number of layers are provided. This suggests that Transformer can perform in-context learning by approximating a neural network."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The in-context learning capability of Transformer is an important topic recently in the community. This paper provides an interesting perspective of explaining the in-context learning performance of Transformer. The authors have clearly explained their idea, and the presentation is easy to follow."
            },
            "weaknesses": {
                "value": "- The main result presents the existence of the weights that enable Transformer to do gradient descent on a certain neural network. It is not shown if Transformer can be actually trained to do so.\n- Theorem 3 and Theorem 4 only provide upper bounds, which do not necessarily suggest a separation.\n- It seems that many recent papers on in-context learning of Transformer are missing. One of the most related ones is \n    - Trainable transformer in transformer. Panigrahi, Abhishek and Malladi, Sadhika and Xia, Mengzhou and Arora, Sanjeev.\n- There are no numerical experiments supporting the theoretical results.\n- Typo: Under Definition 2, \"We doesn't\" -> \"We do not\""
            },
            "questions": {
                "value": "1. In Definition 3, what is the definition of $W_{loc}^{m,\\infty}(\\mathbb{R})$?\n2. It is not clear to me what Assumption 2 means. Is there a concrete example?\n3. In Assumption 1, it is not clear to me what it suggests for the loss function to have finite Barron norm. According to the definition, it seems that we then need $\\ell(w) \\to 0$ as $\\|w\\| \\to \\infty$. Does the commonly-used $\\ell_2$ loss satisfy this?\n4. I find the results in Section 4 a bit confusing. Specifically, what does it mean by \"learn the neural network\"? Is it about doing gradient descent on certain loss? Otherwise, how is this related to the results in Sections?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7411/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699147643645,
        "cdate": 1699147643645,
        "tmdate": 1699636888231,
        "mdate": 1699636888231,
        "license": "CC BY 4.0",
        "version": 2
    }
]