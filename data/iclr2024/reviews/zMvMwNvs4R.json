[
    {
        "id": "Q3hjPl2N4t",
        "forum": "zMvMwNvs4R",
        "replyto": "zMvMwNvs4R",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6463/Reviewer_p8xo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6463/Reviewer_p8xo"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for automatically identifying which data points are potentially noisy.\nSpecifically, this is done based on identifying points that have high L2 norms of the error and removing them from the loss function."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Overall, I do really like the concept of the paper. It is simple and generally makes sense.\n* The method seems to have strong empirical results in synthetic settings, and reasonable experimental results in less synthetic settings.\n* Figure 4 is a nice analysis demonstrating that intuitively why the proposed method is better than log likelihood."
            },
            "weaknesses": {
                "value": "I have a few concerns about the paper:\n\n* It seems that some hyperparameter tuning (detailed in appendix C) was done for all of the loss modification methods, but none was done for MLE. Because of this, perhaps some of the gains over MLE can be attributed to randomness in training, rather than to inherent goodness of the method.\n* The results on real-world datasets (sections 5.3 and 5.4) are somewhat underwhelming. I see small gains (and perhaps small gains are a good result already given how simple the method is), but I'm also a little bit concerned whether these are interesting enough for practitioners to be excited and go back and implement/use this method. Overall, I feel like the paper lacks a big convincing results, such as  significant improvements to SOTA on a dataset that people care about.\n\nNote that I am not saying that the work is solid, it seems to be done reasonably well, I'm just not sure how much impact it will have on the community given the current empirical evidence."
            },
            "questions": {
                "value": "1. How was the thereshold hyperparameter tuned in all experiments in the experimental section?\n2. I was confused by the second equation in section 3, should it be a \"less-than\" sign rather than a \"greater-than\" sign?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6463/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6463/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6463/Reviewer_p8xo"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6463/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698940784512,
        "cdate": 1698940784512,
        "tmdate": 1700611098859,
        "mdate": 1700611098859,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "k9r1sdSmt5",
        "forum": "zMvMwNvs4R",
        "replyto": "zMvMwNvs4R",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6463/Reviewer_Fsrz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6463/Reviewer_Fsrz"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new method for noisy data truncation. It computes the l2 norm of the difference between the model's token distribution and the one-hot groundtruth. The error norm provides a measure of data quality. The Experiments on language modeling, machine translation, and summarization demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The proposed method is simple, effective, and robust.\n- The analysis experiments are insightful.\n- The experiment results on language modeling, machine translation, and summarization are comprehensive and the results are good."
            },
            "weaknesses": {
                "value": "- The improvements over existing methods seem marginal in some experiments.\n- The motivation of the proposed method is a bit unclear to me. See my question below."
            },
            "questions": {
                "value": "One motivation of the proposed method is that previous works treat all non-ground truth tokens as equally incorrect. However, I do not see how the proposed method solve this problem. In my opinion, all non-ground truth tokens are treated in the same way in the proposed method. can you explain?\n\nFollowing above, I think one potential improved version of the proposed method is to take into account the similarity between non-ground truth tokens and ground truth tokens when computing the l2 norm."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6463/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698990153681,
        "cdate": 1698990153681,
        "tmdate": 1699636722608,
        "mdate": 1699636722608,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YS16XhSTXv",
        "forum": "zMvMwNvs4R",
        "replyto": "zMvMwNvs4R",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6463/Reviewer_FiyE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6463/Reviewer_FiyE"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method called Error Norm Truncation (ENT) to enhance the robustness of text generation models against errors in the training data. The Error Norm Truncation (ENT) method is to truncate training data with high L2 error norm. The comprehensive experiments show that ENT improves the robustness of language models and machine translation models against various types of noise and outperforms previous methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper studies a fundamental issue in training neural models. \n- The proposed method is easy to implement and sounds appealing.\n- Experiments show that the proposed method can outperform previous methods on some tasks such as machine translation and language modeling."
            },
            "weaknesses": {
                "value": "- Even though the results have proven the effectiveness of ENT, I think the motivation of using error norm to estimate data quality can be further discussed and provide more insights about how do they correlate. \n - Theoretically, whether an example is helpful to train a model not only depends on the correctness of its label but also on the uncertainty (or entropy) of this example, according to the lessons from active learning. As uncertainty also takes into account of the prob of non-targets as ENT does. Therefore, it would be important to discuss the relationship between uncertainty and ENT in this paper.  \n- The proposed method achieves significant improvements on simulated training data with manually added noise (with two types of noise) but it only yields modest improvements on the standard benchmarks where training data may contain less noise. Therefore, it would be helpful if the proposed method works well on natuarally noisy benchmarks. Of course, it may be difficult to collect a large scale of training data and thus it is practical to apply the proposed method under the finetuning scenario, where a small scale of naturally noisy data is used for finetuning (for example, there is such a shared task in WMT).   \n\u000bp.s. I know there is no time for authors to add new experiments into the paper, because I am an emergency reviewer and submit the reviews just before the deadline. However, I would be happy to see more experiments from the dialog box in the openreview system a couple of days later."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6463/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6463/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6463/Reviewer_FiyE"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6463/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1700655333735,
        "cdate": 1700655333735,
        "tmdate": 1700655333735,
        "mdate": 1700655333735,
        "license": "CC BY 4.0",
        "version": 2
    }
]