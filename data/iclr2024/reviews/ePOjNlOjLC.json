[
    {
        "id": "j8JOzYqmUY",
        "forum": "ePOjNlOjLC",
        "replyto": "ePOjNlOjLC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7628/Reviewer_45wn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7628/Reviewer_45wn"
        ],
        "content": {
            "summary": {
                "value": "This manuscript proposes a new method called Cyclic One-Way Diffusion that integrates diffusion in physics and diffusion in deep learning, providing a learning-free manner by controlling the direction of diffusion in various customization application scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The article proposed a novel method from a new perspective to utilize the capabilities of the diffusion model.\n2. A learning-free manner can be widely used in personality customization with one or several conditions.\n3. The experiment results show good performance."
            },
            "weaknesses": {
                "value": "1. The approach lacks a theoretical foundation, so it is not very intuitive to express why it can work.\n2. The results of comparison methods are a bit too bad. More information about the setting should be given."
            },
            "questions": {
                "value": "I have some questions for the author to further improve this work.\n1. For the consideration of reproducibility, the code of the proposed method is suggested to be provided.\n2. Are the comparison methods learning-free? If so, it would be beneficial to provide additional details about the experimental settings. Furthermore, for the comparison experiments, it might be advisable to incorporate some learning-free methods, such as LIVR [1], to ensure a comprehensive evaluation.\n3. Sections 3.2 and 3.3 lack a theoretical foundation or pseudo-code to facilitate clearer understanding and reading.\n4. It is not clear in Section 3.3, paragraph 4. What is the difference between two steps/two ends and t-th diffusion step, and how to use them?\n5. The evaluation in Table 2 and in Section 4.2 is not matched."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698735789609,
        "cdate": 1698735789609,
        "tmdate": 1699636926779,
        "mdate": 1699636926779,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TNCqKGnuPr",
        "forum": "ePOjNlOjLC",
        "replyto": "ePOjNlOjLC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7628/Reviewer_4D12"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7628/Reviewer_4D12"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a ``diffusion in diffusion'' approach that leverages both physical diffusion and learning-based diffusion for the text-vision-conditioned generation, e.g., in painting, attribute editing and style transfer. The proposed method is based on inverse seed initialization and \"disturb\" and \"construct\" cycles for diffusion.  The proposed method is justified to be able to generate realistic image with higher ID-Distance and Face detection rates."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) The idea of diffusion in diffusion for diffusing image to generate consistent background content in the diffusion process is an interesting idea, and can be combined with the pre-trained diffusion model without retraining.\n\n(2) The experiments on inpainting with visual condition, text-vision-conditioned generation showed that the proposed approach can produce realistic images."
            },
            "weaknesses": {
                "value": "The overall idea of this approach is interesting. I have some questions mainly on the experimental justifications as follows.\n\n1. Most of these examples are based on putting an object in bounding box to a large image by adding backgrounds. This setting has applications, however, whether this approach can be applied to whole image generation/editing instead of pasting object on a larger image.\n\n2. In the main body of this paper, the authors should present failure cases if it has, and analyze the reasons.\n\n3. The inner diffusion cycles for \"disturb\", \"reconstruct\" may introduce additional computational overhead. More details on the computational balance on the number of cycles and its effect on the results should be given. \n\n4. There are typos in the paper, e.g., t around eq.(1). Please check the whole paper. \n\n5. On page 4, the cycles are divided into three phases. Is there strict division boundary between these phases, and why these discussions are introduced to the main body of this paper, and how to support these conclusions on the existing of three phases."
            },
            "questions": {
                "value": "Please see above for my questions on the experiments and discussions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698803110445,
        "cdate": 1698803110445,
        "tmdate": 1699636926653,
        "mdate": 1699636926653,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nppLrKh1J7",
        "forum": "ePOjNlOjLC",
        "replyto": "ePOjNlOjLC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7628/Reviewer_S1EF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7628/Reviewer_S1EF"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a training-free method to better preserve the visual conditions in diffusion-based text-vision-conditioned image generation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is well-written and easy to follow. The idea is clearly illustrated.\n\n2. The proposed method is elegant and straightforward to preserve the visual condition."
            },
            "weaknesses": {
                "value": "1. The proposed method repeatedly replaces part of the diffusion latent variable x_t with the corresponding visual condition, which strongly maintains the visual condition in the generated image. However, this method may have an intrinsic drawback: the visual condition may be too strong and conflict with other conditions. in which case, the generated image may be unrealistic.\n\n2. There are no quantitative analyses of the number of cycles, or positions of the start and end points. These experiments are important for us to understand the effectiveness of the proposed method.\n\n3. According to Table 1, the proposed method is inferior to SD inpainting on both performance and efficiency. The only superiority of the proposed method is training free. However, since it needs cyclical diffusion & denoising, its inference cost is higher than SD inpainting. The superiority may be weakened."
            },
            "questions": {
                "value": "See the weakness above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698823457773,
        "cdate": 1698823457773,
        "tmdate": 1699636926536,
        "mdate": 1699636926536,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wbNquQwwrx",
        "forum": "ePOjNlOjLC",
        "replyto": "ePOjNlOjLC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7628/Reviewer_SshV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7628/Reviewer_SshV"
        ],
        "content": {
            "summary": {
                "value": "This manuscript investigates the diffusion-in-diffusion processes\naiming to enable effective both pixel-level and semantic-level \nvisual conditioning. A cyclic one-way diffusion\nmethod is proposed. The cyclic method starts with an image and builds \nthe entire scene according to the text information, given a pre-trained \nfrozen diffusion model.\n\nExtensive experiments are provided for various applications.\nExperimental results, included human evaluation are provided.\nThe experiments and evaluations demonstrate that the proposed method \ncan generate images with high fidelity to both semantic-text\nand pixel-visual conditions."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The manuscript proposes a diffusion-in-diffusion process which is able to enable effective both pixel-level and semantic-level visual conditioning.\n- Extensive experiment results are provided for various applications.\n-The results indicate that the proposed method can generate images with high fidelity to both semantic-text and pixel-visual conditions."
            },
            "weaknesses": {
                "value": "-"
            },
            "questions": {
                "value": "What is the level of changes that may occur in the region on the seed image following the cyclic one-way diffusion?\nAccording to the results presented some changes occur sometimes in the region of the seed image from the generated image, but not in \nother cases presented."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7628/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7628/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7628/Reviewer_SshV"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699105968217,
        "cdate": 1699105968217,
        "tmdate": 1699636926420,
        "mdate": 1699636926420,
        "license": "CC BY 4.0",
        "version": 2
    }
]