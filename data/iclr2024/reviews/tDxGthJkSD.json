[
    {
        "id": "izg5E7k2Gr",
        "forum": "tDxGthJkSD",
        "replyto": "tDxGthJkSD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6749/Reviewer_Hvbn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6749/Reviewer_Hvbn"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel classification loss, regression loss, and positive anchor sample strategy. The losses are designed based on both the classification and regression quality on the anchors. The proposed method is evaluated on the coco validation dataset with FCOS+ATSS and RetinaNet."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The designed losses use an RCI and a CF module to supervise classification and regression consistently on \"difficult-to-train\" samples.  An anchor selection strategy is proposed to find more optimizable samples."
            },
            "weaknesses": {
                "value": "- There are many parameters involved in the loss, such as theta, mu, alpha, ep, gamma, and l in EATSS, which makes the design complicated and has low generalization ability.\n- Compared with the state-of-the-art methods, the performances are not strong enough. As the results shown in Table 8 and Table 9, the improvement is about 0.2 (37.6 vs. 37.4 for Retina, 40.4 vs. 40.2 QFL, 37.4 vs. 37.2 F-EIoU, 40.2 vs. 40.0 GIoU).\n- The EATSS seems to have a small influence on the results (41.3 vs. 41.2 AP). \n- Can the method be applied to more advanced detectors, like the two-stage Faster RCNN, and transformer-based DETR? Since the detector architecture FCOS, ATSS, and RetinaNet is classical but old, the proposed method will be more solid if the loss is valid on the recent stronger detector."
            },
            "questions": {
                "value": "see the \"Weakness\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Reviewer_Hvbn"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6749/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697627312216,
        "cdate": 1697627312216,
        "tmdate": 1699636777410,
        "mdate": 1699636777410,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "X1DWUruE4L",
        "forum": "tDxGthJkSD",
        "replyto": "tDxGthJkSD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6749/Reviewer_gHLc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6749/Reviewer_gHLc"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes HCRAL to tackle the inconsistency problem between classification and localization. The methods mainly involve classification loss, regression loss, and label assignment. All the proposed modules follow the key idea of hard example mining to focus more on the difficult-to-train samples within each task. The presentation lacks clarity. The experimental results are not state-of-the-art."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Further study on the inconsistency problem between classification and localization is meaningful."
            },
            "weaknesses": {
                "value": "1. The proposed methods introduce many hyper-parameters, which must be tuned carefully. This undermines the generality of the methods. The method designs are technically complicated, involving both loss functions and label assignment. I suggest the author simply the method. \n\n2. The presentation of the experiment section is poor. What is the baseline in Tables 1,2,3 and 4? Also, Table 2 is weird since you report the results for various $\\gamma$ in HCRAC, however, it is $\\mu$. Where do you mention Table 5 in the context? It loses the connection. What is the baseline in Table 5? It is hard to believe that FCOS+ATSS got a 41.2 AP score.\n\n3. The motivation is somewhat unclear. Why did you choose to design the three rules in Sec. 3.1.1 and Sec. 3.1.2?\n\n4. There are many highly related works that aim to solve the inconsistency problem between classification and localization missing comparison and reference, e.g. AutoAssign [1], OTA [2], DW [3]. Particularly, the proposed method does not surpass DW on the COCO test-dev set, which is auxiliary-module-free.\n\n5. The improvement is almost non-existent. And more importantly, the reported SOTA results of previous methods are lower than the reference. As shown in Table 7, under the backbone R50, HCRAL only achieves 44.4 vs VFNet 44.8 [4] and GFLv2 44.3 [5]. Under the backbone R101, HCRAL 46.1 vs VFNet 46.7 and GFLv2 46.2. Under R101-DCN, HCRAL 49.3 vs VFNet 49.2.\n\n6. There is a mistake in the proposed method. In the last paragraph of page 5, \"the coordinates are partitioned into two regions based on $y(Score) = x(IoU) + \\alpha$. In region 1, where samples exhibit higher scores compared to IoU values...\" Clearly, $\\alpha<0$. The samples just between the red line and the yellow line do not exhibit higher scores compared to IoU values.\n\n7. The quality of the paper writing is low. It is difficult to understand the proposed method. Some variables are described before their formal appearance, e.g., \"c is the diagonal length of the smallest enclosing box...\" in Sec. 3.1.2. \n\n    The appearance of the term $\\mathcal{R}_{DIoU}$ is also very strange. It is not used in the previous equations. Besides, the description of EATSS in Sec. 3.2 is hard to understand. You'd better write down equations and variables, especially steps 4 and 6 in the algorithm.\n\n    What is the \"consensus matrix\" mentioned below Eqn. 5?\n\n    In the abstract, you can say \"In object detectors, ...\"\n\n    On page 5, there is a typo \"The the properties 1 and 2...\"\n\n    In the last paragraph of page 6, \"to optimize RCI for every **ground** truth\". And \"...so as to find the biggest boundary to find a positive sample, .\" Remove the comma.\n\n[1] Zhu B, Wang J, Jiang Z, et al. AutoAssign: Differentiable label assignment for dense object detection[J]. arXiv preprint arXiv:2007.03496, 2020.\n\n[2] Ge Z, Liu S, Li Z, et al. OTA: Optimal transport assignment for object detection. CVPR 2021.\n\n[3] Li S, He C, Li R, et al. A dual weighting label assignment scheme for object detection. CVPR 2022.\n\n[4] Haoyang Zhang, Ying Wang, Feras Dayoub, and Niko S\u00fcnderhauf. Varifocalnet: An iou-aware dense object detector. CVPR 2021.\n\n[5] Xiang Li, Wenhai Wang, Xiaolin Hu, Jun Li, Jinhui Tang, and Jian Yang. Generalized focal loss V2: learning reliable localization quality estimation for dense object detection. CVPR 2021."
            },
            "questions": {
                "value": "see weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Reviewer_gHLc"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6749/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698302689902,
        "cdate": 1698302689902,
        "tmdate": 1699636777283,
        "mdate": 1699636777283,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9LpQwErDlp",
        "forum": "tDxGthJkSD",
        "replyto": "tDxGthJkSD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6749/Reviewer_uUTZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6749/Reviewer_uUTZ"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a method which re-weights the classification and regression loss adhering to desired behaviour such as higher classification loss for high IoU samples etc. This is achieved through handcrafted functions to produce the weights. The authors also propose a method EATSS to increase the number of positive samples. The experiments are conducted on COCO using FCOS+ATSS and RetinaNet."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The strengths of this paper lie in the authors ability to highlight the subtle benefits of reweighing the losses according to the desired behaviour such as having high weights on classification for a box with large IoU and high regression weights if the class is correct. This enables the method to improve final performance."
            },
            "weaknesses": {
                "value": "* One of the main weaknesses is the presentation, I found it quite hard to follow due to it being quite verbose, for instance the numerous equations that are introduced quite abruptly. I would suggest the authors take a high level narrative approach to the paper, rather than diving into the specifics straight away.\n* The experiments are fairly limited, the only dataset used is COCO. There are many more available, the authors should be evaluating on them.\n* The only networks the method is demonstrated on is FCOS+ATSS and RetinaNet. For a loss adaptation like this, the authors should be demonstrating on as many as possible.\n* Taking up half a page to demonstrate hyper-parameter values is a significant proportion of the paper, this should be in the Appendix"
            },
            "questions": {
                "value": "* Why would ATSS 'omit certain samples characterized by high scores and high IoU that hold promise'? This isn't clear to me. Moreover, is this even an issue? I can see that the improvement is marginal.\n* Why is Res2Net not applied to VFL? This isn't a fair comparison.\n* Where do the quoted improvements of 1.1 and 1.2 mAP over VFL and GFL come from?\n* Where are the error bars?\n* Table 5, why do you see a decrease in mAP_50 when adding HCRAC? To me this shows it negatively affecting regression quality"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6749/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698771294435,
        "cdate": 1698771294435,
        "tmdate": 1699636777163,
        "mdate": 1699636777163,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "f2IUzfJNtw",
        "forum": "tDxGthJkSD",
        "replyto": "tDxGthJkSD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6749/Reviewer_woyR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6749/Reviewer_woyR"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a hybrid classification-regression adaptive loss function called HCRAL (Hybrid Classification-Regression Adaptive Loss) to improve the performance of the target detection model. HCRAL includes two modules: RCI (Classification and IoU Residual) module and CF (Conditional Factor) module. The RCI module is used for cross-task supervision and resolves task inconsistencies, while the CF module is used to focus on samples that are difficult to train in each task. In addition, the paper also proposes a new strategy called EATSS (Expanded Adaptive Training Sample Selection) to provide additional samples to optimize the loss function."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper proposes a novel loss function, Hybrid Classification-Regression Adaptive Loss (HCRAL), along with a new sample selection strategy, Expanded Adaptive Training Sample Selection (EATSS), for improving the performance of object detection models. The proposed HCRAL loss function consists of two modules: Residual of Classification and IoU (RCI) and Conditioning Factor (CF). The RCI module addresses inconsistencies between classification and regression tasks, while the CF module focuses on difficult-to-train samples within each task. The EATSS strategy provides more effective positive samples to optimize the loss function."
            },
            "weaknesses": {
                "value": "The innovation of this paper is limited, and the two parts proposed, HCRAL and EATSS, are relatively independent. At the same time, a large number of hyperparameters are introduced, which will increase the difficulty of hyperparameter adjustment in the experiment. The final experiment also shows that with the same backbone (R-101-RCN), the results of this paper's method are basically the same as VFL, and it does not bring significant improvement, which also makes me doubt the effectiveness of this method."
            },
            "questions": {
                "value": "- The experiments in this article are limited to the COCO data set, retinanet and FCOS. Experiments should be done on more detectors and data sets to verify the effectiveness of the method.\n- While the paper provides some ablation studies on the individual components of the proposed approach, a more comprehensive analysis of the impact of each component on the overall performance would be beneficial.\n- The motivation of equation 8 is very clear, but the article does not seem to detail the reasons for this design. It can be explained in more detail whether this RCI_reg is optimal when the conditions are met, and whether there is a clearer theoretical proof."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6749/Reviewer_woyR"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6749/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698804880472,
        "cdate": 1698804880472,
        "tmdate": 1699636777000,
        "mdate": 1699636777000,
        "license": "CC BY 4.0",
        "version": 2
    }
]