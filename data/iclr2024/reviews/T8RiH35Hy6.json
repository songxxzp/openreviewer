[
    {
        "id": "1BCOk2Q7hG",
        "forum": "T8RiH35Hy6",
        "replyto": "T8RiH35Hy6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5464/Reviewer_vF6X"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5464/Reviewer_vF6X"
        ],
        "content": {
            "summary": {
                "value": "For the graph learning, this paper discovers the phenomenon which this paper calls community bias amplification. This paper provides theoretical analysis on this phenomenon. Using this theoretical insights, this paper proposes a graph learning algorithm to mitigate this bias. The experimental results show that the proposed method outperforms the existing ones."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "A problem this paper focuses on is interesting. Seeing Fig.1, it is convincing that a bias between classes surely exists, and this itself is novel as far as I believe, at least in the GNN realm."
            },
            "weaknesses": {
                "value": "1. I do not agree with the authors claim on where the bias comes from. \nThe datasets for illustrative examples in Fig.1 contain the independent components. \nOono and Suzuki (2020) and its earlier work [1] shed a light on the phenomenon over-smoothing -- if we stack layers, the stacked adjacency matrix is dominant by the eigenspace associated with the largest eigenvalues. In the Cora and Citeseer cases, that space is a set of indicate vectors of independent components. \nAlso, the claim is this worsens the performance, which is understandable, since the only this eigenspace of the independent components are too simplified as an underlying structure. \nHowever, the underlying graph structure does not necessarily correspond to the classes, while of course graph structure and the classes are loosely related. \nIf they are, we observe somewhat comparative performance only using the graph of Cora and Citeseer, but we do not observe such performance by conducting for example the simple spectral clustering on graph. \nThus, the community amplification bias of the underlying graphs is not the primal reason why we observe the unfairness of Fig. 1. \nInstead, I believe that the bias is more nuanced -- hope to see what is the dominant.\n\n\n2. Also, even if the community bias were primal reason, the argument of Eq. (3) is weak since they only compare the value of the eigenvalues of two clusters. Also, how the example of Appendix A reflects the Cora and Citeceer dataset? Do we observe such things in the real datasets? How do you argue that?\n\n---\n\n[1] Li et al. Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. Proc AAAI 2018."
            },
            "questions": {
                "value": "How do you defend that the community amplification bias of the underlying graph is the primal reason we observe an unfairness between classes? As stated in the weakness section, I feel like there exists some gap between them."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Reviewer_vF6X"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5464/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698079929183,
        "cdate": 1698079929183,
        "tmdate": 1699636556906,
        "mdate": 1699636556906,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0zhBpvIjOK",
        "forum": "T8RiH35Hy6",
        "replyto": "T8RiH35Hy6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5464/Reviewer_bi59"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5464/Reviewer_bi59"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors explore a phenomenon called \"community bias amplification\" in graph representation learning. This phenomenon refers to the exacerbation of performance bias between different classes by graph representation learning methods. The researchers conduct a thorough theoretical investigation of this phenomenon, approaching it from a novel spectral perspective. Their analysis reveals that the structural bias between communities leads to varying local convergence speeds for node embeddings, resulting in biased classification outcomes in downstream tasks. To address this issue, the authors propose a solution called random graph coarsening. This technique is demonstrated to be effective in mitigating the problem of bias amplification. Furthermore, the authors introduce a novel graph contrastive learning model named Random Graph Coarsening Contrastive Learning (RGCCL). This model utilizes random graph coarsening as a form of data augmentation and alleviates community bias by contrasting the coarsened graph with the original graph. Extensive experiments conducted on various datasets highlight the effectiveness of their proposed method in addressing community bias amplification in graph representation learning tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The problem of community bias amplification in GRL is very interesting and has not been extensively studied before.\n\n- The analysis is theoretically sound with appropriate discussion and remarks.\n\n- Experiments on several benchmark graphs show the effectiveness (better node representations) and efficiency (less memory usage) of the proposed method."
            },
            "weaknesses": {
                "value": "- One of the research questions has not been answered in a good way, i.e., why community bias amplification exists in existing GCL method? Although some theoretical analyses have been provided in this paper, they are based on general (and simplified) graphs and it is not clear why there is such bias in GCL methods.\n\n- How to quantitatively measure the (community) bias amplification is not clear in the experiments. More analysis should be conducted to better illustrate why the proposed method is able to mitigate the issue of bias amplification. For example, some measures [1] can be used for the quantitative analysis.\n\n[1] Angelina Wang and Olga Russakovsky.Directional Bias Amplification.ICML 2021"
            },
            "questions": {
                "value": "- What are the answers to the first research question, i.e., why community bias amplification exists in existing GCL method?\n\n- It is possible to give some quantitative analysis on how the proposed method can mitigate the issue of community bias amplification rather than simply comparing the performance between different classes/communities?\n\n- Discussion on extending this key idea to general GRL. I asked this question because the theoretical analysis is general enough on any GRL methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Reviewer_bi59"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5464/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698791590533,
        "cdate": 1698791590533,
        "tmdate": 1700699828755,
        "mdate": 1700699828755,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9uX8QOoABs",
        "forum": "T8RiH35Hy6",
        "replyto": "T8RiH35Hy6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5464/Reviewer_K8c3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5464/Reviewer_K8c3"
        ],
        "content": {
            "summary": {
                "value": "This paper identifies a problem in graph representation learning on graphs with community structures. When the communities have different strengths (e.g., edge densities), the representations of nodes from different communities convergence at different speeds. In the resulting representations, this may lead the representations of nodes from weaker communities to be further apart, which may result in poor classification results on these classes downstream. \nThe paper introduces a contrastive learning approach using random graph coarsening to ameliorate this issue.\nExperiments show that this learning model outperforms existing representation learning methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well written, with only few language errors and typos.\n\nThe problem that is identified is interesting and subtle.\n\nThe proposed solution seems elegant."
            },
            "weaknesses": {
                "value": "It took me quite a while into reading the paper before I understood what was actually meant with this community bias. I think the introduction of this bias can be made a bit more concrete to improve this.\n\nThe message passing operator $\\hat{A}$ is mentioned but not introduced properly. Is this supposed to be the renormalized version of $\\tilde{A}$ that is shown in (1) or should it be something else?\n\nThe performance in the experiments are measured by the Accuracy and Macro-F1 measure. Both of these methods have biases w.r.t. class sizes [1,2]. I understand why you use Accuracy, as you also use this to motivate the community bias, but perhaps you could replace Macro-F1 by the Matthew's coefficient.\n\n[1] Chicco, D., & Jurman, G. (2020). The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation. BMC genomics, 21(1), 1-13.\n[2] G\u00f6sgens, M., Zhiyanov, A., Tikhonov, A., & Prokhorenkova, L. (2021). Good classification measures and how to find them. Advances in Neural Information Processing Systems, 34, 17136-17147."
            },
            "questions": {
                "value": "Consider removing \"Understanding\" from the title, as it sounds a bit generic and makes the title seem less strong.\n\nInstead of using this contrastive learning approach, can't we just cluster the obtained representations by a density-based clustering method like DBSCAN? The problem of different clusterings having different densities doesn't seem like a new problem in clustering.\n\nIt would be interesting to compare the performance of these representation learning methods to community detection methods like the Louvain algorithm [1] or Bayesian community detection methods [2]. This latter method also addresses the issue of different communities having different densities, but does so in a statistical framework.\n\n[1] Blondel, V. D., Guillaume, J. L., Lambiotte, R., & Lefebvre, E. (2008). Fast unfolding of communities in large networks. Journal of statistical mechanics: theory and experiment, 2008(10), P10008.\n[2] Zhang, L., & Peixoto, T. P. (2020). Statistical inference of assortative community structures. Physical Review Research, 2(4), 043271."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5464/Reviewer_K8c3"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5464/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698841310611,
        "cdate": 1698841310611,
        "tmdate": 1699636556713,
        "mdate": 1699636556713,
        "license": "CC BY 4.0",
        "version": 2
    }
]