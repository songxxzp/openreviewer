[
    {
        "id": "BHe3NT2ZHm",
        "forum": "6NO5UVWvo6",
        "replyto": "6NO5UVWvo6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6142/Reviewer_jaNJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6142/Reviewer_jaNJ"
        ],
        "content": {
            "summary": {
                "value": "Due to limited and time-consuming densely annotated images in the medical field, this paper proposes a point-supervised method for medical image segmentation by exploiting labelled and unlabelled pixels. The paper introduces a contrastive variance loss and a partial cross-entropy loss functions for effective training. The proposed method usually outperformed other presented weakly supervised methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- I think the proposed methodology is sensible and is relevant to the scientific community. It is an interesting approach in weakly supervised medical image segmentation.\n- The work extends and combines the existing methods and leverages the pixel-level variance distribution maps.\n- The evaluation was done with two standard datasets in medical imaging, which included both MRI and CT data.\n- The paper provides ablation study and comparisons with the existing methods."
            },
            "weaknesses": {
                "value": "- I think the contributions are somewhat novel for medical imaging but it can be seen as incremental over the existing general methods.\n- The evaluation has some issues, which are detailed below.\n- One main weakness is the importance of the first annotated point for each organ in images. The paper states that the first point annotation is randomly selected. Randomly selected annotations may have substantial effects on the model convergence and the overall performance. In supplementary, the authors provided information about \"Impact of sampling different points.\". However, this should have been done for MRI data instead of CT data due to inherent properties of CT and MRI data (CT is more standardized). In addition, results for annotated extreme points (max, min intensities) are also relevant here. Via repeated training, overall mean performance should have been reported as this would be a meaningful evaluation result. \n- Another interesting fact about the paper is that the Synapse dataset was divided into only training and test datasets. How did the authors find their optimized model without any validation data? It is important that the test dataset remains unseen until the optimized model is acquired. \n- The paper states that \"... in the testing stage we filtered fifty pixels that are close to the left and right edges of the prediction as the background to further refine the results on Synapse for all the methods.\". This seems like an arbitrary post-processing step which may have considerable effect on the performances. What was the reasoning behind this? Why did the authors apply this to only Synapse data but not ACDC data? Is this applied regularly in every testing procedure?\n- The paper does not state the overall computational complexity of the proposed methodology. Can the authors provide some details about this aspect compared to the existing methods?\n- Finally, in addition to the evaluations with Synapse data which is CT data (more standardized values), I encourage the authors to make the same evaluations using ACDC MRI data to show the performances in different scenarios. This might not be possible at this stage, but this is something that I would highly recommend."
            },
            "questions": {
                "value": "I look forward to having productive discussions regarding the questions in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6142/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698258026175,
        "cdate": 1698258026175,
        "tmdate": 1699636665893,
        "mdate": 1699636665893,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FA0ULB41wN",
        "forum": "6NO5UVWvo6",
        "replyto": "6NO5UVWvo6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6142/Reviewer_2T67"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6142/Reviewer_2T67"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a point-supervised contrastive variance method (PSCV) for medical image semantic segmentation, which only requires one pixel-point from each organ category to be annotated. The proposed method trains the base segmentation network by using a novel contrastive variance (CV) loss to exploit the unlabeled pixels and a partial cross-entropy loss on the labeled pixels. The experimental results conducted on two public medical datasets show the effectiveness of the proposed model."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) The targeted problem is important and valuable for medical imaging applications, i.e., annotations are notoriously expensive and time-consuming. \n(2) The overall structure is clear.\n(3) This paper designs a contrastive variance loss to exploit the unlabeled pixels and a partial cross-entropy loss on the labeled pixels.\n(4)  Experiments on two medical segmentation datasets show the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "(1) It is noted that the proposed loss function could make effective use of all the unlabeled pixels to support few-point-annotated segmentation model training. More insightful and theoretical analyses of the loss should be provided.\n(2) The authors randomly select one pixel from the ground truth mask of each category as labeled data to generate point annotations for each training image. However, different locations\u2019 pixels could bring negative impacts when they are labeled points. How to address these issues? \n(3) In comparison, the all compared methods are designed using the point-annotated data? If not, whether this comparison could be not fair? The proposed method is designed for using point-annotated training data."
            },
            "questions": {
                "value": "(1) It is noted that the proposed loss function could make effective use of all the unlabeled pixels to support few-point-annotated segmentation model training. More insightful and theoretical analyses of the loss should be provided.\n(2) The authors randomly select one pixel from the ground truth mask of each category as labeled data to generate point annotations for each training image. However, different locations\u2019 pixels could bring negative impacts when they are regarded as labeled points. How to address these issues? \n(3) In comparison, the all compared methods are designed using the point-annotated data? If not, whether this comparison could be not fair? The proposed method is designed for using point-annotated training data.\n(4) Compared with pixel-level full annotations, the point annotation provides limited information. Thus, it is helpful to show some failure examples, which can provide useful information for readers to better understand this work and valuable clues for the further improvement of this work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Reviewer_2T67"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6142/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698769124129,
        "cdate": 1698769124129,
        "tmdate": 1699636665757,
        "mdate": 1699636665757,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VaV0NMpiNm",
        "forum": "6NO5UVWvo6",
        "replyto": "6NO5UVWvo6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6142/Reviewer_WEjx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6142/Reviewer_WEjx"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a contrastive variance loss function to enhance point-supervised medical image segmentation. Their method modifies the Mumford-Shah loss functional by replacing the mean of pixel-wise intensity differences with a variance map. This contrastive variance approach provides greater discrimination between target structures and background regions. Evaluated on two medical imaging datasets, the technique achieved improved segmentation performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The authors reviewed the challenge in point-supervised medical image segmentation and explained their motivation in a clear way.\n2. The contrastive variance method achieved improved performance than the vanilla MS."
            },
            "weaknesses": {
                "value": "1. Unfair Comparison. While the proposed method demonstrates good performance in Tables 1 and 2, some concerns exist regarding the baseline comparisons. Specifically, certain baselines like WSL4MIS were originally proposed for scribble-supervised segmentation and have achieved much higher performance than reported here (e.g. 0.872 in the original paper versus 0.768 in this work). For a more equitable evaluation, the authors should compare against methods designed specifically for point-supervised segmentation.\n2. Sensitivity to hyperparameters. Figure 4 illustrates a high variance in performance - up to 10% - based on hyperparameter configurations. The authors should provide practical guidance on optimal settings and discuss the model's robustness to these parameters. \n3. Limited novelity. The idea of using both point supervision and information from unlabelled regions is not new as the authors reviewed in the introduction. The main technical novelty is replacing the intensity with a variance map and the integration of contrastive loss."
            },
            "questions": {
                "value": "1. In Figure 3, the improvement of PSCV over vanilla MS looks marginal and it is noted that the performance is sensitive to the hyperparameters. \n2. The authors stated that 'by using the pixel-level variance distribution maps as the appearance representation of the organs for similarity computation, one can effectively eliminate the irrelevant inter-image pixel variations caused by different collection equipment or conditions.' It is not true because the variance map still varies among different acquisition equipment or conditions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Reviewer_WEjx"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6142/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698804562353,
        "cdate": 1698804562353,
        "tmdate": 1699636665643,
        "mdate": 1699636665643,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EjwVDaBbnp",
        "forum": "6NO5UVWvo6",
        "replyto": "6NO5UVWvo6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6142/Reviewer_JEHB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6142/Reviewer_JEHB"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel scheme for medical image segmentation, which only requires one pixel-point annotation for each organ category. The segmentation network is trained in an end-to-end manner with two proposed loss functions. The one is a partial cross-entropy loss based on the labeled pixels. However, it can only provide limited guidance due to the extremely little annotation information. To exploit the unlabeled pixels, and to better detect the boundaries of different kinds of organs, the authors propose a novel contrastive loss function based on pixel-level variance distribution map for each class. This loss function can enforce the inter-image similarity between the same class of organs and force the model to have stronger capacity to separate different categories of organs. Extensive experiments on ACDC and Synapse datasets indicate the superiority of the proposed method with other weakly-supervised medical image segmentation methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Instead of feature-level contrastive loss, the proposed contrastive loss is based on the pixel variation maps, which seems to avoid the information loss during the training phase and ensure the sufficient exploitation of unannotated pixels\u2019 information.\n- Combining inter-image pixel-level contrastive learning into a medical context is interesting.\n- The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "- Although the authors claim the advantages of using cosine similarity, I am expecting to see ablation studies on different ways to measure the similarity.\n- The baselines are all about semi- or weak supervision methods. That\u2019s good. However, recent medical image segmentation methods based on point annotation should be included, like [1] and [2].\n- Two datasets seem not sufficient to support your claim. It\u2019s better to add another 1-2 datasets to help indicate your method\u2019s superiority.\n- The assumption that the spatial locations of the same organ in different medical images will be within limited regions to some extent is very strong and reduces the generalizability of the proposed method.\n\n[1] Xu, Yanyu, et al. \"Minimal-Supervised Medical Image Segmentation via Vector Quantization Memory.\" International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer Nature Switzerland, 2023.\n\n[2] Z. Chen et al., \"Weakly Supervised Histopathology Image Segmentation With Sparse Point Annotations,\" in IEEE Journal of Biomedical and Health Informatics, vol. 25, no. 5, pp. 1673-1685, May 2021, doi: 10.1109/JBHI.2020.3024262."
            },
            "questions": {
                "value": "- In the calculation of the pixel-level variance distribution map (Eq. 4), why multiply the prediction function output for the k-th class?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6142/Reviewer_JEHB"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6142/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811486499,
        "cdate": 1698811486499,
        "tmdate": 1700712237323,
        "mdate": 1700712237323,
        "license": "CC BY 4.0",
        "version": 2
    }
]