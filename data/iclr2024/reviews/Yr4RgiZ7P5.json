[
    {
        "id": "Qg0Ku3i5CE",
        "forum": "Yr4RgiZ7P5",
        "replyto": "Yr4RgiZ7P5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6569/Reviewer_1Rgc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6569/Reviewer_1Rgc"
        ],
        "content": {
            "summary": {
                "value": "For visual recognition, human rely more on shape while Neural Network rely more on textures, and previous methods trained style transfer augmentation failed to extract global shape information. This paper propose Distorted Shape Testbench as a measurement for global shape sensitivity, and a corresponding training method to improve Visual recognition networks' ability to extract global shape. Qualitative and quantitative experiments have been conducted to show the method's superiority."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The choice of research topic is insightful, both interesting and practical. \n2. The proposed method and benchmark are likely to be helpful helpful to many relevant research fields.\n3. The results are promising and the experiments are convincing"
            },
            "weaknesses": {
                "value": "1. In the experiment section, the authors only compared Resnet and ViT, the limited number of network architectures may make the conclusion less persuasive\n2. The proposed DiST benchmark is only tested on classification task, while there are many tasks influenced by global shape information. Experiments on different tasks may be needed to show the Versatility of DiST."
            },
            "questions": {
                "value": "1. The proposed ways of generating shape distortion is based on Neural Style Transfer, does the specific ways of style transfer algorithm used matter? Or could other style transfer/shape distortion methods achieve the same performance?\n2. The distorted images have similar textures but different global shape with the originally images. Would contrastive learning help improve the performance in this situation>"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6569/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6569/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6569/Reviewer_1Rgc"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6569/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697568061399,
        "cdate": 1697568061399,
        "tmdate": 1699636744624,
        "mdate": 1699636744624,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OfjoTnOhcU",
        "forum": "Yr4RgiZ7P5",
        "replyto": "Yr4RgiZ7P5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6569/Reviewer_dedU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6569/Reviewer_dedU"
        ],
        "content": {
            "summary": {
                "value": "This paper propose a benchmark dataset, DiST, to measure the global shape sensitivity of models. The images in this dataset is constructed by applying global shape distortion to natural images. Specifically, it follows Gatys et al. (2015), but optimize the intermediate layers' feature but keep the gram matrix not changes. Therefore, the texture information is kept but the shape information lost. Based on this newly constructed dataset, this paper have several interesting observations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper is studying an interesting problem, and figured out the missing pieces from the previous studies.\n\nThe proposed image construction methods simple but makes sense.\n\nThe experimental results further illustrate the value of the proposed dataset."
            },
            "weaknesses": {
                "value": "The scale of this dataset is too small (less than 10k images IIUC). It would be good to use the proposed method to construct an ImageNet-level dataset.\n\nIt would be good to show some well generated images while show some bad images as well, which can help people better understand the pros and cons of the proposed method.\n\nIt would be good to benchmark more models. For example, the shape-biased and the texture-biased model from [a].\n\n\n[a] Li, Yingwei, et al. \"Shape-texture debiased neural network training.\" ICLR 2021"
            },
            "questions": {
                "value": "See weakness. My main concern is the scale of the dataset on both number of images and number of tested models. This paper is very interesting, but potential can explore more."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6569/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698886099002,
        "cdate": 1698886099002,
        "tmdate": 1699636744514,
        "mdate": 1699636744514,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VwQtXRSiv1",
        "forum": "Yr4RgiZ7P5",
        "replyto": "Yr4RgiZ7P5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6569/Reviewer_PsLQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6569/Reviewer_PsLQ"
        ],
        "content": {
            "summary": {
                "value": "The paper is centralled concerned with robustness of recognition to shape distortion. The question asked in \"does resistance to style transfer equal shape bias?\" By which the authors seem to mean that recogntion algorithms that have been extended to be decently robust to texture change in objects are not robust to shape changes.\n\nThe paper introduces a data set dseigned for the problem, and a distance they call DiST."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "I like the odd-one-out test, which I think is a sound way to measure subjective distances."
            },
            "weaknesses": {
                "value": "It is clear from simple observation that texture and shape can both change, and that neural nets are currently configured to rely primarily on texture. So the paper is not saying too much in that regard.\n\nThe dataset introduced comprises an unconvincing collection of images. These include images that have been assumbled from sub-images of the object at different scales and points of view, peeled fruit (and peeled footballs). The reason this is not convncing is that the shape changes within a class will rarely if ever be expressed in such a way. Far more common would be simple geometric distortions. As an example, a \"man\" could be distorted into a \"strong man\" by increasing body and muscle size compared to the head. A second reason is that in some cases at least shapes can change in very unexpected ways but still be reognisable. Dali's melting watches are an example.\n\nThe fact that current models do not perform so well on the new dataset is not surprising. It is not so hard to contruct such a dataset. And the conclusion that humans out perform machines is equally unsurprising."
            },
            "questions": {
                "value": "Why not use some kind of warping to resist changes in shape? (Inter-class warps should be distinct from intra-class warps).\n\nWhat is your justification for using images made of pieces of photos of an object? (These are not shape distorted, they are mosaics of regualarly shaped parts)\n\nPeople can draw things - say a face - in all sorts of shapes. Eyes can be round, lines, crosses, diamonds and many more shapes.\nWhy not include such examples in your dataset (these examples are real and common in art)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6569/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6569/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6569/Reviewer_PsLQ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6569/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698952004294,
        "cdate": 1698952004294,
        "tmdate": 1699636744402,
        "mdate": 1699636744402,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rgre1HUL66",
        "forum": "Yr4RgiZ7P5",
        "replyto": "Yr4RgiZ7P5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6569/Reviewer_4QYv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6569/Reviewer_4QYv"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new benchmark to measure how well models can handle distorted shapes. They show that removing texture alone is not sufficient to make models robust to shape distortions. They also suggest that combining their method with Stylized Aug training can improve the models\u2019 robustness to both style and shape variations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper is clear and well-structured. The authors share their code, which facilitates the replication of the experiments. The benchmark they propose is original, as it focuses on shape distortions rather than style variations. They also provide a human baseline for comparison."
            },
            "weaknesses": {
                "value": "I have some doubts about the need for models to be robust to shape distortions. The examples in Fig. 2(a) seem very challenging even for humans. Are there any real-world applications that require such ability? The distorted shapes do not seem to have any physical meaning.\n\nAnd what is the benefit of using global shape features if the model can already classify the image based on local shape features?\n\nI also noticed that DiSTinguish itself worsens the performance on SIN-1K, as shown in Table 3. Can you explain why this happens?"
            },
            "questions": {
                "value": "Please check weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6569/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699221920076,
        "cdate": 1699221920076,
        "tmdate": 1699636744293,
        "mdate": 1699636744293,
        "license": "CC BY 4.0",
        "version": 2
    }
]