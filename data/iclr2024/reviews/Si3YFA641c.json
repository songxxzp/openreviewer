[
    {
        "id": "O46yJl0Hcb",
        "forum": "Si3YFA641c",
        "replyto": "Si3YFA641c",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission597/Reviewer_R4i1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission597/Reviewer_R4i1"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a novel R-EDL method to recalibrate uncertainty estimation by relaxing nonessential settings of EDL."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- An interesting perspective to explore uncertainty estimation\n\n- Comprehensive experiments"
            },
            "weaknesses": {
                "value": "- Could you present the detailed derivation of Formulas 7,9 and 10?  These formulas are the essential steps, but I may not catch up with your idea.  \n\n- The authors are recommended to make necessary explanations on different shapes of I-EDL with EDL and R-EDL in Figure 2 and Figure 5.\nAdditionally, uncertainty representations for ID (MNIST) and OOD (FMNIST) are better to show the differences among EDL, I-EDL, and R-EDL, as presented in I-EDL (figure 4). \n\n- What role did W play in the process of uncertainty estimation or evidence collection?"
            },
            "questions": {
                "value": "as aforementioned"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission597/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission597/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission597/Reviewer_R4i1"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission597/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698598998236,
        "cdate": 1698598998236,
        "tmdate": 1700739724024,
        "mdate": 1700739724024,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rYb533StpZ",
        "forum": "Si3YFA641c",
        "replyto": "Si3YFA641c",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission597/Reviewer_5NaH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission597/Reviewer_5NaH"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes new tweaks to the existing framework of evidential deep learning. These tweaks include treating a pre-set parameter as a tuning hyperparameter. The paper also uses an alternative objective to optimize for evidential deep learning.\n\nThe paper provides mathematical justification for the design choices. The paper also run experiments to demonstrate that the tweaks are effective."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "originality: the paper provides incremental improvement toward the existing evidential deep learning framework.\nquality: the proposed modification seems solid both mathematically and empirically. I particularly like that the paper carried out fairly exhaustive experiments to measure the utility of the proposed method across various tasks, comparing the proposed method with various alternatives. The ablation study is also a nice addition.\nclarity: the paper provides a mathematical formula and associated explanation to justify the tweaks of the framework presented in the paper. I can follow the arguments made in the paper on the high level.\nsignificance: the proposed tweaks appeared to make the framework more pratical and effective."
            },
            "weaknesses": {
                "value": "* presentation can be improved. \n  * for example, more intuition about some of the key concepts of the paper can be provided such as subjective opinion, belief mass, uncertainty mass, and Dirichlet distribution.\n  * In the experiments, max probability and UM are used as confidence scores. However, it is not clear how to interpret them and what is a good score and a bad one.\n  * Table 1 caption mentioned AUPR score, but it does not seem to be actually reported.\n* Consider the prior weight as hyperparameter also means that the algorithm requires hyperparameter tunning."
            },
            "questions": {
                "value": "* \"Despite its great success\" sentence in the abstract is difficult to parse. Consider breaking it into a few sentences."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission597/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698653568339,
        "cdate": 1698653568339,
        "tmdate": 1699635987292,
        "mdate": 1699635987292,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4MLe3bwJae",
        "forum": "Si3YFA641c",
        "replyto": "Si3YFA641c",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission597/Reviewer_vQHP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission597/Reviewer_vQHP"
        ],
        "content": {
            "summary": {
                "value": "The paper improves the Evidential Deep Learning (EDL) approach, a method for performing classification with reliable uncertainty estimations, in two ways: i) adopting a more generic definition of evidence that also incorporates prior belief, ii) removing the Kullback-Leibler (KL) divergence based regularizer term and employing a prior weight term for regularization that emerges naturally from this generalized definition."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The proposed approach for improving EDL is novel, creative, and innovative. It is also built on solid theoretical foundations. The resulting loss function is derived rigorously from first principles and clearly identifies the limitations of EDL.\n\n* This is a high-quality piece of work that not only develops a novel method, but also illustrates its development steps and the rationale of each step unequivocally, as well as demonstrating the practical benefit of the end outcome with a large body of experiments. The proposed method brings a clear performance improvement."
            },
            "weaknesses": {
                "value": "*  The paper below addresses the over/under regularization problem of EDL using an alternative approach, strictly speaking via Bayesian inference: **\u201cKandemir et al., Evidential Turing Processes, ICLR, 2022\u201d**. It could be worthwhile to clarify the advantage of the proposed approach with respect to this alternative.\n\n* The phrase \u201cmultiple mutually disjoint values\u201d in Definition 1 is a little confusion and potentially imprecise. A better alternative could be **\u201cLet X be a categorical random variable on the domain $\\mathbb{X}$\u201d**"
            },
            "questions": {
                "value": "* While the paper justifies all the steps up till Equation 10 rigorously, the choice of the loss in Equation 11 looks a bit arbitrary. Why should one choose the MSE between the class probabilities and one-hot labels instead of the simple and straightforward cross-entropy loss? How would it work numerically? If it works better or worse, what is the interpretation of the outcome?\n\n* Why were the MP and UM scores chosen as the performance metrics to measure in-distribution performance instead of the well-established Expected Calibration Error (ECE)?\n\n* How does the method compare against post-hoc calibration algorithms such as temperature scaling?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission597/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668344231,
        "cdate": 1698668344231,
        "tmdate": 1699635987213,
        "mdate": 1699635987213,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EbPAzVbYlF",
        "forum": "Si3YFA641c",
        "replyto": "Si3YFA641c",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission597/Reviewer_yPVK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission597/Reviewer_yPVK"
        ],
        "content": {
            "summary": {
                "value": "The authors focus on improving the popular Evidential Deep Learning approach introduced by Sensoy et al. (2018). They identify two potential sources of improving it, (i) the prior weight by turning it into a hyperparameter, and (ii) the variance term in the objective loss, by removing it. The approach is evaluated in a series of experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is well written with a clear line of thought and additional implementations.\n- Both modifications, prior weight, and removal of variance regularization, are motivated theoretically and their respective influence is validated via an ablation study.\n- The improvements are evaluated in a series of experiments"
            },
            "weaknesses": {
                "value": "- The experiments lack an in-distribution calibration evaluation\n\n\n\n### Minor\n- Typo: The first paragraph on p7 KL-PN is mentioned twice"
            },
            "questions": {
                "value": "- Can the authors report additional calibration results? E.g., by reporting the expected calibration error (Guo et al., 2017)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission597/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698920156349,
        "cdate": 1698920156349,
        "tmdate": 1699635987146,
        "mdate": 1699635987146,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Gt3UaKMMHv",
        "forum": "Si3YFA641c",
        "replyto": "Si3YFA641c",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission597/Reviewer_ErzN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission597/Reviewer_ErzN"
        ],
        "content": {
            "summary": {
                "value": "The authors present a relaxation of Evidential Deep Learning (EDL) methods that makes adjustments to the canonical model formulation and loss function. \nEDL has recently gained popularity as an alternative family of uncertainty quantification methods that provides confidence estimates in a single forward pass by having neural networks parameterize distributions over distributions.\nThe authors argue that two details of the standard formulation of EDL are misguided:\nFirstly, they argue that a scalar which gives weight to the prior compared to the evidence is often unnecessarily set to the number of classes in the classification problem, leading to sometimes unintuitive results.\nTo solve this, the authors propose to instead treat it as a task-specific hyperparameter.\nSecondly, they make a case that optimizing prior networks using the expected MSE loss between the predicted probabilities and a one-hot target vector creates over-confident networks due to the variance term in the objective's decomposition.\nHere, they propose to simply optimize the MSE loss directly, without the expectation.\nThey show in their experiments in a classical, few-shot setting for image classification and video action recognition datasets that their method, called R-EDL) able to better indicate the presence of OOD inputs and misclassified examples based on its uncertainty than their tested baselines, all while maintaining a high classification accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The paper presents its ideas well: Despite the proposed changes being relatively minor in nature, it motivates them with illustrating examples and reiterates EDL's basis in subjective logic to motivate them.\n* The presentation of the paper is polished and it is generally well written, albeit that earlier sections can feel slightly verbose at times.\n* The paper compiles a number of relevant baselines that are used for comparison in the presented experiments.\n* The authors test their approach in a classical, few-shot and noisy setting along with an ablation study.\n* Experimental details for possible replications are documented well in the appendix."
            },
            "weaknesses": {
                "value": "* It would have felt more natural to me to include the Natural Posterior Network [1]\u00a0instead of / besides the Posterior Network as a baseline, since it boasts better results than its predecessor.\n* Regarding the creation of a new hyperparameter, I do appreciate the authors' ablation study in 5.5. However, the investigation, given that this step is one of the key contributions of the paper, feels a bit shallow. I would be interested to understand better how to interpret the best values found in the context of the authors' original argument and to distill any trends. I found Figure 1b) particularly puzzling, since lambda seems to have major effect on classification performance, but less so in terms of actual OOD detection (~2 points AUPR). A similar graph about misclassification detection, which seems to align better with the authors original arguments, is not given.\n* Although the second contribution - effectively deprecating the variance term in the loss function - is supposed to help overconfidence, confidence is never directly evaluated. This might be due to the common conflation of the terms uncertainty and confidence, with the latter often referring to the actual probability assigned to predicted class - however works like the aforementioned Charpentier et al. [1] evaluate both the quality of uncertainty estimates obtained through different EDL metrics as well as the direct confidence of their model through the Brier score. The authors do try to assess confidence through measuring the AUPR for their misclassification task (including the MP value, i.e. the maximum probability across all classes), which I would argue is appropriate, but assesses confidence only in its ability to discriminate between correctly and incorrectly classified samples, not in its degree to correspond to the (in expectation) chance of classifying correctly, like in the instance of the expected calibration error.\n\n[1]\u00a0Charpentier, Bertrand, et al. \"Natural Posterior Network: Deep Bayesian Predictive Uncertainty for Exponential Family Distributions.\" International Conference on Learning Representations. 2021."
            },
            "questions": {
                "value": "My questions are the follows:\n\n* Was there any particular rational in not including Brier score / ECE in the evaluation?\n* What was the reason for including the Posterior Network as a baseline, but not the Natural Posterior Network? (see weaknesses section)\n* Even after consulting the appendix, it is unclear to me if and which regularization term has been used to trained the models (since e.g. Sensoy et al. [2] use an additional KL divergence term). Given the number of options for regularization (see e.g. [3]\u00a0for an overview) it feels necessary to know which regularizer had been used. In any case, this part would deserve a short mention in the main text. If no regularizer had been used at all, I would find the good results for the OOD detection task surprising, since many other works lament that uncertainty on OOD behaves differently for EDL than desired.\n* Judging from Table 3, I find it a bit strange that either fixing lambda = 1 or re-adding the variance term to the loss function seem to have only minor effects on the results of R-EDL compared to the EDL baseline. This implies to me that a) there might be an interaction between the two components that might go beyond the sum of its parts or that b) the EDL baseline might be tuned suboptimally compared to the proposed R-EDL model. I would be interested in the authors commenting on this aspect.\n\nOther notes:\n* The link to the appendix after the contributions in section 1 seems to be missing.\n\n[2] Sensoy, Murat, Lance Kaplan, and Melih Kandemir. \"Evidential deep learning to quantify classification uncertainty.\" Advances in neural information processing systems 31 (2018).\n\n[3] Ulmer, Dennis, Christian Hardmeier, and Jes Frellsen. \"Prior and posterior networks: A survey on evidential deep learning methods for uncertainty estimation.\" Transactions on Machine Learning Research (2023)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission597/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission597/Reviewer_ErzN",
                    "ICLR.cc/2024/Conference/Submission597/Senior_Area_Chairs"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission597/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699372383183,
        "cdate": 1699372383183,
        "tmdate": 1700486032427,
        "mdate": 1700486032427,
        "license": "CC BY 4.0",
        "version": 2
    }
]