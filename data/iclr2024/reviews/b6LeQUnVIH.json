[
    {
        "id": "jzGKa83Xzz",
        "forum": "b6LeQUnVIH",
        "replyto": "b6LeQUnVIH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5743/Reviewer_dPV5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5743/Reviewer_dPV5"
        ],
        "content": {
            "summary": {
                "value": "This paper demonstrates that (1) smaller models can also be used as reference models in data map (DM) methods as described in Swayamdipta et al. 2020 and (2) transfer is possible between models with different pre-training methods on NLI and hate speech detection benchmarks. They also conduct ablation studies on how fast models learn with ERM vs DM. I cannot recommend this paper for acceptance as the novelty is very limited over Swayamdipta et al. 2020."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Although the novelty is limited, ablations and benchmarking shown are quite detailed. Presentation is very clear. Related literature is very well-reviewed."
            },
            "weaknesses": {
                "value": "Contribution is extremely limited over Swayamdipta et al. (2020) who proposed the original method of data maps combined with the work of Sar-Shalom & Schwartz (2023) who demonstrated that a DM constructed by ELECTRALarge can be used to improve the robustness of DeBERTaV3Large. This work reads more like a tech report rather than an ICLR paper. Insights are practically useful, but does not go beyond systematic benchmarking."
            },
            "questions": {
                "value": "I do not have any questions -- presentation is clear."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5743/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698675103625,
        "cdate": 1698675103625,
        "tmdate": 1699636602146,
        "mdate": 1699636602146,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kL8DRpQ76h",
        "forum": "b6LeQUnVIH",
        "replyto": "b6LeQUnVIH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5743/Reviewer_CV2g"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5743/Reviewer_CV2g"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method for finetuning pretrained language models, FTFT, that finetunes a smaller reference model which is then used to select examples for training the target model on a downstream task. The authors demonstrate that smaller models can be used for constructing a DataMap of samples without significant reductions in performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The authors conduct a systematic investigation of various reference model sizes and compare against reference models trained with an alternative discriminative pretraining method.\n2. The authors demonstrate that using smaller reference models and training on the resulting DataMap does not result in performance reduction as compared with an ERM baseline trained over the entire dataset; and results in improved performance on OOD robustness datasets."
            },
            "weaknesses": {
                "value": "1. One of the primary contributions is the sample efficiency of models trained on a smaller data map selected via ambiguity.  However, there is limited comparison or discussion of related work on sample efficient methods of training such as curriculum learning and dataset pruning [1, 2] .\n2. The DataMap selection criteria is limited to example ambiguity -- and does not compare against other criteria such as \"hard-to-learn\", example forgetability [3] \n3. Evaluations are limited to finetuning of models for language classification -- unclear whether results would generalize to other domains or task settings (e.g. image classification, language generation).\n\nReferences:\n1. Sorscher, Ben, et al. \"Beyond neural scaling laws: beating power law scaling via data pruning.\" Advances in Neural Information Processing Systems 35 (2022): 19523-19536.\n2. Paul, Mansheej, Surya Ganguli, and Gintare Karolina Dziugaite. \"Deep learning on a data diet: Finding important examples early in training.\" Advances in Neural Information Processing Systems 34 (2021): 20596-20607.\n3. An empirical study of example forgetting during deep neural network learning. In ICLR, 2019."
            },
            "questions": {
                "value": "* Significance of performance gains over baseline DataMap are unclear without variance across random seeds in Tables {1, 2, 4}?\n* Table 4; How is the cost of one \"ELECTRA-Small with ERM\" calculated (i.e. FLOPs, GPU-Hours, power consumption?) Does this account for the cost of finetuning the reference model and scoring the samples DataMap?\n* Why is 33% chosen for the top q% to create the Data Map? What is the distribution of the ambiguous and hard to learn examples? Do the values have a large degree of skewness?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5743/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698725571495,
        "cdate": 1698725571495,
        "tmdate": 1699636602012,
        "mdate": 1699636602012,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MzOC9YT3P8",
        "forum": "b6LeQUnVIH",
        "replyto": "b6LeQUnVIH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5743/Reviewer_FKcX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5743/Reviewer_FKcX"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes FTFT, an efficient fine-tuning algorithm that selects a core set of examples to fine-tune a large model by using the training dynamics of a small reference model. The authors observe that such an algorithm can achieve better OOD performance with a slight drop in ID performance when compared to the conventional ERM algorithm. The authors conduct extensive experiments to find the right reference model to select the core set, where the selection can be made based on model size and family. Finally, the authors show the efficiency gains of their method compared to ERM by comparing the behavior of the model's OOD performance over training time."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The strength of the paper lies in its easy-to-understand explanation of the algorithm. The authors begin with a clear description of the existing literature on the data map methods and the underlying issue of these methods. With a proposed hypothesis of using a small model to provide the necessary data map, the authors test multiple candidates that can act as the reference small model. Finally, extensive experimentation shows the efficacy of their method on multiple ID-OOD dataset pairs."
            },
            "weaknesses": {
                "value": "I have a few questions regarding the experimental setup.\n\n(a) How efficient is FTFT compared to ERM in terms of total flops? Since FTFT first trains a small reference model to select the ambiguous set of examples, it has to incur the flop necessities of training the small reference model. A rough estimate of the flop counts for both methods will be useful.\n\n(b)  How does FTFT perform when compared to existing algorithms that aim to improve the OOD performance of trained models? Examples of such methods include invariant risk minimization algorithms [4], DRO [5], and WiSE-FT [6]. Comparison to a couple of them will strengthen the results of the FTFT method. \n\n(c) How sensitive is FTFT to training hyperparameters of the small reference model and the target model? Does the ambiguous core set selected using the small reference model change with its training hyperparameters?\n\n(d) I observed that the core set selected with base models (ELECTRA-base and DeBERTaV3-base) performs better OOD than training with a core set selection from large models. Can the authors provide more insights into the behavior?\n\n\nThere are a number of papers that I believe should be part of the related works section to give readers a full overview of the literature. \nFor example, [1] dynamically weighs training domains in the pre-training dataset of a large language model, using the training dynamics of a small language model. Other citations may include works that train a proxy model to select the right set of data to train the target model. [2, 3]\n\n\n1: DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining. Xie et al.' 23\n\n2: Selection via proxy: Efficient data selection for deep learning. Coleman et al.' 19\n\n3: SVP-CF: Selection via Proxy for Collaborative Filtering Data. Sachdeva et al.'21\n\n4: Invariant Language Modeling. Peyrard et al.'21\n\n5:  Distributionally robust language modeling. Oren et al.'19 \n\n6: Robust fine-tuning of zero-shot models. Wortsman et al'21"
            },
            "questions": {
                "value": "Please see my questions in the previous section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5743/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762393199,
        "cdate": 1698762393199,
        "tmdate": 1699636601885,
        "mdate": 1699636601885,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BzzI6BCuq3",
        "forum": "b6LeQUnVIH",
        "replyto": "b6LeQUnVIH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5743/Reviewer_vdXa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5743/Reviewer_vdXa"
        ],
        "content": {
            "summary": {
                "value": "To reduce the training cost of Data map. This paper develops a variant of Data map by swapping in a smaller model for data selection. The authors experimented on DEBERTA, ELECTRA and TinyBERT with a few datasets, showing training cost improvement and mixed results in performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. Simple and clear idea.\n2. The motivation and reasoning are well explained."
            },
            "weaknesses": {
                "value": "1. The proposed method has limited novelty compared to Data map.\n2. The result is mixed. Out of the experiments in Table 2, only half of them show successful transfer. Suggesting the scale of the reference model still needs to be relatively close to the Main model. Besides, even in the remaining rows, the result is inconsistent across datasets.\n3. Cost saving is only in fine-tuning time rather than inference time. However, for LLMs, fine-tuning cost is much less of an issue than pertaining or inference cost."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5743/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698833691409,
        "cdate": 1698833691409,
        "tmdate": 1699636601771,
        "mdate": 1699636601771,
        "license": "CC BY 4.0",
        "version": 2
    }
]