[
    {
        "id": "lD8cngv2ql",
        "forum": "5sixirvG0I",
        "replyto": "5sixirvG0I",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7012/Reviewer_qxXR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7012/Reviewer_qxXR"
        ],
        "content": {
            "summary": {
                "value": "This paper is about computational studies of a Whittle index-based policy on a variant of the restless bandit problem. The restless bandit setting allows multiple actions for each bandit, and there is a constraint that controls the joint state of the bandits. In particular, the paper focuses on the inventory management of multiple stock-keeping units. Here, each stocking-keeping unit corresponds to a bandit, and the list of stock levels that a unit can maintain is the set of actions. The distinction with the existing works on restless bandits is that the problem is not about selecting one bandit but about choosing an action for each bandit. That said, it makes sense to define and compare the indices of multiple actions, instead of comparing some indices of distinct bandits. Moreover, the inventory level constraint imposes restrictions on taking which actions to different units. Therefore, the problem can be viewed as an instance of multi-agent reinforcement learning (MARL)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper provides a novel definition of a Whittle index-type policy for a multi-agent inventory management problem. Indexability for the setting is defined, and some sufficient conditions for the notion of indexability are provided. The framework seems novel.\n* In general, implementing a Whittle index policy can be inefficient as computing Whittle indices is difficult. However, numerical results show that the proposed Whittle index-based policy can be efficiently implemented and at the same time, one can impose satisfying the joint inventory level constraint at least computationally."
            },
            "weaknesses": {
                "value": "* No theoretical guarantee on the proposed method is provided. It seems that the framework sits between restless bandits and multi-agent reinforcement learning (MARL). That said, the reader would wonder if any theoretical results on either restless bandits or MARL extend to the particular problem setting of this paper. \n* It is not clear how the joint inventory level constraint is satisfied by the WIMS policy. The WIMS policy controls individual stock-keeping units separately while the only joint control is on updating the dual variable. That said, in principle, one may use any algorithm for dealing with individual units. It is difficult to convince that the WIMS policy is particularly effective for the multi-agent setting studied in this paper."
            },
            "questions": {
                "value": "* Is it possible to prove that without the joint inventory level constraint, the Whittle index-based policy of this paper achieves optimality?\n* Is it possible to discover and explain any connection between the setting of this paper and the MARL settings, e.g., fully competitive and cooperative settings?\n* Is it possible to compare the proposed framework of this paper and the existing single-agent inventory control methods combined with dual penalization as done in this paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Reviewer_qxXR"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7012/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698647305344,
        "cdate": 1698647305344,
        "tmdate": 1699636821651,
        "mdate": 1699636821651,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CxZKIXDfqw",
        "forum": "5sixirvG0I",
        "replyto": "5sixirvG0I",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7012/Reviewer_xHVA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7012/Reviewer_xHVA"
        ],
        "content": {
            "summary": {
                "value": "This paper considered a multi-agent reinforcement learning setting with multiple actions and one coupling state constraint which has broad applicability across various fields, including inventory management.  The authors proposed WIMS by leveraging deep multi-agent reinforcement learning. Specifically, WIMS built on top of the state-of-the-art Whittle index policy, and generalize it to multi-action and dynamic state constraint settings. Experimental results were provided to validate the performance of WIMS."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper considered a multi-agent reinforcement learning setting with multiple actions and one coupling state constraint which has broad applicability across various fields, including inventory management.  The authors proposed WIMS by leveraging deep multi-agent reinforcement learning."
            },
            "weaknesses": {
                "value": "1. In this paper, the authors assume that the multiple SKUs are independent and their total inventory level cannot exceed some capacity constraint. Unfortunately, this assumption is problematic and lack of justification. For example, rewards are not only independent in large-scale systems (a large number of SKU), and the substitution effect can occur. \n\n2. The proposed algorithm WIMS is mostly heuristic based and lack performance guarantees. First, this paper introduces a state constraint that must be satisfied in each time step $t$ in Section 4.1. However, WIMS is NOT guarantee to satisfy this constraint at all, and hence there is a gap between the formulated problem and the proposed solution. Second, it is not quite clear if the proposed WIMS is asymptotically optimal or not, which is a key performance in restless bandits literature. For example, the state-of-the-art Whittle index policy is provably asymptotically optimal. However, Whittle index policy is designed for restless bandits with a constraint on the action, rather than on the state. It is not straightforward to the reviewer if the asymptotic proof of Whittle index policy can be generalized to that for WIMS. Third, as discussed above, there is a gap between the problem formulation (with state constraint) and the proposed WIMS (ignore the constraint). To this end, this paper tunes the parameters of $\\lambda_g$. Though empirical results are provided, it is unclear if this is theoretically sound given that there is not performance guarantee in this paper. \n\n3. From the experimental results, the proposed WIMS outperformed the considered baselines in terms of accumulated profit. What about the computational complexity? The reviewer did not fully understand the results presented in Table 4. It seems that WIMS takes significant larger computational costs, measured in mins. Given these large numbers (mins), how could this algorithm adapt to dynamic settings?"
            },
            "questions": {
                "value": "See comments in weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Reviewer_xHVA"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7012/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698716130357,
        "cdate": 1698716130357,
        "tmdate": 1699636821529,
        "mdate": 1699636821529,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TcIqvY4KRS",
        "forum": "5sixirvG0I",
        "replyto": "5sixirvG0I",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7012/Reviewer_spvh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7012/Reviewer_spvh"
        ],
        "content": {
            "summary": {
                "value": "This paper extended Whittle index method to a multi-agent reinforcement learning setting under the inventory management setup with multiple discrete actions (number of replenishments) and a global constraint on the state space (total inventory not exceeds a certain limit). The paper bridges two gaps to the restless bandits problem: the constraint is imposed on the state instead of the actions; there are multiple actions for each agent instead of binary actions; by measuring the cost of unit budget consumption and generates the critical points for different actions (changes index into vectors). Then the author proposed a algorithm combines their WIMS with a neural network to solve problem more efficiently. The real data experiments shows that the new policy performs good and efficiently with less constraint violations compared to existing policies."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-\tThis paper introduces a novel adaptation of the Whittle Index tailored for a MARL setting. The adaptation addresses challenges that previously hindered the direct application of the Whittle Index such as multiple actions for each agent and constraints on state spaces instead of action spaces. The application of WIMS in a deep MARL algorithm, called WIMSN, further establishes its originality.\n-\tThis paper compares the proposed algorithm with both traditional operation research methods and other MARL baselines, providing a comprehensive evaluation. The adaptive nature of WIMSN to changes in constraints or combinations of SKUs without requiring retraining emphasizes the quality and flexibility of the proposed approach.\n-\tThis paper is well-structured and organized. Technical concepts such as WIMS are well explained using simple examples, making them easily accessible to readers. \n-\tThe ability to scale WIMSN to thousands of agents highlight its significant, especially in large-scale industrial scenarios. \n-\tThis paper is original in that it measures the cost of unit budget consumption and generates the whittle index to be a vector. Furthermore, the author gave a reasonable sufficient condition of indexability for the vector whittle index, (which is the optimal policy should not reduce the replenishment quantity when the inventory cost decreases.)\n-\tThis paper has high contributions since the methods generally applied to other problems where the global constraint of a multi-agent learning problem depends on states instead of on actions."
            },
            "weaknesses": {
                "value": "-\tThis paper builds upon the Whittle index, but there is no comprehensive exploration of the inherent limitations or challenges of using this index in a MARL context. This oversight could result in practical challenges or unintended outcomes when transitioning to real-world implementations. It would be beneficial for the authors to outline specific assumptions made when integrating the Whittle Index. One potential area of exploration could be the interplay of local constraints in conjunction with global constraints. Some SKUs might have their own unique storage.\n-\tThis paper does not have details on how the dataset is partitioned into training, validation, and testing subsets. Providing this information is essential for ensuring replicability and comprehending the robustness of the outcomes. It would be beneficial for the authors to explicitly define and justify their splitting methodology, particularly given the time series nature of the data.\n-\tIt would be helpful if the authors mentioned areas where their method (WIMSN) could be improved or further developed. By discussing potential future studies or enhancements, the authors would make their paper even more valuable.\n-\tThe literature review seems not very complete and up-to-date. The author reviewed a lot of works on the operation research and on independent learning based MARL without global constraints, and the main comparisons were made with works in 217,2018. I am wondering if there are more recent works focus on similar topic.\n-\tOne of the focuses, main assumptions and challenges in this paper, which is the limit of the total inventory capacity changes across the different seasons is not very reasonable to me. If the constraint is only changed once a long time like once a seasons, it seems to me that wrong those previous algorithms and re-train the model does not bring many troubles."
            },
            "questions": {
                "value": "-\tBased on the above mentioned weaknesses, I feel that the comparison in Figure 2 does not complete or fair enough.  The author compared their adaptive algorithm with two IPPO models trained with two different capacity limits, but the author didn\u2019t mention any training cost or training time for IPPO, so I am wondering why the IPPO users can\u2019t re-train their models on the 50th day, since the reward was compared on a daily manner. \n-\tIn the neural network training phase, in the network update steps, they sample a batch of transitions from the replay buffer, could this word \u201cbatch\u201d be more clarified? And is this replay buffer something important to computational efficient of the algorithm? What is the difference from regular learning algorithms that runs a sequence of data first and without a replay buffer?\n-\tOR-based methods was first mentioned without explanation, should add an abbreviation after first mentioning operation research.\n-\tIt's unclear from the given text what dataset was used for training and testing the proposed methods. This raises concerns about the generalizability and robustness of the proposed models. Are the datasets representative of real-world scenarios? Are they publicly available for verification and reproducibility?\n-\tWhile the paper mentions computational costs and standard deviations of daily profits, are there other metrics (like fill rate, stockout rate, etc.) used in inventory management that could provide a more comprehensive view of performance?\n-\t(Typo in Proposition 3.3) In the third case, Q(s,1) = Q(s,i) -> Q(s,1) = Q(s,0)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7012/Reviewer_spvh"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7012/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698789803016,
        "cdate": 1698789803016,
        "tmdate": 1699636821394,
        "mdate": 1699636821394,
        "license": "CC BY 4.0",
        "version": 2
    }
]