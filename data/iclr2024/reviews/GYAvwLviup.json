[
    {
        "id": "jeHba36ABE",
        "forum": "GYAvwLviup",
        "replyto": "GYAvwLviup",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5566/Reviewer_jWwB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5566/Reviewer_jWwB"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a aligment method to boost the performance of brain decoding."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper proposed a simple method for brain decoding."
            },
            "weaknesses": {
                "value": "1.The loss function has three parameters. How to choose the parmeters is difficult.\n2.The proposed method should be compared with the state-of-the-art methods."
            },
            "questions": {
                "value": "1. The dataset is very small. Hence, How is the generalization of the model\uff1f\n2. The proposed method don't compared with the state-of-the-art methods."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5566/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698710390760,
        "cdate": 1698710390760,
        "tmdate": 1699636572645,
        "mdate": 1699636572645,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "I0fIdIfeBk",
        "forum": "GYAvwLviup",
        "replyto": "GYAvwLviup",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5566/Reviewer_tcU3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5566/Reviewer_tcU3"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to boost the decoding of videos in a single left-out subject with an alignment model and a decoder. The alignment model includes anatomical alignment and functional alignment. Finally, the pre-trained image encoder is used to obtain the video output."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The proposed ideas are simple and intuitive. It's quite generic and can be applied to different models."
            },
            "weaknesses": {
                "value": "1. The novelty needs to be further elaborated.\n1. The proposed method lacks a comparison with other models. As a result, the effectiveness of the method is not convincing and requires further validation.\n2. The proposed method in this paper employs one reference subject. How to deal with multiple reference subjects in practice?"
            },
            "questions": {
                "value": "Please refer to the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5566/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5566/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5566/Reviewer_tcU3"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5566/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698740504807,
        "cdate": 1698740504807,
        "tmdate": 1699636572548,
        "mdate": 1699636572548,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9QXo6SbwAt",
        "forum": "GYAvwLviup",
        "replyto": "GYAvwLviup",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5566/Reviewer_HiZ5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5566/Reviewer_HiZ5"
        ],
        "content": {
            "summary": {
                "value": "The work deals with the decoding of high-level visual features from fMRI recordings. The authors use functional alignment to align fMRI data across subjects. The work claims that using functional alignment instead of standard structural methods boosts the decoding performance when there is limited data available for the subject in case. Further, training a model with aligned subjects can be used, whereas previous models could only decode responses specific to a subject."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Using functional alignment to improve decoding of visual representations across subjects is novel and noteworthy. The quantification of decoder performance with respect to data size is noteworthy."
            },
            "weaknesses": {
                "value": "The approach of showing the left-out subject the same video as the reference subject is a substantial weakness. This coupled with the functional alignment could theoretically act as a \u201cleakage\u201d mechanism for the data"
            },
            "questions": {
                "value": "Does one repetition in line 268 mean the first trail or the second? \n\nLine 281 says the left-out subjects have to watch the same videos, while, line 265 says the subjects are shown the test stimuli for the first time. Does this mean the videos shown themselves are new to the subjects?\n\nWhere is it shown that the approach aligns brain responses in accordance with brain anatomy? ( LIne 12)\n\nPerhaps, adding at least a single subject comparison where the subject is shown different stimuli may help have more robust results"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5566/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698795319500,
        "cdate": 1698795319500,
        "tmdate": 1699636572450,
        "mdate": 1699636572450,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "heYBUmxziF",
        "forum": "GYAvwLviup",
        "replyto": "GYAvwLviup",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5566/Reviewer_uqYK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5566/Reviewer_uqYK"
        ],
        "content": {
            "summary": {
                "value": "This paper is aimed at improving subject video decoding from BOLD functional responses obtained during a movie watching paradigm. To this end, the authors perform brain response alignment via an optimal transport methodology, followed by a linear regression to predict latent representations of video frames (obtained by standard encoder models such as CLIP or VD-VAE).  They find that this method improves out of subject video decoding performance when compared to a purely anatomical alignment approach. They also examine multi-subject alignment in comparison to single subject approaches when limited number of paired recordings are available"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper provides some interesting insights into the use of functional alignment models for studying BOLD responses in the context of naturalistic stimuli. Although the alignment methodology is not entirely a novel contribution in and of itself, the experimental setup is well deigned to examine the hypotheses being tested. The findings are clearly presented and motivated"
            },
            "weaknesses": {
                "value": "The major weakness of this paper is the limited number of subjects that are available for testing. Given that only three different subjects are used, it is unclear whether the findings of the paper and insights will generalize for a larger population."
            },
            "questions": {
                "value": "1. It is not clear how sensitive the method to the choice of image latent representation/granuarity of features? How was the choice of representational models (such as CLIP or VD-VAE etc) made, is one or the other more suitable for this evaluation setup? Additionally, is there a reason the video frame decoding is restricted to a linear regression parameterization\n\n2. How was the choice of retrieval metric made? Is there a reason standard metrics such as mean average precision, or NDCG are not appropriate for evaluating this task?\n\n3. It would be nice to provide more context to explaining the design and modeling strategy in Eq. (1). The way it is currently presented requires the reader to flip back and forth between this manuscript and Thual et al 2022 to understand the methodology properly.\n\n4. It would be nice if a higher resolution image for Figure 2 could be made available to understand the false retrieval cases. Additionally, it would be nice to provide more description in the appendix to help the reader interpret the extended experimental observations."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5566/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5566/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5566/Reviewer_uqYK"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5566/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699566123218,
        "cdate": 1699566123218,
        "tmdate": 1699636572366,
        "mdate": 1699636572366,
        "license": "CC BY 4.0",
        "version": 2
    }
]