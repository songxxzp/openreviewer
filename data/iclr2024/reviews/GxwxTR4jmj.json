[
    {
        "id": "OVjQYZ3tiN",
        "forum": "GxwxTR4jmj",
        "replyto": "GxwxTR4jmj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1341/Reviewer_8CJA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1341/Reviewer_8CJA"
        ],
        "content": {
            "summary": {
                "value": "This paper deals with the cross-view localization problem and considers the domain transfer issue for new areas. It proposes a teacher-student pipeline to improve the generation ability of existing works. This work assumes that the images of the target area are available, but there is no label. The experiments are conducted on VIGOR and KITTI dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ Generalization is very important for the localization system and the work is well-motivated.\n+ The proposed method is evaluated on two widely used datasets with detailed evaluation metrics.\n+ The writing is easy to follow.\n+ The qualitative results look good. The ablation study and analysis are also well presented."
            },
            "weaknesses": {
                "value": "-\tThe proposed method is more like semi-supervised learning rather than weakly-supervised learning, as it generates pseudo labels for training on the target area. Both knowledge distillation and domain adaptation have studied similar problems.\n-\tThe experimental setting could be improved to better support the motivation, i.e. generalization on new areas. The current setting seems to split the images of the target area into several parts. Although the label is not provided, the ground-truth pairs still exist in the training set of the target area, which is not the case for real-world applications. It is very common that some query images may not be covered by the reference images in the target areas. In other words, some images may not have the correct match in the training set of the target area. \n\n-\tThe performance improvement is limited, especially on KITTI dataset.\n\n-\tThe computation cost of the proposed method is not discussed. Given that previous methods have achieved high accuracy on these datasets and the proposed method introduces additional computational cost, It is important to discuss the trade-off between the performance improvement and the additional computational cost."
            },
            "questions": {
                "value": "See the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1341/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698635881921,
        "cdate": 1698635881921,
        "tmdate": 1699636061321,
        "mdate": 1699636061321,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "skwxEIPwUV",
        "forum": "GxwxTR4jmj",
        "replyto": "GxwxTR4jmj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1341/Reviewer_Tcvm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1341/Reviewer_Tcvm"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a weakly-supervised learning approach using knowledge self-distillation to improve the cross-view localization performance in new target areas without accurate ground truth positions. However, the paper is flawed in terms of writing, innovations, and experiments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "+ This article presents a self-distillation framework to enhance the performance of models across domains."
            },
            "weaknesses": {
                "value": "- There is a lack of mathematical analysis as to why self-distillation frameworks are able to improve the fine-grained localization by only using coarse labels from target domain. Intuitive explanations and visualisation diagrams alone are not convincing enough.\n- The ablation experiments are insufficient. Lacking of comparison with domain adaption methods, and enhancements over baseline methods do not entirely come from pseudo label supervision by the teacher.\n- The test results are insufficient. Lack of indicators of the success rate of matching between ground and aerial images e.g. R@1, R@5, Hit Rate. A direct comparison of metre-level localization accuracy in the absence of a matching success rate is meaningless."
            },
            "questions": {
                "value": "1.\tThe proposed introduces the coarse-grained labels from target domain so it is considered a domain adaptation approach. Is the boost due to having seen the distribution of target domains, or is it due to the weak supervision of the pseudo-labels? The addition of ablation experiments to compare other domain adaptation methods is recommended.\n2.\tWhy the poor model (the teacher) can lead good model (the student) in a good direction? Hopefully the authors will give solid mathematical derivations rather than intuitive descriptions and visualisations. This is because visualised heatmaps may simply come from success cases, which cannot be controlled at the time of review.\n3.\tFor the self-distillation approach, it is necessary to maintain the teacher model and the student model in the memory, which is not too demanding in terms of computational resources? I am concerned about the ease of reproducing the method proposed in this paper and suggest that the computational cost be given.\n4.\tLacking of indicators of the success rate of matching between ground and aerial images e.g. R@1, R@5, Hit Rate. A direct comparison of metre-level localization accuracy in the absence of a matching success rate is meaningless.\n5.\tAs the most important general framework diagram, the font size in Figure 2 is too small and the overall flow is not clear and concise. It is recommended that it be redrawn."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I do not have the Ethics Concerns."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1341/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698710254357,
        "cdate": 1698710254357,
        "tmdate": 1699636061249,
        "mdate": 1699636061249,
        "license": "CC BY 4.0",
        "version": 2
    }
]