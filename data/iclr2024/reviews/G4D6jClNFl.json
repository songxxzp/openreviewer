[
    {
        "id": "LcrAJBuZxH",
        "forum": "G4D6jClNFl",
        "replyto": "G4D6jClNFl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2798/Reviewer_GhyQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2798/Reviewer_GhyQ"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of face deepfakes detection. It uses a supervised contrastive learning where a prior set of possible \nmodifications/alteration  of faces is used as data augmentation. The main novelty of the paper comes from the use of a mixed curvature space\nfor the embedding, designed as a product of hyperspherical and hyperbolic geometries. Within this geometries, prototypes are defined \nas corresponding to the different classes of possible alterations of pristine faces. Then a dissimilarity measure to those mixed-space prototypes \nis defined as a combination of a distance over the sphere and a measure of alignment with a hyperbolic prototype thanks to the Busemann \nfunction. A detection score is crafted as a product of similarity in the hyperspherical embedding and a confidence score in the hyperbolical space\ndefined as the distance to the origin. Thorough experiments are conducted on the FaceForensics++ dataset, and comparisons with SOTA approaches \nreveal added value of the mixed-space representation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Empirical evidences thorough experiments of enhanced detection performances with the proposed method ;\n - although I am not an expert in deepfake detection, the considered SOTA seems relevant and complete"
            },
            "weaknesses": {
                "value": "- the paper combines two well-known strategies (contrastive learning on an hypersphere embedding and Busemann prototypes\nfrom the Ghadimi et al. Neurips paper). The amount of novelties with this respect is low, and one could expect from such a paper\na better justification of the choice of this mixed-curvature space besides \u2018the manifold of faces is complicated and non-Euclidean\u2019.\nNotably, it is not clear which aspects necessary to deepfake detection is captured by the two geometries \n- some details are missing from the experimental part (see my questions below). The ablation study is not fully convincing to me \n\nAll in all, and though the proposed approach seems novel and has merits, it seems to me that the paper would be more suited and  impactful in the computer vision community, as far as the novel insight wrt. representation learning are rather limitated."
            },
            "questions": {
                "value": "- in the experimental section, I did not see the dimensions used fo both embeddings (I may have overlooked). Are they comparable to what is used in  other supervised contrastive learning strategies ? What is the impact of those dimensions on performances ? \n- in the ablation study, do you keep the total number of dimensions constant (e.g. if S^100 + H^100 is used, do you compare with a hyperspherical embedding with dimension S^200 ?) I really believe that this question (effectiveness of combination of spherical and hyperbolic geometry) is unsufficiently detailed in the paper)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2798/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2798/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2798/Reviewer_GhyQ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2798/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697619505395,
        "cdate": 1697619505395,
        "tmdate": 1700673792404,
        "mdate": 1700673792404,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WUoFJs8NvC",
        "forum": "G4D6jClNFl",
        "replyto": "G4D6jClNFl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2798/Reviewer_L6YJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2798/Reviewer_L6YJ"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose building facial features by incorporating principles of hyperbolic geometry and using a contrastive loss on a hypersphere to aggregate similar faces, thereby achieving the goal of detecting forged faces. In general, this paper presents a promising approach that contributes to the advancement of deepfake detection."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. An interesting method for constructing facial features.\n2. An effective attempt for using contrastive loss to detect deepfakes."
            },
            "weaknesses": {
                "value": "1. The authors should provide more case studies in the main manuscript, including new features in Section 3 and facial features after clustering using contrastive loss.\n2. More analysis on efficiency should be added, such as overall training time, parameters, and convergence steps.\n3. It is suggested that the authors consider applying this method to other well-known backbones, such as Xception."
            },
            "questions": {
                "value": "na"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2798/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698640405741,
        "cdate": 1698640405741,
        "tmdate": 1699636222483,
        "mdate": 1699636222483,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ckz1DVk95l",
        "forum": "G4D6jClNFl",
        "replyto": "G4D6jClNFl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2798/Reviewer_gKak"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2798/Reviewer_gKak"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to learn deepfake detection representations across multiple-curvature spaces in a self-supervised manner. The detection results combine advantages of both positive and negative curvature spaces. Experimental results validate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed model is the first attempt to learn representations across multiple-curvature spaces for deepfake detection. \n2. The proposed abnormal face generation method can generate fake faces of many different types.\n3. The experimental results show that the proposed model has satisfactory deepfake detection performances."
            },
            "weaknesses": {
                "value": "The reason to combine both negative and positive curvature representation spaces in deepfake detection is not insightful. This makes the paper merely a combination of existing techniques.\n\n(1) The authors only emphasize that the Euclidean-based distances appear sub-optimal for faces as the complexity and nature of human faces go beyond a basic Euclidean manifold. This explanation is vague and general, thus not convincing. \n(2) As I know, using hyperbolic space representations always work well for the tasks with hierachical relation nature. However, the authors fail to explain the inherent hierachical relations in deepfake detection tasks."
            },
            "questions": {
                "value": "I suggest the authors give more detailed and insightful analysis to explain the motivation of using curved spaces."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2798/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698659650873,
        "cdate": 1698659650873,
        "tmdate": 1699636222401,
        "mdate": 1699636222401,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AcRBiJZZIf",
        "forum": "G4D6jClNFl",
        "replyto": "G4D6jClNFl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2798/Reviewer_V3Kg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2798/Reviewer_V3Kg"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a framework, CTru, for fakeface detection. The idea is to project face features into different geometric spaces, and combine the projections into a loss function to learn the encoder with contrastive learning. Some experimental results have been shown for demonstration."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Slightly better results."
            },
            "weaknesses": {
                "value": "1. Novelty: The paper integrates several existing techniques widely used in the computer vision community for the application of fake face detection, with no theoretical justification. Why does such an integration work? Why not other ways? This is one of my major concerns as a publication in ICLR, as to me I feel learning nothing from the paper.\n\n2. Writing: I am not clear how Eqs. 2 and 7 are implemented. Eq. 2 is for generating \u201chigh\u201d quality fake images, but why is \u201chigh\u201d quality? Eq. 7 is for making decisions, but \u201chow\u201d?\n\n3. Experimental results are slightly higher than the approaches that all are before 2023. Not sure if they are state-of-the-art."
            },
            "questions": {
                "value": "see my comments"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2798/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698852240806,
        "cdate": 1698852240806,
        "tmdate": 1699636222334,
        "mdate": 1699636222334,
        "license": "CC BY 4.0",
        "version": 2
    }
]