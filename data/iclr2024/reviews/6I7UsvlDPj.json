[
    {
        "id": "MgMTG4FFSz",
        "forum": "6I7UsvlDPj",
        "replyto": "6I7UsvlDPj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4170/Reviewer_xpjw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4170/Reviewer_xpjw"
        ],
        "content": {
            "summary": {
                "value": "The authors present a method for incorporating LLM likelihoods into tasks such as object segmentation, navigation, and action recognition. For each task, a task-specific base model is combined with a pre-trained LLM and each model estimates the likelihood of an event given some context, e.g. the likelihood of a bed in a bedroom and then likelihood that the given pixels are a bed.The LLM is used to refine the base model's estimated likelihood for an event and in doing so incorporates semantic background knowledge not necessarily present in the task-specific dataset into the final decision. The approach is primarily compared to the Socratic Method for prompting LLMs and the task-specific models run in the absence of the LLM. Three tasks are assessed and for each task the models are assessed on OOD, in-distribution, and zero-shot settings. Across tasks and settings, the proposed approach LaMPP out performs other methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well written and easy to follow.\n- The authors introduce an interesting way to incorporate background knowledge from LLMs into graphical models to estimate the likelihood of events.\n- The authors evaluate on a tasks with different degrees of temporal reasoning required."
            },
            "weaknesses": {
                "value": "- The authors primarily assess the model on tasks where the LLM is expected to perform well. For example, the task-specific training dataset does not contain all possible combinations of objects and the LLM is able to overcome this because of the large amount of data it was trained on. The authors do not assess performance on cases where the LLM may perform poorly on the downstream task. For example, sofas and sinks being in the same room or complex spatial reasoning tasks. The ways in which the LLM could harm performance are not explored and assessed. This is touched on at the very end of the conclusion, but should be addressed and measured more centrally."
            },
            "questions": {
                "value": "- What is mean by \"easy-to-predict object labels\"? What makes them easy? What about hard object labels? \n- For the LM Queries in the semantic segmentation task, where does \"r\" come from?\n- How well is the model able to account for likelihoods of different numbers of objects? For example, a bedroom is likely to have a bedside table, but not likely to have 12 of them. \n- For 3.2 Experiments, you mention that \"a RedNet checkpoint\" is used. How was this checkpoint selected?\n- What are the differences in compute time between LaMPP, SM, and the base models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4170/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698253233023,
        "cdate": 1698253233023,
        "tmdate": 1699636382824,
        "mdate": 1699636382824,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LjIpnfrAOP",
        "forum": "6I7UsvlDPj",
        "replyto": "6I7UsvlDPj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4170/Reviewer_WR1X"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4170/Reviewer_WR1X"
        ],
        "content": {
            "summary": {
                "value": "The paper presents the use of LM (language model) as a source of prior distributions over labels, decisions or model parameters. The approach is empirically demonstrated through 3 different domains -- semantic image segmentation using SUN RGB-D dataset, indoor object navigation using Habitat challenge, and action recognition on Cross-Task dataset.\n\nThe three case studies cover diverse objectives and show consistent improvement on in-distribution, out-of-distribution and zero shot generalization. Further, the studies also show that the proposed approach is more cost effective than the existing approaches such as Socratic Modeling."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-- The empirical studies show a delta between the proposed and existing approaches for the in-distribution results for image semantic segmentation.\n\n-- The three domains chosen, while having some similarities in terms of input modalities, is sufficiently diverse to demonstrate the generalization of the approach."
            },
            "weaknesses": {
                "value": "-- The empirical results for zero-shot and OOD show very minor improvements relative to baseline. For image semantic segmentation, the results in A.3 show 0.2 and 0.5 mIOU improvement for OOD and ZS resp. Similarly, the improvements for ZS and OOD for video segmentation are not very significant.\n\n-- The general approach seems to require a significant amount of domain specific information which might work for smaller / restricted domains but will face issues when generalizing to broader / open domains."
            },
            "questions": {
                "value": "-- Can this approach be shown to work on a large dataset (e.g., 100k+ labels)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4170/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698647661707,
        "cdate": 1698647661707,
        "tmdate": 1699636382747,
        "mdate": 1699636382747,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "b8YEdjD1sn",
        "forum": "6I7UsvlDPj",
        "replyto": "6I7UsvlDPj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4170/Reviewer_C44C"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4170/Reviewer_C44C"
        ],
        "content": {
            "summary": {
                "value": "I have reviewed a previous version of this manuscript.\n\nThe manuscript formulates labeling and decision-making as inference in probabilistic graphical models, where language models can act as the probabilistic prior distribution over labels, decisions, and parameters. The manuscript takes a case study approach, to consider different task settings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The manuscript is well-written.\n\nThe problem formulation is interesting."
            },
            "weaknesses": {
                "value": "Figure 1 is missing illustration for the \u201crobot navigation\u201d task, probably due to attempts to keep it in a floating single column format. Consider redrawing the figure.\n\nSection {3,4,5} (prompting): Provide discussion of how the fixed text prompt templates were chosen, particularly for the action recognition case study. Provide some examples of other templates that were tried, even if they did not prove successful.\n\nSection 5.2: The lack of discussion surrounding evaluation on ID settings (still) stands out; it would be a worthwhile a comparison of task/domain difficulty. Provide discussion in the main content.\n\nSection 5.3: Several other LLMs and VLMs have been available for quite some time now. Missing comparisons with other foundation models.\n\nSection 6: The related works section is sparse and uninformative. The manuscript forgot to highlight *both* the strengths and weaknesses of the relevant related work and describe the ways in which the proposed method improves on (or avoids) those same limitations. This should serve as a basis for the experimental comparisons and should follow from the stated claims of the paper."
            },
            "questions": {
                "value": "N/A \u2013 see above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4170/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818185487,
        "cdate": 1698818185487,
        "tmdate": 1699636382673,
        "mdate": 1699636382673,
        "license": "CC BY 4.0",
        "version": 2
    }
]