[
    {
        "id": "aj8khTP2P9",
        "forum": "npoi2fr882",
        "replyto": "npoi2fr882",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4802/Reviewer_YC1j"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4802/Reviewer_YC1j"
        ],
        "content": {
            "summary": {
                "value": "The current GAN inversion methods typically can only edit the appearance and shape of a single object and background while overlooking spatial information. The method proposed a 3D editing framework, 3D-GOI to enable multi-faceted editing of affine information (scale, translation, and rotation) on multiple objects."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. 3D GAN inversion is at its preliminary start and this method is the first paper that studies multi-object 3D GAN inversion, which is an important while under-explored topic.\n2. The writing is good and experiments is sound."
            },
            "weaknesses": {
                "value": "1. The overall method still lies in the hybrid optimization method, which requires code tuning after the pre-trained encoder gives a coarse estimation.\n2. Lacks qualitative comparison with existing encoder-based method such as E3DGE, only Tab. 1 shows the quantitative comparisions.\n3. What are the limitation of this method, and how many objects can this method handle within an image?\n4. Also, any editing result based on manipulating the latent space, such as using InterfaceGAN?"
            },
            "questions": {
                "value": "1. Since you allocate a single encoder to each code, what's the computational cost compared with existing encoder-based 3D GAN inversion framework such as E3DGE.\n2. I really wonder why having a single optimizer to optimize all the codes in Sec.3.4 will fail, since these codes should be independent to each other?\n3. How do your method address the \"shape collapse\" problem in 3D GAN, where a trivial 3D solution (such as a flat wall) is returned rather than a plausible 3D scene?\n4. In the comparison with encoder-based 3D GAN inversion methods, TriplaneNet performs slightly better to E3DGE over MSE and LPIPS, while slightly worse on ID loss, any intuition behind it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4802/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4802/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4802/Reviewer_YC1j"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4802/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698797702736,
        "cdate": 1698797702736,
        "tmdate": 1699636463084,
        "mdate": 1699636463084,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Hhta8TaE5h",
        "forum": "npoi2fr882",
        "replyto": "npoi2fr882",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4802/Reviewer_gkt1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4802/Reviewer_gkt1"
        ],
        "content": {
            "summary": {
                "value": "The study presents 3D-GOI, an innovative 3D editing framework that seeks to provide multifaceted editing capabilities for multiple objects in a given scene. 3D-GOI employs a three-stage approach that first segments the objects and background in a multi-object image, then uses a Neural Inversion Encoder to derive coarse attribute codes for each object, and finally, through a round-robin optimization strategy, refines these codes to recreate the image. Leveraging GIRAFFE, a well-known 3D GAN, the method allows for detailed editing on both object and scene scales, including adjustments to object appearance, position, and even the camera pose."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper's emphasis on multi-object and multifaceted editing not only differentiates it but also highlights the immense potential such editing holds for future technologies.\n2. The ablation study breaks down different components of the proposed method, such as the Neural Inversion Encoder and the Round-robin Optimization algorithm, shedding light on their individual contributions."
            },
            "weaknesses": {
                "value": "The primary concern with the paper lies in its dependency on multiple stages and components for accuracy, which hints at potential inefficiencies and complexities in the method. Specifically, the Neural Inversion Encoder's inability to precisely predict codes independently underscores a fundamental limitation. This necessitates the round-robin optimization approach, adding another layer of complexity. Furthermore, the model's significant deviations in predicting background codes for multi-object scenes highlight challenges in accurately reconstructing detailed and complex backgrounds. Additionally, the model's sensitivity to the order of feature optimization raises concerns about its consistency and robustness in various scenarios. Coupled with its reliance on pre-trained models, these issues collectively indicate potential areas that could hinder the model's broad applicability and efficiency.\n\n1. With multiple dedicated encoders for fine-tuning specific attributes, there's a risk of the model fitting too closely to training data, resulting in poor generalization to unseen data. It would be valuable to see empirical evidence showcasing the model's performance on diverse, unseen data.\n2. Differentiating between closely related attributes, such as scaling and translation, can be tricky. If the encoders aren't adequately designed to distinguish between such nuances, they might produce overlapping or redundant codes. This can hinder precise scene reconstruction and may result in ambiguity when trying to decipher the attributes of a given scene. It would be beneficial for the authors to offer visualizations of the latent space, as this could shed light on potential overlaps and provide deeper insights into the latent representations.\n\n3. The model's performance is highly contingent on accurate segmentation. If the segmentation phase is off even slightly, the downstream processes, including scene representation and attribute extraction, can be significantly affected. This makes the model sensitive to the initial stages of processing, potentially reducing its resilience against imperfect inputs. It would be beneficial to see results or demonstrations of how the model performs with imperfect segmentation inputs, providing a more holistic view of its resilience."
            },
            "questions": {
                "value": "1. How can the Neural Inversion Encoder's accuracy be improved, so it becomes less dependent on subsequent optimization for precise code predictions?\n\n2. Given the two-step approach of coarse estimation and precise optimization, what are the computational costs associated with the 3D-GOI method, and how do they compare with other inversion methods?\n\n3. Beyond the potential fields mentioned in the conclusion, are there other applications where 3D-GOI could be particularly useful?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4802/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812414135,
        "cdate": 1698812414135,
        "tmdate": 1699636463003,
        "mdate": 1699636463003,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BQGFIKbTuq",
        "forum": "npoi2fr882",
        "replyto": "npoi2fr882",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4802/Reviewer_f1rX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4802/Reviewer_f1rX"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a novel inversion framework to invert the latent codes from GAN for 3D editing on the basis of GIRAFFE. It focuses on inverting the multiple codes of multiple objects in a single image, where the major challenges are two-fold: 1. latent code disentanglement; 2. effective optimization method to solve them. To address the two targets, the authors respectively propose the Neural Inversion Encoder, and Round-robin Optimization, which I believe are the major contributions. The method follows the scene decomposition method similar to GIRAFFE. After decomposition, the Neural Inversion Encoder is proposed to do coarse estimation for each object property (e.g., appearance, shape, etc.). To better optimize so many latent codes from multiple objects, they designed the Round-robin Optimization to update the gradients with a loss gradient ranking style."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper focuses the task of GAN inversion problem of different latent codes from multiple objects in a single image. To address the challenges lying in the multiple latent code estimation and optimization, there are two technical strengths:\n\n1. The round-robin Optimization strategy to optimize all codes simultaneously. \n2. the Neural Inversion Encoder to encode each code for initial estimation.\n3. Extensive experiments that demonstrate their effectiveness"
            },
            "weaknesses": {
                "value": "The weaknesses in this paper are also obvious.\n\n1. This paper still follows the framework of GIRAFFE by using its scene decomposition manner and training strategy, even though the authors claim that they have more object properties to encode.\n\n2. Second paragraph of Intro: there are some other methods based on VAEs (Sync2Gen, ICCV'21) and transformers (NeurIPS'21)\n\n3. Sec 3.2,  and Intro, there is no need to have so many texts to elaborate on why you use the segmentation method. It is pretty intuitive.\n\n4. During training, you mentioned that you train an encoder for one code at a time, and keep the other codes at their true values (Sec 3.3). In Round-robin Optimization (Sec 3.4), you also mentioned that you prioritize optimizing the code with decreasing loss. IIf it does not decrease, then change to optimize the other codes. How do you combine the two training strategies?\n\n5. The paper should be written in a more concise way (see 3.). There are many important sections that should not be moved to the supplementary, e.g., related works, and qualitative comparisons with baselines."
            },
            "questions": {
                "value": "1. Since the authors claim that they use an optimizer for each code, and the Round-robin Optimization method optimizes each code in turn, what is the time efficiency of this method compared with the baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4802/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4802/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4802/Reviewer_f1rX"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4802/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698885865226,
        "cdate": 1698885865226,
        "tmdate": 1699636462902,
        "mdate": 1699636462902,
        "license": "CC BY 4.0",
        "version": 2
    }
]