[
    {
        "id": "aGgSLRHsij",
        "forum": "tIsYpRxMvr",
        "replyto": "tIsYpRxMvr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5373/Reviewer_itCd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5373/Reviewer_itCd"
        ],
        "content": {
            "summary": {
                "value": "The paper considers the problem of imitation learning from noisy demonstrations. To address the problem, the paper introduces Self-Motivated Imitation Learning (SMILE), which filters out noisy demonstrations using a diffusion model. Theoretical results are introduced to show the efficacy of the proposed algorithm, and experiments are done to show that SMILE researches higher rewards compared with other baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper considers an important problem. The proposed algorithm that uses diffusion model to judge the optimality of the demonstrations is novel and interesting. The experimental results show that the algorithm is promising."
            },
            "weaknesses": {
                "value": "1. The technical writing of the paper can be improved. There are several places that are not fully clear to me:\n\n- Definition 2.1, I think comparing the expertise of two demonstrations by only comparing their rewards are not sufficient. What if the two demonstrations start from different initial conditions? Also, the environment considered is a stochastic environment, where the reward of two trajectories can be different even if we use the same policy. How does the definition deal with this problem?\n\n- Proposition 3.1, in what sense does the author mean by \"non-expert\"? Can the authors define \"non-expert\" mathematically first? In addition, in the proof of Proposition 3.1, only action-wise proof is provided. However, is \"non-expert\" a property that might be defined over trajectories?\n\n- The notation $t$ is a bit confusing. Sometimes the subscript $t$ represents for simulation time step, while sometimes it represents for the diffusion step. \n\n- I encourage the authors to add more explanations to Figure 1, which currently is confusing to me. \n\n2. There are some places for improvement in the experiments:\n\n- It is claimed in the paragraph before \"Contributions\" that \"SMILE achieves results comparable to method that rely on human annotations for several tasks\". Which baseline does the authors mean here?\n\n- As introduced in paragraph \"Dataset\", the experts' original actions are corrupted by adding Gaussian noise, which is consistent to the diffusion model. I wonder what if we corrupt the dataset using other methods? For example, with probability $p$, the agent choose random action. \n\n3. There is some incorrectness and insufficiency of the related work. For example, in the last paragraph of page 1, [1] is introduced as \"introduced human annotations to indicate the expertise of the demonstrations\" However, I think there is no human annotation in this work, but the algorithm automatically generates labels by injecting noise in the demonstrations itself. Similar works including [2-4] are not included in the related work. \n\n[1] Brown, Daniel S., Wonjoon Goo, and Scott Niekum. \"Better-than-demonstrator imitation learning via automatically-ranked demonstrations.\" Conference on robot learning. PMLR, 2020.\n\n[2] Chen, Letian, Rohan Paleja, and Matthew Gombolay. \"Learning from suboptimal demonstration via self-supervised reward regression.\" Conference on robot learning. PMLR, 2021.\n\n[3] Zhang, Songyuan, et al. \"Confidence-aware imitation learning from demonstrations with varying optimality.\" Advances in Neural Information Processing Systems 34 (2021): 12340-12350.\n\n[4] Xu, Haoran, et al. \"Discriminator-weighted offline imitation learning from suboptimal demonstrations.\" International Conference on Machine Learning. PMLR, 2022."
            },
            "questions": {
                "value": "Please refer to each point raised in \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5373/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698693312910,
        "cdate": 1698693312910,
        "tmdate": 1699636542649,
        "mdate": 1699636542649,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FByZpunQxm",
        "forum": "tIsYpRxMvr",
        "replyto": "tIsYpRxMvr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5373/Reviewer_z47T"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5373/Reviewer_z47T"
        ],
        "content": {
            "summary": {
                "value": "This paper uses diffusion model in place of GAN in generative adversarial imitation learning problem. At the first stage, this paper uses diffusion model to learn the noise information for forward and reverse process on the expert demo. Then, the noise information is leveraged to predict the diffusion steps between the current policy and demonstrators. Experiments show that this work have some performance gain s upon noisy expert demonstrations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This work is novel and easy to follow. I think diffusion model is applied here do have some advantages. For example, imitation learning could be more robust to the noisy expert demos."
            },
            "weaknesses": {
                "value": "1. The performance gains seem little.\n2. I think there are some methods focusing on noisy expert imitation. Have the authors surveyed these methods and do a comparison?\n3. I would like to see the experiment results based on clean expert data. I am wondering wether diffusion model has some advantages compared to generative models in imitaiton learning when the expert data is clean."
            },
            "questions": {
                "value": "Could the authors report the training time of this newly proposed method. I think diffusion model is too slow for training in imitation learning setting. I am concerned about this. However, I would like to see more results with clean and noisy expert demos in experiments. I am wondering why diffusion model could be better than generative model such as GAIL, except for noisy expert setting. Could the author illustrate this?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5373/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5373/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5373/Reviewer_z47T"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5373/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698721332254,
        "cdate": 1698721332254,
        "tmdate": 1699636542538,
        "mdate": 1699636542538,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5jrnXHZmXw",
        "forum": "tIsYpRxMvr",
        "replyto": "tIsYpRxMvr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5373/Reviewer_76Xe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5373/Reviewer_76Xe"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel method called Self-Motivated Imitation Learning (SMILE) for imitation learning in situations where there are varying levels of expertise in the demonstrations provided. The main contribution is the ability of SMILE to predict the number of diffusion steps (akin to the level of noise) between the current policy and the demonstrations, which correlates to the expertise gap. The authors theoretically justify their approach and provide a detailed explanation of how this prediction mechanism works for filtering purposes. They then validate their method through experiments on MuJoCo tasks. The results show that SMILE can effectively learn from the best available demonstrations and ignore those that are less skilled, leading to more efficient learning of expert policies."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- provide the proof of predicting how many steps to denoise\n- the results is better when the non-expert is just expert plus noise generated by Gaussian distribution"
            },
            "weaknesses": {
                "value": "- The paper claims that they want to handle non-expert demonstrations. However, the non-expert demonstrations they handle are only demonstrations generated by the same expert but some gaussian noise. There are many other ways to generate non-expert trajectories.For example, one can perturb the input observation and get a perturbed action. In addition, dataset D4RL provides non-expert demonstrations directly.  Many other methods have shown the ability to handle those non-expert demonstrations. \n- There can be multiple kinds of experts in Mujoco. The proposed method might learn only one of them and be unable to handle the states of other experts.\n- Since the method filters out many demonstrations, it might lose the chance to learn the dynamic of the environment and ends up being bad at OOD states. \n- The many parts of the design are different from DDPM. The author needs to provide explanations. For example, in eq.6, q(a_t|a_{t-1}, s) is different from ddpm (eq.3). Another example is that it uses a one-step generator. I wonder about the performance of it compared to multisteps. Especially if it uses DDIM."
            },
            "questions": {
                "value": "- It is hard to understand the one-step generator. What is \\mu_t in equation 10? Why not just train an additional policy with algorithms like BC and the data that have been filtered."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5373/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699046555256,
        "cdate": 1699046555256,
        "tmdate": 1699636542445,
        "mdate": 1699636542445,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "t9NT6uiZpH",
        "forum": "tIsYpRxMvr",
        "replyto": "tIsYpRxMvr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5373/Reviewer_Qmx6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5373/Reviewer_Qmx6"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors address the challenge of noisy demonstrations in Imitation Learning (IL), which hinders the discovery of effective policies. They propose Self-Motivated Imitation Learning (SMILE), a method that progressively filters out demonstrations from policies considered inferior to the current policy, eliminating the need for additional information about the demonstrators' expertise. SMILE leverages Diffusion Models to simulate the shift in demonstration expertise, extracting noise information that diffuses expertise from low to high and vice versa. The predicted diffusion steps are used to filter out noisy demonstrations in a self-motivated manner, as empirically demonstrated on MuJoCo tasks, showing proficiency in learning expert policies amidst noisy demonstrations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* This paper employs a diffusion model, which has shown promising performance in generative model training. The idea of this paper seems to be novel. \n\n* The authors provide theoretical derivations and empirical results demonstrate good results."
            },
            "weaknesses": {
                "value": "1. The paper's clarity can be significantly enhanced. For instance, the caption of Figure 1 lacks sufficient information for readers to fully comprehend its content. Furthermore, there is a need for a detailed explanation how does SMILE algorithm actually perform and how the noisy demonstrations filter is incorporated into existing IL methods. The methodology section lacks an overall algorithmic explanation, causing confusion. While the appendix provides pseudocode to elucidate the algorithm, the authors should emphasize these details in the main methodology section. Additionally, the authors introduce Definition 2.1 in the preliminary part, but its application in the subsequent content remains unclear.\n\n2. The authors should provide more details about the dataset used for training since they collect the dataset themselves. For example, the quality of each inferior demonstrator related to varying levels, the number of demonstrations used for training should be provided. Moreover, does the corrupted action being used to transit to the new state when collection demonstration?\n\n3. My critical concern is about the way the suboptimal data is generated. The method is to add Gaussian noise to the actions of an optimal policy. This noise maps exactly the one used in the diffusion process. Is this a relevant factor to explain the performance of the method? It would be great to investigate other forms of noise.\n\n4. The evaluations are only conducted on MuJoCo tasks. Is it able to evaluate the proposed method using one of the many existing datasets of human demos, such as RoboMimic? RoboMimic includes a classification of the level of dexterity of human demonstrations in multiple robotic tasks (in simulation), akin to the levels of noise used in the paper's experiments. Are there additional issues or limitations when applying this method to human-generated data?"
            },
            "questions": {
                "value": "1. From the pseudecode provided in the appendix, it seems that SMILE can be incorporated with both GAIL and BC. However, it's unclear which IL method is used to incorporate with SMILE in Figure 2. If BC is employed, it might introduce a potential fairness issue when comparing it with GAIL. Additionally, is it possible to integrate the SMILE method with online methods, and if so, what could be the expected performance?\n\n2. I believe VILD [1] in online setting or modified VILD in offline setting (using pre-collected demonstrations and using IQL or CQL instead of SAC or TRPO) can serve as a powerful baseline, both theoretically and experimentally.\n\n3. I am wondering if it is suitable to connect the proposed method to the idea of self-paced learning. Self-paced learning starts from easier sample (which is judged by the sample loss) and gradually include more samples into training to ensure the generalization. In SMILE, the authors seem to start from the whole dataset and gradually filter out noisy demonstrations.\n\n4. According to Algorithm 2, while both diffusion model and policy network are initialised, how could the algorithm achieve good performance at filtering out noisy demonstrations? Additionally, is there any theoretical guarantee for the convergence of the diffused policy and the agent policy?\n\n[1] Variational Imitation Learning with Diverse-quality Demonstrations, ICML 2020.\n\n[2] DemoDICE: Offline Imitation Learning with Supplementary Imperfect Demonstrations, ICLR 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5373/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699585134027,
        "cdate": 1699585134027,
        "tmdate": 1699636542336,
        "mdate": 1699636542336,
        "license": "CC BY 4.0",
        "version": 2
    }
]