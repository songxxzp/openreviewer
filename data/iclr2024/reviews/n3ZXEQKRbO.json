[
    {
        "id": "bCdxlQQuF4",
        "forum": "n3ZXEQKRbO",
        "replyto": "n3ZXEQKRbO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7886/Reviewer_ZSuS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7886/Reviewer_ZSuS"
        ],
        "content": {
            "summary": {
                "value": "This paper applies the dimensionality reduction method of pooled marginal slicing (PMS) to find a linear subspace of word embeddings to project away information pertaining to the sensitive attribute for debiasing, which adds to a long line of research on mitigating (gender) bias in word embedding models.  The authors demonstrate the utility of the method on several benchmark tasks/datasets, and provide a theoretical justification for the proposed method."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and easy-to-follow.\n- The proposed method is competitive with existing methods."
            },
            "weaknesses": {
                "value": "1. Description of hyperparameters is missing.  How was $H$ decided, and $q$ chosen, in algorithm 1?  I expect a tradeoff between accuracy and fairness for different settings of $q$, and it would be nice to include such a plot it in the paper.\n\n2. The theoretical justifications/contributions\u2014which is the main contribution of the present work highlighted by the authors\u2014 are very weak.\n\n\t- The *theory* relies on the strong assumption that \"there exists a full rank matrix $B \\in \\mathbb R^{p_1\\times q}$, such that $Z\\perp X \\mid B^\\top X$\".  Is there a theoretical discussion on the scenario where this assumption is violated?  How would the proposed method perform in such cases?\n\t- The authors lists *independence* and *separation* as the two desiderata of their method in definitions 3.1 and 3.2.  On the other hand, it is well-known that these cannot generally be simultaneously attained, see <https://fairmlbook.org/classification.html#relationships-between-criteria>.  How is it reconciled in the proposed framework?\n\t- The second result in theorem 6.1 is, in my opinion, too weak and not really meaningful.  If $X\\perp Y\\mid Q_y X$ and $\\mathrm{span}(Q_y)\\subseteq \\mathrm{span}(Q)$, then $\\widetilde X = (I-Q)X\\perp Y$, i.e., the fair representation is useless for predicting $Y$ (related to the incompatibility between *independence* and *separation*).  In this regard, the first contribution claimed in section 1 of bridging the debiasing and fairness tasks does not hold up.\n\n3. Some design choices are not (theoretically) justified.\n\n\t- In section 4.2, when $Z$ is categorical, why is there a need of learning a classifier instead of just using the one-hot encoding?\n\nIn summary, I think the authors has demonstrated that PMS is effective at debiasing word embeddings at least when compared to existing methods, although, I have my reservations on the practical usefulness of performing linear projection for debiasing word embeddings.  In particular, for text classification, there are more powerful methods (with theoretical guarantees) at achieving EO than performing linear debiasing (see follow-ups of Hardt et al. (2016)).  Instead, I would be more convinced if the author can demonstrate improved performance on WinoBias or WinoGender NLP tasks, for which bias mitigation methods for general classification tasks would not apply.\n\nOn the other hand, the theoretical discussions, as mentioned above, seems lacking if not problematic, and this weakens the overall contribution of the present work\u2014is there anything new besides showing that PMS can give good empirical debiasing performance on the benchmark datasets?"
            },
            "questions": {
                "value": "- What does *evenly* mean in \"We first split all the words evenly into two classes by calculating the cosine similarity between...\"?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7886/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698611589523,
        "cdate": 1698611589523,
        "tmdate": 1699636967678,
        "mdate": 1699636967678,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "n3TrgFSAQG",
        "forum": "n3ZXEQKRbO",
        "replyto": "n3ZXEQKRbO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7886/Reviewer_PbJ8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7886/Reviewer_PbJ8"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a debiasing method (SUP) that identifies minimal subspace correlated with sensitive attribute and project vectors against them. Under the linearity assumption, authors show that the suggested method can recover fair representation consistently. Authors show that the suggested method is superior to previous methods via evaluation using intrinsic metrics (word embedding bias) and extrinsic metrics (fair text classification performance)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This method is applicable to continuous sensitive variables.\n- Using a traditional tool (Pooled Marginal Slicing), the suggested method can provide theoretical guarantee under some conditions.\n- Using intrinsic, extrinsic metrics, evaluation is conducted in two levels, supporting the connection between debiasing and fairness."
            },
            "weaknesses": {
                "value": "- While the method can be applicable to any tasks that use vector representations, experiments are limited to NLP tasks.\n- Most of theoretical results are trivial from the linearity assumption and method."
            },
            "questions": {
                "value": "- Can this result be extended to other modalities? (e.g. fair image classification) While applications to other modalities are implied in the discussion, still I wonder if it is effective in other modalities as well.\n- Can the asymptotic result for PMS in this setting be provided? I am curious about the sample complexity and how the number of partitions affect. Also, it would be nice if it is possible to reveal how the estimation error propagates to bias with some quantifiable measures.\n- Can additional comparison with fair post processing methods be conducted? (e.g. https://fairlearn.org/)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7886/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7886/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7886/Reviewer_PbJ8"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7886/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698636105047,
        "cdate": 1698636105047,
        "tmdate": 1699636967563,
        "mdate": 1699636967563,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WGzE9Io1bd",
        "forum": "n3ZXEQKRbO",
        "replyto": "n3ZXEQKRbO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7886/Reviewer_acJ7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7886/Reviewer_acJ7"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a method for representation debiasing - the task of removing sensitive information from a learned representation post-hoc. The proposed method takes a projection-based approach, leveraging two existing approaches (SIR and PMS) to learn covariance matrices and taking their eigenvectors. Empirically, they run a range of experiments on word embeddings comparing to baselines demonstrating improved performance on metrics that look at both bias in feature space and classification."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- clear presentation\n- thorough experimental section: I appreciated the quantity of experiments and baselines. The empirical component of this is I think a pretty significant contribution, as I don't think I've seen so many debiasing methods lined up side by side like this\n- empirical results are strong and if they hold in general would be a nice improvement over other approaches in the space"
            },
            "weaknesses": {
                "value": "- I think the \"Debias\" and \"Fairness\" terminology introduced in Defns 3.1, 3.2 is misaligned with how these words are usually used: I would consider these tasks to both be debiasing and both be fairness tasks. This is a simple fix but I think a very important one - I think there are many other ways to map these concepts onto notions of fairness/bias which make more sense (e.g. they correspond to different fairness metrics - demographic parity and equalized odds - I'm not saying this is the way authors have to go but it's an option)\n- I think the contribution of the empirical section is nice - however I'm unsure of exactly how far the methodological contribution goes. It seems that the core of this method is in the regression approaches SIR + PMS. It would be good to know a bit more about why these approaches were chosen and why they are superior to other projection approaches, including those that already lean on eigenvalues (e.g. PCA-based approaches)\n- Additionally, given how core SIR/PMS are to this method, I think they could use some more explanation: for instance, why is Z partitioned into H intervals? why does PMS require continuous inputs? how well does it work to first train the classifier f for its probability outputs?\n- In general, I'm left a little bit unclear from Algo 1 how the \"debiased\" and \"fair\" representations, as they are referred to, are computed differently. It seems like everything specified here is for the X \\indep Z setting, rather than the X \\indep Z \\| Y setting\n- I find myself a little confused by some of the experiments in Sec 5.1, it seems like some details are bit short: for instance, I don't quite understand terms like \"bias-by-projection\" in Correlation or \"original bias\" in Profession Words. How are the top 500 male/female words in Clustering chosen?\n- Also missing a few details in Sec 5.4: what model is used for prediction? is Time in seconds? specify more clearly what the predicted labels are\n- I found Thm 6.1 a little confusing: 1) should the last statement be (I - Q_y)X? 2) is the assumption backwards - should span(Q_y) >= span(Q)? I looked at the proof and didn't it very enlightening, I think it could use a little more detail\n\nSmaller comments:\n- Assumption 3.3 + Eq. (1): it seems like there's a contradiction here - Ass'n 3.3 says that Z is perfectly predictable from a linear function of X, then (1) says there's a noise term included as well"
            },
            "questions": {
                "value": "- Clarification: why would we need an intersection of sufficient dimension reduction subspace? in what cases would they differ from each other?\n- Should clarify: is the output of PMS still minimal? it seems like the dimension-wise aggregation might result in a space with redundancies, but I could be wrong\n- In general, a number of experimental details seem to be missing: for instance, how is q chosen? what about H?\n- Interested to see that SUP improves over Glove in Table 2, left - I think this merits further exploration \n- I'd also like to see a comparison in Sec 7 to a PCA-based approach since that one also seems similar and solves directly for the debiasing direction"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7886/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698694479816,
        "cdate": 1698694479816,
        "tmdate": 1699636967418,
        "mdate": 1699636967418,
        "license": "CC BY 4.0",
        "version": 2
    }
]