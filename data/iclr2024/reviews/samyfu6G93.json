[
    {
        "id": "6FVqJX5fU9",
        "forum": "samyfu6G93",
        "replyto": "samyfu6G93",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8318/Reviewer_bkSL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8318/Reviewer_bkSL"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the proposition satisfiability (SAT) problem, which is an NP-complete problem. Recent algorithms focus on enhancing CDCL, the mainstream algorithm for solving SAT problems, using Graph Neural Networks (GNNs). While this can make the  solving process more effective, these methods require online model inferences, which consumes substantial GPU resources. In this paper, the authors design an approach called NeuroBack, which uses the trained model and can be executed on the CPU, avoiding the dependence on GPU resources. The authors claim that enhancing the state-of-the-art SAT solver Kissat with NeuroBack can achieve better results than Kissat itself."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. NeuroBack gets rid of the GPU resource dependence of the solving process and improves the practicality of using GNN to enhance SAT solving.\n\n2. The authors conduct experiments to evaluate the performance of their proposed method."
            },
            "weaknesses": {
                "value": "I have several comments regarding the experiment part, which are listed below.\n\n1. Regarding the baseline competitor. As described in the experiment part, the baseline competitor is kissat. Although kissat can be regarded as the latest breakthrough in the community of SAT solving, lots of kissat\u2019s variants have been proposed since the introduction of kissat (as can be observed in the recent editions of SAT competitions). However, the authors only compare their solver with vanilla kissat. As a submission to a top-tier conference, this is not that thorough.\n\n2. Regarding the evaluation on SAT Competition 2022\u2019s datasets. Actually, as a submission in SAT solving, the tradition is to evaluate their proposed solver on the dataset from the latest edition of SAT Competition. In fact, as of the submission deadline of ICLR, the latest edition of SAT Competition is SAT Competition 2023. According to the official website of SAT Competition 2023 (https://satcompetition.github.io/2023/), the dataset of SAT Competition 2023 was published in July, 2023. Since the submission deadline of ICLR is due on September 28. 2023, there left two months for the authors to conduct the comparative experiments on the dataset of SAT Competition 2023. Hence, such lack of experiments is indeed a minus."
            },
            "questions": {
                "value": "Please see my comments listed in \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Not applicable."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8318/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8318/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8318/Reviewer_bkSL"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8318/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698562531070,
        "cdate": 1698562531070,
        "tmdate": 1699637034527,
        "mdate": 1699637034527,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UthKXwGcnw",
        "forum": "samyfu6G93",
        "replyto": "samyfu6G93",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8318/Reviewer_7KxS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8318/Reviewer_7KxS"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the challenge of improving propositional satisfiability (SAT) problem-solving, a significant task in various research domains like planning, verification, and security. It introduces a novel approach called NeuroBack, which enhances Conflict-Driven Clause Learning (CDCL) SAT solvers using Graph Neural Networks (GNNs. The innovation lies in two key insights: predicting variable phases that frequently appear in satisfying assignments and requiring just one query to the neural model before starting the SAT solving process. Once trained, NeuroBack can operate entirely on the CPU, reducing the reliance on GPU resources.\n\nThe authors developed a new dataset, DataBack, comprising 120,286 data samples, to train NeuroBack and implemented it as an enhancement to the state-of-the-art SAT solver, Kissat. By incorporating NeuroBack into Kissat, the SAT solver exhibited a 5.2% improvement in problem-solving effectiveness, as demonstrated in the SATCOMP-2022 competition dataset. It also improved solving efficiency, resulting in an average time saving of 117 seconds per problem. This research introduces the first practical neural approach to enhance CDCL SAT solving without requiring GPU resources, provides a new dataset, and offers public access to the NeuroBack model and NeuroBack-Kissat source code."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Providing a dataset\nCompeting with SAT 2022"
            },
            "weaknesses": {
                "value": "I think some citations are missing\n\nhttps://cs.stanford.edu/~jure/pubs/g2sat-neurips19.pdf\nNeurogift: Using a machine learning-based sat solver for cryptanalysis\nRole of Machine Learning for Solving Satisfiability Problems and its Applications in Cryptanalysis\n\nIt would be nice to have a use case in Cryptanalysis (solving AES or small AES instance)"
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "-"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8318/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698570465790,
        "cdate": 1698570465790,
        "tmdate": 1699637034382,
        "mdate": 1699637034382,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gtZ9cvJ19s",
        "forum": "samyfu6G93",
        "replyto": "samyfu6G93",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8318/Reviewer_HXv9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8318/Reviewer_HXv9"
        ],
        "content": {
            "summary": {
                "value": "This paper is devoted to improving propositional satisfiability (SAT)\nsolving by means of utilizing modern machine learning (ML) technology.\nNamely, the paper proposes to make use of a GNN architecture for\nrepresenting CNF formulas, which is trained to determine the variable\npolarity / phase following the ideas behind backbone literals.\nBackbone literals of a CNF formula are literals that must necessarily\nbe satisfied by every satisfying assignment of that formula. The\nauthors argue that the GNN architecture they propose can efficiently\ndetermine the polarities of all variables: including those appearing\nin backbone literals but also any other variables in the formula.\nAfterwards, when the predicted polarities are obtained, a\nstate-of-the-art SAT solver can be bootstrapped with these variable\nphases with the hope that such initialization can boost the solver's\nperformance. Experimental results shown in the paper demonstrate the\neffectiveness of this idea if implemented on top of a modern SAT\nsolver called Kissat."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is clearly written and easy to follow. Normally, papers on\n  applying ML for improving combinatorial problem solving are written\n  in Greek, if seen from the perspective of a researcher with\n  expertise in the combinatorial problem of interest. This paper\n  serves as a nice exception.\n\n- The idea is reasonable. It is simple to implement and it can be used\n  with any SAT solver.\n\n- The experimental results reported although not amazing look solid."
            },
            "weaknesses": {
                "value": "- Although everything the paper describes is described well, there are\n  bits that aren't detailed sufficiently - some ML people may find it\n  to be a minus.\n\n- The paper says nothing about the usability of this heuristic for\n  unsatisfiable instances. There are no backbones in those but I\n  presume some variable phases may still be more useful in practice\n  than the others.\n\n- Despite the claimed experimental results, nothing is shown for the\n  unsatisfiable instances. This and the point above can be joined\n  together.\n\n- Although Neuroback+Kissat solves 10 more instances out of 308, there\n  are 92 more (308 + 92 = 400) where Neuroback fails to do anything\n  useful. Hence, the proposed solver configuration must clearly lose\n  to Kissat on those 92 instances as it spends additioanl time with no\n  effect. If this understanding of mine is correct then the results\n  aren't so positive.\n\n- Minor1: in CDCL description, the algorithm undoes not only\n  *wrong decisions* but also propagated literals.\n\n- Minor2: in CDCL description, the conventional algorithm backtracks\n  to the *latest* decision level where the conflict is resolved - not\n  *earliest*."
            },
            "questions": {
                "value": "- Can you comment on the use of this heuristic for unsatisfiable\n  instances? Have you tried this? If yes, what is the performance\n  compared to Kissat? If not, why?\n\n- Can you comment on losing on 82 instances to Kissat if we consider\n  all the 400 instances in the benchmark set? Am I missing anything?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8318/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698810940309,
        "cdate": 1698810940309,
        "tmdate": 1699637034248,
        "mdate": 1699637034248,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sPwb0ygsOs",
        "forum": "samyfu6G93",
        "replyto": "samyfu6G93",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8318/Reviewer_w5iE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8318/Reviewer_w5iE"
        ],
        "content": {
            "summary": {
                "value": "The NeuroBack paper proposes a new approach to improve CDCL SAT solving using Graph Neural Networks. The proposed approach, called NeuroBack, gives an initial assignment to all variables and queries the neural model only once, allowing it to execute exclusively on the CPU and making GNN improvements practical. The paper also introduces a new dataset called DataBack and implements NeuroBack as an enhancement to a state-of-the-art SAT solver called Kissat. The authors evaluate NeuroBack on a variety of benchmarks and show that it outperforms Kissat and other state-of-the-art solvers on many instances."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Using ML to enhance CDCL SAT solver is promising research, which is more likely to yield improvement in SAT solving than end-to-end learning on SAT. I like the idea in this paper of using ML to give an initial assignment for the CDCL solvers by training on predicting the value of backdoor variables. The paper mentions the importance of backdoor valuables and the intuition of why training on backdoor variables can help predict the values for all variables that appear in the majority of the variables.\n\nIt is also promising to see that NeuroBack is actually able to improve Kissat, as state-of-the-art SAT solvers are well-engineered and very hard to optimize."
            },
            "weaknesses": {
                "value": "While training on backdoor variables yields a good predictor for the value of all variables, why this approach works is still a bit mysterious. It would be helpful to have more experiments showing that initialization is actually better than a random assignment. Therefore I would like to see some behavior studies of NeuroBack on different kinds of benchmarks. Possible ways include comparing the distance from this initial assignment given by NeuroBack with the nearest solution. Or evaluating the prediction accuracy of the value of a specific variable given by NeuroBack with the majority value of this variable in all solutions (this requires listing all solutions of a formula, which is only doable on small formulas).  \n\nThe experiment section also lacks a comparison with other initialization methods for SAT solving, as Neuro-back is in essence an initialization method. \n\nI am not quite convinced by the claimed advantage that NeuroBack only needs to be called once. This is a trivial property for any initialization approach for SAT solving. I believe that a more interactive collaboration between GNN and SAT solvers can further improve the performance of STA solvers, even if GNN needs to be called multiple times (correct me if I am wrong). I would be happy to change the evaluation if my concerns can be addressed.\n\nMinor comments:\nI would use \"value\" instead of \"phase\" and \"initial assignment\" instead of \"initialization\" to make it clear."
            },
            "questions": {
                "value": "See the above comments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8318/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8318/Reviewer_w5iE",
                    "ICLR.cc/2024/Conference/Submission8318/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8318/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828437631,
        "cdate": 1698828437631,
        "tmdate": 1700693462187,
        "mdate": 1700693462187,
        "license": "CC BY 4.0",
        "version": 2
    }
]