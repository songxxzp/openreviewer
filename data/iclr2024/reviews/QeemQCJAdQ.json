[
    {
        "id": "iA3Hwu0EOF",
        "forum": "QeemQCJAdQ",
        "replyto": "QeemQCJAdQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2270/Reviewer_om5H"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2270/Reviewer_om5H"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a deep Q-learning approach for resource prioritization in hospitals. They learn a Q function that given the state of all patients and current ventilation status at each bed, for each vector of the next ventilation decisions (a binary vector) outputs the value per patient. These values can subsequently be utilized to formulate a policy. The method's performance is assessed using real ICU data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The problem is well-motivated and holds significant importance.\n- The presentation is mostly clear.\n- Real data is used for evaluation."
            },
            "weaknesses": {
                "value": "1. I don't think the proposed Q-learning framework fits this problem. In fact, the proposed Q-network cannot see the interaction of patients; changing $a_i$ does not change $Q_\\theta(s)_{j,a_j}$, $j \\neq i$. Please clarify if this is not the case.\n2. It's not clear what value this Q function is estimating. Further elaboration is required here.\n3. I cannot see how survival rate as a measure of performance is estimated from offline data. What off-policy evaluation technique is used?\n4. Minor typos: Eq. 3: $x'$ to $x'_i$.  Page 3: in 3 to in Fig. 3."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2270/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2270/Reviewer_om5H",
                    "ICLR.cc/2024/Conference/Submission2270/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2270/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698639546770,
        "cdate": 1698639546770,
        "tmdate": 1700615812780,
        "mdate": 1700615812780,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3aZxgyRAb1",
        "forum": "QeemQCJAdQ",
        "replyto": "QeemQCJAdQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2270/Reviewer_GCVq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2270/Reviewer_GCVq"
        ],
        "content": {
            "summary": {
                "value": "There are many situations within healthcare in which resources such as ventilators are scarce and require the use of carefully thought-out protocols to determine the proper allocation. However, currently there are many different protocols for to handle this allocation which involve conflicting heuristics. Since these decisions are usually sequential, the authors propose using reinforcement learning for\nto construct a fair and effective resource allocation protocol. Specifically, they use a transformer-based deep Q-network to integrate patients' disease progressions and interactions during resource allocation. Their experiments show that their method results in both fair and effective allocation of resources."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The authors did an excellent job detailing the design of the RL problem and the experimental setups."
            },
            "weaknesses": {
                "value": "It would have been nice to see the limitations in the main text rather than the appendix. However, it is understandable due to the page limit."
            },
            "questions": {
                "value": "Is it possible for the authors to disclose the names of the datasets used in this study if they are publicly available?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "10: strong accept, should be highlighted at the conference"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2270/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2270/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2270/Reviewer_GCVq"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2270/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698720223904,
        "cdate": 1698720223904,
        "tmdate": 1699636159635,
        "mdate": 1699636159635,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1plkGwNJX8",
        "forum": "QeemQCJAdQ",
        "replyto": "QeemQCJAdQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2270/Reviewer_dm6i"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2270/Reviewer_dm6i"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a transformer-based deep Q-network method for efficient and fair allocation of ventilators in critical care settings. The experiments on a real-world dataset demonstrated that the proposed method achieved both higher patient survival rates and more equitable allocations across different ethnic groups compared to existing heuristic-based policies utilized by different governments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Originality:** The novelty of this paper mainly lies in the application aspect, in that 1) fairness objectives are incorporated into a DRL framework for healthcare resources allocation modeling 2) the individual patient disease progression and the interaction effects among patients are accounted for simultaneously by utilizing a transformer based Q-network.\n\n**Quality:** The quality of this paper is fair. The experiments showed that the proposed method outperformed existing heuristic-based policies utilized by governments, but did not compare with any data-driven or machine learning baselines. The ablation study showed the effectiveness of different components (the ventilator cost, the patient survival and the fairness in allocation) in the reward function. \n\n**Clarity:** Overall the paper is clear, but the notations are sometimes confusing and more technical details are needed for a better understanding of the method / experiments.\n\n**Significance:** Healthcare resource allocation is an important topic in critical care medicine. A more efficient and fair policy than existing government policies will result in more people being saved at lower levels of costs with minimal disparities among different ethnic groups. Thus this work has high clinical relevance and significance."
            },
            "weaknesses": {
                "value": "1. The notations are confusing in Section 3.3 and 3.4. Based on the context, are $x_i$ and $s_i$ the same (the medical condition of patient i), and $P^\\text{on}$ and $P^\\text{vent}$ the same (the ventilation transition)? If so, please ensure that the notations are consistent. Also, I think the action $a$ is N-dimensional and the i-th coordinate $a_i \\in \\\\{0, 1\\\\}$ is the action applied on patient i, if this is the case, does $I'_i = a$ mean $I'_i = a_i$ in 1? Also, what is the dimension of the overall transition matrix $P$?\n\n2. Currently, the state and action are the concatenations of the medical/ventilator states and the ventilator assignments of individual patients. Will there be scalability issue when the number of patients $N$ is really large and if there is, how to handle that with the current framework?\n\n3. Some details in the transition model are missing. How is $P^\\text{vent} (x'_i | x_i)$ determined? From the description of the simulator in Section 5.2, it seems that you consider the factual data, e.g. $P(x'_i | x_i) = 1$ if $x'_i$ is the actual next state for patient i and $P(x'_i | x_i) = 0$ otherwise? Did you consider any counterfactuals? Will the results be negatively impacted by any potential selection bias in the data if only factual data is used? Also, how are $q_i(s)$ (bed assignment distribution) and $\\xi$ (initial medical condition distribution) determined?\n\n4. Some details in the Method and Experiments are missing. The learning objective is missing. From the context, I am assuming that you are using Q-learning with the proposed reward and then used the greedy policy with the learned Q function, but it's not clear from what's written now in Section 4. Also, the choice of the ventilator cost $c_1$ and the $\\lambda$ to trade-off the fairness reward term are missing in the main paper (found them in appendix). Is there any justification on how they are determined? I am also wondering how the results will change if $c_1$ and $\\lambda$ are chosen differently."
            },
            "questions": {
                "value": "1. Will the dataset be made public if the paper is published? So that the results can be reproduced.\n\n2. The experiments showed that the proposed method outperformed existing government policies. I am wondering if there is any data-driven baselines in the literature and how will your method perform compared to them? \n3. There are some confusions in the writing, e.g. \n\n- Page 3, \"... proposed model in 1\" -> \"... proposed model in Figure 1\"?\n- Page 6: \"... the action set $\\mathcal{A}$ are defined in Eq. equation 2\" -> \"... the action set $\\mathcal{A}$ are defined in Eq. 2\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Responsible research practice (e.g., human subjects, data release)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The dataset used seems to be proprietary and the authors did not provide detailed information on the dataset or whether it can be made public upon paper publication."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2270/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2270/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2270/Reviewer_dm6i"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2270/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698786674107,
        "cdate": 1698786674107,
        "tmdate": 1699636159551,
        "mdate": 1699636159551,
        "license": "CC BY 4.0",
        "version": 2
    }
]