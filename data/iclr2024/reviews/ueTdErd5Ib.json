[
    {
        "id": "q0DI8f9qOh",
        "forum": "ueTdErd5Ib",
        "replyto": "ueTdErd5Ib",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8275/Reviewer_9FbH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8275/Reviewer_9FbH"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a new approach to contextual stochastic optimization. This approach first divides the feasible region into subregions, and then builds a prediction model that predicts the probability that the optimal solution for a given context will fall in a given subregion. These predicted probabilities are incorporated into an optimization problem that can be used to select a decision for a given context. The authors provide asymptotic bounds regarding the generalization error of the method as well as a type of stability of the method. The authors provide computational results demonstrating the results of the method for a newvendor problem and a generator scheduling problem."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The author's approach to contextual stochastic optimization problems is overall quite novel. The paper is well-organized and clearly written. Contextual optimization problems are an important topic of recent interest, so novel methods for this class of problems are a welcome contribution."
            },
            "weaknesses": {
                "value": "There is a significant issue with the framing of the paper. In particular, the authors frame their contribution as an approach for robust contextual stochastic optimization problems. However, I do not think that this an accurate presentation. Consider the central optimization problem (equation 5, page 4): \n$$\\min_{w \\in \\mathcal{P}} \\mathbb{E}_{\\nu_x \\sim D_x}[\\max\\\\{R\\_{\\nu\\_x}(w)-\\phi,0\\\\}]$$\nNote that this problem can be rephrased as the problem of minimizing the expectation of a function $f\\_{\\nu\\_x}$, specifically: \n$$f\\_{\\nu\\_x}(w) = \\max\\\\{R\\_{\\nu_x}(w)-\\phi,0\\\\}$$\nSo, this problem is just a special type of a contextual stochastic optimization problem, and techniques for contextual stochastic optimization problems, such as that in Bertsimas and Kallus (2020) or Donti et al. (2017), could be applied here. Note that robust, distributionally robust, or risk-averse optimization problems cannot typically be easily reduced to a standard stochastic problems. \n\nThe authors do not provide a proof of Lemma A.1 in the appendix, which seems like a fairly critical step in the proof of Theorem 5.1. In addition, I suspect that Lemma A.1 is not actually true. In particular, the Hypothesis Stability provides a convergence rate $\\beta_N$ on the change in predicted probability by omitting a point for a single binary classification problem. However, it seems to me for this lemma to work, the authors would need a uniform convergence rate $\\beta_N$ that applies to all $N$ binary classification problems (note here that the number of binary classification problems appearing in the authors' method increases with sample size). This seems to me to be a much stronger property.\n\nThe computational experiments compare the authors' methods to methods that solve a completely different problem. In particular, three of the four comparison methods seem to be designed to solve the problem $\\min\\_{w}\\mathbb{E}\\_{\\nu\\_x \\sim D\\_x}[R\\_{\\nu\\_x}(w)]$ , while the remaining method (KNN+KL Robust) is designed to solve a robust variant of this problem that is not clearly connected to the problem that the authors are solving. Notably, the authors claim that the method of Bertsimas and Kallus (2020) does not apply to this problem. However, this method can be applied as follows. First, fit a prediction model that predicts the parameter $\\nu$ from the context $x$. Then, given some fixed context $x$, derive weights $\\hat{p}\\_n(x)$ for each training points $\\{x^N,\\nu^N\\}$ (as described in Bertsimas and Kallus 2020).  Then, solve the problem: \n$$\\min_{w \\in \\mathcal{P}} \\sum_{n=1}^N \\hat{p}\\_n(x)\\max\\\\{R\\_{\\nu^n}(w)-\\phi,0\\\\}$$\n\nSimilarly, the method of Donti et al. (2017), the \"policy optimizer method\" and the \"MLE method\" could also be applied to the problem $\\min_{w \\in \\mathcal{P}} \\mathbb{E}_{\\nu_x \\sim D_x}[\\max\\\\{R\\_{\\nu\\_x}(w)-\\phi,0\\\\}]$, rather than to the problem of $\\min\\_{w}\\mathbb{E}\\_{\\nu\\_x \\sim D\\_x}[R\\_{\\nu\\_x}(w)]$ by making relatively straightforward modifications to these methods.\n\nMinor comments:\n\nThe authors state that $\\mathbb{E}\\_{\\nu\\_x \\sim D\\_x}[R\\_{\\nu\\_x}(w)-\\phi \\mid R\\_{\\nu\\_x}(w) \\geq \\phi]$ is the CVar (discussion following equation 6 in page 4). However, this is not accurate. The CVaR in this setting would be given by something like: $ \\mathbb{E}_{\\nu_x \\sim D_x}[R\\_{\\nu\\_x}(w) \\mid R\\_{\\nu\\_x}(w) \\geq q\\_{\\alpha}(R\\_{\\nu\\_x}(w))]$ where $q\\_{\\alpha}(Z)$ gives the $\\alpha$ quantile of the variable $Z$. Minimizing the latter is not equivalent to minimizing the former. \n\nThe authors frequently refer to expressions involving $w^*$ that are only well-defined if the problem has a unique solution. This could easily be fixed, for example by stating that $w^*$ is an oracle that chooses one solution."
            },
            "questions": {
                "value": "Why did you choose this particular form of objective function, rather than using more established notions of risk, such as CVaR?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Reviewer_9FbH"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8275/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698351191342,
        "cdate": 1698351191342,
        "tmdate": 1699637028945,
        "mdate": 1699637028945,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VToPlDX2Zg",
        "forum": "ueTdErd5Ib",
        "replyto": "ueTdErd5Ib",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8275/Reviewer_VbmN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8275/Reviewer_VbmN"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed a new data-driven approach for the contextual optimization problem. It also provides a new loss function to allow users to balance the robustness and the expected performance. To illustrate the performance, the authors provide a theoretical analysis of the regret and algorithm stability as well as the numerical results for many applications."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea is new and interesting, which is to discretize the decision set to do the robust optimization looks interesting.\n\n2. The new loss function can balance the worst-case regret and the expected regret.\n\n2. the numerical performance looks good.\n\n3. the paper has theories corresponding to the algorithm."
            },
            "weaknesses": {
                "value": "1. My main concern is the efficiency of the given algorithm. For me, it might be impossible to efficiently learn $\\hat{p}$ in Step 3 of the algorithm unless the size of the training sample is exponentially large as the dimension of the feasible set. Please see question 1 for more details.\n\n2. It seems that the feasible set must be fixed for different contextual information.\n\n3. It would be better to have more discussion about the choice of $\\phi$ in the loss function.\n\nSome minor points:\n\n4. In addition, It looks like the bound in Theorem 4.1 is established for any fixed decision $w$. It would be better to have a uniform generalization bound instead since the output of the algorithm is not a fixed action.\n\n5. Assumption 5.2 looks strong for many optimization problems. For example, linear programming does not satisfy (14)."
            },
            "questions": {
                "value": "1. Corresponding to Part 1 in the weaknesses, I wonder whether one can learn the probability efficiently. Or, equivalently, I wonder whether the authors could elaborate more on the sample complexity for learning and reducing $\\Epsilon$ in (11) for Theorem 1. Please correct me if I am wrong. For me, I am not sure whether it is possible to learn $\\Epsilon$ efficiently, especially when the dimension of the feasible set is large. In other words, one may require the size of training data to be exponentially large as the dimension of the feasible set to have a low $\\Epsilon$. Particularly, based on the algorithm, H_k^{\\epsilon} may only cover a small region, the volume of which can decrease exponentially when the dimension is high. Then, if the size of the training samples is only polynomially large as the dimension, it is very likely that $H_k$'s are disjointed or rarely have non-empty intersections. In this case, the multi-label data set for each training sample might be a vector with only one non-zero entry.\n\n2. Can the algorithm still be useful when the feasible region also depends on the contextual data?\n\n3. In practice, I wonder how one should choose $\\phi$ and $\\epsilon$.\n\n4. Corresponding to part 4 in the weaknesses, I wonder whether the authors would like to change Theorem 4.1 to a uniform generalization bound."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Reviewer_VbmN"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8275/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698623275450,
        "cdate": 1698623275450,
        "tmdate": 1700619168538,
        "mdate": 1700619168538,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ctsAJAtJ8t",
        "forum": "ueTdErd5Ib",
        "replyto": "ueTdErd5Ib",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8275/Reviewer_67NA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8275/Reviewer_67NA"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes and studies a novel robust optimization framework that is based on discretization of the domain with respect to the data set. The framework proceeds as follows. For each data sample about the problem uncertainty, it constructs the set of near-optimal solutions to the optimization problem whose parameters are specified by the data sample. These sets basically give rise to the \"discretization\" of the solution space. Then the framework builds an ML model to learn the probability that the optimal solution to the problem whose parameter is given by a particular data sample is near-optimal with respect to other data samples. Here, the framework is flexible in terms of choosing which ML models to use, e.g., k-nearest neighbor. The paper provides some theoretical performance guarantees of the proposed framework and promising numerical results.\n\nHowever, it seems that the paper could be further improved by investigating further the connections between the proposed framework and the existing data-driven robust optimization methods. Moreover, the paper needs to refine and better present its theoretical performance guarantees. Lastly, the reader would appreciate if the paper provided more intuitions about the proposed framework for robust optimization problems particularly."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The robust optimization framework of solving minimizing $E[[R(w)-\\phi ]_+]$ is novel while it is related to many of the existing robust optimization frameworks.\n* The data-driven learning-and-optimization method studied in this paper is novel, and the method is flexible in that it can take any ML models to learn the uncertain parameters of the problem.\n* The paper provides both theoretical performance analysis and promising numerical results."
            },
            "weaknesses": {
                "value": "* It is difficult to appreciate the main theoretical performance guarantee on the proposed framework  (given in Theorem 4.1) due to its dependence on the parameters $c$ and $\\alpha$. Here, $c$ would increase as the accuracy parameter $\\epsilon$ as well as the size of each subset decrease, in which case the bound gets weak. We may try to decrease the parameter $\\epsilon$ to make $c$ close to 1, but this would make the mean prediction error $\\mathcal{E}$ large. At the same time, no explicit dependence of $c\\mathcal{E}$ on $\\epsilon$ is studied. Lastly, $\\alpha$ could be arbitrarily large when the objective function is not bi-Lipschitz. \n* The framework is almost equivalent to minimizing the conditional value-at-risk (CVaR), except that there is an additional probability term being multiplied. The paper would be stronger if it discussed the relationship between the existing CVaR minimization setting and the framework of this paper. No numerical results were done with the CVaR framework. \n* There are many typos in the mathematical proofs in the appendix."
            },
            "questions": {
                "value": "* On page 4, the algorithm is described. Should each data be given by $(x^n, (p_k^n)_{k=1,\\ldots, N})$ instead of $k=1,\\ldots, n$?\n* Typically, the notion of regret is defined for iterative learning processes. Is it possible to extend the current framework to the online setting for which we allow updating the model with a new set of data samples.\n* In the introduction, it is stated that the difference between the in-sample cost and the out-of-sample cost decreases on the order of $1/\\sqrt{n}$. Perhaps, it would be a better strategy to decompose the current statement of Theorem 4.1 into two where one explains the statement and the other presents the regret bound. \n* Could you provide more computational results on a broad set of tolerance levels? For example, 50%, 75%, 90%, 95% quantiles."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Reviewer_67NA",
                    "ICLR.cc/2024/Conference/Submission8275/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8275/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698642373823,
        "cdate": 1698642373823,
        "tmdate": 1700611692836,
        "mdate": 1700611692836,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WFGIjXjAuV",
        "forum": "ueTdErd5Ib",
        "replyto": "ueTdErd5Ib",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8275/Reviewer_XXVR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8275/Reviewer_XXVR"
        ],
        "content": {
            "summary": {
                "value": "This paper explores robust contextual stochastic optimization. In this problem setting, we have a feasible set $\\mathcal{P}$ and an objective function $g_{\\bm{v}}(\\bm{\\omega})$, where $\\bm{v}$ is a random variable. The distribution of $\\bm{v}$ depends on a contextual variable $\\bm{x}$, denoted as $\\bm{v} \\sim \\mathcal{D}_{\\bm{x}} $, and this distribution is unknown. Unlike other contextual stochastic optimization problems, the primary focus of this paper is the following problem:\n$\n\\min_{\\bm{\\omega} \\in \\mathcal{P}} \\mathbb{E}_{\\bm{v}_{\\bm{x}} \\sim \\mathcal{D}_{\\bm{x}}} \\left[\\max\\{R_{\\bm{v}_{\\bm{x}}}(\\omega)-\\phi, 0 \\}\\right]\n$\nThis problem aims to minimize the expected violation, where $\\phi$ represents a user-defined cost threshold. Here, $R_{\\bm{v}}(\\omega) = g_{\\bm{v}}(\\bm{\\omega}) - g_{\\bm{v}}(\\bm{\\omega^*(\\bm{v})})$ denotes the regret of decision $\\bm{\\omega}$ when the objective function parameter is $\\bm{v}$.\n\n\\section*{Methodology}\n\nGiven a historical dataset of observations $\\{(\\bm{x}^i, v^i)\\}_{i=1}^n$, the authors propose to define two key components:\n$\nH_k^\\epsilon = \\{\\bm{\\omega}\\in \\mathcal{P}: R_{\\bm{v}^k}(\\omega) \\leq \\epsilon\\},\n$\nand\n$\np^n_k = \\begin{cases}\n    1, & \\text{ if } \\bm{\\omega}^*(\\bm{v}^n) \\in H_k^\\epsilon\n    \\\\\\\\\n    0, & \\text{ otherwise}. \n\\end{cases}\n$\n\nTo harness this information, the authors propose training a machine learning model $\\hat{p}_k^\\epsilon(\\bm{x})$ to predict $\\mathbb{P}(\\bm{\\omega}^*(\\bm{v}_{\\bm{x}}) \\in H_k^\\epsilon)$. Consequently, the contextual stochastic optimization problem transforms into:\n$\n\\min_{\\bm{\\omega}} \\sum_{k=1}^N \\hat{p}_k^\\epsilon(\\bm{x}) \\max\\{R_{\\bm{v}_{\\bm{x}}}(\\omega)-\\phi, 0\\}.\n$\n\n\\section*{Questions and Comments}\n\nIn reviewing this work, several questions and comments have emerged:\n\n\\begin{itemize}\n    \\item First, regarding the definition of $H_k^\\epsilon$, it seems unnecessary to have that $\\cup_{k=1}^n H_k^\\epsilon = \\mathcal{P}$. If this is the case, it is unclear how the authors intend to bound the regret when $\\bm{x}$ is observed and $\\mathbb{P}\\left(\\bm{\\omega}(\\bm{v_x}) \\in \\mathcal{P}\\setminus (\\cup_{k=1}^n H_k^\\epsilon)\\right) > 0$.\n    \n    \\item Additionally, the paper would benefit from a discussion of how the machine learning model $\\hat{p}_k^\\epsilon(\\bm{x})$ is trained based on the provided data. Are the models trained jointly or separately on $(p_k^n)_{k=1, \\cdots, n}$? If trained separately, there may be cases where $\\sum_{k=1}^N \\hat{p}_k^\\epsilon(\\bm{x}) \\neq 1$, making it challenging to interpret $\\min_{\\bm{\\omega}} \\sum_{k=1}^N \\hat{p}_k^\\epsilon(\\bm{x}) \\max\\{R_{\\bm{v}_{\\bm{x}}}(\\omega)-\\phi, 0\\}$ as an approximation of $\\min_{\\bm{\\omega}} \\mathbb{E}_{\\bm{v}_{\\bm{x}} \\sim \\mathcal{D}_{\\bm{x}}} \\left[\\max\\{R_{\\bm{v}_{\\bm{x}}}(\\omega)-\\phi, 0 \\}\\right]$. In cases of joint training, how do the authors handle models when the possible outcomes $(p_k^n)_{k=1, \\cdots, n}$ outnumber the training data size? Regrettably, these details are not addressed in the numerical study neither.\n    \n    \\item Furthermore, when examining the final problem:\n$\n    \\min_{\\bm{\\omega}} \\sum_{k=1}^n \\hat{p}_k^\\epsilon(\\bm{x}) \\max\\{R_{\\bm{v}_{\\bm{x}}}(\\omega)-\\phi, 0\\}\n$\n    it becomes apparent that, although it is linear in $n$, when $n$ is very large, this problem may become computationally challenging. Do the authors have any insights or strategies for addressing this issue?\n    \n    \\item Finally, the overall framework resembles a weighted average optimization problem. It would be meaningful to discuss how this framework fundamentally differs from Bertsimas and Kallus (2020) and related literature.\n    \n    \\item A recommendation is made to move Section 5 entirely to an appendix, allowing more space for a deeper discussion of the framework, algorithm, and implementation details.\n\\end{itemize}\n\n\\section*{Minor Comments}\n\nSome minor comments for consideration:\n\n\\begin{itemize}\n    \\item In Equation (10), $H_\\epsilon^k$ should be corrected to $H_k^\\epsilon$.\n    \n    \\item In the beginning of the sixth line in Theorem 4.1, $H_k$ should be corrected to $H_k^\\epsilon$.\n    \n    \\item In the penultimate line of the same theorem, $x \\to \\bm{x}$ and $\\bm{v}_x \\to \\bm{v_x}$ for consistency.\n\\end{itemize}"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Proposed a new framework to solve robust contextual stochastic optimization problem. Please see my comments in Summary for details."
            },
            "weaknesses": {
                "value": "Not fully clear presentation/discussion of their algorithm. Please see my comments in Summary for details."
            },
            "questions": {
                "value": "Please see my comments in Summary for details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8275/Reviewer_XXVR"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8275/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698796701635,
        "cdate": 1698796701635,
        "tmdate": 1699637028609,
        "mdate": 1699637028609,
        "license": "CC BY 4.0",
        "version": 2
    }
]