[
    {
        "id": "3eBsQnR96r",
        "forum": "uJPWeZffgl",
        "replyto": "uJPWeZffgl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5927/Reviewer_2ZRW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5927/Reviewer_2ZRW"
        ],
        "content": {
            "summary": {
                "value": "This work formulates neuro-symbolic learning as a bilevel optimization problem, using Moreau envelopes to smooth the NeSy energy function. This yields substantial runtime improvements over competing methods."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is nicely structured and easy to follow.\n\n2. The approach is well-motivated and yields substantial runtime benefits.\n\n3. The considered problem is important to the machine learning field."
            },
            "weaknesses": {
                "value": "1. Neither variant of the propsed method (CC / LF) consistently beats the ADMM baseline across all datasets. However, it is significantly faster in most cases.\n\n2. Only one baseline was considered. As neural-symbolic systems aren't my field I'll defer to other reviewers on whether this is adequate."
            },
            "questions": {
                "value": "1. In table 2, the LF D-BCD method performs poorly for the MNIST addition tasks. The authors note that this is due to the \"high number of tightly connected components.\" I didn't quite understand this explanation.\n\n2. Where does the value function introduced in (7) come from? Is it learned from data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5927/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697735990298,
        "cdate": 1697735990298,
        "tmdate": 1699636630733,
        "mdate": 1699636630733,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nyoIBm9kZP",
        "forum": "uJPWeZffgl",
        "replyto": "uJPWeZffgl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5927/Reviewer_vhBN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5927/Reviewer_vhBN"
        ],
        "content": {
            "summary": {
                "value": "This paper develops a general first-order gradient-based framework for end-to-end neural and symbolic parameter learning. \nThe framework is formulated as a bilevel optimization problem with a constrained lower-level inference problem. The inference problem minimizes a task-specific energy function, while the upper-level problem minimizes a mixed value- and minimizer-based objective. Using the value-function approach, the bilevel problem is reformulated as an inequality-constrained optimization problem, which in turn is relaxed by allowing finite violations of the constraint. Further, to deal with potential  non-differentiability of the energy function, a Moreau-envelope-based smoothening is applied. The final algorithm iteratively solves increasingly tight relaxations of the resulting smoothed optimization problem. Each relaxation is solved using a bound-constrained augmented Lagrangian algorithm.\n\nNext, the framework is applied to neural probabilistic soft logic, in which inference is formulated as MAP on a deep hinge-loss Markov random field. The inference problem is then reformulated as a regularized LCQP, for which several continuity properties are established. An efficiently parallelizable dual block coordinate descent algorithm is proposed for solving it.\nFinally, an empirical investigation shows that the proposed set of methods consistently improves inference and training runtime, while improving the accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The reformulation of the NeSy learning problem into its relaxed and smoothened formulation (9) is quite powerful as it allows the application of first-order optimization techniques. The employed higher-level bound-constrained augmented Lagrangian method for solving it is known but applied in a new context.\n- The novel formulation of NeuPSL as an LCQP and the presented efficient and parallelizable dual block coordinate descent algorithm for solving it seems to be the key contribution. The shown continuity properties are a nice addition, the detailed proofs appear correct.\n- The experiments show impressive results in terms of runtime and accuracy in multiple settings. The experimental methodology is good, with detailed information on resources and hyperparameter optimization, with open-source code provided. \n- Overall, this paper makes multiple contributions that are empirically shown to significantly improve the runtime and accuracy of neuro-symbolic methods. The presented framework will probably be a starting point for various potential future applications."
            },
            "weaknesses": {
                "value": "My main critique of this paper is that the presentation is in parts not very clear, especially in Section 4. Notation is not always properly defined (e.g. the prox operator), dependencies are omitted without explicitly mentioning it (e.g. in the definition of the value function), or important parts are left out of the main text (e.g. how the the dual variables in equation 10 are updated or how the Moreau envelope of the energy function is computed). See questions for additional parts that were unclear to me."
            },
            "questions": {
                "value": "- If I understand correctly, the Algorithm 1 requires computing both the Value function and the Moreau envelope at each iteration. Both require minimization over $y$, so in the case of NeuPSL are these both computed using the BCD algorithm in section 5? I.e., is the $\\epsilon$ smoothening in equation 13 the same as the $\\frac{1}{\\rho}$ smoothening term in equation 8? In any case, I would recommend highlighting more explicitly how exactly Section 5 links into Section 4.\n- At the end of Section 5.1, the authors mention that mapping primal variables to dual variables requires calculating a pseudo-inverse of the matrix A. Is this at any point required in the proposed learning algorithm? If yes, is it described anywhere?\n- Are the authors aware of previous work using Moreau envelopes in the context of neuro-symbolic or structure learning with non-differentiable settings? Such links would be a useful addition to the related work. Otherwise, if this has not been used before, the novelty of this contribution could also be highlighted more.\n- One of the mentioned key contributions is that the \"dual BCD algorithm for NeuPSL inference [...] naturally produces statistics necessary for learning gradients\". I don't undertand this statement, how are the statistics in the BCD algorithm necessary for \"learning\" gradients? Do you mean they help in computing the gradients required for the NeSy learning algorithm?\n\nRemarks:\n- After equation 7: \"The formulation in (7) is referred to as a value-function approach in bilevel optimization literature.\" Citations would be great here.\n- In section 5.1, the vector $b$ seems to be an affine function in the neural predictions and symbolic inputs rather than linear."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5927/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698637597712,
        "cdate": 1698637597712,
        "tmdate": 1699636630637,
        "mdate": 1699636630637,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1XhJni65VG",
        "forum": "uJPWeZffgl",
        "replyto": "uJPWeZffgl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5927/Reviewer_Zeyx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5927/Reviewer_Zeyx"
        ],
        "content": {
            "summary": {
                "value": "I am not sure why I got assigned this paper, which focuses on neuro-symbolic methods and is therefore fairly far away from my area of expertise. I feel only partially qualified to review it: I don't believe I bid on this paper, but if I did, this was certainly a misclick. While I am very familiar with optimization, I don't know much about neuro-symbolic methods, and this review will reflect that, but I will still do my best. I am very open to changing my mind about this paper based on feedback from the authors and other reviewers on what to direct my attention towards.\n\nThe authors study how to fuse symbolic processing with neural networks. They start with a bilevel optimization problem for neuro-symbolic learning, reformulate it as a constrained optimization problem with certain inequality-based constraints, then propose a smoothed variant of said constraints which replaces a certain energy-function with its Moreau envelope. This problem is optimized using an augmented-Lagrangian-based algorithm. The authors apply this approach to a neural probablistic soft logic model, and study optimization-theoretic properties of the resulting objective. The authors benchmark their approach on certain models, mainly against ADMM, and show that their technique performs much better in some cases."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The proposed algorithm is shown to perform significantly on a number of benchmarks compared to ADMM. This makes sense, as the authors' method is specialized to their setting, whereas ADMM is generic. \n\nThe convex-optimization-based aspects seem reasonably well-thought-out. There are a lot of choices that one could make here, and the authors' choices seem reasonable.\n\nThe paper is reasonably well-written, though at times not easy to parse for someone outside the area. \n\nI am very interested in what the other reviewers, who will likely know much more about this area than me, will have to say, as their reviews are likely to help direct me to what are the most important parts of the work I should direct attention to, and will update my thoughts and edit my review accordingly once the time comes."
            },
            "weaknesses": {
                "value": "Way too many acronyms. I had trouble remembering what half of them stood for once I got far enough away from their definitions. This paper goes so far in the direction of using acronyms for everything, that I strongly recommend the authors go into the other extreme and remove *all* acronyms, since doing this will make the paper easier to read.\n\nVery little seems to actually happen in Section 2. The paper would be improved by reviewing some of the technical points in more detail, otherwise the description is so high-level that it is almost meaningless. In particular, the differences between implicit-differentiation-based methods and value-function approaches are not sufficiently explained, and are not clear to me even though I know exactly how to differentiate through an optimization problem using envelope theorems and similar. This is much more background than many readers will have, so if I'm confused, chances are most people will be. Please see questions.\n\nThe main technical sections are notation-heavy, and are quite complex to read. Theorem 5.3 in particular is somewhat hard-to-parse and takes a third of a page, in total, to state, even though its first main claim is a simply saying that a certain objective is convex-concave, and the other claims are also relatively simple.\n\nThe evaluation is purely quantitative: the authors show better numbers on tables compared to alternatives. While this is a valid way to evaluate, it also gives a much weaker idea of what is going on compared to evaluations that are not table-based and consider factors other than performance metrics. Nothing I saw in the experimental section rules out a situation of the form \"none of the algorithms work, but the authors' is slightly less broken\" - I would like to see some evidence that this isn't the case. \n* I've previously seen misleading results like this in reinforcement learning papers where an agent achieved \"good performance\" through random actions that were slightly-more-aligned with the objective compared to baselines, but was so far from correct behavior that most people would reasonably view both the method and the baselines as equally bad, and the differences in metrics as meaningless. In total, how do we know the neuro-symbolic system is performing as it should in this setting?"
            },
            "questions": {
                "value": "I do not understand the described difference between implicit-differentiation-based methods and value-function approaches. \n* Is a value-function approach one where the lower-level objective is solved either analytically or to convergence, after which one applies a suitable envelope theorem approach to calculate the gradient of the objective using the optimal value?\n* In contrast, is an implicit-differentiation approach one where we do not solve the inner optimization problem to convergence? Or am I completely confused by what you mean by this distinction here?\n\nWhy is the constraint in (7) an inequality constraint, rather than an equality constraint? The paragraph directly after it mentions an equality constraint. Is this a typo?\n\nIs there a way to evaluate the performance of the resulting neuro-symbolic system qualitatively, to ensure it behaves in the manner that the algorithmic designer expects it does? Is there some kind of sanity check one could do to guard against the \"all the methods fail at the given task, but ours fails with slightly better numbers\" potential failure mode? While I certainly have no direct evidence that this is happening, it would make me feel much better about the paper if this could be definitively ruled out via the experiments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5927/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698727033975,
        "cdate": 1698727033975,
        "tmdate": 1699636630520,
        "mdate": 1699636630520,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0dpW8Br74H",
        "forum": "uJPWeZffgl",
        "replyto": "uJPWeZffgl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5927/Reviewer_oqJp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5927/Reviewer_oqJp"
        ],
        "content": {
            "summary": {
                "value": "The authors give an equivalent formulation of NeSy EBMs learning as a bilevel problem. Such formulation allows smooth first-order optimization."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The writing of the paper makes it very hard to identify many strengths. It is my understanding, however, that by operating at the level of NeSy EBMs, any advancement applies to (potentially) a broad class of neuro-symbolic methods."
            },
            "weaknesses": {
                "value": "- The paper is a neuro-symbolic AI approach for learning and inference with barely any mention of previous related work in the field [1, 2, 3, 4, 5, 6, ..].\n\n- The paper is **very** hard to read with not a single figure or running example to help with the exposition.\n\n- Empirical evaluation is only carried out on toy datasets, using very basic tasks (e.g. MNIST-addition is evaluated only using $2$ digits, which can be easily solved using existing baselines), and the numbers are presented with no extra commentary/analysis.\n\nReferences: \n\n[1] Semantic Probabilistic Layers for Neuro-Symbolic Learning. Kareem Ahmed, Stefano Teso, Kai-Wei Chang, Guy Van den Broeck, Antonio Vergari. NeurIPS 2022.\n\n[2] A Semantic Loss Function for Deep Learning with Symbolic Knowledge. Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van den Broeck. ICML 2018.\n\n[3] Semantic Strengthening of Neuro-Symbolic Learning. Kareem Ahmed, Kai-Wei Chang, Guy Van den Broeck. AISTATS 2023.\n\n[4] Neuro-Symbolic Entropy Regularization. Kareem Ahmed, Eric Wang, Kai-Wei Chang, Guy Van den Broeck. UAI 2022.\n\n[5] Coherent Hierarchical Multi\u2212Label Classification Networks. Eleonora Giunchiglia and Thomas Lukasiewicz. NeurIPS 2022.\n\n[6] Deep Learning with Logical Constraints. Eleonora Giunchiglia\u201a Mihaela Catalina Stoian and Thomas Lukasiewicz. IJCAI 2022."
            },
            "questions": {
                "value": "- I'm struggling to understand what the problem being solved here is exactly. The second paragraph in the introduction mentions that \"the predictions are not guaranteed to have an analytical form or be differentiable, and traditional deep learning techniques are not directly applicable\", could you please say more about that? All the NeSy AI techniques that I am aware of: semantic loss, deepproblog, NeSy entropy, semantic strengthening, semantic probabilistic layers, neupsl, etc... are able to train the models end-to-end using back-propagation.'\n\n- As a follow-up question: why should we be interested in developing this equivalent formulation as a bilevel problem? What could one possibly gain that improves upon the exact inference proposed in semantic loss, deepproblog, NeSy entropy and  semantic probabilistic layers?\n\n- I am struggling to understand the results obtained on MNIST-addition. How can it be that NeuPSL, which is approximate, can outperform DeepProbLog which performs exact inference?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5927/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698878719844,
        "cdate": 1698878719844,
        "tmdate": 1699636630425,
        "mdate": 1699636630425,
        "license": "CC BY 4.0",
        "version": 2
    }
]