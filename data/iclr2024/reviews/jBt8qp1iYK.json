[
    {
        "id": "n1D0GdSEER",
        "forum": "jBt8qp1iYK",
        "replyto": "jBt8qp1iYK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission363/Reviewer_q4FE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission363/Reviewer_q4FE"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a family of submodular combinatorial objectives for representation learning tasks through the submodular combinatorial representation learning framework to overcome class imbalance in real-world vision tasks. The authors conduct experiments on two benchmark datasets to show the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper is well-written and easy to read.\n2. The performance seems good compared with other approaches."
            },
            "weaknesses": {
                "value": "1. The novelty is unclear. The method part only lists some existing metric learning losses.\n2. The proposed framework is called the Submodular Combinatorial Representation learning framework. What does Combinatorial mean? It is unclear what the framework looks like since there are only some metric learning loss functions in the method part.\n3. The authors do not compare with the recent state-of-the-art method since the latest method in Table 2 is in 2020."
            },
            "questions": {
                "value": "see the weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission363/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698667195455,
        "cdate": 1698667195455,
        "tmdate": 1699635963505,
        "mdate": 1699635963505,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XmgbU5JJpY",
        "forum": "jBt8qp1iYK",
        "replyto": "jBt8qp1iYK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission363/Reviewer_KzrN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission363/Reviewer_KzrN"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on improving the way deep learning models handle imbalanced class scenarios in real-world applications. In such situations, where some classes are rare, conventional neural networks struggle to learn useful features. This leads to a significant imbalance between rare and abundant classes in the data. To address this, the paper introduces the SCoRe framework, which utilizes Submodular Combinatorial Loss functions. These functions can effectively model feature diversity and cooperation among classes. Experimental results on image classification tasks, including imbalanced datasets like CIFAR-10 and object detection tasks, show that the proposed approach outperforms existing metric learning methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper introduces a new approach to tackle the challenge of class-imbalanced data in deep learning, which is a critical problem in real-world applications.  \n\n- This paper is generally easy to follow."
            },
            "weaknesses": {
                "value": "- Unclear Link Between Diversity and Robust Representations: While the paper's motivation to employ submodular functions as loss functions to promote diversity is evident, the direct connection between diversity and the creation of robust representations from imbalanced datasets remains somewhat ambiguous. The paper does not clearly elucidate how fostering diversity contributes to the development of robust representations in such scenarios.\n\n- Limited Experimental Evidence: The experimental results exhibit certain weaknesses:\na) The paper compares its approach with well-known metric learning methods but does not utilize popular metric learning datasets, which could potentially limit the generalizability of the findings.\nb) All experiments are conducted on relatively small datasets, as opposed to widely recognized datasets commonly used in imbalanced classification, such as ImageNet-LT. This choice of datasets might limit the broader applicability and relevance of the research."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission363/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698675408948,
        "cdate": 1698675408948,
        "tmdate": 1699635963415,
        "mdate": 1699635963415,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SuZHx6knZs",
        "forum": "jBt8qp1iYK",
        "replyto": "jBt8qp1iYK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission363/Reviewer_zWRY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission363/Reviewer_zWRY"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses class imbalance problem in real world for representation learning tasks.\nFor this purpose, a SCoRe framework and a family of Submodular Combinatorial objectives are proposed to overcome lack of diversity in visual and structural features for rare classes.\nPerformance evaluation is conducted on two image classification benchmarks (pathologically imbalanced CIFAR-10, subsets of MedMNIST) and a real-world road object detection benchmark (India Driving Dataset ). The newly introduced objectives like Facility Location, Graph-Cut \nand Log Determinant can boost the large performance when compared with state-of-the-art metric learners."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The class-imbalance is a challenging problem, and the illustration of motivation is clear. The effect of class-imbalance on the performance metrics (mAP50) is shown for the object detection task of the IDD.\n+ It seems novel by studying metric learners from an assemblage perspective, treating class-specific feature vectors as sets. \n+ There are some useful conclusions, e.g., the submodule combinatorial objective can construct more distinguishable clustering features for representation learning. At the same time, the derivation proves that the existing contrastive learning objectives are either submodular or can be reformulated as submodular functions.\n+ Three novel objective functions: Facility-Location (FL), Graph-Cut (GC), and Log Determinant (LogDet).\n+ Sufficient experiments on datasets with different degrees of class imbalance for different tasks (image classification and image detection), compared to SoTA metric/contrast learners, indicate the importance of combinatorial loss functions."
            },
            "weaknesses": {
                "value": "- This paper shows comparative analysis related to metric learning and contrastive learning, without focusing on class imbalance issues. Missing some latest methods in Related Work.\n- As far as I know, there are various methods available to address class imbalance or long-tail problems, such as focal loss, WPLoss, OHEM, data augmentation... What are the differences between SCoRe and these methods? And there are no comparative experiments with these methods.\n- The formulas/symbols in the paper are unclear and lack more explanation.\nFor instance, 'f' is used to denote both the feature extractor and the submodular function; 'S' is utilized to represent both similarity kernels and total submodular information.\n- There are minor writing errors, particularly related to subscript issues, concentrated in Section 3.1. For example, Sij(\\theta) , yii=1,2,...|T |."
            },
            "questions": {
                "value": "- The class imbalance issue may be more pronounced in some other object detection datasets such as the MS COCO[1] or the LVIS[2] which is dedicated to long-tailed object detection. We are looking forward to see some results on them.\n- How does SCoRe solve the localization/regression problem in object detection tasks under the class-imbalanced settings?\n- Can you provide a detailed explanation of equation (1), as well as the distinction between Total Submodular Information and Total Submodular Correlation?\n- Can you provide a visualization of the class distribution in the CIFAR-10 dataset or other dataset?\n- Will codes be released in the future?\n [1] Microsoft COCO: Common Objects in Context. ECCV, 2014. [2] LVIS: A Dataset for Large Vocabulary Instance Segmentation. CVPR, 2019."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission363/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698721131836,
        "cdate": 1698721131836,
        "tmdate": 1699635963332,
        "mdate": 1699635963332,
        "license": "CC BY 4.0",
        "version": 2
    }
]