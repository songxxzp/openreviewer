[
    {
        "id": "n1S83NqA4y",
        "forum": "fHZ04oyEed",
        "replyto": "fHZ04oyEed",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3823/Reviewer_WWQo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3823/Reviewer_WWQo"
        ],
        "content": {
            "summary": {
                "value": "This paper first introduces a problem where the data is a mixture of observational and interventional data. The authors proposed a method that can limit the dependency between variables for interventional data based on NHSIC measure. Experiments demonstrate superior performance against current methods on synthetic datasets and other tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Many case studies and examples are given to motivate the problem, and the results are clearly presented. The RepLin method seems to be a novel use of the NHSIC dependence measure. There are a lot of experiments spanning a variety of tasks including robustness to image corruption, which is very interesting. All experimental results demonstrated superior performance against benchmarks."
            },
            "weaknesses": {
                "value": "It seems that RepLin algorithm assumes knowledge of which datapoint is interventional, whereas the ERM and other methods do not use this assumption. ERM-Resampled uses that knowledge, but not as directly as RepLin. However, experimental comparisons with ERM-Resampled is absent. In Section 3, it is unclear what the author(s) are trying to discuss, especially the phrase \u201cit is advisable to remove spurious information from the representations entirely\u201d. The title of the paper is about representation learning, but the paper evaluates the quality of the representation only via a single downstream task, making the problem more like supervised learning."
            },
            "questions": {
                "value": "- What is the test dataset for the problem in Figure 3? If in Figure 3(b) the test is on the full support, then it is a significantly harder problem then Figure 3(a), making the motivation unclear.\n- Why is there no comparison between RepLin and ERM-Resampled?\n- Does the method work when there are more than two features that directly affect X?  What about when the intervention is on two variables?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Reviewer_WWQo"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3823/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698679965247,
        "cdate": 1698679965247,
        "tmdate": 1699636339928,
        "mdate": 1699636339928,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "81C15RB3WJ",
        "forum": "fHZ04oyEed",
        "replyto": "fHZ04oyEed",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3823/Reviewer_XFMF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3823/Reviewer_XFMF"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of representation learning under distribution shift. Specifically, the paper considers the setting where the data generating process is described by a causal DAG, and the learner is able to observe both observational data and data generated by a specific, known intervention. The paper shows that on a toy example, both ERM and a resampled-version of ERM fail to generalize when given a large amount of observational data but only a small amount of interventional data. The paper uses this example to motivate their representation learning approach which, in addition to minimizing predictive error, also seeks to minimize a statistical dependency measure between features that are known to be independent on the observational data. The paper then goes on to compare their method against ERM and the resampled version of ERM on a synthetic toy dataset and an image classification dataset where smiling and gender have been subsampled to induce dependence. The paper also compares against ERM and fine-tuning on an ImageNet subset where noise is added to correlate with certain labels. On all experiments, the paper shows that their method leads to improvement over the baselines."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper considers an important area of study: learning under distribution shift. The paper distills the particular type of distribution shift that they interested in into an easily understood model, and illustrates the issue with common heuristics in addressing this problem on a toy example. Finally, the paper considers both toy and realistic data in their experiments."
            },
            "weaknesses": {
                "value": "The paper has a few weaknesses that should be addressed.\n\n1. It is unclear exactly where the dependency and self-dependency losses come from. In particular, they seem to be only heuristically motivated, and it's unclear what minimizers of this loss should look like. Why should the \"self-dependence loss\" prevent the model from learning only irrelevant features, and how do we know that this is the right loss to do so? A rigorous mathematical treatment of the proposed loss would be very helpful here.\n\n2. The paper only considers ERM-based baselines. The field of domain generalization is currently rich with approaches to problems that subsume the current work, but this paper does not compare against any of those. E.g., invariant risk minimization is one approach to domain generalization that would seem to easily apply to the present problem.\n\n3. The paper doesn't really motivate the problem setting. It's not clear to me when we would be in a setting where (a) we know the true causal DAG, (b) we get to observe interventional data, and (c) we want to learn representations of our data for some downstream purpose, e.g. prediction in this setting."
            },
            "questions": {
                "value": "Building on the weaknesses I pointed out above:\n\n1. Can you show that minimizing the RepLin loss leads to provably optimal properties for the minimizing function?\n\n2. Can you justify why you did not compare against methods from domain generalization?\n\n3. Can you present a concrete setting that motivates the paper setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Reviewer_XFMF"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3823/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698696432108,
        "cdate": 1698696432108,
        "tmdate": 1699636339846,
        "mdate": 1699636339846,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mR4n7ISKHn",
        "forum": "fHZ04oyEed",
        "replyto": "fHZ04oyEed",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3823/Reviewer_Uyzd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3823/Reviewer_Uyzd"
        ],
        "content": {
            "summary": {
                "value": "The paper considers the problem of prediction under distribution shifts as a result of interventions on one of the label and proposes an approach inspired by the conditional independence in the intervened graph. The authors consider a setup with multiple labels with causal relationships between the labels, and known hard-interventions that act on one of the labels to remove its dependence from other relevant labels. The proposed approach enforces statistical independence between intervened labels and their parent labels in the original graph; and highlights its benefits over several baselines like reweighting, classifier fine-tuning, etc. on multiple benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "* The claims made in the paper are supported by rigorous experimentation over multiple synthetic, semi-synthetic, and realistic benchmarks. Further, the authors also compare with important baselines of reweighting, classifier fine-tuning, pre-training, etc.\n\n* The paper is well-written with good motivation for the proposed approach using synthetic benchmarks, and the presentation of the results is clear and well-organized.\n\n* The proposed approach uses loss objectives from prior work to enforce independence between features with minor modifications, though the application for the task of multi-label prediction with interventions is novel."
            },
            "weaknesses": {
                "value": "* My major concern with the work is that the technical contribution of the work is weak since the problem setup is very simple. The authors assume they know exactly the label that has been intervened and its non-descendants, which makes the proposed approach a simple application of the d-separation criteria in causal graphs. In contrast, the common setups in OOD generalization involving distribution shifts [1, 2] do not assume that we observe the intervened variables (and their causes) explicitly. \n\n* I appreciate the rigorous experimentation in the work, however, the significance of the results is highly limited as the application of d-separation criteria in the intervened graph with known variables and causal relationships is supposed to work. Further, the experiments on the corrupted CIFAR and ImageNet require the knowledge of corruption labels, which would simplify the problem. \n\nReferences:\n\n[1] Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.\narXiv preprint arXiv:1907.02893, 2019\n\n[2] Polina Kirichenko, Pavel Izmailov, and Andrew Gordon Wilson. Last layer re-training is sufficient\nfor robustness to spurious correlations. arXiv preprint arXiv:2204.02937, 2022"
            },
            "questions": {
                "value": "My suggestion to the authors is to consider the case with unknown causal relationships and intervened nodes, as that is a more practical and challenging setup. I understand that would require substantial efforts with a completely different approach in principle to solve the problem, but I am interested in hearing the thoughts of the authors regarding this point.\n\nMinor points:\n\n* The description of the prior work Ahuja et al. (2022) in the learning using interventional data section is incorrect. Their work is not limited to independent latent factors, rather they allowed for general causal relationships between the latents."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Reviewer_Uyzd"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3823/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793222902,
        "cdate": 1698793222902,
        "tmdate": 1699636339755,
        "mdate": 1699636339755,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FPwTU83AoS",
        "forum": "fHZ04oyEed",
        "replyto": "fHZ04oyEed",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3823/Reviewer_Pdav"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3823/Reviewer_Pdav"
        ],
        "content": {
            "summary": {
                "value": "In this work the authors propose the RepLIn method for representation learning that aims to be more robust under distribution shift obtained via a perfect intervention on a single feature. For a model that has a causal data generating process, standard techniques like ERM propose to learn the generative process and the recent field of causal representation learning has brought along an array of sophisticated tools to handle this. In general, when the data generating process is modified by a hard intervention on a causal variable, this brings a distribution shift and the learned representations are not robust. The authors propose to modify the loss function of representation learning methods using their regularization term to handle such issues.\n\nInitial experiments on the windmill datasets (with 2 causal variables) suggest that there is a correlation between accuracy drop on interventional data and independence of the features corresponding to the intervened variable. This situation is somewhat mitigated by using additional interventional data. However, the authors propose a different fix which is to define a modified regularization term that aims to minimize the dependence between features on interventional data. To avoid pathological feature learning, an additional regularization term is added. The authors call this the RepLIn method.\n\nThey validate their observation of correlation on the windmill dataset. Experiments on CelebA dataset (using the causal variables smile and gender) show that RepLIn is more robust than the baseline algorithms by 2%. Additional experiments on 3-variable causal data generating process is also shown on label prediction. These experiments weakly validate the method and suggest that spurious correlations are mitigated.\n\n### References:\n\n- [1] Interventional causal representation learning.\n\n- [2] Learning Linear Causal Representations from Interventions under General Nonlinear Mixing"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The statistical correlation between drop in representation learning accuracy and independence of the causal covariates is a nice observation. Retrospectively, it's not surprising considering the data generating process but the authors suggest to exploit this via explicit regularization.\n\n- Experiments show that the proposed method RepLIn can beat methods such as classifier fine-tuning to handle distribution shift on various image datasets."
            },
            "weaknesses": {
                "value": "- The kind of distribution shift considered, i.e. hard perfect interventions on causal features, maybe too restrictive for real-life applications. In fact, IRM aims to be as general as possible, unfortunately at the overhead of significant additional complexity. Therefore, this model loses this generality.\n\n- Related to the above, even if we have weak dependence among the causal variables after intervention, the proposed regularization method will still be feasilbe to apply, but it's not clear how much the hyperparameter tuning will be needed in the experiments. Could the authors comment on this?\n\n- The authors should have a detailed discussion on the array of 10+ works on causal representation learning from interventional data, e.g. [1], [2] (see also related works section in [2] which contains a wide list of such works). I'm surprised the authors seem unaware of this very closely related line of work.\n\n- Related to the above point, while the authors compare to IRM in app. F and highlight the differences, I feel like the works on causal representation learning are more apt to contrast with, due to various modeling assumptions."
            },
            "questions": {
                "value": "Some questions were raised above.\n\n- The authors consider perfect interventions. How robust are their methods to imperfect or soft interventions (with the usual meanings from the causal literature)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3823/Reviewer_Pdav",
                    "ICLR.cc/2024/Conference/Submission3823/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3823/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698804739324,
        "cdate": 1698804739324,
        "tmdate": 1700543191429,
        "mdate": 1700543191429,
        "license": "CC BY 4.0",
        "version": 2
    }
]