[
    {
        "id": "RvzT6IDLLh",
        "forum": "ZrY38sUYWs",
        "replyto": "ZrY38sUYWs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5135/Reviewer_NfBj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5135/Reviewer_NfBj"
        ],
        "content": {
            "summary": {
                "value": "This paper propose two methods to increase OOD performance:\n(1) a score function called Feature Sim (FC), which is the mean absolute deviation of feature maps.This rely on the assumption that the activation difference between the foreground and background of the ID data is larger than OOD data.\n(2) a Threshold Activation (TA) module which is a shifted ReLU applied on the feature maps, the underlying assumption is that ID features have higher activations and significant foreground component than OOD feature.\nCombining FS and TA with ASH gives state-of-the-art results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. FS measures the mean of the channel-wise deviation of the feature map: The underlying assumption of the FS is \"The activation of the network for ID data is usually concentrated in the foreground (salient area), while the activation difference between foreground and background (other areas) in OOD features is not as significant.\" the author models this separation using GMM and provide in-depth theoretical analysis.\n\n2. TA module enlarge the distance between ID and OOD data by weaking the lower part of the activations. \n\n3. FS+TA+ ASH achieves state-of-the-art result and the author also provided comprehensive experiments on various dataset."
            },
            "weaknesses": {
                "value": "(1) The GMM assumption, as illustrated in Figure 3 also C.2, relies on the fact that ID has object, while OOD data has only background. However, this is not clearly defined in the ID and OOD data definition. In fact, for near OOD task, ID and OOD data both contain objects. (e.g. ImageNet vs. SSB-hard, MINIST vs. CIFAR). \n\n(2) The author should provide more details on the hyperparameter $\\labmda$ for Section 5.3. For example, how to choose it? In the experiments, is it chosen by validating on validation dataset or testing dataset? Is there any ablation on this factor?\n\n(3) Although the author shows state-of-the-art results combing FS and TA with ASH (+energy score), this treats FS and TA as orthogonal methods with ASH and Energy Score. However this is not true, as FS is an OOD scores and TA is a model rectification technique, the author should compare them separately and directly with their opponents.\n- compare FS with other OOD score function: Energy, MLS, MSP.\n- compare TA with other post-hoc model rectification technique: ReAct, DICE, ASH"
            },
            "questions": {
                "value": "Regarding FS:\n\n(1) For Eq.4, what is the GAP operator?\n\n(2) FS measures the mean of the channel-wise deviation of the feature map, what is the intuition for this design? What is the difference if using the deviation of the feature map?\n\nRegarding TA:\n\n(3) The design of TA is opposite to ReAct, how this leads to the same outcome (distancing ID and OOD data) while the changes are opposite to ReAct?\n\n(4) For the choices of the stage to apply TA and FS, are they validated directly in the testing dataset?\n\nI am willing to raise my score if the author can address the above issues."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Reviewer_NfBj"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5135/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698455435138,
        "cdate": 1698455435138,
        "tmdate": 1699636506761,
        "mdate": 1699636506761,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uvugxqUZyP",
        "forum": "ZrY38sUYWs",
        "replyto": "ZrY38sUYWs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5135/Reviewer_gmH7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5135/Reviewer_gmH7"
        ],
        "content": {
            "summary": {
                "value": "The authors propose one simple yet effective method Feature Sim (FS) and one plug-in module Threshold Activation (TA). Experiments demonstrate their method can achieve good performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper is well written, and the concept of \"foreground\" and \"background\u201d is interesting. The experiments are comprehensive, and the results are promising."
            },
            "weaknesses": {
                "value": "1)\tIn Figure 1 and Figure 6, the authors give the feature visualization of ResNet50 (perhaps using the last layer, as claimed in Appendix C.1). However, as far as I know, in ResNet, each layer has a multitude of feature maps. Especially in the middle layers, most feature visualizations on the feature maps can\u2019t be directly to be utilized for visualization. The patterns FS utilizes maybe like ReAct, leveraging abnormally high activations. Could the authors provide clarification about this?\n2)\tFeature Sim Score essentially quantifies the data dispersion (like variance) on each feature map. It is more like utilizing extreme values on intermediate feature layers, a concept that has been extensively explored by previous feature-based methods. Could the authors clarify the difference?\n3)\tThreshold Activation appears to borrow the concept from ReAct and apply it to intermediate layers. Could the authors clarify the novelty of TA?"
            },
            "questions": {
                "value": "Shown in Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Reviewer_gmH7"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5135/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698659024995,
        "cdate": 1698659024995,
        "tmdate": 1700814830354,
        "mdate": 1700814830354,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YzbsqYTxCf",
        "forum": "ZrY38sUYWs",
        "replyto": "ZrY38sUYWs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5135/Reviewer_sGRf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5135/Reviewer_sGRf"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new perspective to utilize the feature maps for OOD detection. A Feature Similarity score function, which is defined as the absolute difference between the feature map and its mean value, is proposed to distinguish the ID and OOD data. Besides, a Threshold Activation module is introduced to increase the feature separability between ID and OOD data. The performance of the proposal looks good."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The motivation is clear and the whole method makes sense. \n2.  The method is simple and extensive experiments are performed to demonstrate the effectiveness of the proposal. \n3.  The method can collaborate well with previous post-hoc methods, and FS+TA+ASH can achieve state-of-the-art on various OOD detection benchmarks."
            },
            "weaknesses": {
                "value": "1. After Eq.3 \u201cFeature Sim measures the self-similarity of the feature maps, whose core idea is to compare the activation differences between foreground and background on the ID and OOD feature maps\u201d, It is a little bit confused why Feature Sim compares the activation differences between foreground and background on the ID and OOD feature. More explanations should be provided.\n2. \"Eq. (2) is equivalent to the GAP operator\". Actually, Eq. 2 is not a GAP operator, GAP performs global pooling in the feature map, whereas Eq. 2 performs pooling across different channels.\n3. In section A.1, the authors train the ResNet50 from scratch, while other comparison methods (Energy, ReAct, DICE ect.) use the off-the-shelf ResNet model for experiments. Therefore, the comparisons might be unfair, I recommend the author to utilize the off-the-shelf model.\n4. The Threshold Activation module is quite similar to ReAct and ASH, which makes the novelty of the introduced TA module limited. Besides, the TA module decreases the ID classification accuracy significantly, even it can be remedied by using another classification branch."
            },
            "questions": {
                "value": "1. It is not clear why employ the absolute difference between the feature map and its mean value as OOD score. Have the authors considered to use the mean value of Gram Matrix as the similarity score, which I think should be better than the absolute difference. The Gram Matrix captures the similarity between different feature maps [1]. \n\n[1] Image Style Transfer Using Convolutional Neural Networks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5135/Reviewer_sGRf"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5135/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698721632721,
        "cdate": 1698721632721,
        "tmdate": 1700654367955,
        "mdate": 1700654367955,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gGbBWzypwP",
        "forum": "ZrY38sUYWs",
        "replyto": "ZrY38sUYWs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5135/Reviewer_gWG8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5135/Reviewer_gWG8"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a post-hoc method for out-of-distribution detection. The authors observe that ID data is more robust than OOD data and the gap between foreground and background features is more prominent. Based on these observations, the authors propose a new OOD score function based on the spatial feature maps, and a threshold activation technique to further boost the performance. Experiments are conducted on various OOD detection benchmarks and some results are appealing."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method is simple and easy to implement.\n2. The authors conduct comprehensive experiments to evaluate the method.\n3. The method achieves state-of-the-art results when combined with other techniques."
            },
            "weaknesses": {
                "value": "1. he method claims to leverage spatial clues in the feature maps. However, no spatial information is actually used in the final OOD score calculation (cf. Eq. (3)). \n\n2. The method is mainly based on the observation that the activation difference between foreground and background is more prominent for ID data. However, the generalizability of this observation remains unverified. Notably, most of the visualizations of OOD data in Figure 6 display small foreground objects, which calls into question the applicability of this method to a broader range of OOD scenarios.\n\n3. The theoretical analysis of the method assumes that the features of foreground and background follow two Gaussian distributions. This is a strong assumption that may not hold in realistic settings.\n\n4. As indicated in Table 1, this method requires integration with other OOD detection techniques to achieve state-of-the-art results. This raises two concerns: Firstly, combining different OOD functions could understandably lead to a performance boost, making it unclear how much of the improvement is attributable to the proposed method itself. Secondly, the aggregation parameters appear to require meticulous tuning, as shown in Appendix A.1, which casts doubt on the method's ease of use in real-world applications.\n\n5. The paper claims that the proposed method is adaptable to other tasks such as semantic segmentation and object detection. However, the experimental setup is puzzling. The method appears to focus on distinguishing between image-level ID and OOD, which deviates from these standard tasks, such as OOD segmentation [1]. Besides, it remains unclear the unique advantages of this method in these application areas.  For example, one could easily use a simple average of existing pixel-wise OOD scores as the image-level OOD score for the segmentation task.  There are no comparisons with any baseline methods in Table 6. \n\n[1] Chan Robin, et al. Segmentmeifyoucan: A benchmark for anomaly segmentation. NeurIPS, 2021."
            },
            "questions": {
                "value": "See detailed comments/concerns above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5135/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698819527811,
        "cdate": 1698819527811,
        "tmdate": 1699636506449,
        "mdate": 1699636506449,
        "license": "CC BY 4.0",
        "version": 2
    }
]