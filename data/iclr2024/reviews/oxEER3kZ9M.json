[
    {
        "id": "9zofG5ezim",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6790/Reviewer_6pNs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6790/Reviewer_6pNs"
        ],
        "forum": "oxEER3kZ9M",
        "replyto": "oxEER3kZ9M",
        "content": {
            "summary": {
                "value": "This paper presents a theoretical and empirical analysis of the feasibility of AI-generated text detection as LLMs become more powerful. Overall, the paper shows that even with the most powerful LLMs, AI-generated text detection will always feasible with enough samples / long-enough generated sequences.\n\nAs some background, Sadasivan et al. 2023 [1] recently showed in their work that AI-generated text detection performance is fundamentally bounded by the total variation norm between human-written and machine-generated text. Sadasivan et al. 2023 hypothesize that as LLMs become stronger, this variation will reduce, eventually making AI-generated text impossible.\n\nThis paper builds on the theoretical analysis of Sadasivan et al. 2023, but instead includes the *number of available AI-generated / human-written samples* into their proof. The paper argues that in many real-life scenarios (like AI Twitter bot detection), it is always possible to access multiple samples of AI-generated text. The paper finds that the bound on AI-generated text detection performance exponentially increases with the number of samples. The paper also provides an equation to obtain the required number of samples to achieve a particular AU-ROC score.\n\nThe paper further supports the theoretical results with several empirical experiments, showing that AI-generated text can be better detected with more samples or with longer sequences. The experiments include 4 datasets and evaluate 5 different LLMs with classification-based detection methods.\n\n[1] - https://arxiv.org/abs/2303.11156"
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Given the growing risk of plagiarism in college essays and the spread of misinformation using large language models, the topic of the paper is timely and very important.\n\n2. The paper presents an optimistic theoretical take on the feasibility AI-generated text detection, and in a sense, their proof conflicts with the impossibility result of Sadasivan et al. 2023. This proof is a good motivation for researchers to continue working on AI-generated text detection, despite the fear of LLMs approach human performance.\n\n3. The paper provides the exact theoretical bounds on AU-ROC performance, measures its tightness, and provides an equation to derive the required samples for a desired AU-ROC performance (however, also see weakness #1 on how this could be more practical).\n\n4. The paper supports their theoretical analysis with comprehensive experimental results, showcasing the benefit of longer sequences and more samples in 4 datasets and with 5 large language models.\n\n5. The paper is well written and a fair amount of intuition is added before/after the theoretical analysis to make it more accessible to a general audience."
            },
            "weaknesses": {
                "value": "Overall, I liked the sentiment in the paper and thought the theoretical and empirical analysis was thorough. While I am leaning accept, I had some concerns about the real-world takeaways from the work, and would love to hear the author's thoughts on it (please let me know if this was mentioned somewhere in the paper or appendix and I missed it!).\n\n1. The theoretical analysis in the paper has a nice overall takeaway, but I am not sure how helpful the bounds are for practioners who are developing these algorithms / trying to detect AI-generated text. Specifically,\n\n* How does one go about computing the variation between machine-generated text and human-written text (`TV(m,h)^n`) for some SoTA LLMs like ChatGPT or GPT4, perhaps in a restricted domain? This is needed in both proposition 1 (for AU-ROC upperbound calculation), and in Theorem 1 (for sample estimation). I wonder if the authors could walkthrough an example in their paper: calculate `TV(m,h)^n` for ChatGPT for different output lengths, and then provide the corresponding upperbounds for AU-ROC for different values of the output length. I wonder if the method used in the MAUVE text evaluation paper (https://arxiv.org/abs/2102.01454) may be helpful for this calculation, who propose a clever approximation for measuring the divergence between human/machine-written text.\n\n* Is it possible to derive a bound on the true-positive rate (TPR) for a fixed false-positive rate (FPR), instead of a bound on AU-ROC? This may be a more practical metric, since practioners will want to optimize TPR for a fixed low FPR.\n\n2. I feel like the authors are under-selling themselves in the title/abstract/introduction, by focusing on the \"number of samples\" rather than \"sequence length\". Overall, I think in many AI-generated text detection scenarios only 1 sample will be available (like essay plagiarism detection, fake news detection). However, these individual samples are likely to have multiple sentences (or even paragraphs) in them. Moreover, the general empirical consensus seems to be that longer AI-generated sequences are easier to detect (https://arxiv.org/pdf/2306.04634.pdf). Does a multi-sentence output result in `n > 1` in the author's theoretical analysis? I am suspecting this is true, since a number of empirical experiments iterate on the output length rather than the number of samples. If feasible, I recommend the authors to make output length the first-class citizen of the work, rather than number of samples."
            },
            "questions": {
                "value": "I was wondering how the retrieval-based defense from Krishna et al. 2023 (https://arxiv.org/abs/2303.13408) fits in the theoretical analysis of this paper. While I appreciate the discussion in Appendix A, I think the analysis in both Sadasivan et al. 2023 and this paper does not directly apply to retrieval-based detection. If I understand the retrieval-based detection algorithm correctly, it does not leverage the difference in properties between `m(s)` and `h(s)`. In other words, I think retrieval-based detection will work with `h_1(s)` and `h_2(s)` as well, where `h_1` and `h_2` are two identically distributed human writers. Is it fair to say that in retrieval-based detection, the support (`S` in this paper's 3.1) of `m(s)` and `h(s)` is almost disjoint, and hence the `TV(m,h)` will be quite high / infinity? With a bigger database there may be a few collisions between `m(s)` and `h(s)`, so `TV(m,h)` will slightly drop?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6790/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697407045912,
        "cdate": 1697407045912,
        "tmdate": 1699636784710,
        "mdate": 1699636784710,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jw1i2YidEp",
        "forum": "oxEER3kZ9M",
        "replyto": "oxEER3kZ9M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6790/Reviewer_JMFi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6790/Reviewer_JMFi"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a theoretical analysis of the feasibility of AI-generated text detection based on sample complexity and TV distance. The paper includes two main theorems, one on the possibility of sample complexity in general (which I believe is an existing known result) and the second which extends to non-IID cases. The paper also includes a few experiments on the effect of document length on detection accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper is clear and well-written and provides a clear justification for a known result, i.e., that AI-generated text detection is easier with longer documents. The argument that Sadasivan, et al. 2023 (\u201cCan AI-generated Text Be Reliably Detected?\u201d) ignores the effect of document length and the possibility of having multiple sampled documents is reasonable and well-taken."
            },
            "weaknesses": {
                "value": "My main concern is that the results in this paper are general facts about sample complexity and not specific to detection of AI-generated text. For example, Theorem 1 is included here: https://github.com/ccanonne/probabilitydistributiontoolbox/blob/master/testing.pdf. As this paper is outside of my area, I am less confident about the novelty of Theorem 2, but its formulation is not dependent on the domain of AI-generated text detection. It is also unclear from the paper whether the \u201cmultiple samples\u201d required by this theorem are meant to be individual words, sentences, or documents. \n\nThe experiments also replicate known results, namely, that AI-generated text detectors perform better on longer sequences and that they perform worse with paraphrasing. As far as I can tell, the main novel finding is the \u201cpairwise with IID samples\u201d condition (Figure 2c). It would be interesting to see a more controlled experiment here, which compares the performance of detectors on two IID documents of lengths X,Y versus one single document of length X+Y."
            },
            "questions": {
                "value": "1. Could you provide additional details on the process used to generate Figure 2a? How were documents tokenized and how was AUC computed? I am also confused by the statement in Section 4.1 that this analysis \u201capproaches sentence to paragraph level\u201d while the maximum value of n seems to be 6 (which is shorter than most sentences, let alone paragraphs)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6790/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698724336666,
        "cdate": 1698724336666,
        "tmdate": 1699636784595,
        "mdate": 1699636784595,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FlJ35t0Fkt",
        "forum": "oxEER3kZ9M",
        "replyto": "oxEER3kZ9M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6790/Reviewer_Xeu7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6790/Reviewer_Xeu7"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the possibility of detecting machine-generated texts. With a theoretical analysis of true positive rate/false positive rate, the high-level message is that detecting MGT is possible if we have sufficient examples from humans and the machine. Empirical study on four datasets with a wide range of combinations between generation models and detection models demonstrate the utility of the theoretical results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The research problem is important and very challenging\n- The theoretical analysis is strong and sounding\n- The results support the high-level conclusion, although I am not sure whether it directly supports the conclusion about sample complexity  (please refer to the question section)"
            },
            "weaknesses": {
                "value": "- Interesting method and conclusion; however not sure how much we can connect this with MGT detection. It seems like the conclusion is generally applicable. This means the proposed method itself is not necessarily a weakness, but the disconnection is.\n- Equation 7 is not surprising. As pointed out by Sadasivan et al. (2023), it is impossible to get a reliable detector (high TPR, e.g., 90% and lower FPR, e.g., 1%), when the overlap of two distributions is relatively small.\n- Furthermore, equation 7 does not depend on sample complexity. So, I am not sure I understand how increasing the number of examples can get around this issue pointed out by the previous comment.\n- More generally, the real challenge of detecting MGT is the lack of information on generative models. In practice, it\u2019s hard to predict whether a collection of texts is from the same generation model. Furthermore, a gray area of this research question: how we should treat the texts generated by machines and edited by humans."
            },
            "questions": {
                "value": "- What is the \u201cPercentage of Sequence used for Detection\u201d?\n- What does \u201cexponentially fast\u201d mean in the caption of Figure 1?\n- Are there any experiment results on non-IID data?\n- Maybe I missed something from the paper, but is there any sample complexity directly related to equation 15?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6790/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811043552,
        "cdate": 1698811043552,
        "tmdate": 1699636784482,
        "mdate": 1699636784482,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cOoiSztcg1",
        "forum": "oxEER3kZ9M",
        "replyto": "oxEER3kZ9M",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6790/Reviewer_hkaL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6790/Reviewer_hkaL"
        ],
        "content": {
            "summary": {
                "value": "This work tackles the possibility of the detection of AI-generated texts from a perspective of increasing sample sizes (length). Specifically, the authors argue that there is a hidden possibility of the detection even with the machine and human text distributions close to each other, if more samples can be collected/used. They derive sample complexity bounds for their finding and corroborate the results with empirical experiments in conditional generation (e.g., on news or Wikipedia articles)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper is tackling an important problem on the possibility of detecting machine-generated text. The writing of the paper is overall clear, and the authors explore several empirical experiments to support the theoretical findings (on the hidden possibility of detection)."
            },
            "weaknesses": {
                "value": "The novelty of the finding. While the \"hidden possibility\" argument over the increasing sample size and increasing detectability of machine-generated texts is valid and intuitive, the novel insight in the argument is rather limited. The assumption and use of an increasing sample size/length in the machine-generated text detection problem is regular, for example, in watermarking (Kirchenbauer et al., 2023). The practical takeaway of the finding is relatively vague.\n\nThe experimental setup. In (1) and (2) of Section 4.1, the detector setup is very basic, for example, with n-gram features and linear classifiers. Then, if a 6-gram detector (in the basic setup) can achieve 97% accuracy in detection, is the possibility of detection still a relevant concern? Additionally, the experiments can be conducted on question-answering/instruction-following based tasks (e.g., generating chatbot-style answers) instead of only performing completions on news or Wikipedia articles."
            },
            "questions": {
                "value": "Please see the weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6790/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699536778107,
        "cdate": 1699536778107,
        "tmdate": 1699636784384,
        "mdate": 1699636784384,
        "license": "CC BY 4.0",
        "version": 2
    }
]