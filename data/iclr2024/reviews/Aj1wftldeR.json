[
    {
        "id": "vGOBY7kEMV",
        "forum": "Aj1wftldeR",
        "replyto": "Aj1wftldeR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7967/Reviewer_55ef"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7967/Reviewer_55ef"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new benchmark for offline RL, which includes additional domains (such as legged locomotion and robotic manipulation) and new modalities (such as visual observation).\n\nSeveral SOTA methods are also evaluated in this new benchmark, under both the pure offline setting and the online finetuning setting. Low performance is observed across domains and tasks, showing the potential space for improvements for current RL algorithms."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- This work improves D4RL by introducing some new domains and new modalities. These efforts could be helpful toward deployable offline RL, mainly for robotics.\n- The benchmark provides the evaluation results for online fintuning, which has its meaning. Most of works in offline RL only utilize offline data, while neglecting the benefit of a small portion of online data to address the distribution shift issue."
            },
            "weaknesses": {
                "value": "I appreciate the works from authors to push forward the benchmarking in Offline RL. However, there still exist some critical issues for this work, that make me tend to give a strong reject:\n- **The proposed benchmark does not include much more diverse domains compared to D4RL.** I think with some past works such as RoboMimic [1] and some recent works such as RL-ViGen [2], similar and even more diverse benchmarks could be easily made, by running RL agents to collect offline datasets.\n- **Low technical contributions.** This is fine, but I think for papers qualified for ICLR, low-technical papers should possibly provide some new insights.\n- **Possibly unfeasible settings.** As shown by evaluation results, most SOTA algorithms are not working well on this benchmark. This could possibly be attributed to the difficulties of the task, but from my perspective, there could also be some key factors that are not right, such as the problem formulation and the framework of offline RL. (This point might be not significant, but it is my personal concern about the benchmark.)\n- **Overclaim of the paper title**. This work names the newly proposed benchmark as D5RL, which is obviously following the name of D4RL. However, this could be misleading for the entire community to keep pursuing the limited improvements on a new but essentially similar benchmark.\n\nOverall, I appreciate the efforts made by the authors, and the motivation to improve the benchmarking in offline RL. This direction could be right and cherished by the community, but this work is not qualified for acceptance.\n\n\n[1] Mandlekar, Ajay, et al. \"What matters in learning from offline human demonstrations for robot manipulation.\" arXiv preprint arXiv:2108.03298 (2021).\n\n\n[2] Yuan, Zhecheng, et al. \"RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization.\" arXiv preprint arXiv:2307.10224 (2023)."
            },
            "questions": {
                "value": "See `weakness`."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Reviewer_55ef"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7967/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698575732610,
        "cdate": 1698575732610,
        "tmdate": 1700964790011,
        "mdate": 1700964790011,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xu0sdCGYRd",
        "forum": "Aj1wftldeR",
        "replyto": "Aj1wftldeR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7967/Reviewer_VAo4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7967/Reviewer_VAo4"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a new dataset benchmark for offline and online fine-tuning RL methods. The paper comprised of tasks which are of great interest to real-world robotics such as locomotion and manipulation. Also provides the diversity in domain of representation, as it covers both state-space and image domains."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The tasks in the dataset capture various challenges that are encountered in real-world robotics such as extrapolating policies, changes in environment, different viewpoints, etc.\n* Both image-based and proprioceptive modes of states are covered across settings and tasks.\n* The datasets are gathered for platforms that are embodied in the real-world and hence will allow for sim-to-real transfer to some extent."
            },
            "weaknesses": {
                "value": "* Limited number of tasks for the A1 legged locomotion. Tasks such as jumping, obstacle avoidance, etc. can also be of interest in this. \n* No evaluation of any of these tasks/settings in the real world. To what extent can the models trained on these datasets transfer to the real-world?"
            },
            "questions": {
                "value": "Don't have any major questions"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Reviewer_VAo4"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7967/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698811548994,
        "cdate": 1698811548994,
        "tmdate": 1699636980079,
        "mdate": 1699636980079,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5v6a9z8YuO",
        "forum": "Aj1wftldeR",
        "replyto": "Aj1wftldeR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7967/Reviewer_mGUu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7967/Reviewer_mGUu"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes D5RL, a novel benchmark that aims to facilitate the development of offline RL algorithms. The benchmark focuses on robotics environments based on real-world robotic systems. To address the drawbacks of existing benchmarks, D5RL includes a suite of tasks that pose different challenges for offline RL algorithms, including learning from various (sub-optimal) data distributions, image observations, temporal compositionally, generalization to randomized scenarios, and offline-to-online settings. Experiments show that existing methods that perform well on standard benchmarks fail to achieve meaningful performances on D5RL."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Overall, I think the paper is a good attempt to replace existing benchmarks that are likely saturated, and having a new benchmark would have a high impact on the offline RL community. The paper is well structured, where it first motivates the need for a new benchmark, presents a list of criterion for it, and proceeds to describe the benchmark and how it satisfies the criterion. The datasets and tasks are also well explained."
            },
            "weaknesses": {
                "value": "My biggest concern about the paper is the benchmark results section. \n- My impression from Tables 1 and 2 is the proposed benchmark is too difficult for existing offline RL methods to achieve meaningful performances, since most methods except BC and IQL have near-zero returns. While having a challenging benchmark is good, a too-challenging benchmark will not provide much signal to improve the performance of current methods. \n- The paper is currently lacking ablation studies to understand what components of the benchmark are challenging and/or why current algorithms fail.\n- I would like to see a random policy as a simple baseline. I wonder if the benchmarked methods even do better than a random policy.\n- Why is there such a big gap between IQL and other similar methods such as CQL and TD3+BC? These methods often perform very similarly in D4RL, at least in the locomotion tasks.\n- The paper did not choose a good collection of RL algorithms to benchmark. There are too many value-based methods, while return-conditioned methods (or generative methods) such as DT [1] and DD [2] are not mentioned. These methods have been shown to surpass value-based methods in sparse-reward and long-horizon tasks. Online DT [3] is also a good method for the offline-to-online setting.\n\nOther comments:\n- Section 5.2 states that the goal of the Frank Kitchen environment is to study offline RL and online fine-tuning, but the following text does not mention how the proposed task facilitates online finetuning.\n\n[1] Chen, Lili, et al. \"Decision transformer: Reinforcement learning via sequence modeling.\" Advances in neural information processing systems 34 (2021): 15084-15097.\n\n[2] Ajay, Anurag, et al. \"Is Conditional Generative Modeling all you need for Decision Making?.\" The Eleventh International Conference on Learning Representations. 2022.\n\n[3] Zheng, Qinqing, Amy Zhang, and Aditya Grover. \"Online decision transformer.\" international conference on machine learning. PMLR, 2022."
            },
            "questions": {
                "value": "- Is there only one dataset for the legged locomotion domain? Can we have multiple datasets with various qualities similar to D4RL?\n- How accurately it tracks the target speed of 0.75 m/s --> How is accuracy measured here? Is it the l2 distance between the actual and target speed?\n- Is hiking a sparse-reward task?\n-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7967/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698833563424,
        "cdate": 1698833563424,
        "tmdate": 1699636979923,
        "mdate": 1699636979923,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WfpdO8xbre",
        "forum": "Aj1wftldeR",
        "replyto": "Aj1wftldeR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7967/Reviewer_axPt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7967/Reviewer_axPt"
        ],
        "content": {
            "summary": {
                "value": "The submission proposes a new benchmark for offline RL algorithms.\nThe benchmark modifies previous domains or adds new domains to evaluate unsolved challenges in offline RL.\nExperiments demonstrate that existing offline RL algorithms do not perform well for the tasks in the benchmark."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The introduction of new domains and offline datasets in the benchmark offers the community a broader range of choices, potentially supporting the easier development of offline algorithms."
            },
            "weaknesses": {
                "value": "It is unclear whether promoting the use of this benchmark within the community will indeed accelerate offline RL algorithm development.\n- the benchmark does not *specifically* address current challenges in offline RL. While the paper broadly covers various challenges of offline RL,\n  - some of these challenges could be already observed in previous benchmarks. Evaluating temporal compositionality seems  possible using previous benchmarks (D4RL Maze2D, AntMaze, FrankaKitchen-Mixed, Calvin). The proposed benchmark has less diversity than D4RL, and different levels of data distribution are also discussed in D4RL. However, the text does not explicitly claim why using this new benchmark is better than using previous benchmarks for each challenge.\nTo encourage using this benchmark, the paper should address questions like: when to choose this benchmark? Are previous works successful on prior benchmarks likely to fail on this new benchmark specifically due to one of specific challenges?\n  - addressing offline-to-online learning adaption appears to be incremental. As almost all previous offline RL benchmarks are based on simulation environment and rule-based reward function, implementing online fine-tuning on the top of exisiting benchmarks is feasible.\n  - More information or resource should be provided to challenge the community to solve the image observation version of Franka Kitchen. Is the failure of existing works attributed to the incompleteness of offline RL algorithms or the lack of image representation learning? Can this task be intuitively completed solely with the provided offline data? If not, is there an alternative data source that the community can leverage to address this challenge?\n\n- Even if the benchmark doesn't specifically address one of those challenges, it can still be beneficial to have a domain with a collection of challenges if it is important to solve the domain. However, the provided domains are not significantly more realistic or different compared to existing tasks, making them less of an important target domain that the community aims to solve."
            },
            "questions": {
                "value": "Questions are included in weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7967/Reviewer_axPt"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7967/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699943579785,
        "cdate": 1699943579785,
        "tmdate": 1699943579785,
        "mdate": 1699943579785,
        "license": "CC BY 4.0",
        "version": 2
    }
]