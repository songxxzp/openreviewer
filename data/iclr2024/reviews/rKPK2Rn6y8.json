[
    {
        "id": "PwPDDogQxi",
        "forum": "rKPK2Rn6y8",
        "replyto": "rKPK2Rn6y8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7438/Reviewer_51yR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7438/Reviewer_51yR"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes developing \"autonomous tree-search (ATS) ability\" for large language models (LLMs) to allow them to solve reasoning tasks requiring exploration and search. ATS allows LLMs to generate responses demonstrating tree-structured search trajectories in either breadth-first search (BFS) or depth-first search (DFS) format. For large models like GPT-4, ATS ability can be activated through prompting the model to \"role play\" an assistant to generate the \"tree\" of the reasoning steps. Experiments on 4 puzzle tasks show GPT-4 with ATS prompts outperforms chain-of-thought. For smaller models like 7B/13B LLaMA, ATS ability can be acquired through supervised fine-tuning on GPT-4 generated ATS data. Experiments show ATS-tuned LLaMAs outperform both chain-of-thought tuned LLaMAs."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper proposes an approach to impart autonomous search ability to LLMs without specialized external programs. Could make LLMs more flexible and capable at complex reasoning. The ATS prompt approach seems quite generalizable to new tasks, requiring only fixed prompt. More flexible than task-specific passive search programs.\n2. The empirical investigation covers both large and small LLMs. Demonstrates effectiveness over strong baselines like Tree of Thoughts on the puzzle solving tasks."
            },
            "weaknesses": {
                "value": "1. While the proposed idea presents a certain degree of improvement, its contribution appears incremental when compared to both CoT and ToT.\n2. The scope of the literature survey is somewhat narrow. Notably absent are related works such as \"PAL: Program-aided Language Models\" and two concurrent studies that utilize pseudo-code-style prompts. These methodologies, too, emphasize simplicity and flexibility in generating reasoning steps.\n3. Although the \"Graph-of-thoughts\" work is referenced, there is a lack of empirical comparison with it.\n4. The empirical tasks primarily focus on simple games, which presents a limitation. It would be beneficial to incorporate more complex reasoning tasks. For instance, the ToT paper show the effectiveness of their methods through \"Creative Writing.\"\n5. LLM is known for its challenges in producing lengthy contextual answers, often leading to hallucinations. In contrast, ToT methods excel at breaking down complex tasks into more manageable steps, thereby enhancing the reliability of the output. The one-round prompting strategy, however, may encounter difficulties in handling intricate tasks, especially when they have significant breadth and depth."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7438/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698526894855,
        "cdate": 1698526894855,
        "tmdate": 1699636893226,
        "mdate": 1699636893226,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ryET4sqnRO",
        "forum": "rKPK2Rn6y8",
        "replyto": "rKPK2Rn6y8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7438/Reviewer_Tc6e"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7438/Reviewer_Tc6e"
        ],
        "content": {
            "summary": {
                "value": "This paper studies using language models in tasks that benefit from systematic search. The paper proposes \"Autonomous Tree Search\", a prompting method that instructs the language model itself to perform tree search in-context, requiring a single call to the LLM. This contrasts to Tree of Thoughts, which uses an external program to guide search, repeatedly calling the LLM to propose next states and evaluate states. Experiments on 4 puzzles show improvements over CoT and ToT using GPT-4. Moreover, the authors explore distilling ATS from GPT-4 into smaller models (LLaMA 2 7B and 13B), showing that fine-tuning with ATS yields the best performance (e.g. compared to fine-tuning on GPT-4-generated ToT)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes a simple idea that is very easy to apply in appropriate settings, so it's likely that it will be tried out by some of readers. The paper is well in scope around the current literature, and the idea itself is sound.\n\nThis is also the first work (that I'm aware of) that tried distilling tree-search into smaller models. An ongoing discussion in the area is whether there is a benefit of doing search in-context, since then one branch can be informed by others (in contrast to ToT, where the branches are expanded and evaluated independently). The experiments with LLaMA suggest that there might indeed by a noticeable difference between the two."
            },
            "weaknesses": {
                "value": "With regards to the method, one disadvantage that should be mentioned explicitly is that ATS is limited to search trees that fit in the context window. While this is not an issue for the simpler puzzles, more complex tasks might require extensive search that might not fit in-context. This limitation does not apply to Tree of Thoughts, so there is a trade-off between the two.\n\nThe main weaknesses of the paper in its current form are in the evaluation and presentation of the results.\n\nFirst, the paper gives little insight into what drives the current results. While the idea of ATS is intuitive, it is not clear to me what factors allow it to have higher accuracy. While the authors show better overall accuracies than ToT, the lack of any qualitative analysis doesn't allow the reader to understand why that is the case. This is especially important when the evaluation is in tasks that themselves don't matter much, like puzzles. The main benefit of these simple, synthetic tasks is to allow us to get insights into the models. If not for that, higher accuracy on these tasks doesn't mean much by itself.\n\nThe \"low-cost setting\" of Tree of Thoughts does not seem to be tree search at all. If the search width is 1, then the model is ultimately only following a single path, even if at each level it will propose multiple next steps. The fact that this performs even worse that CoT (which I can speculate, but don't fully understand from the paper) indicates to me that this comparison is unfair.\n\nThe cost evaluation in cents will get old fast. I'd suggest maybe showing some of them in the paper as with a note that \"at the time of writing\" these are the costs, but these numbers might be meaningless for readers even a few months from now.\n\nFor fine-tuning, it would have been useful to also compare to fine-tuning on CoT generated by the larger model, as done in recent prior work.\n\nThere seems to be quite a bit of redundancy between the figures and tables (e.g., the cost/accuracies in Figures 3 and 4, then in Table 1). A lot of this space could have been used to give insight into some of the numbers.\n\nFinally, and perhaps the main weakness: I found the choice of tasks a bit arbitrary. The authors propose 4 puzzles and only evaluate on those, without reference to prior literature. The paper makes a point about the choice of tasks in the Tree of Thoughts paper (that they don't fully isolate the tree search ability), but I don't think that that justifies discarding them completely."
            },
            "questions": {
                "value": "- Why would \"low-cost ToT\" perform worse than CoT in some settings (noticeably so in the Drop Water puzzle)?\n- What are the main failure modes you observed for ToT, and why does ATS seem to address them?\n- Are there any viable applications of ATS in existing tasks that are not synthetic puzzles?\n- Why is the output cost for ATS often smaller in the 4-shot setting, compared to 0-shot?\n- Why do figures 2 and 3 not include the low-cost results for other methods other than ToT?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Reviewer_Tc6e"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7438/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698616130389,
        "cdate": 1698616130389,
        "tmdate": 1699636893110,
        "mdate": 1699636893110,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zPJUwZO3R8",
        "forum": "rKPK2Rn6y8",
        "replyto": "rKPK2Rn6y8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7438/Reviewer_Mb1G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7438/Reviewer_Mb1G"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes developing \"autonomous tree-search ability\" in large language models (LLMs) to enhance their reasoning and problem-solving capabilities. In contrast with previous work like chain-of-thought and tree-of-thought, this paper demonstrates a prompting method to help large language models to automatically conduct planning without external planners (such as tree-search). Experiments with GPT4 over four puzzle games verify the effectiveness of ATS compared with CoT and ToT. By collecting ATS data from GPT4, the authors successfully show a much smaller model (such as LLaMA-7b/13b) can be supervise-finetuned to have the similar ability."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper has the following strengths:\n\n1. The paper writing is overall clear and straightforward.\n2. The idea is overall novel.\n3. The author conducts the experiment by prompting GPT4 and training on smaller LLaMA models to validate the general capability of such methods."
            },
            "weaknesses": {
                "value": "The paper has the following Weaknesses:\n\n1. The experiments are not comprehensive from a few perspectives.\n1.1 The evaluation is limited to just 4 puzzle games. More complex reasoning tasks should be tested to better validate the value of autonomous tree search.\n1.2 The author mainly analyzes the performance and the paper lacks in-depth analysis. For example, there is no analysis of how search spaces, branching factors, solution depth, search algorithms, and different prompt variations can affect performance.\n\n2. The author is supposed to discuss more about the limitations of ATS. For instance, ATS seems to generate more tokens and is more easily constrained by the model context length. Also, It seems hard for ATS to generalize to complex and long-term planning problem.  I recommend the authors include several limitation discussions like this (experiments will be appreciated).\n\n3. Lack of enough related work. A lot of work is discussing how to combine tree search with LLM, for example (Hao et al., 2023) and I am sure there have been more in the past few years. The author should add these literatures as related work.\n\n\nReference\nHao, Shibo, et al. \"Reasoning with language model is planning with world model.\" arXiv preprint arXiv:2305.14992 (2023)."
            },
            "questions": {
                "value": "1. Will GPT4 generate wrong planning during the ATS process? How do you filter the wrong planning out from the dataset?\n2. You mentioned that DFS exploration was inconsistent without task-specific examples. Did you investigate why DFS was not as robust? Are there ways to improve the generalizability of DFS search?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Reviewer_Mb1G"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7438/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698691451534,
        "cdate": 1698691451534,
        "tmdate": 1699636893004,
        "mdate": 1699636893004,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OXEO8Hkmhj",
        "forum": "rKPK2Rn6y8",
        "replyto": "rKPK2Rn6y8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7438/Reviewer_Dq3i"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7438/Reviewer_Dq3i"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a prompting method to make LLM automatically perform tree search (such as BFS and DFS) in one text completion. In the 4 synthetic puzzles tested, the method demonstrate gains over Tree of Thought, especially under zero-shot low cost setting. The proposed method can also be used to collect reasoning traces, which is then used to fine-tune smaller LMs to improve its performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is mostly well-written and easy to follow\n- The proposed method is simple and novel, although can be seen as one type of chain of thought.\n- The experiment results demonstrate substantial gains over CoT and ToT."
            },
            "weaknesses": {
                "value": "- The experiment settings are very toy/synthetic, making it unclear whether the method is useful for more realistic tasks."
            },
            "questions": {
                "value": "n/a"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7438/Reviewer_Dq3i"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7438/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698795455133,
        "cdate": 1698795455133,
        "tmdate": 1699636892893,
        "mdate": 1699636892893,
        "license": "CC BY 4.0",
        "version": 2
    }
]