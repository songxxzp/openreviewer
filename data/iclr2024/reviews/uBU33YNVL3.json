[
    {
        "id": "eHEmjMNrGV",
        "forum": "uBU33YNVL3",
        "replyto": "uBU33YNVL3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission101/Reviewer_kScR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission101/Reviewer_kScR"
        ],
        "content": {
            "summary": {
                "value": "This paper explored the learning behavior of MAE (one of symmetric loss functions), i.e. the limited overlap between the network output at the initial phase and non-zero derivative regions of the loss function. For tackling this issue, the paper introudced 'logit bias' to restore the overlap, and enabled MAE to learn on datasets with noisy labels. Extensive experiments on various datasets show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper provided detailed  analysis of proposed 'logit bias' from both theoretical (Eq.1 -- Eq.4) and experimental point of view (comparing with various loss functions).\n2. The author's writing is very good, and the entire paper is relatively easy to understand.\n3. Simple algorithm, easy to follow as only one additional parameter (\u03f5) are needed.\n4. The experimental results are reliable and sufficient to verify the effectiveness of this method.\n5. The last paragraph of Section 4 discusses some limitations."
            },
            "weaknesses": {
                "value": "1. The proposed method dosen't achieve SOTA accuracy in Table 2, 3, 4. The method didn't show dominant advantages over other loss functions, further explorations are expected. (current improvements are not very significant) \n2. The estimation of \"logit bias\" is still empirical for tasks or number of classes, which is not easy to configure it for different tasks."
            },
            "questions": {
                "value": "1. \"thus laying the foundation for a universal classification framework.\" Can this work support this strong conclusion?\n2. one paper relates to this work, would you please give some comments (comparison): IMAGE for Noise-Robust Learning: Mean Absolute Error Does Not Treat Examples Equally and Gradient Magnitude's Variance Matters,Published at ICLR 2023 Workshop on Trustworthy and Reliable Large-Scale ML Models."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission101/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission101/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission101/Reviewer_kScR"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission101/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697781683650,
        "cdate": 1697781683650,
        "tmdate": 1699635935424,
        "mdate": 1699635935424,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zch38OEH8c",
        "forum": "uBU33YNVL3",
        "replyto": "uBU33YNVL3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission101/Reviewer_jRF4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission101/Reviewer_jRF4"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to handle label noise. They observed that although bounded losses exhibit robustness against label noise, they suffer from serious underfitting. Taking MAE example, the authors explore its learning behavior. Motivated by this, they propose a new method called logit bias to address the underfitting."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper is well-organized and easy to follow.\n2. This paper is well-motivated. Specifically, the authors analyze the learning behavior of MAE at the early stage of training process, revealing the reason why MAE suffers from underfitting.\n3. Based on the above analysis, the author proposed logit bias, which is easy to implement and really helps to alleviate underfitting in some cases based on their experimental results."
            },
            "weaknesses": {
                "value": "In my humble opinion, the contributions of this paper seem limited and do not achieve the bar of ICLR.\n1. It is widely known that bounded loss such as MAE suffers from underfitting, an early work [1] also performed gradient analysis to explain this phenomenon. Although the analysis in this paper is somewhat different from the early work, I don't think it provides enough new insights.\n2. The proposed method \"logit bias\" seems too simple. It is definitely okay if it is effective enough, unfortunately, it is not.\n3. The current experimental results are not sufficient to demonstrate the effectiveness of the proposed method. First, most experiments are performed on symmetric label noise, I wonder if the proposed method can also handle asymmetric noise. I know that Webvision contains asymmetric noise, but its noise rate is relatively low. Moreover, even for symmetric label noise, the proposed method lags behind some previous methods such as genCE in many cases. Finally, I noticed that the authors claim that genCE has no hyper-parameter. I guess that they set $q$ of GCE to 0.7 by default. However, in my experience, the performance of genCE can improve remarkably if we elaborately adjust $q$. For instance, if we set $q$ to 0.5 or a smaller value, genCE might outperform other robust losses on WebVision. In fact, considering that MAE* has one hyper-parameter, it is unfair to freeze $q$ of genCE.\n\nReference\n\n[1] Generalized cross entropy loss for training deep neural networks with noisy labels, NeurIPS 2018."
            },
            "questions": {
                "value": "Please see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission101/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698404430661,
        "cdate": 1698404430661,
        "tmdate": 1699635935339,
        "mdate": 1699635935339,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XaESBRJlhT",
        "forum": "uBU33YNVL3",
        "replyto": "uBU33YNVL3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission101/Reviewer_cujv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission101/Reviewer_cujv"
        ],
        "content": {
            "summary": {
                "value": "In this study, the authors analyzed the dynamics of early-stage learning by computing the average backpropagation error, providing quantitative insights into how increasing the class count influences initial learning, especially in the context of bounded loss functions such as Mean Absolute Error (MAE). They introduced a hyperparameter-independent approach called \"logit bias,\" which realigns the distribution of a newly initialized network, enabling effective learning with MAE loss even in scenarios with a multitude of classes. Empirical evidence demonstrates the effectiveness of this method, with logit bias enhanced MAE loss showing comparable or superior performance across datasets spanning ten to a thousand classes. This is significant as such outcomes were previously largely exclusive to Cross Entropy or biTemp loss, which tend to overfit. The authors argue that their method is a first step towards a comprehensive framework that allows for noise-robust learning, regardless of the number of classes, and without an over-reliance on fine-tuned hyperparameters."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. This paper offers a novel insight into the underfitting phenomenon observed in some robust loss functions, pinpointing the discord between the non-zero range of the average error and the logit distribution of a newly initialized network as the primary culprit.\n\n2. The approach of this paper is simplicity and efficiency, requiring only a single parameter, \u03f5, which is directly determined by the number of classes.\n\n3. The paper provides clear details about the experimental setup, allowing for reproducibility and further exploration by other researchers."
            },
            "weaknesses": {
                "value": "1. The notations are not clearly defined; for example, the meaning of $\\delta_{nj}$ is unclear.\n\n2. This method is only designed for MAE, could it be expanded to help other robust losses?\n\n3. The empirical improvement is trivial. In the dataset CIFAR100 and with Resnet-34, it only achieves the state-of-the-art for clean data."
            },
            "questions": {
                "value": "1. In figure 1, the label for x-axis is \"pre activation $z_k$\", but there is no information about the activation function, I wonder what is the specific meaning of $z_k$, $a_j$ and $\\delta_{nj}$.\n\n2. How to get the output error of $\\delta_n$ in Tabel 1? Is that related to activation function?\n\n------\nI acknowledge that I have read the response of the authors. However, I am not convinced by the contribution of this work. Therefore, I tend to keep my score as 5."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission101/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission101/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission101/Reviewer_cujv"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission101/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698845284163,
        "cdate": 1698845284163,
        "tmdate": 1700641599670,
        "mdate": 1700641599670,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ivx7W9tZWd",
        "forum": "uBU33YNVL3",
        "replyto": "uBU33YNVL3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission101/Reviewer_n8a1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission101/Reviewer_n8a1"
        ],
        "content": {
            "summary": {
                "value": "This paper explores the learning behavior of bounded loss functions and proposes a modified version of MAE (adding logit-bias), addressing its under-fitting issue, especially when used in scenarios with a large number of classes. Both theoretical and numerical analyses demonstrate the picture behind the proposed logit-bias. Experiments show the proposed method's effectiveness and superiority over other noise robust losses."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- the paper is well-written, and the idea is clearly presented.\n- the observation of the overlapping between the distributions of the averaged error and the logit and its implication on network learning is keen and illuminating. \n- the proposed logit-bias is simple yet effective."
            },
            "weaknesses": {
                "value": "- the study of learning behavior still needs to be completed. It only considers the learning at the initialization stage. \n    - for example, in Fig. 4, the test acc using MAE* degrades in the late stage of training when the noise is present. Why does this happen? It would be interesting to investigate the learning behavior during the full training phase.\n- it would be desirable to consider more types of noise, e.g., skewed label noise, feature-dependent noise, etc., and more network architectures.\n- the way of choosing optimal $ \\epsilon $ needs to be explored more."
            },
            "questions": {
                "value": "- should we not consider the two temperatures as parameters for the Bi-Tempered loss? \n- how would the overlapping state change during training? would a dynamically tuned $\\epsilon$ helpful? would you consider other strategies for choosing $\\epsilon$?\n- is it possible, based on your observation, to design an initialization method that can also improve the overlapping?\n- as had been noticed in the paper, training with the logit-bias may introduce a kind of inductive bias to the resulting network, and this issue is addressed in a heuristic way by using small $\\epsilon$ values. However, a smaller $\\epsilon$ would have reduced its ability to restore overlapping. Could you elaborate on how this inductive bias would affect the trained model? Is there a systematic way to mitigate it?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission101/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699366482138,
        "cdate": 1699366482138,
        "tmdate": 1699635935202,
        "mdate": 1699635935202,
        "license": "CC BY 4.0",
        "version": 2
    }
]