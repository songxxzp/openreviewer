[
    {
        "id": "EoSbEWGvKb",
        "forum": "Mngdhgi711",
        "replyto": "Mngdhgi711",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3430/Reviewer_YAvt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3430/Reviewer_YAvt"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a hierarchical agent-based system called OKR-Agent for complex task solving. It utilizes a multi-level decomposition of objectives and key results along with role-specific agents and self-evaluations. Experiments on storyboard, trip planning, and creative writing tasks demonstrate enhanced performance over simple prompting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The idea of hierarchical task decomposition and role assignment is logical and aligns well with real-world collaborative workflows.\nMulti-level self-evaluations from different agent perspectives are interesting and help refine the solution."
            },
            "weaknesses": {
                "value": "- One of my major concerns is the limited technical novelty. Apart from the cute prompting, I did not see many method improvements from both technical and theoretical perspectives.\n\n- Limited evaluation in a narrow domain with limited baselines. I would expect more complex open-world LLM-agent benchmarking results, and more language models to be tested. Currently, only simple comparisons with ChatGPT (not sure which model version as well) can not justify why the proposed prompting framework can be generalized to different models.\n\n- More analysis is needed on the agent objectives, key results, and evaluation criteria to provide insights into what is being learned.\n\n- Agent coordination details are lacking - how are dependencies managed?\n\n- Safety mechanisms to prevent unbounded generation of objectives/agents need to be addressed.\n\n- No comparison to hierarchical planning methods from classical AI is presented."
            },
            "questions": {
                "value": "- How does the performance scale with increasing levels of hierarchy? Is there a sweet spot?\n- Can the approach work for very open-ended creative tasks without clear sub-objectives?\n- Has the approach been tested on goal-driven tasks like process planning vs just content generation?\n- What techniques are used to elicit useful evaluation criteria from the agents?\n- How sensitive is performance to the quality of the initial user prompt?\n- How difficult is it to construct such initial prompts from ambiguous and general tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3430/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698033086348,
        "cdate": 1698033086348,
        "tmdate": 1699636295111,
        "mdate": 1699636295111,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "k4lAT2w2Wp",
        "forum": "Mngdhgi711",
        "replyto": "Mngdhgi711",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3430/Reviewer_EcJ8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3430/Reviewer_EcJ8"
        ],
        "content": {
            "summary": {
                "value": "The paper presents the OKR-Agent, an advanced task-solving system that incorporates a hierarchical and self-collaborative approach to improve upon existing Large Language Model (LLM)-based methodologies. The system functions by breaking down tasks into Objectives and Key Results, allocating these to specific agents based on their roles within a workflow. This structure facilitates a more organized and coherent execution of tasks.\n\nThe contributions of the paper include:\n\n1. Introducing a hierarchical and self-collaborative model for task decomposition and execution, which enables more structured and coherent task management.\n2. Proposing a multi-level self-evaluation mechanism that allows agents to provide comprehensive evaluations from multiple perspectives, enhancing the accuracy and quality of outputs across strategic and executional levels.\n\nThe OKR-Agent was evaluated on tasks such as storyboard generation, creative writing, and trip planning, demonstrating superior performance in global task planning and detail generation. The results indicate that OKR-Agent is a significant step forward in the field of artificial intelligence, providing robust solutions for complex, multifaceted task-solving scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper tackles a compelling set of problems with its innovative integration of language agents and structured prompting, employing the Objectives and Key Results (OKR) framework to enhance task-solving capabilities. The concept is both novel and promising, as it fuses the flexibility of language-based AI agents with the goal-oriented precision of OKRs. This synergy enables the OKR-Agent to effectively decompose complex tasks into manageable sub-tasks, demonstrating a sophisticated approach to task execution. The idea of leveraging hierarchical structures to improve the clarity and efficiency of problem-solving is an excellent contribution to the field, showcasing a significant step forward in how AI systems can be structured for better performance and more coherent output."
            },
            "weaknesses": {
                "value": "Limited Comparative Benchmarking: The paper's comparison with existing methods seems constrained. A more extensive benchmark, including a variety of state-of-the-art systems, would better position the OKR-Agent's performance relative to the current landscape.\n\nHeavy Reliance on Subjective Evaluation: The paper predominantly uses subjective evaluations for performance assessment. Objective metrics and statistical validation could provide a more balanced and reproducible evaluation framework.\n\nWeakness in Evaluation Depth and Diversity: The paper lacks a diverse set of evaluation metrics. It primarily relies on subjective assessments, which, while valuable, may not capture the full performance spectrum of the OKR-Agent. Objective metrics like precision, recall, F1-score, or BLEU score for language tasks could provide a more comprehensive picture. The absence of these metrics is a significant weakness, as they are critical for substantiating the model's effectiveness across different scenarios and for different use cases.\n\nInsufficient Ablation Studies: The paper does not present in-depth ablation studies. Ablation studies are critical for understanding which components of the proposed method contribute most significantly to its performance. By systematically removing or altering parts of the OKR-Agent, researchers can gain insights into the importance of each feature. This omission means that the reader has limited understanding of why the OKR-Agent works and which aspects are essential for its success.\n\nLack of Error Analysis: There is no detailed error analysis provided. An error analysis would help in understanding the limitations of the OKR-Agent and in which situations it might fail or underperform. This kind of analysis is crucial for iterative improvement and for setting realistic expectations for the model's deployment.\n\nWeakness in Comparative Analysis Justification: The paper does not thoroughly justify the selection of systems used for comparative analysis. Understanding why certain systems were chosen as benchmarks and others were not is important for assessing the validity of the comparison. Without this justification, it's challenging to determine the relative standing of OKR-Agent in the broader field.\n\nNo Discussion on Model Robustness and Generalizability: The evaluation does not robustly test the generalizability of the OKR-Agent. It's unclear how well the agent would perform on tasks that were not part of the initial evaluation set, which is a significant weakness for claims of versatility and adaptability.\n\nBy addressing these weaknesses, the paper could strengthen its evaluation methodology and provide more insightful analysis into the of the proposed method."
            },
            "questions": {
                "value": "1. How does the OKR-Agent manage the computational complexity and resource allocation when scaling to more complex tasks and a larger number of agents?\n\n2. In cases of ambiguous or poorly defined tasks, what mechanisms does the OKR-Agent use to ensure effective decomposition into Objectives and Key Results?\n\n3. Could you provide insights into how the OKR-Agent might be adapted for use in highly specialized or technical domains that differ from those tested?\n\n4. Are there any plans to conduct ablation studies to pinpoint the most critical components of the OKR-Agent's architecture for its task-solving performance?\n\n5. How does the OKR-Agent interface with external data sources, and what strategies are implemented to ensure the integrity and applicability of this external data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3430/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698877248501,
        "cdate": 1698877248501,
        "tmdate": 1699636295012,
        "mdate": 1699636295012,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tLZHINy59Y",
        "forum": "Mngdhgi711",
        "replyto": "Mngdhgi711",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3430/Reviewer_ndXE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3430/Reviewer_ndXE"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a way of using self-collaboration and self-correction mechanisms to enhance LLMs.  The idea is that in-depth knowledge is\nrequired for complex tasks, so using specialized agents will increase performance.  Solving the task requires high-level strategic planning and low level execution.  The proposed framework uses a hierarchical generation of objects which are assigned to different role-specific agents and produces a multi-level collaborative evaluation. Experimental results on three different tasks show that the proposed approach outperforms other methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The main idea proposed seems novel and makes sense. It can provide a valuable paradigm for evaluation of complex tasks that are to be solved by LLMs."
            },
            "weaknesses": {
                "value": "The paper does not include enough details to be able to reproduce the work. For instance, the examples of the sentences used for generation prompt in Section 3.1 might not work with other LLMs or even with the same one after some time since LLMs get updated.\n\nThe examples shown do not use quantitative assessments. There are human subjects evaluations  but no indication of which differences are statistically significant, so saying the method proposed outperforms other methods does not seem to be strongly supported by the results presented."
            },
            "questions": {
                "value": "It is not clear to me that the method you proposed is easy to replicate.  Can you explain what is needed to replicate your results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3430/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698988847584,
        "cdate": 1698988847584,
        "tmdate": 1699636294938,
        "mdate": 1699636294938,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Srvkz2dS0T",
        "forum": "Mngdhgi711",
        "replyto": "Mngdhgi711",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3430/Reviewer_gKgL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3430/Reviewer_gKgL"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a novel method to enhance the performance of LLMs in solving general, complex tasks. First, the main task is decomposed to subgoals (i.e. objectives); Then for each objective, a special agent (persona) and evaluation metrics are generated. In the solving stage, each objective specific agent will propose solutions and got reviewed by associated agents before an answer is accepted. The authors demonstrate that their proposed system can outperform DramaTron in storyboard generation tasks, and also can provide more detailed trip plans that ChatGPT for vacation plans."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1) The paper is novel in that it hierarchically decomposes the tasks into smaller objects and tackle these objectives with specialized agents. \n2) The results seem impressive, i.e. that it can generate good stories that beat specialized models."
            },
            "weaknesses": {
                "value": "1) The biggest draw back of this paper is that, it is just not clearly written. I will be great to include code examples and intermediate solving results in the experiment session to help understanding. \n2) If I understand correctly, for each key result the LLM has to be invoked at least multiple times during solution proposal and review. So overall this system seems costly and slow from an inference perspective. It will be great if the authors can compare with other methods from this perspective."
            },
            "questions": {
                "value": "Since the paper is not well written, I highly recommend the authors to consult with a professional proofreading service. Also, if will be great if the authors can help clarify the following questions in the next version:\n\n1) The proposed system will decompose an task into many hierarchies. So who is deciding the number of hierarchies needed? From algorithm 1 it looks like an hyper parameter.\n2) Since the task will be broken into many objectives, are there causal or temporal links between different objectives? For example, how objective 2 can be solved should depend on objective 1's solution. \n3) If so, how can the different agents coordinate to solve the objectives in the correct order? From algorithm 2 it seems that each agent is just independently updating a portion of the final answer.\n4) What if one agent cannot give a satisfying answer? What will happen to the whole task? \n5) Are there any \"replannings\" where certain objectives should be removed/reconsidered?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3430/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699225485728,
        "cdate": 1699225485728,
        "tmdate": 1699636294858,
        "mdate": 1699636294858,
        "license": "CC BY 4.0",
        "version": 2
    }
]