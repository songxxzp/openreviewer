[
    {
        "id": "MBGz0Gj0P3",
        "forum": "etm456yoiq",
        "replyto": "etm456yoiq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3653/Reviewer_Kyed"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3653/Reviewer_Kyed"
        ],
        "content": {
            "summary": {
                "value": "This work aims to address the problem of domain adaptive semantic segmentation, mainly focusing on \"where and when to align\". At first, a hybrid-attention mechanism is proposed to achieve feature fusion and alignment. Then, an adaptive alignment controller (AAC) is designed to determine the alignment feature at each stage. Next, a coordinate weight is proposed to adjust the alignment time through the training process. In summary, the main contributions of this work are somehow novel, however, the performance gains are limited, and the comparison results are insufficient."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Originality**: The paper proposes three ideas, hybrid branch, adaptive alignment controller (AAC), and coordinate weight, which are generally applicable and work for feature alignment and fusion.\n\n**Quality**: The paper provides a thorough experimental evaluation of B$^3$CT on two simulation-to-real domain adaptive semantic segmentation bechmarks. The paper also conducts ablation studies to analyze the impact of different components of B$^3$CT, such as data flow in the hybrid branch, qualitative experiments on AAC, and the hyperparameter of coordinate weight. The paper demonstrates that B$^3$CT can achieve superior performance when combined with the HRDA baseline.\n\n**Clarity**: The paper also provides sufficient background information and related work to situate the contribution of B$^3$CT in the context of existing literature on domain adaptive semantic segmentation and self- and cross-attention.\n\n**Significance**: The paper addresses an important and challenging problem of domain adaptive semantic segmentation, which has many applications in autonomous driving, robotics, and scene understanding."
            },
            "weaknesses": {
                "value": "**Major Issues**:\n\n**Insufficient novelty and contribution**: The newly proposed B$^3$CT framework lacks justification for its design. The pipelines of hybrid-attention and adaptive alignment controller seem natural and basic.\n\n**Insufficient results for experiments**: \n\n- Although the authors state in the main text, \"the third branch of which facilitates learning domain-invariant features for alignment\", they provide no experimental results. \n\n- In Tab. 1, the result of only ablating \"coor. weight\" also should be reported.\n\n- In Sec. 4.4, the authors should differentiate the comparison results according to different network architectures, such as deeplab and segformer.\n\n- Recent works not only conduct experiments on two standard simulation-to-real benchmarks, i.e., GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes but also extend to adverse conditions. To name a few, SePiCo [a] and MIC [b] have extended to more challenging daytime-to-nighttime semantic segmentation task and CoTTA [c] has also investigated clear-to-adverse conditions using online adaptation. I would like to see the potential of B$^3$CT on more challenging scenarios.\n\n**Insufficient justifications**: For example, about training accuracy or pseudo-accuracy, some justifications are missing in this paper. Any advantages and limitations of pseudo-accuracy? \n\n**Insufficient details**: From Tab. 3, the only thing we can see is that there will be one hybrid attention with AAC in each stage. However, where should we exactly insert hybrid branch into a feature encoder? And what is the consumption of resources, such as GPU memory?\n\n**Minor Issues**:\n\n- In Eq. 2 and Eq. 5, $p_t^{i,j,c}$ (target predictions from student model) should be $\\hat{y}_t^{i,j}$ (target pseudo-label from teacher model)? Also, in Eq. 7 and Eq. 8 $p_t^i, \\hat{y}_t^i$ should be $p_t^{i,j}, \\hat{y}_t^{i,j}$, respectively?\n\n- The results of the experiments throughout the text are in two retained decimals, except for Table 5, where the authors should be consistent.\n\n- Typos: \"hybrid-attention different stages.\" -> \"Hybrid-attention different stages.\" in Sec. 4.1.\n\n\nRefs:\n\n[a] Xie et al. SePiCo: Semantic-Guided Pixel Contrast for Domain Adaptive Semantic Segmentation, TPAMI 2023.\n\n[b] Hoyer et al. MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation, CVPR 2023.\n\n[c] Wang et al. Continual Test-Time Domain Adaptation, CVPR 2022."
            },
            "questions": {
                "value": "The authors should discuss the limitations and potential negative societal impact in the Conclusion.\n\nPlease also refer to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Reviewer_Kyed"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3653/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698638819660,
        "cdate": 1698638819660,
        "tmdate": 1700660475268,
        "mdate": 1700660475268,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "psHG4p4PV4",
        "forum": "etm456yoiq",
        "replyto": "etm456yoiq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3653/Reviewer_Prz3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3653/Reviewer_Prz3"
        ],
        "content": {
            "summary": {
                "value": "The paper primarily focuses on the domain-adaptive semantic segmentation task. The authors introduce a so-called \"Three-Branch Coordinated Training\" (B^3CT) framework. This framework encompasses distinct source and target domain branches, along with a mixed attention branch equipped with an Alignment Controller (AAC) to transfer knowledge from the source to the target domain gradually. Additionally, the authors propose a \"coordinate weight\" strategy to emphasize when to execute the knowledge transfer. The authors have effectively evaluated their approach to major public benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem of unsupervised domain adaptation is important and pertinent to the community.\n\n2. The exposition on related techniques is quite comprehensive.\n\n3. The ablation studies are thorough, and the experimental configurations are clearly presented."
            },
            "weaknesses": {
                "value": "1. While the authors' motivation offers some insight, the experimental results presented are not entirely convincing. Despite the inclusion of three carefully designed components, the model's performance only improves by 1% mIoU on the GTA to Cityscapes transfer. Moreover, the performance on the Synthia to Cityscapes transfer is even lower than the baseline (HRDA).\n\n2. The authors only conducted experiments in the relatively simple and ideal scenario of transferring from synthetic datasets to real datasets, neglecting the more convincing Cityscapes to ACDC experiments. I believe that adding this experiment would make the authors' work more robust.\n\n3. I have some reservations to the extent that the introduced three-branch and AAC modules may add additional parameters and computational load, potentially boosting the model's Oracle performance. The performance gains claimed by the authors could very well stem from this."
            },
            "questions": {
                "value": "See weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Reviewer_Prz3"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3653/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698654174614,
        "cdate": 1698654174614,
        "tmdate": 1699636321494,
        "mdate": 1699636321494,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "98jri28rk3",
        "forum": "etm456yoiq",
        "replyto": "etm456yoiq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3653/Reviewer_YWN9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3653/Reviewer_YWN9"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an unsupervised domain adaptive segmentation method named B$^3$CT. In addition to the traditional UDA learning approach, which involves supervised training on the source domain and re-training on the target domain, the key idea lies in the introduction of a third branch that facilitates the alignment of the source and target domains through cross-attention mechanisms.\n\nWhen addressing the question of \"where to align,\" the paper introduces an Adaptive Alignment Controller (AAC) at each layer to determine varying degrees of alignment. As for the question of \"when to align,\" the paper defines a coordinate weight that controls the loss value within the hybrid branch, where the coordinate weight is derived from the pseudo-accuracy of target predictions generated by the student model compared to the target pseudo-labels provided by the teacher model. The experiments are conducted on two public benchmarks: GTA5-to-CityScapes and Synthia-to-CityScapes, showing the effectiveness of the method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and easy to follow.\n- The concept of using cross-attention to align source and target features is elegant and logically sound.\n- The design of the coordinate weight, which operates smoothly, is well-founded."
            },
            "weaknesses": {
                "value": "- The paper claims to achieve state-of-the-art performance on GTAV\u2192Cityscapes (74.8), which is not entirely accurate. A previously published paper, MIC (CVPR2023) [1], has achieved a higher performance of 75.9. I noticed the authors did not cite and compare it. Therefore, the claimed contribution should be reconsidered.\n- The proposed B$^3$CT is only applicable to transformer-based architectures and cannot be employed with CNN-based models.\n- B$^3$CT introduces additional computation during the inference stage, which raises concerns about computational efficiency for both training and testing. It would be valuable to include a comparison of computational efficiency in the paper's evaluation and report the results accordingly.\n\n[1] MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation. CVPR2023."
            },
            "questions": {
                "value": "Will authors release code?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3653/Reviewer_YWN9"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3653/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698744140395,
        "cdate": 1698744140395,
        "tmdate": 1699636321413,
        "mdate": 1699636321413,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wE0yRwG5Aa",
        "forum": "etm456yoiq",
        "replyto": "etm456yoiq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3653/Reviewer_qoMd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3653/Reviewer_qoMd"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on unsupervised domain adaptation and proposes a multi-branch coordinated training method. Specifically, it designs three-branch coordinated training technique, where the final loss function is dynamically weighted by coordinate weight on the loss values of three branches. Extensive experiments show that the proposed method has achieved good unsupervised domain adaptation performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-a. It proposes a multi-branch coordinated training method for unsupervised domain adaptation.\n- b. It designs three-branch coordinated training technique, where the final loss function is dynamically weighted by coordinate weight on the loss values of three branches.\n- c. The experimental results show that the performance of the proposed method is promising in unsupervised domain adaptation."
            },
            "weaknesses": {
                "value": "Although this paper is well written with comprehensive evaluation and good results, there are still some issues.\nSeveral parts of this paper are not very clear and need further clarification. Please check the questions.\nIn addition, some key related works that also address unsupervised domain adaptation are missed. Please check the questions.\n1. In table 5, it seems that the proposed method performs less effectively on Synthia to Cityscapes benchmark. It would be better to provide some insights and analysis to illustrate these results.\n2. As shown in the ablation studies in Tables 1-3, the performance gains seem not significant. Did the author conduct experiment with multiple random runs or random seeds? It is not clear how much the training randomness affects the performance when the gains are not significant.\n3. The key related unsupervised domain adaptation papers [A, B, C, D] are missed. This paper focuses on unsupervised domain adaptation and proposes a multi-branch coordinated training method. The differences, pros and cons of the proposed multi-branch coordinated training method and the traditional UDA co-training methods [A, B, C, D] are not clear. [A] introduces multiple feature spaces and performs co-training by conducting Co-regularized Alignment among them, whereas [B] introduces multiple classifiers and performs co-training by conducting Collaborative Alignment upon them. [C] achieves co-training by introducing multiple diverse classifiers to generate class-balance weights, which are then used to weight/regularize adversarial learning or self-training, whereas [B] achieves co-training by leveraging current and historical models to generate historical consistency weights, which are then used to weight/regularize adversarial learning or self-training. It would be better to provide discussion and analysis to illustrate the differences, pros and cons of the proposed method and [A,B,C,D]. For example, the differences, pros and cons of the proposed coordinate weights, the class-balance weights in [C] and the historical consistency weights in [D], for UDA.\n[A] Co-regularized Alignment for Unsupervised Domain Adaptation. NIPS 2018\n[B] Collaborative and Adversarial Network for Unsupervised domain adaptation. CVPR 2018\n[C] Taking A Closer Look at Domain Shift: Category-level Adversaries for Semantics Consistent Domain Adaptation. CVPR 2019.\n[D] Model Adaptation: Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data. NeurIPS 2021.\n4. According to Table 3, it seems that HRDA (73.8) has been taken as the baseline. Did the author try to apply the proposed method on other methods/baselines and what about the performances/gains? It is very interesting to investigate the generalization ability of the proposed method by testing it on other baselines."
            },
            "questions": {
                "value": "Please check Weaknesses.\n\nConclusion\nOverall, this work proposes a multi-branch coordinated training method for UDA and yields good experimental results. However, there are some details that need to be made clearer, as listed in the questions. I would like to upgrade the score if the questions could be well addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3653/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698849081509,
        "cdate": 1698849081509,
        "tmdate": 1699636321341,
        "mdate": 1699636321341,
        "license": "CC BY 4.0",
        "version": 2
    }
]