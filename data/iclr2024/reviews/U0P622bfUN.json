[
    {
        "id": "2ZurMVHvCB",
        "forum": "U0P622bfUN",
        "replyto": "U0P622bfUN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1/Reviewer_zu8q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1/Reviewer_zu8q"
        ],
        "content": {
            "summary": {
                "value": "The Federated Generative Learning (FGL) framework offers a novel approach to federated learning, leveraging foundational generative models like Stable Diffusion to generate training data from prompts shared by clients. Clients contribute class-level or instance-level prompts, encapsulating key features of their local data. The server, in turn, amalgamates these prompts and synthesizes corresponding training data for global model training. This approach trims down communication costs since only concise prompts, and not bulky gradients or models, are transferred. This system also boasts robustness to data diversity and has demonstrated superior performance \u2013 with just one communication round, it outdid FedAvg's 200 rounds in accuracy. When trialed on skewed ImageNet100 distributions, FGL exceeded FedAvg's performance by 30% in just five communication rounds. Apart from being efficient, FGL also enhances privacy, as prompts reveal lesser private data than traditional methods. Evaluations confirmed no private data memorization in the synthetic images and an enhanced resilience against membership inference attacks. However, challenges persist with non-IID data, intricate domains, and the potential risks associated with prompts."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tNovel idea of using foundation models to synthesize training data for federated learning, enabling low communication costs and better privacy.\n2.\tCompelling experimental results demonstrating accuracy improvements over traditional FedAvg, especially with skewed data distributions.\n3.\tThorough analysis and quantification of privacy benefits, showing reduced memorization and vulnerability to membership inference attacks."
            },
            "weaknesses": {
                "value": "1.\tThe evaluation of the Federated Generative Learning (FGL) framework is limited to simpler domains like ImageNet and doesn't extend to other areas, casting doubt on whether prompts can encapsulate complexity.\n2.\tWhile FGL aids in data generation for non-IID data, achieving congruence with a global distribution is yet to be addressed. \n3.\tSecurity risks of prompts require more analysis. Could prompts be reverse-engineered to obtain private data?\n4.\tThe framework hasn't been benchmarked against other federated learning methods that employ generative models."
            },
            "questions": {
                "value": "please refer to the weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698543827436,
        "cdate": 1698543827436,
        "tmdate": 1699635924030,
        "mdate": 1699635924030,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VulmbS3YYc",
        "forum": "U0P622bfUN",
        "replyto": "U0P622bfUN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1/Reviewer_ZNb2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1/Reviewer_ZNb2"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses efficiency and client-shift issues in federated learning by harnessing generative foundation models. Unlike traditional approaches that communicate model parameters, this work exploits clients to send instance-level or class-level prompts, generated by a pre-trained captioning model, to the server. The server aggregates these prompts to produce a proxy dataset via a pre-trained generative model, enabling standard federated learning on this dataset. The server then dispatches the refined weights back to the clients. Empirical evaluations underscore the efficacy of the proposed approach."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed approach significantly reduces communication costs compared to traditional parameter transmission.\n2. By leveraging foundation models to synthesize proxy data, the authors effectively mitigate the client-shift problem.\n3. A variety of experimental settings across four datasets demonstrate the robustness and effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. The training framework is predominantly tailored for image datasets, limiting its applicability.\n2. The method heavily depends on the congruence between the captioning and generative models, making it challenging to ensure the proxy dataset's distribution aligns with the private data.\n3. The experimental setup, with only five clients, may not adequately represent real-world scenarios; expanding the evaluation to include 50 or 100 clients could provide more insightful results.\n4. The comparison to a single baseline, FedAvg, falls short; including comparisons to advanced Federated Learning frameworks could better highlight the proposed method's effectiveness.\n5. Table 2 shows the proposed method outperforming centralized learning significantly; a thorough explanation of this phenomenon is warranted."
            },
            "questions": {
                "value": "1. I wonder if the approach cam be applied to other types of datasets, besides the image datasets.\n2. What the experimental results would be when the number of clients becomes bigger, e.g., 100."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698549593720,
        "cdate": 1698549593720,
        "tmdate": 1699635923922,
        "mdate": 1699635923922,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rBIpJVtNpZ",
        "forum": "U0P622bfUN",
        "replyto": "U0P622bfUN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1/Reviewer_wnsW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1/Reviewer_wnsW"
        ],
        "content": {
            "summary": {
                "value": "- The main idea of the paper is to use prompts to \u201csummarize\u201d the client-side data in federated learning. These prompts are then sent to the central server and fed to a foundation generative model, with the hope that the generated data distribution is close to the client data distribution.\n- With this idea, federated learning can be made one-round or few-round to drastically reduce communication costs, where clients can just send over the prompts one-shot to the server as the prompts and labels require very little communication.\n- The paper then evaluates on several natural image datasets (subsets from ImageNet) and show that the proposed technique can match FedAvg in performance.\n- The paper also performs some privacy analysis and shows that by transmitting prompts instead gradients/model updates/data, the membership inference attack success drops significantly."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed approach is interesting and novel to my understanding. Assuming the client data distributions can be well captured by the foundation generative model, the proposed technique can clear benefits in simplicity and reducing communication costs.\n- Putting aside the underlying assumptions of the proposed techniques (see weaknesses), the paper is overall well-executed in terms of the diversity of the experiments and visualizations.\n- The paper is generally well-written and easy-to-follow."
            },
            "weaknesses": {
                "value": "[W1] The main weakness of the proposed method is the underlying assumption that client data can, in fact, be generated by foundational models. This sound obvious but is key to the applicability of the proposed approach in practice. To put it bluntly, is the proposed solution searching for a problem?\n\n1. Settings where FL is helpful\u2014such as medical images across hospitals [1], user-generated text across mobile phones [2]\u2014are often where the data distributions aren\u2019t covered by the pre-training data of foundational models. The datasets used by the experiments are all natural image datasets (ImageNette, ImageFruit, etc.), which can be well-represented in the pre-training dataset of foundation generative models. I would appreciate results on non-natural image datasets.\n2. In particular, if we consider horizontal FL settings (as with the paper), the server may even know about the possible classes / labels (e.g. federating binary classifiers) without communicating to the clients, in which case the \u201cclass-level prompts\u201d may not be needed at all since the server can just generate images by itself. \n\n[W2]  More broadly, the threat model of the paper may need to be defined more clearly.\n\n- What exactly is client privacy in this case? Can the client data be still considered \u201cprivate\u201d if you could already generate them with public foundation models (see also [3])? Does the privacy of the data lie in the pixels, or simply the description of the pixels?\n- In many cases, the descriptions of the images can already be leaking privacy. If we apply the proposed method to cross-device federated learning on user\u2019s photo data, the server could already learn a lot about the user data distribution and preferences. For example, following Sec 5.4 and Figure 6, knowing that a user have lots of golf photos (without knowing the pixels of the photos) already allows the FL service provider (e.g. Google) to sell targeted ads.\n\n[1] FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in Realistic Healthcare Settings. NeurIPS 2022 Datasets and Benchmark.  https://arxiv.org/abs/2210.04620 \n[2] https://research.google/pubs/pub47586/ \n[3] Considerations for Differentially Private Learning with Large-Scale Public Pretraining. https://arxiv.org/pdf/2212.06470.pdf"
            },
            "questions": {
                "value": "- [Intro section] Why exactly does the proposed method provide robustness to data heterogeneity? Heterogeneity can still surface in the (instance-level) client prompts and subsequently the generated images.\n- Minor comment: consider using different citation commands `\\citet` , `\\cite`, etc. in LaTeX to make the formatting of the in-text references consistent."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Privacy, security and safety"
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1/Reviewer_wnsW"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698700659171,
        "cdate": 1698700659171,
        "tmdate": 1699635923758,
        "mdate": 1699635923758,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uP676dsarr",
        "forum": "U0P622bfUN",
        "replyto": "U0P622bfUN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1/Reviewer_HdAm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1/Reviewer_HdAm"
        ],
        "content": {
            "summary": {
                "value": "This work introduces a novel federated learning framework called Federated Generative Learning, which addresses the inefficiency and privacy issues of existing solutions that transmit features, parameters, or gradients between clients and servers. In this framework, clients generate text prompts tailored to their local data and send them to the server, where informative training data is synthesized using stable diffusion. This approach offers enhanced communication efficiency, significant performance gains, and improved privacy protection, as demonstrated through extensive experiments on ImageNet and DomainNet datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This work proposes a novel learning framework to train local data without accessing the raw data directly.\n\n- communication of prompts instead of model parameters addresses several issues of existing federated learning frameworks; high communication cost and potential privacy threats by attackers."
            },
            "weaknesses": {
                "value": "- The proposed method may be highly dependent on the performance of both diffusion models and visual-captioning models. \n  - An ablation study of varying the foundation models is needed.\n\n- In a similar vein, the local training dataset should be unseen for pertaining foundation models and should be more difficult than ImageNet which is a standard image classification dataset. As mentioned in the Introduction section, the local training data are more likely to be privacy sensitive, so they are more likely to be unseen or not contained for pre-training foundation models such as BLIPv2 and Stable Diffusion. Evaluation on ImageNet or DomainNet implicitly uses the assumption that local data have a similar or subset domain to the pretraining dataset of foundation models, which are publically accessible or have no privacy issue.\n\n- Clients in federated learning are often assumed to have limited capacity in memory or computation. Generating prompts using a large visual captioning model in each client is impractical."
            },
            "questions": {
                "value": "- The quality of synthetic data could be highly different according to domain discrepancy between the local training data and the pretraining data for the foundation model. Instead of using standard image classification datasets, does the proposed method work for federated learning on fine-grained classification such as CUB-200, Cars, and medical image datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824961127,
        "cdate": 1698824961127,
        "tmdate": 1699635923633,
        "mdate": 1699635923633,
        "license": "CC BY 4.0",
        "version": 2
    }
]