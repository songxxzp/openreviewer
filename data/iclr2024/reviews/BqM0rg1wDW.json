[
    {
        "id": "q8zaFUZXBu",
        "forum": "BqM0rg1wDW",
        "replyto": "BqM0rg1wDW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1845/Reviewer_ccA4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1845/Reviewer_ccA4"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel spiking neural network (SNN) architecture for coincident particle event detection in positron emission tomography (PET). Technically, the authors design a dedicated multi-objective loss function for SNNs that is both sensitive to spike counts and timing critical. Meanwhile, they implement large-scale data-parallel SNN training on a multi-node GPU system. Experiments show that PETNet outperforms SOTA algorithms with faster inference speed."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "i) The topic of particle event detection using SNNs is very interesting and attractive.\n\nii) The authors verify a surprising conclusion that SNNs can speed up this task and even improve detection accuracy by learning coincidence patterns.\n\niii) The writing is straightforward, clear, and easy to understand."
            },
            "weaknesses": {
                "value": "i) I am curious and surprised by a sentence \u201cSNN provide a promising alternative with the potential of surpassing conventional ANN prediction accuracy while requiring substantially less computational resources\u201d in the introduction section. Why can SNNs have better performance than the corresponding ANN model and reduce computational complexity? I am curious and surprised by a sentence made in your introduction. Why can SNNs have better performance than the corresponding ANN model and reduce computational complexity? I am curious and surprised by a sentence made in your introduction. Why can SNNs have better performance than the corresponding ANN model and reduce computational complexity? Please prove this point in terms of theoretical explainability and experimentation. To the best of my knowledge, one of the biggest advantages of SNNs over ANNs is low power consumption.\n\nii) The authors should show more visualization results for better understand the task of particle event detection.\n\niii) The authors should give the detailed SNN architecture in the manuscript."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Reviewer_ccA4"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1845/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698311217513,
        "cdate": 1698311217513,
        "tmdate": 1699636114615,
        "mdate": 1699636114615,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eHoljDo0XX",
        "forum": "BqM0rg1wDW",
        "replyto": "BqM0rg1wDW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1845/Reviewer_iojo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1845/Reviewer_iojo"
        ],
        "content": {
            "summary": {
                "value": "This article formulates the type II coincidence pairing problem from PET dataset and highlights the time reduction and accuracy improvement over classical SCW algorithm using a well-designed SNN training method (PETNET)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "please see Summary"
            },
            "weaknesses": {
                "value": "1. The motivation of this research has migrated SNN into a new medical classification problem (i.e. PET data). The writer introduce a multi-objective loss function where data sparsity and temporal resolution are both considered. The PET dataset characteristics may well capture SNN inherent spatiotemporal design that could make up good performance. However, in most research topics, ANN is always outperforming SNN, especially in terms of precision (e.g. CIFAR-10, imageNet). It is questionable for directly comparison only between non-ML algorithm (SCW) and SNN. \n\n2. The multi-node GPU contributions is migrating the classification problem from non-GPU framework to GPU-accelerated framework (i.e. cuda). This acceleration raised the idea that if the problem can be fulfilled using only very simple ML algorithm that also can process in a very fast and accurate manner, such as SVM, decision trees or clustering if considering only single fully connected layer is needed for the SNN. \n\n3. It is suggested to combine the Figure 1 figure 2 into one figure. Especially the PET dataset, as a subset of biomedical signal, is little covered by research topic. It is at best to illustrate the dataset in picture and visualise 1-2 selected examples from numerical vector/matrix in your dataset.\n\n4. Extending from (1), it is also suggested to include state-of-the-art algorithm which also capture temporal dynamics apart from single-layer LSTM. For example, transformer type model vs SNN approach or CNN based classification models. The expected SNN result may also be deployed on neuromorphic hardware instead of parallel hybrid \u201csupercomputer\u201d. If supercomputer is available, computing resources can be sacrificed for shorter time as there could be many available ML choices apart from SNN."
            },
            "questions": {
                "value": "please see the weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Reviewer_iojo"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1845/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698680743214,
        "cdate": 1698680743214,
        "tmdate": 1699636114532,
        "mdate": 1699636114532,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jcNsOxnluw",
        "forum": "BqM0rg1wDW",
        "replyto": "BqM0rg1wDW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1845/Reviewer_xnxs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1845/Reviewer_xnxs"
        ],
        "content": {
            "summary": {
                "value": "Spiking Neural Networks (SNNs) are explored as an energy-efficient alternative for processing Positron Emission Tomography (PET) data. The study introduces PETNet, a method that uses SNNs to filter invalid photon hits in PET imaging. Results show PETNet has a 95.2% F1 score and is 36 times faster than traditional methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The study utilizes Spiking Neural Networks (SNNs) to develop PETNet, which not only achieves an impressive F1 score of 95.2% in photon coincidence detection but also processes data at a remarkable speed."
            },
            "weaknesses": {
                "value": "While the author applied SNN technology to PET data processing, the innovative aspects of the research still appear limited. The LSTM mentioned in the article fails to effectively capture long-range dependencies, and the transformer faces challenges related to memory consumption due to sequence length. Regrettably, the author did not compare with these methods in the experiments."
            },
            "questions": {
                "value": "The SNN using LIF neurons primarily relies on the constant between membrane potentials to determine its temporal dependency, which may be inadequate. Moreover, it adopts the standard fully-connected SNN design. Compared to architectures like LSTM, RNN, and Transformer, where does the SNN's advantage lie? Can this be demonstrated through experimental results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1845/Reviewer_xnxs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1845/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698734555143,
        "cdate": 1698734555143,
        "tmdate": 1699636114456,
        "mdate": 1699636114456,
        "license": "CC BY 4.0",
        "version": 2
    }
]