[
    {
        "id": "OnBKUgTBVD",
        "forum": "nTNElfN4O5",
        "replyto": "nTNElfN4O5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5798/Reviewer_MWq4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5798/Reviewer_MWq4"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a denoising diffusion model for generating interacting hand meshes. The method is used for randomly sampling pairs of interacting hands,  conditional sampling by replacing parts of the input with the corresponding hand conditions. It can also act as an post-processing step for 3D hand meshes by fitting to observations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The proposed method that leverages diffusion models and collision avoidance loss to learn a generative model to capture interacting hand priors is reasonable.\n* The proposed method successfully produces reasonable and physically plausible results in three applications, achieving better results than baselines."
            },
            "weaknesses": {
                "value": "* The DDIM sampling steps are set to 1000, which makes the fitting extremely slow and brings marginal improvement to vertex error.\n* The novelty is quite limited. The architecture is not different from the current 3D hand mesh reconstruction methods where cross-attention from different hands is widely used. What makes these three applications useful?\n* Predicting the original clean sample instead of predicting added noise for denoising is a common practice in various diffusion model applications."
            },
            "questions": {
                "value": "* Any network can model the prior distributions of hand meshes. What benefits does the method offer, aside from modeling through a diffusion model?\n* Why is generating interacting hand meshes considered an important task?\n* Only the VAE part of MLD is used for comparison. More diffusion model-based baselines are needed for comparison."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Reviewer_MWq4"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5798/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698511027994,
        "cdate": 1698511027994,
        "tmdate": 1699636610580,
        "mdate": 1699636610580,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XeWJIESiyD",
        "forum": "nTNElfN4O5",
        "replyto": "nTNElfN4O5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5798/Reviewer_uZ7W"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5798/Reviewer_uZ7W"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce a pioneering generative model tailored for 3D interacting hands. This innovative approach harnesses the power of a diffusion model integrated with a transformer architecture, incorporating both Self-Attention (SA) and Cross-Attention (CA) mechanisms. Notably, the algorithm is versatile, allowing for random sampling, conditional random sampling, and adeptly fitting to observational data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Innovative and Practical Algorithm: This study presents the pioneering generative model tailored for 3D interacting hands, characterized by its unique network design. The significance of this prior distribution modeling is underscored by its fitting to observation capabilities, which outperforms current regressor methods both quantitatively and qualitatively.\n2. Clarity and Accessibility: The manuscript is exceptionally clear and reader-friendly. Even those unfamiliar with the domain can grasp the content effectively.\n3. Thorough Experiments and Analysis: The authors have conducted comprehensive experiments across three distinct settings, showcasing the model's efficacy on both simulated and real datasets. The research is bolstered by user studies, qualitative analyses, and quantitative results, making a compelling case for the model's strengths. The appendix further enriches the paper by detailing the problem settings, network configurations, dataset specifics, and baseline comparisons."
            },
            "weaknesses": {
                "value": "1. The methodology for integrating the generative prior with the regressor in an end-to-end manner remains ambiguous. It would be beneficial if the authors could delve deeper into this aspect, either in the appendix or the section dedicated to future work.\n2. The model's capacity for enhanced generalization, especially concerning varying hand sizes and shapes, is not explicitly addressed. A clearer exposition on this topic would provide valuable insights into the model's adaptability and robustness."
            },
            "questions": {
                "value": "Please see the weakness above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Reviewer_uZ7W"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5798/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698641723455,
        "cdate": 1698641723455,
        "tmdate": 1699636610436,
        "mdate": 1699636610436,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IA2Yj4JgV3",
        "forum": "nTNElfN4O5",
        "replyto": "nTNElfN4O5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5798/Reviewer_Z2YY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5798/Reviewer_Z2YY"
        ],
        "content": {
            "summary": {
                "value": "Authors proposed to apply the diffusion model for generating 3D interacting hands. This is the first attempt to learn prior distributions of interacting two hands in 3D space. They leverage transformer-based architecture as the denoising network to better capture inter-hand interactions. Experiments demonstrates the SOTA results on interhands2.6M dataset in terms of vertex error and contact accuracy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Diffusion model was first used for interacting hand pose estimation task; while some were proposed for human body domains.\nAchieves SOTA results on handling contacts and collisions\nThe work claims the proposed collision loss can prevent both self-collisions and inter-collisions while the widely used (SDF)-based collision avoidance loss function can only handle the inter-collisions.\nThe english is well written.\nThroughout diverse experiments, authors proves the effectiveness of the diffusion model in interacting hand domain."
            },
            "weaknesses": {
                "value": "The work fails to achieves SOTA in the in terms of vertex error.\nTechnical contribution seems weak. The only contribution seems like that using transformer-based architecture for denoising process.\nSimple methods such as nearest neighbor search outperforms their method in the ratio of collision. This makes it unconvincing for their results."
            },
            "questions": {
                "value": "Authors proposed the right hand-relative space to represent inputs. I\u2019m curious if it is possible to represent inputs based on the left hand relative space.\nThe work claims to model the priors for interacting hands. However, I am curious about the generalization capability of the model. How effectively the prior can be applied to the unseen data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5798/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698742107657,
        "cdate": 1698742107657,
        "tmdate": 1699636610324,
        "mdate": 1699636610324,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nrwyrrQVXr",
        "forum": "nTNElfN4O5",
        "replyto": "nTNElfN4O5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5798/Reviewer_h3k4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5798/Reviewer_h3k4"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a diffusion based two-hand interaction prior. This prior enables many applications such as random pose sampling, conditional pose sampling and image pose fitting. The core algorithm is a Transformer based network that encode the left-right-hand interaction through cross-attention."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This is the first two-hand interaction prior using diffusion model. Several applications have been enabled. \n\n2. The results are impressive, especially the physical plausibility compared with VAE baseline."
            },
            "weaknesses": {
                "value": "1. The method seems to be a trivial modification of diffusion process with limited novelty. \n\n2. The evaluation is not satisfactory, see questions below. A prior model is definitely useful for hand pose sampling or hand pose estimation. However, more thorough comparisons are necessary to convince me with the effectiveness of this prior on single-image two-hand recovery."
            },
            "questions": {
                "value": "My concerns mainly relate to the comparison for single image hand reconstruction. The paper mainly compared with InterWild (Moon et.al. CVPR 2023) in Table.3 on HIC dataset. (1) Why not use interhand2.6M dataset for comparison? (2) I noticed that the authors cited \"Reconstructing Interacting Hands with Interaction Prior from Monocular Images\" (Zuo et.al. ICCV 2023), which is the new sota. It would be better to compare with it as it also claims an interaction prior. Although Zuo et.al. handled a more narrow task (image based hand reconstruction), it is valuable to discuss the difference of the two priors for image-based hand reconstruction.  (3) I would like to see a direct comparison with IntagHand (Li et.al. CVPR 2022) for single-image two-hand recovery. In my opinion, IntagHand focused on capturing the interaction part of hands using attention, which might be more suitable than InterWild as a baseline."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5798/Reviewer_h3k4"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5798/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698744577036,
        "cdate": 1698744577036,
        "tmdate": 1699636610180,
        "mdate": 1699636610180,
        "license": "CC BY 4.0",
        "version": 2
    }
]