[
    {
        "id": "e5QsHnYTx6",
        "forum": "TW0MVSflg5",
        "replyto": "TW0MVSflg5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission953/Reviewer_qP3j"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission953/Reviewer_qP3j"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces Self-Evolving Neural Radiance Fields (SE-NeRF), a teacher-student framework for the few-shot Neural Radiance Fields task. The authors propose an innovative self-training approach to tackle the challenge of overfitting scenes with sparse viewpoints. The key idea is to refine the model iteratively by generating and using pseudo labels, allowing it to learn a more robust representation of the scene. A novel reliability estimation method has been proposed to identify which rays can be trusted and assist in the distillation process. The experimental results demonstrate state-of-the-art performance on multiple datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposal of a self-evolving framework for Neural Radiance Fields is innovative. The integration of a self-training approach into NeRF is a significant and original development.\n- The quality of work appears high. The proposed method of reliability estimation for distilling reliable and unreliable rays is well thought out, and its application in a self-training framework is a noteworthy achievement. \n- The paper is well-written with a clear and comprehensive explanation. The authors provided detailed derivations of their methodology, as well as thorough analysis and justification of design choices in the ablation study.\n- The results show that SE-NeRF improves the quality of rendered images and achieves state-of-the-art performance, which is a meaningful contribution to the novel view synthesis and 3D reconstruction fields."
            },
            "weaknesses": {
                "value": "- The authors mention various methods for distilling the knowledge of nearby reliable rays, but the specific difference in performance between these methods is not sufficiently discussed.\n- The experimental section could have benefited from additional comparisons against other few-shot learning methods or self-supervised training methods. For example, SparseNeRF [1], SimpleNeRF [2], and Vip-NeRF [3].\n- The authors mention that the performance of the model on the NeRF Synthetic dataset is highly affected by the randomly selected views, which indicates an aspect of fragility in the model. This limitation could have been discussed in more detail.\n\n[1] Wang, Guangcong, et al. \"Sparsenerf: Distilling depth ranking for few-shot novel view synthesis.\" ICCV 2023.\n[2] Somraj, Nagabhushan, Adithyan Karanayil, and Rajiv Soundararajan. \"SimpleNeRF: Regularizing Sparse Input Neural Radiance Fields with Simpler Solutions.\" SIGGRAPH Asia 2023.\n[3] Somraj, Nagabhushan, and Rajiv Soundararajan. \"ViP-NeRF: Visibility Prior for Sparse Input Neural Radiance Fields.\" SIGGRAPH 2023."
            },
            "questions": {
                "value": "- Could the authors elaborate on their choice of VGGNet for estimating the reliability of pseudo labels? How would using another architecture affect the estimation?\n- How does the method perform with larger or more complex datasets?\n- Could the authors clarify how they determine that some viewpoints are reliable and others are not? How generalizable is this approach to diverse real-world cases with more pronounced viewpoint variety?\n- How does the magnitude of performance improvement compare between the first iteration and subsequent iterations? Does the model reach a plateau after a certain number of iterations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission953/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission953/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission953/Reviewer_qP3j"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission953/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698212381981,
        "cdate": 1698212381981,
        "tmdate": 1700662928379,
        "mdate": 1700662928379,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JNsQOs9a6f",
        "forum": "TW0MVSflg5",
        "replyto": "TW0MVSflg5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission953/Reviewer_BBPH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission953/Reviewer_BBPH"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a teacher-student network designed to address the neural rendering task using a limited set of training view images. The authors present a technique for estimating ray reliability. Utilizing this estimation, they perform ray distillation and subsequently iterate the process multiple times, augmenting the training view images with pseudo ground truth."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The teacher-student idea for few-shot NeRF can inspire many follow-up works.\n2. The authors provide many detailed analysis in the appendix, which can help understand the method better."
            },
            "weaknesses": {
                "value": "1. The method of estimating ray reliability raises concerns. The authors use a 2D-CNN to obtain super-pixel features, meaning that the features for similarity computation are derived from a pixel region, not individual pixels. This approach seems misaligned with the NeRF setting, which relies only on per-pixel information instead of per-region data. Such a discrepancy makes the ray reliability estimation seem less accurate and contradicts the proposed method.\n\n2. There's a noticeable absence of an ablation study for the unreliable ray distillation. The proposed method for this distillation isn't entirely convincing. An ablation study demonstrating the effects of removing this module would have been beneficial in validating its effectiveness.\n\n3. The performance improvement appears to be marginal. According to Table 1, the PSNR value for the NeRF Synthetic dataset and NeRF base model only saw a slight enhancement from 19.38 to 20.53. Given this quality level, the baseline model's performance is somewhat volatile, potentially fluctuating between 2-4dB with changes like altering the selected view. The paper itself even acknowledges this. A more significant achievement would have been, for example, if the authors could elevate the performance from 30dB to 32dB.\n\n4. The research lacks comparisons to other few-shot NeRF models. Several methods, including PixelNeRF, MSVNeRF, and IBRNet, address the few-shot neural rendering challenge. Integrating the proposed method with these established works would have provided valuable insights into its effectiveness. Unfortunately, such experiments are absent.\n\n5. There's a discrepancy in the results presented in two different tables. For the LLFF dataset, 3-view setting, and the K-plane baseline model, outcomes are documented in both Table 1 and Table 7. While the results for SE-NeRF(K-Planes) are consistent across the two tables (e.g., 16.30dB for the PSNR metric), the baseline model's results differ: Table 1 shows 14.18dB, while Table 7 indicates 15.77dB. This inconsistency raises questions about the data's accuracy."
            },
            "questions": {
                "value": "Please see the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission953/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698605511958,
        "cdate": 1698605511958,
        "tmdate": 1699636021752,
        "mdate": 1699636021752,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M35hKUGKR7",
        "forum": "TW0MVSflg5",
        "replyto": "TW0MVSflg5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission953/Reviewer_qLAL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission953/Reviewer_qLAL"
        ],
        "content": {
            "summary": {
                "value": "This work considers the problem of training a NeRF with sparse views. In this scenario, there are two issues: 1) the estimated cameras will cause errors; 2) the views are few and cannot support enough supervision. Taking these questions as consideration, this work presented a self-training strategy: it first train a NeRF directly, and then a consistency-based measurement is proposed to obtain ray reliability. Given reliability, the Nerf can be boosted using the reliable region to guide the training. The above procedure is conducted iteratively."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper raises an interesting problem and an interesting strategy to boost NeRF training from sparse views. \n- A new reliability estimation method is proposed, based on a consistency-based measurement. \n- The experiments verifies the effectiveness of the proposed strategy where the artifacts are reduced."
            },
            "weaknesses": {
                "value": "- The major issues of NeRF with sparse views are two aspects: 1) few constraints for optimization; 2) wrong camera estimations. But, I don't see any designs for camera correction. Evenly the reliable regions are detected, but the cameras are still wrong. More discussions on this are needed. \n\n- Another major concern is about the quality: although artifacts are reduced, the visual quality are still far from satisfactory, seeing from Fig 1, 4, and 5. I am wondering why we need such a self-training strategy. To me, sparse-view NeRF is a very challenging task, resorting to prior model might be a better way to involving self-training strategy."
            },
            "questions": {
                "value": "See weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission953/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698745258098,
        "cdate": 1698745258098,
        "tmdate": 1699636021673,
        "mdate": 1699636021673,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "r1bwIPUIiA",
        "forum": "TW0MVSflg5",
        "replyto": "TW0MVSflg5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission953/Reviewer_qNfa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission953/Reviewer_qNfa"
        ],
        "content": {
            "summary": {
                "value": "This paper tailors a self-training framework for NeRF reconstruction with few views, dubbed SE-NeRF. Technically, SE-NeRF iteratively optimizes NeRF parameters via reliability-aware pseudo-label supervision, which are generated by the teacher NeRF model obtained from the previous iteration. The reliability is computed by thresholding the feature similarity between epipolar correspondences. The reliable points are supervised directly using the teacher NeRF while the unreliable points are supervised by the Gaussian average over the adjacent rays."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The paper is clearly written and illustrated. The proposed method, which employs a self-training framework to maximize the utilization of training views, is not only intuitive but also well-motivated (Sec. 3.2).\n\n+ The self-training framework has been carefully tailored to the NeRF setting. The approach to adaptively estimate ray reliability and the supervision scheme for both reliable and unreliable rays is elegant, straightforward, and efficient to implement.\n\n+ The empirical improvements over the baseline methods are substantial (as shown in Tab. 2). The comprehensive ablation studies presented in Fig. 6 and Tab. 3 effectively establish the effectiveness of the iterative training and the two-fold supervision schemes employed in SE-NeRF. Furthermore, the appendix is well-prepared with necessary discussions and visualizations."
            },
            "weaknesses": {
                "value": "- A major concern arises from the apparent similarity to the existing work, Self-NeRF [1], which also employs a self-training framework in a few-shot setting, incorporating pseudo-label supervision and uncertainty estimation. Do authors acknowledge Self-NeRF as an independent concurrent work?\n\n- More details need to be provided especially for unreliable ray distillation. What is the formulation for $\\tilde{\\sigma}$ and what is the definition of the Gaussian mask and the associated hyper-parameters, such as the kernel size etc.? See more in Question section.\n\n[1] Bai et al., Self-NeRF: A Self-Training Pipeline for Few-Shot Neural Radiance Fields"
            },
            "questions": {
                "value": "1. What is the reason behind SE-NeRF generally achieving greater improvements on vanilla NeRF compared to K-Planes (as indicated in Tab. 2)?\n\n2. Would it be possible for the authors to provide results based on other NeRF representations, such as the more prevalent Instant-NGP [1] or Gaussian Splatting [2]?\n\n3. While the concept of estimating unreliable rays via adjacent reliable rays is intuitive, it becomes apparent that an unreliable ray might not find a reliable ray within a local region, as illustrated in Fig. 15. How does the approach handle supervision for an unreliable ray when the neighboring reliable rays form an empty set?\n\n4. Why is point-wise density only distilled rather than including color information? Can authors provide an ablation study on this technical design?\n\n\n[1] Muller et al., Instant Neural Graphics Primitives with a Multiresolution Hash Encoding\n\n[2] Kerbl et al., 3D Gaussian Splatting for Real-Time Radiance Field Rendering"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission953/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission953/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission953/Reviewer_qNfa"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission953/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698982052290,
        "cdate": 1698982052290,
        "tmdate": 1699636021584,
        "mdate": 1699636021584,
        "license": "CC BY 4.0",
        "version": 2
    }
]