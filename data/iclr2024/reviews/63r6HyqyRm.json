[
    {
        "id": "77sFoz3Vyb",
        "forum": "63r6HyqyRm",
        "replyto": "63r6HyqyRm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4782/Reviewer_gdiQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4782/Reviewer_gdiQ"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses the exploration of using large language models (LLMs) trained only with text to improve grammar induction in multimodal datasets. The approach, called LLM-based C-PCFG (LC-PCFG), outperforms previous multimodal methods and achieves state-of-the-art performance in grammar induction for various multimodal datasets. Compared to image-aided grammar induction, LC-PCFG shows remarkable improvement, with significantly fewer parameters and faster training speed. In three video-assisted grammar induction benchmarks, LC-PCFG outperforms the prior state-of-the-art, with 8.8\u00d7 faster training. These findings suggest that text-only language models may contain visually grounded cues that assist in grammar induction in multimodal contexts. The results also highlight the importance of establishing a strong vision-free baseline for evaluating the benefits of multimodal approaches."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper proposed to use powerful LLM-based embeddings to improve multimodal grammar induction.\n- The proposed LC-PCFG outperforms the prior state-of-the-art methods.\n- The experiments are sufficient. The writing and presentation are clear and easy to read."
            },
            "weaknesses": {
                "value": "-\tThe title (\u201cvision-free\u201d, \u201cmultimodal\u201d) is confusing because the proposed LC-PCFG requires only textual inputs.\n-\tThe major concern is that the proposed method is based on a pre-trained model, which imports billions of extra training data. It\u2019s not fair to compare with the method without pre-training. For example, the original implementation of C-PCFG takes a CNN-based network for text embedding and the version used in this paper takes a LSTM network, both learned from scratch on the task without pre-training. If the author could provide the results of a reproduced version with pretrained embeddings, the improvement will be more convincing. \n-\tI\u2019m not sure if the using of pretraining model will weaken the point on \"unsupervised\" grammar induction (because the pre-training language model now may require amount of corpus and multi-task objectives). Could the author explain this issue.\n-\tI guess the \u201c#Param\u201d column in Table 1 should be \u201c#Training Param\u201d. The pre-training parameters (OPT-7B) are not included. The same problem in Table 4, i.e. the embedding and training hours do not include the pre-training stage.\n-\tCould the author provide the performance of each type of label (NP, VP\u2026)?\n-\tTo sum up, it seems that the improvement totally comes from the LLM-based embeddings. My concern is that if the LLM already has powerful ability such as understanding syntax knowledge and even high-level semantic knowledge, why we use it on a very basic task. Therefore, research motivation should be clarified.\n-\tLimitations should be discussed somewhere."
            },
            "questions": {
                "value": "see weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4782/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698566740954,
        "cdate": 1698566740954,
        "tmdate": 1699636460495,
        "mdate": 1699636460495,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cfIZxef0lP",
        "forum": "63r6HyqyRm",
        "replyto": "63r6HyqyRm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4782/Reviewer_5YMo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4782/Reviewer_5YMo"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the problem of compound PCFG (C-PCFG; Kim et al., 2019) induction with features from large language models (LLMs), and claims such an approach could serve as a vision-free baseline for multimodal grammar induction models."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The presentation is very clear, and the paper is very easy to understand."
            },
            "weaknesses": {
                "value": "The motivation for this work does not make any sense to me for the following three reasons.\n\n1. The comparison between the LLM-based approach and existing multimodal grammar induction work is unfair regarding data availability and cognitive plausibility.\nThe primary goal of the multimodal grammar induction work, critiqued in this paper, is not leaderboard chasing.\nThe multimodal setting provides a simplified environment to model the syntax acquisition process of humans, and the amount of training data should be strictly limited to what humans can access in the language acquisition processes.\nNo one acquires their first language by solely reading trillions of words and predicting the next token, like how LLMs are trained.\nThe comparison between an LLM-based C-PCFG and multimodal grammar induction is unfair regarding data exposure.\n\n2. There may be data contamination issues in LLM training.\nThe training data of LLMs are not curated to exclude constituency parse trees.\nThat is, although they are not explicitly trained with the objectives used in supervised constituency parsing, they are exposed to the specific supervision and, therefore, should not be considered as fully unsupervised grammar *induction*.\nAs an alternative, I suggest the authors try prompting LLMs (such as ChatGPT or LLaMa-2) using the following templates:\n\n    > Q: In PTB style, what is the constituency parse tree of the following sentence? \\\n    [SENTENCE] \\\n    A:\n\n    With some simple post-hoc checking (e.g., ensuring the output sentence is faithful to the input), this approach will hopefully result in even better results reported in this paper.\n    Does this mean LLMs successfully *induce* the grammar? The answer is absolutely no. They are learning from explicit supervision in the training set.\n\n3. I can't see why the authors specifically target multimodal grammar induction and not compare it to text-based grammar induction results.\nAs a background, DIORA (Drozdov et al., NAACL 2019; not even cited in this paper as a representative recent work in grammar induction) used ELMo, one of the first-generation \"LLMs,\" for the initialization of word embeddings.\nI suggest the authors check out DIORA and its follow-up work and re-consider the claim.\n\nIn addition to motivation, recent work on text-only grammar induction is almost entirely missing.\nPlease at least check out the following ones, and I suggest the authors to do a more comprehensive literature research using these as starting points:\n- Drozdov et al. Unsupervised latent tree induction with deep inside-outside recursive autoencoders. NAACL 2019\n- Drozdov et al. Unsupervised parsing with S-DIORA: Single tree encoding for deep inside-outside recursive autoencoders. EMNLP 2020\n- Jin et al. Variance of average surprisal: a better predictor for quality of grammar from unsupervised PCFG induction. ACL 2019\n- Kim et al. Unsupervised Recurrent Neural Network Grammars. NAACL 2019"
            },
            "questions": {
                "value": "My only questions are about the motivation of this work (details above). It would be great if the authors could justify their motivation by addressing the comments raised above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4782/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4782/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4782/Reviewer_5YMo"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4782/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698790122850,
        "cdate": 1698790122850,
        "tmdate": 1699652891768,
        "mdate": 1699652891768,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vdH4JvOgin",
        "forum": "63r6HyqyRm",
        "replyto": "63r6HyqyRm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4782/Reviewer_qYkX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4782/Reviewer_qYkX"
        ],
        "content": {
            "summary": {
                "value": "This work proposes an unsupervised text parsing with vision information using large language model without any vision information. Experimental results comparing other vision aware models, the proposed method achieve better results by simply leveraging representations from a large language model using compound probabilistic context free grammars."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The work presents systematic comparisons with vision aware unsupervised parsing and demonstrates the gains of the proposed approach."
            },
            "weaknesses": {
                "value": "* Vision-free unsupervised text parsing for a vision aware task is merely unsupervised text parsing. Thus, this work should compare with various latest unsupervised methods for a fair comparison with and without the use of the representations from large language models:\n\n  - Yikang Shen, Shawn Tan, Alessandro Sordoni, and Aaron Courville. Ordered neurons: Integrating tree structures into recurrent neural networks. In ICLR 2019.\n  - Andrew Drozdov, Patrick Verga, Mohit Yadav, Mohit Iyyer, and Andrew McCallum. Unsupervised latent tree induction with deep inside-outside recursive auto-encoders. In NAACL-HLT 2019.\n  - Steven Cao, Nikita Kitaev, and Dan Klein. Unsupervised parsing via constituency tests. In EMNLP 2020.\n  - Jiaxi Li and Wei Lu. Contextual distortion reveals constituency: Masked language models are implicit parsers. In ACL 2023.\n\n* This work should investigate vision aware large language models, e.g., mPLUG-Owl, as a comparison if the major focus is a baseline for vision aware unsupervised parsing."
            },
            "questions": {
                "value": "See the weakness above. I'd rather like to know if the authors run experiments comparing various unsupervised parsing using only textual information and vision aware language models."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4782/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816252869,
        "cdate": 1698816252869,
        "tmdate": 1699636460302,
        "mdate": 1699636460302,
        "license": "CC BY 4.0",
        "version": 2
    }
]