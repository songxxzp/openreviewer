[
    {
        "id": "XPMLja1alv",
        "forum": "7VVGO0kuuY",
        "replyto": "7VVGO0kuuY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_miEU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_miEU"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces an object-oriented causal dynamics model (OOCDM) that leverages the hierarchical structure among state and action variables. Specifically, state and action variables are decomposed into a number of object variables, and the objects that belong to the same class share the same causality and transition function. Assuming that these object structures are given as prior knowledge, OOCDM learns the forward dynamics (i.e., transition function) and causal relationships between objects and fields. As OOCDM leverages the known hierarchical structure (i.e., objects and classes), it is more computationally efficient, and robust compared to previous CDMs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper tackles an important problem and the motivation is clear. It is known that causal dynamics models (CDMs) are more robust compared to traditional dense dynamics models and it is important to improve the scalability of CDMs for their wider applicability.\n- The formulation of OOCDM which extends previous CDMs to object-oriented MDP representations seems novel, as far as I know.\n- The authors provide experimental results on larger-scale environments compared to prior works."
            },
            "weaknesses": {
                "value": "First, the manuscript is hard to follow due to the heavy notations and too much jargon, which could be more simplified. Second, the assumptions need more explanation. The *result symmetry* (eq. 3) is understandable, but the *causation symmetry* (eq. 4) does not seem to always hold. It would be better if the authors provide scenarios where this assumption holds and does not hold, and explain why it is reasonable to make the assumption.\n\nFinally, I have a concern regarding the experiments, e.g., the evaluation and interpretation of the results, which is also related to the main claim of the paper. Specifically, the authors claim that OOCDM outperforms prior CDMs in terms of (a) computational efficiency, (b) causal discovery, and (c) generalization of model-based RL. For (a), which is shown in Table 2, it is reasonable but also somewhat obvious since OOCDM leverages the hierarchical structure of the variables and common causal relationships shared with different objects. My major concern is at (b) and (c), which I elaborate on below.\n\n- Evaluation of causal discovery is not thorough. The performance of causal discovery is typically measured as structural hamming distance (SHD), or sometimes AUC and F1 score. The term \u201caccuracy\u201d in table 1 is confusing and details on how it is evaluated are missing.\n- OOFULL, which is the ablation of OOCDM without causal discovery, uses fully-connected bipartite graph. In other words, it only leverages the (A) *structural information* (objects belonging to the same class share the same dynamics), without the (B) *causal relationship* between variables. As shown in Table 3-4, OOFULL outperforms other CDMs. Given that CDMs work fairly well in causal discovery (as shown in Table 1), this implies that **(A) structural information (how variables are grouped with objects and classes) is the major contribution** to the performance gain of OOCDM. This poses additional questions, e.g., why and how does OOFULL (which is non-causal) generalize better than CDMs? It seems the assumptions are too strong (i.e., more important than causality). Also, how does the accurate understanding of causality lead to the improvement of OOCDM compared to OOFULL?\n- CDMs work fairly well in causal discovery (Table 1), but they fail on o.o.d data, as shown in Table 3. This is contrary to the findings of prior works (CDL, GRADER) and requires explanations.\n- In the evaluation of model-based RL (Table 4), the dynamics models are trained using only offline data. However, prior work (GRADER) suggests that it achieves better performance (in terms of both causal discovery and RL) when using online data. I would appreciate it if the authors could provide a justification for this."
            },
            "questions": {
                "value": "- Attention-based architecture is used to handle varying numbers of objects. In the experiments, does the number of objects vary in the same trajectory? If yes, then how do baselines handle varying input dimensions?\n- How is accuracy in Table 1 evaluated?\n- Table 1 shows that GRADER performs worse in causal discovery compared to other methods. This is counter-intuitive given that GRADER uses explicit conditional independence tests, unlike others.\n\n**Minor (mostly about notations and typos)**\n\n- Why does it need two separate notations in Def. 2? For example, $C_k\\left[U \\rightarrow V^{\\prime}\\right]$ can be written as $C_k\\left[C_k \\cdot U \\rightarrow V^{\\prime}\\right]$. It would be much easier to follow the paper with simple and consistent notations (maybe just write as $C_l \\cdot U \\rightarrow C_k \\cdot V'$?)\n- In eq. 4, $O_p, O_q$ should be $O_x, O_y$\n- The notation $f(\\cdot\\mid \\mathbf{O}; \\mathbf{U}_{-O}; \\mathcal{G})$ in Eq. 5 (as well as Eq. 8-10) is confusing. Isn\u2019t it basically the same as $f(\\cdot\\mid \\mathbf{U}; \\mathcal{G})$? Also, notations in Eq. 8-10 are not consistent with Eq. 5.\n- In Sec 4.3, it says \u201c$\\mathcal{G}_1$ is the full OOCG\u201d. To my understanding, $\\mathcal{G}_1$ is a fully-connected bipartite graph and is not OOCG.\n- Table 7, description of $O.\\mathbf{S}$: action \u2192 state\n- Ground-truth causal graph provided in the appendix is hard to understand (the actual graph or adjacency matrix would be better)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Reviewer_miEU",
                    "ICLR.cc/2024/Conference/Submission4429/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4429/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698558900882,
        "cdate": 1698558900882,
        "tmdate": 1700471837324,
        "mdate": 1700471837324,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZjOF2Vrg9L",
        "forum": "7VVGO0kuuY",
        "replyto": "7VVGO0kuuY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_dZfY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_dZfY"
        ],
        "content": {
            "summary": {
                "value": "The authors study the combination of causality and reinforcement learning by providing an extension to the setup of causal dynamics models through the lens of object oriented programming, which essentially provides a sharing of information based systems where the causal dynamics are shared across objects that belong to the same class. Further, the authors provide a learning mechanism based on key-value attention which enables generalization to arbitrary numbers of objects as long as the underlying classes remain the same. The authors\u2019 experiments highlight that such an object oriented causal dynamics model (OOCDM) outperforms existing approaches along various fronts like causal discovery, performance accuracy and generalization capacity."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The authors are tackling a quite interesting and relevant problem and the approach used is well motivated and cognitively inspired. While it is studied for causality and RL approaches, it has been sparsely leveraged when combining the two fields in trying to model the causal dynamics of the environment itself and hence makes this work a very interesting and worthwhile read.\n- It is a natural extension to CDL which also further reduces the computations required owing to sharing of information between objects of the same class.\n- The authors test out on a variety of domains ranging from causal discovery and prediction accuracy as well as combining it with planning and highlight that the proposed approach is competitive and lucrative."
            },
            "weaknesses": {
                "value": "- While the work is quite interesting and very relevant to the field, the writing itself could use some work. The notation is not clearly specified over the paper and the distinction between bold and normal capital letters is hard to understand (eg. for U). For example, in Section 3.1, what does the random variable S represent? What happens if the transitions are time-depdendent?\n- The difference between $\\mathcal{F}$ and $\\mathcal{F}_s$ is not explained at all, and just directly used in Definition 2.\n- In Section 4.2, when the authors propose a model for implementing the prediction function, while the approach satisfies causation symmetry, it does not treat the dynamics induced by different kinds of classes in the same manner as opposed to differently. For example, the attributes $C_1.U_1$ should impact the predictor differently from the attributes $C_2.U_2$, while the key-value attention mechanism would imply using the same mechanism. Could the authors clarify this?\n- The authors should also take some space to explain the fundamentals of CIT / CMI methodology, and can then point to the Appendix for further clarity. However, without some background on CIT / CMI as well as how gradient based learning can be used to learn the graph structure (Equation 12), it is hard to follow the paper since graphs are discrete objects and gradient ascent based procedures only work on continuous spaces.\n\nFor the most part, my main qualms about the work are regarding the clarity and completeness of writing in the main draft. While the Appendix does contain a lot of details, I felt that there was some key information missing in the main draft and the preliminary section which makes the paper fairly dense and hard to read. There are also a few related works that the authors are missing, which I will mention below. I think clarifications on the math and making the notation and related work clearer in the main draft would go a long way, and I would be happy to increase my score if the changes were made.\n\n*Mittal, S., Bengio, Y., & Lajoie, G. (2022). Is a modular architecture enough?. Advances in Neural Information Processing Systems, 35, 28747-28760.*\n\n*Locatello, F., Weissenborn, D., Unterthiner, T., Mahendran, A., Heigold, G., Uszkoreit, J., ... & Kipf, T. (2020). Object-centric learning with slot attention. Advances in Neural Information Processing Systems, 33, 11525-11538.*\n\n*Mittal, S., Lamb, A., Goyal, A., Voleti, V., Shanahan, M., Lajoie, G., ... & Bengio, Y. (2020, November). Learning to combine top-down and bottom-up signals in recurrent neural networks with attention over modules. In International Conference on Machine Learning (pp. 6972-6986). PMLR.*"
            },
            "questions": {
                "value": "- After equation 1, the authors state that they assume the underlying graph is unknown. What about the probability distribution, is that known or also unknown?\n- What does it mean that the state variables transit independently? It would be nice if the authors could write it down in math, as it is not immediately clear for people who do not work on RL or the FMDP setup. I understand it is in the appendix but it would be nice to spell it once in the main text.\n- In equation 2, does the symbol used represent conditional independence, or the negative of that because it is not clear from the statement under the equation.\n- How does the theorem imply that testing every edge requires O(n) complexity?\n- In Equation 3, why does the distribution not depend on $\\mathbf{O}_{i+2}$ and so on? Further, what is the benefit of using semicolon in describing the conditioning, and why is $O_i.(\\mathbf{S}\u2019)$ dependent on $\\mathbf{O}_i$ and not $\\mathbf{O}_i.\\mathbf{S}$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Reviewer_dZfY",
                    "ICLR.cc/2024/Conference/Submission4429/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4429/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698629624470,
        "cdate": 1698629624470,
        "tmdate": 1700491273117,
        "mdate": 1700491273117,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VqnYNyvlge",
        "forum": "7VVGO0kuuY",
        "replyto": "7VVGO0kuuY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_LMvE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_LMvE"
        ],
        "content": {
            "summary": {
                "value": "This paper discuss the current progress of learning and applying Causal Dynamics Models in training RL agents. They note that challenges arise in large-scale RL environments with vast number of objects and complex causal dependencies. Inspired by humans' object-oriented (OO) perspective for task perception, the authors developed the Object-Oriented Causal Dynamics Model (OOCDM). OOCDM allows sharing causalities and model parameters among objects from the same class, thus enhancing causal discovery and learning efficiency in RL. The proposed modified Causal Dynamics Learning (CDL) paradigm accommodates varying numbers of objects. Experimental results demonstrate the performance of OOCDM in terms of causal graph accuracy, prediction accuracy, generalization, and computational efficiency."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) the authors formally defined the problem of object oriented learning in RL from a causal perspective, which paved the way for future work.\n(2) the authors identified the core problem of the current causal dynamics model learning algorithms, which is the poor efficiency in the face of mass variables. The proposed method alleviated this problem to some extent with intuitive explanations and thorough justifications.\n(3) the writing is clear and easy to follow."
            },
            "weaknesses": {
                "value": "(1) Dynamics bayesian networks are rather limited rendering them unsuitable to model causal mechanisms. Especially when there is a need for cross layer inference, i.e., identifying the effect of an intervention from observational data. For more information, please see \"On Pearl\u2019s hierarchy and the foundations of causal inference.\" in Probabilistic and Causal Inference: the works of Judea Pearl. In the specific scenario like the one define in this paper, it would be fine (Markovian, no confounders). But still, I would suggest the author use more rigorous causal tools to model the problem.\n\n(2) In section 3.2, when the authors started to define OOMDP, they claim that \"following (a Factored MDP paper), we formulate the task as an Object-Oriented MDP (OOMDP)...\". The way of presenting the concept totally ignores a seminal previous work that proposed OOMDP already [1]. Interestingly, the authors also referred to this paper in the related works section but seem to forget it here in the main text.\n\n(3) In section 4, the core assumption of this paper, \"causation symmetry\", which assumes that objects from the same class have the same causal effect on other objects, is too strong to be practical. Consider a system where three objects from the same class are linked one by one by springs in a line (obj1 --spring-- obj2 --spring-- obj3). For the causal effect of pulling obj2/obj3 on obj1, they are not interchangeable due to the existence of springs. \n\n(4) The proposed method requires manual construction of the OOMDP representation (obj classes, attributes fields, etc.). When there are truly a vast number of classes, this would be a new bottleneck for scaling. This fact, to some extent, hinders the authors' original goal of improving the efficiency of current CDMs learning methods. Similarly, when each object belongs to a distinct class, the proposed method might be even worse due to those detailed object fields.\n\n(5) For the experiments, the authors seem to be using a factored state space observation space. If it's not a high-dimensional pixel one, model-free methods are already competitive enough to solve state space observations problems. I doubt if there is really a strong need to introduce the extra complexities of the object oriented learning here. In another word, I do believe there are values in the OO representation and the proposed method even under the strong assumption of \"causation symmetry\", but it would be better demonstrated via high-dimensional challenging tasks.\n\n[1] Diuk, Carlos, Andre Cohen, and Michael L. Littman. \"An object-oriented representation for efficient reinforcement learning.\" Proceedings of the 25th international conference on Machine learning. 2008."
            },
            "questions": {
                "value": "(1) Could you elaborate the potential solution if people plan to apply your methods to environments with pixel observations?\n\n(2) Is there a more principled way of defining the object classes and attribute fields?\n\n(3) How would you compare your work with \"Causal dynamics learning for task-independent state abstraction.\" from ICML 22'? Is your proposed method significantly more efficient than theirs?\n\nI will consider change my rating if those questions and weaknesses are properly handled."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Reviewer_LMvE",
                    "ICLR.cc/2024/Conference/Submission4429/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4429/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722650232,
        "cdate": 1698722650232,
        "tmdate": 1700671072710,
        "mdate": 1700671072710,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9aokoJp5VB",
        "forum": "7VVGO0kuuY",
        "replyto": "7VVGO0kuuY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_mQjQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_mQjQ"
        ],
        "content": {
            "summary": {
                "value": "This manuscript introduces a comprehensive framework for object-oriented reinforcement learning (OORL), utilizing an object-oriented causal dynamic model to capture the intricacies of the OORL environment. The framework adeptly simplifies complex RL scenarios through a decomposition based on object types, ensuring that similar objects share parameters and causality characteristics. This integration of inductive biases such as causal symmetry and result symmetry enhances the model\u2019s capability to represent complex scenarios effectively. The authors provide the framework to learn the corresponding model and the effectiveness of the proposed model is substantiated through a set of empirical experiments.\n\nOverall, this work stands out as an effective and logically sound approach to modeling the OORL environment, with a particular emphasis on causality. It is poised to make significant contributions to the field. Despite these strengths, there are certain elements of the method, presentation, and experimental design that will be further clarified by the authors. Addressing these points is crucial for a comprehensive understanding of the work. Given these considerations, my initial inclination is to recommend a borderline accept."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "**[Motivation and General Idea]** The manuscript establishes a robust motivation, addressing the critical challenge of inefficiencies prevalent in Causal Dynamic Models (CDMs) within complex reinforcement learning (RL) scenarios. The authors\u2019 choice to navigate RL in the context of multiple objects and categories is judicious and aligns well with the overarching theme of the paper.\n\n**[Proposed Framework]** The architectural design of the proposed framework is simple to follow and technically sound. The framework extends the classical paradigms of Object-Oriented Markov Decision Processes (OO-MDP) and Relational Markov Decision Processes (Relational MDP), incorporating causality as a vital inductive bias. This strategic design choice facilitates an empirically grounded solution, paving the way for efficient causal discovery in settings populated with numerous objects."
            },
            "weaknesses": {
                "value": "I listed the weaknesses and questions here. I am also a reviewer of the previous version of this paper. Most of my concerns have been addressed by the authors. However, some of them are still a bit unclear to me. \n\n- **[Definition of the local causality]** \n\nWhen we typically mention local causality, we refer to the case where the causal edges vary, as illustrated in Figure 2 in [1]. In this paper, when the authors mention local causality, it refers more to the causal graph of transitions for individual category objects. I think it is better to give a clarification in the revised version.\n\n- **[About potential relational interactions]**\n\nWhile the presented work demonstrates a comprehensive approach to object-oriented reinforcement learning, it appears to omit direct consideration of interactions between objects or entities within the framework. Given the prevalence of interactions among objects in real-world reinforcement learning scenarios, particularly in tasks involving object manipulation, this seems to be a significant aspect to address. Could the authors shed light on whether the framework is capable of learning and accounting for these interactions? Insights on how the model might be extended or adapted to incorporate direct interactions among objects would be greatly beneficial, as it would enhance the applicability of the approach to a wider array of real-world scenarios.\n\n- **[Potential to extend to image domains by combing the OCR models]**\n\nIn light of works such as [1-3], which integrate Object-Centric Representations (OCR) models into the learning process, the authors might consider incorporating similar OCR models equipped with permutation invariant modules at the beginning of their pipeline. This would enable the extraction of object representations directly from image data, making the method more scalable and applicable to a broader range of real-world scenarios.\n\n*References*\n\n[1] Pitis, Silviu, Elliot Creager, and Animesh Garg. \"Counterfactual data augmentation using locally factored dynamics.\" Advances in Neural Information Processing Systems 33 (2020): 3976-3990.\n\n[2] Yoon, Jaesik, et al. \"An investigation into pre-training object-centric representations for reinforcement learning.\" arXiv preprint arXiv:2302.04419 (2023).\n\n[3] Zadaianchuk, Andrii, Maximilian Seitzer, and Georg Martius. \"Self-supervised visual reinforcement learning with object-centric representations.\" arXiv preprint arXiv:2011.14381 (2020).\n\n[4] Kossen, Jannik, et al. \"Structured object-aware physics prediction for video modeling and planning.\" arXiv preprint arXiv:1910.02425 (2019)."
            },
            "questions": {
                "value": "I listed the weaknesses and questions together in the above section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Reviewer_mQjQ"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4429/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698784105157,
        "cdate": 1698784105157,
        "tmdate": 1699636417419,
        "mdate": 1699636417419,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8lCfQfhA2q",
        "forum": "7VVGO0kuuY",
        "replyto": "7VVGO0kuuY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_6VtU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4429/Reviewer_6VtU"
        ],
        "content": {
            "summary": {
                "value": "This paper considers causal dynamics learning in an object-oriented environment, which is modeled using Object-oriented (OO) MDP. Based on the setting, the authors define OO causal graph that illustrates how attributes of different entities influence other attributes of possibly different entities at the next step. With a measure of conditional dependence (CMI) and flexible model (attention) for conditional probability involving OO, the authors demonstrated the usefulness of OO approach to causal dynamics modeling."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The use of OO concept in causal dynamics learning seems a very well-motivated work where real-world environments are naturally multi-agent setting with heterogeneous players.\n\n- I guess the use of attention to handle a varying number of objects\u2019 attributes seems a clever idea. (Is this idea already adopted in other OO related research?, The authors only left a figure and a single sentence before Section 4.3)"
            },
            "weaknesses": {
                "value": "As a researcher who worked on causal discovery in relational data and causal dynamics learning, this combination seems interesting. However,\n\n- The combination seems a bit not nontrivial in a sense that, while the fomulation is a bit complicated but, at a fundamental level, we just generalize causal dynamics learning to an object-oriented version, and apply the idea of conditional independence. Causal dynamics learning or causal discovery is just a transition probability between the two time steps, and we replace probabilities of random variables to represent probabilities among attributes of objects. We refine variables to consider only the relevant ones.\n\n- This OO causal graph or causal discovery is not a new concept (see Marc Maier and Prof. David Jensen (UMASS)\u2019s work on relational causal discovery), which is a more general setting not just t-1 and t. Temporal version is also proposed (Marazopoulou et al. Learning the Structure of Causal Models with Relational and Temporal Dependence, UAI 2015) . There is no special needs to class-level local/global causality."
            },
            "questions": {
                "value": "- Regarding \u201cScalability\u201d, do you mean this part \u201cThis causality sharing greatly simplifies causal discovery and improves the readability of CGs in large-scale environments. \u201c in page 4? If so, isn\u2019t this an already existing result in relational causal discovery? Otherwise, where does the claim of scalability come from?\n=========\nafter the discussion, I see that the paper has certain merits (introducing OO into RL) and raising my rating from 5 to 6."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4429/Reviewer_6VtU"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4429/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698919645365,
        "cdate": 1698919645365,
        "tmdate": 1700527438893,
        "mdate": 1700527438893,
        "license": "CC BY 4.0",
        "version": 2
    }
]