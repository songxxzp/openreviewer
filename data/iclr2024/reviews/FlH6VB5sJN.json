[
    {
        "id": "VOEkBhI7wr",
        "forum": "FlH6VB5sJN",
        "replyto": "FlH6VB5sJN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_Chwq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_Chwq"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a new architecture for sequence modelling, based on multicompartment neuron dynamics. They then develop a method for parallel training of these systems and apply them to several benchmark tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The experimental results seem very strong, significantly outperforming previous methods. In addition, the figures are clear and help the reader with understanding the content. Lastly, parallelizing the training of such spiking multi-compartment models in the temporal dimensions is novel (to my knowledge) and can be potentially impactful."
            },
            "weaknesses": {
                "value": "**Soundness**\n\nOne of the main contributions of the paper, the parallel implementation of the algorithm, seems to hinge on the fact that they set beta_{n, n-1}. What is the effect of this on the neuronal dynamics? Can this model still be considered biophysically realistic?\n\n**Clarity**\n\nMany parts of the paper are presented in an overly convoluted way. I believe that this paper would largely benefit from moving math that is not essential to understanding the context of the paper to the appendix, for example equations 17, 18, 19.\n\nIn addition, it would be valuable if the authors attributed a biophysical meaning to their learnable parameters. \n\nFinally, I fail to understand where equation 14 comes from (although I am not exactly from the field, maybe it is clear to other reviewers).\n\n**Novelty**\n\nI believe that the claims on novelty for the multicompartment model are a bit over-stated. At the very least should the authors cite some of the (decades of) work on multicompartment modelling and its numerical implementations (starting from Hines 1984). The voltage update equations (apart from the non-linear reset) are identical to those papers, and I think this should be clarified."
            },
            "questions": {
                "value": "See questions in the \"weaknesses\" section.\n\nPage 6: I do not understand this sentence: `we force vs to reset to a level below the firing threshold, which bears closer resemblance with biological observations.` Why does this have closer resemblance to biological observations? Also closer than what other mechanism?\n\nLastly, the authors claim (even in the abstract) that their work is motivated by a cable model of cable model of hippocampus pyramidal neurons. Given that the model they eventually use is a 5-compartment cable without any particular dynamics, this choice of model seems extremely specific. What exactly is the reason to claim that the model is in any way \"hippocampal\" or even \"pyramidal\"?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5407/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5407/Reviewer_Chwq",
                    "ICLR.cc/2024/Conference/Submission5407/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5407/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698528307863,
        "cdate": 1698528307863,
        "tmdate": 1700396496895,
        "mdate": 1700396496895,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "u4bzJQWiGh",
        "forum": "FlH6VB5sJN",
        "replyto": "FlH6VB5sJN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_kRbB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_kRbB"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes the parallel multi-compartment spiking neuron (PMSN). The PMSN has n compartments, and only the last compartment can fire and reset. Thus, the neuronal dynamics of the first (n - 1) compartments can be paralleled easily. For the last compartment, the soft reset and the floor function are combined, which parallelizes the neuronal dynamics with reset. The performance and energy estimation are validated on temporal datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Compared with the previous work PSN (Fang et al., 2023) which removes the neuronal reset, the PMSN can be parallelized with the neuronal reset. The ablation experiments show that the removal of neuronal reset decreases task performance.\n\n2. The experiment results on sequential CIFAR are high, showing the advantage of the PMSN."
            },
            "weaknesses": {
                "value": "In section 5.3, only the speeds of serial and parallel implementation of the PMSN are compared. \n\nThe accuracy of the ImageNet dataset, which is an important benchmark for deep SNNs, is not reported."
            },
            "questions": {
                "value": "Can the authors provide a speed comparison between the PSN and the PMSN?\n\nWhat are the theoretical FLOPs and memory consumption of the PMSN? I suggest that the authors provide a comparison between these two neurons. It would be better if a comparison between the memory consumption during training of an SNN with two neurons is provided."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5407/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698645479262,
        "cdate": 1698645479262,
        "tmdate": 1699636548209,
        "mdate": 1699636548209,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M3NgLlK99P",
        "forum": "FlH6VB5sJN",
        "replyto": "FlH6VB5sJN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_9iDX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_9iDX"
        ],
        "content": {
            "summary": {
                "value": "The authors develop a new multi-compartment spiking neural model,\nwhich is can be efficiently computed on GPUs, because 1) feed-forward\narchitecture is assumed, so that generated spikes at one time do not\neffect the membrane potential in future and 2) the spiking activity is\ndecoupled from the membrane potential of all but the last compartment.\nThe authors show how the equations can be efficiently integrated and\ncompute on GPUs (as membrane potential evolution is just a linear\nfilter of the inputs). They compare the results on benchmarks\nrequiring long temporal integration of information, where typical SNNs\n(in particular feed-forward SNNs based on simple\nleaky-integrate-and-fire neurons) struggle, and show that the richer\ncompartmental dynamics indeed can capture long term information."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Overall, it is a solid paper that suggests a new neuron model based on\ncompartments for SNNs trained with SGD, and shows in detail how to efficiently implement the\nsimulation in forward, backward, and gradient update. The idea of\ndendritic computing is not new, however, it is largely restricted to\nbiological spiking networks instead of SNNs.\n\n* Since the added dynamics is at the neuron-level (instead of synapse\nlevel), and its efficient implementation, the additional computational\ncost for simulating (or deploying on neuromorphic hardware) is\nmanageable."
            },
            "weaknesses": {
                "value": "* The\nimplementation seems to require feed-forward structure as well as\npositive inputs, which seems quite restrictive (in particular the\nlatter).\n\n* The neuron model does not seem to\nimprove the benchmark results dramatically over other approaches in\nall tasks (ie recurrent RNNs are similar for S-MNIST) and it thus\nremains open how useful the model will be."
            },
            "questions": {
                "value": "* I don't follow why one can assume that $I(t)$ is always positive for\nthe ``parallel implementation of the output compartment with\nreset''. In typical SNNs, the input current is given by $I(t)=WS(t-1)$\n(without a synapse model) and the weights are positive or negative\nreal numbers, so in general, the inputs *can* be negative. Isn't that\nassumed here? However, if negative inputs are allowed, then the floor\nof the accumulated input with the threshold $\\theta$ (in Eq 15) will\nnot result in the number of spikes over the time period. Maybe I am\nmissing something here. If only positive currents are allowed, it\nshould be discussed as it seems to be a major restriction. If so it\nwould be interesting to know what the impact of this step would be (on\nthe simulation speed) if not done in parallel to allow for negative\ncurrents.\n\n* It is not clearly stated whether the flux parameters and decay rates\nof and between the compartments are learned with SGD?\n\n* In the equations (eg Eq. 3) the neural indices are written as\nsuper-script ($v^{i}$) which is easily confused with power. Better to\nuse subscripts or write $v^{(i)}$ to avoid confusion."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5407/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5407/Reviewer_9iDX",
                    "ICLR.cc/2024/Conference/Submission5407/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5407/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772193910,
        "cdate": 1698772193910,
        "tmdate": 1700378238279,
        "mdate": 1700378238279,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kLTWZdoBjs",
        "forum": "FlH6VB5sJN",
        "replyto": "FlH6VB5sJN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_QBv1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_QBv1"
        ],
        "content": {
            "summary": {
                "value": "The authors define a multi-compartment spiking neuron model that is able to process signals of \"high temporal complexity\".  Importantly, this model accounts for the spike reset mechanism.  The Parallel Multi-Compartment Spiking Neuron is inspired by hippocampal pyramidal neurons and admits a formulation that facilitates parallel training on GPUs.  The authors demonstrate the model's advantages in terms of performance and complexity."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The model and the approximations/trade-offs made are well-presented and clear.  Capturing complex temporal sequences is also a useful property.  A GPU accelerated model is of course an advantage in the modern day with the ubiquity of such hardware."
            },
            "weaknesses": {
                "value": "The model is very specific, without any particular justification.  When one uses spiking networks, it is usually (in my experience) because one wants to model a spiking neuron system, but then choices of compartments are no longer arbitrary.  This is really a question of motivation for the paper that seems missing to me.  What problem are the authors solving?  Why does one need a spiking neuron model? Or is this particular spiking neuron model related to one in common use in circumstances unfamiliar to me?  If it is already related to a model in common use, then having a fast implementation is of some importance.\n\nA related issue is that the models used for comparisons seem very limited (if one is only concerned with whether the model is a spiking model).  Many groups have been training spiking neural networks for a long time (Zenke & Ganguli 2018 is but one example).  If the multi-compartment model itself is not of particular importance, but I needed to train a spiking model, I could just as well use a network model from one of these groups.  Does the PMCS have advantages over those models?"
            },
            "questions": {
                "value": "The main question I have (from above) is why this particular model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5407/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5407/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5407/Reviewer_QBv1"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5407/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698805309482,
        "cdate": 1698805309482,
        "tmdate": 1699636548009,
        "mdate": 1699636548009,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TMo3LadgbJ",
        "forum": "FlH6VB5sJN",
        "replyto": "FlH6VB5sJN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_cmkV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5407/Reviewer_cmkV"
        ],
        "content": {
            "summary": {
                "value": "Simplified spiking neuron models, such as LIF, have trouble with multi-scale sequence modeling, or learning tasks involving learning complex temporal dynamics. While others have developed methods to account for this, training speed and performance is still relatively subpar. In this paper, the authors utilize biological inspiration from hippocampus pyramidal neurons and their multi-compartmental modeling to design a new generalized multi-compartment model which allows for arbitrary numbers of compartments. They also introduce a parallel implementation of this model for faster training on GPU accelerated hardware while accounting for the reset mechanism, unlike previous works."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1) The new multi-compartment model performs better than other memory-enhanced models and single compartment models on sequence modeling tasks with relatively similar parameter counts on standard benchmarks.\n2) The topic of better exploiting temporal dynamics during SNN training is important for their development.\n3) The parallel implementation, especially accounting for reset, is an important and useful contribution as SNNs are generally slow to train and have yet to be parallelized effectively."
            },
            "weaknesses": {
                "value": "1) Regarding Figure 4: while the parallel model was compared to its serial implementation in terms of speed up, what is the ratio/training time difference between PMSN and PSN? If PSN is faster, since it is only a single compartment model, how significant is this difference? I am not referring to the computational cost but instead training acceleration only.\n2) Is the parallel implementation/methodology that incorporates the reset mechanism general enough to be applied to single compartment models?"
            },
            "questions": {
                "value": "Please see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5407/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698878474359,
        "cdate": 1698878474359,
        "tmdate": 1699636547925,
        "mdate": 1699636547925,
        "license": "CC BY 4.0",
        "version": 2
    }
]