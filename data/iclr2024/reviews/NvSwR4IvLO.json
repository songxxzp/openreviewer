[
    {
        "id": "ejcYLdwjGU",
        "forum": "NvSwR4IvLO",
        "replyto": "NvSwR4IvLO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6773/Reviewer_reDY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6773/Reviewer_reDY"
        ],
        "content": {
            "summary": {
                "value": "The authors highlight the potential weaknesses of AI-generated text detectors such as neural-network based detectors, zero-shot AI text detection, watermarking, and information retrieval-based detectors. Specifically, the authors propose a recursive paraphrasing attack that recursively paraphrases an AI generated text until the text is likely to be classified as non AI-generated. Experimental results using 2000 text passages with each roughly 300 tokens in length from the XSum dataset and 2 different models used for paraphrasing suggest the attack is significantly effective against a wide range range of AI-generated text detectors."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The authors address the important problem of reliable AI-generated text detection. This problem is likely to become increasingly important with the rapid rise in popularity of large language models in society.\n\n* The proposed approach is simple yet effective in undermining the reliability of current AI-generated text detectors. The simplicity of the attack may also make it more likely to generalize to different models and domains.\n\n* The authors perform a human evaluation using Amazon's Mechanical Turk (MTurk) to evaluate the resulting paraphrased text passages. Their results suggest the original content of the text passage is preserved in addition to the grammar and overall text quality.\n\n* The authors also discuss the overall hardness of AI text detection, providing a formal upper bound of detection performance based on the total variation (TV) between AI-generated and human-generated text distributions.\n\n* The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "* The experiments only use text passages from a single dataset, and tend to only evaluate a single model for each detector type. Evaluations on a wider range of datasets and detectors would greatly strengthen any generalizable claims regarding the proposed paraphrasing attack.\n\n* Lack of baseline methods. In many of the experiments, the proposed attack is the only method being evaluated, have the authors compared their attack with similar attacks?\n\n* I appreciate the human evaluation in the \"Watermarked AI Text\" section, however, this type of evaluation is missing in the other experimental sections. For example, Figure 5 claims a significant drop in detector accuracy with minimal degradation in text quality; however, it's unclear to me how significantly text quality degrades based on a perplexity score increase from 6.15 to 13.55.\n\n* The insight that smaller TV between AI-generated and human-generated text distributions leads to more difficult detection problems seems rather obvious. Although the authors show that more complex models can lead to smaller TV distances, the authors do not provide any empirical evidence that smaller TV distances actually lead to more difficult AI text detection.\n\n* There is no empirical runtime evaluation of the proposed attack.\n\n* There are several grammatical errors throughout the paper, consider using a service like Grammarly to fix these issues.\n\n* Figure 9 is not colorblind friendly."
            },
            "questions": {
                "value": "* How is TV distance defined, and why is it difficult to compute for larger datasets?\n\n* How did the authors determine 5 rounds of paraphrasing to be sufficient?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6773/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697860703926,
        "cdate": 1697860703926,
        "tmdate": 1699636781063,
        "mdate": 1699636781063,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "L4d3VQbLGR",
        "forum": "NvSwR4IvLO",
        "replyto": "NvSwR4IvLO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6773/Reviewer_Ce9G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6773/Reviewer_Ce9G"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a study to showcase whether the AI-generated text can be reliably detected. For that, the authors have performed several experiments by transforming the text through recursive para-phrasing and showcasing the vulnerability of existing detection/defense algorithms. Further, the authors also showcase the spoofing attack which aims to label the genuine text into the AI-generated text by the defense algorithm."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "It is highly important to understand the limitations of current AI-generated text detection algorithms and to accurately identify the generated text to protect privacy and ethics."
            },
            "weaknesses": {
                "value": "* The biggest concern is with the para-phrasing task. Should be called the para-phrased text generated by any LLMs? Does it not destroy the inherent characteristics of the generated model? Have the original texts also been paraphrased by the paraphrases? What's the impact of para-phrasing genuine texts?\n* Ablation study of different paraphrasers? What is the contribution here? Do the authors have directly used the existing algorithms for phrasing? With the existence of several studies, the current paper leaves a low contribution concerning the sensitivity of LLM detectors.\n\n[1] Krishna K, Song Y, Karpinska M, Wieting J, Iyyer M. Paraphrasing evades detectors of ai-generated text, but retrieval is an effective defense. NeurIPS 2023\n[2] Kumarage T, Sheth P, Moraffah R, Garland J, Liu H. How Reliable Are AI-Generated-Text Detectors? An Assessment Framework Using Evasive Soft Prompts. EMNLP. 2023.\n\n* The experimental setting is weak. It is not clear how many samples have been used (2000 or 1000).\n* Are these existing detectors trained using multiple augmentation strategies such as data of multiple LLMs and/or para-phrased samples?\n* For retrieval-based detectors only 100 samples have been used reflecting inconsistency in the experimental setup. Figure 5 also shows the drastic drop in PPI value.\n* A detailed experimental study is needed concerning experiments in sections 4 (i) and 4 (ii). Only 3-length tokens are used along with a single-layer LSTM network. Further, the decrement shown in Figure 9, is statistically significant?"
            },
            "questions": {
                "value": "Please check the weakness section.\n\n--------------- Post Rebuttal --------------\n\nThanks for responding. However, in light of serious concerns such as the destruction of inherent characteristics of LLMs through paraphrasing, existing works on similar themes, and limited evaluation, I would like to retain my original rating.\n\nThe authors can conduct the analysis when human texts are also paraphrased and while augmenting the data, these paraphrased texts can also be used. If we used original (human and AI) and augmented (paraphrased human and AI), will it still increase type-1 (or 2) but decrease the other one?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6773/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6773/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6773/Reviewer_Ce9G"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6773/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698652307390,
        "cdate": 1698652307390,
        "tmdate": 1700658338391,
        "mdate": 1700658338391,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sUpHCBGFhP",
        "forum": "NvSwR4IvLO",
        "replyto": "NvSwR4IvLO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6773/Reviewer_JvAi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6773/Reviewer_JvAi"
        ],
        "content": {
            "summary": {
                "value": "The authors claim current methods for detecting AI-generated text from LLMs are ineffective, and their proposed recursive paraphrasing attack can bypass detectors. Watermarking techniques are also vulnerable and can be fooled by their proposed method for misidentifying human text as AI-generated. The authors claim, the challenge of distinguishing AI from human text is fundamentally difficult, as evidenced by a proposed theoretical model."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Well-Written and Structured Content also the research tackles an increasingly important topic in the AI community. \n- The paper's focus on recursive paraphrasing attacks represents an innovative and practical contribution to the field of AI security by showing that these attacks can effectively remove watermarks from AI text. \n- The paper supports its practical experiments with theoretical proofs, providing a deep understanding of the problem space."
            },
            "weaknesses": {
                "value": "The paper does not include testing on a diverse array of datasets like the M4 or Deepfake text detection, which encompasses Multi-generator, Multi-domain, and Multi-lingual data. Incorporating these datasets could provide a more comprehensive evaluation of the paraphrasing model's effectiveness across different text generation sources, domains, and languages.\n\nPu, J., Sarwar, Z., Abdullah, S. M., Rehman, A., Kim, Y., Bhattacharya, P., ... & Viswanath, B. (2023, May). Deepfake text detection: Limitations and opportunities. In 2023 IEEE Symposium on Security and Privacy (SP) (pp. 1613-1630). IEEE.\n\nWang, Yuxia, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun, Chenxi Whitehouse et al. \"M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection.\" arXiv preprint arXiv:2305.14902 (2023).\n\nRecursively paraphrased text could potentially suffer from semantic drift, where the meaning changes or degrades with each paraphrase iteration. How do you address the concern of maintaining semantic integrity and coherence with only perplexity metrics in text after multiple rounds of paraphrasing?"
            },
            "questions": {
                "value": "Question 1: Recursively paraphrased text could potentially suffer from semantic drift, where the meaning changes or degrades with each paraphrase iteration. How do you address the concern of maintaining semantic integrity and coherence in text after multiple rounds of paraphrasing? \n\nQuestion 2: Could you elaborate on how perplexity (without semantic understanding) and other quality metrics have been validated to accurately reflect the readability and coherence of the paraphrased text?\n\nQuestion 3: Given that detection methods are constantly evolving, how might adaptive detectors, which are designed to learn and counteract paraphrasing patterns over time, impact the effectiveness of the DIPPER paraphrasing model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6773/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699139973857,
        "cdate": 1699139973857,
        "tmdate": 1699636780816,
        "mdate": 1699636780816,
        "license": "CC BY 4.0",
        "version": 2
    }
]