[
    {
        "id": "zfrhSqniA7",
        "forum": "Z2xLkpkh0s",
        "replyto": "Z2xLkpkh0s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5174/Reviewer_WJKv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5174/Reviewer_WJKv"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a model for efficient asynchronous event processing that exploits sparsity. They design the Fully Asynchronous, Recurrent and Sparse Event-Based CNN (FARSE-CNN), a novel multi-layered architecture which combines the mechanisms of recurrent and convolutional neural networks. To build efficient deep networks, they propose compression modules that allow to learn hierarchical features both in space and time."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "S1: The authors try to present an inherently spiking/event domain based approach for processing asynchronous data from event-like sensors. Often in the related literature you see efforts at converting the data to frame like representations in order to process it using traditional algorithms developed for the synchronous domain. This approach tries to deal with the problem of processing the raw data directly without performing this limiting transformation which could hinder latency. As a result this is the main strength of the paper in my opinion\n\nS2: overall the paper is well written and the algorithm seems interesting, so i think it will be of interest to a subset of the community interested in on the edge based processing approaches"
            },
            "weaknesses": {
                "value": "W1: it is not clear to me if source code will be provided. Please clarify\n\nW2: I would have liked to see a more thorough discussion on the number of events produced internally by this architecture. To run something like this on neuromorphic hardware efficiently, you need to ensure that a sparse number of events are created internally. A discussion on this in the paper, would improve it"
            },
            "questions": {
                "value": "See comments above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5174/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698333365589,
        "cdate": 1698333365589,
        "tmdate": 1699636513226,
        "mdate": 1699636513226,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JqnoGjZsFp",
        "forum": "Z2xLkpkh0s",
        "replyto": "Z2xLkpkh0s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5174/Reviewer_Dqva"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5174/Reviewer_Dqva"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the asynchronous processing of individual event data without converting them into image-like inputs, thereby significantly reducing the overall model energy consumption. The paper designs and implements modules such as FARSE-CNN, SUB-FARSE-CNN, Sparse Pooling, Temporal Dropout, and validates the model's effectiveness in tasks like recognition and detection."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Based on LSTM design, the paper has implemented a FARSE-CNN for event data, with Sub-FARSE-CNN specifically producing outputs for the central pixel of each cell and updating the state of each cell, addressing the issue of a sharp increase in the number of events after passing through the module.\n\n2. Sparse Pooling compresses event data in the spatial dimension, while Temporal Dropout considers discarding some data in the temporal dimension to encourage the model to learn long-term features, fully utilizing the spatiotemporal characteristics of events.\n\n3. In the tasks of object recognition and object detection, the paper validates the role of the proposed modules in the network, showing their ability to balance computational complexity and accuracy, achieving performance comparable to or better than previous methods. It also achieves performance similar to synchronous methods in gesture recognition tasks."
            },
            "weaknesses": {
                "value": "1. Although the asynchronous method proposed in the paper handles event data, it does not demonstrate the real-time performance and execution speed of this method. Is there any data available regarding this aspect?\n\n2. For the Temporal Dropout discussed in Contribution 2 and the \"l\" parameter mentioned in Section 3.5, the experimental section does not provide relevant configurations or discussions.\n\n3. While the paper mentions both FARSE-CNN and SUB-FARSE-CNN, with the latter being an optimized improvement of the former, there is no experimental data to prove the effectiveness of this optimization. For example, there is no performance or computational complexity comparison."
            },
            "questions": {
                "value": "see Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5174/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698694731169,
        "cdate": 1698694731169,
        "tmdate": 1699636513137,
        "mdate": 1699636513137,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "z8E7piugRi",
        "forum": "Z2xLkpkh0s",
        "replyto": "Z2xLkpkh0s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5174/Reviewer_bxjc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5174/Reviewer_bxjc"
        ],
        "content": {
            "summary": {
                "value": "A new deep learning architecture - RNN for processing event data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors show similar or better performance at higher computation efficiency than other approaches that uses asynchronous methods."
            },
            "weaknesses": {
                "value": "- How does the complexity of the architecture affect the implementation? Does this architecture of asynchrony give actual speedup?\n- Are the datasets shown here sufficient? I am aware of a few other event vision work that looks at some other event data-streams. Can the authors do more SOTA comparisons ?\n- Temporal dropout while interesting seems to be an already existing technique? [1] uses some dynamic temporal exit. Further, there are some temporal coding works [2] that use some interesting forms of temporal representation. Can the authors comment on how dropout is different from these?\n\n[1] Li, Yuhang, et al. \"SEENN: Towards Temporal Spiking Early-Exit Neural Networks.\" arXiv preprint arXiv:2304.01230 (2023).\n[2] Zhou, Shibo, et al. \"Temporal-coded deep spiking neural network with easy training and robust performance.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 35. No. 12. 2021."
            },
            "questions": {
                "value": "See above weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5174/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698780836364,
        "cdate": 1698780836364,
        "tmdate": 1699636513051,
        "mdate": 1699636513051,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Nekd84tCMo",
        "forum": "Z2xLkpkh0s",
        "replyto": "Z2xLkpkh0s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5174/Reviewer_oYpd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5174/Reviewer_oYpd"
        ],
        "content": {
            "summary": {
                "value": "The paper intorduces an RNN architecture that is tailored to event-based processing in asynchronous manner. The architecture is evaluated against several other methods on 3 event-based datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is written clearly, and the illustrations support the text well. I believe the problem that is being addressed in the paper is important, as the authors mentioned, many modern event-based camera methods rely on image-like representations and thus are suboptiomal for event data processing."
            },
            "weaknesses": {
                "value": "1) Abstract: It would be better to clarify or paraphrase, as these two sentences seem to contradict each other: \"most successful algorithms for event cameras convert batches of events into dense image-like representations\" and \"achieves similar or better performance than state-of-the-art\nasynchronous methods\". What was the goal of the paper - to beat the best methods or do develop a sota asynchronous pipeline? I assume the latter, but this needs to be stated more clearly in the abstract.\n\n2) It would help if the evaluation was expanded, since there are not so many event-based datasets available. E.g. CIFAR10-DVS and SL-Animals could be added. A more complex EV-IMO (https://better-flow.github.io/evimo/download_evimo_2.html) could strengthen the paper further.\n\n3) It would be also great to see the performance of the method measured (train / inference separately) on a modern computer or embedded platform. Theoretical computations are valuable, but in practice there are many factors besides flops that can affect the performance. A side-by-side comparison of a few methods would make it more clear to the reader what the implications of the architecture are.\n\n4) From table 1, it seems that the accuracy is not the best (or significantly better compared to competition). The compute cost seems not the lowest as well. I believe a better explanation should be provided to explain the results."
            },
            "questions": {
                "value": "1) The authors mention, in the introduction, 3D convolutional networks. What is the main difference / advantage of the presented asynchronous scheme compared to 3D cnns, given that both leverage temporal information and, in theory, could be ran event-by-event? An example paper that explores this: https://openaccess.thecvf.com/content_CVPR_2020/papers/Mitrokhin_Learning_Visual_Motion_Segmentation_Using_Event_Surfaces_CVPR_2020_paper.pdf - it would be beneficial to add it to the review section as well.\n\n2) Are there plans to release the source code as a (e.g. Pytorch) package? I believe this would add to the overall contribution of this work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5174/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699141440703,
        "cdate": 1699141440703,
        "tmdate": 1699636512949,
        "mdate": 1699636512949,
        "license": "CC BY 4.0",
        "version": 2
    }
]