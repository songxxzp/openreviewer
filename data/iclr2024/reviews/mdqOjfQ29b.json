[
    {
        "id": "tLYr0DPRWs",
        "forum": "mdqOjfQ29b",
        "replyto": "mdqOjfQ29b",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4136/Reviewer_3cs3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4136/Reviewer_3cs3"
        ],
        "content": {
            "summary": {
                "value": "Distributional Data Distillation (D3) is a groundbreaking approach that transforms dataset distillation into a distribution-based problem. Unlike traditional methods that create a finite set of real or synthetic examples, D3 generates a probability distribution and a decoder to approximate the original dataset. Using Deep Latent Variable Models (DLVMs), it combines a trajectory-matching distillation loss with a distributional discrepancy term, resulting in strong alignment between original and distilled data. Across various computer vision datasets, D3 demonstrates effective distillation with minimal performance loss, even excelling with large datasets like ImageNet, surpassing sample-based methods consistently."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. simple and intuitive idea\n2. presentation is smooth and easy to understand"
            },
            "weaknesses": {
                "value": "1. I highly disagree with the statement claimed in this authors, \"Existing methods face challenges in scaling efficiently beyond toy datasets.\", \"More generally, these methods lack fine-grained control over distillation strength and often struggle to scale beyond smaller datasets like CIFAR-10 and MNIST, experiencing diminished performance when compressing larger or higher-dimensional datasets, such as ImageNet.\"[1, 2] cited in this paper, presented in CVPR 2023 has its main results in ImageNet on its cover.\n\n2. Lack of novelty and significant contributions, the idea is of sampling from a latent distribution has been thoroughly explored since VAE came out. It's unclear what is the significant contribution or additional innovation the authors are intending to propose.\n\n3. Experiment results in tables seem incomplete, it's hard to have holistic picture on how good this method is.\n\n\n[1] Cazenavette, George, et al. \"Generalizing Dataset Distillation via Deep Generative Prior.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n[2] Cui, Justin, et al. \"Scaling up dataset distillation to imagenet-1k with constant memory.\" International Conference on Machine Learning. PMLR, 2023.\n[3] Wu, Xindi, Zhiwei Deng, and Olga Russakovsky. \"Multimodal Dataset Distillation for Image-Text Retrieval.\" arXiv preprint arXiv:2308.07545 (2023)."
            },
            "questions": {
                "value": "1. Is it a typo where in the abstract, it claims to have done experiments on imageNet, but in the actual experiments, it runs ImageNette, which is a 10 class subset and a much easier problem to solve.\n2. Why does ConvNet have better accuracy than more complex and sophisticated networks?\n3. Why are Imagenette and imagewoof results not available for DM in table 1?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4136/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697663987619,
        "cdate": 1697663987619,
        "tmdate": 1699636379081,
        "mdate": 1699636379081,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hnA2ouIMdO",
        "forum": "mdqOjfQ29b",
        "replyto": "mdqOjfQ29b",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4136/Reviewer_yDY8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4136/Reviewer_yDY8"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces Distributional Data Distillation (D3), a novel approach to dataset distillation. Unlike existing methods that condense datasets into smaller versions, D3 focuses on creating a conditional latent distribution $p(z)$ and a decoder $Q_\\mathcal{S}^\\theta (x|z)$. The paper utilizes the resulting data distribution $Q_\\mathcal{S}^\\theta (x) = \\int Q_\\mathcal{S}^\\theta (x|z) p(z) dz$, called Deep Latent Variable Models (DLVMs), and a new training objective, combining trajectory-matching distillation with a distributional discrepancy term like Maximum Mean Discrepancy (MMD). Experimental results across various computer vision datasets, including the challenging ImageNet, demonstrate that D3 effectively condenses datasets with minimal performance loss. Notably, it consistently outperforms traditional sample-based distillation methods, even for large high-resolution datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The proposed method is simple and the description is easy-to-follow.\n\n- This paper proposes improved MMD loss over previous work which only matches mean of feature vectors."
            },
            "weaknesses": {
                "value": "- The idea of utilizing a generative prior has already been explored in several papers, including HaBa, LinBa, KFS, IT-GAN, and GLaD.\n\n- The comparison to the original literature on dataset distillation is entirely unfair. The proposed method outputs a distribution; therefore, it should be compared to deep generative models. Deep generative models can perform the exact same tasks as the proposed method."
            },
            "questions": {
                "value": "- In the loss of $\\mathcal{L}_\\texttt{MTT}$, why do we need the KL penalty? How does this regularization effects the performance?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4136/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698671473497,
        "cdate": 1698671473497,
        "tmdate": 1699636378986,
        "mdate": 1699636378986,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Mjs8EIZqil",
        "forum": "mdqOjfQ29b",
        "replyto": "mdqOjfQ29b",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4136/Reviewer_TU1J"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4136/Reviewer_TU1J"
        ],
        "content": {
            "summary": {
                "value": "Dataset distillation is a technique used to condense large datasets into smaller synthetic versions while maintaining predictive performance. It has applications in various machine learning domains, but existing methods face challenges when scaling beyond small datasets and experience diminishing returns as the distilled dataset size increases. To address these limitations, a novel approach called Distributional Data Distillation (D3) is introduced.\n\nUnlike previous methods that distill datasets into finite sets of real or synthetic examples, D3 frames the data distillation problem as a distributional one. Instead of producing individual examples, D3 generates a probability distribution and a decoder that can approximately regenerate the original dataset. Deep Latent Variable Models (DLVMs) are used to parameterize the condensed data distribution.\n\nD3 introduces a new training objective that combines a trajectory-matching distillation loss with a distributional discrepancy term, such as Maximum Mean Discrepancy. This objective encourages alignment between the original dataset distribution and the distilled distribution.\n\nExperimental results on various computer vision datasets demonstrate that D3 effectively distills datasets with minimal performance degradation. Even for large high-resolution datasets like ImageNet, D3 consistently outperforms sample-based distillation methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) This paper challenge the conventional approach of distilling into a finite set of samples, instead\ncasting the problem as a distributional one: finding a synthetic probability distribution which, when\nsampled to produce training data, yields performance comparable to training on the original dataset.\n\n2) To make this optimization problem tractable, this paper parametrize the distribution using Deep Latent\nVariable Models (Kingma & Welling, 2013), and design a loss function that combines a state-of-the\u0002art gradient-matching criterion (Cazenavette et al., 2023) with a distributional loss (e.g., MMD or\nWasserstein distance) \u2014 a natural choice for our distributional framework.\n\n3) This novel distributional dataset distillation perspective is appealing and it could addresses many of the limitations of prior distillation methods."
            },
            "weaknesses": {
                "value": "1)  The design in LEARNING THE DISTILLED DISTRIBUTION Matching is simply borrowed from [1]. Please clarify the difference.\n\n2) The comparison in Table 1 is confusing.  Is Comp. rate good when this rate is high or low?\n\n3) More comparison with generative-based dataset distillation methods could be added.\n\n[1] Dataset distillation by matching training trajectories."
            },
            "questions": {
                "value": "Please see weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4136/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4136/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4136/Reviewer_TU1J"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4136/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698747277913,
        "cdate": 1698747277913,
        "tmdate": 1699636378875,
        "mdate": 1699636378875,
        "license": "CC BY 4.0",
        "version": 2
    }
]