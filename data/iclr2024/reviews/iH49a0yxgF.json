[
    {
        "id": "YWJ4UanXee",
        "forum": "iH49a0yxgF",
        "replyto": "iH49a0yxgF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3875/Reviewer_qJ3Y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3875/Reviewer_qJ3Y"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an unsupervised domain adaptation framework for physiological time series data. The framework extends an existing Nearest Neighbor Contrastive Learning of Visual Representations (NNCLR) algorithm by allowing multiple nearest neighbors in the support set. Extensive experiments on 8 datasets with 3 tasks suggested that the model improved over existing methods on out-of-distribution domain."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper studies an underexplored area: unsupervised domain adaptation for physiological time series.\n2. Experiments are extensive and results are promising.\n3. Paper is easy to understand."
            },
            "weaknesses": {
                "value": "1. Some parts of the methods need more clarification or justification. For example, what are the encoders? Why is the Domain Shift Uncertainty (DSU) layer necessary?\n2. Technical contribution is limited. The model extends existing NNCLR algorithm by incorporating more nearest neighbors in the support set.\n3. Citation format is wrong, which reduces readability of the paper."
            },
            "questions": {
                "value": "1. What are the encoders for each task? Why is the Domain Shift Uncertainty (DSU) layer necessary? Please clarify in Methods.\n2. It would be interesting to see how model performance varies across $\\delta$ (i.e., number of neighbors), e.g., does model performance saturate or degrade with larger number of neighbors?\n3. In ablation study (Figure S1), what\u2019s the setup for DSU and $NNCLR_{\\Delta}$? Please clarify.\n4. Hidden in the supplement, the authors discuss that including a supervised loss prevents latent space collapse. Please provide an ablation study to support this claim."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Reviewer_qJ3Y",
                    "ICLR.cc/2024/Conference/Submission3875/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3875/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697927766382,
        "cdate": 1697927766382,
        "tmdate": 1700944738591,
        "mdate": 1700944738591,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pOlcdvKIfw",
        "forum": "iH49a0yxgF",
        "replyto": "iH49a0yxgF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3875/Reviewer_Pmyo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3875/Reviewer_Pmyo"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes an unsupervised domain adaptation approach for physiological time series based on a contrastive loss that leverages nearest neighbor samples from the source domain to the target domain."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The method is simple, which is nice, and it can be used with a variety of contrastive losses, possibly with minimal changes. The evaluation is thorough across datasets, tasks, and baselines."
            },
            "weaknesses": {
                "value": "The main concern is how effective the nearest neighbor strategy is. It is the main contribution, as all the other components already exist, and unsupervised domain adaptation with self-supervised losses has been extensively studied in the vision domain."
            },
            "questions": {
                "value": "What if one selects source samples randomly instead of nearest neighbors? How many samples are really needed from the source domain to be effective for adaptation?\n\nDuring adaptation, how important it is to also use a supervised loss? Ablation is very important, but it is missing.\n\nAre the baseline results (in Table 1-4) are from corresponding papers, or are the methods reimplemented and ran by the authors?\n\nHow does the performance vary based on the changing number of nearest neighbors?\n\nReferences for the augmentations used are missing. Random Switch Windows, Jitter, and Flipping were proposed in earlier work [1] on self-supervised learning for sensory data.\n[1] Saeed, Aaqib, Tanir Ozcelebi, and Johan Lukkien. \"Multi-task self-supervised learning for human activity detection.\" Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 3.2 (2019): 1-30."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Reviewer_Pmyo"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3875/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698410811125,
        "cdate": 1698410811125,
        "tmdate": 1700742221472,
        "mdate": 1700742221472,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4xFGZxZVJX",
        "forum": "iH49a0yxgF",
        "replyto": "iH49a0yxgF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3875/Reviewer_nstb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3875/Reviewer_nstb"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the problem of domain shifts in the case of time series data and suggests a new structured approach ('DUDE') that uses a dynamic method for neighbor selection which faces the absence of \ncommon support between the source and the target domain. The evaluation on real world datasets of continuous time series displays the higher f1 scores of the suggested framework versus the existing baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper develops a model and tests it on three dissimilar settings. \n- Research on this domain has a considerable impact in real-world predictions of clinical interest and can be deployable as an indicative medical tool.\n- The paper tries to face the obstacle of weak generalization of the trained models when used in an unobserved domain.\n- It explores the realistic scenario of the training data distribution being  the testing data distribution. \n- The supplement explains to some extent the logic of the loss function in figure S3, which is an incremental construction if NNCLR and seems to have emerged mostly from an empirical try.\n- Although the code is missing, some of the implementation details are provided. Maybe some more would make the submission stronger."
            },
            "weaknesses": {
                "value": "- The improvement in the f1 scores is higher or same as in the existing baselines. However, only in two datasets (Target: MESA, Target: Asian) the difference form the baselines is more than 3%. This shows the encouraging consistent improvement of DUDE framework, but it is not making its superiority strong. \n\n- Writing style: the citations are neither hyperlinked nor separated from the text."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Reviewer_nstb"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3875/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698549027104,
        "cdate": 1698549027104,
        "tmdate": 1699671036906,
        "mdate": 1699671036906,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "scOpsifRRL",
        "forum": "iH49a0yxgF",
        "replyto": "iH49a0yxgF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3875/Reviewer_1WBk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3875/Reviewer_1WBk"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a Deep Unsupervised Domain adaptation using variable nEighbors (DUDE) for physiological time series analyses. Based on Nearest-Neighbor Contrastive Learning of Visual Representations (NNCLR), the authors propose a new strategy that can adaptively select the number of neighbors. Experiments on three machine learning tasks are done to verify the effectiveness of the proposed DUDE."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strength:\n\n1.\tA DUDE framework is proposed in the context of continuous physiological time series analysis.\n\n2.\tDomain shift uncertainty (DSU) layers are applied in DUDE framework.\n\n3.\tAn adaptive neighbor selection strategy is proposed. \n\n4.\tExperiments on 3 different machine learning tasks are done."
            },
            "weaknesses": {
                "value": "Weakness:\n\n1.\tThe technical novelty of the work is quite limited. The two main parts of DUDE are either using existing techniques (DSU) or making marginal improvements on existing work NNCLR. Using threshold to adaptively select neighbors is not new, and it also brings a question on how to determine the threshold for different or new tasks. The paper claims that the best hyperparameter \u0394 found on the validation set was 0.95 for both experiments and thus shows the consistency for different experimental settings, which is not convincing. The authors may need to conduct a more comprehensive sensitivity analyses on this hyper-parameter or propose a valid hyper-parameter selection guideline for new tasks or unseen datasets.\n\n2.\tThe paper highlights that DUDE is proposed for physiological time series analyses, but from the technical view, the framework can be used for general time series UDA problems. It is unclear why the context of physiological time series is necessary.\n\n3.\tBased on point 2, more general time series UDA baselines should be compared, e.g. [ref1] and [ref2], to name a few. \n\n4.\tFor DSU layer, what\u2019s the difference between DSU and instance normalization used in [ref3].\n\n5.\tWhy different data augmentation used for different tasks? It is necessary to have an ablation study on different data augmentation techniques.\n\n6.\tThe paper lacks ablation studies on the two parts (DSU and NNCLR) of DUDE. \n\n\n[ref1] Contrastive domain adaptation for time-series via temporal mixup\n\n[ref2] Time Series Domain Adaptation via Sparse Associative Structure Alignment\n\n[ref3] Arbitrary style transfer in real-time with adaptive instance normalization"
            },
            "questions": {
                "value": "Please refer to the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3875/Reviewer_1WBk"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3875/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698639089966,
        "cdate": 1698639089966,
        "tmdate": 1701055158294,
        "mdate": 1701055158294,
        "license": "CC BY 4.0",
        "version": 2
    }
]