[
    {
        "id": "BbBlofez8z",
        "forum": "YItWKZci78",
        "replyto": "YItWKZci78",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_tSuv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_tSuv"
        ],
        "content": {
            "summary": {
                "value": "The authors considered the problem of developing a symmetric mean-field Langevin dynamics (MFLD) algorithm for distributional minimax problems with global convergence guarantees. Based on the mean-field Langevin descent ascent (MFL-DA) dynamics, the authors proposed mean-field Langevin averaged gradient (MFL-AG) flow that replaces the MFL-DA drift with the historical weighted average; based on the mean-field best response (MF-BR) flow, the authors proposed the mean-field Langevin anchored best response (MFL-ABR) process. Extensive convergence analyses were provided for both methods. The authors also studied the time and particle discretization error and applied their methods to zero-sum Markov games. Numerical experiments were conducted to compare their methods with MFL-DA."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Compactly written, this paper is the first to establish convergence results in using MFLD for minimax optimization over probability measures. By incorporating a weighting scheme into MFL-AG, the authors offered a creative direction for future works on MFLD. The comprehensive discretization analysis complements the continuous-time convergence result well.  Their second method, MFL-ABR, is also an interesting improvement upon MF-BR that is realizable by a particle algorithm and enjoys convergence guarantees."
            },
            "weaknesses": {
                "value": "The paper could be improved by providing more intuitions for the proposed methods. For example, what is the intuition for using a weighting scheme in MFL-AG, and what might cause MFL-AG and MFL-ABR to converge more slowly than MFL-DA in the numerical experiments? Is it correct to think that the slowdown of the convergence ensures better convergence?"
            },
            "questions": {
                "value": "See weakness. Also, what are some limitations of the proposed methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Reviewer_tSuv"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9271/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697593946052,
        "cdate": 1697593946052,
        "tmdate": 1699637168224,
        "mdate": 1699637168224,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oiYkCEiHx5",
        "forum": "YItWKZci78",
        "replyto": "YItWKZci78",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_q6kk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_q6kk"
        ],
        "content": {
            "summary": {
                "value": "This paper studied the mean-field minimax theorem with entropic regularization. The contributions can be summarized as follows:\n\n1. The authors proposed the MFL-AG algorithm, which convergence polynomially in continuous time. The author also proposed a discretized algorithm with a uniform-in-time propagation of chaos. \n\n2. The authors proposed the MFL-ABR algorithm and provided a convergence rate for the discrete outer loop."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed MFL-AG dynamic is new in the literature, and the weighted average of the dynamic provably converges to the MNE polynomially in time.\n\n2. The authors provide a uniform-in-time propagation of chaos for a finite-particle implementation of the MFL-AG flow. Despite I have a few questions on the utility of the results, I believe the techniques based on Chen et.al 2022 are novel in mean-field minimax problem literature, and could potentially benefit future works.\n\n3. The proposed MFL-ABR flow provides a potential way to find a discrete finite-particle algorithm for the best-response dynamics in mean-field min-max problem settings."
            },
            "weaknesses": {
                "value": "**Regarding the MFL-AG**:\n\n1. The utility of the finite particle analysis in section 3.3 is not very clear to me. I have the following questions: \n\n- 1.1 In Theorem 3.7, you bound the Wasserstein distance  $ W_1( {E}[ \\mu_{ \\overline{\\mathscr{X}}\\_k } ], \\mu\\_* )$. However, I didn't see why it is useful to consider ${E}[ \\mu_{ \\overline{\\mathscr{X}}\\_k } ]$ since ${E}[ \\mu_{ \\overline{\\mathscr{X}}\\_k } ]$ is basically the average of the pushforward of joint measures to each particle, what does the convergence of this measure to MNE implies? To my understanding, the propagation of chaos refers to that the particles behave almost i.i.d, how does this convergence results imply the particles are almost i.i.d ? Thus, it makes more sense to me to consider  $ W_1 ( \\mu_{ \\overline{\\mathscr{X}}\\_k }, \\mu_*)  $ for example.\n\n- 1.2 Cont'd: you mentioned in the footnote on page 6 that the typical rate Wasserstein distance between a measure and **i.i.d** sampled empirical measure is $N^{-1/d}$. In this case, it seems that the particles in $ \\mu_{ \\overline{\\mathscr{X}}\\_k}$ are highly correlated since the dynamics are coupled. The correlation is not only between the particles in $ \\overline{\\mathscr{X}}\\_k$ for a fixed $k$, but also between particles in different times (i.e.$ \\overline{\\mathscr{X}}\\_k$ and $ \\overline{\\mathscr{X}}\\_j$ for $j \\neq k$ ). Thus, it is unclear to me what is the convergence rate of $W_1(\\mu_{ \\overline{\\mathscr{X}}\\_k},   \\mathbb{E} [ \\mu_{ \\overline{\\mathscr{X}}\\_k} ] )$?\n\n- 1.3 The discussion on top of page 7 is not very clear to me. First of all, you say you expand around $\\mu, \\hat{\\nu} $, but the first order condition in (3) is only for MNE, i.e. it is not clear to me why $ \\frac{\\delta }{\\delta \\mu} \\mathcal{L}\\_\\lambda(\\mu, \\hat{\\nu}) =  \\frac{\\delta }{\\delta \\hat{\\nu}} \\mathcal{L}\\_\\lambda(\\mu, \\hat{\\nu}) = 0$ for an arbitrary $\\mu$. Do you mean you expand around $  \\mu_*, \\nu_*$? Also, it is unclear to me why one can ignore the higher-order terms. Thus, currently, I don't understand how the upper bound on $W_1$ implies an upper bound on $NI$ error. In fact, since the $NI$ error upper bound the KL-divergence, and the KL-divergence upper bound $W_1$, I doubt the correctness of that the $NI$ error can be upper bounded by the sum of $W_1$ in general.\n\n- 1.4 Cont'd: in the case where $\\mathcal{L}$ is bilinear and assumes good regularity (e.g. the kernel is uniformly bounded), is that possible to upper bound  $NI( \\mathbb{E}[ \\mu\\_{ \\overline{\\mathscr{X}}\\_k } ], \\mathbb{E}[\\nu_{ \\overline{\\mathscr{Y}}_k } ])$ by the sum of $W_1$ in the propagation of chaos results?\n\n- 1.5 Cont'd: I suggest making the discussions on top of page 7 more formal and rigorous. The current ambiguous discussion makes it hard to understand the utility of the propagation of chaos results.\n\n\n**Regarding the MFL-ABR**\n\n2. The utility of the results in section 4 is also not very clear to me, I have the following questions:\n\n- 2.1 It's not very clear to me why algorithm 2 works. Since in each round, one should input $\\mu_k, \\nu_k$ which comes from the outer iteration, while in algorithm 2, input $\\mu\\_{\\mathscr{X}\\_k}, \\nu\\_{\\mathscr{Y}\\_k} $ which are empirical measures. Due to the lack of propagation of chaos results, it is not clear to me that $\\mu\\_{\\mathscr{X}\\_k}, \\nu\\_{\\mathscr{Y}\\_k} $ will converge to $\\mu\\_k, \\nu\\_k $.\n\n- 2.2 Theorem 4.1 analyzes the convergence of the discretized version of MFL-ABR. However, compared to the results in Lascu et al. (2023), it seems to me that there are two drawbacks due to the inner Langevin dynamics: (1) There's a non-vanishing error $C \\beta$, so one has to make $\\beta$ small which in turn will make the convergence rate small. (2) The convergence rate of inner Langevin dynamics depends on the LSI, in the case of small $\\lambda$, the convergence rate can be small.  These two drawbacks might limit the utility of the MFL-ABR algorithm."
            },
            "questions": {
                "value": "Please also refer to the strengths and weaknesses part. \n\n1.  In Chen et al. (2022), they provide a propagation of chaos in KL-divergence, under extra regularity assumptions (see Theorem 2.4 in Chen et al. (2022) ). In this paper's settings, do you expect a similar propagation of chaos in KL divergence? Also, the propagation of chaos in Chen et al. 2022 provides a $O(1/N)$ error, which is optimal in order of $N$. Is it possible to improve the bounds to  $O(1/N)$ or is there any lower bound on the convergence rate (of propagation of chaos)?\n\n2. In the numerical experiments, you use a 3-point NI error to approximate NI error, what's the justification for this? Since in principle for given $\\mu_{\\mathscr{X}^i}$, one should compute $\\arg\\max_{\\nu} L_{\\lambda}(\\mu_{\\mathscr{X}^i}, \\nu )  $ , it could be that $ \\nu_{\\mathscr{Y}^j}$ are far from $\\arg\\max_{\\nu} L_{\\lambda}(\\mu_{\\mathscr{X}^i}, \\nu ) $. Besides, for fixed $\\mu_{\\mathscr{X}^i} $, to compute $\\arg\\max_{\\nu} L_{\\lambda}(\\mu_{\\mathscr{X}^i}, \\nu )  $, can't one directly run a mean-field Langevin dynamics for example?\n\n3 . Is it possible to apply the annealing techniques in Lu (2022) to achieve the MNE of the unregularized object (assume there is)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Reviewer_q6kk"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9271/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698231156991,
        "cdate": 1698231156991,
        "tmdate": 1699637168109,
        "mdate": 1699637168109,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "szcG79EmVt",
        "forum": "YItWKZci78",
        "replyto": "YItWKZci78",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_ByeN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_ByeN"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an approach to minimize optimization over probability distributions by extending the principles of mean-field Langevin dynamics. They propose two methods: (MFL-AG),  a single-loop algorithm designed to achieve convergence towards the mixed Nash equilibrium, and (MFL-ABR), a two-loop algorithm that demonstrates linear convergence in the outer loop. Furthermore, they also investigate various discretization methods and offer a fresh analysis of how chaos spreads, taking into account its dependencies on past distributions. This research paves the way for more in-depth investigations into mean-field dynamics for numerous learning agents."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The paper's contributions are supported by theoretical proofs\n* It seems that the convergence of mean-field Langevin dynamics was still an open problem and the problem of this paper is well defined."
            },
            "weaknesses": {
                "value": "* Proposed methods could be well motivated. The two proposed methods themselves are convincing. However, is there any reasons or motivation why you have both methods at the same time: mean-field Langevin averaged gradient and mean-field Langevin anchored the best response? Any explicit relationship between these two settings? \n* The description of the equation can be more comprehensive. Usually, we should describe all the notations of the equation at least right after it. For example, you do not mention what $\\rho^{\\mu}$ and $\\rho^{\\nu}$ are in equation 1."
            },
            "questions": {
                "value": "* Could you please explain more about what \"SYMMETRIC\" means in your proposed method and title? Is it mainly from the same temperature or regularization strength $\\lambda$ for both players?\n* Then how compatible your proposed method and proof can be extended to when there exists $\\lambda_1$ and $\\lambda_2$ for two players respectively? Since you mentioned that the problems you are looking for naturally arise for example solving robust learning or zero-sum games in reinforcement learning. Usually, in the robustness via adversarial learning, the regularization strength is relevant to the strength of the adversary. For example, if the adversary is attacked on soft actor-critic (SAC)[1], which originally had its regularization term (temperature), then it is not flexible to have the regularization terms for the target agent and the adversary the same values.\n* Could you analyze why MFL-AG can have a lower NI error compared with MFL-ABR and does it mean that MFL-AG performs better than MFL-ABR in this experiment? Furthermore, please suggest what kind of numerical experiment is more suitable with MFL-ABR against MFL-AG, and vice versa.\n\n[1] Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor. In International Conference on Machine Learning (ICML), 2018"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9271/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698475522309,
        "cdate": 1698475522309,
        "tmdate": 1699637167983,
        "mdate": 1699637167983,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QL1rZp9LQv",
        "forum": "YItWKZci78",
        "replyto": "YItWKZci78",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_DQbp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_DQbp"
        ],
        "content": {
            "summary": {
                "value": "The paper considers the solution of minmax problems with convex-concave objectives (plus entropic regularization terms) in the space of pairs of probability measures. Numerous problems can be viewed as particular cases of this. \n\nThere exists a natural Mckean-Vlasov type system of diffusions --  mean-field Langevin dynamics (MFLD) -- that should converge to the saddle point that solves the above problem. The paper shows such a result for a version of these diffusions where the drift term is averaged over past states. Moreover, particle approximations of the diffusions are shown to satisfy strong convergence rates: for instance, the approximation bounds are uniform in time. \n\nBounds for the authors' methods are given for \"Markov games\" assuming oracle access to certain functions and gradients related to the problem. A small simulation study suggests improved performance vis a vis MFLD."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The class of minmax optimization problems under consideration is quite natural. The result seems to be the first of its kind for this sort of problems. Similar results on convergence of McKean-Vlasov particle systems for convex optimization would be much easier to prove. The technical difficulties faced in the minimax scenario with the time averaging seem considerable."
            },
            "weaknesses": {
                "value": "The assumptions over the two measures used in entropic regularization are quite strong. The result of Theorem 3.7 has an expectation inside $W_1$, which is somewhat hard to interpret: it would seem to be saying that the bias of the procedure is small, but not the variance, so many repetitions of the particle dynamics would be needed to estimate the expectation of some function $f$. The outer-loop particle discretization error is not accounted for in the algorithm from Section 4.\n\nI do not understand what is going on in Lemma C.7 (it might be because I do not understand $\\Pi$ fully -- see below). \n\nSome of the notation is unnecessarily hard to parse. Let me offer a few examples.\n\nPage 5: *Denote ordered sets of $N$ particles* -- it would seem that the authors mean a vector in $\\mathcal{X}^N$. Also on the same page: it seems that the authors introduce the subscript $1:k$ to identify particle positions at different times, but then don't use this notation consistently at the bottom of the page (and also elsewhere). \n\n$L_\\mu$ and $L_\\nu$ are used to denote Lipschitz constants in the first/second variable, but also, $L$ is the functional and $(\\mu,\\nu)$ are used to denoted arbitrary elements of the space of probability measures.  \n\nThe definition of $\\Pi$ in page 6 as ``the average of the pushforward operators along the projections $X\\mapsto X^i$ does not seem correct. How can you project to a higher-dimensional space?"
            },
            "questions": {
                "value": "*(Q1)* Algorithm 1 and elsewhere - rathen than sample subsets of $\\mathcal{X}_k,\\mathcal{Y}_k$, maybe you could just use a weighted empirical measure where set $\\mathcal{X}_k$ has weight proportional to $\\beta_k$?\n\n*(Q2)* Can you clarify what is $\\Pi$ and explain specifically the proof of Lemma C7?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9271/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793247078,
        "cdate": 1698793247078,
        "tmdate": 1699637167795,
        "mdate": 1699637167795,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OeLFLdg3ZL",
        "forum": "YItWKZci78",
        "replyto": "YItWKZci78",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_bLee"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9271/Reviewer_bLee"
        ],
        "content": {
            "summary": {
                "value": "The paper analyzes two approaches for simulating mean-field games, denoted by MFL-AG and MFL-ABR respectively.  The convergence of the algorithms (in idealized form, and finite particle form) is provided."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This appears to be the first algorithm which achieves a convergence in time + propagation of chaos result for mean-field games under transparent assumptions.\n\nThe proofs are well-written and contain analytical insight into this problem. In particular there is clear intuition on how averaging helps to regularize this problem.\n\nBoth algorithms are realizable and seem to have reasonable performance in practice."
            },
            "weaknesses": {
                "value": "I have some issues with the Assumptions in the paper.\n\tFirstly, the requirement of convexity combined with strictly bounded gradients is quite strict, as it essentially forces the problem to be roughly linear. I think this is a major restriction and the authors should do their best to circumvent this, or otherwise explain why this assumption was necessary in their opinion.\n\nSecondly, it is unclear to me why the authors prefer to use $L^1$ Lipschitz-ness and obtain their result in Wasserstein-1. Isn\u2019t it more natural to frame all results in W2, or was W1 chosen for a specific reason?\n\nThe dependencies on $N$ are worse when compared to standard mean-field results. The dependence on $\\eta$ in the first term is also not ideal. For instance uniform-in-time propagation of chaos for the mean-field Langevin dynamics would look like $k^2/N^2$ (in $W_2^2$ under mild assumptions).\n\nThe results in Figure 1 are decent, but it is difficult to have any scale for comparison. It seems as well from the $W_1$ convergence that there is some degree of persistent bias for the choice of parameters. I would recommend further experiments if the authors are interested in highlighting the empirical performance of their approach.\n\nIn summary, I think this is a useful first result in this setting. However, there are numerous ways that it could be improved and I have some important questions regarding the results. I would be willing to raise my score if some of my questions could be addressed in more detail."
            },
            "questions": {
                "value": "Is it possible to write in this setting an analogue of the BBGKY hierarchy, and conduct the analysis that way? Would this at all sharpen the rates? It seems that under the convex-concavity assumption and bounded gradients assumptions at least, the analysis would be tractable using that approach.\n\nCould Figure 1 be moved to the main text? It is a core part of the contribution and should not be placed in the appendix.\n\nCould the dependency of $K$ on key problem parameters be clarified in the main text? It seems from the Appendices that it should be roughly $\\epsilon^2$. Additionally, it would be good to highlight dimension dependence, which appears to be fairly mild.\n\nWhy in Theorem 4.1 should $k$ be taken as $1/\\epsilon \\log \\epsilon$? Shouldn\u2019t $\\log 1/\\epsilon$ suffice?\n\nIn Lemma C.2, no need to refer to Gronwall\u2019s lemma (induction suffices).\n\nA definition of \u201cconvexity\u201d should be given in the Appendix. E.g. geodesic convexity in $W_2$, or convexity wrt TV distance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9271/Reviewer_bLee"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9271/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698803088331,
        "cdate": 1698803088331,
        "tmdate": 1700503482534,
        "mdate": 1700503482534,
        "license": "CC BY 4.0",
        "version": 2
    }
]