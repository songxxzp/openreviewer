[
    {
        "id": "SIGSqs7RbQ",
        "forum": "TilcG5C8bN",
        "replyto": "TilcG5C8bN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6644/Reviewer_wGaZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6644/Reviewer_wGaZ"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an efficient SSL approach called SimWnW. Through studying the impact of similar and dissimilar image regions on SSL performance, the authors find that similar regions are less important and removing them in augmented images (and in feature maps) can significantly reduce the computation cost and improve model convergence. To remove similar regions, the authors propose a new method under the ResNet/ConvNet settings. Specifically, a waxing-and-waning process is proposed for region removal while mitigating the region shrinking problem in convolutional layers. Experiments show that SimWnW can reduce the computation cost of SSL without compromising accuracy -- SimWnW yields up to 54% and 51% computation savings in training from scratch and transfer learning tasks, respectively."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper offers a comprehensive exploration of the impact of similar/dissimilar regions on SSL accuracy, which lays a good foundation for a region removal-based method to improve SSL efficiency.\n- Strong results in efficiency boost are achieved for two representative SSL frameworks.\n- Decent analysis is provided for region removal-related hyper-parameters like similarity threshold and block size."
            },
            "weaknesses": {
                "value": "- The key hyper-parameter of block removing portion is unspecified, and convincing explanations are missing (see questions below).\n- The comparisons with recent related works seem insufficient, e.g. (Addepalli et al., 2022) and (Koc\u00b8yigit et al., 2023).\n- The proposed waxing-and-waning method is customed too much to ConvNets. It seems hard to translate to transformers and hence transformer-based SOTA SSL methods (this makes the paper title a bit overclaim)."
            },
            "questions": {
                "value": "Key question around the portion of block removal:\n- Intuitively, comparing similar blocks won't generate too much useful signal for SSL. This is validated by Fig. 2 where the performance of \"Similar Blocks (x\\%)\" is consistently worse than \"Dissimilar Blocks (x\\%)\". On the other hand, comparing dissimilar blocks (after removing similar ones), despite being more useful, has a key hyper-parameter of the removing portion (1-x)\\% which can significantly affect the learning quality. Specifically, if we remove too much, comparing those top dissimilar blocks either makes learning too hard or the dissimilar blocks may not even be semantically related (which hurts SSL quality). If we gradually increase x\\%, the retained blocks would include both dissimilar and relatively similar blocks, which makes the learning signals more balanced for SSL.\n- Fig. 2 shows that SSL performance peaks at \"Dissimilar Blocks (75\\%)\". What's the actually used x\\% after region removal in SimWnW? If it's 75\\% or higher, then it shouldn't lead to that much of computation saving. Fig. 7(a) shows some hint about x in terms of similarity threshold. 1) When the default threshold is set to 20, what's the corresponding x\\%? 2) With the default similarity threshold 20, the SSL performance remains about the same but the training cost is increasing. So again, the computation saving is still concerning. Any comments?\n- One side question, why the compute saving on ImageNet is much smaller than CIFAR 10/100? This suggests the amount of removed blocks from high-resolution ImageNet images is smaller than that of low-resolution CIFAR images, given the same similarity threshold (if that's how it works). Any intuitions about why this is the case?\n\nOther minor questions:\n- To find similar blocks, what's the neighborhood size for searching? Does it depend on augmentation parameters? - since how we crop/rotate/flip images will impact the block locations a lot.\n- For \"block matching\" in pixel space, is PSNR an accurate enough metric? What if the found correspondence is wrong and how well can SimWnW tolerate such errors?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Reviewer_wGaZ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6644/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698482854083,
        "cdate": 1698482854083,
        "tmdate": 1700700572520,
        "mdate": 1700700572520,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1NEKQKZ6ap",
        "forum": "TilcG5C8bN",
        "replyto": "TilcG5C8bN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6644/Reviewer_5JXS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6644/Reviewer_5JXS"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to enhance the efficiency of self-supervised learning (SSL). Based on contrastive SSL methods, such as SimCLR and SimSiam, this paper proposes to reuse and remove the similar regions so as to save computation. To achieve this, this paper first identifies the similarities between regions. However, directly operating on regions would face the region shrinking problem caused by convolution layers, this paper proposes to expand the size of removed region. Compute savings in FLOPs in observed in ImageNet benchmarks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ Self-supervised learning is computation expensive, this paper proposes to reduce the pretraining cost while preserving the accuracy, which is important topic for the community. \n\n+ The idea of reusing and replacing similar regions is intuitive. Also I am not sure if there are other similar works proposing similar ideas, it is good to see these simple yet effective training techniques."
            },
            "weaknesses": {
                "value": "- This paper claims that the proposed method is efficient regrading the FLOPs. However, reduced FLOPs may not directly lead to time saving given that the proposed method requires dedicated sparse computation of convolutional kernel. It is important to report the real run time saving to claim efficiency.\n\n- In the title, authors claim the proposed method is generic. It is worth to apply SimWnW to self-supervised vision transformers as well. Moreover, the reuse and replace strategies are expected to be applicable to ViTs since there would be no region shrinking problem in ViTs."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Not applicable."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Reviewer_5JXS"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6644/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698608816415,
        "cdate": 1698608816415,
        "tmdate": 1700689741451,
        "mdate": 1700689741451,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EyI4OL18ga",
        "forum": "TilcG5C8bN",
        "replyto": "TilcG5C8bN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6644/Reviewer_Aoaq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6644/Reviewer_Aoaq"
        ],
        "content": {
            "summary": {
                "value": "The authors aim to improve the training efficiency of self-supervised learning (SSL) and they propose a similarity-based SSL framework called SIMWNW. SIMWNW removes less important regions (remove most similar regions in two views) in augmented images and feature maps and saves the training cost. Experimental results show that SIMWNW reduces the amount of computation costs in SSL."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper is well-written and easy to follow.\n2. The authors analyze the importance of different regions on augmented images by removing and reusing similar blocks for the two branches.\n3. The authors show that the removed region will shrink after convolution operation and they propose to expand the size of removed region in the feature map.\n4. Experimental results show that the proposed method can achieve comparable accuracy using fewer training FLOPs."
            },
            "weaknesses": {
                "value": "1. Compared with the training FLOPs, the actual time used for training is more important, and the authors did not report it. How much the proposed method can reduce the training time is what we are concerned about. Steps such as matching in the method cannot actually be reflected intuitively through FLOPs.\n2. In Table1 and Table2, the authors should list the accuracy of the baseline methods using the same training overhead. For example, how much lower will simclr be than the proposed method when using 80% overhead?\n3. Do the training FLOPs in Table2 refer to pre-training or downstream fine-tuning? If it is the former, why is it different from Table1\uff1fIf it is the latter, how is the proposed method used in single-branch supervised learning?\n4. From Figure 6, I cannot see the obvious advantages of the proposed method. I suggest the author change the horizontal axis to training hours.\n5. Some related works [1], [2].\n\n[1] Fast-MoCo: Boost Momentum-based Contrastive Learning with Combinatorial Patches. ECCV2022.\n\n[2] Rethinking Self-Supervised Learning: Small is Beautiful. arXiv 2103.13559."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Reviewer_Aoaq",
                    "ICLR.cc/2024/Conference/Submission6644/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6644/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698632401671,
        "cdate": 1698632401671,
        "tmdate": 1700798970703,
        "mdate": 1700798970703,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IRNjctjFRK",
        "forum": "TilcG5C8bN",
        "replyto": "TilcG5C8bN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6644/Reviewer_vumm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6644/Reviewer_vumm"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method for improving the efficiency of SSL methods by discarding features in augmented images and feature maps that are deemed less important, saving computation and reducing the risk of slowing the learning process by providing irrelevant features. The authors propose to remove blocks from pairs of augmented images that share high semantic similarity, in order to prevent unnecessary processing of irrelevant information such as image backgrounds. To this end, they provide a method for semantic matching of block pairs in images, their removal, and the treatment of the resulting feature maps throughout the network. Authors show results for training from scratch and transfer learning compared to a number of other SSL methods, in most cases showing barely degraded performance - or even improved performance - at a significantly reduced computational cost."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The authors provide a sensible method for improving computational efficiency of SSL methods, one of their main challenges currently. The authors are very thorough in motivating and describing their method, using illustrative examples throughout the paper. Experimental results are impressive, the proposed method shows good performance in its ability to reduce computational cost while retaining model performance.  A very sound paper overall, with good experimental design. Given that the authors spend some time sculpting the manuscript to improve its readability for the rebuttal, I think it represents an interesting and valuable addition to the CVPR proceedings."
            },
            "weaknesses": {
                "value": "Overall readability of the paper could be improved, I\u2019m having a bit of a hard time understanding some of the specifics of the approach as outlined in 3.1 and 3.2. Specifically, the block matching as outlined in paragraphs 1 and 2 under 3.1 seem to overlap; from my understanding you first search for most similar block pairs (paragraph 1) after which you calculate similarity for all block pairs (paragraph 2)? Why not calculate similarity for all block pairs directly?\n\nUnder 4.1, you indicate that, for a given pair of original and augmented image, you divide the first into blocks and loop for a similar block in the paired image. However, instead of performing an exhaustive search over all possible blocks in the augmented image, you narrow the search to \u201ca specific region surrounding a block\u2019s counterpart in the paired augmented image\u201d to ensure semantic consistency. Where does this block\u2019s counterpart come from? Is it simply the same augmentation applied to the block in the original image, i.e. the location of the original block under a flip? In this case, why would the same block in the augmented image not be the most similar block? Semantically, their content is identical is it not? Could you give an intuition as to why you would want to pair image blocks in the same region in the online and target images but not simply pair exact matches under augmentation?"
            },
            "questions": {
                "value": "Could you give a little more explanation for figure 1. In my opinion, the first two paragraphs of 3.1 read a bit confusingly. What is the distinction between the block matching described in the first paragraph and the similarity calculation after the creation of block pairs in the second paragraph? Aren\u2019t they overlapping?\n\nHow does computational complexity of the block-matching factor into the overall training complexity? I.e. do the FLOPs listed in tables 1 and 2 contain the overhead for your method? I think this should definitely be taken into account."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6644/Reviewer_vumm"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6644/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698832766304,
        "cdate": 1698832766304,
        "tmdate": 1700920272440,
        "mdate": 1700920272440,
        "license": "CC BY 4.0",
        "version": 2
    }
]