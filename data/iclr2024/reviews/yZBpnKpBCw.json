[
    {
        "id": "AhzqNtmeeP",
        "forum": "yZBpnKpBCw",
        "replyto": "yZBpnKpBCw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7313/Reviewer_Y5kQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7313/Reviewer_Y5kQ"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces FALCUN, a method in active learning, which promises efficiencies in labeling and processing. It brings a dynamic acquisition strategy to the table, focusing initially on uncertain instances near decision boundaries and gradually shifting to emphasize batch diversity. While the proposed approach looks new in some aspects, the lack of acknowledgment of previous works that have explored similar territories casts a shadow over its originality.\n\nKey foundational concepts seem to echo pre-existing methodologies in active learning literature, which were not appropriately credited, making FALCUN appear more as an incremental advancement rather than a groundbreaking innovation. Additionally, some experimental results, particularly those involving LeNet and BADGE's performance, seem somewhat inconclusive and could benefit from further rigor and validation to strengthen their credibility.\n\nFurthermore, the paper\u2019s experimental breadth appears limited. A more expansive inclusion of diverse and challenging benchmarks, such as CIFAR-100 and TinyImageNet, would enhance the robustness of FALCUN\u2019s evaluation, providing a more comprehensive understanding of its effectiveness and applicability across various domains. A reconsideration of these aspects could elevate the paper\u2019s contributions and clarity, fostering a more nuanced appreciation of FALCUN's position in the active learning landscape."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed algorithm tries to improve efficiencies in labeling and processing through a dynamic acquisition strategy, emphasizing a transition from focusing on uncertain instances to prioritizing batch diversity, showcasing a potential way in active learning strategies."
            },
            "weaknesses": {
                "value": "- The paper seems to overlook several crucial references relevant to the discussed topic. Fundamental concepts such as the theoretical importance of the near decision boundary have been comprehensively explored and articulated in previous works, notably in references [1] and [2]. These pivotal papers, along with others, offer profound insights that would augment the paper\u2019s foundational grounding. Moreover, the proposition of a linear-time scalable algorithm, a core element presented in the paper, has previously been introduced and elaborated upon in reference [3]. In addition to that, an influential work cited as [4] such as PowerBALD/or PowerEntropy adopting a sampling similar to Eq (6) but with better originality has also proposed a scaling approach that intriguingly maintains the algorithm\u2019s linear-time complexity.\n\n- The active learning results presented in the paper for LeNet on datasets like EMNIST or RepeatedMNIST seem somewhat unconvincing. Typically, in prevailing literature and experiments, around 300-500 images are required (not > 1000 images) to achieve accuracy comparable to supervised learning methods on these datasets. The reported results in the paper appear to deviate from these established benchmarks. It may be beneficial to revisit and scrutinize the experimental setup, methodology, and the specific implementation of LeNet in the active learning context to ensure that the presented results are robust, reliable, and in alignment with existing standards and expectations in the field. This could enhance the credibility and persuasiveness of the results and the overall contributions of the paper.\n\n- The performance of BADGE as presented in the paper raises some questions. It seems that with appropriate hyperparameter settings, BADGE should be capable of delivering much improved results. This discrepancy suggests that there might be room for optimizing the configuration of BADGE in the experiments, ensuring that it operates under the most suitable conditions for a fair and rigorous comparison. To uphold the integrity and reliability of the comparative analysis, it might be beneficial to revisit and fine-tune the hyperparameters used with BADGE, ensuring that its performance is accurately represented and evaluated against its full potential.\n\n- The experimental section of the paper seems somewhat limited and could be enhanced to bolster the claims made. Incorporating a broader array of realistic scenarios, such as tests involving CIFAR-100, TinyImageNet, or ImageNet, would offer a more comprehensive insight into the method\u2019s applicability and effectiveness. Including such varied and complex datasets in the evaluation would not only strengthen the validity of the results but also improve the generalizability of the conclusions drawn. This expansion in the experimental design would be instrumental in substantiating the method's robustness and adaptability across diverse challenges and use-cases.\n\n[1] Efficient Active Learning with Abstention, NeurIPS 2022 - https://openreview.net/forum?id=4u-oGqB4Lf6\n\n[2] Active Learning with Neural Networks: Insights from Nonparametric Statistics, NeurIPS 2022 - https://openreview.net/forum?id=LRMmgkcoCnW\n\n[3] Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle, ICLR 2023 - https://openreview.net/forum?id=ZTMuZ68B1g\n\n[4] Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning, TMLR 2023 - https://openreview.net/forum?id=vcHwQyNBjW"
            },
            "questions": {
                "value": "- What criteria determine the **most informative region**? Is a point considered most informative solely based on its proximity to the decision boundary?\n\n- **Could the authors please provide a more explicit explanation regarding the source of diversity in the proposed formula?** The margin considers two class boundaries. It might not be sufficiently generalizable. It would be beneficial to have a more explicit elucidation on how diversity is incorporated and manifests itself within the algorithmic design. Understanding the origins and implementation of diversity within the formula can enhance the comprehension of its functionality and overall impact on the method's performance. An in-depth clarification would contribute to a more robust and insightful evaluation of the proposed approach\u2019s effectiveness and novelty.\n\n- It seems crucial to **re-evaluate the experiment setups in the study to enhance the reliability and comprehensiveness of the findings**. Including a broader selection of benchmarks in the evaluation process would be instrumental in demonstrating the robustness and versatility of the proposed method across varied scenarios. **A more diversified array of benchmarks** will not only contribute to a deeper, better understanding of the method's performance but also bolster the study's overall credibility and impact. Therefore, revisiting and expanding the experiment setups with additional benchmarks is a highly recommended step to enrich the empirical validation of the study.\n\n- Section 4.4 discusses the influence of $\\gamma$ parameter, indicating that **different benchmarks may require distinct $\\gamma$ parameter values for optimal performance**. This aspect raises a practical concern: how can users effectively determine or choose an appropriate $\\gamma$ value a priori for various benchmarks? The ability to discern and select suitable parameters is crucial for the method's practical applicability and usability in real-world scenarios. Clarification or guidance on this matter would significantly enhance the method\u2019s practical value."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Reviewer_Y5kQ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7313/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698547838625,
        "cdate": 1698547838625,
        "tmdate": 1699636873959,
        "mdate": 1699636873959,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "b3yb9bkWyN",
        "forum": "yZBpnKpBCw",
        "replyto": "yZBpnKpBCw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7313/Reviewer_sEgU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7313/Reviewer_sEgU"
        ],
        "content": {
            "summary": {
                "value": "This paper explores two key limitations of existing active learning methods. First, many sophisticated AL algorithms have high computation + runtime cost, which make them undesirable for real-world implementation. Second, many AL algorithms focus on labeling images that optimize image diversity or maximizing the number of uncertain / currently-hard unlabeled images, with some recent works that attempt to use both. The paper proposes a new active learning strategy that combines uncertainty and diversity in a computationally fast algorithm. The proposed method is numerically validated on a number of image and tabular datasets to demonstrate improvements in model performance and low time complexity of the algorithm compared to existing baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Both of the limitations of existing AL algorithms are core problems, which the paper addresses. The time complexity analysis and demonstrated fast runtime with competitive performance are nice."
            },
            "weaknesses": {
                "value": "The key methodological motivation for the algorithm seems to be to derive a function that balances the uncertainty of the existing model and the diversity between samples selected in the current batch. However, there is no theoretical justification for why the proposed algorithm is a good strategy. Moreover, the experiments primarily use relatively simple image datasets and small models. It is not clear whether these results would meaningfully transfer to more realistic datasets (e.g., ImageNet). Currently, the difference between the methods and benchmarks appear small in every dataset considered. Lacking rigorous theoretical justification or validation on hard benchmark problems, the argument for the proposed method in practice is unconvincing. \n\nThe problem of dealing with two competing objectives, diversity and uncertainty, has been studied in recent works, and the paper misses a lot of this related literature (e.g., [1], [2]). This also leads to a missed opportunity for discussion and validation on how these two objectives trade-off overall. What is the major contributor overall to selection? Does the uncertainty score dominate or the diversity score? \n\n\n**References**\n\n[1] Active Learning on a Budget: Opposite Strategies Suit High and Low Budgets\n\n[2] MISAL: ACTIVE LEARNING FOR EVERY BUDGET"
            },
            "questions": {
                "value": "1. What do you mean when you state \u201can optimization function for diverse samples should not have a global optimum\u201d? This is a confusing statement. Furthermore, it is unclear how margin uncertainty satisfies this property. Please clarify.\n2. How does the proposed method trade-off diversity and uncertainty over active learning iterations?\n3. Why does KCenterGreedy perform poorly on Openml-156?\n4. How do you tune the $\\gamma$ parameter? Furthermore, is it advantageous to vary $\\gamma$ across the active learning stage (e.g., from small to large)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Reviewer_sEgU"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7313/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698603221856,
        "cdate": 1698603221856,
        "tmdate": 1699637492007,
        "mdate": 1699637492007,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xfYyqMqmQW",
        "forum": "yZBpnKpBCw",
        "replyto": "yZBpnKpBCw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7313/Reviewer_ZfdV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7313/Reviewer_ZfdV"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors proposed a label- and time-efficient active learning method, namely FALCUN. They incorporated both uncertainty and diversity into the data evaluation strategy and performed probability-based sampling to balance the uncertainty and diversity. Furthermore, they conducted experiments on both image and tabular data to validate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The authors designed a data evaluation metric considering both uncertainty and diversity and performed data sampling based on the probabilities, rather than strictly adhering the hard ranking approach."
            },
            "weaknesses": {
                "value": "Weakness\n1.Compared to identifying the most informative samples, the time cost of data evaluation is not the primary concern since the online data evaluation is not required.\n2.In uncertainty component, the margin uncertainty lacks novelty.\n3.As for diversity component, the rationale behind calculating the diversity score using the distance of predicted probabilities is still unclear. Why do the authors choose to measure the distance of predicted probabilities instead of using feature embeddings?\n4.Why did the authors perform probability-based sampling, instead of designing an alternative hybrid sampling strategy that combines the uncertainty-based and diversity-based metrics?\n5.The authors conducted experiments on small-scale datasets. We recommend verifying the efficacy of the proposed method on more challenging and large-scale benchmarks, such as CIFAR-10, CIFAR-100, and ImageNet.\n6.They authors should include additional experiments to compare the proposed method with state-of-the-art approaches like TOD [1] and Gradnorm [2].\n\n[1] Huang, Siyu, et al. \"Semi-supervised active learning with temporal output discrepancy.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.\n[2] Wang, Tianyang, et al. \"Boosting active learning via improving test performance.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. No. 8. 2022."
            },
            "questions": {
                "value": "see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Reviewer_ZfdV"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7313/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698743708526,
        "cdate": 1698743708526,
        "tmdate": 1699636873738,
        "mdate": 1699636873738,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dAHCPdkN0X",
        "forum": "yZBpnKpBCw",
        "replyto": "yZBpnKpBCw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7313/Reviewer_z6tU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7313/Reviewer_z6tU"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes FALCUN, a new pool-based active learning approach for deep neural networks. FALCUN operates directly on output probabilities for efficiency and naturally balances uncertainty and diversity. Experiments on various image datasets show it matches or exceeds state-of-the-art methods in accuracy while being faster. The core ideas are interesting but the empirical evaluation methodology could be stronger."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Leveraging output probabilities for uncertainty estimation and batch diversity is novel, simple and elegant. This intuitively should capture informativeness and redundancy better than latent features.\nThe empirical results generally validate that FALCUN provides excellent accuracy across datasets at low computational cost. Outperforming methods like BADGE and CLUE is impressive.\nAnalysis of the uncertainty and diversity components in the ablation study highlights their complementary benefits. The automatic balancing between the two is also shown to be effective."
            },
            "weaknesses": {
                "value": "The chosen baselines are reasonable but given the focus on computational efficiency, comparing to BatchBALD would have strengthened the empirical claims.\nFor the colored image experiments, using pre-trained weights gives FALCUN an advantage over baselines that train from scratch. Comparisons should be fair.\nSome dataset choices like MNIST and FashionMNIST are dated. More modern complex datasets would better highlight benefits.\nThe empirical methodology uses a limited set of architectures. Testing on bigger models like ResNets would be important to substantiate scalability claims.\nMore rigorous hyperparameter tuning for baselines could lead to better optimized versions for fairer comparison with the proposed approach."
            },
            "questions": {
                "value": "On the proposed method:\n\nThe margin-based uncertainty measure is intuitive. But are there any theoretical justifications for using it over other alternatives like entropy or Bayesian uncertainty?\nFor the diversity initialization and update, were other potential approaches considered? Is there a principled basis for the specific design choices made?\nHow sensitive is FALCUN to the choice of the \u03b3 parameter for sampling from the relevance distribution? Is tuning gamma required for different datasets?\nWhat impact does the neural network architecture have on FALCUN's performance, if any? Does it generalize across model families like CNNs, MLPs etc?\nOn the experiments:\n\nBatchBALD is a highly relevant Bayesian batch active learning method - would be good to compare against it. What advantages can FALCUN provide over Bayesian approaches?\nThe datasets seem heavily focused on MNIST variants - were results consistent on more complex, modern datasets? How was performance with higher input dimensionality?\nFor colored image experiments, using pretrained weights may favor FALCUN over baselines - could this be addressed?\nWhat was the hyperparameter tuning strategy for baselines? Would better optimized baselines affect relative comparisons?\nHow was robustness to things like random initialization and train-test splits evaluated?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7313/Reviewer_z6tU"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7313/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699276212969,
        "cdate": 1699276212969,
        "tmdate": 1699636873630,
        "mdate": 1699636873630,
        "license": "CC BY 4.0",
        "version": 2
    }
]