[
    {
        "id": "wlSaz7zJEg",
        "forum": "xkXdE81mOK",
        "replyto": "xkXdE81mOK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4245/Reviewer_QwLj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4245/Reviewer_QwLj"
        ],
        "content": {
            "summary": {
                "value": "To overcome the challenge of personalization, the authors introduce the Federated Recommendation with Additive Personalization (FedRAP). This method combines global item insights from FL with local, user-specific perspectives. FedRAP ensures efficient communication by promoting sparser global embeddings and uses two regularizers to balance global and local views. The primary contributions include the introduction of the dual personalization approach, the use of two distinct regularizers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe authors have adeptly addressed communication challenges in Federated Learning by advocating for a sparse global view. This practical strategy can potentially alleviate communication bottlenecks.\n2.\tThe emphasis on federated recommendations is commendable, since data privacy is a priority."
            },
            "weaknesses": {
                "value": "Clarity and Consistency in Writing: The manuscript requires clarity and consistency checks.\na. In Figure 1's title, \"five dataset\" is mentioned, whereas at the end of Section 1, it states \u201cfour dataset\u201d.\nb. There seems to be a mismatch in presentation; the results from Section 4.4 on Page 7 are introduced as early as Page 2 in the introduction. Is there a specific reason behind placing the experimental results in the introductory section?\n\nExplicit Statement of Motivation and Research Question: The introductory section should more explicitly state the motivation and the central research question. While Paragraph 3 introduces federated recommendation, and Paragraph 4 delineates the main contribution, there's a lack of clarity on the necessity of addressing heterogeneity and personalization in Federated Recommendation (FedRec). The central research questions around the importance of personalization in FedRec and the inadequacies of existing methods demand elaboration.\n\nDifferentiating Heterogeneity from Personalization: The distinction between heterogeneity and personalization needs to be clearer. The manuscript suggests two challenges: heterogeneity, which seems to pertain to varying client interests, and personalization. Given their similarities in this context, why are they presented as two separate challenges?\n\nOrganizational Refinements: There's a need for reorganizing the content, especially in Section 3.1 (Problem Formulation). Here, the authors discuss the loss function and the proposed method's entire framework. A more suitable structure might involve mathematically introducing the problem in the Problem Formulation and discussing the method's framework in a separate section.\n\nClarification on 'Reconstruction Error': Figure 2 illustrates the \"reconstruction error\". As per my understanding, it seems to measure the discrepancy between actual user ratings and predicted ones. The term \"reconstruction error\" suggests that something undergoes reconstruction. Can the authors clarify this?\n\nQuestioning Novelty: The paper's primary innovation appears to be the maintenance of a user-specific item embedding matrix, D(i), for every user, i. Given that local interactions are usually sparse, which motivates federated training, the uniqueness of this approach is incremental. The two regularizers are essentially the normalization of two embedding tables. While differential privacy is prevalent in federated learning, its application here doesn't seem groundbreaking.\n\nComparative Analysis with Relevant Works: The manuscript cites PerFedRec [1] in the related works but doesn't present a comparative analysis in the experiments. It would be insightful for the authors to contrast their work with PerFedRec. Moreover, considering the work on PerFedRec++ [2] could be beneficial, even if it's a recent arXiv publication.\n\nReferences:\n[1] Luo, S., Xiao, Y., & Song, L. (2022, October). Personalized federated recommendation via joint representation learning, user clustering, and model adaptation. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management (pp. 4289-4293).\n[2] Luo, S., Xiao, Y., Zhang, X., Liu, Y., Ding, W., & Song, L. (2023). PerFedRec++: Enhancing Personalized Federated Recommendation with Self-Supervised Pre-Training. arXiv preprint arXiv:2305.06622."
            },
            "questions": {
                "value": "1.\tWhy is the term \"Reconstruction error\" used in Figure 2? What exactly is being 'reconstructed' in the given context?\n2.\tCould the authors delineate the difference between 'heterogeneity' and 'personalization'? As of now, the distinction is not abundantly clear, and the terms seem somewhat interchangeable.\n3.\tThe paper emphasizes the sparse embedding's ability to reduce communication costs, a known limitation of current methods. Why is this specific aspect not experimentally validated or discussed in the results section? Can the authors provide insights or potential experimental outcomes supporting this claim?\n4.\tGiven that \"PerFedRec\" is cited in the related work and seems to be a relevant approach in this domain, why is it omitted from the experimental comparisons? A comparative analysis could provide a clearer perspective on the proposed method's advantages or potential differences."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4245/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4245/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4245/Reviewer_QwLj"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4245/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698663480720,
        "cdate": 1698663480720,
        "tmdate": 1700709072514,
        "mdate": 1700709072514,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ElQdWC4XC2",
        "forum": "xkXdE81mOK",
        "replyto": "xkXdE81mOK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4245/Reviewer_MAPK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4245/Reviewer_MAPK"
        ],
        "content": {
            "summary": {
                "value": "Federated Recommendation Systems (FRS) is a promising field, however, existing methods not pay enough attention to personalization . To enhance personalization in the field of FRS, FedRAP proposed by the authors address the challenges of heterogeneity and personalization in FRSs. FedRAP decouples the common knowledge and personalized knowledge by decoupling user embedding to on-server (updated by server-client communication) sparse one and on-client one. Regularization is used to restrict training."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. It points out the shortcomings of the existing FRS methods, and gives a complete solution, which is instructive.\n2. The framework is complete, and the paper is clearly expressed.\n3. Theoretical analysis is sufficient. Proofs of error and differential privacy in federated learning are comprehensive.\n4. Limitations about FedRAP are detailed"
            },
            "weaknesses": {
                "value": "None"
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4245/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698773206958,
        "cdate": 1698773206958,
        "tmdate": 1699636391505,
        "mdate": 1699636391505,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "muO59qDtTY",
        "forum": "xkXdE81mOK",
        "replyto": "xkXdE81mOK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4245/Reviewer_eLAA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4245/Reviewer_eLAA"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of federated recommendation and proposes a new method improving the personalization performance. The authors developed a new additive item embedding model that combines a sparse global embedding with a user-personalized embedding, where the federated recommendation only needs to periodically send the sparse embedding between servers and users, and thus saves the communication cost. The user-personalized embedding is only stored at the user devices and optimized for each user so the personalization performance can be improved. They developed a curriculum to facilitate the training of the two embeddings, which learns the personalized ones at first before adding the sparse global one. This method achieved significant improvements on five benchmark datasets of different domains and sizes. The paper also provides a differential privacy analysis to the proposed approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Federated recommendation is an important problem that has not been fully explored in the federated learning community. Improving the personalization performance is an open key challenge in the federated recommendation setting.\n2. The proposed additive item embedding model is a novel contribution to the field and addresses two critical challenges in the federated recommendation area, i.e,. reducing communication cost and personalization with knowledge sharing.\n3. The ablation study shows that the curriculum is important to learn the item embedding model.\n4. The performance achieved by the proposed FedRAP is remarkable in Figure 1: on six widely-used benchmarks, it outperforms all the federated recommendation baselines by a substantial margin and largely reduces the gap between federated algorithms and centralized ones---this is nontrivial and worth being highlighted. \n5. The ablation study includes 8 variants of the proposed methods and demonstrates the advantage of most components in the proposed FedRAP. The analysis and experiments regarding differential privacy make their method more trustworthy. \n6. They provided the code, which facilitates reproducible research in the future. I believe this work with the code released can be very interesting to people working in the area of federated recommendation systems."
            },
            "weaknesses": {
                "value": "1. The variants in the ablation study introduced in Section 4.5 do not come with intuitive explanations of the motivations for comparisions with them. They are unclear to readers if they do not carefully read the following analysis. \n2. There are some typos and grammar errors which should be corrected."
            },
            "questions": {
                "value": "1. Can you provide an ablation study of the regularization in Eq2? \n2. \"FedRAP-No: Removes item diversity constraint on C\" --- should \"diversity\" be \"sparsity\"? Is this a typo?\n3. In Figure 7, it seems that each user-personalized matrix is row-sparse with most rows to be all-zeros. How do we understand this row-sparsity? Can you (or did you) take advantage of this row-sparsity to further reduce the communication cost (e.g., by only sending the non-allzero rows)?\n4. How do we justify whether the degradation numbers in Table 1 are large or small? Are there any baselines' degradation results to be compared with?\n\nOverall, I think this is a solid work on an important open problem. Their proposed item embedding model has a novel design successfully addressing the communication and personalization problems in federated recommendation. Their reported improvement (when compared to existing federated recommendation approaches) on six well-known benchmark datasets is impressive and significant, demonstrating the effectiveness. The ablation study and differential privacy analysis are thorough and further strengthened the work. The paper is clear overall but there is still some room for improving the writing/presentation. Some questions above need further clarifications."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4245/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4245/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4245/Reviewer_eLAA"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4245/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698830955444,
        "cdate": 1698830955444,
        "tmdate": 1699636391421,
        "mdate": 1699636391421,
        "license": "CC BY 4.0",
        "version": 2
    }
]