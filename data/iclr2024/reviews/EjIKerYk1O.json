[
    {
        "id": "EOeq86ih5V",
        "forum": "EjIKerYk1O",
        "replyto": "EjIKerYk1O",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2476/Reviewer_E31H"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2476/Reviewer_E31H"
        ],
        "content": {
            "summary": {
                "value": "This paper propose a method to estimate the distance for aircraft in digital towers. Distance/depth estimation is an interesting topic in 3D vision."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Distance estimation is a challenging task.  \n2. This paper is easy to understand."
            },
            "weaknesses": {
                "value": "1. The model design is not novel, which has limited technical learning.   \n2. The dataset is not available. Then it cannot be a part of contribution.  \n3. Calibaration network is a little strange. Why it can align two views without knowing the related position for the two cameras? If the two camera's position is changed, can this model still work?   \n4. The number of views in the dataset is only 2.  The statement of \"multi-view\" is unsoundness. Author should increase the view number.  \n5. The paper writing should be further improved. Besides, figure in the manuscript should be the vector figure (Most figures are blur)."
            },
            "questions": {
                "value": "Refer to the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2476/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698119061875,
        "cdate": 1698119061875,
        "tmdate": 1699636184135,
        "mdate": 1699636184135,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bdDXxooHor",
        "forum": "EjIKerYk1O",
        "replyto": "EjIKerYk1O",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2476/Reviewer_Z485"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2476/Reviewer_Z485"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a multi-view deep learning approach for distance-touchdown (DTD) estimation. Yolov7 is utilized here to detect the aircraft in image. Input vecotrs from different views are further combined in an LSTM model, resulting the estimated distance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The experiments on simulated and real video data demonstrate that the proposed method can favorably extimate the distance of the aircraft."
            },
            "weaknesses": {
                "value": "1. This manuscript sounds more like a technique report instead of a research paper. The proposed approach simply utilize an off-the-shelf detection model and an LSTM network to train a distance estimation model.\n2. The authors are encourged to evaluate the performance of baselines with different detection models and network structures."
            },
            "questions": {
                "value": "When there are more than one aircrafts in the frame, how do you associate the aircrafts across different views?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2476/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2476/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2476/Reviewer_Z485"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2476/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698194091997,
        "cdate": 1698194091997,
        "tmdate": 1699636184043,
        "mdate": 1699636184043,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "r15JRGPFEy",
        "forum": "EjIKerYk1O",
        "replyto": "EjIKerYk1O",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2476/Reviewer_kvrA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2476/Reviewer_kvrA"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a deep learning solution that uses images captured by cameras installed at airport runways to monitor aircraft traffic around an airport to estimate distance-to-touchdown for incoming (i.e., landing) aircrafts.  Distance-to-touchdown is an important piece of information that is used by airtraffic controllers to manage the air traffic.  The work proposed here develops a key enabling technology for the future digital (air taffic control) towers.  The proposed method is able to integrate information captured by multiple cameras in order to carry out the task at hand.  Each camera feed is processed independently to detect and segment the incoming aircrafts.  Camera network layers process features computed at each camera and the result is sent to an LSTM+inference network.  An auxiliary regression task is used to improve training.  The work is evalauted on both synthetic data, rendered using the popular X-Plane 11 flight simulator and on real data collected at the Singapore Changi airport."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper tackles an important problem in aircraft traffic management and control.  Clearly, vision-based automated schemes for detecting, identifying, and tracking air traffic in and around an airport is of immense value.  The paper cogently argues the need for such a system.  The paper also makes a clever use of synthetic data to train and evaluate the distance-to-touchdown estimation model.  The paper also makes use of TensorRT engine to speed up inference.  This is important due to the real-time nature of the task that the paper wants to solve."
            },
            "weaknesses": {
                "value": "The work as presented suffers from a number of weaknesses.\n\nFirst off, majority of training and evaluation takes place in a setting that uses only two cameras.  This is unsatisfactory given that the multi-view analysis is one of the central claims of this work.\n\nIt is not immediately obvious how the architecture depicted in Figure 1 manages to integrate the information from multiple cameras.  It seems that the \"calibration network\" is tasked with transforming the features captured by multiple cameras into a shared space where these can be reasoned with jointly.  I feel that we need a lot more discussion around this \"calibration network\" and how it helps integrate information from multiple cameras. \n\nPart of the \"inference\" network contains an LSTM.  It is not clear to me if LSTM is needed to deal with a single frame from multiple cameras or if LSTM is needed to process video feeds.  It appears to me that temporal information may be helpful in regularizing the distance-to-touchdown estimates.  Does the system uses temporal information?\n\nWhat role does auxiliary network play?  And more importantly how does it play the said role?  What is a reversed network?  \n\nThe overall scheme seems rather ad hoc.  YOLO is used as an object detector here.  What if it fails to record a plane?  What if planes are mis-labelled in multiple views?  At a distance most planes look similar!  \n\nSome of the discussion around results raises questions.  On page 8, why does the system perform better in low-light conditions.  This is very counter-intuitive.  This is a safety critical application, so the bar of scientific rigour is very high.  It is not sufficient that the proposed system achieves good results.  It is also important that we understand the limits of this system.  We should be able to explain good (or bad) results.  Perhaps an ablative study will help explain the roles played by individual components of the system."
            },
            "questions": {
                "value": "1. What happens if the N_views are set to more than 2 in Algorithm 1?\n2. Why max_epoches are set to 225K in Algorithm 1?  This seems an arbitrary number.\n3. Why does the system perform better in low-light conditions?    Do we know why?\n4. How does the system deal with the object association problem in multiple images?\n5. Not sure I can understand the second sentence in the Conclusions section.  It refers to stochastic number of input videos ...  What does it actually mean?\n6. The paper refers to TensortRT?  Do you mean TensorRT?\n7. What is a reversed network?\n8. Can you provide some details of the auxiliary regression network?\n9. Can you provide some details of the calibration network?  It may be useful to provide an ablative study on this, since it plays a central role in integrating information from multiple cameras.\n10. What role does LSTM play?  Is it used to combine information from multiple cameras?  Or it integrates information over time to provide better distance-to-touchdown estimates."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2476/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698771710182,
        "cdate": 1698771710182,
        "tmdate": 1699636183886,
        "mdate": 1699636183886,
        "license": "CC BY 4.0",
        "version": 2
    }
]