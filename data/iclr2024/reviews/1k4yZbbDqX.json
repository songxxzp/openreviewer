[
    {
        "id": "JJmEHrFvtv",
        "forum": "1k4yZbbDqX",
        "replyto": "1k4yZbbDqX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3230/Reviewer_mwbp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3230/Reviewer_mwbp"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to address the limitations of diffusion models in text-to-image (T2I) generation, particularly their slow multi-step sampling process. The authors propose a novel one-step generative model derived from Stable Diffusion (SD) using a method called Rectified Flow. The core of Rectified Flow is its reflow procedure, which improves the coupling between noises and images and facilitates the distillation process."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Well organized and clarified.\n2. The contribution is great. Making the conditional diffusions work with one or very few steps will greatly boost the development of diffusion community. \n3. The comparison experiments are carefully and fairly set up, and I appreciate that."
            },
            "weaknesses": {
                "value": "I have several questions about this paper, and I hope the authors to clearly clarify them.\n\n1. **Storage Overhead**: In my opinion, it seems that either the distillation process or the reflow process actually requires us to create a relatively large (noise, image) pair dataset in advance, which would cause the additional storage overhead.\n\n2. **Intrinsic Difference between the so-called distillation and reflow process**: The distillation step aims to make the model predict the same as target computed by the ODE process of Stable Diffusion at the zero-timestep. While the reflow process seems to only change to make the distillation applied to all possible timesteps. \n\n3. **Noise Scheduler**: The noise scheduler of SD requires a normal diffusion noise scheduler. The reflow requires the \"linear\" (I call it \"linear\" just for convenience) scheduler. Wouldn't that cause trouble? Besides, the SD Unet requires time embedding, what time embedding do you use?\n\n4. Why do you choose to predict \"x1-x0\" instead of \"x1-xt\"? Do you have any considerations about this?"
            },
            "questions": {
                "value": "I tend to accept the paper, considering its theoretical and technical contributions. However, I have several questions about this paper and hope the authors answer them for me to make the final decision."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3230/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3230/Reviewer_mwbp",
                    "ICLR.cc/2024/Conference/Submission3230/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3230/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698573503267,
        "cdate": 1698573503267,
        "tmdate": 1700650338793,
        "mdate": 1700650338793,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NTFw9qhBG0",
        "forum": "1k4yZbbDqX",
        "replyto": "1k4yZbbDqX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3230/Reviewer_W54n"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3230/Reviewer_W54n"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes the InstaFlow, an application that applies the Rectified Flow to Stable Diffusion. The authors implement the rectified flow technique on Stable Diffusion and subsequently distill a one-step diffusion model from the rectified model. The rectified method makes the trajectories of Stable Diffusion straighter, thus making it much easier to distill the multi-step model to fewer or even one-step model."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well-written, and the experiments conducted are both sufficient and convincing. The InstaFlow achieves amazing performance (1-step inference with reasonable quality in approximately 0.09 seconds)."
            },
            "weaknesses": {
                "value": "While this model demonstrates impressive performance, it does involve a trade-off between inference speed and generation quality. From the supplementary document of InstaFlow, we can still observe various artifacts, which may be inherited from the 2-Rectified Flow (e.g., many faces are already distorted in the rectified model). Nevertheless, as the authors also mentioned, this model can be used for generating quick reviews, and then larger models can be employed for further generating high-quality images."
            },
            "questions": {
                "value": "I don't have further questions regarding the experiments since they're satisfactory to me.\nHowever, given that this work involves practical applications, I encourage the authors to consider sharing the source code and pretrained models, as this would undoubtedly be of great benefit to the community."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3230/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3230/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3230/Reviewer_W54n"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3230/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698673838921,
        "cdate": 1698673838921,
        "tmdate": 1699636271233,
        "mdate": 1699636271233,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5SUbNXhSEd",
        "forum": "1k4yZbbDqX",
        "replyto": "1k4yZbbDqX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3230/Reviewer_ZDe9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3230/Reviewer_ZDe9"
        ],
        "content": {
            "summary": {
                "value": "This paper extends a recently introduced framework of rectified flows to the distillation of the coupling learned by the pretrained diffusion model, e.g. Stable Diffusion (SD). \nWhile the recent work [1] reported the results of experiments on unconditioned generation (on CIFAR-10, LSUN, AFHQ, MetFace and CelebA-HQ datasets) as well as on img2img translation, the current submission focuses on text-conditional generation.\nThe paper reconfirms that a \"rectified\" ODE produces an easier target for 1-step distillation. \n\nThe main contribution is the InstaFlow model which essentially is a multi-step pipeline which takes a pretrained SD model as an input and outputs a 1-step generative model. \nIn addition, a novel type of architecture called Stacked U-Net is presented.\nAs the conducted evaluation shows, InstaFlow outperforms recent baselines such as Progressive Distillation of SD and StyleGAN-T in terms of FID and CLIP score.\n\n[1] Liu et al. Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow. In ICLR, 2023."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The writing style of the paper is extremely clear.\nIt provides a very good introduction to the framework of rectified flows for a reader without deep knowledge of the topic, and overall the manuscript is quite self-contained. \nThe conducted experiments provide a sufficient support for the motivation of the method. I find the evaluation thorough enough.\nThe results achieved in the paper are definitely interesting for the broad community of ML researchers and practitioners due to the achieved combination of required computational resources for the model training and inference and its performance."
            },
            "weaknesses": {
                "value": "1. First of all, this submission is more an extension of the previous work [1] rather than an independent work. The novelty of the presented ideas is definitely limited: all parts of the pipeline were actually introduced previously, and the submitted work applies the same pipeline to the coupling learned by SD model instead of independent coupling of noise and images. The proposed results are definitely valuable for applications. However, they look more like a technical exercise on top of the [1]. Overall, I find this work too incremental although helpful for practitioners.\n1. While the idea of Stacked U-Net is interesting, the paper lacks the study if this type of architecture is actually better than increasing the depth (or the number of channels) of the conventional U-Net model.\n1. The paper provides the results for latent models only. Taking the empirical nature of this work into account, I suggest adding any of the open cascaded models to the comparison to see, e.g. DeepFloyd IF [2].\n\n[2] https://github.com/deep-floyd/IF"
            },
            "questions": {
                "value": "1. Please, address the limitations discussed above.\n1. The training pipeline described in the Appendix D, looks pretty complicated. \n    1. Why was it necessary to change the batch size (step 2), and why wasn't more common learning rate tuning applied instead? \n    1. What is the reasoning behind switching from L2 to LPIPS objective (step 4) instead of training with a combination of L2 and perceptual loss from the very beginning of the distillation phase? \n    1. How were switching points for steps 2 and 4 selected?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3230/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698775985155,
        "cdate": 1698775985155,
        "tmdate": 1699636271146,
        "mdate": 1699636271146,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YDsyOMfoht",
        "forum": "1k4yZbbDqX",
        "replyto": "1k4yZbbDqX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3230/Reviewer_VVpt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3230/Reviewer_VVpt"
        ],
        "content": {
            "summary": {
                "value": "This paper successfully demonstrates the use of RECTIFIED FLOW to linearize the model's sampling trajectory, followed by distillation to enhance the sampling speed of the ODE model. It proposes a method for distilling Text-Conditioned flow models, showcasing a variety of ablation studies and results across multiple settings."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The results of this paper are truly captivating. It manages to generate images of impressive quality with just one or two steps. The quality showcased in the figures is highly satisfying. In addition, the paper provides a detailed account of various experiments and the corresponding performance metrics, which adds greatly to its value."
            },
            "weaknesses": {
                "value": "While the paper demonstrates impressive results, it appears to be a straightforward application of RECTIFIED FLOW. I was unable to discern any clear novelty in the algorithms or methods presented. If I'm wrong please kindly let me know the difference.\n\nThe model that claims to operate in 1 step actually resembles a configuration of two UNets linked together, and thus feels closer to a 2-step process. Additionally, when the refined model from SDXL is not applied, the results show a noticeable degradation in high-frequency details."
            },
            "questions": {
                "value": "Given that RECTIFIED FLOW is trained based on its own trajectory, are there any issues that arise from this approach?\n\nMethods like DDIM inversion also seem like they could be applicable in a flow-based context. I am curious about the results in cases where a small number of steps, close to 2, are used."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Additionally, I would like to highlight the importance of discussing the ethical implications of the presented work in the paper."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3230/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3230/Reviewer_VVpt",
                    "ICLR.cc/2024/Conference/Submission3230/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3230/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698837717689,
        "cdate": 1698837717689,
        "tmdate": 1700532324174,
        "mdate": 1700532324174,
        "license": "CC BY 4.0",
        "version": 2
    }
]