[
    {
        "id": "OuzfyaRvg1",
        "forum": "v9Sfo2hMJl",
        "replyto": "v9Sfo2hMJl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1793/Reviewer_gsuz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1793/Reviewer_gsuz"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a hybrid model that utilizes multiple structures for improved time series forecasting, demonstrating strong performance across various datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.This paper conducts comprehensive ablation experiments, analyzing the role of each module in the model. This demonstrates the importance of a multiscale hybrid model in the field of time series prediction.\n2.The article provides open-source code, facilitating the reproducibility of experimental results.\n3.It thoroughly compares different parameter search methods and the impact of various hyperparameter choices on the model's predictive performance."
            },
            "weaknesses": {
                "value": "1.This paper lacks innovativeness, merely combining currently high-performing models without introducing novel elements. The proposed model appears to draw heavily from existing model structures, with limited originality in its design. While the work effectively combines and leverages existing approaches, it lacks a significant level of novelty in terms of introducing truly innovative components.\n\n2.This paper does not provide sufficiently convincing reasons for the selection of these modules. \n\nThe paper offers valuable insights into time series forecasting models and their performance. I encourage the authors to consider further enhancing the originality of the proposed model in future work."
            },
            "questions": {
                "value": "see my concerns"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1793/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698673949755,
        "cdate": 1698673949755,
        "tmdate": 1699636108799,
        "mdate": 1699636108799,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NDUECNmdXs",
        "forum": "v9Sfo2hMJl",
        "replyto": "v9Sfo2hMJl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1793/Reviewer_EGjq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1793/Reviewer_EGjq"
        ],
        "content": {
            "summary": {
                "value": "Propose a long-range forecasting model for multivariate time-series using hybrid aprroach through local and global feature extraction mechanism. Their global feature mechanism leverage more like transformer like architecture and local is CNN architecture. The model adapts for input pre-precessing though instance normalization, patching, and decomposition."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Model Outperforms the baselines in terms of MSE, MAE score. Experiments are done in multiple public datasets including ILI, electricity, weather, traffic,etc.\n\n2. In terms of long-range forecasting range, model outperforms with prediction length upto 60 compared to the transformer architecture and upto 720 compared to the 2nd best performing model PatchTST.\n\n3. Authors showed an extensive ablation analysis showing usefulness of leveraging different modules (local LFE, global GFE, attention, PE, IN, etc) in the hybrid approach.\n\n4. Paper is well-written with convincing experiments."
            },
            "weaknesses": {
                "value": "1. Is there any particular reason to not compare this model with the state-of-the-art long-range forecasting model like Spacetimeformer (Grigsby et al. 2023), and NBeats. Both models perform vey well for long range forecasting on multivariate data. SpaceTimeFormer paper shows result for prediction length upto 672 (on some weather data).\n\n2. LFE and GFE architeture are not very novel, and mostly adapted from state-of-the-arts."
            },
            "questions": {
                "value": "1. Is there a reason why patchTST working so much better than transformer achitetures like AutoFormer/Fedformer, especially, where the ablation studies clearly show attention, PE mechanisms are useful?\n2. Can you show the results compared to SpaceTimeFormer and Nbeats? SpaceTimeformer model also has local+global architeture approach."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1793/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1793/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1793/Reviewer_EGjq"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1793/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698701306359,
        "cdate": 1698701306359,
        "tmdate": 1699636108730,
        "mdate": 1699636108730,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pjGo3O9t8w",
        "forum": "v9Sfo2hMJl",
        "replyto": "v9Sfo2hMJl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1793/Reviewer_Y4Q5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1793/Reviewer_Y4Q5"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to combine different models for the long-term time series forecasting in a framework \"UniTS\", in which Convolutional Neural Network is used to extract local feature and MLP (or Transformer) is used to extract global feature. In addition, this paper points out the unfair comparison issue in existing works due to the lack of standardized parameter design. Experiments on the 8 benchmark datasets are conducted to evaluate the proposal."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper uses the advantages of different models and combines them in a framework for a better long-term time series forecasting. This paper also points out the unfair comparison issue in existing works due to the lack of standardized parameter design."
            },
            "weaknesses": {
                "value": "1. Some parts of the proposal UniTS are not introduced clearly. e.g.,\n\nWhat are the meanings of H^{l,N} and H^{g,N} in Figure 1?\n\nHow to do the LFE and GFE after Patching?\n\nWhat is the meaning of j and what is the Decompose in the first equation of section 3.2.3?\n\n2.  The RLinear and RMLP models in the following reference outperform PatchTST on some datasets. It is better to compare with them as well.\n\nLi, Zhe, et al. \"Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping.\" arXiv preprint arXiv:2305.10721 (2023).\n\n3. I think it is unfair to compare with PatchTST/64 which uses lookback window length 512 only. As shown in the Figure 2 of the PatchTST paper, the performance is also changed with different lookback windows. It is better to choose the best results from different lookback windows for PatchTST as well, since this paper highlights the unfair comparison issue.\n\n4. The hyperparameter selection (including learning rate, hidden size, e.t.c. besides the use of lookback window length) is only used for the proposed UniTS but not for other baselines. I am doubting whether it results in another unfair comparison problem.\n\n5. There is no complexity analysis, especially, the complexity introduced by the hyperparameter selection.\n\nTypos:\n\"four primary categories\" in Page 1 -> \"three primary categories\"\n\n\"Table 1 provides a overaTidell view analysis\" in Page 6 -> \"Table 1 provides a overall view analysis\"\n\nV_i is not used before explaining it in Page 8."
            },
            "questions": {
                "value": "Same to the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1793/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1793/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1793/Reviewer_Y4Q5"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1793/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698721629434,
        "cdate": 1698721629434,
        "tmdate": 1699636108662,
        "mdate": 1699636108662,
        "license": "CC BY 4.0",
        "version": 2
    }
]