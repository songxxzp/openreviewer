[
    {
        "id": "MnyVJ6O5iF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1594/Reviewer_xPJ6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1594/Reviewer_xPJ6"
        ],
        "forum": "JfcLYCqOkQ",
        "replyto": "JfcLYCqOkQ",
        "content": {
            "summary": {
                "value": "The paper proposes a multiple masking strategy for MAE to enhance the local perception ability of Masked Image Modeling. In addition, the paper also summarizes several takeaways from the observation. Downstream experiments on classification, object detection and semantic segmentation show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes an incremental masking strategy based on MAE, which may provide some experience for the community. \n\nThe experiments show the performance gains on multiple downstream tasks."
            },
            "weaknesses": {
                "value": "Actually, the contribution is limited. The proposed method is more of an empirical technique. I do understand the authors have done lots of tuning experiments, however, most of them are not that significant, or even well-known for the community (e.g., the one-shot masking). \n\nIn addition, the three-shot masking is significantly worse than the baseline as shown in Table 5, further implying its limitation."
            },
            "questions": {
                "value": "Please see the weakness. \n\nTypos: fine-grind --> fine-grained"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1594/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697437982938,
        "cdate": 1697437982938,
        "tmdate": 1699636088028,
        "mdate": 1699636088028,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "m6QFKJNyBz",
        "forum": "JfcLYCqOkQ",
        "replyto": "JfcLYCqOkQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1594/Reviewer_MagS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1594/Reviewer_MagS"
        ],
        "content": {
            "summary": {
                "value": "The paper studies masking strategies in masked autoencoders. Moreover, the paper proposes a multi-shot masking strategy for MAE,  and shows the results of downstream tasks, such as image classification, object detection, and semantic segmentation. However, the experiments mainly focus on ImageNet-100 and several downstream tasks to demonstrate the effectiveness. Meanwhile, I am confused about the motivation of this paper."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper explores the application of masking in MAE training and validates its effectiveness through a series of comprehensive experiments. The problem they aim to address seems reasonable to me. The writing in the paper is clear and comprehensible."
            },
            "weaknesses": {
                "value": "1. Readers are confronted with a perplexing dilemma due to the lack of support for motivation in the given context. The second paragraph in the introduction is particularly confusing. The reasons behind the failure of these methods and the evidence supporting the interior robustness of MAE are uncertain. The original MAE paper indicates a more comprehensive evaluation of robustness. These statements appear to be fabricated.\n\n2. In fact, VideoMAE v2 is the first to propose to mask MAE. Therefore, this paper is not the first research to explore the impact of multiple shots masking in MAE.\n\n3. The experimental setting of this paper does not convince me of its results. The dataset selection has several issues. For the main experiments, the author selected the less commonly used benchmark, ImageNet-100. Since the scale and diversity of the data can significantly influence the experimental results, the validity of comparing with MAE is uncertain. Furthermore, the author also failed to choose common datasets for the downstream tasks. Moreover, the article makes adjustments under the original experimental setup conditions of MAE, thus rendering the conclusions drawn from the experiments inaccurate.\n\n4. The proposed method appears to lack technical contributions, and I fail to discern any tangible practical benefits in terms of performance or speed."
            },
            "questions": {
                "value": "Implementing more experiments on the benchmark ImageNet-1k dataset with the same experimental setting is necessary."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1594/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1594/Reviewer_MagS",
                    "ICLR.cc/2024/Conference/Submission1594/Senior_Area_Chairs"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics review needed."
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1594/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698205984739,
        "cdate": 1698205984739,
        "tmdate": 1700651912971,
        "mdate": 1700651912971,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fEDrf3Eddm",
        "forum": "JfcLYCqOkQ",
        "replyto": "JfcLYCqOkQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1594/Reviewer_GAuN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1594/Reviewer_GAuN"
        ],
        "content": {
            "summary": {
                "value": "This article focuses on the mask strategy issue in MAE, which adopts a multi-stage mask approach instead of a fixed mask method. The optimal mask ratio and layer are selected in different stages to mask both the input image and feature layers. The author believes that this method effectively enhances the attention of the mask on locality, and the effectiveness of this method is verified through a series of experiments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Originality**: Although this article proposes new improvements based on the masking strategy of MAE, the problem addressed is a commonly overlooked issue. Through a series of experiments, the author reflects on the mask strategy and verifies the specific role of the mask in SSL.\n\n**Quality**: The article presents a well-organized and well-argued thought process, and the effectiveness of condition-MAE is demonstrated through a series of comparative experiments.\n\n**Clarity**: The article is highly readable, with clear logic and structure.\n\n**Significance**: The further exploration of the role of the mask and the unexpected findings in the experiments are also worth attention."
            },
            "weaknesses": {
                "value": "1. The essence of this article is based on MAE and explores the mask strategy. However, this setting lacks novelty as there have been many studies on mask strategies (e.g., [1-3]), and the related work mentioned is not sufficient. It is hoped that the author can conduct further comparisons and supplements to evaluate performance.\n\n2. Some findings mentioned in the article, such as the non-positive correlation between linear probing and finetune performance, are relatively straightforward. Linear probing mainly evaluates the model's discriminative generalization ability, while finetune focuses on the model's fitting ability to the data. However, there is still a positive correlation, mainly depending on the model's scale. The larger the model, the less obvious the positive correlation.\n\n3. The article proposes that the second-stage mask introduces more locality. However, I am concerned that the feature-level mask may have caused this result, as the input image is low-level, while the feature is high-level. Therefore, the combination of the two naturally makes SSL focus on global and local representations.\n\n\n[1] Choe, J., Shim, H.: Attention-based dropout layer for weakly supervised object localization. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 2219\u20132228 (2019) \n\n[2] Shi, Y., Siddharth, N., Torr, P.H., Kosiorek, A.R.: Adversarial masking for self-supervised learning. arXiv preprint arXiv:2201.13100 (2022)\n\n[3] Wei, C., Fan, H., Xie, S., Wu, C.Y., Yuille, A., Feichtenhofer, C.: Masked feature prediction for self-supervised visual pre-training. arXiv preprint arXiv:2112.09133 (2021)"
            },
            "questions": {
                "value": "1. The mask ratio in the first stage of the article follows the MAE setting, while the best ratio in the second stage is selected manually. However, it is unclear whether this setting will be effective if a different backbone is used instead of VITs. Would it still require manual tuning?\n\n2. There are some minor changes that need to be noted. For example, the sentence \"The dashed line denotes the one-shot baseline with masking ratios of 0.75 and 0.9 respectively\" is unclear in terms of the baseline used in the graph. Additionally, the experiment with a mask ratio of 0.9 is missing, and if it is included in the appendix, it should be mentioned to improve readability. In the \"Potential Application\" section, \"fine-grained\" should be used instead of \"fine-grind\", and there are inconsistencies in the use of nouns throughout the article.\n\n3. In Figure 4, it can be seen that the difference between layer 0-3 and layer 0-6 is significant, and according to your statement, there should be an improvement. However, the experimental results show a decrease from 84.1 to 84.0. On the other hand, the improvement from layer0-6 to layer0-9 is significant, but the graph shows that the difference from the baseline is not as significant. This has caused some confusion, and it would be helpful if the author could explain this discrepancy."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1594/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698675518506,
        "cdate": 1698675518506,
        "tmdate": 1699636087863,
        "mdate": 1699636087863,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OiuqMXbuii",
        "forum": "JfcLYCqOkQ",
        "replyto": "JfcLYCqOkQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1594/Reviewer_JZAj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1594/Reviewer_JZAj"
        ],
        "content": {
            "summary": {
                "value": "This work is a systematic empirical study of multi-shot masking in MAE by applying additional masking on hidden representations on chosen layers of the encoder on top of input masking in standard MAE. The ratios of masking (different ratios used at different layers) and how many of these additional masking (\u201cshots\u201d) are extensively studied. There are several interesting insights from these studies, as clearly stated in the introduction by the authors: Masking at the beginning is always beneficial for task performance, with 75% being optimal; building on one-shot masking, increasing the interval of two-shot masking with a large first ratio and a small second ratio is helpful; a small third ratio is helpful for three-shot masking; and more. Extensive and crucial analyses have been performed, such as linear probing / fine-tuning on models with different numbers of masking shots, different masking ratios, and masking levels, Centered Kernel Alignment, attention distance and entropy, visualization, robust analysis, and classification on fine-grained datasets, and transfer learning.\n\nGiven the strong, comprehensive empirical analysis and the great presentation of this submission, the reviewer recommends an acceptance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Originality: as the author rightfully cited and compared, there have been numerous works analyzing and studying masked image modeling. However, to the reviewer\u2019s knowledge, this is the first paper to study the effect of multiple masking ratios across different layers in the MAE encoder. The work is, in this sense, original.\n\nQuality: the quality of the paper is high in terms of experimental results and analysis. First, four layers at equal intervals, five masking ratios, and two model sizes (ViT-S/16 and ViT-B/16) are considered, and the representations of one-shot, two-shot vs. three-shot maskings are carefully compared via linear probing/fine-tuning,  Centered Kernel Alignment of layer representation, attention distance and entropy, and fine-grained locality oriented datasets such as Flower102, Stanford Dog and CUB-200. The transfer learning analysis is also done on COCO for detection and ADE20K for semantic segmentation. There are further studies on robustness measured by classification results after occlusion and shuffling perturbation and the scalability of performance under different model sizes.\n\nClarity: this paper is very well written, with key messages clearly presented, results from each section nicely summarized, and key figures carefully designed.\n\nSignificance: given that masking image modeling is a popular topic, the research is beneficial to the community by creating new potentials to improve existing approaches with multi-shot masking."
            },
            "weaknesses": {
                "value": "Post rebuttal update: the authors successfully clarified the differences between this work and previous methods and provided extensive discussions. Therefore, the rating was updated.\n\n----------------------------------\n\nOriginality: progressive masking has been extensively studied in generative modeling or the combination of SSL and generative modeling [1-3]; adaptive masking strategies on images or languages have also been proposed [4-5]. However, the authors did not cite or discuss them.\n\nQuality: Considering the nature of ICLR, the biggest weakness of this paper is not having any theoretical results, insights, or even discussions about the proposed approach. The insights are not theoretically backed, reducing the quality of the work.\n\nThe scalability discussion in Sec. 3.4 is weaker because there are only two model sizes. Also, the pre-training is done using ImageNet-100, creating a gap between the conclusions of the submission and the hypothetical behaviors of MAE trained on ImageNet-1K using multi-shot masking.\n\n[1] Chang, Huiwen, et al. \"Maskgit: Masked generative image transformer.\" CVPR 2022.\n\n[2] Chang, Huiwen, et al. \"Muse: Text-to-image generation via masked generative transformers.\" 2023.\n\n[3] Li, Tianhong, et al. \"Mage: Masked generative encoder to unify representation learning and image synthesis.\" CVPR 2023.\n\n[4] Bandara, Wele Gedara Chaminda, et al. \"AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with Masked Autoencoders.\" CVPR 2023.\n\n[5] Xiao, Yisheng, et al. \"AMOM: adaptive masking over masking for conditional masked language model.\" AAAI 2023."
            },
            "questions": {
                "value": "1. The authors may not need to perform empirical experiments on this, but what would the authors conjecture about using a low masking ratio (e.g., 0.1) on the beginning position for one-shot masking?\n\n2. \"We reconstruct it primarily conditioned on the 'borrowed' information through such interaction.\" The authors may rephrase this sentence to be more precise. \n\n3. Minor grammar errors: \"We need reconstruct two targets\", and \"pretaining loss\" in Figure 7."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1594/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1594/Reviewer_JZAj",
                    "ICLR.cc/2024/Conference/Submission1594/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1594/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698790203987,
        "cdate": 1698790203987,
        "tmdate": 1700624055447,
        "mdate": 1700624055447,
        "license": "CC BY 4.0",
        "version": 2
    }
]