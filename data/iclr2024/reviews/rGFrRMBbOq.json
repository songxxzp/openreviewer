[
    {
        "id": "nPmum0tBx5",
        "forum": "rGFrRMBbOq",
        "replyto": "rGFrRMBbOq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission566/Reviewer_H5Ez"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission566/Reviewer_H5Ez"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses a novel practical task scenario where a pretrained video neural implicit representation needs to continually learn new data while keeping the learned information. It proposes a novel Progressive Fourier Neural Representation method to tackle this, which continuously learns a compact subnetwork for each video in Fourier space. The proposed method is tested on several datasets with multiple metrics including PSNR and SSIM, and proves to outperform the baseline and other competiters."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The problem of encoding new videos into existing video INRs is important in practice, and the proposed method addresses it well according to the experiment results with higher PSNR and SSIM compared to other competitiers.\n\n- Besides the detailedly listed final metric results, it also shows abundant ablations on several hyperparameters and such as which layer to choose for the proposed model to learn etc., in both the main paper and the supplementary.\n\n- Many baselines are discussed in the related work section as well as compared technically in the experiments."
            },
            "weaknesses": {
                "value": "- Although the quantitative results are listed in details for every video in two settings, overall the proposed method is only tested on two datasets, and both UVG series. More diverse choices would make the results more solid, such as the DAVIS dataset series etc.\n\n- The compression performance (model size) is not well tested and displayed, especially in the tables. Figure 2 and its paragraph discussed some but is still not clear to link with the values in other tables.\n\n- The illustration of the proposed method is relatively limited, e.g. about the details in Fourier space, which might hide the novelty and complexity of the proposed method.\n\n- Not many visual comparisons are provided especially in the main paper, and Figure 7 is not specifically explained on their differences and advantages etc.\n\n- [Minor] Section 3.1 said that Figure 1 is one \"possible\" structure, while there isn't any other design mentioned in this paper. Maybe there can exist more variants but if not mentioned then Figure 1 is just exactly \"our proposed structure\" to be clearer.\n\n- [Minor] Figure 1 is overall good but the font and diagram size is a bit small compared to frame images.\n\n- [Minor] Sometimes the HNerv paper is noted as Nerv (but with the correct 2023 reference)."
            },
            "questions": {
                "value": "- In the abstract and introduction, it is illustrated that since the INRs learn to memorize videos \"regardless of data relevancy or similarity\", it is hard for them to be generalized to multiple complex data and thus continual learning is important for the models to learn new videos without forgetting previously learned videos. I agree that memorizing videos regardless of data relevancy or similarity limits INRs' efficiency and scalability, but shouldn't this characteristic help an INR to learn multiple unrelated videos compared to those that learn with data relevancy or similarity?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Reviewer_H5Ez",
                    "ICLR.cc/2024/Conference/Submission566/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission566/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698825568160,
        "cdate": 1698825568160,
        "tmdate": 1700522303406,
        "mdate": 1700522303406,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "G5WwUR57Dx",
        "forum": "rGFrRMBbOq",
        "replyto": "rGFrRMBbOq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission566/Reviewer_MyBt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission566/Reviewer_MyBt"
        ],
        "content": {
            "summary": {
                "value": "The response provides a comprehensive analysis of a work focused on Neural Implicit Representation (NIR) for video data encoding. The work introduces a novel method, Progressive Fourier Neural Representation (PFNR), to improve the accumulation and transfer of neural implicit representations for complex video data across sequential encoding sessions. PFNR leverages a sparsified neural encoding in Fourier space, enabling better adaptation for future videos and lossless decoding for previous representations. The method shows impressive performance gains over continual learning baselines on UVG8/17 video sequence benchmarks.\n\nStrengths of the work include the novel and straightforward concept of combining Fourier representation with sparsification and the method's superior performance over baselines with the same capacity. However, weaknesses are noted in the manuscript\u2019s clarity, particularly in interpreting tables and comparing performance to baselines, as well as in the diverse configuration for Fourier transform.\n\nSeveral questions are raised, seeking clarification on the commonality of NIR usage, details on Fourier transform configurations, baseline performances in Single Task Learning, comparisons to WSN, the meaning of outperforming an upper bound, and a typo in Table 3. These questions aim to probe deeper into the work\u2019s methodology, performance, and presentation for a clearer understanding and evaluation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed idea, combining Fourier representation and its sparsification is a straightforward and novel concept.\n2. With the same capacity, the proposed method provides better performance over baselines."
            },
            "weaknesses": {
                "value": "1. The target task seems to be small compared to the generality of the method.\n2. The tables are a little hard to interpret.\n3. The current version of the manuscript is missing comparable performance to its baselines.\n4. The diverse configuration for Fourier transform."
            },
            "questions": {
                "value": "1. Is it common to use neural implicit representation (NIR)? As I know, many works adopt the term implicit neural representation (INR) rather than NIR.\n2. The configuration for Fourier transform?\n    - What is the temporal length of frames ($d_\\nu$ in the paper right?) Does the $d_\\nu$ affect the final performance?\n    - Some sparsification protocols for Fourier transform ignore an imaginary part in both Fourier and inverse Fourier transform. \n3. The performances of baselines in Single Task Learning (STL).\n    - What is the performance of the proposed method with Single Task Learning (STL)? Does the proposed method impact negatively due to the proposed components for continual learning?\n    - How about the performance only FSO without Conv block in NeRV block?\n4. Comparison to WSN\n    - What is the averaged PSNR and MS-SSIM performance of the proposed method and WSN on UVG8/17 with varying capacity? It is better to visualize in plot of the performance and capacity rather than table because the capacity of the model seems to be important for this setting. I conjecture that table 8 is the good starting point.\n5. Meaning of upper bound \n    - The proposed method, PFNR, outperforms the upper bound, MLT. What is the reason behind?\n6. Typo\n    - Table 3 shows the result of MS-SSIM while the caption has PSNR."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Reviewer_MyBt"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission566/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698855234932,
        "cdate": 1698855234932,
        "tmdate": 1700500185504,
        "mdate": 1700500185504,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "o7O6BVPsaY",
        "forum": "rGFrRMBbOq",
        "replyto": "rGFrRMBbOq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission566/Reviewer_uKbd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission566/Reviewer_uKbd"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the neural implicit representation in continual learning settings and proposes a novel method to encode the learned knowledge compactly. With this design, the model becomes able to accumulate neural representations for multiple videos with few decoding losses for previous videos. Experiments on UVG8/17 verifies its effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed learning scenario is very practical in real applications, that is, encoding multiple videos continually via a neural implicit representation. With this setting, the generalization ability of NIR can be evaluated.\n\n2. I like the idea that incorporates the Lottery Ticket Hypothesis to find subnetworks for each video session. Frozing these subnetworks proves to be an effective way to encode existing knowledge about previous videos.\n\n3. The designed experiments verify its ability to adapt to new training sessions. With the proposed methods, the performance achieved significant improvements."
            },
            "weaknesses": {
                "value": "1. The writing is not so clear. It's hard to learn the connection of Sec 3.1 with other sections.\n\n2. The experiments miss one important point. All tables show the results of the newly added sessions. However, to verify the \"lossless decoding\" stated in the abstract, previous videos need also to be evaluated. Otherwise, the reported metrics only verify the quick adaptation ability of the proposed method.\n\n3. There are some neglected details.\n- At the 2nd line of Sec 3, the cited paper is E-NeRV instead of NeRV.\n- In the caption of Fig 1, the symbol $H_N$ is used without definition and no further usage.\n- At the line before Eq 3, should it be \"session s\" instead of \"session t\"?\n- I suggest moving Algorithm 1 to the same page as Sec 3.2, where it is referred."
            },
            "questions": {
                "value": "In Algorithm 1, the operation at line 7 is not differentiable, so how to calculate $\\partial L / \\partial \\rho$?\nI'm willing to change my score if all my issues can be solved"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Reviewer_uKbd"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission566/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698916809324,
        "cdate": 1698916809324,
        "tmdate": 1700722976883,
        "mdate": 1700722976883,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LidXaaBhGG",
        "forum": "rGFrRMBbOq",
        "replyto": "rGFrRMBbOq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission566/Reviewer_inAP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission566/Reviewer_inAP"
        ],
        "content": {
            "summary": {
                "value": "This article addresses the existing problem in Neural Implicit Representation (NIR) that these models specialize in learning only one mapping between target data and fail to generalize when implemented over more data, thus limiting scalability. The authors propose a modification on top of the NeRV pipeline [Chen et al, 2021a]. In order to capture information while doing a fine discretization of model parameters, the authors transform the weights to the Fourier space, on the lines of the work done by [Li et al., 2020a]. Experimentation has been done on Video Task-incremental Learning and comparisons have been made against relevant baselines. The experiments closely follow NeRV [Chen et al, 2021a] and HNeRV [Chen et al., 2023] to make fair comparisons. Results are satisfactory and visualizations look good.\n\n\nHao Chen, Bo He, Hanyu Wang, Yixuan Ren, Ser Nam Lim, and Abhinav Shrivastava. Nerv: Neural representations for videos. Advances in Neural Information Processing Systems, 34:21557\u201321568, 2021a.\n\nZongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations. arXiv preprint arXiv:2010.08895, 2020a\n\nHao Chen, Matt Gwilliam, Ser-Nam Lim, and Abhinav Shrivastava. Hnerv: A hybrid neural representation for videos. arXiv preprint arXiv:2304.02633, 2023."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The article benefits from generally good writing, appropriate use of mathematical language. \n\nBackground literature survey is highly appropriate and extensive.\n\nThe article builds on top of a NeRV pipeline, addressing relevant and interesting shortcomings. The rationale behind the use of Fourier Subneural Operators has been developed clearly.\n\nExtensive experimentation and provision of visual results in the paper and the supplementary file also adds to the strengths of the paper. Results are satisfactory.\n\nThe ability of the model to generate videos has also been shown in the supplementary document which only adds to the broader impacts of the research done by the authors."
            },
            "weaknesses": {
                "value": "The methodology section may appear somewhat difficult to some readers without the necessary background in the domain. This however is only a minor weakness that does not affect the final rating.\n\nIt is not very clear if the authors used the exact frame sizes of the videos as available, or if the authors did any spatial or temporal downsampling on the videos to fit the model training pipeline, as is usual with most papers pertaining to video data.\n\nIt appears that the model may be limited by computational expenses as the datasets used are that of short video clips."
            },
            "questions": {
                "value": "How does the proposed architecture compare with existing baselines in terms of computational requirement? Does the FSO module increase the computational requirements significantly from the baseline NeRV?\n\nHow many frames for each video was considered during training? Can the authors elaborate the video frame resolution vs frame rate trade-off i.e. what\u2019s the maximum number of frames that can be considered at a time at a certain resolution or what\u2019s the maximum resolution that can be processed at a certain number of frames?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "none"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission566/Reviewer_inAP"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission566/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698936526306,
        "cdate": 1698936526306,
        "tmdate": 1699635983841,
        "mdate": 1699635983841,
        "license": "CC BY 4.0",
        "version": 2
    }
]