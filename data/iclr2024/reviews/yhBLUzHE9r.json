[
    {
        "id": "mnCNjIMasE",
        "forum": "yhBLUzHE9r",
        "replyto": "yhBLUzHE9r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1008/Reviewer_N48q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1008/Reviewer_N48q"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes Silencer, which is a model pruning scheme designed to defend against (possibly dynamic) poisoning attacks in decentralized federated learning scenarios.\n\nThe threat model assumes a small portion of malicious clients trying to minimize the loss over a poisoned dataset.\nTo determine which parameters in the trained architecture are important, Silencer utilizes the (approximate) fisher information (FI) metric across clients. \n\nIt uses pruning aware training utilizing FI to train local sparse models and then consensus filtering to filter globally unimportant parameters based on FI. The high-level idea (as stated in the paper) is that the poisoned parameters would only be deemed important for adversaries \u2013 namely, parameters that are shared by minority will most likely be the poisoned ones."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The paper is clearly written and concise. \n\n2. Evaluation results show improvement over several previous defense techniques."
            },
            "weaknesses": {
                "value": "1. The threat model is not convincing. It assumes that the poisoned data is concentrated in a small group of clients rather than having some poisoned data that can be scattered over many clients. \n\n2. The consensus filtering approach is not convincing. It non-explicitly assumes that malicious clients have no knowledge about any data except their own which is unrealistic. It also appears to non-explicitly assume some data similarity in non-IID setups.\n\n3. The evaluation is insufficient. With respect to the motivation that mentions LLMs, the evaluation is based on few toy CNNs and datasets.\n\n4. There is no sufficient evidence (theoretical or empirical) for why Silencer with DFL converges."
            },
            "questions": {
                "value": "1. Can Silencer perform well when there is a small portion of poisoned data scattered over many clients? or when malicious clients have also benign datasets?\n\n2. How the pruning approach affects the ML performance of contemporary models? e.g., perplexity of a LLM? \n\n3. FL is designed to keep clients' data private. With a centralized coordinator, privacy can be enhanced using DP and secure aggregation techniques. What privacy guarantees can be expected in DFL?\n\n4. In a non-IID DFL setup, each client may have a different data distribution with different resulting FI. In that case, why consensus filtering is expected to work?\n\n5. In a non-IID DFL setup, multiple local steps may result in bad performance without additional mechanisms to prevent client drift. Has this consideration been taken into account in the non-IID evaluation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Reviewer_N48q"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1008/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697639670276,
        "cdate": 1697639670276,
        "tmdate": 1699636026726,
        "mdate": 1699636026726,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0m4V05YP8R",
        "forum": "yhBLUzHE9r",
        "replyto": "yhBLUzHE9r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1008/Reviewer_fqq5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1008/Reviewer_fqq5"
        ],
        "content": {
            "summary": {
                "value": "The paper propose Silencer, an algorithm resilient to poisoning attacks in gossip algorithms by identifying suspicious updates due to their diagonal of empirical Fisher information matrix and pruning the suspicious nodes at the neighbors level. The contributions are to use the empirical Fisher information matrix, to design a pruning scheme in decentralized learning, and to evaluate empirically their methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Silencer maintains a good accuracy compared to other defenses mechanism\n- Computing the Fisher Information matrix looks like a sound idea, and the masking strategy seems realistic\n- The experiments are quite detailed, with various datasets and topology for the graphs."
            },
            "weaknesses": {
                "value": "- Silencer performances are clearly reduced as soon as the attackers try to learn the masks, making the interest of the method questionable\n- The \"finding\" of the fact that Fisher information matrix is a good signal for different objective function seems not so novel, as per definition it is roughly the average \"sensitivity\" of the log-likelihood to changes of the parameters.\n- page 8 is an example of excess of tables and is barely readable. There are 8 tables and 7 figures in the main text!"
            },
            "questions": {
                "value": "- can you adapt your solution to accelerated gossip or asynchronous gossip ?\n- could you explain the curves of the figure 1? I am not sure to see what are the conclusions of it.\n- could you comment on the extra computation needed by silencer? I believe you only discussed the speedup due to sparsity, but does it compensate the extra computation needed?\n- could you comment on the stability? I saw some paragraph in appendix (Decay+ Pruning Reclamation) but it is not clear to me what are the keys messages and intuition"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Reviewer_fqq5",
                    "ICLR.cc/2024/Conference/Submission1008/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1008/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698701128849,
        "cdate": 1698701128849,
        "tmdate": 1700497857173,
        "mdate": 1700497857173,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ISX9aVTJTw",
        "forum": "yhBLUzHE9r",
        "replyto": "yhBLUzHE9r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1008/Reviewer_m7hp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1008/Reviewer_m7hp"
        ],
        "content": {
            "summary": {
                "value": "The paper demonstrates the SILENCER framework for back-door defense in the decentralized federative learning setting by pruning. The authors first stated the interesting findings when probing the weight and the Fisher information of malicious clients' weight compared with benign clients. Then based on the observation, the authors proposed a two-stage pruning-aware training by asking the client to only train a subset of the weights that are important locally and prune the weights that are considered unimportant. Based on extensive experiments, the proposed method achieves the SOTA performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The findings of the weights dynamics and the fisher information seem exciting and could benefit the following research.\n2. The proposed framework achieves the SOTA performance, which is attractive.\n3. The presentation of the paper is easy to understand. And there are variations of the proposed algorithm in the different settings."
            },
            "weaknesses": {
                "value": "1. Although the paper visualized the statistical comparison in Figure 3(a), it looks like the approximation is not good for coordinates around 300. Considering the evaluated models are small in experiments. I wonder if the proposed method will work on larger models, for example, ResNet50. \n2. There is a gap between the observation of the stability of the Fisher information and using the magnitude of the Fisher information as the indicator for pruning. \nSuppose the magnitude of the fisher information of benign models could be larger than the malicious models. In that case, I will consider this work an extension of the pruning based on the sharpness, one of the significant investigated indicators of the hessian in the generalization field. Previously, people believed that the low sharpness directly leads to better generalization. However, this is not true based on the recent paper, and I think it will comprise the contribution of the proposed method.\n\"A Modern Look at the Relationship between Sharpness and Generalization, ICML 2023\"\n3. Some major unclear content:\n    a. How to see the pruning rate in Figure 3c, since the authors mentioned: \".. ASR is significantly reduced with a small pruning rate\".\n    b. Line 12 of algorithm 1 is different from Equation 8. I think the mask should also be included in line 12."
            },
            "questions": {
                "value": "1. What is the error when approximating the hessian with the diagonal of FI with respect to the training process of the whole model? The gradient will close to 0 when closing to convergence, but the hessian will not.\n2. What is the connection between the FI stability and using the magnitude for pruning? The variance should be used to measure the stability.\n3. What is the relation between the proposed method and sharpness minimization?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Reviewer_m7hp"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1008/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767239599,
        "cdate": 1698767239599,
        "tmdate": 1700278486598,
        "mdate": 1700278486598,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LBqkCbrgzN",
        "forum": "yhBLUzHE9r",
        "replyto": "yhBLUzHE9r",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1008/Reviewer_dudw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1008/Reviewer_dudw"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a defense mechanism for backdoor attacks in decentralized FL based on parameter pruning. The effectiveness of the proposed method is evaluated and compared with other baseline defenses empirically."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe findings on the invariance of poisoning pattern that motivates the defense is interesting.\n2.\tExperiments on multiple attacks, defenses, and datasets are performed.\n3.\tThe paper is well written."
            },
            "weaknesses": {
                "value": "1.\tMore discussions and explanations on the invariance of poisoning pattern are needed. Why this is the case? Does this hold for particular types of backdoors or more general cases, e.g., clean and dirty label backdoors? \n2.\tThe threat model only considers the backdoor injection during training and does not consider the possibilities of adversary manipulating the masking process, which significantly simplifies the defense design. While the authors include discussions and evaluations on adaptive attacks in the experiments, it does not exclude other malicious attacks to surpass the defense.\n3.\tFrom the experiment results, Silencer is outperformed by other defenses in some scenarios. For example, in Table 1 ASR compared with D-Bulyan, in Table 8 on the FashionMnist and GTSRB datasets."
            },
            "questions": {
                "value": "See weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1008/Reviewer_dudw"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1008/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828005457,
        "cdate": 1698828005457,
        "tmdate": 1699636026450,
        "mdate": 1699636026450,
        "license": "CC BY 4.0",
        "version": 2
    }
]