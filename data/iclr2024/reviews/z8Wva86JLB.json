[
    {
        "id": "Lui0jtvpzp",
        "forum": "z8Wva86JLB",
        "replyto": "z8Wva86JLB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6542/Reviewer_xPkB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6542/Reviewer_xPkB"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces GEOFFair, a framework that convert the conventional fairness formulation using probability distributions into vector representation in the Hilbert space. The authors claim that their formulation offers a more intuitive understanding of fairness related concepts, and visualizes fairness mitigation techniques."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1.\tThe authors provide a taxonomy of fairness in Section 2.4 under their vector representation\n2.\tThe authors discuss the case of finite samples"
            },
            "weaknesses": {
                "value": "1.\tThe authors claim that the conventional formulation for fairness interventions using probability distributions is challenging; however, they fail to provide concrete evidence on why it is challenging (e.g., in terms of computational efficiency). Therefore, their proposed vector representation seems unnecessary, as I do not see any advantages using this vector representation in terms of easier optimization, or could potentially lead to a new fairness metric with better operational meanings.\n2.\tThe authors claim that the proposed vector representation offers a more intuitive understanding and visualization, but fails to provide any evidence throughout the paper (just one figure in Section 3.3), nor do they provide any algorithm to implement/ compute the Fair Projection stated in Property 1. There are also no numerical results at all. \n3.\tThe taxonomy introduced in Section 2.4 is trivial and provide no new insights for fairness problems. \n4.\tThe connection/ discussion between existing fairness intervention methods/ notions and the proposed vector representation is lacking, indicating an insufficient literature survey. For example, how could existing methods such as multi-calibration, multi-accuracy, FERMI, FairProjection, Reduction, etc. benefit from this new framework? \n5.\tThe authors only discuss very limited fairness constraints (equalized odds, a very common metric, is missing), and it is doubtful that the proposed framework is meaningful for many other fairness constraints. \n6.\tDespite that the authors discuss finite sample case, they fail to provide a sample complexity bound/ error probability bounds.\n7.\tIt is well-known that the accuracy and fairness forms a trade-off. This paper fails to discuss this trade-off, which is the most important consideration in practice."
            },
            "questions": {
                "value": "Please refer to the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6542/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6542/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6542/Reviewer_xPkB"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6542/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698700812343,
        "cdate": 1698700812343,
        "tmdate": 1699910279742,
        "mdate": 1699910279742,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lU9KWrdOgG",
        "forum": "z8Wva86JLB",
        "replyto": "z8Wva86JLB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6542/Reviewer_p9x9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6542/Reviewer_p9x9"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors introduce GEOFFair, a geometric framework that offers an intuitive and visual understanding of fairness in machine learning (ML). It represents ML components as vectors and sets, making fairness concepts and mitigation techniques easier to grasp and analyze. Specifically, the main contributions of GEOFFair include visualizing fairness mitigation as vector projections, investigating bias injection, constructing proofs, and studying fairness properties through geometric considerations. The authors emphasize that maximizing accuracy based on observed labels may not always lead to optimal fairness outcomes."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tIn this paper, the authors introduces GEOFFair, a Geometric Framework for Fairness, which stands out as an innovative approach in the realm of machine learning fairness. By representing machine learning elements as vectors and sets, it provides a more intuitive and visual understanding of fairness-related concepts, which is a significant departure from traditional, complex mathematical analyses.\n\n2.\t GEOFFair not only provides theoretical insights but also offers practical utility through the visualization of fairness mitigation techniques."
            },
            "weaknesses": {
                "value": "1.\tThe paper does not provide a clear and specific definition of 'fair outputs.' Given the potential for varied interpretations of fairness, a concrete definition or examples would enhance the manuscript's clarity and applicability. I recommend that the authors incorporate case studies or examples to illustrate the potential differences in fair outputs and how these differences can be quantified within the vector space.\n\n2.\tThis paper lacks an in-depth discussion on the trade-off between model fairness and performance. This is a crucial aspect of machine learning models, and the manuscript would benefit from a detailed explanation on how to measure and visualize this trade-off. I suggest that the authors add content to explicitly address this trade-off, providing methodologies or visual aids to assist readers in understanding its implications on the model's outputs.\n\n3.\tSome of the assumptions made in this paper are not clearly articulated. Providing additional examples and a clearer explanation of these assumptions would aid in the reader\u2019s comprehension and application of the presented framework. I recommend that the authors revisit the section on assumptions, ensuring that they are explicitly stated and supported by relevant examples.\n\n4.\tThis paper should address how the labeling of assumptions in the proposed methodology is ensured to be unbiased. Additionally, given the possibility of biased labeling, the manuscript would benefit from a discussion on how to validate the model under such circumstances. I suggest that the authors provide guidelines or methods to check for biases, mitigate them, and validate the model."
            },
            "questions": {
                "value": "In the paper, the term 'fair outputs' is used extensively, but it lacks a specific definition or concrete examples. I appreciate if the authors could provide a clear and specific definition of 'fair outputs' and enhance the paper with case studies or examples that illustrate potential variations in fair outputs? How can these differences be quantified within the vector space to provide clarity and applicability to proposed framework?\n\nIn the paper, the authors touches on the crucial aspect of balancing model fairness and performance, but it does not delve into a comprehensive discussion or provide methodologies to measure and visualize this trade-off. I appreciate if the authors could expand on this topic, providing detailed explanations, methodologies, or visual aids to help readers understand the implications of this trade-off on the model's outputs? How does addressing this trade-off contribute to the robustness and fairness of the model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6542/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698813827127,
        "cdate": 1698813827127,
        "tmdate": 1699636737186,
        "mdate": 1699636737186,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9U8YExyTVE",
        "forum": "z8Wva86JLB",
        "replyto": "z8Wva86JLB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6542/Reviewer_w6Hu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6542/Reviewer_w6Hu"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a geometric framework for fairness, where distributions and (learned) conditional distributions are represented as infinite-dimensional vectors, and hypothesis classes as sets. It makes the observation that a model that maximizes accuracy based on observed labels may not always be optimal for fairness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper is clear and I see no issue with the claims made."
            },
            "weaknesses": {
                "value": "In my view, the core observation of the paper is that a distribution can be represented as an infinite length transcript of samples from that distribution, and function evaluations can likewise be represented as the infinite length vector of the evaluation of the function over the transcript. This representation conserves conditional means (in the almost sure sense).\n\nI just fail to see how this framework provides any insight, actionable or otherwise, on the fairness problem that is not equally or more simply understood in the original statistical framework. Figure 1, for example, could just as easily be drawn using the set of achievable (conditional) probability distributions. \n\nDefinitions 1 and 2 are additionally 'intuitive' but not formal."
            },
            "questions": {
                "value": "What are the practical or theoretical advantages of this framework over the standard probability framework."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6542/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699233318490,
        "cdate": 1699233318490,
        "tmdate": 1699636736959,
        "mdate": 1699636736959,
        "license": "CC BY 4.0",
        "version": 2
    }
]