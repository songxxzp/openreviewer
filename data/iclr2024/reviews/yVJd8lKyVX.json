[
    {
        "id": "Gc9P5F8n1v",
        "forum": "yVJd8lKyVX",
        "replyto": "yVJd8lKyVX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5495/Reviewer_7ihD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5495/Reviewer_7ihD"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a transformer-based approach with mixture-of-experts design for multi-label classification task.  The approach is design for better leveraging semantic correlation and heterogeneity among labels. The experiments on Pascal Voc and MSCOCO datasets show the effectiveness of the propose approach and get SoTA performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The paper offers valuable insights on multi-label classification, the solution based on MoE is a pretty novel view.\n\n+ The approach achieves good results.\n\n+ The paper is well-organized and have clear figures and demonstrations."
            },
            "weaknesses": {
                "value": "The main concern I have is in the experiment section.\n\n1). The author missed some important experiments on MS-COCO.  The latest paper chosen for comparison is the ML-Decoder. However, the author didn't choose the same model backbone and the same image resolution to make a fair comparison. Besides, the model backbone pretraining details can also be an important factor in the model performance, so what's the difference between these methods?.\n\n2). The ML-Decoder's code is available for years, the author should also fill the blanks in (CF1 OF1 CF1 OF1).\n\n3). The ML-Decoder's paper and code is publicly available on arxiv at 2021, they didn't make any change to their best results even when they published to WACV 2023. This means all the results you compared with are before or in 2021, so why not choose some latest methods in 2022 and 2023 for comparison?\n\n4). Please indicate the Flops and Parameters in the experiments and compared with the mentioned methods.\n\n5). MSCOCO is a relatively small dataset with well annotated labels in the multi-label classification task. Why not using NUS-WIDE or OpenImages Dataset which are stronger benchmark and can also show the robustness of the model under the case with more labels and more data?"
            },
            "questions": {
                "value": "Please answer the questions in [weaknesses]."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5495/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5495/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5495/Reviewer_7ihD"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5495/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697952990587,
        "cdate": 1697952990587,
        "tmdate": 1700647346622,
        "mdate": 1700647346622,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9jHxIItmvZ",
        "forum": "yVJd8lKyVX",
        "replyto": "yVJd8lKyVX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5495/Reviewer_rQYR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5495/Reviewer_rQYR"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors regard the multi-label image recognition task as a multi-task problem. To address the \"label heterogeneity\", the authors propose a transformer-based model, Hybrid Sharing Query (HSQ), that introduces the mixture-of-experts architecture to multilabel classification, which leverages label correlations while mitigating heterogeneity effectively. As presented in their experiment results, the proposed framework achieves state-of-the-art performance, which demonstrates the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. It is novel that presenting a \"mixture of experts\" to the multi-label image recognition task, which is ignored in previous MLR works.\n2. The design of the proposed framework is technically clear, and the experiment results demonstrate its effectiveness."
            },
            "weaknesses": {
                "value": "1. As the core motivation, the authors should provide a detailed and comprehensive discussion about \"label heterogeneity\" in MLR.\n2. In the hybrid sharing layer, what is the difference between the task-specialized experts group and the semantic features in other MLR works? And what is the shared experts group? These are crucial for understanding this work.\n3. Could you provide some visualizations of the impact of the shared experts group? Considering the claim \"shared experts help to extract correlations between tasks, encourage positive correlation sharing and suppress negative transfer\""
            },
            "questions": {
                "value": "Please see the above weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5495/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5495/Reviewer_rQYR",
                    "ICLR.cc/2024/Conference/Submission5495/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5495/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698635278712,
        "cdate": 1698635278712,
        "tmdate": 1700790569852,
        "mdate": 1700790569852,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zhRrC1RCpR",
        "forum": "yVJd8lKyVX",
        "replyto": "yVJd8lKyVX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5495/Reviewer_2H28"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5495/Reviewer_2H28"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the issue of heterogeneity in the multi-label learning process. It transforms multi-label tasks into multi-task learning and innovatively incorporates the MoE model into visual classification tasks. Drawing inspiration from models like MMoE and PLE, the authors employed multiple experts and gating theories to learn various labels in their experiments. To prevent negative transfer during the model learning process, they also employed a shared expert approach to learn label correlations. Finally, the authors conducted experiments on the VOC and MS-COCO datasets and achieved outstanding performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Innovatively introducing the MoE model from the NLP field into the domain of computer vision, the paper achieved outstanding results. The use of gating and expert effectively enhanced the model's capacity for relationship modeling in multi-label tasks.\n2. The paper's algorithmic description is concise and clear, with pseudo-code illustrating the core model workflow.\n3. The experiments are comprehensive, including model comparisons, ablation studies, and visualizations."
            },
            "weaknesses": {
                "value": "1. In the ablation experiments section, there is a lack of explanation for the decrease in experimental performance, particularly why the performance declines when n_t is 1 and n_s is 0, and why is there not a more in-depth exploration of the impact of the quantities of n_s and n_t on the results?\n2. There is a lack of visualization of how different experts in the model process images.\n3. Contribution 1 and Contribution 2 appear quite similar. The experiments on heterogeneity are not sufficiently intuitive, why is it solely demonstrated through experiments rather than being theoretically proven? \n4. The paper uses extensive textual descriptions in the methodology section; using formulas would provide a more concise representation.\n5. Although the paper incorporates the MoE model, it has relatively few innovative aspects of its own."
            },
            "questions": {
                "value": "1. What is the significance of Figure 6? The reduction in image resolution implies a decrease in information, which may lead to a decline in the model's performance. How does this relate to robustness?\n2. What is the difference between hybrid experts and attention mechanisms? Is the model's good performance due to the introduction of a large number of parameters? Does MoE in the paper improve training speed? It is recommended to conduct an efficiency experiment to verify this question.\n3. MoE models generally encounter the issue of load balancing. Is there a possibility that certain experts consistently dominate during the model training process? It is recommended to conduct an experiment to verify this question."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5495/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5495/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5495/Reviewer_2H28"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5495/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698749066505,
        "cdate": 1698749066505,
        "tmdate": 1700661140545,
        "mdate": 1700661140545,
        "license": "CC BY 4.0",
        "version": 2
    }
]