[
    {
        "id": "rBe8llQFQn",
        "forum": "uUELOzcTk8",
        "replyto": "uUELOzcTk8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4207/Reviewer_sPYy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4207/Reviewer_sPYy"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to generate adversarial examples while avoid compromising semantic information. To achieve this goal, they propose a semantic distance which replaces the geometrical distance. Then, they utilize the technique of Langevin Monte Carlo to search the adversarial examples. Instead of generate adversarial examples in a geometrical constraint, they transition to a trainable, data-driven distance distribution, which can incorporate personal comprehension of semantics into the model. The generated adversarial examples shown in Experiment seem more natural and untouched than the tradition PGD-generated examples."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The problem is interesting to me. Although adversarial examples are widely known as imperceptible to human eyes, some adversarial examples are vague compared to the original images. This work generates more clear adversarial examples, which are harder for humans to detect.\n* The algorithm is theoretically supported and empirically efficient."
            },
            "weaknesses": {
                "value": "* Although the generated adversarial examples are indeed elusive to human eyes, it is unknown whether these examples are harder for the defense methods to detect.\n* It would be better if the authors can also validate the efficacy of the proposed method on larger network such as ResNet-50, and more difficult task such as CIFAR-100 and ImageNet."
            },
            "questions": {
                "value": "What is the perturbation radius used in Figure 1?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4207/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698373380136,
        "cdate": 1698373380136,
        "tmdate": 1699636387535,
        "mdate": 1699636387535,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QMPZD3bHZm",
        "forum": "uUELOzcTk8",
        "replyto": "uUELOzcTk8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4207/Reviewer_DtN5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4207/Reviewer_DtN5"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces generating adversarial examples from a probabilistic perspective. The geometric constraints of adversarial examples are interpreted as distributions, thus facilitating the transition from geometric constraints to data-driven semantic constraints. The paper introduces relevant background knowledge in detail and introduces four techniques that enhance the performance of our proposed method in generating high-quality adversarial examples.  The effectiveness of the proposed method was verified on some simple dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. It provides detailed background knowledge on paper writing and is very reader-friendly.\n2. The author models adversarial examples from a probabilistic perspective and proposes an energy model-based adversarial example generation method."
            },
            "weaknesses": {
                "value": "1.  Although the author models the generation process of adversarial examples through the energy model, there is no essential difference between the previous adversarial example generation processes (they all use gradients to find optimization targets\uff0cthe objective function used in this paper is still the C&W attack.). \n2. The method has only been verified on some small datasets( e.g., MNIST and CIFAR), and the effectiveness of the method needs to be verified on larger-scale and more complex semantic datasets(e.g., ImageNet). Although the authors discuss this weaknesses."
            },
            "questions": {
                "value": "Some questions\uff1a\n1:  Generating adversarial samples through the energy model requires multiple data transformations. The author discussed changes in semantic distribution and geometric distribution. Can defenders train a classifier to filter adversarial samples generated based on the energy model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed.",
                    "Yes, Discrimination / bias / fairness concerns"
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4207/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698485618559,
        "cdate": 1698485618559,
        "tmdate": 1699636387448,
        "mdate": 1699636387448,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8E7yChfZvk",
        "forum": "uUELOzcTk8",
        "replyto": "uUELOzcTk8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4207/Reviewer_URQr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4207/Reviewer_URQr"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a probabilistic approach to construct semantically meaningful adversarial examples by interpreting geometric perturbations as distributions. The approach relies on training an energy based model (EBM) to emulate such distributions. The approach is evaluated on a variety of image classification datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The proposed approach is a principled take on the semantic adversarial attacks where in the authors derive an EBM-style formulation to generate geometric adversarial examples.\n\n2. The algorithm presents high attack success rates on adversarially trained models."
            },
            "weaknesses": {
                "value": "1. The paper is missing several references, and is relatively sparse with regards to related work. Similar works include Spatially Transformed Adversarial Examples (Xiao et al., ICLR 2018), Semantic Adversarial Attacks (Joshi et al, 2019, ICCV 2019), Semantic Adversarial examples (Hosseini et al, CVPRW, 2018) and Unrestricted adversarial examples (Bhattad et al, ICLR 2020). Several of these works use generative models to generate semantic adversarial examples and should be discussed and contrasted in this work.\n\n2. The experiments are limited to just two adversarially trained networks. Furthermore, the adversarially trained models do not appear to have been trained under the semantic attack threat model and hence unlikely to be robust to such attacks. \n\n3. The attack also relies on adversarially trained models learning semantically meaningful features. However, the images shown in the figures appear to be distorted which could be a consequence of the models overfitting on a subset of semantic features.\n\n**Update**: The authors have addressed some of my concerns and clarified certain points of misunderstanding. I am therefore increasing my score to 5 to reflect this."
            },
            "questions": {
                "value": "Could the authors clarify the training setup for the adverarially trained models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4207/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4207/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4207/Reviewer_URQr"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4207/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698723350044,
        "cdate": 1698723350044,
        "tmdate": 1700586096592,
        "mdate": 1700586096592,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lsxRMyjMY2",
        "forum": "uUELOzcTk8",
        "replyto": "uUELOzcTk8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4207/Reviewer_CGw2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4207/Reviewer_CGw2"
        ],
        "content": {
            "summary": {
                "value": "This paper propose a novel and simple methods for constructing semantic-aware adversarial examples. The proposed frame work use a probabilistic perspective method to generate semantics-aware adversarial examples.  As depicted in the figure of this paper, it seems this attack successfully attack classifiers while retaining the original image's semantic information."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The method for generating semantics-aware adversarial examples is very intuitive.\n* This paper is well-written. The problem this paper focuses is important, and the proposed method is interesting."
            },
            "weaknesses": {
                "value": "Please correct me if I have some misunderstanding of the paper.\n\n1. Since this paper proposes a semantics-aware method, the human evaluation is important to verify the validity of adversarial examples.\n\n2. It lacks a comparison on the number of queries.\n\n3. There is a lack of an ablation experiment. In $p_{adv}$, what will happen if $p_{dis}$ uses L2 or other methods to calculate Figure 1 or Table 1?"
            },
            "questions": {
                "value": "Please see the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4207/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4207/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4207/Reviewer_CGw2"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4207/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762272826,
        "cdate": 1698762272826,
        "tmdate": 1699636387287,
        "mdate": 1699636387287,
        "license": "CC BY 4.0",
        "version": 2
    }
]