[
    {
        "id": "t5KGvGxnez",
        "forum": "IRtIHp7vsM",
        "replyto": "IRtIHp7vsM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2600/Reviewer_HozN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2600/Reviewer_HozN"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a framework for applying AutoML in a multimodal setup using Large Language Models. The system comprises several stages: 1) modality inference, 2) automated feature engineering, 3) model selection, 4) pipeline assembly and 5) hyperparameter optimization. The authors divide the experiment section in 2 parts: 1) quantitative evaluation, 2) user study"
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The problem is important as it is very common to find different use cases where many modalities are available for the prediction. Moreover, there are not many tools that aim to solve this problem, directly, so far."
            },
            "weaknesses": {
                "value": "- The paper is very hard to follow, with many different acronyms, stages, and components. At some points, it gives the impression to be a technical report of a very complex software, rather than a scientific paper introducing a novel method.\n- Lack of strong benchmarking: the authors compare with only AutoGluon (one method) in four datasets. Although I understand that there are not many tools, the authors should include more datasets, and demonstrate that the tool also performs relatively well in uni-modal cases. Moreover, a valid baseline would be to aggregate the predictions of models that are obtained after optimizing per mode type.\n- The authors do not report standard deviation to assess the significance of the results. In most of the experiments, the improvement is very small."
            },
            "questions": {
                "value": "- Could the authors elaborate on the time, hardware, and/or price needed for the execution? From my perspective, using an LLM for AutoML seems still very impractical, as it demands a lot of hardware, which many final users can probably not afford."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2600/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697899128146,
        "cdate": 1697899128146,
        "tmdate": 1699636197946,
        "mdate": 1699636197946,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MUa4KwxwHV",
        "forum": "IRtIHp7vsM",
        "replyto": "IRtIHp7vsM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2600/Reviewer_Lpkx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2600/Reviewer_Lpkx"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors study using LLMs for multimodal AutoML. Specifically, the authors propose AutoM3L, which can automate ML for multimodal data using natural language instructions, covering automated pipeline construction, automated feature engineering, automated hyper-parameter optimization, etc. Experimental results showcase the usage of the proposed method over AutoGluon baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1) Exploring the potential of LLMs for multimodal AutoML is an interesting unexplored direction.  \n(2) The proposed method (or system) can leverage natural languages in the pipeline, enhancing user-friendly.  \n(3) The authors have conducted user studies for the proposed method.   \n(4) The authors have provided the source codes for reproduction and showcases."
            },
            "weaknesses": {
                "value": "(1) This paper neglects neural architecture search (NAS), which is one of the most important components in AutoML, if not the single most important one, especially in the deep learning era. There exist many multimodal NAS methods, which should be compared or added into the proposed system. Actually, I find such negligence kind of surprising, considering that NAS has received more attention than other AutoML techniques nowadays.  \n(2) Experiments are somewhat weak considering essentially only AutoGluon is compared. Though other methods may focus on a certain aspect of multimodal AutoML, e.g., HPO, the authors need to properly compare with them.  \n(3) Since the proposed AutoM3L is more like a library/system than a technical method, I would suggest adding more documentation, tutorials, etc., to help users get familiar with the system.  \n(4) Though LLMs have been constantly improving in their abilities to follow instructions, I wonder how the uncertainty and fragileness in LLMs may potentially have on the system. This is especially important if the proposed system is applied in real production scenarios."
            },
            "questions": {
                "value": "See Weaknesses above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2600/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698646001496,
        "cdate": 1698646001496,
        "tmdate": 1699636197830,
        "mdate": 1699636197830,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BHGIYGWNuJ",
        "forum": "IRtIHp7vsM",
        "replyto": "IRtIHp7vsM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2600/Reviewer_4U2h"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2600/Reviewer_4U2h"
        ],
        "content": {
            "summary": {
                "value": "In the paper \"AutoM3L: Automated Multimodal Machine Learning with Large Language Model\", the authors present an AutoML approach based on large language models to tackle multi-modal learning tasks. In their study, they compare their approach to AutoGluon, a state-of-the-art AutoML tool that is also able to tackle multi-modal datasets, achieving competitive performance. Furthermore, a user study is conducted to compare AutoM3L to AutoGluon in terms of the time required for learning the handling of the framework, the accuracy of user actions, the usability of the framework, and the user workload."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- A novel paradigm for designing complex AutoML tools based on LLMs\n- Competitive performance to AutoGluon across different types of tasks that exhibit multi-modality\n- User study to test the AutoML tools with respect to their usability"
            },
            "weaknesses": {
                "value": "- Tiny scope of datasets and it appears that only a single train test split has been used for the evaluation\n- No significance test is applied to the evaluation results with respect to the performances and standard deviations for repetitions are missing.\n- Only single runs of the AutoML tools are considered. However, AutoML tools are known to be quite noisy, so repeated runs would be required to tell how stable the performances are.\n- The participants are not fully described in terms of their priming regarding the tools etc and detailed background. In particular, no previous experiences with LLMs or other AutoML tools are mentioned.\n- Ablation studies regarding the effect of the different modules are lacking.\n- Limitations should be elaborated more, in particular, what are the pitfalls of AutoM3L and how to deal with biases contained in LLMs? E.g., gender or racial biases? To what extent is a corresponding bias even endangering the usage of AutoM3L?"
            },
            "questions": {
                "value": "- How stable are the performances obtained by the AutoML tools?\n- What is the background of the study participants? To what extent did they already touch on LLMs and AutoML or HPO tools beforehand? To what extent are they already capable of handling multi-model data on their own?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "LLMs, especially GPT3.5, are known to have issues with biases, e.g., gender or ethnical biases. The impact of such biases on the overall approach is not addressed in the paper. From my point of view, when automating machine learning tasks based on LLMs, such biases should at least be acknowledged and discussed."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2600/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698760461728,
        "cdate": 1698760461728,
        "tmdate": 1699636197737,
        "mdate": 1699636197737,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Znrwd1IKWo",
        "forum": "IRtIHp7vsM",
        "replyto": "IRtIHp7vsM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2600/Reviewer_jKdu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2600/Reviewer_jKdu"
        ],
        "content": {
            "summary": {
                "value": "This paper targets to devise an univeral AutoML framework for multimodal tasks, which has been rarely explored. In specific, this paper combines the powerful reasoning ability to their framework. Firstly, the design MI-LLM to identify the data type and AFE-LLM to facilitate the feature engineering. Then an MS-LLM is devised to select the suitable encoder for each modaliyu. Finally, PA-LLM and HPO-LLM generates corresponding excutable codes and optimal hyper-parameters for training model. The experiments of comparison with AutoGluon show the proposed method can outperform the competing baseline."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+S1: This paper has explored how to combine the LLMs with AutoML framework at an early stage.\n+S2: The authors provide many details of implementation for their framework, which can ease the reproduction of the work.\n+S3: The paper is well-writen, which is easy to understand."
            },
            "weaknesses": {
                "value": "-W1: Though the motivation to combine the LLMs is clear, no technical difficulty is seen for combining LLMs with AutoML. It seems only a simple application of LLMs to AutoML, which may degrade the contributions of this paper.\n-W2: This paper only introduce few related works, but lack of sufficient relevant work collection. The authors claim that AutoGluon is the only work for automl multi-modal, but I find several other related works [1][2][3].\nonly one baseline is compared. In my view, you can compare with the variants of some existing approach.\n-W3: Some designs in the proposed framwork seems abundant. For example, is it necessary to design the modality inference module? In general, the data format is pre-defined and given by the dataset.\n-W4: Some errors exist in the paper. For example, in figure 2(a), the text in outputs_1 should be \"state\" but not \"stage\"?\n-W5: Lack of related baselines, which is relevant to the weakness W2. Also, I find some baselines in AutoGluon compared, such as H2O AutoML. In my view, these baselines also should be included in the experiments.\n\n[1] Jin, H., Chollet, F., Song, Q., & Hu, X. (2023). Autokeras: An automl library for deep learning. Journal of Machine Learning Research, 24(6), 1-6.\n[2] Sun, P., Zhang, W., Wang, H., Li, S., & Li, X. (2021). Deep RGB-D saliency detection with depth-sensitive attention and automatic multi-modal fusion. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 1407-1417).\n[3] Erickson, N., Shi, X., Sharpnack, J., & Smola, A. (2022, August). Multimodal automl for image, text and tabular data. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (pp. 4786-4787)."
            },
            "questions": {
                "value": "Q1: Does the AFE-LLM only can handle the tabular features, instead of multi-modal features? If it is, the idea is much similar to [4]. Besides, it seems that you conduct such feature engineering for each sample in dataset. I think it is extremely time-consuming, which may conflict the intuition of AutoML.\nQ2: Besides, there seems no specific multi-modal information is utilized in the proposed method. Only text path or image path are adopted. If it is, all other single-modal AutoML framework may be adpated to such task. \nQ3: Please also respond the questions mentioned in weakness.\n\n[4] Borisov, V., Sessler, K., Leemann, T., Pawelczyk, M., & Kasneci, G. (2022, September). Language Models are Realistic Tabular Data Generators. In The Eleventh International Conference on Learning Representations."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2600/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2600/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2600/Reviewer_jKdu"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2600/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699677144554,
        "cdate": 1699677144554,
        "tmdate": 1699677144554,
        "mdate": 1699677144554,
        "license": "CC BY 4.0",
        "version": 2
    }
]