[
    {
        "id": "piU6rTDyjj",
        "forum": "1pSL2cXWoz",
        "replyto": "1pSL2cXWoz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4861/Reviewer_MqR8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4861/Reviewer_MqR8"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new scoring method for post-hoc out-of-distribution (OOD) detection, by considering the OOD detection problem as a density estimation over the exponential family. Using the connections between the exponential family of distributions and the Bregman divergence, the original density estimation problem over the exponential family is converted into the problem of finding the Bregman divergence. Then, to reduce the search space for selecting Bregman divergence, the authors propose a pair of conjugate functions and reframe the original problem into the problem of finding the optimal norm coefficient $p$ against the given dataset. The partition function is estimated using the Mont Carlo-based importance sampling technique. Experimental results demonstrate the efficacy of the proposed score, with varying $p$ depending on the dataset (p=2.2 for CIFAR-10, 2.5 for CIFAR-100, 1.5 and 1.8 for ImageNet-1k on ResNet50 and MobileNetv2)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Proposed a unified scoring method for post-hoc OOD detection using a general exponential family.\n- Converted the original search problem over the expansive function space of Bregman divergence into a simple problem of selecting optimal norm coefficient.\n- Demonstrated the effectiveness of the proposed score on CIFAR-10/100, ImageNet-1k, and scenarios including hard OOD detection and long-tailed OOD detection."
            },
            "weaknesses": {
                "value": "- The main search problem of optimal coefficient $p$ for OOD scoring is remained as a hyperparameter search, which may constrain the practicality of the proposed score. Furthermore, the OOD detection performance (FPR95) is quite sensitive to the value of $p$ (Figure 4), which implies that the performance of the proposed score highly depends on the hyperparameter $p$."
            },
            "questions": {
                "value": "- Can the authors provide any reasonable method to choose $p$ given the training dataset and the corresponding features given NN architecture without the hyperparameter search?\n- The partition function is estimated using the importance sampling-based approximation. For long-tailed OOD detection when the ID training data exhibits an imbalanced class distribution, I guess the accuracy of the importance sampling-based estimation may decrease given a limited number of tail-class predictions. Given that, can the authors elaborate why their method still outperforms in the long-tailed scenarios?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4861/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698670733044,
        "cdate": 1698670733044,
        "tmdate": 1699636469823,
        "mdate": 1699636469823,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fOARPSnnPb",
        "forum": "1pSL2cXWoz",
        "replyto": "1pSL2cXWoz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4861/Reviewer_LYsh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4861/Reviewer_LYsh"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the task of out-of-distribution (OOD) data detection for supervised learning tasks. The proposed method is essentially along the lines of density level set thresholding, and the density estimates leverage a particular type of exponential family (uniform) mixtures originating from a Bregman-divergence-related framework. After choosing specific parameters for computational tractability and performance, the authors compared their method with multiple baselines and prior works to demonstrate its effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper reads well and introduces background and prior works properly. In addition, the authors leverage concrete examples and visualizations, such as plots and tables, to help the reader get the most critical points. All these benefit the readability and clarity of the submission. \n\nRegarding novelty and originality, the proposed method differs from existing approaches algorithmically and originates from a more general framework. It is good that the authors spend efforts building theoretical justifications and showing underlying motivations. \n\nThe experiment results (seem to) suggest that the new method has advantages over the prior works and often outperforms its predecessors, at least within the experimental setting of the authors. Sometimes, there are seven to ten competitors and two to five benchmark datasets, such as ImageNet and CIFAR-10. From my perspective, this is the most substantial contribution added by the paper, showing the method's practicality."
            },
            "weaknesses": {
                "value": "One area for improvement is that while the method comes from a theoretical framework, I need to find explicit theoretical guarantees and technical claims to justify its effectiveness. So, the lack of theoretical justification is a weakness worth addressing, potentially deriving some for simple cases like the Gaussian one or explaining why the algorithm tends to perform well for small p values. \n\nThe second weakness is that the prior work (Morteza & Li, 2022) already proposed a method based on Gaussian assumptions and Mahalanobis distance. The extension in this paper, at least logically, is relatively straightforward, i.e., from Gaussian to Exponential Family and from Mahalaobis distance to Bregman-divergence (an extension). Maybe it's worth adding a section summarizing the paper's technical novelty. \n\nAnother weakness is that while the framework's formulation seems general, multiple assumptions come along the way. For example, the authors assumed a uniform prior and set $\\psi$ to the $l_p$ norm. Of course, these might be necessary for a computationally tractable approach and could be acceptable in their current form."
            },
            "questions": {
                "value": "Following the comments on the weaknesses, it would be helpful if the authors could\n- Provide theoretical justification (guarantees) for the proposed method.\n- Explain and summarize the technical novelty in addition to prior works.\n- List out all the assumptions made leading to the final method.\n\nIn addition, it would be good if the authors could make the notations more distinguishable, e.g., addressing the overuse of $\\hat{p}_\\theta(\\star)$."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4861/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698810522130,
        "cdate": 1698810522130,
        "tmdate": 1699636469739,
        "mdate": 1699636469739,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wBvQzwbsua",
        "forum": "1pSL2cXWoz",
        "replyto": "1pSL2cXWoz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4861/Reviewer_WvTp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4861/Reviewer_WvTp"
        ],
        "content": {
            "summary": {
                "value": "The authors present a data density estimation method targeted towards out of distribution detection. The authors parameterize Bregman Divergences, which in turn are shown to parameterize Exponential Families up to an approximable normalization constant.\n\nThe authors conduct extensive evaluations on numerous OOD tasks and include ablations, showing improvements over benchmarks on many tasks.\n\nIn general the mathematical presentation is careful, results are contextualized, and the reader learns both about OOD in general and about the specific presented method, picking up some tricks on parameterizing densities along the way."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The authors conduct extensive evaluations on numerous OOD tasks and include ablations, showing improvements over benchmarks on many tasks.\n\nIn general the mathematical presentation is careful, results are contextualized, and the reader learns both about OOD in general and about the specific presented method, picking up some tricks on parameterizing densities along the way."
            },
            "weaknesses": {
                "value": "Nothing particularly bad and things seem correct and well reported and well explored. \n\nMostly, the weakness would just be the lack of discussion of Deep Generative Models. The paper seems to present density estimation as the main challenge of OOD detection. For some of the considered benchmarks such as GEM, the main criticism is the specific distribution assumptions, hence the exploration in this work across the Exponential Family.\n\nOn the other hand, Deep generative models (DGMs) are a flexible approach for modeling data distributions without making distributional assumptions. Not all DGMs give the user a computable density, but there are some that do such as Normalizing Flows and more recently methods like Flow Matching, Stochastic Interpolants, and others to name a few. More generally some models give you un-normalized log densities, which also seem to be okay for this work considering that this work is willing to estimate certain normalization constants.\n\nIt's totally okay to explore a non-DGM-based method in this work, but I think it would strongly benefit from some contextualization and an attempt to answer this question in at least one way: \n\nFor high dimensional data such as images, why should someone not pick generic deep generative models that admit densities (or un-normalized densities, or maybe log density lower bounds) and why instead should someone stick with search within the exponential family (for which you give good methods, algorithms, etc, and for which you get good results)?\n\nThere is some older work on role of DGMs in OOD detection (such as https://arxiv.org/abs/2107.06908) but I think a LOT of progress has been made in image DGMs since then (like DDPM https://arxiv.org/abs/2006.11239, Interpolants, https://arxiv.org/abs/2209.15571, Diffusions in latent space, https://arxiv.org/abs/2212.09748, etc)"
            },
            "questions": {
                "value": "1)\n\nCould you please clarify this phrase? I re-read it a few times and just did not understand its meaning\n\n\"Without loss of generality, we employ latent features z extracted from deep models as a surrogate for the original high-dimensional raw data x. This is because z is deterministic within the post-hoc framework.\"\n\n2)\n\nPlease answer my main question in Weaknesses, on why no discuss of the role in DGMs for flexible density estimation in OOD detection.\n\n3) small comment:\nplease tell the reader more about why learning the natural parameter of an Exp. Family intractable."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4861/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4861/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4861/Reviewer_WvTp"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4861/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699425275878,
        "cdate": 1699425275878,
        "tmdate": 1699636469657,
        "mdate": 1699636469657,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GwWPsoTrau",
        "forum": "1pSL2cXWoz",
        "replyto": "1pSL2cXWoz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4861/Reviewer_EBSh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4861/Reviewer_EBSh"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of density estimation for density-based out-of-distribution detection. The authors firstly point out that existing logit, distance, and density based OOD methods can be either inconsistent or too restrictive. Then the authors utilize the property of exponential family and its relation to Bregman divergence to induce a modeling of the density function using conjugate norms. They further combine different method for the estimation of partition functions and finally experimentally validate their methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The assumption of exponential family is mild and the authors utilize the property of conjugate functions to derive a concise formulation of density functions.\n2. The estimation of partition functions can be combined with different methods, which indicates the flexibility of the proposed method. \n3. The experimental results on widely-used benchmark datasets validate the usefulness of the proposed method."
            },
            "weaknesses": {
                "value": "The theoretical results of this paper are based on the exponential family of distribution. I think this is an explicit assumption on the prior distribution, which contradicts your answer to question \u2660. An analysis on the potential extension of your results can be helpful."
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4861/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699530191904,
        "cdate": 1699530191904,
        "tmdate": 1699636469566,
        "mdate": 1699636469566,
        "license": "CC BY 4.0",
        "version": 2
    }
]