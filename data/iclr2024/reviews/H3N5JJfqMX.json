[
    {
        "id": "f7ulG3mNUp",
        "forum": "H3N5JJfqMX",
        "replyto": "H3N5JJfqMX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4079/Reviewer_tEiT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4079/Reviewer_tEiT"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to use semi-supervised learning methods for Bayesian optimization (BO). The idea is to use an alternative paradigm for BO instead of fitting a regressor to the observed data. The authors suggest to use density ratio estimation BO instead. In DRE-BO one uses a classifier as the model to guide the search and the acquisition function is computed in terms of the class probability ratios. The authors suggest to strengthen the classifier accuracy by using semi-supervised learning techniques. The method is compared to other strategies in synthetic and real problems."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Extensive experimental evaluation."
            },
            "weaknesses": {
                "value": "The introduction is poor. It does not introduce properly the problem addressed in the paper.\n\nIn general the writing of the paper has to be improved a lot. It does not introduce the concept of DRE-based BO right. If the reader is not familiar with it, they cannot understand it properly. The authors have failed in this task.\n\nIt is not clear what is the motivation for DRE-based BO. It is also unclear how the threshold value y^t is chosen.\n\nThe authors have to better explain DRE-based BO, why does it work, why is it interesting and why it is better than regression based BO.\n\nFigure 1 is not explained properly.\n\nThe proposed method is not very well motivated. It seems it is simply using a better classifier. The authors claim that they use semi-supervised learning techniques to train the classifier. However, the semi-supervised data seems to be generated by sampling from a truncated Gaussian and then label propagation is used to generate the associated labels. Therefore, the proposed method can be understood simply as using a better classifier. Given this, I do not find that much novelty in the proposed method."
            },
            "questions": {
                "value": "Please, explain better figure 1 and why it illustrates the over-confidence problem.\n\nPlease, explain how the threshold value y_t is chosen.\n\nPlease, explain why the proposed method needs to sample from a truncated multivariate Gaussian distribution."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4079/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4079/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4079/Reviewer_tEiT"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4079/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698663529617,
        "cdate": 1698663529617,
        "tmdate": 1700665313662,
        "mdate": 1700665313662,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jl03A3DXos",
        "forum": "H3N5JJfqMX",
        "replyto": "H3N5JJfqMX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4079/Reviewer_NoA7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4079/Reviewer_NoA7"
        ],
        "content": {
            "summary": {
                "value": "This paper extends the binary classifier-based Bayesian optimization such that the classifier is trained in a semi-supervised manner. The authors argue that the semi-supervised classifier expands the region of ${\\bf x}$ associated with high probability $P(y \\leq y^\\dagger | {\\bf x}, \\mathcal{D})$, which leads to more efficient exploration of black-box optimization. \nProposed method, called DRE-BO-SSL, is compared with the ordinary BO as well as DRE-BO with sueprvised classification approaches for function optimization as well as hyperparameter tuning tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea sounds sensible to incorporate semi-supervised learning for encouraging the exploration of DRE-based Bayesian optimization method. \nFigure 1 illustrates how the search space is explored by the proposed framework. \nWith that said, the figure needs more explanation for better comprehension of its content. \nFor example, the color bar is labeled as *Class Probability*, which suggests something like $p(y \\leq y^\\dagger | {\\bf x}, \\mathcal{D})$.\nHowever, in the text most probability is shown as the distribution over the input such as $p({\\bf x} | y \\leq y^\\dagger, \\mathcal{D})$. \nWhat does the figure specifically illustrate?"
            },
            "weaknesses": {
                "value": "The presentation of current manuscript is problematic in that many things are uncertain from the text. \nSee *Questions* part below for details. The reviewer believes this information is necessary to better understand the method and enhance the reproducibility of results.\n\nUnfortunately, the efficacy of proposed method in the performance of optimization over iterations is hardly distinguishable in Figs. 5 or 6. \nI acknowledge a clear victory is not so common in comparisons of black-box optimization methods. \nThe bigger problem is that it is unclear  from the text on what condition and why the proposed method outperforms the existing approaches."
            },
            "questions": {
                "value": "1. Truncated normal distribution for sampling unlabeled data points. \n\nHow is matrix ${\\bf A}$ designed? What covariance is taken for this disbiribution, for what? \nWhat are lower and upper bounds ${\\bf l}$ and ${\\bf u}$? \nAre they boundaries of search space $\\mathcal{X}$? Is it assumed to be rectangular?\n\n2. Fixed-size pool. \n\nDoes *fixed-size pool* scenario mean some finite number of candidate points ${\\bf x}_i$ are selected in advance and that optimized over these points? \nIf true, is the set of points dynamically updated or fixed in advance? \n\n3. Definition of simple regret. \n\nWhat is the definition of simple regret? \nIs it $f({\\bf x}_n) - f^*$ in the $n$th iteration, where $f^*$ is the minimizer of function $f$. \nI am wondering why the regret is monotonically decreasing in Fig. 2. \nDoes this plot $\\min_n f({\\bf x}_n) - f^*$?\n\n4. What is dimensionality of ${\\bf x}$ in four benchmark tasks in Fig. 2. \n\nAre they all two? This is crucial information on the difficulty of black-box optimization problems. \n\n5. Hyperparameter optimization of Fig. 6\n\nHow do you define the distance $\\|{\\bf x}_i - {\\bf x}_j \\|$, especially when categorical values are involved such as activation function and learning rate schedule."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4079/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4079/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4079/Reviewer_NoA7"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4079/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698751966229,
        "cdate": 1698751966229,
        "tmdate": 1699636372341,
        "mdate": 1699636372341,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Dy7ZkzRiDY",
        "forum": "H3N5JJfqMX",
        "replyto": "H3N5JJfqMX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4079/Reviewer_fMcY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4079/Reviewer_fMcY"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a novel method called DRE-BO-SSL which combines SSL with DRE-based BO.\nThe intention is to improve the exploration-exploitation trade-off as previous DRE-based BO (BORE and LFBO) tends to focus on exploitation due to the over-confident classifiers.\nThe paper explores two types of SSL method (label propagation and label spreading).\nEmpirical results show that the proposed method work better than competitive BO methods on a wide range of tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**originality** The proposed method is novel.\n\n**quality** The proposed method is sound and the empirical results are promising.\n\n**clarity** The technical part of the paper is good.\n\n**significance** The proposed method is a good contribution to DRE-based BO and can be potentially useful to solve the over-confidence problem in DRE in general."
            },
            "weaknesses": {
                "value": "The presentation could be improved.\nSpecifically, the focus on over-confidence in the beginning is confusing and I only understand the main point until I read section 3.1 where the relation to exploitation is mentioned.\nPerhaps this should be moved towards the front.\n\nSome limitations of the work should be explicitly mentioned/discussed.\nFor example, assumption 4.1. seems to imply that the method is only intended to work on smooth functions.\n\nSome related work is missing; see questions below."
            },
            "questions": {
                "value": "The over-confident problem of DRE is recently studied by [1,2]. \nCan the author(s) comment on how the construction of auxiliary distribution in these work is related to the sampling distribution of DRE-BO-SSL?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4079/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809715905,
        "cdate": 1698809715905,
        "tmdate": 1699636372249,
        "mdate": 1699636372249,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QR3GZ6eOje",
        "forum": "H3N5JJfqMX",
        "replyto": "H3N5JJfqMX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4079/Reviewer_WaiC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4079/Reviewer_WaiC"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an extension to bayesian optimisation (BO) using density rato estimation (DRE) to tackle the problem of overconfidence in the estimators used.  Specifically, the authors suggest using semi-supervised learning (transduction) to increase the accuracy of the model (overcome the difficulties typically caused by the imbalance between dataset sizes above and below the threshold)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is very well written.  I quite like the underlying idea, and the implementation appears reasonable."
            },
            "weaknesses": {
                "value": "One doubt I have with this paper perhaps stems from unfamiliarity with semi-supervised algorithms in general.  My understanding of such approaches is that they tend to assume that the unlabelled training points are nevertheless generated from the underlying x distribution.  In most applications of BO, however, this concept is nonsensical: the only x distribution is the points sampled by BO, which are (in some sense) arbitrary (depending on the acquisition function they may cluster around the optimum as time passes, but not necessarily).  Am I missing a key point here?"
            },
            "questions": {
                "value": "See weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4079/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821245821,
        "cdate": 1698821245821,
        "tmdate": 1699636372157,
        "mdate": 1699636372157,
        "license": "CC BY 4.0",
        "version": 2
    }
]