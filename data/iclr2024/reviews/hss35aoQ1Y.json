[
    {
        "id": "qPbDEOP8c1",
        "forum": "hss35aoQ1Y",
        "replyto": "hss35aoQ1Y",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1358/Reviewer_n3DU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1358/Reviewer_n3DU"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new grounding dataset, which is created with LLM (LLAMA) and VLM (LLAVA). They propose to leverage LLAMA in the single modality pathway, which receives the text only descriptions and bounding boxes to create annotations, in the same spirits to LLAVA. And LLAVA is leveraged in the multi modality pathway. After creating the dataset automatically, they leverage CLIP to drop out the annotations with low quality. A simple baseline model has been proposed to showcase the effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The proposed dataset may be a good resource for future research in visual grounding tasks."
            },
            "weaknesses": {
                "value": "Weaknesses: \n1. The major concern I have is regarding the quality dataset. The author uses the open-source model LLAMA, which is not instruction-tuned, in the single modality pathway. As opposed to GPT4 used in LLAVA\u2019s instruction tuning dataset. In addition, LLAVA is used in multi-modality pathways. I have doubts about the quality of the dataset since both LLAVA and LLAMA have problems of their own, such as hallucinations and incapability to describe the objects of small scales.\n\n2. The experiments are insufficient. The author only presents the result in their own proposed dataset and the original ref coco benchmark. I am not certain how much the dataset actually helps the performance of the model, or helps equip the model with new capabilities. Specifically, the performance on refcoco is not extraordinarily high and is not compared with SOTA methods such as poly former.\n\n3. What does the author mean by \u201cinitializing LLAVA with minigpt4 weights\u201d? I think LLAVA finetunes the entire LLM, while minigpt4 only finetunes a linear layer, and the architectures are different."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1358/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698649611580,
        "cdate": 1698649611580,
        "tmdate": 1699636063370,
        "mdate": 1699636063370,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mVYCJVSzgt",
        "forum": "hss35aoQ1Y",
        "replyto": "hss35aoQ1Y",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1358/Reviewer_nJxy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1358/Reviewer_nJxy"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces \"InstructDET,\" a novel method for referring object detection (ROD) that identifies and localizes target objects in images using user instructions. This approach is an advancement from the traditional referring expressions (REC) and places emphasis on generating a wide variety of user-centric instructions linked to object detection tasks using VLM and LLMs\nThe InstructDET dataset is a compilation of images, their associated bounding boxes (bbxs), and the generalized instructions curated from VLM and LLM. Models trained on the InDET dataset demonstrated enhanced performance, outclassing existing methods on traditional REC datasets and the new InDET test set. InstructDET showcases the potential to expand by integrating any image accompanied by object bounding boxes."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper proposes a novel and interesting way to produce rich visual descriptions of objects and their relationships using LLM and VLM\n2. I like the approach for removing hallucination from the VLM model using vision language matching for CLIP.\n3. This approach is scaleable which means that the results can continue to improve with more bbox data."
            },
            "weaknesses": {
                "value": "1. It's not clear from the paper that the method comparison in table 2 is fair because it's not clear if the models were trained on the same images and bounding boxes\n2. One additional interesting experiment that would make this a stronger paper - run SAM on web scale images to get bboxes for images and then scale up this approach further to understand if the benefits saturate"
            },
            "questions": {
                "value": "Can you please address weakness 1?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1358/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1358/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1358/Reviewer_nJxy"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1358/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817295678,
        "cdate": 1698817295678,
        "tmdate": 1699636063225,
        "mdate": 1699636063225,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "avGNkc4y4f",
        "forum": "hss35aoQ1Y",
        "replyto": "hss35aoQ1Y",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1358/Reviewer_uAXw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1358/Reviewer_uAXw"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces InstructDET as new method for referring object detection (ROD). The paper identifies the lack of diversity in the user prompt in existing ROD datasets as a critical limitations. To address this limitation, a data pipeline based on query of foundation models, such as LLaVA and LLaMA is built. This pipeline creates accurate and diverse object reference via a combination of prompt engineering and heuristics. It first create object and image level expressions via LLaVA, then reject hallucination via CLIP, and finally diversify the expressions via LLaMA. The resultant expressions can then serves as training data for the ROD task. The paper shows that the dataset curated from the proposed procedure can significantly improve the model performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* This paper provides an interesting research direction in referring object detection. While many existing works attempt to improve ROD via better model design, this work suggests that it could be fruitful to enrich existing dataset via a combination of data mining and/or prompt engineering from existing foundation models. It would be of great interests to the community in general.\n\n* The method taken from this paper seems to quite novel. While the use of foundation models as a data curation tool is not new (as fully acknowledged in this work, and is the practice used in LLaVA which is in return used heavily in this work), this work has explored some novel ideas to improve this procedure. For example, the \"vision and language mapping\" via CLIP as a verification step is particularly interesting.\n\n* The resultant model trained on the curated dataset seems to outperform prior arts by a large margin, even with the same network architecture."
            },
            "weaknesses": {
                "value": "* There are many language errors throughout the submission, including strange use of words, grammatical mistakes etc.. It is still possible to comprehend the ideas despite those writing issues, but this submission can use additional proofreading. Part of the issue is with the naming of concepts. The \"pathways\" are easily confused with the terminology used to describe parallel branches in a deep network. The \"dropout\" can be confused with the regularization method. These names are unfortunate in the sense that they are in fact significant distractors for readers in this field, and not really descriptive of the concepts.\n\n* I find the definition of \"single\" versus \"multi\" modality pathways confusing. To my best understanding, the \"single modality pathways\" refers to a sub-process in the data generation that uses LLaVA to create output texts descriptions for an input image. As such, it needs both an image and some text prompts to obtain text result. The \"multi modality pathways\" refers to a procedure that similarly use LLavA to create results from image & text prompts. The two pathways have the same form of inputs and outputs. Why one is \"single modality\", while the other is \"multi modality\"? It is also hard to see, at least from the discussions provided in the submission, why the \"single modality\" case can use an out-of-box LLaVA model, whereas the \"multi-modality pathways\" must use a finetuned version.\n\n* While the main contribution from this paper is the proposed data generation step procedure, the details are not included in a way that would allow other researchers to reproduce the results. For example, Section 3.1 (combined with appedix C) describes the \"single modality\" pathway. However, critical details such as the procedure to generate prompts are left in a rather abstract level. I don't think it would be possible for reader to re-produce the method described. Similarly, in Section 3.2. the paper does not precisely describe the procedure. For example, while the paper mentions fine-tuning LLaVA on some REC dataset, it does not describe the exact dataset nor the exact training setting for this. Another example is in the \"post-processing\" section. It is not at all clear from reading the paper how the expressions are \"verify and remove\", and how LLaMA is used to \"diversify\" the expressions."
            },
            "questions": {
                "value": "* Could you include more details in terms of the prompts that are use, the exact procedure to generate them (number of queries, the services used, costs etc.)? I think these are interesting information for the community that should be included to the paper wherever appropriate.\n\n* Do you plan to release the dataset curated for this paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1358/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1358/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1358/Reviewer_uAXw"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1358/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826867297,
        "cdate": 1698826867297,
        "tmdate": 1699636063151,
        "mdate": 1699636063151,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3mzrxlY7aS",
        "forum": "hss35aoQ1Y",
        "replyto": "hss35aoQ1Y",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1358/Reviewer_Vtb3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1358/Reviewer_Vtb3"
        ],
        "content": {
            "summary": {
                "value": "The authors propose InstructDET for referring object detection (ROD) that localizes objects based on user instructions. They leverage diverse instructions generated by vision-language models to create the InDET dataset. Based on InDET, their InstructDET outperforms existing methods on referring expression comprehension datasets and their own InDET test set."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- As the authors claim, InDET is the largest real-world REC dataset. It is expected that InDET will push the study of REC and its application.\n- The dataset covers many real-world scenarios, including multiple object instruction.\n- The proposed DROD model is simple yet effective. And it helps prove the quality of InDET."
            },
            "weaknesses": {
                "value": "- More experiments are expected. For instance, previous REC models should be trained on InDET and evaluated on RefCOCO/+/g."
            },
            "questions": {
                "value": "See Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1358/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698846680115,
        "cdate": 1698846680115,
        "tmdate": 1699636063050,
        "mdate": 1699636063050,
        "license": "CC BY 4.0",
        "version": 2
    }
]