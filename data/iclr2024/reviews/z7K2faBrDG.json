[
    {
        "id": "tWMlD0xAYd",
        "forum": "z7K2faBrDG",
        "replyto": "z7K2faBrDG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2733/Reviewer_qN8s"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2733/Reviewer_qN8s"
        ],
        "content": {
            "summary": {
                "value": "The authors derive nonlinear relations between certain univariate image features and the perceptual scale (human response) to these features using Fisher information. \nWhile the response for frequency and orientation of Gaussian Random Fields proves to be quite consistent with actual human responses derived from similarity judgements, the situation is more complicated in naturalistic textures.\nFor Gaussian fields the correspondence is good because (1) these images are easy to characterize with those parameters and hence, the Fisher information of those parameters captures all the information of the multidimensional objects, and (2) the discriminability is actually related to the image information. However, for the responses to interpolation between naturalistic textures, it is not clear which features to consider to compute the Fisher information. In this case, the authors try different features (pixel values, wavelet responses, VGG19 responses, and the power spectrum), and the best agreement is found using the power spectrum."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors address an interesting issue (the nonlinearity of the human image representation), and they show that Fisher information may be a driving factor of discriminability in simple textures defined by band-pass power spectra. \nThe provided expressions of Fisher information have technical interest."
            },
            "weaknesses": {
                "value": "It is not clear how to generalize their approach to more complicated textures, where it is not obvious the features to describe them and how to compute Fisher information, J, from those. \n\nIn the more complicated scenario the authors only try a limited (non conclusive) set of features on some so-called naturalistic textures which are not very general either. All this reduces the strength of the experiments and the possible conclusions. Moreover, in some of the cases (e.g. pixel and wavelet features) they do not explain how to compute J.\n    \nGiven the normalization of the response axes, the derived nonlinear functions cannot be used as a metric to compute differences between textures."
            },
            "questions": {
                "value": "MAJOR QUESTIONS:\n\n* Please give examples interpolating between more general textures (e.g. a brick wall, and a flower field, or a pile of fruits -see examples of natural textures in Portilla & Simoncelli IJCV 2000-). Do you get similar results (theoretical predictions and human responses) in those cases?\n\n* The description of the method is confusing. For example, how do you get the nonlinear response in Fig. 1? I guess first you use the expressions in appendix A, then, you use \\Psi in Eq. 6 and then you integrate, right?. This is not clear in the text. Similarly, how do you get the predictions in Fig. 2?. For the VGG response you assume they are Gaussian vectors, then you apply Proposition 4, and then you integrate Eq. 6?.  \n\n* Appendices give explicit expressions for the Fisher information for the frequency and orientation of Gaussian fields and of Gaussian vectors for the activations of VGG-19 (if they were Gaussian), but how do you compute J for the pixel representation? (just apply an FFT and then use that estimation of the spectrum and the formula in Preposition 3?). \nHow do you do it for wavelets?... What is the wavelet decomposition you used? There are many of them!\n\n* The normalization of the response axes imply that all modifications of the stimuli lead to the same perceptual distortion. Simple visual inspection of the pairs in Fig. 2 shows that this is not correct. If the authors do not propose a way to give an absolute scaling in these different dimensions they should not claim that they are giving a metric of the image space.\nWhat they just provide is a nonlinear (up to a scalar) relation between displacements in certain directions and variations in the inner representation, but this is not a metric.\n\n* Following the above comment, the proposed method would be unable to give a measure to predict the Mean Opinion Score (MOS) on distortion in databases such as TID [Ponomarenko et al. 13] or KADID [Lin et al. 19]. If this is not the case, the authors should mention how to infer this MOS. \n\n* The title is too vague, it does not reflect the content of the paper, and actually overstresses \"distances\" and \"metrics\" not quite addressed in the work. What about changing the title by something like: \"Nonlinear image representations in humans from Fisher information\".\n\nMINOR ISSUES:\n\n* In the abstract authors say \"we demonstrate that it is related to the Fisher information of the generative model that underlies perception\", while it should say \"we demonstrate that it is related to the Fisher information of the generative model that underlies the stimuli\"\n\n* In the first paragraph of page 6 the authors say \"We will see that in both cases...\" ... Where do the authors show this? (this is related to the confusing description of the method stated above).\n\n* Typos:  \nfirst paragraph of page 8 \"VGG-19 to another (bottom-right of Fig. 2)\" ---> \"VGG-19 to another (bottom-left of Fig. 2)\"\nsecond paragraph page 8 \"frequency mode (Proposition 2 and Proposition 2)\" ---> ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Reviewer_qN8s"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2733/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698652787949,
        "cdate": 1698652787949,
        "tmdate": 1700757531155,
        "mdate": 1700757531155,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "E4pkG5yw0c",
        "forum": "z7K2faBrDG",
        "replyto": "z7K2faBrDG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2733/Reviewer_wfqs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2733/Reviewer_wfqs"
        ],
        "content": {
            "summary": {
                "value": "The paper seems to measure the perceptual scale of spatial frequency, orientation, and synthetic texture interpolation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem is of fundamental importance.\n\n2. The reviewer likes reading the introduction, especially the literature review."
            },
            "weaknesses": {
                "value": "1. The reviewer has read the paper multiple times but fails to comprehend the main contributions. \n\n2. The authors claim to have a convergence theorem, but what are the implications and practical relevance? Specifically, a Gaussian field is assumed, but high-dimensional natural images are highly non-Gaussian.\n\n3. The function $\\psi$ in Eq. (2) as the perceptual scale is tested in a very constrained scenario, without comparing to competing methods. For example, a recent computational model of the contrast sensitivity function considers spatio-temporal frequency, eccentricity, luminance, and area [C1].\n\n4. Moreover, the experimental results regarding texture interpolation are performed in a discriminative setting, not from a generative perspective (i.e., texture synthesis).\n\n\n[C1] stelaCSF: A unified model of contrast sensitivity as the function of Spatio-Temporal frequency, Eccentricity, Luminance and Area,\n SIGGRAPH 2022."
            },
            "questions": {
                "value": "1. The goals of the paper should be more precise.\n\n2. The comparison to previous methods should be performed, and performed in a comprehensive way.\n\n3. The authors may want to test their models on natural photographic texture images, besides the synthetic and simplistic ones (as shown in Figs. 1 and 2)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N.A."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2733/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722785345,
        "cdate": 1698722785345,
        "tmdate": 1699636215758,
        "mdate": 1699636215758,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "83CRHq9rTj",
        "forum": "z7K2faBrDG",
        "replyto": "z7K2faBrDG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2733/Reviewer_AMLy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2733/Reviewer_AMLy"
        ],
        "content": {
            "summary": {
                "value": "This paper shows that the assumption that an observer has an internal representation of univariate parameters such as spatial frequency or orientation while stimuli are high-dimensional does not lead to contradictory predictions when following a theoretical framework. The perceptual scale is found to correspond to the transduction function in this framework and is related to the Fisher information of the generative model underlying perception. The research suggests that the stimulus power spectrum largely influences the perceptual scale. Furthermore, the study proposes that measuring the perceptual scale can help estimate the perceptual geometry of images, going beyond simple distance measurements to understand the path between images."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- A theoretical analysis on the perceptual scale in the case of GRFs was performed.\n- Different scaling experiments involving GRF and naturalistic textures were conducted."
            },
            "weaknesses": {
                "value": "- The theoretical analysis is performed for the case of GRFs, which does not apply to naturalistic textures (Note that Gaussian textures are a very limited class of images). Most of the Propositions are special cases of previous work, so what is the theoretical contribution of this work?\n- The different scaling experiments only involve a small set of pairs and 5 naive participants. There may be insufficient data for detailed analysis, and actually results were presented in Sec. 3 without any analysis.\n- The paper appears to be hastily written with many typos (e.g., page 5: e have -> we have; Fig. 2: the colors are wrong, and the caption's description conflicts with the main body, Page 8: Proposition 2 and Proposition 2; ...) and symbols are not always well-defined or explained."
            },
            "questions": {
                "value": "This looks like careful and sophisticated work at first glance. I did not notice major defects in the paper, to my knowledge. However, the paper is difficult to follow and would benefit from careful editing.\nSince I do not have a solid background in this area, I cannot confidently evaluate the significance here.\nIt may be better if the authors can write their manuscript from the point of view of a general researcher in ICLR.\n\nAdditional question: Can the authors explain more on how measuring the perceptual scale helps estimate the perceptual geometry of images? This is claimed in the Abstract but rarely mentioned in the main body."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Reviewer_AMLy"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2733/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698738927950,
        "cdate": 1698738927950,
        "tmdate": 1699636215653,
        "mdate": 1699636215653,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wd0L81rW2q",
        "forum": "z7K2faBrDG",
        "replyto": "z7K2faBrDG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2733/Reviewer_gWW2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2733/Reviewer_gWW2"
        ],
        "content": {
            "summary": {
                "value": "The paper concerns itself with perceptual measures, in particular the perceptual distance between images showing what to me look like \"noise\" images each with a dominant spatial frequency. A theoiry is developed, and then tested experimentally."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I very much approve of the style of the experiment.\nAnd I applaud all efforts to measure human-based distances."
            },
            "weaknesses": {
                "value": "I am not fully convinced by the model - the departure from human measures is significant.\n\nThe stimulli are very limited - gray scale images of textures that look to me like band-limited noise.  I am not at all sure how I should generlise any reults in this paper to general images. That is, it is not clear the model is general. \n\nI suppose what I would really like to see would be something akin to a just-noticable difference, and then to build a measure in frequency space based on jnds - by analogy to jnd in colour space.\n\n--\n\nNot all equations are not numbered, which is a presentation error because it makes discussion hard."
            },
            "questions": {
                "value": "What does the parameter \"s\" mean?\n\nI do not understand the experiment. Three stimulli were presented with s1 < s2 < s3.  I suppose this means the parameter s somehow orders the stimulli, but I don't know how.  Then participants are required to pair either (s1,s2) or (s2,s3). Why remove the (s1,s3) option? (It's removal may bias results.)\n\nOverall, I get the impression the the authors have conducted perceptually experiments (on a very low number of participants) and that this paper is probably better suited to one of the perceptual psychology forums.  But, I found it hard to read, so I could very easily be wrong."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2733/Reviewer_gWW2"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2733/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698954486599,
        "cdate": 1698954486599,
        "tmdate": 1699636215596,
        "mdate": 1699636215596,
        "license": "CC BY 4.0",
        "version": 2
    }
]