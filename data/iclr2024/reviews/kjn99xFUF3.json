[
    {
        "id": "J3wntHlQ5u",
        "forum": "kjn99xFUF3",
        "replyto": "kjn99xFUF3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8857/Reviewer_pEfb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8857/Reviewer_pEfb"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors propose FedDA, an adaptive gradient method for constrained optimization in the Federated Learning context. The proposed method builds on top of previously released approaches in local adaptive gradients, and Federated composite optimization. The authors make their claims clear with both theoretical and experimental results (under homogeneous and heterogeneous data distributions). The main motivation behind their approach is to accelerate federated constrained optimization, by adopting the Mirror Descent view of momentum-based acceleration methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1- The method FedDA is general and can incorporate several adaptive gradient methods.\n\n2- FedDA-MVR, the momentum-based variance-reduction gradient estimation, achieves the optimal  iteration complexity rates of non-convex stochastic optimization, without bounded gradient assumption.\n\n3- FedDA performs better or on par with existing methods, on constrained biomarker identification tasks. FedDA-MVR performs well on image classification tasks, even on the challenging non-i.i.d. setting (Fig.12 in appendix).\n\nOverall, the authors provide a clear overview of dual and/or adaptive Federated methods both theoretically (Table.1) and numerically (>5 concurrent methods tested in Fig.3)."
            },
            "weaknesses": {
                "value": "1- $\\tilde{x}_t$ in equation.9 is not defined in the main text. In particular, how do you compute the L2 distance in between $x_t$ and $\\tilde{x}_t$? Your random variable $\\mathcal{G}_t$ gives an upper-bound (rk.B.17) of L2-norm of the gradient on $\\tilde{x}$ in the unconstrained case. Can we obtain the same for $x$? If yes, is the convergence rate to first order stationary point the same ?\n\n2- I understand fine-tuning NNs on large image classification tasks can be time consuming. However, did you carefully tune the hyper-parameters for FedAvg method? FedAvg is known to perform well under the unconstrained homogeneous setting, but is below $45$% of test accuracy in your experiment on CIFAR-10 (homogeneous; Fig.3). Maybe playing on the local step value $I$, or increasing the batch size (fixed at $16$ in your experiments) can give better gradients estimates, and better performances for FedAvg.\n\n3- Some typos about referencing your algorithms can be confusing (see details in the Questions section below)."
            },
            "questions": {
                "value": "1- At the end of page.5, I think there is a typo about lines 9, 10, 11 of your Algo.1. In particular there is no line.11 in your Algo.1.\n\n2- Minor: Please check your references before updating the final version. For instance the MiME paper is cited twice (on page.11 and on page.12). There is also a typo at the beginning of Section.6.1: PATHMN(I)ST."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8857/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698405320589,
        "cdate": 1698405320589,
        "tmdate": 1699637114093,
        "mdate": 1699637114093,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zoHSxneQdF",
        "forum": "kjn99xFUF3",
        "replyto": "kjn99xFUF3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8857/Reviewer_hZzf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8857/Reviewer_hZzf"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel approach to addressing the problem of constrained federated learning by leveraging adaptive gradient methods. In conventional, non-federated contexts, various techniques and algorithms are available for finding local minimizers of functions, with adaptive gradient methods being particularly effective. The authors extend this idea into the federated learning framework by creating a general adaptive gradient framework.\n\nThis framework includes multiple adaptive gradient methods that rely on a restarted dual averaging technique. The authors begin by adopting a mirror descent perspective of adaptive gradient methods. The central concept in this paper is that if all clients share a common mirror map, they will operate in the same dual space. Consequently, the server can aggregate the local dual states of different clients effectively.\n\nThe paper provides a theoretical analysis of the convergence rate for a specific instantiation of this framework, which employs a momentum-based variance reduction technique. To validate their approach, the authors conduct empirical experiments on various datasets, demonstrating its effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The authors propose an algorithm that solves the under-explored field of constrained federated learning with optimal convergence rates for the constrained setting (up to my knowledge).\n- The algorithm proposed by the authors is projection-free which is remarkable in a constrained optimization problem."
            },
            "weaknesses": {
                "value": "- I found the paper to be poorly written and presented.\n- While I did not found the proposed method to be highly competitive in the unconstrained setting, I believe it holds significant promise in the constrained setting. In my view, the authors should have emphasized the motivation and results from this perspective, rather than aiming to compete with potentially more efficient existing methods.\n- This algorithm is more computationally demanding compared to other algorithms. The added computational cost arises from computing an argmin at each iteration. It remains unclear whether, with this additional step, the proposed algorithm maintains the same level of computational efficiency as its competitors and achieves similar theoretical and experimental results within the same computational budget.\n- While the assumptions made by the authors are common in the analysis of adaptive gradient methods, I find some of them to be rather restrictive, particularly Assumptions 5.1 and 5.4. In light of this observation, the comparison with non-adaptive methods seems somewhat unfair."
            },
            "questions": {
                "value": "- Can we check that assumption 5.4 really holds for the provided update of the adaptive matrix in the case of the momentum-based variance reduction instantiation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8857/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698503399795,
        "cdate": 1698503399795,
        "tmdate": 1699637113957,
        "mdate": 1699637113957,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JoWXl90o44",
        "forum": "kjn99xFUF3",
        "replyto": "kjn99xFUF3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8857/Reviewer_VFUm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8857/Reviewer_VFUm"
        ],
        "content": {
            "summary": {
                "value": "The authors propose an adaptive gradient approach for federated constraint optimization. While existing schemes have focused separately on federated optimization and adaptive gradient approaches for the centralized setting, they combine these two lines of research. Specifically, they derive order results for the convergence and the communication complexity of their proposed scheme and perform numerical experiments for a variety of homogenous and non-homogenous datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The authors have filled a missing gap in proposing adaptive gradient schemes for FL, which did not seem to exist in the open literature before. This is useful for constraint optimization in a federated setting, for example for regularization."
            },
            "weaknesses": {
                "value": "To my opinion, there are two major weaknesses. First, I think that the underlying idea of combining dual averaging with federated constraint optimization is fairly straightforward. The merit of the work is rather in the theoretical order complexity results.\n\nSecond, the paper lacks important information, and thus it is difficult to evaluate their results, specifically with respect to the adaptive gradient results. Specifically, they state on page 5 that the mapping matrix H is updated in line 11 of Algorithm 1, however, line 11 is not present in that algorithm."
            },
            "questions": {
                "value": "What is the comparison of the sample and communication complexity to other non-adaptive schemes? A little table containing these results would be useful.\n\nIn Figs. 1 and 2, the third plot from the right is not explained in the text. Also, here, essentially the gain of FedDA is due to the addition of a regularization constraint (Lasso). Is there also a gain over benchmark schemes (as FedAvg) for settings where these schemes are not overfitting and why?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8857/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699215868290,
        "cdate": 1699215868290,
        "tmdate": 1699637113848,
        "mdate": 1699637113848,
        "license": "CC BY 4.0",
        "version": 2
    }
]