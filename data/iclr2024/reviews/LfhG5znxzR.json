[
    {
        "id": "meQBhtAi8m",
        "forum": "LfhG5znxzR",
        "replyto": "LfhG5znxzR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2820/Reviewer_v2JW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2820/Reviewer_v2JW"
        ],
        "content": {
            "summary": {
                "value": "The paper explores the concept of \"codebook features\" to make the hidden states of neural networks sparse, discrete, and more interpretable. By introducing a vector quantization bottleneck at each layer of the network, the authors achieve this sparse and discrete representation with only a modest performance degradation. The resulting codebook features serve as a promising unit for understanding and controlling neural network behavior, validated through experiments on finite state machines and large-scale language models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The authors show a method of using codebook features introduces a novel way to create sparse and discrete hidden states in neural networks. This approach facilitates the unsupervised discovery of both algorithmic and linguistic features within language models, tackling challenges like the superposition problem and thereby advancing the field of interpretability.\n\n* The paper successfully demonstrates that the sparse, discrete nature of codebook features simplifies the complexity of a neural network's hidden state. This makes it easier to identify specific features and control network behavior, suggesting that this could be a powerful tool for more granular and sophisticated control in future applications."
            },
            "weaknesses": {
                "value": "* While Transformers are prevalent, there are many architecture differences between different models (e.g. novel layers, group-query attention, etc.). In this sense the study is limited in scope by focusing only on Transformer neural networks and examining their performance on a singular algorithmic dataset and two natural language datasets. This leaves unanswered questions about the generalizability of codebook features to other neural network architectures or different types of data, such as visual information.\n\n* While the paper demonstrates the capability of codebook features in topic manipulation for language models, it does not explore other linguistic features like sentiment, style, or logical flow. This limitation narrows the understanding of how versatile and broadly applicable codebook features might be for controlling various aspects of neural network behavior."
            },
            "questions": {
                "value": "1. In authors' two-phase method for understanding and controlling the network's behavior, you focus on generating hypotheses for the role of codes and then steering the network by activating these codes. How robust is this method to the presence of adversarial or noisy input?\n\n2. Authors mention that codebook features reduce the complexity of a neural network\u2019s hidden state, making it easier to control the network\u2019s behavior. Could you provide more details on the trade-offs involved? Specifically, how does the use of codebooks affect the model's capacity for generalization across different tasks or data distributions?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698427717714,
        "cdate": 1698427717714,
        "tmdate": 1699636225791,
        "mdate": 1699636225791,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5P4BbZYayO",
        "forum": "LfhG5znxzR",
        "replyto": "LfhG5znxzR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2820/Reviewer_aakk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2820/Reviewer_aakk"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to select Top-k hidden units with the highest similarity score to learn sparse and discrete codebook features in an unsupervised way. They have also tried to apply this technique to transformers for language modeling tasks. Experiments show that the model can do well in the task of topic manipulation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is well-written and easy to follow.  The proposed method is straight forward. The experiment results are interesting in table 4. I believe that the proposed method may be applicable to many use cases, which potentially can lead to applications in future work."
            },
            "weaknesses": {
                "value": "1. The paper is missing the comparison for computational time. With a sparse and discrete codebook, it should lead to increased efficiency.\n2. A chart or figure showing the learned topics for each layer may be missing."
            },
            "questions": {
                "value": "1. How do you find the activated codes and their corresponding topics? How do you know for example 'code 123' leads to the topic of 'dragon'?\n2. Will the model lead to better computational time?\n3. There are dead codes during training and how do we avoid them? Will the activated codes learn repeated semantics (For example, will one of the codes be activated all the time)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2820/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2820/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2820/Reviewer_aakk"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698768846775,
        "cdate": 1698768846775,
        "tmdate": 1699636225703,
        "mdate": 1699636225703,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DPyqbcUmQI",
        "forum": "LfhG5znxzR",
        "replyto": "LfhG5znxzR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2820/Reviewer_AYvz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2820/Reviewer_AYvz"
        ],
        "content": {
            "summary": {
                "value": "In this work, a method is proposed to improve the interpretability and controllability of a transformer network by quantizing the activations per token with a sparse combination of entries from a codebook. To select the sparse codes, the cosine similarity between token activations and codebook entries are computed and a weighting is taken based on top-k most similar entries. Experiments on a dataset of state transitions and on language datasets show that the use of codebook entries correlate with certain aspects of the dataset (e.g., states or semantic concepts). Furthermore, experiments show that codebook entries can be applied as a token to steer the output of the transformer network."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* This work considers the problem of interpreting the intermediary layers and controlling the output of transformer networks, which are of significant interest to the machine learning community. Furthermore, quantizing features with codebooks is a popular technique which the work demonstrates leads to a minimal degradation in model performance.\n* Experiments with the TokFSM dataset are intuitive and clearly demonstrate the ability to intervene in the output of a transformer trained with codebook quantization. Experiments such as the JS divergence with the target token distribution in Figure 4, are used to demonstrate effective intervention. Given that one has access to the semanticity of entries in the learned codebook, the proposed method seems to be effective at steering the output of transformer network.\n* The work contains a comprehensive related works section in the appendix that clarifies the benefits of a discrete codebook over using a dictionary approach (referred to as \u201cfeatures-as-directions\u201d)"
            },
            "weaknesses": {
                "value": "* One shortcoming of the experiment in table 1 is that it has two dependent variables: both the quantization level k and the codebook size C. It is important to ablate changes to these two variables separately to better understand if they both independently provide benefits. There is a similar issue of two dependent variables being tested at the same time in Table 2 where both k is modified as well the features being quantized (i.e., attention vs mlp features). \n* The benefit of sparsity in the combination of codebook entries has not been clearly articulated. In fact, in section F.1.1 of the manuscript, it is argued that the continuous combination of different atoms reduces interpretability. Selecting codebook entries via top-k cosine similarity is a naive approach that has not been compared to more recent sparse coding techniques (e.g., variational sparse coding methods like in Tonolini et al. 2020 and Fallah et al. 2022). Except for the potential increase in modeling capacity, the work does not demonstrate the benefit of quantizing with multiple codebook entries per token.\n* Interpretation of codebook entries still seems to require manual intervention. It requires a user to find input data for which a codebook entry is often activated, which can be timely and costly. It is unclear how one would use current methods to find a codebook entry that corresponds with a certain semantic concept without manually performing a forward pass using data corresponding to that concept.\n\n\nMinor:\n* Some citations need revising in the bibliography (e.g., \u201cOn the role of scientific thought\u201d)."
            },
            "questions": {
                "value": "* Can the authors clarify the benefit from increasing k? Since the authors use cosine similarity between the activations and the codebook to pick the top-k entries, what would the difference be between each of these k codebook entries? It seems that taking k entries contradicts the viewpoint of \u201cfeatures-as-points\u201d, and may even lead to what the authors refer to as \u201csmuggling of information\u201d. I would expect that increasing k may improve performance of the model, at potential cost to interpretability.\n* Out of curiosity, have the authors considered quantizing each vector along the feature components (i.e., divide the N features of each token into k blocks)? Is this what the authors refer to as \u201cgrouped codebooks\u201d in E3? If so, I believe this warrants discussion and attention in the main text. This would be an alternative to quantizing each token with k codebook entries that are very close in cosine similarity and be closer to the VQ-VAE setting.\n* The notation and presentation of the different loss terms in section 2.1 can be made more clear. In the cross-entropy loss, x is used to denote a categorical random variable corresponding to a token being selected. In the reconstruction loss, to my understanding, x is referring to a continuous random variable corresponding to the activation in an intermediary layer, even though the variable a is used in an earlier section. Furthermore, k-codes are combined to quantize each activation. Is the MSE taken with the sum of these codes or each code individually?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698798706137,
        "cdate": 1698798706137,
        "tmdate": 1699636225625,
        "mdate": 1699636225625,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "00YDRIzgbN",
        "forum": "LfhG5znxzR",
        "replyto": "LfhG5znxzR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2820/Reviewer_XCvz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2820/Reviewer_XCvz"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes the discretization of intermediate features within deep Transformers, ensuring that the network's outputs (decisions) are contingent solely on finite, interpretable, and sparse codes. The authors demonstrate that by exploring the connections between specific codes and semantic or high-level topics and by adjusting these intermediate codes, users can exert intuitive control over the network's behavior. A comprehensive set of experiments reveals that the modified networks maintain competitive performance levels after fine-tuning."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The authors introduce an intriguing inquiry into the performance of deep Transformers when their intermediate features are discretized. Surprisingly, the results appear promising for both small-scale and large-scale Transformers.\n* Introducing discrete features (codes) which are shown associated to specific semantics in the paper brings interpretability to some extent. More importantly, such an approach enables users to control the models' output by modifying codes that have human understandable semantics. In fact, a similar approach has been introduced in computer vision to facilitate the creation of interpretable inference procedures [1] and controllable image synthesis [2].\n* The paper is technically sound, and it provides a thorough discussion of the related literature.\n* The paper is well-written and easy to follow.\n\n\n>[1] Schema Inference for Interpretable Image Classification. (ICLR 2023)\n>\n>[2] Taming Transformers for High-Resolution Image Synthesis. (CVPR 2021)"
            },
            "weaknesses": {
                "value": "[Major]\n1. **Experiments:** As mentioned in the paper that a code can be related to some specific semantics; however, the results supporting such claim appears insufficient. The authors may consider conducting comparative analyses of the distribution disparities between code associated with similar and dissimilar semantics to substantiate this claim. \nIn addition, is it possible that a (some) certain code(s) may correspond to a multitude of distinct semantic contexts?\n2. **Experiments:** It is interesting that model outputs is controlled by the codes. However, based on the results on TokFSM dataset, it appears that the code following the MLP layer plays a more significant role. Nevertheless, the experiments conducted by the authors on WikiText-103 dataset only involve discrete attention layers (in Table 2 (b)). Does this incongruity potentially render it challenging to control the model?\n3. \n4. **Experiments:** In Section 2, the authors sum top-k codes weighted by the same value (specifically, 1). How will each code influence to the model's decision? (For example, does codes having semantics related to the target task contributes most to the model's decision evaluated by attribution methods?) In particular, the authors can utilize feature attribution methods [3-5] to present quantitative and qualitative analyses.\n5. What is the extent of the contributions made by these pieces of code to the final outcome? It may be worthwhile to investigate this using feature ablation techniques to discern whether the words crucial for the model's decision-making align with human intuition.\n\n    >[3] Deep inside convolutional networks: Visualising image classification models and saliency maps.\n    >\n    >[4] Did the model understand the question? (ACL 2018)\n    >\n    >[5] Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions.\n\n[Minor]\n1. The font size in the figures is excessively small, making them particularly challenging to decipher when printed (e.g., Figure 1, 2 and 3). Furthermore, it is advisable for the authors to employ vector graphics to enhance the quality of the illustrations.\n2. The authors do not provide codes for reproducibility check.\n3. The authors could provide some failure cases to facilitate further analysis of how the proposed method yields incorrect results. If feasible, this could also serve as a basis for advancing future work."
            },
            "questions": {
                "value": "My questions are listed in the \"Weaknesses\" section. I am looking forward to the authors' relply."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2820/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2820/Reviewer_XCvz",
                    "ICLR.cc/2024/Conference/Submission2820/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2820/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698836240509,
        "cdate": 1698836240509,
        "tmdate": 1700449602119,
        "mdate": 1700449602119,
        "license": "CC BY 4.0",
        "version": 2
    }
]