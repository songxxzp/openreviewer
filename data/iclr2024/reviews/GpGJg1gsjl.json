[
    {
        "id": "j79Pqn4P7v",
        "forum": "GpGJg1gsjl",
        "replyto": "GpGJg1gsjl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3559/Reviewer_FXsp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3559/Reviewer_FXsp"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a comprehensive study of applying Uncertainty Sampling (US) within the Active Learning (AL) framework for node classification within graphs. The authors provide a benchmark for AL and evaluate the performance of AL baselines using real word datasets. Additionally, they propose novel Bayesian uncertainty estimation methods based on the ground truth labels, and illustrate their effectiveness using synthetic CSBM dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper offers a thorough evaluation of AL performance through a series of well-conducted experiments and a qualitative analysis."
            },
            "weaknesses": {
                "value": "The proposed ground truth uncertainty is not so useful and the uncertainty sampling US based on it is not practical. During prediction procedure, the ground truth label remains unknown and therefore it is inappropriate to define an uncertainty based on it. \n\nUS with knowledge of ground truth label would benefit from the information leakage and so the good performance in the CSBM dataset is not achievable in real-world datasets. For example, in traditional AL algorithms, it's difficult to select a node for query when the classifier gives the ground truth label of the node a low predictive probability, although querying such node would provide the classifier a lot information. Take, for instance, a scenario where  p(ground truth class| y_i ) = 0.1 and p(incorrect class| y_i ) = 0.9. Typically the prediction to incorrect class of y_i might be considered confident and AL algorithm will not choose y_i for querying, and such error will cause general AL algorithm not perform as good as random sampling. But for US based on ground truth uncertainty, the epistemic uncertainty is large and the node will be selected. Therefore, the good performance in the CSBM dataset is not practical."
            },
            "questions": {
                "value": "Please explain the practical application of the ground truth uncertainty."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3559/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698453190446,
        "cdate": 1698453190446,
        "tmdate": 1699636310517,
        "mdate": 1699636310517,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "G0QxsNHFcL",
        "forum": "GpGJg1gsjl",
        "replyto": "GpGJg1gsjl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3559/Reviewer_KZ6P"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3559/Reviewer_KZ6P"
        ],
        "content": {
            "summary": {
                "value": "The authors establish a benchmark for uncertainty sampling based active learning approaches for graph data. The paper also proposes a Bayesian uncertainty estimation to actively select the node. This estimation is based on the knowledge of data-generating process. The authors validate the effectiveness of their approach with both theoretical analysis and empirical experiments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "a. This paper studies the active learning problem with graph data from an interesting perspective--uncertainty sampling strategy and propose a new Bayesian uncertainty estimation.\n\nb. The authors provide both theoretical analysis and empirical results to show the effectiveness of the proposed estimation."
            },
            "weaknesses": {
                "value": "a. Theoretical contributions in this paper appear to be somewhat limited. The proposed uncertainty estimation is based on the posterior probability given the ground-truth label of the unobserved nodes. However, the essence of active learning lies in addressing this problem without access to ground-truth information, which remains inadequately addressed.\n\nb. The experimental results provided are restricted to synthetic data, and the method's reliance on knowledge of the true data generation process probabilities pose practical challenges. How to approximately compute the estimation remains unclear.\n\nc. In the empirical evaluation, the compared baselines are only random queries and other uncertainty-based methods, the state-of-the art methods are missing, e.g. SEAL[1] and IGP[2]. \n\nd. The paper's presentation could be improved. For instance, when introducing concepts like aleatoric and epistemic uncertainty, the authors provide limited explanations and intuitions, potentially causing readers unfamiliar with these terms to struggle to follow the paper.\n\n[1] Li Y, Yin J, Chen L. Seal: Semisupervised adversarial active learning on attributed graphs[J]. IEEE Transactions on Neural Networks and Learning Systems, 2020, 32(7): 3136-3147. \n[2] Zhang W, Wang Y, You Z, et al. Information Gain Propagation: a new way to Graph Active Learning with Soft Labels[J]. arXiv preprint arXiv:2203.01093, 2022."
            },
            "questions": {
                "value": "a. How can the proposed uncertainty estimation be computed in practical scenarios where true data generation probabilities are unknown? Are there methods or approaches to approximate this estimation without relying on ground-truth knowledge?\n\nb. What's the performance of non-US based active learning methods on CSBMs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3559/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3559/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3559/Reviewer_KZ6P"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3559/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698743618285,
        "cdate": 1698743618285,
        "tmdate": 1699636310442,
        "mdate": 1699636310442,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QJkawNBrTl",
        "forum": "GpGJg1gsjl",
        "replyto": "GpGJg1gsjl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3559/Reviewer_5NFL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3559/Reviewer_5NFL"
        ],
        "content": {
            "summary": {
                "value": "This work is an empirical study of a typical Active Learning method, Uncertainty Sampling (US) for node classification on graphs. The authors present an extensive benchmark for US methods that goes beyond predictive uncertainty, revealing that, the US employing modern uncertainty estimators struggles to outperform random queries consistently. The authors establish ground-truth Bayesian uncertainty estimates for a Bayesian classifier based on the underlying graph generative process, providing formal evidence of the alignment between US and AL. When they apply their approach using a Clustered Stochastic Block Model (CSBM), they empirically confirm the effectiveness of US when uncertainty estimates are accurately disentangled into aleatoric and epistemic uncertainty while considering all available graph information."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This work provides an empirical study for US with node classification on graphs, highlighting both its efficacy and potential limitations.\n\n- An important finding is that the existing AL methods cannot outperform random sampling benchmarks."
            },
            "weaknesses": {
                "value": "- The study primarily concentrates on a specific graph type, the CSBM, which might not fully represent the characteristics of all real-world graphs.\n\n- Novelty concern: undoubtedly, this work offers an extensive exploration of uncertainty-based Active Learning (AL) within the context of graphs. However, it does not introduce any novel methods for active learning in the graph domain."
            },
            "questions": {
                "value": "- In the experimental results, such as Figure 3, the curves depicting acquired labels versus accuracy exhibit significant fluctuations. Did the authors conduct repeated trials to mitigate these fluctuations in the model's performance?\n\n- In the Introduction section, the authors dedicated an extensive portion of the text to explain uncertainty sampling. This level of detail might be excessive as uncertainty sampling is a straightforward concept. It would be more beneficial to present the essential formulations and allocate additional space to elaborate on active learning in graph-related tasks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3559/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698787920326,
        "cdate": 1698787920326,
        "tmdate": 1699636310337,
        "mdate": 1699636310337,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ptfTYm1MlN",
        "forum": "GpGJg1gsjl",
        "replyto": "GpGJg1gsjl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3559/Reviewer_fMcb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3559/Reviewer_fMcb"
        ],
        "content": {
            "summary": {
                "value": "This article studies the application of AL to graph data, with a focus on the approach of uncertainty sampling. The authors demonstrated through an extensive empirical analysis that many AL strategies, uncertainty-based or not, failed to surpasse random sampling on graph data. A curious observation is that uncertainty estimators which distinguish the reducible uncertainty caused by the randomness of training data from the irreducible uncertainty due to the underlying data generating process and use only the reducible uncertainty to guide the label queries work well on i.i.d. data but not on graph data. Motivated by this observation, the authors proved theoretically that, under a Contextual Stochastic Blockmodel (CSBN) with known parameters, minimizing the reducible uncertainty leads to an optimal AL strategy. This remark is  confirmed on simulated data of (CSBN)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This work is well guided with a series of inquiries, starting with open questions in literature review, conducted with empirical observation, theoretical investigation, ending with experimental confirmation.\n\n- The thorough empirical analysis and the original theoretical insights are of interest to the scientific community."
            },
            "weaknesses": {
                "value": "- The theoretical investigation, which is a major contribution of the article, not only considers a specific model (which is perfectly acceptable), but also assumes the full knowledge of the parameters underlying the model. As in practice the model parameters are rarely known and have to be estimated from data, their estimation error will contribute to the reducible uncertainty. Therefore defining the reducible uncertainty while assuming the model parameters to be pre-known seems to be problematic and needs at least to be discussed.\n\n- It should be made clear earlier in the article (e.g. in the abstract or introduction) that the proposed uncertainty measure is not directly applicable in practice, and rather of theoretical interest."
            },
            "questions": {
                "value": "My questions are related to the first point of Weaknesses:\n\n- How will the reducible uncertainty change without the knowledge of model parameters ?\n\n- Will the conclusion regarding the optimality of using the reducible uncertainty to guide AL stay the same ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3559/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3559/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3559/Reviewer_fMcb"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3559/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698834310916,
        "cdate": 1698834310916,
        "tmdate": 1699636310232,
        "mdate": 1699636310232,
        "license": "CC BY 4.0",
        "version": 2
    }
]