[
    {
        "id": "AoYTXdOzYB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3266/Reviewer_JdCs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3266/Reviewer_JdCs"
        ],
        "forum": "EvBx5whpzJ",
        "replyto": "EvBx5whpzJ",
        "content": {
            "summary": {
                "value": "This paper proposes a blurred-segmented time series classification framework, Con4m, that forces label coherence and prediction behavior between two consecutive predictions. It also incorporates curriculum learning and gradual label change to cope with label inconsistency in transitions. Con4m shows its superiority in two public dataset and one private dataset with ablation studies for each component."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper covers a novel time-series data, blurred-segment time series.\n2. Proposes practical framework for time series classification with noises."
            },
            "weaknesses": {
                "value": "1. Model degradation by label inconsistency in transition is not validated. The number of timestamp where transition occurs is very small comparing to the length of a whole time series. Does it really harm the model performance significantly? Plus, when annotating SleepEDF, multiple doctors are already recruited to make an agreement in their annotations, which can reduce inconsistency in state transition regions.\n\n2. Methods seem to be a heuristic without enough justification and not novel. In neighbor class consistency discrimination, there could be so many ways to achieve it but there is no explanation on the design choice the authors made. Also, the theory does not support the reason why $\\ell_2$ loss should be used.\n\n3. Experiment setting is not convincing. The labels are disturbed synthetically and one of three datasets is a private dataset, which cannot be reproducible."
            },
            "questions": {
                "value": "1. What is the dimension of $x_t$? Is it different from $x_1,\\ldots,x_L$? Is $x_t \\in \\mathbb{R}^{L \\times d}$ where $d$ is the number of feature?\n\n2. The function fitting incurs more computations in training loop. Can you elaborate on computational complexity?\n\n3. At which layer $\\ell_1$ and $\\ell_2$ is applied?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3266/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697332524338,
        "cdate": 1697332524338,
        "tmdate": 1699636275130,
        "mdate": 1699636275130,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NGkKXDrVgO",
        "forum": "EvBx5whpzJ",
        "replyto": "EvBx5whpzJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3266/Reviewer_zaSc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3266/Reviewer_zaSc"
        ],
        "content": {
            "summary": {
                "value": "The paper focuses on a time series classification problem in a novel setting of \"blurred segmented\" time series where each time series is exhaustively segmented and each segment is labeled with one of the given states. The notion of \"blur\" stems from the blurry transition boundaries between the two consecutive states in a given time series. The ultimate goal (to my understanding) is to train a Time Series Classification (TSC) model which can automate the segmentation and labeling process on such time series.  To train such a TSC model, the training data is comprised of labeled BS time series where the labels of all segment are manually annotated by multiple domain experts. The key feature of the proposed solution  is a novel deep learning attention-layer based architecture which is capable of leveraging the contextual dependencies between adjacent segments of time series. The proposed approach is evaluated against multiple baselines on three real-world datasets  (two public and one private) from healthcare and neuro-science domain which also appear to be the key applications of such work. The evaluation results seem to indicate better performance of the proposed approach in comparison to the baselines."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The problem setting of time series classification on blurred segmented time series is quite relevant for many domains. \n2. The proposed approach seems to be outperforming the state-of-the-art time series classification baselines on multiple real-world datasets. \n3. Ablation studies seem to justify the value of various components of the approach."
            },
            "weaknesses": {
                "value": "1. The paper is not written well and a bit difficult to follow. To begin with, the term \"blurred segmented time series\" is not concretely defined throughout the manuscript. To the best of my knowledge, this term is not ubiquitous in ML community. Further, the introduction does not clearly define the problem formulation.  In particular, it is not clear whether the end result is to classify the individual segments or classify an entire time series which comprises of multiple segments. The problem formulation is not mathematically defined even in subsequent sections which keeps a reader busy guessing. Further, several terms like samples vs segments vs timestamps , state vs labels are confusingly used at several places which makes it super difficult to understand the exact problem formulation. It is also not clear whether a segment is of fixed length or varying length. \n\n2. The motivation regarding too much noise in the labels in the segments due to label inconsistencies on boundary segments is also not super convincing. For instance, why can't one simply get rid of  such boundary segments and train the model only on cleaner samples?\n\n3. The theoretical justification section also lacks rigor and not quite convincing. In particular, the authors use mutual information definitions to make arguments in support of choosing augmented features from a neighborhood segment window. However, those arguments are very superficial and lack rigor (see detailed comments below).\n\n4. The description of proposed approach is also quite difficult to follow. Several key notations are not well defined (e.g. what are V_s and V_t) and I had to read the papers in related work (e.g. Xu et al. 2022) in quite detail from where the ideas are borrowed. Even then, certain components of the approach such as neighbor class consistency discrimination are yet not clear to me."
            },
            "questions": {
                "value": "Specific comments/questions: \n1. Page 3, line 86-87: This statement doesn't sound quite valid to me. What does it mean to say that we need to increase p(x_{A_t}|x_t)? We aren't talking about one specific value of x_{A_t} here, it's a distribution, right?  And ultimately all the terms are being summed up over all possible values of x_{A_t}. Similar concern for KL divergence argument. Basically, the justification given  in the support of design of proposed approach is not convincing and needs more rigor. \n\n2. Page 3, lines 87-88: What do you exactly mean by \"easier to predict\"? Do you mean adding small noise to the samples? Perhaps being more specific here along with some citations will help.\n\n3. A mathematical problem statement is dearly missing in Section 3. \n\n4. Section 3.1: What is meant by a \"smoother representation\"? Perhaps you meant to say that the representation function should be \"temporally smooth\" so that the neighboring segments get embedded close-by in the embedding space? \n\n5. Section 3.3, Lines 235 - 238: What is the significance of every group? How are you exactly getting 12 and 6 cross-validation results? \n\n6. In section 4.5 (case study), what is the length of each segment? Is it fixed to 2 s? If so, how come SREA and MiniRocket has sub-segments of labels of lengths<2s? Or are we not labeling the entire segment with the same label?\n\n7. Section 4.2, In lines 266-272: Is the noise coming due to challenging boundary disturbances similar to random noise as introduced in this experiment?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3266/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698575621006,
        "cdate": 1698575621006,
        "tmdate": 1699636275035,
        "mdate": 1699636275035,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eoe09WaTFm",
        "forum": "EvBx5whpzJ",
        "replyto": "EvBx5whpzJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3266/Reviewer_5NtK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3266/Reviewer_5NtK"
        ],
        "content": {
            "summary": {
                "value": "Blurred-segmented time series (BST) data has continuous states with inherently blurred transitions, leading to annotation noise. Existing time series classification methods do not consider label inconsistency and contextual dependencies between consecutive classified samples. To address these issues, the paper first theoretically identifies the value of contextual information, and then proposes a transformer-based model that incorporates contextual information from BST data. Moreover, the paper adopts curriculum learning techniques to train the model under annotation noise. Experiments show the proposed method achieves better classification accuracy than baseline methods on three datasets under different levels of label noise."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The problem setting is new and realistic. The paper consider time series classification on the new blurred-segmented time series data which has inherent contextual dependencies between classified samples. Without relying on the common i.i.d. assumption on samples, the proposed method boosts classification accuracy by explicitly exploiting the neighboring samples of a target sample. \n\n+ The proposed method exploits both contextual information and noisy labels and can be applied to many realistic time series classification problems.\n\n+ The experiments are well-designed and extensive. Results show that the proposed method outperforms baselines on the three datasets with different levels of label noise. Ablation studies show that each of the proposed components are effective in improving the time series classification accuracy."
            },
            "weaknesses": {
                "value": "- The clarity of the paper can be improved.\n  Proposition 1 is a basic mutual information inequality. It is unclear how the mutual information $I(y_t;x_t,x_{\\mathbb{A}_t})$ relates to the performance of a model.\n\n- The proof of Theorem 1 mismatches with the claim.\n  The proof only analyzes in what cases can $I(y_t;x_{\\mathbb{A}_t}|x_t)$ be increased.\n  How the predictive capability for the labels is defined? How do we know the contextual information enhances the predictive capability? And what is the connection between predictive capability and the mutual information gain?\n\n- The motivation for the proposed method is not clear. For example, why using a Gaussian kernel function can better align with  $p(x_{\\mathbb{A}_t}|x_t)$ and $p(y_t|x_t, x_{\\mathbb{A}_t})$?"
            },
            "questions": {
                "value": "1. In Proposition 1, how the mutual information $I(y_t;x_t,x_{\\mathbb{A}_t})$ relates to the performance of a model.\n\n2. In Theorem1, how the predictive capability for the labels is defined? How do we know the contextual information enhances the predictive capability? And what is the connection between predictive capability and the mutual information gain?\n\n3. What is the computational complexity of the proposed method? Can the proposed method scale to longer time series?\n\n4. Why using a Gaussian kernel function can better align with $p(x_{\\mathbb{A}_t}|x_t)$ and $p(y_t|x_t,x_{\\mathbb{A}_t})$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3266/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698726046289,
        "cdate": 1698726046289,
        "tmdate": 1699636274922,
        "mdate": 1699636274922,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "l6Q6tluekC",
        "forum": "EvBx5whpzJ",
        "replyto": "EvBx5whpzJ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3266/Reviewer_2FMY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3266/Reviewer_2FMY"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors study the blurred segmented time series (BST) data prediction problem. The authors theoretically clarify the connotation of valuable contextual information. Based on these insights, prior knowledge of BST data is incorporated at the data and class levels into the model design to capture effective contextual information. Moreover, the authors also propose a label consistency training framework to harmonize inconsistent labels. The authors have performed extensive experiments on real datasets to demonstrate the effectiveness of the proposed method in handling the time series classification task on BST data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe authors propose a new framework to handle the time series classification task on blurred segmented time series data.\n\n2.\tThe authors provide some theoretical analysis about the connotation of the valuable contextual information.\n\n3.\tIn the proposed framework, prior knowledge of the BST data at both the data and class levels are incorporated into the proposed model to capture the effective contextual information.\n\n4.\tThe authors have performed extensive experiments on 3 real datasets to demonstrate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1.\tSome assumption of the proposed method seems a little strong. In Section 3.2, for the prediction behavior constraint, it is assumed that consecutive time segments span at most 2 classes within a suitably chosen time interval. The time interval may have a big impact on the model performance. However, it is not clear how to choose a suitable time interval for each dataset. The authors also need to perform experiments studying the impacts of the time interval on different datasets.\n\n2.\tThe experimental analysis seems not consistent enough. In Figure 3(b), the analysis about random disturbance is studied on fNIRS and Sleep datasets. In Table 3, the ablation studies are performed on Sleep and SEEG datasets.\n\n3.\tThe experimental analysis is not sufficient. Compared with existing methods, one advantage of the proposed method is to exploit the prior information at both the data and class levels. The authors are suggested to perform experiments studying the performance of the proposed method with only considering the prior information at data level and class level respectively."
            },
            "questions": {
                "value": "As discussed in Section 3.2, the time interval may have a big impact on the model performance. How to choose a suitable interval for each dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3266/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699070388680,
        "cdate": 1699070388680,
        "tmdate": 1699636274842,
        "mdate": 1699636274842,
        "license": "CC BY 4.0",
        "version": 2
    }
]