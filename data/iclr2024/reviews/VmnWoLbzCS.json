[
    {
        "id": "2RlTm8a3no",
        "forum": "VmnWoLbzCS",
        "replyto": "VmnWoLbzCS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8483/Reviewer_xkWX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8483/Reviewer_xkWX"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an overview of the LLM Agent architecture, with: planning, execution and grounding. The method is competitive for math, QA, and WebShop tasks with significantly smaller model size. The proposed framework is generally applicable to tasks where Language Models are used as an agent."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper demonstrated a solid framework for using smaller models as LLM agents.\n2. The presentation of the paper is easy to follow and the figure is straightforward. \n3. I do appreciate the paper does some detailed ablations of the method, making it stronger."
            },
            "weaknesses": {
                "value": "1. My first question for the authors is: the agent framework has been discussed quite often (there have been some follow-ups since the ReACT paper came out). Although the author claimed they are mostly based on close-source API based models (not the open-source ones), it seems the architecture is quite similar?\n2. Why on math tasks, LUMOS-O significantly outperforms LUMOS-I while in the other two tasks, the results seem to reverse? Some more analysis on the error patterns would be preferred to give some more insights.\n3. Why LUMOS in general outperforms UA-T? Does this mean some tasks jointly fine-tuned together can result in some conflict? Does this imply that we should train multiple smaller models each fine-tuned for a specific task?"
            },
            "questions": {
                "value": "Please see above for comments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8483/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698810275522,
        "cdate": 1698810275522,
        "tmdate": 1699637059187,
        "mdate": 1699637059187,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mTtk6Ue3b1",
        "forum": "VmnWoLbzCS",
        "replyto": "VmnWoLbzCS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8483/Reviewer_7VK9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8483/Reviewer_7VK9"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new framework to train LLMs for certain tasks such as answering questions related to maths, textual comprehension and outputting actions for a website (click). The new framework has three parts (\u201cmodules\u201d):\n\n- \u201cplanning\u201d, which converts a prompt to (simpler, but still human language-like) queries (\u201csubgoals\u201d), e.g. \u201cQuery the living period of Lowell Sherman\u201d\n\n- \u201cgrounding\u201d, which converts the subgoals to \u201cactions\u201d: function-call type queries, e.g. \u201cKnowledgeQuery(Lowell Sherman)\u201d\n\n- \u201cexecution\u201d, which executes those actions\n\nFor both planning and the grounding phases (\u201cmodules\u201d) GPT-4 is used to generate annotated examples for the given task at hand to train LLAMA-7B with.\n\nTwo versions are suggested: LUMOS-O (which goes through the above three parts/modules sequentially) and LUMOS-I (which iterates through each subgoal until the execution of that subgoal, the result of which is then used for the next planning the next subgoal).The framework is applied to the open source LLAMA 7B LLM and claims superior or competitive performance on larger LLMs without or with techniques to improve their performance such as Chain of Thought prompting, SelfInstruct, ReWOO-Planner-7B (an improvement of React) and for this claim provides experiment details on these tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes a new framework/pipeline to achieve better results with prompting LLMs in a nascent field, which could be seen as original.\n\nQuality: The methodology of the paper is well-documented, the experiment section contains results on relevant datasets.\n\nClarity: the paper follows the ICLR formatting style, images are mostly clearly captioned, there is an attempt to place the work in the (very recent) literature. Large sections of the paper are easy to understand.\n\nIn terms of significance, using their particular setting a 7B-parameter open-source LLM outperforms larger LLMs queried by previous techniques."
            },
            "weaknesses": {
                "value": "Having said the above in terms of strengths, in my opinion the paper includes a fair bit of weaknesses.\n\nThe paper\u2019s claim that LUMOS outperforms or is competitive compared to larger LLMs is not well justified by evidence. A list of issues are:\n\n- F1-scores are not reported, and to the best of my knowledge that is the primary metric in this field of AI\n\n- The LLM is fine-tuned for the specific tasks (for subgoal and action generation), whereas the baselines use publicly available APIs at best, hence they are more general\n\n- Unless I am mistaken: on GSM8K, ReWOO achieves 62.4% accuracy (as opposed to the reported ~38) in Xu et al. 2023 and is significantly better than LUMOS (50.5%)\n\n- I could be wrong, but to me it looks like ReWOO trained a 7B model, they only used GPT-3.5 for the QA tool. I also cannot find the claimed LLAMA-7B results in Xu et al. 2023. Also, ReWOO-7B uses GPT-3.5-turbo as a QA tool, achieves 66.6% accuracy on StrategyQA, which is better than all LUMOS agents that used GPT-3.5-turbo as QA. \n\n- Mind2Web baselines were not fine-tuned at all, hence comparing them to LUMOS is not that fair.\n\nI also have concerns about the significance of this contribution. React and Self-Instruct defined ways to improve the performance of LLM agents with little to no fine-tuning, only publicly available API calls. The concept that large neural networks can be fine-tuned with additional task-specific training data for better performance on those tasks is fairly well-known in the community. \n\nIn terms of clarity, the paper has a lot of typos, odd sentences and style issues that made it much more difficult to understand than it should have been. Although they ultimately did not affect the score of this paper, they were close to it. I will list some of the found issues below:\n\nIn the abstract: showd -> showed\n\nIntroduction\n\n2nd paragraph: However, Lie et al\u2026 citations ideally should not be used as nouns.\n\nBeginning of 3rd paragraph: There should be an introductory sentence to ask the question. Then instead of \u201cto this end\u201d\u201d write to answer this question\u201d\n\nIn Figure 1, the prompt should be included in the Figure.\n\nEnd of 3rd paragraph: What are environment states? They are never defined.\n\n4th paragraph: \u201c[...] language agents to acquire these skills [...]\u201d what skills?\n\n2.2\n\n2nd paragraph: \u201c[...] part of grounding module\u2019s input\u201d -> the missing before grounding\n\n2.2 and 2.3 general comment: the difference between LUMOS-I and LUMOS-O should be demonstrated with the same example for easier comprehension (e.g. with the Obama example)\n\nFigure 3a right image:\n\n<|user|> Should we keep planning?\n<|assistant|> No I will keep planning.\nShouldn\u2019t the user say \u201cShould we stop planning?\u201d\n\n3.2\n\n3rd paragraph\n\nThe subsequent conversation is constructed in the similar patterns. -> remove the\n\n\u201cWe assume ourselves as user\u201d -> as the user\n\n\u201cTell the execution results\u201d -> provide the execution results\n\n\u201cTo planning module\u201d -> to the planning module\n\n4th paragraph\n\n\u201c[...] play a user role to provide the task\u201d -> provide to what? Do you mean get/acquire/obtain?\n\n\u201cIn the rest conversations\u201d -> remaining, of rest of the\n\n4.4\n\n\u201cAchieves 5-10 average reward than\u201d -> odd sentence\n\n\u201cThan using Self-Instruct method\u201d -> missing the\n\n\u201cAnnotation is\n\n beneficial than\u201d -> more beneficial\n\nRelated Work\n\n\u201cWe notice that directly generating annotation with for training planning and grounding modules may introduce large number of errors\u201d -> \u201cWe notice that directly generating annotations for the training, planning and grounding modules may introduce a large number of errors\u201d\n\n\u201cLLMs transform the gold reasoning steps\u201d -> I don\u2019t understand what you mean, but I am fairly certain not what is written here"
            },
            "questions": {
                "value": "The Self-Instruct paper lists a lot more related work. How are those related to the work presented in this paper?\n\nIn the Introduction this sentence is written: \u201cTogether, our proposed framework and unified model provides valuable resource and direction for advancing open-source interactive language agents.\u201d (resource -> resources)\n\nBut it is never elaborated upon and you do not mention potential future work in the conclusion either.\nWhat future work do you envision after this paper? How could the community successfully build on top of this new framework that was proposed?\n\nWhat are the limitations of the work you suggested?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8483/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812462145,
        "cdate": 1698812462145,
        "tmdate": 1699637059080,
        "mdate": 1699637059080,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "idWgn5AfyT",
        "forum": "VmnWoLbzCS",
        "replyto": "VmnWoLbzCS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8483/Reviewer_9Mw2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8483/Reviewer_9Mw2"
        ],
        "content": {
            "summary": {
                "value": "The paper presents LUMOS, a language agent framework built for open source LLMs with unified formats and modular design. LUMOS divide the framework into separate modules for planning, grounding and execution. The obtain high-quality annotations for training the modules, the authors leverage LLMs to convert ground truth intermediate reasoning steps in existing benchmarks into a unified format. LUMOS demonstrates competitive or superior performance compared to SOTA systems on a variety of interactions including web agent, math reasoning and complex QA."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper studies an important problem of developing language agents, and a unified framework and format is much needed in the field.\n2. The overall description of the method is clear and easy to follow.\n3. Experiment covers both regular fine-tuning setting, and generalization to unseen task."
            },
            "weaknesses": {
                "value": "1. My main concern is regarding the claim on LUMOS achieving superior performance than other LLM-based agents:\n    1. LUMOS is trained on top of LLAMA-2, while some of the baselines are based on LLAMA. For example in Table 1, according to the latest results from AgentBench, updated vicuna-13B v1.5 based on LLAMA-2 now has 41.7 on WebShop, even outperform LUMOS. To make a fair comparison, I would recommend to keep it consistent across models, reporting both LUMOS and baselines with LLAMA, or update the baseline results to the version using LLAMA-2. This should also be made more clear in the paper.\n    2. In most experiments, LUMOS is tuned with data from downstream tasks, while if I understand correctly other LLM baselines are tested under few-shot or in-context learning settings. If this is correct, it should be made more clear in the paper, and the comparison seem a little unfair.\n2. With the baseline systems mostly evaluated under few-shot, I feel it is important to understand the efficiency of LUMOS and how well it generalizes. It is great that the authors have the generalization on WebShop, but I feel more emphasis on this direction, with additional few-shot experiments would be much better.\n3. A modular design, in particular divide the agent into planning, grounding and execution has been studied in various previous works as well. This limits the novelty of the proposed method. Also there is some missing reference to relevant work, e.g., Saycan: Grounding Language in Robotic Affordances\n4. Many of the baseline results are directly taken from results reported in other papers. While I understand that running experiments with LLMs are costly, this causes some in-consistency in the baselines that are compared in different datasets. And the comparison might also get affected by the implementation details of different papers."
            },
            "questions": {
                "value": "1. Is it true that most other baseline LLM agents are applied under few-shot / in-context learning setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8483/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8483/Reviewer_9Mw2",
                    "ICLR.cc/2024/Conference/Submission8483/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8483/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824952059,
        "cdate": 1698824952059,
        "tmdate": 1700619951933,
        "mdate": 1700619951933,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wlgOVTGscr",
        "forum": "VmnWoLbzCS",
        "replyto": "VmnWoLbzCS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8483/Reviewer_UN8U"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8483/Reviewer_UN8U"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes LUMOS, Language agents with Unified formats, Modular design, and Open Source LLMs to solve complex tasks with planning, grounding, and execution modules fine-tuned from LLAMA-7B on high-quality annotations collected by leveraging LLMs to convert ground truth reasoning steps in existing benchmarks into a unified format. LUMOS achieves competitive performance with agents of larger size and outperforms GPT-4/3.5-based agents on complex QA and web agent tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The proposed modular framework is well-motivated.\n\n- The converted dataset can contribute to training better small open models for complex tasks.\n\n- The results show the proposed method is effective and promising for its generalizability on unseen tasks.\n\n- The paper is well-written and presented clearly."
            },
            "weaknesses": {
                "value": "- Why is LUMOS-O better than LUMOS-I on Math benchmarks?\n\n- Some discussion on the performance-efficiency tradeoff between LUMOS-O and LUMOS-I would provide further insights.\n\n- Figure 3 (a) in the Final planning module annotation \"**No**, I will keep planning. Subgoal 2: Query the living\nperiod of Jonathan Kaplan.\" Is that a typo?\n\n- Some related work on modular language agents framework for complex tasks\n  - _Cognitive Architectures for Language Agents_\n  - _Building Cooperative Embodied Agents Modularly with Large Language Models_"
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8483/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698825433196,
        "cdate": 1698825433196,
        "tmdate": 1699637058815,
        "mdate": 1699637058815,
        "license": "CC BY 4.0",
        "version": 2
    }
]