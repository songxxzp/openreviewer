[
    {
        "id": "HXo5dFuI66",
        "forum": "SqNi6Se1NT",
        "replyto": "SqNi6Se1NT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5548/Reviewer_n2mn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5548/Reviewer_n2mn"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of clustered federated learning. Inspired by a Bayesian modeling of clustered FL, the provides three clustering heuristics. The paper evaluates the proposed heuristics and shows that in practice they outperform  WeCFL, which is the state-of-the-art FL clustering method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed clustering heuristics exhibit superior performance compared to the current state-of-the-art WeCFL in federated learning.\n- The experimental results section is well-crafted, providing a thorough evaluation of the proposed methods.\n- BCFL distinguishes itself from other clustering federated learning methods by dynamically adjusting clusters, offering a unique approach that departs from hierarchical clustering strategies."
            },
            "weaknesses": {
                "value": "- The paper's overall clarity is compromised due to unnecessarily complex and at times undefined notation, making it challenging to follow.\n- The update mechanism for the parameters of the Bayesian model lacks explicit explanation, leaving a crucial aspect of the methodology unclear.\n- The comparison and discussion of related work are superficial, lacking a fundamental exploration of how the proposed method differs from other clustering approaches. \n- The claim that the paper provides a \"unified framework with a rigorous formulation\" and offers \"new theoretical insights and algorithms\" is disputed, as the paper fails to present any novel theoretical contributions.\n- Section 3 contains derivations that are deemed obvious, contributing minimally to the understanding of the proposed approach.\n- The content in Sections 3 and 4.1 communicates a message that, in my interpretation, appears rather straightforward. The outlined two-step iteration involves computing the \"optimal\" association $\\theta^{*}_{t}$ given cluster weights $\\Omega$ and updating cluster weights based on the current association rule. Furthermore, the solution presented in equation (16) suggests associating a client $j$ with a cluster $i$ that maximizes $\\log(D^j|w^i)$. While these concepts are essential, the simplicity of the presented message does not seem commensurate with the extensive coverage given to these sections (four pages). The detailed explanation does not justify the space allocated, and as such, Sections 3 and 4.1 may be perceived as overextended for the relatively straightforward content they provide. \n- In light of the preceding remark, it might be beneficial for the paper to discuss soft clustering approaches based on the EM algorithm.\n- The proposed methods lack theoretical guarantees, relying solely on heuristics without a solid theoretical foundation.\n- The success of the proposed method heavily depends on the higher computational cost of BCFL-MH, raising concerns about the practicality and efficiency of the cheaper variants (BCFL-G and BCFL-C). In fact,  BCFL-G and BCFL-C do not show a significant improvement over FedAvg and WeCFL; the improvement never exceeds $1$ p.p., and is often lower then $0.1$ p.p.   \n- Several minor issues, including inconsistent citation style, grammatical errors, and unclear notation choices, need attention for a more polished presentation: \n     - The paper seems to use the wrong citation style. It refers to the authors when it should refer to the paper. For example, the sentence \"FL allows collaborative model training without data sharing across clients, thus preserving their privacy McMahan et al. (2017)\" should be \"FL allows collaborative model training without data sharing across clients, thus preserving their privacy (McMahan et al., 2017). \"\n    - In Section 1, \"the is a lack\" -> \"there is a lack\". \n    - What is the reason behind using $\\mathbb{P}$ instead of $P$ in page 3?\n    -In Page 4, \"to denote the a particular\" -> \"to denote a particular\".\n     - In Page 7, \"both feature- and label- skew\" -> \"both feature---and label---skew\""
            },
            "questions": {
                "value": "- My understanding of the paper is that each iteration is split into two steps: compute the \"optimal\" association $\\theta^{*}_{t}$ given the weights of the clusters $\\Omega$, then, update the cluster weights given the current association rule. Could you please confirm or deny my interpretation?\n- Regarding (13), it seems for me that the optimal solution would pick $A^{i j} = 1$, for $i \\in \\text{arg}\\min_{i} L^{i, j}$. It translates in (16), to  associating the client $j$ to the cluster $i$ that justifies the best its data, i.e. the cluster $i$ such that $log(D^j|w^i)$ is maximal. Could you please confirm or deny my claim?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5548/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698859821850,
        "cdate": 1698859821850,
        "tmdate": 1699636569929,
        "mdate": 1699636569929,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dsoVaNZ8kf",
        "forum": "SqNi6Se1NT",
        "replyto": "SqNi6Se1NT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5548/Reviewer_Yz5m"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5548/Reviewer_Yz5m"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a clustered FL method based on a bayesian framework which assigns clients to clusters, and provides three different variations of the proposed bayesian clustered FL framework to address practical considerations, namely approximate BCFL, greedy BCFL, and consensus BCFL. Specifically, for $K$ clusters and $C$ clients, BCFL assigns each client to its optimal cluster based on a target posterior characterization. The work performs preliminary experiments to validate the BCFL's performance on CIFAR10 and FMNIST."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The work proposes many different variants of BCFL that considers practicality.\n- The work investigates clustering in FL dependent on the different data distributions of the clients which is a relevant topic in FL where data heterogeneity can be particularly severe. \n- The work includes details of their experimental results including graphs that show the relationship across clients and their relatedness with the results."
            },
            "weaknesses": {
                "value": "- A major concern I have is regarding the efficacy and practicality of the proposed framework. Although the authors have proposed the three variants of the proposed BCFL framework, they still require the downloading of the models and weights under past associations, and then again uploading the associations of the weights to get the association decisions again from the server. Then finally the clients upload the local models based on the conditional associations. This requires at least 2 times the communication rounds compared to the conventional FL framework as well as more computation imposed to the clients. I became more skeptical after looking at the experimental results which only include 10 clients in total or 8 clients in total for more cross-device like datasets such as digits-dive or amazon review. Another concern regarding this approach of BCFL is the sensitivity of the number of clusters $K$ to the performance. It will be difficult to know this value in advance in practice. How does the authors address this problem as well? Overall due to these issues I am skeptical of the efficacy and practicality of the proposed framework for realistic FL settings. \n\n- Another concern I had regarding the practical variant approximate BCFL, the authors assume that there is no overlap in the distribution across different client partitions. This is quite a strong assumption which does not hold in most of the cases in FL. Can the authors comment on this assumption and how realistic it is?\n\n- The writing of the paper can be improved. for instance in pg1 when the authors address problem 1 and problem 2 in bold, there seems to be a typo/error. Ex: Problems2: The is a lack of a united theory. Moreover, optimality is used throughout the paper from the beginning without a proper explanation on what the authors exactly mean by this. It can mean differently for different readers. In addition, the presentation of Figure 3 can be improved, It is quite hard to see the differences across the curves.\n\nDue to these concerns, I am leaning towards rejection for the work."
            },
            "questions": {
                "value": "See weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5548/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699214604991,
        "cdate": 1699214604991,
        "tmdate": 1699636569847,
        "mdate": 1699636569847,
        "license": "CC BY 4.0",
        "version": 2
    }
]