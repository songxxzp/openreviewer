[
    {
        "id": "8zycPyL01T",
        "forum": "Pc8AU1aF5e",
        "replyto": "Pc8AU1aF5e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1312/Reviewer_bu8M"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1312/Reviewer_bu8M"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of data driven computer control using large language models (LLM's). It adds three components to improve capabilities of current approaches. It abstracts from the state of the environment by parsing it via an LLM such that only information necessary for the task is kept. It conditions on complete trajectories of similar tasks. It keeps a memory from which similar example trajectories are sampled.  The method is compared against strong baselines on two current benchmarks in the field of data-driven computer control. It shows improved task success rate on both, while often needing less data. Ablations on each component of the method show that the state abstraction procedure is the main reason for the improved performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The method is mostly explained well and it is easy to follow the explanation. Experiments and results are presented well.\n\nImproved task success rate on two benchmarks in the field of data driven computer control.\n\nCompetitive baselines from a variety of recent approaches in the domain of data driven computer control.\n\nAblations investigate the effect of each component of the method. \n\nThe state abstraction approach allows the method to be tested on tasks that were infeasible for prior methods."
            },
            "weaknesses": {
                "value": "- From the results in the MindAct task it seems that adding any trajectories helps but it does not matter which ones.\n\n- Have you studied the effect on performance on the MiniWob++ environment for different amount of tasks in the memory. The comparison to RCI does not seem fair at the moment (Figure 3)?\n\n- It would be helpful to have an illustrating example of the result of the state abstraction procedure (i.e. a figure of a (state,observation)-pair) as well as an example prompt (maybe in the Appendix). Figure 1 only shows that some <body> and <h1> tag got removed but it's not yet clear to me what the result of the state abstraction procedure looks like. Its also not clear to me where the examples from the state abstraction prompt come from. Are they designed a-priori? If yes how and how difficult is that? Are the same examples reused for all states or also taken from the memory?\n\n- The text states (last paragraph of 4.3) that failed trajectories are displayed in Appendix C, but Appendix C only refers to the supplementary material?\n\n- In the original paper of MindAct, they used 3 in-context exemplars for GPT3.5  but Synapse uses 5, so the comparison favours Synapse. In general I would maybe add a sentence that clarifies that results are SOTA, conditioned on the fact that GPT3.5 was used as the underlying LLM."
            },
            "questions": {
                "value": "- Have you considered building up the memory from scratch by adding successful trajectories over the course of training?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1312/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1312/Reviewer_bu8M",
                    "ICLR.cc/2024/Conference/Submission1312/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1312/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698757450200,
        "cdate": 1698757450200,
        "tmdate": 1700472230391,
        "mdate": 1700472230391,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ElJSw0BJhH",
        "forum": "Pc8AU1aF5e",
        "replyto": "Pc8AU1aF5e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1312/Reviewer_mGYB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1312/Reviewer_mGYB"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new technique to prompt language models with example trajectories for computer control tasks. It utilizes language models to abstract clean states for long-context conditioning, and design a retrieval module to improve generalization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The writing and presentation is clear in general\n2. The proposed method surpassed baselines like CC-Net, RCI on various benchmark like MiniWoB++ and Mind2Web"
            },
            "weaknesses": {
                "value": "1. Some details are not well explained, see questions."
            },
            "questions": {
                "value": "1. SYNAPSE uses state abstraction to make sure LLM can learn from compact information while ensuring the context length is well utilized. However, in the experiments, SYNAPSE sets k=5 for retrieval. How does the performance change if k grows? And why longer context is not helping here?\n\n2. Table 1 seems confusing. It's non-standard to use \"SYNAPSE w/ state abstraction, SYNAPSE w/ trajectory-as-exemplar, SYNAPSE w/ training set as memory\" to indicate gradually adding \"state abstraction, trajectory-as-exemplar, training set as memory\" 3 components. If you want to demonstrate a component *A* is useful, better to write it in \"SYNAPSE w/o *A*\", as SYNAPSE is a method that combines all components\n\n3. For Table 1 training set as memory experiments, do you add all the training data for 3 scenarios (\"cross-task, cross-web, and cross-domain)? Or only the corresponding training data (e.g. cross-task but same web when evaluated on cross-task setting).\n\n4. For tasks that need code to abstract state information, how can you examine if a code can successfully extract desired information? if examined from task success, it can be because of the suboptimal execution of policy.\n\n5. For the cross-domain tasks, retrieval doesn't seem to help, can you give a better explanation about this result? The retrieval number is set to 5, which is a small number. Is it because the retriever doesn't return the desired examples? Maybe showing some retrieved examples can be more intuitive.\n\n6. \"The action generation starts from prompting LLMs with successful trajectories to warm up LLMs\nwith the dynamics of the current environment\". Is it describing prompting with retrieved trajectories? Or that's some other warmup procedure? If it's cross-task/cross-web/cross-domain setting, how's current environment defined?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1312/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699373153321,
        "cdate": 1699373153321,
        "tmdate": 1699636058594,
        "mdate": 1699636058594,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NM6dRxDVIt",
        "forum": "Pc8AU1aF5e",
        "replyto": "Pc8AU1aF5e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1312/Reviewer_z7sh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1312/Reviewer_z7sh"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a prompting-based method (SYNAPSE) for computer control that takes in states and outputs actions in a discrete, human-computer-interaction-like action space. The paper is motivated by gaps in existing computer control methods: in-context learning, which struggles with long-horizon tasks and generalization and often needs post-hoc correction; and trained/fine-tuned methods, which are data- and compute-inefficient.\n\nSYNAPSE consists of three components: a state abstraction procedure in which an LLM is used to extract important information from the raw state, thereby significantly reducing token length; \"trajectories as exemplars\" (TaE) prompting, in which full, relevant trajectories (sequences of clean states and actions) are added to the prompt for generating each new action; and exemplar memory in which trajectories and their associated tasks are encoded and stored, to be used as exemplar trajectories when a related task is being planned. \n\nExperiments are conducted on MiniWoB++ and Mind2Web. The MiniWoB++ experiments show SYNAPSE's major data efficiency (and moderate performance) gains over BC+RL and finetuning baselines, as well as performance and simplicity gains over ICL baselines. The Mind2Web experiments demonstrate the same, along with its generalization capability across tasks, websites, and domains. SYNAPSE beats SOTA on various tasks from MiniWoB++, including notably difficult ones for which human-level performance is not achieved by prior work."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "#### Quality\n- Method is intuitive and effective\n- Experimental setup is useful. It is useful to have one standard benchmark with extensive comparison to baselines and one realistic benchmark on which more qualitative advantages like generalization are shown. \n- Results are promising - the similarity to human performance on MiniWoB++ and the significant increases on generalization show the power of SYNAPSE's TaE and exemplar memory components. \n- Ablations are useful as well to concretely break down each component of the approach. \n- Overall a well-constructed, well-executed paper. \n\n#### Clarity\n- Very well written!\n- Figures are especially useful compared to a lot of papers. Tables as well. Overall, results are not only promising but well-communicated. \n\n#### Originality\nThe paper positions itself well in prior work. As far as I am aware, the specific three components used here have not been combined elsewhere. \n\n#### Significance\nThe performance on existing computer control benchmarks is impressive, especially when comparing to human baselines. Figure 4 particularly tells a story of a significant improvement in capability. The results on MiniWoB++ show only some improvement, so it's unclear how significantly SYNAPSE distinguishes itself, but the results on Mind2Web show a lot of improvement margin."
            },
            "weaknesses": {
                "value": "#### Quality\n- The same ideas (gaps in prior work, the three components and their descriptions, the benchmarks being used) are repeated several times throughout the paper. While I very much agree that some amount of repetition is crucial to get a reader to understand what you are saying, in this case it's not just two or three times but four or five, or even if it's three, there's lots of detail every time. It feels as though the repetition is there to fill up space, even if that's not really the case. It gets tiring to read the same high-level concepts over and over. \n\n#### Clarity\n- I don't quite understand what \"step success rate\" is as opposed to \"success rate\" - it's brought up several times as the metric for Mind2Act, but not defined as far as I'm aware.\n- It doesn't seem to be made clear what exactly the state abstraction entails. In figure 1, the only difference between \"raw state\" and \"clean state\" is `<body><h1>\u2026</h1></body>\u201d --> <input id=\u201dwhere\u201d type=\u201dtext\u201d>`. There aren't clear examples in the main text, but intuition about this would be very useful. \n- Not clear how SYNAPSE's history-in-prompt approach is significantly different from Mind2Act's (or lots of other works') to the point of being novel. \n- From both Fig 1 and the text, it's unclear when new trajectory exemplars and example state abstractions are generated - is it per task (that's what I'd think) or per step? \n- Fig 3: might help to have clearer visual distinction of SYNAPSE and the human baseline, especially since the colors aren't always visible. Lines/shading/callout boxes could help. \n\n#### Originality\nThough the approach is technically unique and clearly effective, there are some originality concerns in terms of what the paper claims. For example, the paper positions itself against works like Inner Monologues and SayCan by saying that they focus on high-level planning; however, though RCI uses *even higher* level planning, SYNAPSE is still working with a discrete, abstract action space. Meanwhile, the low-level BC/RL/motion planning+control used for the robotics papers cited are operating in a much more granular, potentially continuous, action space. For another example, the paper spends considerable space discussing how it is unique compared to other prompting-based methods in helping the LLM understand the current state. However, MindAct gives trajectory-so-far back to the LLM when prompting for the next step. SYNAPSE gives observation as well, thereby informing the LLM in more detail about the current state, this just isn't a very original idea. It's an important step past MindAct, but not a big one, especially relative to how much it's discussed as a unique contribution. \n\n\nNits:\n- Page 5, last paragraph: `Obseravtion` is a misspelling"
            },
            "questions": {
                "value": "- What exactly is step success rate vs. success rate?\n- It is inherently interesting that this approach does not need self-correction unlike other prompting-based approaches, but does that offer any significant performance/efficiency gain?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1312/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699431015141,
        "cdate": 1699431015141,
        "tmdate": 1699636058517,
        "mdate": 1699636058517,
        "license": "CC BY 4.0",
        "version": 2
    }
]