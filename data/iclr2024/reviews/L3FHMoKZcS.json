[
    {
        "id": "t0t8a8Wu4O",
        "forum": "L3FHMoKZcS",
        "replyto": "L3FHMoKZcS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5226/Reviewer_tiQs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5226/Reviewer_tiQs"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a study on calibration methods for in-context learning. The authors provide a unified and systematic analysis of existing calibration, focusing on their decision boundaries. They also investigate the common use of content-free tokens in calibration. The paper highlights the biases in language models\u2019 predictions and proposes Batch Calibration (BC) as a zero-shot and inference-only calibration method. BC aims to accurately model the contextual bias in prompt contexts by marginalizing the language model scores. The authors extend BC to black-box few-shot learning by introducing a learnable parameter to adapt to available labeled data. The performance of BC is evaluated and compared to baseline methods, showing improved performance in various tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper is technically sound and well-written (although some writing issues are listed in weaknesses). The authors' revisiting of previous methods is novel to the research community."
            },
            "weaknesses": {
                "value": "- For writing:\n    - \"Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning\" has been accepted by EMNLP-2023. Please cite it correctly. \n    - Why is the related work in section 5? Introducing it in section 2 will make readers understand the background better.\n    - Unify the usage of abbreviated words. Tab. -> Table.\n\n- When introducing BCL, the author takes some examples to make readers understand the $\\gamma$. I suggest authors provide more experiments on how different $\\gamma$s affect the results. \n\n- As shown in Figure 3, the improvement from BC to BCL seems marginal. \n\n- Any border impact and limitation discussion?"
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5226/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697876176998,
        "cdate": 1697876176998,
        "tmdate": 1699636520941,
        "mdate": 1699636520941,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lZPUTAOG65",
        "forum": "L3FHMoKZcS",
        "replyto": "L3FHMoKZcS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5226/Reviewer_jGRr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5226/Reviewer_jGRr"
        ],
        "content": {
            "summary": {
                "value": "This paper studies model calibration in the context of LLMs (large language models). The authors first analysed the recently proposed methods with empirical results, and they also discussed the two important design principles behind those ICL calibration methods. A novel calibration method (which is termed batch calibration) is then introduced for zero-shot learning; an extended version that has a hyperparameter is proposed for fine-tuning. The authors conducted extensive experiments on multiple NLP tasks and showed superior performance as compared to the existing ICL calibration methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper addresses an important and interesting topic: calibrating LLMs in zero or few shot settings.\n\n2. The paper gives an overview of the most relevant and recent ICL calibration methods and discusses their motivations and design principles with empirical results.\u00a0\n\n3. The experiments are extensive, and the proposed method achieves better performance on most tasks."
            },
            "weaknesses": {
                "value": "1. My main concern goes to the $\\textit{strength}$ parameter in BCL; the current results show $\\gamma = 1$ seems to give strong performance (though not optimal) across tasks on CB and SST-2. Does this generalize to other tasks as well? It would be good to provide the optimal $\\gamma$ for each task; maybe include it in Table 2? Besides, would it be more reasonable to sample \\gamma in [0, 5]?\n\n2. There are some statements that are not well presented or supported. In Sec. 4.3, the authors claimed BC retains the performance even when using emoji pairs as verbalizers. Is there an example or result related to this specific experiment?"
            },
            "questions": {
                "value": "1. In e.q.(3), how to obtain the contextual prior $\\hat{\\mathbf{p}}$? \n2. How would BC work on the task other than classification? \n3. It seems the calibration perform is not stable across different model architectures in 1-shot setting on some tasks. E.g., MNLI, 75.12/         60.02/81.34 for PaLM-2-S/PaLM-2-M/PaLM-2-L. I understand that PaLM-2-S/L are based on 5 runs and PaLM-2-M result is from a single run. Could you help to understand, what causes the high perform variance, I may miss something here."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5226/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5226/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5226/Reviewer_jGRr"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5226/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698656878894,
        "cdate": 1698656878894,
        "tmdate": 1699636520813,
        "mdate": 1699636520813,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lHHu7akuQb",
        "forum": "L3FHMoKZcS",
        "replyto": "L3FHMoKZcS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5226/Reviewer_99FV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5226/Reviewer_99FV"
        ],
        "content": {
            "summary": {
                "value": "The paper delves into the current challenges faced in adapting Large Language Models (LLMs) to new tasks through the method of human-designed instructions. Although these models possess a commendable ability for in-context learning (ICL) and can efficiently adapt from few-shot input-label pairs, they are significantly influenced by the choice of templates, verbalizers, and demonstrations. This results in biases that can act as barriers to creating adaptable and robust LLM applications. While several studies have tried to address these biases, a holistic analysis differentiating the merits and demerits of each approach is lacking."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper provides a thorough and systematic examination of existing calibration methods for LLMs, filling a gap in the existing research landscape. Methodologically, the introduction of Batch Calibration (BC) offers a zero-shot, inference-only calibration method that is computationally efficient, addressing a primary concern in the domain. BC proves effective in reducing prompt sensitivity, a prominent issue in LLMs, thereby facilitating easier prompt engineering.\n\nThe scope is also broadened compared to previous works like CB, which only studies GPT-2's biases."
            },
            "weaknesses": {
                "value": "While BC introduces minimal computational overhead, in highly resource-constrained environments, even small overheads might be significant.\n\nThe term calibration can be confusing, maybe using bias is better. At least should add a footnote to the Introduction. Another widely used notion of calibration is from the perspective of uncertainty, explainability, and reliability. \n\nPlease include model sizes and details in the paper, as the performance of ICL and prompting is quite irreproducible and context-dependent.\n\nPlease adjust the margins of subfigures in fig. 2, it's overlapped. \n\nThe liteature review of Test time tuning is a bit unnecessary as ICL itself is not a tuning method"
            },
            "questions": {
                "value": "In fig.5, why does a strength greater than 1 consistently decrease accuracy?\n\nHow significant is the bias/miscalibration of the ICL performance? that say is the problem still relevant for models with greater scales? \nShould consider 65B llama2, GPT-3.5, GPT-4 etc as the method does not require tuning"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5226/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698895997416,
        "cdate": 1698895997416,
        "tmdate": 1699636520623,
        "mdate": 1699636520623,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "f3SoPXAs9a",
        "forum": "L3FHMoKZcS",
        "replyto": "L3FHMoKZcS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5226/Reviewer_r8cW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5226/Reviewer_r8cW"
        ],
        "content": {
            "summary": {
                "value": "This paper discusses the issue of bias and unexpected performance degradation in large language models (LLMs) when using prompting and in-context learning (ICL). To address this, the authors first provide a comprehensive analysis of existing calibration methods and their decision boundaries, and then propose a new calibration method called Batch Calibration (BC) with linear decision boundaries, which mitigates the bias from the batched input and is both zero-shot and inference-only. BC can be easily extended to learn the bias from labeled data, and applied to calibrate vision-language models. The authors conduct extensive experiments on over 10 natural language understanding and image classification tasks and show that BC achieves state-of-the-art results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed Batch Calibration method is simple and empirically effective.\n2. Extensive experiments are conducted."
            },
            "weaknesses": {
                "value": "1. The proposed method is not thoroughly justified.\n2. The writings could be improved in terms of the analysis of existing methods and the proposed method."
            },
            "questions": {
                "value": "1. The authors argued that linear decision boundaries produced by calibration methods can be more robust and generalizable across tasks. This argument is not well supported theoretically and empirically. \n2. The advantage of Batch Calibration over existing methods is not thoroughly justified. Could you provide more intuitive descriptions and theoretical analysis for it?\n3. The derivations of Table 1 could be provided in more details in the main contents or supplementary. Currently, it is not easy to understand."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5226/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5226/Reviewer_r8cW",
                    "ICLR.cc/2024/Conference/Submission5226/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5226/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699361846410,
        "cdate": 1699361846410,
        "tmdate": 1700549503779,
        "mdate": 1700549503779,
        "license": "CC BY 4.0",
        "version": 2
    }
]