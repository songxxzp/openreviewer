[
    {
        "id": "TLTZw4opNj",
        "forum": "uWVC5FVidc",
        "replyto": "uWVC5FVidc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_MH5n"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_MH5n"
        ],
        "content": {
            "summary": {
                "value": "The paper explores the use of unbiased watermarks for large language models (LLMs) to track and attribute model outputs without compromising output quality. The authors introduce an innovative family of watermark methods that guarantee non-degradation of text quality and offer a comprehensive framework for designing and detecting unbiased watermarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Improved accountability: Unbiased watermarks can help track and attribute model outputs to specific providers, which can improve accountability and transparency in the use of LLMs. This can be particularly important in applications such as automated content generation, where it may be difficult to determine the source of generated content.\n\n2. Maintaining output quality: Previous studies have suggested that watermarking can compromise the quality of model-generated outputs. However, the use of unbiased watermarks can maintain output quality while still providing a means of tracking and attribution.\n\n3. Protection against misuse: The use of unbiased watermarks can help protect against the potential misuse of LLMs, such as the generation of fake news or other malicious content. This can help ensure that LLMs are used responsibly and ethically.\n\n4. Flexibility: The authors offer a comprehensive framework for designing and detecting unbiased watermarks, which can provide flexibility in the implementation of watermarking for different applications and use cases. This can help ensure that unbiased watermarks are tailored to specific needs and requirements.\n\n5. Generality: The authors propose a mathematically well-defined framework for watermark trade-off."
            },
            "weaknesses": {
                "value": "1. Potential limitations: The paper does not address the potential limitations or challenges of implementing unbiased watermarks in practice. It is possible that there may be technical or logistical challenges that could make it difficult to implement unbiased watermarks effectively.\n\n2. Complexity: The implementation of unbiased watermarks may require significant technical expertise and resources, which could be a barrier to adoption for some providers. Additionally, the complexity of the watermarking process could potentially impact the performance of LLMs or other downstream tasks."
            },
            "questions": {
                "value": "How do you envision the implementation of unbiased watermarks in practice, and what challenges do you anticipate?\n\nHow do you plan to address concerns (in practice) regarding the potential manipulation or removal of watermarks by users?\n\nCan you elaborate the key factors when chasing the optimal trade-off between mentioned in the paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5485/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5485/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5485/Reviewer_MH5n"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698695064723,
        "cdate": 1698695064723,
        "tmdate": 1699636560353,
        "mdate": 1699636560353,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LWJs2p2n6X",
        "forum": "uWVC5FVidc",
        "replyto": "uWVC5FVidc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_7gzS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_7gzS"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces the \"unbiased watermarks\" in large language models, challenging the prevalent belief that watermark strength negatively affects output quality. Two novel watermarking techniques, $\\delta$-reweight, and $\\gamma$-reweight, are proposed; they maintain output quality in machine translation and text summarization tasks. Through theoretical analysis, they proved two methods could guarantee the unbiasedness of the watermarked generation. Additionally, a new log-likelihood ratio test is presented for watermark detection, which has theoretical guarantees on type I errors."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The concept of an \"unbiased watermark\" is interesting and crucial for practical implementation in real-world scenarios.\n\n2. The paper introduces two novel methodologies that are not only straightforward (simple logit reweighting) , but also empirically effective, as demonstrated through experimental evaluation.\n\n3. The study proposes a novel maximin variant of the Log-Likelihood Ratio (LLR) score for hypothesis testing, exhibiting enhanced robustness compared to the  LLR score."
            },
            "weaknesses": {
                "value": "My major concern about this paper is the lack of comprehensive evaluations:\n1. The evaluations do not contain any attacks (the authors mentioned them in Appendix A2). I highly recommend the authors evaluate those attacks. If the proposed watermark methods suffer from a simple attack like paraphrasing, it would significantly undermine the paper's contributions. \n2. Larger models like LLAMA-2 should also be evaluated to further enhance the practicality."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5485/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5485/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5485/Reviewer_7gzS"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698766704398,
        "cdate": 1698766704398,
        "tmdate": 1700501951027,
        "mdate": 1700501951027,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ENb2m5XXkG",
        "forum": "uWVC5FVidc",
        "replyto": "uWVC5FVidc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_usqd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_usqd"
        ],
        "content": {
            "summary": {
                "value": "The paper studied watermarking LLM with two goals: a) is efficiently detectable by the service provider; b) can\u2019t be detected by users and does not negatively impact the quality of the output. The experiments are comprehensive that they also explore that output quality can be well preserved in downstream tasks, such as machine translation and text summarization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The proposed two reweighing algorithms are backed by solid mathematical foundations. \nThe experiments are quite comprehensive, and I enjoyed reading about them. \nThe emphasis on unbiasedness and downstream tasks adds significant value to the paper."
            },
            "weaknesses": {
                "value": "As someone who is not very familiar with this topic, I find the paper to be well-organized, solid, and supported by comprehensive experiments. I do not see any obvious weaknesses in the paper from my perspective."
            },
            "questions": {
                "value": "I am confused by the `NW' output in Table 3. It appears to be quite unreadable, especially when compared to the outputs with watermarking strategies. Is this because the OPT-6.7B model is not fine-tuned for the NW cases? I am concerned about whether this comparison is fair enough."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698857803306,
        "cdate": 1698857803306,
        "tmdate": 1699636560158,
        "mdate": 1699636560158,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5gaUqnitwc",
        "forum": "uWVC5FVidc",
        "replyto": "uWVC5FVidc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_ZzM6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_ZzM6"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a unbiased watermarking method for LLM generated text, aiming at addressing the problem of attribution the model outputs without compromising the output quality. Specifically, two distribution re-weighting strategies are proposed to satisfy the unbiased property, and the corresponding score-based hypothesis testings are proposed. Furthermore, the authors evaluate the effectiveness of the proposed method on summarization and translation tasks."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The authors propsoe two unbiased reweighting methods and the theoretical proofs are given. \n\n2. The authors propose a novel maximin variant of LLR score, which is more robust than previous LLR score\n\n3. The authors conduct the experiment on machine translation and text summarization tasks, showing the quality of the generated text."
            },
            "weaknesses": {
                "value": "1. The tasks included in the experiment are only summarization and translation, and more tasks, such as general natural language generation, are required to demonstrate the effectiveness of the proposed method.\n\n\n2. It seems that the robustness towards the exiting watermarking attacks are not verified in the paper. It seems that only in Appendix F.5, the authors evaluate the robustness under random perturbation. More attacks mentioned in Appendix A.2 are expected. \n\n\n3. Minor: Since the highlight of the proposed method is the unbiased property, in my opinion, the theorems 14 should be in the main body instead of the appendix."
            },
            "questions": {
                "value": "See weakness 1 & 2."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699082298647,
        "cdate": 1699082298647,
        "tmdate": 1699636560069,
        "mdate": 1699636560069,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RYaWBXsZQk",
        "forum": "uWVC5FVidc",
        "replyto": "uWVC5FVidc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_tWzc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5485/Reviewer_tWzc"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes two new algorithms for watermarking the outputs from language models, one based on gamma-reweight and other based on a delta-reweight. The algorithms are sound and non-distortionary, and can be used to watermark LLMs without provably reducing their utility. The authors present minimal experimental evidence illustrating the detectability of the watermarks on translation and summarization tasks, and further some quality measurements to demonstrate the quality of the LLM on the task remains unaffected from watermarking. \n\nThe \"signature\" being watermarked is based on the previously seen context, and they store all contexts so you do not watermark when you encounter the same context again. This is key to preserving the non-distortionary nature of the watermarks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strengths:\n1. The formulation of the LLR approach is very interesting, and is novel to the best of my knowledge. It deviates from z-score based tests used in prior work, and seems promising (with certain caveats, see weaknesses).\n2. While the gamma scheme overlap with the schemes presented in Kuditipudi et al. (I recognize the distinction between hashing and the sequence of keys protocols, there are strong similarities in the way the signature is encoded however), I acknowledge that it is concurrent work and has not been published yet at a peer reviewed venue. Hence, I would regard this as a novel contribution, and both the schemes are interesting and sound watermarking schemes.\n3. This is an important and timely topic, and the algorithms presented are non-distortionary, and are a step forward in watermarks that can be adopted in the real-world without reducing the utility of the LLMs."
            },
            "weaknesses": {
                "value": "Cons:\n1. The experiments are somewhat on the weaker side. I do not know how these schemes compare in relation to the UMD scheme in terms of detectability, or perform more generally (even if we disregard the UMD scheme since it is non-distortionary). Table 1 compares the two schemes in terms of quality of the outputs, but there is a lack of discussion of the watermarking performance more generally. Table 2 presents the evidence at a token level, but it would be much more interesting to give our some sort of a global metric, such as the AUC (or AUC-PR) in detecting watermarked vs unwatermarked text.\n\n2. While the LLR scheme is novel and interesting, it is not clear how robust the maximin LLR scheme is to different scenarios. Meaningful ablation experiments are missing.\n\n3. The authors proposed storing a log of all the responses so far. At some point, you will exhaust all the possible n-grams, and you will not be watermarking any more, and the watermark will get weaker and weaker over time. This seems like a practical limitation."
            },
            "questions": {
                "value": "1. How does the watermarking scheme perform on context completion and instruction following tasks? Is it possible to present some empirical evidence on how many tokens are needed to achieve a certain level of detectability on open source LLMs?\n\n2. What happens if you do not have access to the original LLM? (e.g., if you watermarked with ChatGPT but ran verification with Llama-1b, the shift in distributions would be quite large). Would the maximin LLR scheme outperform a z-score based statistical test?\n\nEven for the same model, if you have edits (e.g., you don't have access to the prompt, or if someone has shuffled the sentences in the text), does the maximin LLR scheme work?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5485/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699124472662,
        "cdate": 1699124472662,
        "tmdate": 1699636559963,
        "mdate": 1699636559963,
        "license": "CC BY 4.0",
        "version": 2
    }
]