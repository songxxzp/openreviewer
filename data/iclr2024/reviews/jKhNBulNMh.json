[
    {
        "id": "ExpSiXmB9r",
        "forum": "jKhNBulNMh",
        "replyto": "jKhNBulNMh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5144/Reviewer_hTDx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5144/Reviewer_hTDx"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces Symb4CO, the first symbolic discovery framework, to learn high-performance symbolic policies on the branching task in CO solvers. Symb4CO's CPU-based strategies match the performance of top GPU-based methods. With efficient training, quick inference, and clear interpretability, Symb4CO offers a promising way to integrate machine learning into modern CO solvers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The problem the paper is trying to address is important. Indeed, we should have a light-weight machine learning approach to facilitate CO solvers. The directions that the author tries to improve, including requiring less training data and producing interpretable policies, are reasonable to me. \n2. The authors of Symb4CO apply reinforcement learning to make training efficient with much less data needed."
            },
            "weaknesses": {
                "value": "1. Symb4CO, although data efficient during the training, requires feature extraction by human. I have concerns about if the extracted features are expressive enough, and how much efforts does it take for these feature extractions. Does it really the so-called training efficient?\n2. From the experimental results, I can observe that GPU based GNN approach can make CO solvers perform faster than CPU based Symb4CO. The overall goal is to facilitate CO solvers in efficiency, if GPU based approach can facilitate it more, than why not prefer GPU based approach? Besides, today\u2019s machine can make very fast GPU-CPU interactions. I think we should be open to bringing in machine learning models inside CO solvers (not just adding the learned interpretable policies inside CO solvers) and making use of GPU\u2019s high computation to facilitate logical reasoning tools."
            },
            "questions": {
                "value": "Please refer to the questions in the weakness section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5144/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5144/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5144/Reviewer_hTDx"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5144/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698628000835,
        "cdate": 1698628000835,
        "tmdate": 1699636508207,
        "mdate": 1699636508207,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CocO36fJkU",
        "forum": "jKhNBulNMh",
        "replyto": "jKhNBulNMh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5144/Reviewer_dfwS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5144/Reviewer_dfwS"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces an approach that combines the advantages of using machine learning (ML) and human-designed policies in solving combinatorial optimization (CO) problems. Symb4CO leverages deep symbolic optimization to learn interpretable symbolic expressions, transforming complex ML models into compact and efficient decision-making policies. The key strengths of Symb4CO lie in its efficiency, both in terms of training and inference, making it suitable for practical deployment on CPU-based devices. The paper shows that Symb4CO outperforms existing ML-based and human-designed policies. \n\nNovelty:\nThe paper introduces the concept of using deep symbolic optimization for solving CO problems, specifically focusing on the branching task. This is a novel approach that combines symbolic representations with optimization tasks, making it distinct from traditional machine learning techniques applied to CO problems.It is designed to be highly efficient, particularly in terms of training and inference, and the learned symbolic policies are interpretable. The paper highlights the importance of these features for practical deployment in real-world applications. Symb4CO's ability to perform well on purely CPU-based devices is quite practical. Most previous ML approaches for CO problems require GPU acceleration, but Symb4CO demonstrates that it can achieve comparable performance with CPU-based resources. The paper explores the concept of using compact symbolic policies for CO tasks. This is in contrast to complex machine learning models, which are often resource-intensive. Symb4CO's approach leads to concise, one-line mathematical expressions for decision-making.\n\nImpact:\nThe impact of this work is significant, especially within the field of combinatorial optimization and machine learning. Symb4CO's ability to achieve competitive performance on CPU-based devices with limited training data can make it accessible to a broader range of real-world applications. The emphasis on interpretability in Symb4CO's learned policies addresses a critical concern. Symb4CO's success on CPU-based devices reduces the need for GPU resources. \n\nQuality of writing and experiments:\nThe quality of writing in the paper needs improvement. Here are some detailed comments:\n- Section 4.3 talks about the fitness function, which is a crucial part of the training pipeline. So, it would be helpful to expand on the explanation of Equation 2. \n- Since the authors use an FSB-based fitness function, why does the FSB model perform so poorly (Table 1) compared to their tool?\n- Table 2 mentions the use of one training instance. How was this training instance chosen? How do the results vary if a different training instance was chosen? Providing a standard deviation in Table 2 would be helpful. Similarly, how were the ten instances chosen (Section 5.1)?\n- Authors mention discovering more complex working flows like RPB can be an interesting future work. Since RPB is compared against in Table 1, why do the authors think RPB performs so poorly compared to Symb4CO?\n- In Section 5, what is the reason for using 1-shifted geometric mean?\n- The interpretability claim in Section 5.2 needs some clarity. E.g., \"RPB ... uses a scoring function with human-designed features and expressions rather than vanilla pseudocosts.\" Why is this relevant to the interpretability claim?\n- How do the authors ensure the output expression from the RNN (Figure 2) is syntactically correct?\n- Providing a concrete example and comparing the results with some of the other tools might be helpful to improve clarity.\n- RNNs are usually not considered suitable for long-term sequences. How did the authors tackle that problem? How long are the output expressions from the RNN model?\n- Part 3 in Figure 2 is challenging to understand. The fitness measure can include concrete values to improve clarity. \n\nAblation studies explore the choice of mathematical operators and constants. Nevertheless, I believe it is important to address the following questions as well:\n- Section 4.2 briefly mentions applying constraints during the training process. How is the length constraint implemented? Do the authors allow only a fixed length? Was there any ablation performed for the use of this constraint?\n- Section 3.2 talks about 80% masking, but Section 4.1 mentions using all 91 features. How is the masking performed during training and evaluation across different benchmarks? Were any ablation studies performed on a different subset of features?\n- How sensitive is the approach to different hyperparameter choices for the sequential model?\n- Comment on the scalability of the approach. Do medium and hard problems have significantly larger search spaces? \n\nAdditional comments:\n- Out of curiosity, did the authors explore the extent to which the learned symbolic policies generalize across different problem domains within combinatorial optimization? For example, test the policies trained on one benchmark on a different but related benchmark to assess their transferability.\n- The paper discusses the efficiency and interpretability of Symb4CO. Can the authors provide insights into any trade-offs when prioritizing efficiency and simplicity over complex but potentially more accurate models?\n\nMinor nitpick - Expand FSB in Figure 2 as it has not been used till page 3\n\nReview summary:\nThe paper introduces Symb4CO, a novel approach for solving combinatorial optimization problems by combining machine learning and interpretable symbolic expressions. It leverages deep symbolic optimization to generate efficient and interpretable decision-making policies. Symb4CO is highly efficient for inference, making it suitable for CPU-based devices. The paper provides a comprehensive experimental evaluation, demonstrating its superiority over existing methods. The key strengths include its innovative use of deep symbolic optimization, efficiency, interpretability, and the potential for real-world applications. However, the paper could benefit from improved clarity, expanded related work discussion, and addressing potential limitations. The ablation studies exploring mathematical operators and constants are valuable, but additional questions and considerations should be addressed for a more comprehensive understanding."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Symb4CO is shown to be efficient, both in terms of training and inference, making it suitable for deployment in real-world scenarios on CPU-based devices.\n\n- The paper emphasizes the interpretability of Symb4CO's learned symbolic expressions.\n\n- The paper presents a thorough experimental evaluation, comparing Symb4CO with various baselines and showcasing its superior performance in terms of training efficiency, inference efficiency, and overall effectiveness."
            },
            "weaknesses": {
                "value": "- The paper could benefit from improved clarity and organization. I will expand more on this in the following few sections.\n\n- The discussion of related work is quite brief and could be expanded to provide a more comprehensive overview of existing approaches and how Symb4CO differentiates itself.\n\n- While the paper discusses the limitations of previous ML approaches, it needs to address the potential limitations of Symb4CO. A dedicated section on drawbacks or areas for future improvement would enhance the paper's completeness."
            },
            "questions": {
                "value": "- Out of curiosity, did the authors explore the extent to which the learned symbolic policies generalize across different problem domains within combinatorial optimization? For example, test the policies trained on one benchmark on a different but related benchmark to assess their transferability.\n- The paper discusses the efficiency and interpretability of Symb4CO. Can the authors provide insights into any trade-offs when prioritizing efficiency and simplicity over complex but potentially more accurate models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5144/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5144/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5144/Reviewer_dfwS"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5144/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816016836,
        "cdate": 1698816016836,
        "tmdate": 1699636508106,
        "mdate": 1699636508106,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "67nZdZlZ0z",
        "forum": "jKhNBulNMh",
        "replyto": "jKhNBulNMh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5144/Reviewer_z5TX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5144/Reviewer_z5TX"
        ],
        "content": {
            "summary": {
                "value": "This paper introduce a neural-symbolic approach to discover branching heuristics for MILP solving. Instead of directly using a neural network as the branching heuristics, they propose to use a neural network to predict a symbolic expression, which is more efficient to invoke online."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The idea of not directly using a neural network for branching prediction, but rather using it to produce a symbolic expression is quite interesting and plausible.\n- The paper shows a substantial performance gain over the other methods."
            },
            "weaknesses": {
                "value": "- The paper relies on manual feature extraction. This leaves open the question what are useful features, which is difficult to answer. Presumably the choice of the features are dependent on the particular benchmarks and can have significant impact on the performance. I get that the alternative deep representation makes the inference more expensive though.\n- It is unclear how the training instances are selected and how similar to the test/validation instances the training instances are."
            },
            "questions": {
                "value": "- In the experiments, are the proposed branching heuristics invoked at each node, or only the top node?\n- What is the cost of the training?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5144/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699257994941,
        "cdate": 1699257994941,
        "tmdate": 1699636507936,
        "mdate": 1699636507936,
        "license": "CC BY 4.0",
        "version": 2
    }
]