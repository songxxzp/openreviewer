[
    {
        "id": "K8tQcGCxjd",
        "forum": "UCfz492fM8",
        "replyto": "UCfz492fM8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6375/Reviewer_Xm7A"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6375/Reviewer_Xm7A"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes learning cross-morphology human motion-driven control to map from human motion to robot control signals in a guided unsupervised learning fashion. Without using any pre-collected dataset from the robot domain, this work proposes using a cycle-consistency reward based on translation from human motion to robot motion and then from robot motion to human motion to train such a control network. By formulating the problem as a skill-discovery problem, where the skill is specified through direct human motion input and the reward is based on the mutual information between the robot state and human motion (specified by the cycle-consistency reward), the method shows interesting results in translating human motion to semantically meaningful and natural robot motion."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper provides a convincing approach for automatic human motion to robot motion translation framework that does not rely on any predefined robot motion dataset. Since human motion is relatively accessible, using human motion to directly control robot motion and try to create semantically similar motion is an intuitive and useful approach.\n- I find the use of cycle consistency to translate between human motion and robot motion a well-principled approach for this task. As far as I know, this is a novel approach. The R2H-Mapper and H2R-Mapper provide a scalable approach for human motion-guided robot control.\n- The provided qualitative result shows that the method can translate human motion into relatively realistic human motion. In the handful of motion with semantic meaning (dancing motion), the robot generates similarly semantically meaningful motion.\n- Compared to prior methods that perform retargeting in the kinematic space (e.g. ACE [1]), this paper tackles the more challenging simulated control task. \n\n[1] Li, Tianyu et al. \u201cACE: Adversarial Correspondence Embedding for Cross Morphology Motion Retargeting from Human to Nonhuman Characters.\u201d ArXiv abs/2305.14792 (2023): n. pag."
            },
            "weaknesses": {
                "value": "- Missing evaluation on the R2H-Mapper and H2R-Mapper. As the main reward provider, it is important to visualize how well these learned networks can translate between the two different modalities of motion. Do certain correspondences emerge (e.g. robot forward foot mapping to hands)? Are there failure modes that the mapper didn't learn?\n    - I think the whole application section could be replaced with a more detailed analysis and results from the two mappers. If the method can really handle human motion, applying it to language control and interactive control could be explored to supplement or just provide video results. If applications are studied, I think the robustness of the method to different modes of human motion should be investigated: e.g. can the learned motion mapper handle unseen motion like breakdancing and cartwheeling?\n    - Since the mapping between poses $p^h$ and $p^r$ is done locally, I think showing the reconstructed result together with the ground truth root would be beneficial.\n- Though the qualitative results provide a number of motion sequences, most of them are locomotion sequences (walking and running) which I think a Task-only controller should solve relatively easily. The only semantically meaningful sequences are dancing, of which there are only a handful of examples. There is a glimpse of good semantic mapping, but it is not super conclusive. Instead of focusing on dancing, maybe simpler motions like raising hands, reaching for objects, and more complex hand movements could be more suitable for evaluating this system's capabilities. Similar to the previous point about evaluating the mappers, it's not clear how well each part of the human body is mapped.\n    - The results on Deepmimic show that an expert-designed mapping may not be plausible and not easy to learn. However, since there is no study on what kind of mapping CrossLoco learned, it is hard to see how CrossLoco is better. Does a good mapping exist between bipedal and quadruped robots? Is this task too ill-posed? Or have we just not found a good mapping yet?\n- Need to discuss the limitations of the current framework. On what human motion does the matching score the lowest? Which human motion can be best matched? What happens if more or fewer human motion sequences are used for learning the mapping?\n    - I think the entire application section could be replaced with a more detailed analysis and results from the two mappers. If the method can truly handle human motion, it could be applied to language control and interactive control, which could be supported by supplementary materials or video results. If applications are studied, I believe the robustness of the method to different modes of human motion should be examined. For example, can the learned motion mapper handle unseen motions such as breakdancing and cartwheeling?\n    - Since the mapping between poses $p^h$ and $p^r$ is done locally, I believe showing the reconstructed result together with the ground truth (GT) root would be beneficial."
            },
            "questions": {
                "value": "- I think providing results on the two Mappers, either a reconstruction metric or visualizations, could really help in understanding the capability of the framework. Does the algorithm learn some novel mapping?\n- Showing results on simple and semantically meaningful sequences, such as raising hands, moving hands, and hands and feet, could really demonstrate the capabilities of the method. Showing results on locomotion does not really add much value since root tracking reward already exists."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6375/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698617247869,
        "cdate": 1698617247869,
        "tmdate": 1699636705369,
        "mdate": 1699636705369,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "De1W7slhyY",
        "forum": "UCfz492fM8",
        "replyto": "UCfz492fM8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6375/Reviewer_QSkw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6375/Reviewer_QSkw"
        ],
        "content": {
            "summary": {
                "value": "This paper presents CrossLoco, an unsupervised reinforcement learning framework designed to translate human motions into robot controls, addressing the challenge of establishing correspondence between humans and quadrupeds. This framework introduces a cycle-consistency-based reward term and maximize mutual information between human motions and robot states. CrossLoco outperforms baseline algorithms demonstrating its effectiveness. Additionally, the framework shows use in applications like language2robot and interactive robot control."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The implementation of both R2H-Mapper and H2R-Mapper to reconstruct human and robot motion is a novel approach that ensures cycle consistency.\nThe inclusion of a supplementary video provides a more intuitive showcase of the qualitative results.\nThe authors conducted a user study to demonstrate the effectiveness of their motion retargeting control results.\nThe potential applications for language-driven motion control and interactive motion control for quadrupeds are promising. Scaling up to larger human more datasets to enable quadrupeds to perform more tasks could be very promising."
            },
            "weaknesses": {
                "value": "The baseline used for retargeting seems weak. Why not employ stronger learning-based retargeting baselines combined with motion imitation algorithms?\n\nThe definition of the root tracking reward is unclear, particularly the definition of $s_{root}$ and $\\bar s_{root}$. I assume $s_{root}$ refer to robot root states including global translation and orientation but what is $\\bar s_{root}$? The paper claims this reward minimizes deviation between the normalized base trajectory of human and robot, is  $\\bar s_{root}$ the root states of human? A clearer definition would be beneficial.\n\nThe evaluation metrics could be improved. For instance, introducing Frechet Inception Distance (FID), used in ACE, to measure human motions and robot motions. \n\nAdditionally, the use of the averaged correspondence reward is questionable; as the author mentioned, a human forward walking motion could be mapped into a robot\u2019s lateral movements. This metric may not accurately reflect correspondence between motions and seems more like a reflection of the training reward (loss) rather than a robust evaluation metric. A suggestion would be for the author to use paired data to train the two mappers independently and apply these mappers for testing all methods or directly use existing SOTA motion retargeting models.\n\nThere is only one sequence for qualitative comparison with the baselines, I encourage authors to provide more and include the reference motion for deepmimic (retargeting results)."
            },
            "questions": {
                "value": "It seems the authors didn't provide details about the human motion dataset, also lack RL training and supervised training hyperparameters. These details would be beneficial for researchers to follow."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6375/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6375/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6375/Reviewer_QSkw"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6375/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698813659879,
        "cdate": 1698813659879,
        "tmdate": 1699636705250,
        "mdate": 1699636705250,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6IsDuuZo0Q",
        "forum": "UCfz492fM8",
        "replyto": "UCfz492fM8",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6375/Reviewer_TXup"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6375/Reviewer_TXup"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes the CrossLoco framework, a guided unsupervised reinforcement learning framework that simultaneously learns robot skills and their correspondence to human motions. This is achieved thanks to the use of a \"cycle-consistency-based\" reward, inspired in generative vision system such as Cycle-GAN. The reward function has components related to the learning of a policy, components related to the human-robot correspondence problem, and terms to regulate the training and preserve the high-level semantics. The proposed framework is validated in the task of transferring a set of human motions to the Aliengo quadrupedal robot, and its performance compared against manually engineered and unsupervised base-line algorithms. CrossLoco obtains better results than the other algorithms in this comparison."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The main contribution of this paper is the CrossLoco framework which uses a \"cycle-consistency-based\" reward. The reward function has components related to the learning of a policy, components related to the human-robot correspondence, and additional rewards terms to regulate the training and preserve the high-level semantics.\n\n2. The proposed framework is correctly validated by using it for transferring a set of human motions to the Aliengo quadrupedal robot.\n\n3. The paper is clear, well-organized and well-written."
            },
            "weaknesses": {
                "value": "I do not see any clear weakness."
            },
            "questions": {
                "value": "No questions"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concerns"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6375/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699011310127,
        "cdate": 1699011310127,
        "tmdate": 1699636705140,
        "mdate": 1699636705140,
        "license": "CC BY 4.0",
        "version": 2
    }
]