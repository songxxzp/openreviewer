[
    {
        "id": "g7mwaDzZVt",
        "forum": "WLgbjzKJkk",
        "replyto": "WLgbjzKJkk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4477/Reviewer_gEi4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4477/Reviewer_gEi4"
        ],
        "content": {
            "summary": {
                "value": "This paper is about using Transformer to perform multi-object tracking task. Authors introduce \"coopetition alternative\" strategy to train Transformer's decoders, also a \"shadow set\" is proposed to maintain a set of queries when tracking each object. Experiments are conducted on DanceTrack, BDD100K, MOT17 to compare with prior works."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) This paper comes with a good motivation by first analyzing the drawbacks transformer based trackers, such as MOTR and MOTRv2, then try proposing some improvements based on that.\n\n2) The idea of using a set of queries to track each object, is interesting. \n\n3) Results on DanceTrack seems to be strong, e.g. it is comparable to MOTRv2 from Table 2(a) and it is better than a recent work MeMOTR, which is also based on Transformer."
            },
            "weaknesses": {
                "value": "1) The performance is not stable across different datasets. For instance, the tracker cannot even achieve comparable performance with existing trackers such as GTR/PA3Former/GRTU on MOT17, which is by far the most widely used and trusted benchmark within MOT community. While authors claim that MOT17 is rather a small dataset to train transformer-based trackers, other ways such as using synthetic dataset[a] could be one option. \n\n Also the proposed tracker performs worse than the major baseline MOTRv2, which is also transformer-based, in terms of IDF1 and HOTA. In this case, it is a bit hard to justify that authors are making a direction towards improving MOTRv2. \n\nIn fact, I would stay away with a rather heavier tracker (Transformer with multiple layers and many parameters) that gives even worse performance on MOT17 than light-weight tracking-by-detection/regression based trackers that require way less data to train, while still work better on major tracking benchmarks.\n\n2) The current approach lacks some form of interpretability. For example, from this claim \"COLA and TALA on the different decoders,\", why different label assignment should be used in different decoders? What exactly happened inside the decoder part for Transformer-based MOT, is it solving data association exactly or approximately? It would be more advocated if authors could come up with a more insightful explanation for this, and it will also benefit readers.\n\n3) For the idea of using shadow set, too many engineering tricks such as min, max, operations are used, it would be much better if authors could come up with some mathematical formulations as a technical sound approach to replace these simple heuristics, so as to better justify the use of this method. For example, IMHO, how about borrowing ideas from particle filter, to use importance sampling to maintain a set of queries to track each object?\n\nReferences:\n[a] Motsynth: How can synthetic data help pedestrian detection and tracking? ICCV2021"
            },
            "questions": {
                "value": "I see in Table 3(a) that adding COLA and shadow set both improves performance than not having them, but this is only tested on DanceTrack, would the COLA and shadow set also work better than not having them at all, on MOT17 validation set?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4477/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4477/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4477/Reviewer_gEi4"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4477/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697723055691,
        "cdate": 1697723055691,
        "tmdate": 1699636423686,
        "mdate": 1699636423686,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ezGqdBsQXZ",
        "forum": "WLgbjzKJkk",
        "replyto": "WLgbjzKJkk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4477/Reviewer_oLii"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4477/Reviewer_oLii"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an end-to-end Transformer-based MOT method. It introduces a coopetition alternative for training the intermediate decoders, and also develops a shadow set as units to augment the queries. Experimental results on some public datasets demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper is well written and organized. The S-COLA is also clearly explained.\n2. Experimental results on some public datasets demonstrate the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1. For the tracking queries and the detection queries, they both self-attend each other and then cross-attend the image feature tokens. Intuitively, all the queries can perceive the whole image, and it is not good enough to split them into two parts, which may degrade the detection results.\n\n2.  Why not evaluate the proposed method on the crowded dataset MOT20? In crowd scenes, the tracking query has the similar semantic information with the detection query, and may fail to assign correct label in crowd scenes.\n\n3. In Table 1, the authors point out that the detection result of MOTR can be improved by removing the tracking queries. How about the proposed CO-MOT? If CO-MOT is only used as a detection task, and whether the tracking performance can be further improved?\n\n4. It is better to evaluate the effect of the number of decoders L on the tracking performance.\n\n5. Pease reorganize the formats of the references, and make them consistent."
            },
            "questions": {
                "value": "See the Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4477/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4477/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4477/Reviewer_oLii"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4477/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698152298364,
        "cdate": 1698152298364,
        "tmdate": 1699636423611,
        "mdate": 1699636423611,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dtTFU9k3yD",
        "forum": "WLgbjzKJkk",
        "replyto": "WLgbjzKJkk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4477/Reviewer_NAsG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4477/Reviewer_NAsG"
        ],
        "content": {
            "summary": {
                "value": "The paper works on an end-to-end Multi-Object Tracking problem via a query-based Transformer, which assumes that the existing label assignment leads to scarce positive samples for detecting newborns. With this limitation in training, this paper observes a tracking terminal without renewal or re-initialization compared to other tracking-by-detection methods. To remedy this issue, this work presents Co-MOT by matching detection queries to all the tracked and untracked targets. Additionally, each query is augmented by a set with limited disturbance to itself. CO-MOT, with extra costs, achieves 69.4 HOTA on DanceTrack and 52.8 TETA on BDD100K, making it 1.4 times faster than the previous approach MOTRv2."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Deep observation of the existing approaches: This paper provides qualitative results in Figure 1 and quantitative results in Table 1 to bring the readers to what has been done to the existing e2e-MOT via Transformer. The bipartite matching label assignment in the previous approaches has a limitation regarding the video task, compared to the image task, such as object detection. From this perspective, this work involves the inherent property of the e2e-MOT via Transformer and offers a promising solution to the limitation. The superior performance of the proposed method is inspiring, which only requires fewer FLOPS of MOTRv2 to achieve a similar performance. I reckon this work reveals the core problem of the Transformer-based e2e-MOT.\n\nSimple and effective solutions: The paper reveals that the target assignment on detection queries is scarce due to the exclusive tracking queries, leading to unbalanced training. The proposed coopetition label assignment solves this problem by allowing the detection queries to match all the targets in the intermediate decoders except the last decoder. This simple solution can effectively recall newborn detection in the intermediate decoders while keeping standard MOT in the final outputs.  In addition, the shadow concept is introduced to augment each query in a feature-augmentation manner. A bulk of ablations are provided to demonstrate the effectiveness of each proposed solution."
            },
            "weaknesses": {
                "value": "Missing experiments on more models: In Section 3.2, this paper mentions that we revisit the Tracking Aware Label Assignment (TALA) used to train end-to-end Transformers such as MOTR and TrackFormer for MOT. However, all the ablations are conducted on MOTR. I cannot find evidence that COLA and shadow work on other models like TrackFormer. The authors should provide results of TrackFormer on two datasets at least to make the proposed solutions more solid.\n\nComparison of failure cases: The failure cases shown in Figure 5 are the common cases of all the Transformer-based approaches.  The authors should provide the failure cases of previous approaches and denote which kind of case has been solved by CO-MOT."
            },
            "questions": {
                "value": "In Table 2, the authors categorize all the methods into Non-End-to-end and End-to-end. What are the exact definitions of these two categories? Also, it will be better to list all the methods using Transformer. \n\nIn Figure 4, do the FLOPs of the MOTR include the YOLOX detector? What are the specific numbers of parameters for different approaches? The specific number of parameters should be indicated in Figure 4. For example, the number can be placed in circles."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4477/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698719435258,
        "cdate": 1698719435258,
        "tmdate": 1699636423512,
        "mdate": 1699636423512,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RtKuCQqmb8",
        "forum": "WLgbjzKJkk",
        "replyto": "WLgbjzKJkk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4477/Reviewer_kcLe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4477/Reviewer_kcLe"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces CO-MOT, a method that enhances the performance of end-to-end Transformer-based MOT. It addresses issues in the existing framework where label assignment fails to fully utilize detection queries due to the exclusive nature of detection and tracking queries. To overcome this, a coopetition alternative is proposed for training intermediate decoders. Additionally, a shadow set is developed to augment queries and mitigate training imbalances caused by one-to-one matching. The experiments are conducted on MOT17, BDD100k and DanceTrack."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ This paper mentioned that there is a large amount of post-processing in non-end-to-end methods in the MOT field, which leads to difficulties in parameter tuning in application. In this paper, some improvements have been made based on existing end-to-end methods, resulting in certain speed and accuracy improvements.\n\n+ This paper analyzes the shortcomings of existing e2e-MOT models and proposes a new network design strategy based on the analyses."
            },
            "weaknesses": {
                "value": "- The layout of the article is quite chaotic. Figure 1 is used as an example in the method introduction, but it is too far from the text information. For another example, in Section 3.2 of the introduction of strategies and methods, formulas are mixed in a large paragraph without a comprehensive formula or image description, making it difficult for readers to understand. The reviewer must refer to the paper of the baseline tracker MOTR for a comprehensive understanding. The authors should re-organize the method introduction and include a detailed figure to highlight the technical improvements of the new approach, including both the label assignment and shadow set.\n\n- The comparisons with more tracking approaches on the BDD100k or DanceTrack datasets are required to demonstrate the performance improvement."
            },
            "questions": {
                "value": "Please see the Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4477/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698741833202,
        "cdate": 1698741833202,
        "tmdate": 1699636423434,
        "mdate": 1699636423434,
        "license": "CC BY 4.0",
        "version": 2
    }
]