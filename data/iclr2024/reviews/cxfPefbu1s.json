[
    {
        "id": "LKZjIjZrag",
        "forum": "cxfPefbu1s",
        "replyto": "cxfPefbu1s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission734/Reviewer_R8GC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission734/Reviewer_R8GC"
        ],
        "content": {
            "summary": {
                "value": "The authors look at the issue of disguised procedural unfairness. They focus on the data generation process and try and decouple parts of the process which could be objectionable. Through their findings, they advocate for procedural fairness in the data generation process and argue that just trying to fit parameters in a fair manner may not be viable."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors do a good job of situating their work in terms of other efforts in the fairness literature. It is an important issue and preventing disguised procedural unfairness is an area where we need to better understand the practical harms as a community."
            },
            "weaknesses": {
                "value": "The paper brings in a number of areas (e.g. causal modeling, procedural fairness, procedural justice, hypothesis classes, graphical models, etc.) making it challenging to parse. There are only two experiments, one of which is a synthetic dataset. The algorithms are difficult to parse: examples, digressions, and new notation and comments are mixed in with math. The heatmap experiments embed several concepts, references and notation, making it difficult to parse their claims."
            },
            "questions": {
                "value": "- Does your framework require a causal model between attributes?\n- Are their simpler toy examples which you can illustrate as a warm-up?\n- In practice, what does it mean to constrain the data generating process (DGP)? Are we essentially filtering out data based on constraints before learning a model?\n- Are there other examples of work which look at the DGP and constraining it? Why haven't they?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission734/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission734/Reviewer_R8GC",
                    "ICLR.cc/2024/Conference/Submission734/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission734/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698253141462,
        "cdate": 1698253141462,
        "tmdate": 1700583188500,
        "mdate": 1700583188500,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AQOZRGvvLZ",
        "forum": "cxfPefbu1s",
        "replyto": "cxfPefbu1s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission734/Reviewer_GSnz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission734/Reviewer_GSnz"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the issue of objectionable components in a data-generating process in predictive modeling that might lead to unfair predictions. The focus is on scenarios where model parameters exhibit objectionable aspects, and seeks to isolate and correct these aspects to achieve procedural fairness. The proposed approach integrates concepts from causal inference, fairness constraints, and optimization to propose algorithms aimed at achieving fairer outcomes. It is based on two main requirements: (1) Fair Equality of Opportunity: The opportunity should be open and attainable, with the same prospects of success, for those who are at the same level of talent and ability, and have the same willingness to use them. (2) The Difference Principle: The (social and economic) inequalities are to be arranged so that they are to the greatest benefit to the least advantaged members of the society."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The approach is well-motivated and well-presented.\nThe addressed problem is interesting.\nThe authors provide a systematic examination and manipulation of objectionable components, and the use of reference points and value instantiation rules, with the goal to mitigate unfairness in predictive modeling stemming from objectionable data-generating processes."
            },
            "weaknesses": {
                "value": "The approach is motivated by very simple examples/models involving causal dependencies.\nFor more complex models, it requires a deep understanding of causal relationships within the data, which may require expert knowledge and extensive data analysis.\nThe approach builds on the identification of objectionable components, the availability of causal relations, and the correct specification of local causal modules (which is extremely hard for real-world datasets and scenarios). Moreover, in real-world applications, the distinction between objectionable and neutral components might not be possible. Is there a practical way to identify objectionable and neutral components in high-dimensional settings with intricate and unknown dependencies between variables? \nWhile the optimization problem of configuring reference point values to maximize the benefits for the least advantaged individuals makes sense, it is unclear how complex it is.\nThe evaluation is based on the UCI Adult dataset only, and the results might not be generalizable across different domains or datasets. Also, a comparison to other fairness strategies might be insightful."
            },
            "questions": {
                "value": "Please see comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission734/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission734/Reviewer_GSnz",
                    "ICLR.cc/2024/Conference/Submission734/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission734/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698577508735,
        "cdate": 1698577508735,
        "tmdate": 1700649795493,
        "mdate": 1700649795493,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ijxLSOAH8s",
        "forum": "cxfPefbu1s",
        "replyto": "cxfPefbu1s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission734/Reviewer_2K3E"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission734/Reviewer_2K3E"
        ],
        "content": {
            "summary": {
                "value": "The paper aim to address inadvertent biases in the data generation process that can affect even neutral aspects of this process, potentially compromising fairness.\nThis is referred to as procedural unfairness. The authors propose a framework to decouple objectionable data-generating components from neutral ones, using reference points and a value instantiation rule."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper studies a difficult, important, and often overlooked issue.\n- The framework is grounded in a well-established philosophical theory of justice. \n- I liked the idea of using reference points to decouple objectionable components in the data generation process of the predictive outcome. \n- I also appreciated the comparison against existing approaches."
            },
            "weaknesses": {
                "value": "- It's unclear how broadly the framework can be applied across different domains and whether there are any limitations to its scalability. In particular, the evaluation seems to be limited, with the only \"real-world\" dataset used is the UCI adult dataset where  only 6 features are used. \n- I also did not find a discussion regarding the practicality of implementing the proposed framework."
            },
            "questions": {
                "value": "1. Have you tried to use the proposed framework to more complex datasets (more variables and larger domains)? How does it scale? \nWhat happens when you have multiple confounding variables?\n\n2. As a follow-up from the previous question; What are the computational costs associated with implementing the framework, and how do they compare to existing methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission734/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699228849862,
        "cdate": 1699228849862,
        "tmdate": 1699636000192,
        "mdate": 1699636000192,
        "license": "CC BY 4.0",
        "version": 2
    }
]