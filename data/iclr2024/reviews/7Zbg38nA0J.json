[
    {
        "id": "nKXjSFGX3P",
        "forum": "7Zbg38nA0J",
        "replyto": "7Zbg38nA0J",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5816/Reviewer_m2MB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5816/Reviewer_m2MB"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a theory of grokking in neural networks based on the concept of sub-networks. Based on the theory, many interesting behaviors are predicted and verified. The paper is well written and the theory is novel to me. The only issue that prevents me from giving a higher score is the relatively simple setting of the problem (see weakness part). However, I believe the current version is good enough for ICLR."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. I believe the \u201cungrokking\u201d and \u201csemi-grokking\u201d phenomenons are quite persuasive: continuing training on a subset after the grokking point makes the test loss drop again; training on a dataset of a specific size will make the training loss fluctuate around a very low level, and the test loss will hover around some intermediate value. It makes me believe that the two types of circuits are \u201ccompeting\u201d during the learning, and the size of the training set decides which will win. The results in Figure 4 also demonstrate that weight decay doesn\u2019t influence the value of $D_{crit}$.\n2. The paper is well-written and quite easy to follow."
            },
            "weaknesses": {
                "value": "1. How do the findings in grokking help us understand emergent behavior better? How could these results guide the design of our deep learning systems? It would be nice if the paper included some discussion about this.\n2. Although most of the papers in this direction consider a similar setting that contains only x and y as input, is it possible to extend the analysis to a more general setting, e.g.,$(a+b+c*d)$ mod $p$?\n3. Similar concerns for the network structure. Will the analysis (or even the grokking phenomenon) still work for non-transformer models?\n4. Similar concerns for the way we encode the values of the input. Will the analysis (or even the grokking phenomenon) still work when the input signal is encoded in different ways?"
            },
            "questions": {
                "value": "1. I think using \u201cnorm of parameters\u201d to measure efficiency is not good, as we can create the same function by multiplying c to one layer and multiplying 1/c to another layer: the same function can have different parameter norms. I speculate the concept of efficiency is related to \u201chow complex the function is\u201d. Memorizing a circuit would be quite complex as it cannot uncover the ground truth rules and have to remember everything, generalizing a circuit would be simpler as it captures the rules. IMO, these two concepts are quite similar to the holistic mapping and compositional mapping mentioned in [1], which evaluate the generalization ability of different mappings using coding length. In summary, rather than the parameter\u2019s norm, I suggest considering coding length, Kolmogorov complexity, or even sample efficiency (number of training samples needed to make the model generalize well) to compare how efficient a circuit is.\n2. Why do memorizing circuits learn faster than generalizing circuits in the setting of grokking? This counters with my intuition, because we usually believe memorizing happens in the overfitting phase, which is the latter phase of training. What is the difference between the settings of general supervised learning and grokking?\n3. Are there any methods that can probe the model and allow us to directly observe these circuits? As discussed in the strength part, although the semi-grokking and the ungrokking behavior are strong evidence of the proposed explanation, some other mechanisms might also cause similar behavior. For example, ungrokking might be caused by catastrophic forgetting: the subset used for continuous training might contain some poison samples that harm the generalization ability. So I believe more evidence would make the paper\u2019s claim more solid.\n\n[1] Yi Ren, Samuel Lavoie, et. al. Improving Compositional Generalization using Iterated Learning and Simplicial Embeddings, NeurIPS 2023"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5816/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698478273742,
        "cdate": 1698478273742,
        "tmdate": 1699636613843,
        "mdate": 1699636613843,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0y53TXIkaO",
        "forum": "7Zbg38nA0J",
        "replyto": "7Zbg38nA0J",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5816/Reviewer_JVYB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5816/Reviewer_JVYB"
        ],
        "content": {
            "summary": {
                "value": "Grokking is the phenomenon by which models generalize long after overfitting. The paper aims to explain the phenomenon from a circuit efficiency perspective with a postulate that there are competing subnetworks: a generalizing subnetwork that is slow but more efficient than a memorizing subnetwork, which is fast but requires high complexity to accommodate a large training sample. The authors argue that these properties can explain delayed generalization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The writing is clear and well-structured and the authors laid out an interesting story explaining grokking.\n- The paper tackles a very interesting phenomenon that can shed light on the dynamics of representation learning.\n- The experiments are clean, and the visualizations are informative."
            },
            "weaknesses": {
                "value": "- On the empirical side, there are few results beyond modular arithmetic. \n- On the theoretical side, there is a focus on the phenomenological observation that generalizing circuits are learned at a different speed compared to memorizing circuits, but the theory offers no explanation as to why they are slow in the first place. I think the real question is not whether or not the generalizing circuit is slower but rather *why* it is slower in this particular way, i.e., why does the model generalize so long after it overfits its training data? The origin of dynamics is crucial here.\n- Furthermore, there is a heavy reliance on weight decay as an explanation for why generalizing circuits are favored, even though Grokking is known to occur without it. This is acknowledged in the paper but not addressed adequately. \n- The efficiency metric based on parameter norm appears to have little to do with the main predictions and empirical observations (dataset size and semi-grokking and ungrokking). One can reach the same conclusions using only the simple premise that larger datasets are generally conducive to generalization while small ones are not (assuming consistent quality). Presumably, the transition between the two regimes depends on the specifics of the task.\n- Many of the prior works cited studied the dependence of Grokking on data set size extensively. The novelty here is limited.\nOverall, it's not clear this paper provides deeper insights than what is already in the literature so I cannot recommend acceptance."
            },
            "questions": {
                "value": "- Does the ungrokking setting maintain performance on the excluded part of the initial training set?\n- It's hard to see how ungrokking is not a special instance of catastrophic forgetting (CF). I don't think the discussion making this distinction on page 5 is correct. Clearly, taking a specific subset of a dataset can be viewed as taking a different one, e.g., removing all points above a threshold effectively changes the training set distribution. The distinction from CF based on the choice of the (post)training set seems arbitrary. I would recommend dropping it."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5816/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698827473962,
        "cdate": 1698827473962,
        "tmdate": 1699636613741,
        "mdate": 1699636613741,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aS7skbvSU3",
        "forum": "7Zbg38nA0J",
        "replyto": "7Zbg38nA0J",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5816/Reviewer_Rk5Z"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5816/Reviewer_Rk5Z"
        ],
        "content": {
            "summary": {
                "value": "This paper studies grokking via the lens of circuit efficiency. In particular, they conjecture the existence of both memorization and generalization circuits, which have different efficiency, measured by parameter norm when given the same predictive performance. Based on their analysis, they also predict theoretically and verify empirically two new phenomenon called ungrokking and semi-grokking."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper is well written and easy to follow.\n* The story is in general sound and nicely supported by empirical results\n* Enrich the literature of grokking by discovering semi-grokking and un-grokking"
            },
            "weaknesses": {
                "value": "* Although I find the general story to be believable, some details are either incomplete or could have alternative explanations. See the question part."
            },
            "questions": {
                "value": "* I'm not sure about the terminology \"circuit efficiency\", since there is no mechanistic interpretability literally picking out circuits.\n* I would like to see more analysis on semi-grokking. For example, what are these semi-generalized algorithms doing? For modular addition, one may expect some of semi-generalizing algorithms somehow learn the symmetry of two inputs (Abelian), but fail to learn the more sophisticated generalization patterns.\n* For ungrokking, is there a theory for predicting the phase transition point? It would be nice to have a theory (at least some analysis) regarding the critical data size.\n* Also for ungrokking, the explanation in the paper is that when the dataset size is small, the memorizing circuit is more efficient than the generalization circuit. Maybe I missed something but I didn't see empirical evidence for that. An alternative explanation could be: memorization and generalization circuits are equally efficient, so a circuit basically randomly wanders around, but they are more memorization circuits than generalization circuits. As a result, the network is more likely to end up being a memorization circuit just because there are more memorization circuits, but not because they are more efficient. In general, maybe both factors are contributing. My point is: there could be alternative hypotheses for ungrokking, and the authors seem overly confident with their claims with limited evidence."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5816/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5816/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5816/Reviewer_Rk5Z"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5816/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699057717429,
        "cdate": 1699057717429,
        "tmdate": 1699636613642,
        "mdate": 1699636613642,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "O5ZcU3Um6A",
        "forum": "7Zbg38nA0J",
        "replyto": "7Zbg38nA0J",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5816/Reviewer_A2EW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5816/Reviewer_A2EW"
        ],
        "content": {
            "summary": {
                "value": "This paper explains the grokking phenomenon through the so-called \"circuit efficiency,\" where a circuit means a neural net with certain weights, and the efficiency refers to the parameter norm of a circuit that achieves a small training loss. This paper points out three ingredients in combination that can cause grokking: (1) the existence of a circuit that generalizes well and another circuit that doesn't; (2) the generalizing circuit is more \"efficient\"; (3) the training algorithm needs to take a long time to find the generalizing circuit.\n\nThis implies that the dataset size may be important: when it is smaller than a critical value, the memorizing circuit could be more efficient; when it roughly equals the critical value, the final test accuracy may not be close to 100%."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The grokking phenomenon being studied in this paper is very puzzling and important.\n2. This paper provides simple and intuitive arguments that can partially explain grokking.\n3. The importance of the three ingredients and dataset size is validated by experiments.\n4. The explanation provided in the paper also leads to the discovery of the \"ungrokking\" and \"semi-grokking\" phenomena."
            },
            "weaknesses": {
                "value": "1. Although the paper claims that they provide a \"theory\" for grokking, there are no real theorems in the main paper. Many key concepts, such as circuit efficiency, are not defined with formal math, either. I encourage the authors to spend more effort to formulate and present their intuitive arguments with rigorous math.\n2. Although the explanation provided by the paper seems intuitive, several key puzzles are still left unexplained, even if we follow the authors' argument with 3 ingredients. This paper mainly explains the second ingredient (\"the generalizing circuit is more efficient\"). However, the more interesting ones are the first and third ingredients, which may have a closer relation to practice but the paper doesn't make much progress on them.\n    * (Related to the first ingredient.) Why are there only two circuits instead of a series of circuits that continuously trade-off between efficiency and training speed? Understanding this is crucial to understand why the transition in grokking is very sharp.\n    * (Related to the third ingredient.) Why does the generalizing circuit need more time to be learned? If we just search circuits among those with small parameter norms (or being efficient under other efficiency measures), can we completely avoid meeting memorizing circuits during training? Understanding this is crucial to making neural nets learn algebra/reasoning/algorithmic tasks more efficiently in time.\n3. The newly discovered phenomena in the paper, ungrokking and semi-grokking, are indeed very interesting, but a minor weakness is that it is a bit unclear to me whether these phenomena will be of much practical use in the near future."
            },
            "questions": {
                "value": "This paper is of good quality overall. My main concerns are the weaknesses 1 and 2 above. I would like to know if the authors would like to (1) make the arguments more formal; (2) point out some useful insights about the first and third ingredients that I could have missed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5816/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699206301223,
        "cdate": 1699206301223,
        "tmdate": 1699636613523,
        "mdate": 1699636613523,
        "license": "CC BY 4.0",
        "version": 2
    }
]