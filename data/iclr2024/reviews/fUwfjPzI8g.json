[
    {
        "id": "hrTxzoBszM",
        "forum": "fUwfjPzI8g",
        "replyto": "fUwfjPzI8g",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission196/Reviewer_91vA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission196/Reviewer_91vA"
        ],
        "content": {
            "summary": {
                "value": "This paper describes a proposal for deep neural networks that use units that compete locally in a stochastic manner to represent new tasks. This approach creates sparse task-specific representations in each network layer, with different sparsity patterns for different tasks. During training, weight updates for each unit are regulated based on their winning probability. During inference, only the winning unit is retained, and the weights for non-winning units are set to zero for the given task. The authors claim to achieve state-of-the-art predictive accuracy in few-shot image classification experiments while requiring less computational resources compared to the current state-of-the-art techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-\tA competition strategy between units offers an exciting paradigm for continual learning. Although the use of subnetworks is not new, this competition strategy seems to work efficiently and reach good performance.\n-\tOverall, the computation time of the proposed approach is less than previous methods, achieving better performance."
            },
            "weaknesses": {
                "value": "-\tMy biggest concern is the scalability of this approach. Why are experiments with ImageNet100 not performed? It could be that the method is not suitable for this scale yet. \n-\tCould you add a column with the number parameter used by your method? If not, at least mention how it compares to other architectures."
            },
            "questions": {
                "value": "-\tHow much is the first task accuracy degrading compared to other methods? Is this competition strategy forgetting more or less in the first tasks? Does it have more recency bias?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission196/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission196/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission196/Reviewer_91vA"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission196/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828463593,
        "cdate": 1698828463593,
        "tmdate": 1699635945314,
        "mdate": 1699635945314,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mIlzjWOHAB",
        "forum": "fUwfjPzI8g",
        "replyto": "fUwfjPzI8g",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission196/Reviewer_beRr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission196/Reviewer_beRr"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method for task incremental Continual Learning by leveraging sparse representing. The main idea is to group the neurons into blocks of ReLU units such that different units in a block learn different tasks and thus avoid interference while learning new tasks. During inference, only units corresponding to the task are used, and the rest are dropped, resulting in improved inference time. The evaluation against multiple baselines shows the efficacy of the method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The paper is well-written, and notations are easy to follow.\n\n* The idea of grouping neurons into different blocks is novel and interesting. *Table 3** validates this and shows that the method can reduce forgetting between different tasks. \n\n*The method is benchmarked against multiple baselines and shows substantial improvement, which confirms the hypothesis of the method. \n\n* An ablation study to understand the effect of different block sizes is presented."
            },
            "weaknesses": {
                "value": "* > In our approach,  a group of J ReLU units is replaced by a group of J competing linear units, organized in one block; each layer contains I blocks of J\n\n* It is unclear how the networks learn non-linearity if the ReLU units are removed. \n\n* It would be interesting to see the comparison with dynamic sparse training-based and other sparsity-based methods is missing.\n\n* > We keep few exemplars X few from the previous task, t \u2212 1\nIt is not mentioned in the paper if the examples are selected randomly or based on some heuristic. It would be helpful to study the effect of exemplar selection on the method."
            },
            "questions": {
                "value": "* Why is *U* sampled from a Gaussian distribution instead of Gumbel distribution in **eqn 5**?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission196/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698844364744,
        "cdate": 1698844364744,
        "tmdate": 1699635945232,
        "mdate": 1699635945232,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nC2dDg5AfT",
        "forum": "fUwfjPzI8g",
        "replyto": "fUwfjPzI8g",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission196/Reviewer_BkhS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission196/Reviewer_BkhS"
        ],
        "content": {
            "summary": {
                "value": "The paper considers a deep network referred to as task winner-takes-all (TWTA), and it comprises unit blocks that compete locally to win the representation of each new task. The competition is performed in a stochastic manner (Gumbel Softmax), leading to regulating gradient-driven weight updates for a new task. During inference, the network retains only the winning unit and zeroes out all weights pertaining to the non-winning units for the task at hand. The proposed TWTA produces state-of-the-art predictive accuracy on class/task incremental tasks and imposes a considerably lower computational overhead than the current state-of-the-art."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-A novel mechanism referred to as task winner-takes-all (TWTA) that inherently learns to extract sparse task-specific data representations in a stochastic manner is proposed. \n-The learned stochastic competition posteriors are used for regulating the weight training strength of TWTA.\n-Winner-based weight pruning provided faster inference time."
            },
            "weaknesses": {
                "value": "-There is no analysis of sparse task-specific data representation and winning block units.\n- Few-shot image classification tasks are mentioned; however, it is not explored in this work.\n- The comparison of the number of parameters is not clear in architecture tables. Instead of talking about block/unit sizes, specific numbers would be easier to follow."
            },
            "questions": {
                "value": "(-) Does TWTA provide a forget-free solution in task-incremental learning (TIL)? How about the backward transfer?\n(-) How sensitive is the performance to the selection? What is the performance when blocks are selected randomly? \n(-) It would be nice to know the few-shot class incremental (FSCIL) performance of TWTA\u2019s weight training strength regulation."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission196/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699413033239,
        "cdate": 1699413033239,
        "tmdate": 1699635945149,
        "mdate": 1699635945149,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "loTdxqpnmA",
        "forum": "fUwfjPzI8g",
        "replyto": "fUwfjPzI8g",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission196/Reviewer_RSpN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission196/Reviewer_RSpN"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the problem of catastrophic forgetting in class-incremental learning, focusing on finding specific subnetworks obtained by sparsifying the learned representation per task. Specifically, the authors remove the non-linearities in the neural network and reorganize the output of each hidden layer representation, such that it consists of a fixed number of blocks denoted as $I$ each characterized by $J$ output units.\n\nThe proposed approach involves learning a mask so that, at the end of each task training, only one out of $J$ output units per block is considered in the forward pass, reducing the overall number of parameters used during inference. Each task learns a separate mask, which are then at test time to evaluate continual learning performance. Specifically, for class incremental scenario only the last mask is used, while for task incremental the task-specific masks are used.\n\n To design  learnable masks, the authors use hidden winner indicator variables drawn from a Categorical posterior distribution. They  represent the proportion of output units to be masked in the current task for performing inference. The parameters of this distribution are learned by maximizing the Evidence Lower Bound, and sampling from this distribution is achieved through the Gumbel-Softmax trick, allowing backpropagation during training."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Novel usage of Gumbel-Softmax trick to learn mask for identifying winning subnetworks in the class-incremental scenario.\n- Their approach is supported by a good theoretical background and it seems well generalizing to large domain shift as proved by the experiments conducted on different datasets.\n- The proposed approach can be plugged into various architecture based on linear and convolutional layers by simply swiching the standard linear and convolutional layers with the layers described in the paper."
            },
            "weaknesses": {
                "value": "From an high-level perspective, I have the following significant concerns:\n\n* **Poor Presentation Quality**: the paper presentation is not optimal, and there are concerns about its clarity and organization.\n* **Lack of Reproducibility**:  In the paper, many details necessary needed to reproduce the results are missing, such as a comprehensive list of the hyperparameters employed in the experiments related to the loss functions. While the code is included within the submission, clear instructions for its execution and for the dataset retrieval are needed.\n* **Fixed-Size Classifier**: In a classical continual learning scenario, the prior knowledge of the number of classes to be encountered is not available. Common Continual Learning Frameworks (e.g., FACIL[1], Avalanche[2]) adapt the size of the last classifier as new classes are encountered, simulating a real scenario. It appears from the paper and the attached code that the output layer of the classifier is fixed from the start to the total number of classes that will be encountered. This represents a significant limitation of the proposed approach.\n* **Scalability Limitations**: The paper lacks a dedicated section to discuss its scalability limitations, which is an important aspect for understanding the broader applicability of the proposed method.\n\n[1]: Masana, M., et al. \"Class-incremental learning: Survey and performance evaluation on image classification\".\n\n[2]: Carta, Antonio, et al. \"Avalanche: A PyTorch Library for Deep Continual Learning\""
            },
            "questions": {
                "value": "**Poor Presentation Quality**\n\n* In the abstract, the authors claim that their approach achieves high predictive accuracy for few-shot image classification. However, the paper lacks experiments specifically focused on few-shot image classification. The only reference to few-shot class incremental learning coming from the citation of SoftNet (Kang et al. 2023), which actually tackles the problem of few-shot classification in incremental learning scenarios. Am I missing something? Have the author adapted the approach of Kang et al. to the standard class incremental learning to provide the results presented in Table 1?\n* The Model Formulation section (Sec. 2.2) is challenging to follow. There is a need for a more detailed description of how the competing linear units are organized. To enhance clarity, I suggest to provide a high-level figure illustrating how the output units are organized and masked. This figure can be used as fundamental block for undestanding Figure 1 and Figure 2 and can help to follow the notation used in the subsequent sections. Moreover, increasing the font size of the mentioned figures will improve readability.\n* To enhance the paper organization, it is advisable to improve image captions by directly referencing the corresponding sections of the paper. Additionally, positioning Figures and Tables at the top of the pages, rather than interrupting the text, is recommended to improve the readability.\n* It would be beneficial to enhance the logical flow of the training section (Section 2.4). The current presentation gives the impression that each text block is somewhat disjointed from the preceding one. While the authors attempt to breakdown the training loss (Eq 7) into various components, the overall discussion is hard to follow. Since ELBO Maximization is not a standard procedure in the context of CIL scenario, I suggest introducing the ELBO formulation first, followed by how the training loss is linked to it and then presenting Equation 5. for Gumbel-Softmax relaxation. A reformulation of the section could help clearly delineate which terms in the loss are specifically tailored for learning the new task, which are added ad-hoc for continual learning regularization, and which originate from ELBO Maximization. Lastly, in Equation 6, the repetition of \"J\" within the parentheses might be unnecessary and the step in Equation (8) is not obvious, thus additional details may be provided.\n\n  *Exemplars*: The concept of \"Exemplars\" is introduced twice in the text, before and after the training loss definition. Improving readability could involve describing the exemplar loss and how exemplars are managed in a reserved paragraph.  Moreover, considering the current organization, clarity is compromised in explaining how exemplars are managed (point 3.), as the description of the KD loss is only provided at the end of the section.\n\n  *Supplementary References*: The paper lacks references to all the supplementary material sections.\n\n**Training Loss Questions**:  I have some concerns regarding the training loss. Why does the third term depend on the dataset at task $t-1$ (i.e., $X_u^{(t-1)}$)? Additionally, it would be beneficial to gain a clearer understanding of the authors' choice to implement knowledge distillation, as described by Hinton et al., for exemplars, and to use the KL distance between network probabilities of the current task model and the previously trained one when dealing with the current task (the third component in the training loss). I wonder if there is a specific reason for not applying knowledge distillation when using data from the current task?\n\n**Lack of Reproducibility**: The authors provide code without instructions on how to run it, and the current Readme.md comes from another work (Chen et al. [3]). Additionally, the existing code does not facilitate the execution of experiments outlined in the main paper:\n\n* the standard dataset (Cifar10 ad Cifar100) are not automatically downloaded and should be downloaded manually from the official site. Even if this download is performed, the code for pre-processing the datasets is absent. Currently, the code requires that Cifar10 and Cifar100 must be organized in dictionaries already splitted in Train and Validation. The provided link in the Readme.md(from [3]) for pre-processed datasets is not working.\n* The code doesn't support experiments on other datasets (Tiny-Imagenet, PMnist, Omniglot, 5-Datasets).\n* Execution of experiments presented in the paper tables is not feasible. For example, the number of blocks $J$ is hard-coded and set to $2$ (while in the paper $J=8$  is indicated as the best-performing choice). Additionally, certain hyperparameters for training losses are hardcoded without mention in the main paper. For instance, a factor $\\lambda=1/1000$ is placed in front of the KL distance between p and q (Equation 7, second component). See also next question.\n* Hyperparameter Selection: What are the training loss hyperparameters and how they are selected? How  $\\tau$ (Equation 5), the hyperparameter controlling the sparsity of the masks fixed to 0.67, is selected? A discussion in the main paper is required.\n* Batch Size Dependency For Task-wise discrete mask. Does the size of parameters $\\pi_{t, i, j}$ and the corresponding $\\tilde{\\xi}_{t,i}$ (Equation 6) depend on the batch size used during the training?\n\n[3] Long Live the Lottery: The Existence of Winning Tickets in Lifelong Learning, Tianlong Chen\\*, Zhenyu Zhang\\*, Sijia Liu, Shiyu Chang, Zhangyang Wang\n\n**Fixed-size Classifier**:  In addition to the concern previously raised about prior knowledge of the number of classes, I have two questions regarding the structure of the last classifier placed on the top of the network. In section 2.4, the authors mention that the class probabilities are generated by \"the penultimate Softmax layer of the network.\" What does this mean? To the best of my knowledge, in the standard supervised classification paradigm for class incremental, a single Softmax function is typically applied after the last and only fully connected layer of the network. Moreover, inspecting the attached code, I see that in the file **small_model.py**, two final linear layers are defined (named *linear* and *linear_main*). Is this connected to the previous sentence? I'm curious to understand the rationale behind having two linear classification layers at the end of the network.\n\n\n**Summary of the Review**: The paper presents a lot of interesting ideas with a good theoretical background in support. However, I have significant concerns on the reproducibility of the experiments and on the clarity of the presented method. I believe that the current version of the paper does not satisfy high quality standard for paper presention of ICLR. I am inclined to assign a reject score; however, I am open to reconsidering my decision during the rebuttal if the authors adequately address the issues raised for both the paper and the experimental code."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission196/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission196/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission196/Reviewer_RSpN"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission196/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699529050634,
        "cdate": 1699529050634,
        "tmdate": 1699635945072,
        "mdate": 1699635945072,
        "license": "CC BY 4.0",
        "version": 2
    }
]