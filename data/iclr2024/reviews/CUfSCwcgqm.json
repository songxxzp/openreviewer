[
    {
        "id": "bvEG4dAm8Y",
        "forum": "CUfSCwcgqm",
        "replyto": "CUfSCwcgqm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3722/Reviewer_2N34"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3722/Reviewer_2N34"
        ],
        "content": {
            "summary": {
                "value": "Summary:\nThis paper proposes a method called \"Neural Atoms\" to help graph neural networks (GNNs) better capture long-range interactions in molecular graphs. The key ideas can be understood as: (i) introduce a small set of \"neural atoms\" that group together subsets of the original atoms in the molecule. This reduces long interaction paths to a single hop between neural atoms. (ii) use attention mechanisms to learn how to group atoms into neural atoms; and to exchange information between the neural atoms. (iii) enhance the atom representations by mixing in information from the neural atoms, allowing GNNs to capture long-range interactions. \n\nOverall, the paper seems to formalize the concept of neural atoms as virtual atoms that represent clusters of real atoms. In concept, this resembles similar to DiffPool (Ying et al., 2018 reference in the paper). however their implementation and purpose can be differently understood."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strengths:  \n(a) simple and architecture-agnostic method that can enhance any GNN.  \n(b) reduces long-range interactions to single hop, avoiding path explosion issue.  \n(c) outperforms baselines on molecular graph tasks needing long-range modeling.  \n(d) visualizations show neural atoms learn meaningful groupings aligned with interactions."
            },
            "weaknesses": {
                "value": "Weaknesses:    \n(a) does not utilize 3D coordinate information available for some molecules.   \n(b) mainly considers intra-molecular, not inter-molecular interactions.   \n(c) hyperparameter tuning needed for number of neural atoms, as the problem with pooling operation known earlier in graph learning literature.   \n(d) lacks strong theory on optimal atom groupings."
            },
            "questions": {
                "value": "Questions:   \n(a) How are the neural atom groupings initialized? Are they randomly assigned?   \n(b) is there a theoretical justification for why this approach models long-range interactions well?  \n(c) could 3D coordinate data be incorporated to better model distance-dependent interactions?   \n(d) how does this approach scale to very large molecular graphs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3722/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698512169657,
        "cdate": 1698512169657,
        "tmdate": 1699636328370,
        "mdate": 1699636328370,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mlXX35eaiN",
        "forum": "CUfSCwcgqm",
        "replyto": "CUfSCwcgqm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3722/Reviewer_9FRM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3722/Reviewer_9FRM"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a technique called Neural Atom that tries to abstract a cluster of nodes into a single node and subsequently leverage these condensed nodes for exchanging information that may not be achievable within the original molecule graphs. The authors validate the effectiveness of these proposed techniques through comprehensive experimentation conducted on three distinct datasets and employing various GNNs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The authors have made commendable efforts to clarify how their proposed algorithm works by providing theoretical explanations, which is commendable. \n- They have also used real-world case studies to show how their method functions in practice."
            },
            "weaknesses": {
                "value": "- The incorporation of virtual atoms is not a novel concept, as it has previously been applied graph research as early as 2017 [r1, r2, r3]. It would be beneficial for the authors to engage in a discussion regarding how their proposed techniques differ from these referenced works. Furthermore, it is worth noting that there is a concurrent study that outlines a similar pipeline [r4]. Given the potential significance of this similarity, it would be valuable to include a discussion of this related work.\n\n- The proposed approach has the potential to be employed across various types of graphs, as the concept of \"virtual atoms\" could be (and already have been) utilized  in other datasets like the OGB benchmarks. However, the authors did not explore this possibility in their work.\n- The quality of writing in the paper seems to get worse as you read further, especially in Section 4. There are a lot of grammar mistakes in Section 4.2. Additionally, there are some terms like \"ratio\" in Table 4 and \"varying proportion\" in the last paragraph on page 7 that are introduced without prior explanation. This gives the impression that the paper was completed hastily.\n\n[r1] Molformer: Motif-Based Transformer on 3D Heterogeneous Molecular Graphs, AAAI 2021\n\n[r2] Neural Message Passing for Quantum Chemistry, ICML 2017\n\n[r3] An analysis of virtual nodes in graph neural networks for link\nprediction, LoG 2022\n\n[r4] On the Connection Between MPNN and Graph Transformer"
            },
            "questions": {
                "value": "I have a couple of questions about Figure 5. Can atoms within the same neural atoms share information? If so, I'm wondering whether information exchange between atoms from different neural atoms is actually more than between atoms within the same neural atoms.\n \nI am open to adjust my scores after the discussion with the authors."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3722/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3722/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3722/Reviewer_9FRM"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3722/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698741160182,
        "cdate": 1698741160182,
        "tmdate": 1700757340286,
        "mdate": 1700757340286,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1hYm0JNsPQ",
        "forum": "CUfSCwcgqm",
        "replyto": "CUfSCwcgqm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3722/Reviewer_4gc7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3722/Reviewer_4gc7"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors address a crucial challenge in drug discovery using Graph Neural Networks (GNNs) - the difficulty in capturing both short-range interactions (SRI) and long-range interactions (LRI) within molecular graphs. While current GNNs excel at modeling SRI, they struggle with LRI, essential for determining molecular properties. To overcome this limitation, the authors propose a novel approach. They introduce \"Neural Atoms,\" abstract representations that amalgamate information from atomic groups within a molecule. By exchanging information among these neural atoms and projecting them back to atoms\u2019 representations, they establish effective communication channels among distant nodes, reducing the interaction scope of node pairs to a single hop. The method's efficacy is validated through extensive experiments on three long-range graph benchmarks, demonstrating its ability to enhance any GNN in capturing LRI, a crucial step forward in molecular graph analysis for drug discovery. Additionally, the paper provides a physical perspective, establishing a connection between this method and the traditional LRI calculation method, Ewald Summation.\n\n====================\n\nDuring rebuttal, the authors provided more experimental results and more detailed discussions on several aspects. Therefore, I increase my rating."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The problem of capturing long-range interactions in molecular graphs is interesting and important.\n\n- The paper is generally well-written and almost clear everywhere.\n\n- Experiments conducted on several datasets, to some extent, show the effectiveness of the proposed method in both graph-level and link-level tasks."
            },
            "weaknesses": {
                "value": "- The novelty of the proposed method is limited. For example, from the perspective of general graph machine learning, supernodes have been widely used which are the same as the concept of neural atoms.\n\n- Some claims are controversial: in the Introduction, the authors claimed the disadvantages of transformers, especially the self-attention mechanism, but the way to project atom representations to neural atom representations in the proposed method still uses multi-head attention. Similarly, the controversy also happens in the running time experiment.\n\n- There are some limitations in the experimental studies including:\n\n1.  Experiments have been conducted on only three relatively small-size benchmark datasets. In fact, there are some larger and more recent benchmark datasets such as OC20 and OE62.\n2.  Representative SOTA methods have not been compared, for instance [1].\n\n[1] Ewald-based Long-Range Message Passing for Molecular Graphs, ICML 2023"
            },
            "questions": {
                "value": "- From the comparison of the running time, there are no clear advantages of the proposed method compared to the transformers which conflicts with the claim in the Introduction (GTs are more computationally expensive than GNNs). What are the reasons? The multi-head attention used in step 1?\n\n- What will be the performance on larger datasets? Can the proposed method beat more recent SOTA such as [1]?\n\n[1] Ewald-based Long-Range Message Passing for Molecular Graphs, ICML 2023"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3722/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3722/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3722/Reviewer_4gc7"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3722/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698837561005,
        "cdate": 1698837561005,
        "tmdate": 1700749602906,
        "mdate": 1700749602906,
        "license": "CC BY 4.0",
        "version": 2
    }
]