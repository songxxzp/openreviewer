[
    {
        "id": "XwECcwt6Qa",
        "forum": "UPvufoBAIs",
        "replyto": "UPvufoBAIs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7928/Reviewer_wu5J"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7928/Reviewer_wu5J"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new domain adaptation method for category-level object pose estimation. The method uses only RGB images, without relying on source domain data or 3D annotations in the target domain. The authors represent an object that belongs to a known category as a cuboid mesh and utilize an existing method to learn the vertex features. The features are iteratively updated in the target domain based on their proximity to corresponding image features. The experiments show much better performance in the target domain compared with the competitors without domain adaptation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "\u2022\tThe authors handle the problem that neither depth information nor 3D annotations are available in the target domain, which is challenging yet important in real applications.\n\n\u2022\tThe intuition behind the presented domain adaptation method is that the local features, which represent specific parts of the object, are more robust than the global features in the target domain, which makes sense to me.\n\n\u2022\tThe presented method achieves impressive object pose estimation results in multiple datasets with different kinds of nuisance."
            },
            "weaknesses": {
                "value": "The majority of the figures in this paper such as Fig.2, Fig.2, and Fig.10, exhibit low quality. It would be better if the authors could consider revising them to enhance the clarity and resolution.\n\nI am not familiar with the topic of domain adaptation, so I would not judge the novelty of this paper. Please refer to \u201cQuestions\u201d for my concerns."
            },
            "questions": {
                "value": "\u2022\tTo my understanding, in the experiments, the baseline models are evaluated in the target domain without domain adaptation. In this context, it is reasonable that those methods cannot generalize well in the target domain. I was wondering if there are some existing domain adaption approaches that can be applied to the baseline models. The evaluation would be more convincing, comparing NeMo + 3DUDA with a competitor such as NeMo + another domain adaption method.\n\n\u2022\tThe pre-render feature maps are generated from the source mesh. As the vertex features are not updated here, how to make sure those feature maps are reliable in the target domain? Are there situations in which the method might be stuck in local optima or even diverge? Conducting an ablation study on the pre-rendered feature maps would be valuable.\n\n\u2022\tIn Sec.3.2.1, the parameter $\\delta$ seems crucial for effectively updating vertex features. The authors mentioned they chose a $\\delta$ such that the majority of source domain features lie within the likelihood score. How to set $\\delta$ in practice? Is it constant? Intuitively, as the vertex features are updated, one would expect the similarity between vertex features and image features to increase. Does it make more sense to update $\\delta$ accordingly?\n\n\u2022\tIt seems the method is time-consuming due to the iterations and pre-rendering. However, the actual time consumption during testing is unclear."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7928/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697802056425,
        "cdate": 1697802056425,
        "tmdate": 1699636973753,
        "mdate": 1699636973753,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FEd8suAgTA",
        "forum": "UPvufoBAIs",
        "replyto": "UPvufoBAIs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7928/Reviewer_PE77"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7928/Reviewer_PE77"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the task of category-level 3D pose estimation within the setting of source-free and image-only unsupervised domain adaptation. The authors introduce a novel method called 3DUDA, which is developed based on the observation of the invariance of object local parts and is supported by theoretical insights. 3DUDA utilizes a learnable cuboid feature matrix to represent an object category, and assesses the accuracy of a pose by comparing the feature map of the test image with the one rendered from the categorical cuboid feature matrix using the pose. This render and compare approach enables domain adaptation by iteratively updating the categorical feature matrix and fine-tuning the source model. Experimental results demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The proposed method, 3DUDA, is developed based on the common observation that certain object parts exhibit invariance across out-of-distribution (OOD) scenarios, and utilizes the categorical learnable cuboid meshes to effectively capture and store the part features at each vertex.\n- To achieve domain adaptation, 3DUDA employs an iterative process that involves updating the features of categorical meshes and fine-tuning the source model through feature-level render and compare optimization.\n- The paper is well-written and presents its ideas in a clear and understandable manner. It is accompanied by comprehensive supplementary materials and theoretical results, which greatly enhance the persuasiveness of the paper."
            },
            "weaknesses": {
                "value": "- It is recommended to evaluate the proposed method on commonly used datasets for category-level pose estimation, such as REAL275 [1] or Wild6D [2].\n\n- It would be beneficial to include relevant works [3,4,5,6] in the paper to provide a comprehensive overview of the existing literature in the field.\n\n[1] Wang et al., Normalized object coordinate space for category-level 6d object pose and size estimation. CVPR2019.\n\n[2] Fu et al., Category-Level 6D Object Pose Estimation in the Wild: A Semi-Supervised Learning Approach and A New Dataset.\n\n[3] Lin et al., Category-level 6D object pose and size estimation using self-supervised deep prior deformation networks. ECCV2022.\n\n[4] He et al., Towards Self-Supervised Category-Level Object Pose and Size Estimation.\n\n[5] Zhang et al., Self-Supervised Geometric Correspondence for Category-Level 6D Object Pose Estimation in the Wild. ICLR2023.\n\n[6] Goodwin et al., Zero-Shot Category-Level Object Pose Estimation. ECCV2022."
            },
            "questions": {
                "value": "- How does 3DUDA address the issue of minimizing the impact of translation and object size on neural feature rendering?\n- What values are set for the number $R$ of vertices of the mesh and the hyperparameter of $N$ of the clutter model? How do they  impact the performance of the method?\n- The format of citations in Table 1 does not align with the citation format used in the rest of the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7928/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7928/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7928/Reviewer_PE77"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7928/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698661116174,
        "cdate": 1698661116174,
        "tmdate": 1699636973633,
        "mdate": 1699636973633,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pLGn1kDCFh",
        "forum": "UPvufoBAIs",
        "replyto": "UPvufoBAIs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7928/Reviewer_xesL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7928/Reviewer_xesL"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the challenge of unsupervised category-level pose estimation in a target domain using only RGB images, without access to source domain data or 3D annotations.\nThe authors introduce a method that adapts to a target domain, even when it is complicated by nuisances, without requiring 3D or depth data.\nThey represent object categories with simple cuboid meshes and use a generative model of neural feature activations at each mesh vertex.\nThey focus on updating local mesh vertex features based on their proximity to corresponding features in the target domain, even when the global pose is incorrect.\nThe key insight is the stability of specific object sub-parts across different scenarios, which allows for effective model updates."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper suggests effective render-and-compare adaptation pipeline for unsupervised domain adaptation for category-level object pose estimation task.\n\n2. Its proposed method shows the state-of-the-art performance in various corruption scenarios compared to some of the previous methods.\n\n3. The methodology part is intuitive and easy to follow text-wise."
            },
            "weaknesses": {
                "value": "1. Poor presentation.\nI think this paper holds good insights and corresponding technological contributions.\nYet, the presentation of the whole paper is relatively poor, making it hard to follow the overall message.\nFigure placement is not well-aligned with the text context.\nFigure 3 seems to be a very important description of explaining one of the main contributions of this paper to match sub-vertices, while there is no mention in the main manuscript referring this.\nMoreover, the main manuscript refers to figures in appendix very often, which is very inconvenient to read, while some of these figures seem important enough to be contained in the main paper for effective description. (ex, Figure 5)\nI believe that ablation studies regarding several design choices of the proposed method should be contained in the main manuscript as well, since they can effectively validate the authors claim."
            },
            "questions": {
                "value": "1. Baseline methods and other datasets\nExcept OOD-CV results, only previous baseline is NeMo. Can the authors explain why there can't be other methods in this comparison? Being better than only one baseline is not enough to claim the superiority of the proposed method.\nAlso, while I acknowledge that the paper mainly focuses on data corruption scenarios, is it possible to compare this type of approach in conventional category-level object pose benchmarks like CAMERA and REAL275 datasets provided by NOCS? I believe it would strengthen the authors' motivation if it can be generally applied to conventional syn-to-real UDA scenarios.\n\n2. GT reliability\nGround truth pose illustrated in Figure 1 and 5 seems to be not perfectly aligned with the image. Can the authors explain how these GTs are obtained, and how they are utilized? Are they only used for evaluation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7928/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7928/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7928/Reviewer_xesL"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7928/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698823388670,
        "cdate": 1698823388670,
        "tmdate": 1700704907651,
        "mdate": 1700704907651,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4Vvnkf9NHC",
        "forum": "UPvufoBAIs",
        "replyto": "UPvufoBAIs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7928/Reviewer_KkCS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7928/Reviewer_KkCS"
        ],
        "content": {
            "summary": {
                "value": "This paper study the problem of source-free unsupervised category-level pose estimation from only RGB images to a target domain without any access to source domain data or 3D annotations during adaptation. The author propose a new pipline which focus on the  individual local mesh vertex features and utilize their pose ambiguity to iteratively update them based on their prox- imity to corresponding features in the target domain even when the global pose is not correct. The proposed method shows good results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method outperform previous approaches by a large margin\n2. The author evaluate their model on real world nuisances like shape, texture, occlusion, etc. as well as image corruptions and show the robustness of proposed method"
            },
            "weaknesses": {
                "value": "1. As mentioned in the article, an observation is that global information is noisy, but some local details are robust. I hope there is rigorous explanation and quantitative analysis here to support this hypothesis.\n2. Ablation is not enough, (e.g., Ablation on top-n \n3. I think this method is similar to the iterative optimization often used in instance-level post-processing. It is unfair to compare this method with other single forward methods.\n4. I'm not sure if it's right to say \"normalized real-valued feature activations\" ? (\nThe fourth line from the bottom of the third page)\n5. The figures in this article are very rough and difficult to understand."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7928/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7928/Reviewer_KkCS",
                    "ICLR.cc/2024/Conference/Submission7928/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7928/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699470426877,
        "cdate": 1699470426877,
        "tmdate": 1700662931351,
        "mdate": 1700662931351,
        "license": "CC BY 4.0",
        "version": 2
    }
]