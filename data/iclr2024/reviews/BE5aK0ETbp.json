[
    {
        "id": "0eDg2D90uk",
        "forum": "BE5aK0ETbp",
        "replyto": "BE5aK0ETbp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3042/Reviewer_KmRA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3042/Reviewer_KmRA"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new objective function for task-based continual learning (TBCL). There are two key contributions: The first one consists in highlighting that all regularisers proposed in regularised-based, memory-replay and Bayesian approaches can be seen as specific instantiations of a Bregman divergence term, thus casting the whole formulation of TBCL into a single overarching objective criterion. The second contribution consists of proposing an additional regulariser to promote generalisation, which is based on the minimisation of the L2 norm of the weighted gradient loss (here, the weight corresponds to the inverse of the Fisher Information matrix computed using the parameters from the previous tasks). A corresponding learning algorithm is proposed based on an alternating minimisation scheme. Indeed, the training algorithm updates the parameters firstly by approximately minimising the gradient loss term (the approximation avoids (i) the computation of the Hessian matrix, as assuming to be an identity, and (ii) it introduces Gaussian noise to promote exploration) and secondly by minimising the cross-entropy on the current task. Experiments on CIFAR-10, CIFAR-100 and Tiny-Imagenet demonstrate the effectiveness of the new regulariser in enhancing the generalisation performance of existing approaches. Consequently, the proposed regulariser effectively complements the ones proposed in the literature of TBCL."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea behind the two contributions is original and novel. Specifically, it is nice to see a unified view of the three classes of TBCL leveraging the general definition of Bregman divergence. Additionally, while the proposed new regulariser is known to increase generalisation in supervised deep learning, as promoting solutions characterised by flat minima [1], its adaptation to the TBCL is novel and non-trivial (**Originality**)\n2. Overall, the paper is quite clear and easy to follow, except for one part (see weaknesses) (**Clarity**)\n3. The solution and the experiments are convincing, demonstrating its benefits (**Significance**)\n\n[1] Penalising Gradient Norm for Efficiently Improving Generalization in Deep Learning. ICML 2022"
            },
            "weaknesses": {
                "value": "1. The main concern I have is with the overstated claim about the introduction of an innovative concept, \u201crefresh learning\u201d. The idea boils down to approximately minimising the weighted gradient norm, known to promote flatness in the achieved minima and therefore to increase generalisation performance. Section 3.3 is a bit handwavy and unclear. Perhaps, it is better to rephrase it directly in terms of gradient penalty as originally proposed in [1] and focus more on its extension to the TBCL setting. This would help to have a clearer understanding and intuition on why the proposed regulariser works (**Quality**).\n2. It would be good to provide the ablation study for all datasets. Indeed how are the hyperparameters chosen in practice and how should practitioners choose them in general? This should help to give a better sense on how sensitive the hyperparameters are on different datasets (**Quality**)\n3. All experiments are conducted on a similar family of natural images. It would be good to see how the proposed approach works on a traditional and more different MNIST-like benchmark (**Quality**)\n4. Code is not available (**Reproducibility**)\n\n**MINOR**\n\nSome typos:\n1. Section 3, remove \u201cIn this section\u201d\n2. Last paragraph page 4 (and also later in page 5) -> the NEGATIVE entropy function\n3. Eq. (5) misses the expectation term in its second addend\n4. Eq. (8) and all occurrences of F -> missing L"
            },
            "questions": {
                "value": "All questions are related to the main weaknesses:\n1. Why not directly minimising the (weighted) gradient penalty? Also, what is the advantage of introducing the Gaussian noise (it would be good to see its necessity in practice)?\n2. Can you provide the complete ablation analysis on all datasets and also include some experiments about MNIST?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3042/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698070473788,
        "cdate": 1698070473788,
        "tmdate": 1699636249756,
        "mdate": 1699636249756,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "epxZkFtL4F",
        "forum": "BE5aK0ETbp",
        "replyto": "BE5aK0ETbp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3042/Reviewer_tVq3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3042/Reviewer_tVq3"
        ],
        "content": {
            "summary": {
                "value": "The paper considers a unified objective that includes prior methods as special cases.\n\nIt further proposes an unlearn-relearn method to minimize the proposed objective function.\n\nNext, there is a short section on theoretical analysis.\n\nFinally, experiments are conducted in comparison to prior methods."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Omitted."
            },
            "weaknesses": {
                "value": "In my opinion, the paper has the following weaknesses:\n- The proposed framework is not very interesting. Basically, it says that prior work has loss functions $L_1,L_2,L_3$, therefore let us propose a unified objective $\\alpha_1L_1 + \\alpha_2 L_2 + \\alpha_3L_3$. In my eyes this proposal is incremental and has limited novelty.\n\n\n- The work is not solid and there are issues with writing. For example:\n   - The first part of the paper (pages 1-5, until section 3.3), appears to be a review of prior works. This is more than half of the main paper. \n   - There are many repetitive sentences. This is just one example (and there are more): There is a long paragraph on page 2 discussing refresh learning, and then a highly similar paragraph appeared on page 6.\n\nI was not very convinced by what the paper argues about over-memorization. But after witnessing the repetitive style of the paper I realized that over-memorization is indeed harmful.\n\nThe theoretical analysis is very informal. I don't see how the theory statement connects to the proofs. The proofs seem to be written in a rush. Please justify that."
            },
            "questions": {
                "value": "I have no specific questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3042/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698587509046,
        "cdate": 1698587509046,
        "tmdate": 1699636249683,
        "mdate": 1699636249683,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4OmNbmtjFY",
        "forum": "BE5aK0ETbp",
        "replyto": "BE5aK0ETbp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3042/Reviewer_Dw6m"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3042/Reviewer_Dw6m"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a unified optimization objective which is capable of encompassing existing CL approaches, including regularization based/Bayesian-based and memory-replay based methods. From the objective, the authors identified a novel method of refresh-learning, which act as a plug-in to augment the performance of CL methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper presents a unified framework for different continual learning methods, and derived a new CL approach from the unified objective. The paper presents detailed theoretical derivations of the algorithm and comprehensive experimental results to demonstrate the advantage of the new method of refresh learning."
            },
            "weaknesses": {
                "value": "For me the more interesting and novel part of the paper is the refresh learning method, its derivation, intuition behind it, and its performance, while the part where the unified approach corresponds to different CL methods in different setup is more expected and easier to follow. I would recommend the authors shorten the part of how the unified objective corresponds to different special cases and further elaborate on refresh learning."
            },
            "questions": {
                "value": "1.Why can't the over-memorization issue be solved by properly tuning the regularization strengths alpha/beta?\n2.Can you provide an intuitive explanation why unlearning the posterior first and relearning a single set of parameters from the unlearned posterior is a good method for encouraging forgetting of outdated information?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3042/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3042/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3042/Reviewer_Dw6m"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3042/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698713889301,
        "cdate": 1698713889301,
        "tmdate": 1699636249612,
        "mdate": 1699636249612,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "F0lwHgwJR8",
        "forum": "BE5aK0ETbp",
        "replyto": "BE5aK0ETbp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3042/Reviewer_ngze"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3042/Reviewer_ngze"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors provide a unified framework for various types of continual learning (CL) algorithms, Specifically, by using Bregman divergence, they show that well-known CL approaches can be viewed as instances of the general objective coming from different parametrization of the Bregman divergence function. Then, they propose a new CL algorithm, which consists of a two-step process: unlearn and relearn. The authors provide empirical results that show the merits of their approach as compared to other relevant CL algorithms."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The unified framework provided by the authors is interesting and sheds light on particular characteristics of existing algorithms.\n- The main idea behind the proposed \"refresh learning\" algorithm seems to be reasonable.\n- The authors integrated their \"refresh learning\" approach to existing algorithms showing empirical results on three different datasets."
            },
            "weaknesses": {
                "value": "- The first part of the paper (unified framework) seems to be unrelated to the second one (Refresh learning algorithm). \n- The refresh learning objective eqs (12), (13) is insufficiently motivated.\n- It's not clear why unlearning should be enforced on the current batch. The authors do not provide any motivation. \n- The conversion of the constraint to a PDE is not obvious to me and is not sufficiently explained in the paper.\n- The refresh learning algorithm ends up in a preconditioned ascent followed by a decent step. But the descent step seems to be applied in a different loss (??) (eq. 6 in Algorithm 1). This is a bit confusing.\n- The authors integrate the proposed algorithm into various existing schemes. However, this is arbitrarily introduced in the experimental section only, and not clear how this integration can naturally arise from the problem introduced in section 3.3 or the unified CL framework of section 3.2.\n\n** Post-rebuttal comment: I appreciate the authors' efforts to address my concerns. The revised version of the paper has now been improved. The proposed refresh learning framework is better motivated and the derivations provided by the authors make the paper easy to follow. Therefore, I have decided to increase my score."
            },
            "questions": {
                "value": "- Could the proposed refresh learning algorithm be derived by the unified CL framework?\n- Why energy functional is defined as in (13)? Could you please provide more intuition? Are there any other ways to promote unlearning?\n- What is the loss function in eq. (6) of Algorithm 1?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3042/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3042/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3042/Reviewer_ngze"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3042/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699425816415,
        "cdate": 1699425816415,
        "tmdate": 1700758909441,
        "mdate": 1700758909441,
        "license": "CC BY 4.0",
        "version": 2
    }
]