[
    {
        "id": "NCiNYhz8Yc",
        "forum": "A6kK5e3DhR",
        "replyto": "A6kK5e3DhR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8169/Reviewer_Umbq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8169/Reviewer_Umbq"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes VAE-based deep generative models for controllable data generation. The problem setups are defined as follows: given data $x\\in\\mathbb{R}^n$, $K$ different property interests $y\\in \\mathbb{R}^K$, and underlying mapping function $f: x \\in \\mathbb{R}^n \\mapsto y \\in \\mathbb{R}^K$, the goal of this paper is to learn deep generative models $g_{\\theta, \\gamma}: y \\in \\mathbb{R}^K \\mapsto x \\in \\mathbb{R}^n$. Specifically, this paper tackles remaining challenges of those deep generative model: 1) disentangling desired properties with unrelated latent variables, 2) out-of-distribution property control, and 3) objective optimization for out-of-distribution property control. To overcome these challenges, this paper proposes several objectives and self-training procedure of the deep generative models. The experimental results domonstrate the proposed method consistently provide better trade-off between overall quality and property for generated samples for several controllable generation tasks."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper overally well-written and easy-to-follow. Figure 2 provide much information for understanding the proposed overall framework.\n\n- The proposed method has a plug-in-play property for any VAE framework.\n\n- The experimental results have shown the proposed method consistently improves various VAE frameworks."
            },
            "weaknesses": {
                "value": "- This paper has a severe problem for deriving the training objective of $\\mathcal{L}_2$. Here,  $\\mathcal{L}_2 = \\mathbb{E}_q[-\\log p(y|x)] = \\int - q(z, w|x, y) \\log p(y|x) dz dw = - \\log p(Y=y|X=x)$, where $x, y \\in \\mathcal{X}_1, \\mathcal{Y}_1 $ are real samples but not generated one. This is because $-\\log p(Y=y|X=x)$ This term is then just constant since it does not depend on any parameters $\\theta, \\phi, \\gamma$.\n\n- For the above reason, the proposed generative model does not maximize the variational lowerbound of the joint likelihood $p(x, y)$. This does not guarantee sample generation quality of the generative models."
            },
            "questions": {
                "value": "- If I understand this paper correctly, this paper assumes that underlying property predictor $f: x \\in \\mathbb{R}^n \\mapsto y \\in \\mathbb{R}^K$ exists. Is this correct? If so, how do we get this function? e.g., training neural network-based $f$ using given data."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8169/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8169/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8169/Reviewer_Umbq"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698641574969,
        "cdate": 1698641574969,
        "tmdate": 1699637013003,
        "mdate": 1699637013003,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "f2nKO5l62D",
        "forum": "A6kK5e3DhR",
        "replyto": "A6kK5e3DhR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8169/Reviewer_YxqT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8169/Reviewer_YxqT"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to address several challenges in controllable data generation. \nThey propose a novel generic framework that employs a series of VAE-based models and control parameters to produce data tailored to specific needs. \nThis framework can ensure the precision of both in-distribution and out-of-distribution property control and the disentanglement between the controlled properties and the unrelated latent variables. \nThrough a series of experiments, the authors demonstrate the efficacy of their approach in various applications, from image synthesis to molecule generation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. **Innovative Approach:** \nThe framework enhances VAE-based generators with better property controllability and ensures superior disentanglement, offering a new perspective on data generation.\n\nS2. **Versatility:** \nThe proposed framework is shown to be applicable in different VAE models and multiple domains, from images to molecules, suggesting its broad utility.\n\nS3. **Supporting Out-of-Distribution Property Control:**\nThrough designing new objective functions and optimization strategies, their framework can support seen and unseen data properties, which is particularly beneficial in scenarios where data is scarce."
            },
            "weaknesses": {
                "value": "W1. **Increased Complexity:**\nThe proposed approach, while comprehensive, seems to add multiple components and constraints to the training process. This complexity might make it difficult for practitioners to adapt and integrate the framework into existing pipelines. Furthermore, the merger of control parameters with generative models could complicate model design, training, and deployment. \n\nW2. **Scalability Concerns:** \nThe iterative training procedure, while innovative, might raise questions about scalability and computational efficiency when applied to large-scale datasets. Some insights or experiments on how the framework scales with data size or complexity would be valuable for potential users.\n\nW3. **Diverse Datasets Testing:**\nThe method's robustness and generalizability could be further validated by testing on diverse datasets. Specifically, they could employ datasets with intricate features (like human facial datasets) to further validate the claim of disentanglement between the controlled properties and the unrelated latent variables.\n\nW4. **Limited Competitor Analysis:** \nWhile the authors compare their methods with existing VAE-based generation models, it would strengthen the paper if more competitors, especially advanced disentangled VAEs were incorporated into the analysis, such as:\n\n* Joy, T., S. Schmon, P. Torr, S. Narayanaswamy, and T. Rainforth. \"Capturing label characteristics in VAEs.\" In ICLR, 2021.\n* Ren, Yurui, Ge Li, Yuanqi Chen, Thomas H. Li, and Shan Liu. \"Pirenderer: Controllable portrait image generation via semantic neural rendering.\" In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 13759-13768. 2021.\n* Wang, Shiyu, Xiaojie Guo, Xuanyang Lin, Bo Pan, Yuanqi Du, Yinkai Wang, Yanfang Ye et al. \"Multi-objective Deep Data Generation with Correlated Property Control.\" Advances in Neural Information Processing Systems 35 (2022): 28889-28901."
            },
            "questions": {
                "value": "Q1: This paper could benefit from a more in-depth discussion of how the method generalizes to other untested scenarios or different data domains.\n\nQ2: Given the iterative nature of the training process, how does the method perform with large-scale datasets both in terms of computational efficiency and final output quality?\n\nQ3: Can the authors consider testing the methods on human facial datasets like FFHQ1024 or CelebA?\n* FFHQ1024: https://github.com/NVlabs/ffhq-dataset, https://github.com/DCGM/ffhq-features-dataset\n* CelebA: https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698764626932,
        "cdate": 1698764626932,
        "tmdate": 1699637012899,
        "mdate": 1699637012899,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xjDlGPf6lQ",
        "forum": "A6kK5e3DhR",
        "replyto": "A6kK5e3DhR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8169/Reviewer_UtY6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8169/Reviewer_UtY6"
        ],
        "content": {
            "summary": {
                "value": "The authors have introduced a new approach to controlled data generation using a variational auto-encoder. The primary objective of this method is to generate output with semantically meaningful control over specific data properties. This is done by learning a mapping function, which maps the desired property to the associated latent vectors. Authors further ensure that the influence of a change in one property (y) is independent of others during data generation by ensuring independence in the sampled latent vector (z) and the desired property (y) of the generated data. Furthermore, they propose techniques for incorporating out-of-distribution properties into the data generation process by considering different values for the properties (y) and incorporating the generated data into the overall training process."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Strengths : \n1. The concept of generating output with out-of-distribution properties has a broad range of applications and can be utilized to create previously unseen data for various downstream tasks.   \n2. The paper is well-written and easy to follow. It provides a thorough assessment of the limitations in prior works and demonstrates how the proposed method tackles these shortcomings.\n3. The authors introduced a novel loss function to guarantee disentanglement among the desired properties."
            },
            "weaknesses": {
                "value": "Major Comments : \n1. The authors have proposed generating the latent vector (w) associated with a given property by utilizing both the sampled latent factor (z) and the desired property (y). However, the rationale for incorporating (z) in this mapping function remains unclear, particularly given that prior works[1] in the field have only used y. It is important for the authors to provide an explanation for why both z and y are considered in the mapping function and elucidate their impact on the overall results.\n\n2. The authors should clarify the impact of choosing different values of y on the quality of the generated output, especially when the selected values for properties (y) deviate significantly from the original dataset.\n\n3. It seems that the authors have incorporated out-of-distribution data in a manner that resembles various data augmentation techniques, like Mixup [2], aimed at improving performance. While they have demonstrated the potential of this method for generating new molecules, conducting similar experiments on datasets such as dsprites, 3D shapes, and other real-world datasets would provide valuable insights into the impact and advantages of this strategy for generating new data, as opposed to generating intermediate data points in interpolation.\n\n4. The utilization of various constraints in the overall training of the model lacks clarity in the paper. The authors should provide more comprehensive details about these constraints and explain how they influence the overall results.\n\n5. The authors should provide clear notational explanations for terms like \"e,\" particularly in the context of L4 (loss), to enhance the reader's understanding.\n\n6. The authors have provided information on how well their proposed method preserves the desired properties in the generated output. However, there is a lack of information regarding the impact on the quality of the generated images and molecules. It would be beneficial for readers to have a quantitative evaluation of these aspects, especially after incorporating out-of-distribution data during the training process.\n\n7. Authors should clarify the prior distribution used for 'w' and 'z' in the overall optimization.\n\n8.  There has been a lot of literature discussion around the impossibility of learning disentangled representation in an unsupervised manner.  The Authors have missed a seminal work in this direction [3]. This work has to be discussed and the current paper has to be positioned correctly in that context (despite the focus of this paper is not a fully unsupervised learning). \n\n9. There has been work on disentangled learning beyond datasets such as Dsprites. For instance, real-world datasets, that have attributs can be considered to test the proposed idea. I recommend the Authors to consider such experiments, especially given the cliam regarding the \"precisely controlling the properties of generated data\". \n\n10. There is a very closely related work that claims to do a similar type of stuff detailed in [4].\n\nReferences:\n[1] Guo, Xiaojie, Yuanqi Du, and Liang Zhao. \"Property controllable variational autoencoder via invertible mutual dependence.\" International Conference on Learning Representations. 2020.\n[2] Taghanaki, Saeid Asgari, et al. \"Jigsaw-vae: Towards balancing features in variational autoencoders.\" arXiv preprint arXiv:2005.05496 (2020).\n[3] Locatello F, Bauer S, Lucic M, Raetsch G, Gelly S, Sch\u00f6lkopf B, Bachem O. Challenging common assumptions in the unsupervised learning of disentangled representations. In international conference on machine learning 2019 May 24 (pp. 4114-4124). PMLR.\n[4] Mondal, Arnab Kumar, Ajay Sailopal, Parag Singla, and Prathosh Ap. \"SSDMM-VAE: variational multi-modal disentangled representation learning.\" Applied Intelligence 53, no. 7 (2023): 8467-8481."
            },
            "questions": {
                "value": "Please see the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698769774120,
        "cdate": 1698769774120,
        "tmdate": 1699637012788,
        "mdate": 1699637012788,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9ezL0LzveR",
        "forum": "A6kK5e3DhR",
        "replyto": "A6kK5e3DhR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8169/Reviewer_rFTY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8169/Reviewer_rFTY"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel framework for controllable data generation that enhances Variational Autoencoder (VAE)-based generative models with property controllability and disentanglement. This framework features a shared backbone and customizable module, making it adaptable to different model assumptions. The authors extend the traditional objective function to encompass both in-distribution and out-of-distribution data, enabling the model to generate data with desired properties, even in unseen ranges.It also outlines an effective training procedure that optimizes the model by iteratively mapping data and properties, including those not encountered during training, further improving the model's controllable data generation capabilities."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Disentanglement within the framework appears to be somewhat effective, demonstrating the model's ability to separate and control specific properties or features in the generated data in certain instances. However, the degree to which this disentanglement consistently holds or the specific conditions under which it succeeds remain topics of interest for further investigation.\n\nDespite the framework's potential, it is notably challenging to identify and pinpoint any consistently meaningful strengths. The versatility and reliability of the model's property controllability, disentanglement, or other capabilities may require more in-depth exploration and refinement to harness its full potential."
            },
            "weaknesses": {
                "value": "The significance of this work becomes apparent when considering it in the context of state-of-the-art generative models. There is a clear need for this investigation to ascertain how the proposed framework contributes to the field and whether it offers substantial improvements or unique capabilities compared to existing models.\n\nThe presentation of the work, unfortunately, poses challenges in terms of its clarity and comprehensibility. It is evident that the way the research findings and methodology are conveyed may need refinement to enhance accessibility and ease of understanding for readers.\n\nThe unnecessary introduction of mathematical operators, which may not directly enhance the quality of the contribution, can potentially obscure the core concepts and findings of the research. Simplifying and streamlining the presentation might be beneficial.\n\nA notable concern is the utilization of extremely low-quality datasets with limited relevance. This choice could potentially hinder the model's effectiveness and real-world applicability. The inclusion of more representative and high-quality datasets may be crucial to improve the robustness and practicality of the framework."
            },
            "questions": {
                "value": "Drawing meaningful comparisons between the framework presented in this work and Mathieu et al.'s \"Disentangling Disentanglement in Variational Autoencoders\" is a promising avenue for research. This exploration could shed light on how the proposed framework either builds upon or differs from the prior work, particularly in terms of disentangling capabilities within Variational Autoencoders."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8169/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698799519447,
        "cdate": 1698799519447,
        "tmdate": 1699637012683,
        "mdate": 1699637012683,
        "license": "CC BY 4.0",
        "version": 2
    }
]