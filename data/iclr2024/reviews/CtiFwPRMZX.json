[
    {
        "id": "uEDHkq3RFa",
        "forum": "CtiFwPRMZX",
        "replyto": "CtiFwPRMZX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6475/Reviewer_s2iN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6475/Reviewer_s2iN"
        ],
        "content": {
            "summary": {
                "value": "The idea of the paper is to connect flatness as a generalization metric and representation compression (like in neural collapse phenomena). The authors point out that these two metrics are investigated as indicators of good generalization, but there were not connected to each other before. The authors concentrate on the interpolation regime when a neural network has reached minimal loss and derive a boundary on particular form of volume of the representations with a particular measure of flatness. An empirical investigation on VGG10 and CIFAR10 dataset demonstrated the reduction in volume and (mostly) sharpness."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Connection of flatness, as well as compression (in a sense of neural collapse conjecture) to the generalization abilities of models is an important research area. Interconnection between possible generalization metrics can prove to be useful in deriving unified understanding of generalization in neural networks."
            },
            "weaknesses": {
                "value": "The paper gives an impression of an unfinished work. It is not clearly signified which of the derivations are novel contributions and which are reproducing the existing research. The experimental evaluation is very limited and not fully showing the correctness/tightness of the bound presented.\n\nEven with the assumption that trace of the Hessian is indeed a good generalization indicator (which was disproven by Dinh et al.), the discussion in the beginning of section 2 is very imprecise. If the loss indeed reaches the point of zero value and its derivatives are zero, SGD would not change the solution anymore - just by definition. The referenced works take into account label noise for example, that allows for further dynamic of the optimization even after reaching a minimal loss. Therefore the theoretical justification of the bounds is ill-posed and it also does not connect to the experiments performed, since there network there does not achieve 0 loss and 0 gradients (which should effectively stop the changes of the model).\n\nThe observations made in section 4.2 are basically showing that the derived boundary is extremely imprecise, which to some extent diminishes its value.\n\nMinor:\n\n- the positioning of images makes it very hard to follow the text and description of the experiments, they should be moved closer to the part where they are described\n\n- short mention of possible perspective through the lens of entropy (in the end of section3) should be either elaborated more or removed, because currently it is much more confusing\n\n- eq. 14 is introduced in the very end of the paper, while being used in all the experimental section which makes reading unnecessarily hard"
            },
            "questions": {
                "value": "1 - What model of SGD dynamics do you have in mind when using terms \"second phase\" and \"interpolation regime\"?\n\n2 - How the used volume connects to the representation collapse?\n\n3 - What is the additional metric introduced in the last section of the paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698412567233,
        "cdate": 1698412567233,
        "tmdate": 1699636724854,
        "mdate": 1699636724854,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mq4pk7JaOj",
        "forum": "CtiFwPRMZX",
        "replyto": "CtiFwPRMZX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6475/Reviewer_Km7j"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6475/Reviewer_Km7j"
        ],
        "content": {
            "summary": {
                "value": "The authors study the interplay between 1) the flatness of the loss landscape at minima found during training, and 2) dimensionality of learned neural representations.  Building on Ying and Ma, the authors prove that flatter minima in the loss imply an upper bound on the volume occupied by neural representations. Experiments on a (simplified) image classification task confirm their analysis."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Originality:\n\nThe authors draw an original connection between two major concepts: flatness of loss landscapes and compression of representations.  These ideas have been studied independently quite thoroughly, but this thread is, to my knowledge, new.  Further, their experimental analysis bolsters support to this thread.\n\nQuality/clarity:\n\nThe proofs and empirical studies were, to my eye, rigorous, clear, and thorough.\nThe paper is clearly structured, easy to follow, and provides intuitive explanations.\nThe authors clearly acknowledge the limitations of their work.\n\nSignificance:\n\nThis work is another solid contribution to the ongoing research thread of trying to understand the connection/interplay between flatness/sharpness and generalization."
            },
            "weaknesses": {
                "value": "Not that this work is particularly weak, but there could probably be more empirical analysis.  I'd love to see the analysis repeated for additional learning problems, beyond the simple classification problem studied."
            },
            "questions": {
                "value": "No questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698442455418,
        "cdate": 1698442455418,
        "tmdate": 1699636724731,
        "mdate": 1699636724731,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lwRZVGgsbx",
        "forum": "CtiFwPRMZX",
        "replyto": "CtiFwPRMZX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6475/Reviewer_Hwwc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6475/Reviewer_Hwwc"
        ],
        "content": {
            "summary": {
                "value": "The paper explores the correlation between the sharpness of minima and the corresponding representation manifold volume. The authors show, theoretically as well as experimentally, that in the last stage of training, when the loss is zero, further training leads to (1) flatter minima, which correspond to (2) a more compressed representation of inputs. As such, authors provide further theoretical and empirical support for an existing understanding of generalisation behaviour in neural networks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This is a well-written paper on a very relevant topic. Authors do not rely on solely the theory or the experiments, but rather bring the two together to build a stronger argument.\n\n**Originality:** Authors propose the idea that flatness of discovered minima correlates with the amount of compression of the inputs. Many studies claim that flatness is correlated with better generalisation, and this paper provides a perspective that may explain this known correlation. Although the idea that compression leads to improved representations is not novel on its own, I have not encountered works that have explicitly linked it to minima flatness.\n\n**Quality and clarity:** The paper is very well-written and easy to follow. The experiments are not extensive, but are well-designed. \n\n**Significance:** I believe the topic of generalisation in NNs to be extremely relevant, thus any insight into the dynamics of training that lead to improved generalisation are significant. The paper brings together a few existing seminal works, and elegantly ties them together. An important contribution is the suggestion to consider parameter space alongside the feature space, which is rarely done in practice."
            },
            "weaknesses": {
                "value": "The authors consider Hessian eigenvalue magnitudes as the only measure of sharpness. This seems limiting, as recent studies (Yang, L. Hodgkinson, R. Theisen, J. Zou, J. E. Gonzalez, K. Ramchan- dran, and M. W. Mahoney, \u201cTaxonomizing local versus global structure in neural network loss landscapes,\u201d) have shown that Hessian trace may be more closely related to ruggedness of the landscape rather than sharpness of the basin, due to the fact that the Hessian is approximated locally and does not consider the neighborhood of a solution. In fact, the authors state in a few places that sharpness (as measured by the eigenvalues) may not be sufficient to explain the manifold volume reduction.\n\nExperimentation is convincing, although somewhat limited. Only a single CNN architecture is considered. Since fundamental questions are being asked, wouldn\u2019t it make sense to include a standard MLP in the experiments?"
            },
            "questions": {
                "value": "Formatting: equations are referred to as \u201cequation N\u201d and \u201cEq. (N)\u201d interchangeably. Please use the latter format. Figure references are not always appropriately enclosed in parenthesis.\n\nPlacement of figures: Figures 1 and 2 are placed very early in the document, and the reader is expected to \u201cpage back\u201d to inspect the figures when they are eventually discussed in the text. While this is a minor inconvenience, I still believe the paper would be more pleasant to read if the figures were placed as close to their first mention in the text as possible.\n\nThe paper is written from the standpoint that flatness is an indication of better generalisation. However, this is not a fact, but rather a hypothesis, and should not be treated as an axiom. See, for example, https://arxiv.org/abs/2302.07011, where the relationship between sharpness and generalisation is challenged for modern NN architectures. I would appreciate it if authors could comment on this aspect, and perhaps include a discussion of the open-endedness of sharpness VS generalisation question in the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698596327391,
        "cdate": 1698596327391,
        "tmdate": 1699636724595,
        "mdate": 1699636724595,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cDcCANZUcw",
        "forum": "CtiFwPRMZX",
        "replyto": "CtiFwPRMZX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6475/Reviewer_Wiq9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6475/Reviewer_Wiq9"
        ],
        "content": {
            "summary": {
                "value": "The paper tries to connect loss landscape flatness with generalization, along with compression. It has some theoretical results, and some experiments backing it."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper studies an interesting avenue of different effects in neural network dynamics, and tries to connect between them in an interesting way. It has some theoretical guarantees, and presents some experimental results."
            },
            "weaknesses": {
                "value": "** The paper is not well presented. The text is not clear, and the figures are not well presented**\nThe text has many mistakes, many things are well explained. \n\nBellow are a few of many comments on the text presentation\n1. L73 : The Frobenius norm is defined yet it is not clear for what.\n2. L94: \"Let W be the input weights to the network, and \u03b8\u00af the corresponding set of parameters.\" - it is not clear what W (\"Input Weights\") is.\n3. L112: This amounts to asking whether the transformation of the differential volume around x\u00af is an expansion or a contraction: This is problematic in my opinion, as NN often change the dimensions between layers, and this is not incapsulated in this measure as far as I understand. \n4. \"The interpolation phase\" - is usually used for the phase of zero **error** not zero loss (e.g. Neural Collapse literature).\n5. Figure 1 is extremely not clear. The caption is even misleading, as \"From left to right\" does not include the Train loss. \n\n\n**Missing Literature:**\n\n[1] Ben-Shaul, I. &amp; Dekel, S.. (2022). Nearest Class-Center Simplification through Intermediate Layers. <i>Proceedings of Topological, Algebraic, and Geometric Learning Workshops 2022</i>, in <i>Proceedings of Machine Learning Research</i> 196:37-47 Available from https://proceedings.mlr.press/v196/ben-shaul22a.html.\n\n[2] Ben-Shaul, I., Shwartz-Ziv, R., Galanti, T., Dekel, S., & LeCun, Y.  Reverse Engineering Self-Supervised Learning. In Proceedings of the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023).\n\n[3]  Rangamani, A., Lindegaard, M., Galanti, T. &amp; Poggio, T.A.. (2023). Feature learning in deep classifiers through Intermediate Neural Collapse. <i>Proceedings of the 40th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 202:28729-28745 Available from https://proceedings.mlr.press/v202/rangamani23a.html.\n\n[4] Gamaleldin F. Elsayed, Dilip Krishnan, Hossein Mobahi, Kevin Regan, and Samy Bengio. Large margin deep networks for classification. In NeurIPS, 2018.\n\n[5] Galanti, T., Galanti, L., & Ben-Shaul, I. (2023). Comparative Generalization Bounds for Deep Neural Networks. Transactions on Machine Learning Research, (ISSN 2835-8856)."
            },
            "questions": {
                "value": "I think adding much more experimental evidence of the effects, explaining them more thoroughly, and well would improve the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6475/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698782630359,
        "cdate": 1698782630359,
        "tmdate": 1699636724482,
        "mdate": 1699636724482,
        "license": "CC BY 4.0",
        "version": 2
    }
]