[
    {
        "id": "CDrfm7HKzH",
        "forum": "80faVLl6ji",
        "replyto": "80faVLl6ji",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission125/Reviewer_DPfm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission125/Reviewer_DPfm"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to use kinematic phrases as a quantifiable way of judging human motion. Kinematic phrases are defined as objective facts based on the state and relationship between human body parts. A VAE-based model for KP is learned to align motion latent space with KP latent space, which is then used for tasks such as motion interpolation, modification, and generation. Experiments show that using KP as a representation aids in objective motion understanding while using KP as a criterion serves as a better way to judge motion generation quality."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- I find the formulation of KP as a motion representation refreshing and intuitive. It provides a quantifiable way to judge motion and serves as a much-needed metric for human motion generation. While the community has made significant progress, it appears that the current metrics are not quite indicative of the models' performances.\n    - The design of KP seems well-principled and well-thought-out. Using indicator signs to show the rough trend of the motion and compressing a continuous space of kinematic motion to a 403-bit value could be a powerful way to compress the \"essence\" of motion.\n    - KP provides a very quantifiable way to connect high-level semantics with low-level motion facts. It can serve as the bridge between kinematic motion sequences and high-level human descriptions and commands.\n    - The result on KPG (Table 2) shows that the current human motion generation method falls far short in generating accurate semantically correct human motion. A ~50% success rate shows that current popular methods, while they can generate high-quality motion, lack a deeper understanding of phrases and motion.\n- The proposed KP-guided motion generation method achieves state-of-the-art results in motion interpolation and generation."
            },
            "weaknesses": {
                "value": "- I find the lack of more analysis on current models and their failure modes on the KPG benchmark a missed opportunity. What are the main failure modes these methods are failing on and which part is the proposed method winning at? The analysis could provide far more valuable insight into the current human motion generation community, while the FID and diversity tell very little.\n- More qualitative result on using the proposed KP and motion VAE method is needed for better assessment of the proposed method. The provided results are very short and not super informative. No qualitative result is provided for the motion interpolation and modification tasks."
            },
            "questions": {
                "value": "- Are all the models (MDM/MotionGPT/etc.) trained with the same data? Is the KP-guided joint latent space trained on all the data in Table 1 or similar to prior methods?\n- I do find the proposed method the weaker link in the submission. Not enough information and intuition are provided for the proposed method and no supplemental materials are provided. How is the alignment done? How does $D_m$ and $D_p$ take an arbitrary combination of $z_m$ and $z_p$ as input? How is the interpolation done based on the output latent codes?\n- I am willing to raise my score if more analysis on thee current models and their failure modes on the KPG benchmark could be provided, as well as some more insight into the qualitative performance of the proposed method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission125/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698633731659,
        "cdate": 1698633731659,
        "tmdate": 1699635938160,
        "mdate": 1699635938160,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sIybVohKH5",
        "forum": "80faVLl6ji",
        "replyto": "80faVLl6ji",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission125/Reviewer_HZyv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission125/Reviewer_HZyv"
        ],
        "content": {
            "summary": {
                "value": "This work proposes an intermediate human motion representation based on hand-crafted features with the goal to bridge the gap between human motion and action descriptions. This representation can be used for various tasks such as motion interpolation and motion generation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors propose a deterministic and easy to replicate approach to extract low-level features from human motion. The features are generally well-described in Section 3.1 and Figure 2 aids in understanding."
            },
            "weaknesses": {
                "value": "The claim that \u201cKinematic Phrases\u201d bridges the gap between human motion and action is over-selling the paper: one could imagine a person either (1) slightly hammering (slight up-down motion of wrist) or (2) swiping through a book (slight left-right motion of wrist) while standing perfectly still and the proposed KP would not pick up the difference due to the small motion - this has also been acknowledged by the authors in the Discussion. The advantages of textual descriptions of motion or of action labels is that they are easy for humans to understand: while KPs are easier to understand that directly looking at joint angles they are much more difficult to interpret than language and generating novel and sensible KPs from scratch sounds difficult for a human to do without tools.\n\n\nSome information is missing, for example: In 3.1. the authors define various sets of Kinematic Phrases (36 PPs, 242 PRPPs, 81 PDPs, etc) - where do those numbers come from? \n\nKP as evaluation alternative to common methods such as FID is also questionable: Even broken and unrealistic human motion would produce \u201cvalid\u201d KP that would be difficult to differentiate from valid sequences.\n\nI strongly suggest the Authors to use Equations on separate lines when describing the models in 4.2.\n\nMinor issues:\n* On Page 3 $r^f = r^r \\times r^r$ should be $r^f = r^r \\times r^u$\n* It is a bit unclear in 3.1 what the \u201cPhrase\u201d is exactly: is it the sign or is it the signal"
            },
            "questions": {
                "value": "* What is the \u201chuman cognitive view\u201d on Page 3?\n* It seems that the authors approach could be useful for approaches such as nearest neighbor: did the authors experiment with those approaches i.e. for action recognition or motion to text?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission125/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission125/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission125/Reviewer_HZyv"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission125/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698790268060,
        "cdate": 1698790268060,
        "tmdate": 1699635938050,
        "mdate": 1699635938050,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DfPgq4RiPB",
        "forum": "80faVLl6ji",
        "replyto": "80faVLl6ji",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission125/Reviewer_537a"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission125/Reviewer_537a"
        ],
        "content": {
            "summary": {
                "value": "This paper presents Kinematic Phrases, a set of motion features extracted based on manually defined rules, which is claimed to enhance motion interpretability to bridge the gap and tackle the many-to-many problem between human motion and action semantics. Based on KP, the paper introduces KPG as a benchmark to evaluate whether a generated motion is consistent with particular action semantics."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The introduction to this paper is well thought out and motivated. Modeling many-to-many mappings between motion and semantics is challenging and interpretability has not been well addressed in this area.\n\nThe evaluation results show the merits of the proposed approach, but weakness is also revealed (see below)."
            },
            "weaknesses": {
                "value": "Considering that the proposed method does not perform as well as the diffusion-based baseline method on most of the standard metrics, the method also only slightly outperforms the baseline method in the user study by more than between 0.01 and 0.04, which means that on average maybe just 5 out of 200 sequences show better quality in terms of motion semantics. This result may not be strong enough to support the paper.\n\nI would also suggest that the paper provide some qualitative results with their corresponding standard metrics values to show that the paper's methodology generates movements that are indeed more semantically correct, whereas the metrics show the opposite. The KPG could be used and the accuracy compared to the above results to provide further evidence."
            },
            "questions": {
                "value": "I wonder how to make a motion modification exactly, given another description (as shown in Figure 6), how to modify that phrase to another phrase corresponding to the description. In Figure 3,  seems some frames of phrase C are just masked out.\n\nI think the description of KPG evaluation in section 5 is a bit unclear. what exactly is c_i and how is c_i \\in C_i calculated. For example, it would be good to list their shapes\n\nHow KP handles ambiguity in the time dimension. While the discussion mentions amplitude and velocity constraints. For example, \"the left eye is in front of the right eye and then behind the right eye\", this would actually lead to a completely different phrase\n\nOverall, the author's response to the concerns in the Weaknesses and questions is needed to make the final decision. I am happy to increase the rating if my concerns are addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission125/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission125/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission125/Reviewer_537a"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission125/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698825194091,
        "cdate": 1698825194091,
        "tmdate": 1699635937984,
        "mdate": 1699635937984,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YiYDBOCXVC",
        "forum": "80faVLl6ji",
        "replyto": "80faVLl6ji",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission125/Reviewer_87dC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission125/Reviewer_87dC"
        ],
        "content": {
            "summary": {
                "value": "The objective of the work is to fill the gap between motion and action semantics by proposing Kinematic Phrases, and intermediate, interpretable representation that focuses on kinematic facts. The authors state they construct a unified large-scale motion knowledge base, and then learn with self-supervision a motion-KP joint latent space that is later used for different target tasks: (i) motion interpolation, (ii) motion modification, and (iii) generation. Furthermore, they propose a benchmark called Kinematic Prompts Generation. \nThe experimental evaluation is performed on a public dataset and comparison with alternative approaches are reported."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper addresses an important point: the gap between raw motion data and action semantics, which negatively affects the ability of automatic methods to evaluate the quality of their results. The approach is fairly motivated and a discussion on existing approaches that should help better place the proposed method is reported. \nThe experiments seem extensive and cover the different tasks the authors propose. An ablation study is also reported. Details on the training procedure are provided, to favour the reproducibility of the main results."
            },
            "weaknesses": {
                "value": "I do not find the reading particularly easy and clear. There are some parts that are very dense in technical details and/or that make reference to previous approaches. Indeed, the paper strongly relies on previous works and is not fully self-contained. While of course, this is understandable, I would suggest the authors be sure that at least the minimal information to understand and appreciate the work is included (just as an example: the meaning of the metrics in Tab. 3). \n\nI am not sure I fully understood the placement with respect to the literature: in what sense does the proposed method advance the state-of-art?\n\nI find that one of the main target tasks for this work, i.e. motion generation, should be better clarified from the very beginning, in the introduction (the impression that I have is that it becomes clear just after a while, by reading the next sections).\n\nThe authors state their task is motion understanding, but in my opinion, they should be more specific: all the examples refer to walking sequences as if there was a particular interest in them. Nevertheless, the datasets employed in the experimental evaluation seem more rich. Some examples of different motions might help better identify the setting and the problem of interest.\n\nThe figures are not always enough explanatory. For instance, while Figure 2 is very clear, from Fig. 1 I would expect to have a better focus on what the authors mean when they say that there is a significant gap between motion and action semantics, but it is not clear to me"
            },
            "questions": {
                "value": "In addition to my comments above, I report here some more questions I have, hoping this may help to improve the readability and understanding of the method:\n\n- \"For objectivity and actuality, KP captures sign changes with minimal pre-defined standards\" I am not sure I understand this statement\n- \"KP offers proper abstraction, which disentangles motion perturbations and semantics changes\"  How is it assessed in the experiments?\n- The initial part of Sect. 3.1, where the amount of KP of each type is introduced, is a bit unclear to me. How such numbers are derived?\n- \u201c...we limit the criteria of KP as the indicator signs to minimize the need for human-defined standards (e.g., numerical criteria on the closeness of two joints) for objectivity and actuality \u201c I can not understand this statement\n- When describing the way the different types of KP are extracted, it is often reported: \u201cAfter filtering...\u201d. However, I missed what this filtering is\n- I am not sure I understand the difference between PRPP and LOP, the formula is apparently the same\n- Sec. 4.1: are these preliminaries reporting things already introduced in the previous sections? How are they related to them?\n- The description in \u201cModel structure\u201d in Sect. 4.2 is a bit dense and technical, I\u2019m not sure it favours the understanding of a reader not fully familiar with the tools\n- Self-supervision: I did not get how the self-supervised approach is designed (in particular, what is the task to be addressed for the self-supervision)\n- \"Moreover, most current motion generation evaluations are performed on datasets (Guo et al., 2022a; Plappert et al., 2016; Ji et al., 2018) with considerable complex everyday actions, further increasing the difficulty. \" This should be better justified: in what sense the proposed approach is an advancement? And how it would extend to more complex actions?\n- I fail to understand how the accuracy is computed. Giving an intuition, maybe with an example, would be beneficial \n- \u201cFor each prompt, we generate one sample considering the annotation cost. We claim that the models should generate natural text-matching motion most of the time so that the one-sample setting would not hurt the fidelity of our user study.\u201d I might misunderstand the statement, but I don\u2019t think just one sample is enough to make considerations on the general behaviour of the method\n- In Tab. 5 the performance w/o Body KS seems slightly better on the accuracy. It would be interesting to provide a comment on that"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission125/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699028282050,
        "cdate": 1699028282050,
        "tmdate": 1699635937914,
        "mdate": 1699635937914,
        "license": "CC BY 4.0",
        "version": 2
    }
]