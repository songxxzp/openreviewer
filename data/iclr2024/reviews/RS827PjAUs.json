[
    {
        "id": "P6o9vnybvi",
        "forum": "RS827PjAUs",
        "replyto": "RS827PjAUs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3320/Reviewer_DyDT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3320/Reviewer_DyDT"
        ],
        "content": {
            "summary": {
                "value": "While showing revolutionary abilties in classical language sequences processing, Large Lanuage Models fall short at processing protein sequences, for example, protein function annotation. This paper makes effort to allow LLMs work better in protein processing tasks.\n\nThe authors claim the main challenge lies on the corpus diffenrence between the areas of human and protein languages.\nTo align the two languages, the authors propose (1) incrementally pre-training a LLM using both protein corpus and text corpus and (2) supervised instruction tuning LLMs by collecting and utilizing a knowledge-graph-enhanced instruction dataset.\n\nWhen applying the instruction-tuning, the authors propose a relatively new data-collection framework that utilizes the knowledge-graph to make the instuctions reveal more causal knowledge and a data-sampling technique to overcome the data-inbalance of commonly- and uncommonly-researched proteins.\n\nExperiments demonstrate the proposed methods can help LLMs achieve SOTA on several protein processing tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- aligning protein 'language' with human language where LLMs originally trained on is one key and promising field to make LLMs solve protein processing tasks. In general, this paper can contribute to this field, i.e. achieving new SOTA by incremetally pre-training and collecting new data to conduct instruction finetuning.\n- collecting instuction-tuning dataset from knowledge-graph is novel and insightful.\nThis can help to pose causal knowledge priori on finetuning LLMs.\nThe motivation is clearly clarified, and I think it can motivate further works in broader fields.\nBut the writing lacks details and citations of related works. I will detail the weakness in the next part.\n- the data-sampling strategy is interesting and relatively new from my perspective. The experiments, althought with some weakness, demonstrate that the data-sampling strategy can heavily boost the performances."
            },
            "weaknesses": {
                "value": "- Regarding the data-collection. Prompt each triplet to ChatGPT and get the results as the instruction is an important step. But will this assume that ChatGPT can already be prompted to understand the protein input and make output correctly? Especially, in the Figure 4 which is an example of how ChatGPT is prompted, the ChatGPT can infer the information 'it is in the leptin family' and this information is important to pose the causal knowledge. How you guarantee that the output is correct and useful? 'ChatGPT' can understand protein is not a desiable assumption.\n\n- Lacking of details. Regarding the data-collection, more details about the knowledge-graph need to be provided. You claim knowledge-graph can provide causal knowledge. The motivation can be more straghtforward if you tell what relationships the KG can provide and help the downstream tasks. Regarding the sampling, how the protein KG embedding is initialized? and what are the training details?\n\n- More citations needed. The authors provide an overview of different instruction methods but I cannot see any related citations in the context. Also, regarding the sampling strategy, the authors should cite highly-related works in the context rather than putting all to the related-works far-away.\n\n- More ablation studis needed. Ablation experiments on the incremental pre-training is necessary. And as  there is no enough details about training KG embeddings, I suspect the training is too tricky. The authors should provide ablations studies about only clusering by the editing distance to demonstrate the necessary of the embedding training. Also, ablation studies about the hyperparameters choices are needed."
            },
            "questions": {
                "value": "Please address my concerns list in the Weakness Part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3320/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698722127041,
        "cdate": 1698722127041,
        "tmdate": 1699636281515,
        "mdate": 1699636281515,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iReFILii7s",
        "forum": "RS827PjAUs",
        "replyto": "RS827PjAUs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3320/Reviewer_modh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3320/Reviewer_modh"
        ],
        "content": {
            "summary": {
                "value": "The paper you described proposes InstructProtein, a large language model designed to bridge the gap between natural language and biological sequences, specifically proteins."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper introduces an approach to leverage large language models for comprehending biological sequences, such as proteins.\n\n2. The paper introduces a knowledge graph-based instruction generation framework to construct a high-quality instruction dataset. \n\n3. Experimental results show that InstructProtein outperforms state-of-the-art large language models."
            },
            "weaknesses": {
                "value": "1.It is mentioned in the text that the higher the absolute value of the pLDDT score, the better. However, I believe it is not that straightforward. The pLDDT score is an indicator of the quality of a protein's structure, and in the text, protein sequences are generated using a language model. The unstructured regions in the protein sequence have a significant impact on the protein's function, and correspondingly, the pLDDT score may be lower. To compare the quality of generated protein sequences, it's important to evaluate whether the distribution in multiple dimensions aligns with real proteins as shown in Figure 5. In addition, the visualized results should incorporate real protein visualization results. \n\n2.In addition, There are alternative evaluation metrics for evaluating the generated sequences , such as assessments based on \u03b1\u03b2 structures, barrel helices, thermostability, metal element binding, etc. From an AI perspective, tools like Biopython can also be used to analyze biological aspects, such as pI values and electrostatic potential.\n\n3.When conducting baseline comparisons, it is more convincing to compare against Mol-Instructions in addition to LLaMA and Alpaca. Mol-Instructions is a dataset constructed from text data of proteins based on UniProtKB, and fine-tuned on LLaMA-7B. Therefore, this paper should give the comparison results against Mol-Instructions. \n\n4.In the section 4.2 , \"For a fair comparison, we designed a template for each model through prompt engineering so that the model could follow our instructions and output the answers.\" What I understand is that for other models, they will fine-tune based on templates. Can you add supplementary information in the appendix regarding the hyperparameters and dataset size for model fine-tuning? This would make the results more reliable.\n\n5.For ablation study, the article could delve into topics like how to address key residue mutations in overcoming the GO task or why the introduction of annotations leads to performance improvements. Additionally, the paper could elaborate on why fragment clusters based on protein properties can help avoid such issues."
            },
            "questions": {
                "value": "see above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3320/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698732379472,
        "cdate": 1698732379472,
        "tmdate": 1699636281416,
        "mdate": 1699636281416,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0p2G7YWsYz",
        "forum": "RS827PjAUs",
        "replyto": "RS827PjAUs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3320/Reviewer_Cqaz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3320/Reviewer_Cqaz"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new model called InstructProtein that enables bidirectional generation capabilities between natural language and protein sequences within a single large language model (LLM). The key ideas are:\n- Pre-train an LLM on both protein sequences and natural language text to acquire representations for both modes.\n- Generate a  instruction dataset from a protein knowledge graph using a proposed debiased sampling strategy and knowledge causal modeling.\n- Perform supervised instruction tuning on the LLM using the generated instructions to align the protein and natural language modalities.\n\nThe model is evaluated on classification tasks for protein sequence understanding tasks. Results show  improvements over open source LLMs."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The idea of using instruction tuning to align proteins and text is innovative and enables bidirectional generation between the two modes. This opens up new possibilities for protein design and engineering.\n- The proposed instruction generation methodology using knowledge graphs to improve instruction quality and the debiased sampling handles annotation imbalance and knowledge causal modeling provides causal links. These proposed method is able to improve instruction dataset quality.\n- Comprehensive evaluations in classification tasks shows the improvement on the proposed methods."
            },
            "weaknesses": {
                "value": "-Additional baselines should be incorporated for a more comprehensive analysis. The current comparison lacks an evaluation against more advanced Large Language Models (LLMs) such as ChatGPT[1] , GPT-4 [2] , and Claude-2[3] . It is crucial to understand the performance disparities between the proposed method and these well-established models.\n\n-The evaluation is restricted to classification tasks. There is a need to extend the assessment to more free-form instruction-based tasks[4] . One of the predominant applications of current chat assistant models is to interact with users. Hence, an evaluation that transcends beyond classification tasks is imperative to reflect more realistic usage scenarios.\n\n-There is an absence of experimentation on the model's generalization capabilities. Recent studies in domain-specific instruction tuning suggest that training confined to a particular domain may impede generalization due to a lack of diversity in the training data [5]. I urge you to emphasize the aspect of 'diversity' in your study. Could you demonstrate the generalization abilities of your model in various contexts?\n\n-Lack of scale up experiments. I am not sure if the conclusion holding in larger LLMs such as 7B,13B?\n\n-Lack of experiments on different model family, such as LLaMA[6] and LLaMA-2[7].\n\n[1] OpenAI. (2022). Introducing chatgpt. https://openai.com/blog/chatgpt, 2022. \\\n[2] OpenAI (2023). GPT-4 Technical Report \\\n[3] Anthropic (2022). Instroducing claude. https://www.anthropic.com/index/introducing-claude \\\n[4]  Dubois et al (2023). AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback \\\n[5]  Zhang et al (2023). AlpaCare:Instruction-tuned Large Language Models for Medical Application \\\n[6]  Touvron et al (2023). LLaMA: Open and Efficient Foundation Language Models \\\n[7] Touvron et al (2023). Llama 2: Open Foundation and Fine-Tuned Chat Models"
            },
            "questions": {
                "value": "- Can you show your results on compare with more powerful LLMs e.g ChatGPT, GPT-4, and Claude-2?\n\n- Can you show results on some open-ending text generation tasks both in-domain and general domain. For general domain, I suggest to follow Alpaca-farm.\n\n- Can you show results on different size of LLMs across different LLM families ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3320/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3320/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3320/Reviewer_Cqaz"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3320/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698949559265,
        "cdate": 1698949559265,
        "tmdate": 1699636281356,
        "mdate": 1699636281356,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mlyKPEquwK",
        "forum": "RS827PjAUs",
        "replyto": "RS827PjAUs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3320/Reviewer_Ex2Y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3320/Reviewer_Ex2Y"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors developed LLM called InstructProtein that has bidirectional generation capabilities: (1) translating the protein sequence to its textual function description (2) translating natural language instruction to the protein sequence. \nTo achieve this, the LLM is pre-trained on protein and natural language corpora. Specifically, the protein UniRef100 and sentences from PubMed abstracts are used for pre-training. To further obtain good performance on downstream tasks, the authors constructed a high-quality instruction dataset. This dataset is generated based on the knowledge graph that is constructed from the annotations of UniProt/Swiss-Prot. Overall, a KG triple to instruction generator (based on ChatGPT) was used . The chain-of-thought strategy and debiased sampling strategy were used for this generation process. In total, 2.8 million data is constructed.\nExperiments on de novo design and three protein function classification tasks (1) Protein localization prediction (2) Protein function annotation (3) Metal Ion Binding prediction showed that the protein knowledge instructions can boost the performance of protein understanding and design tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This is an interesting work on applying large language model to bioinformatics. Some related work have tried to align protein with human language. However, they either only showed unidirectional cross-modal capability, focusing solely on converting protein language to texts, or did not align the protein and human language very well. InstructProtein improves this by pre-training on UniRef100 and sentences from PubMed abstracts, providing a good foundation model on protein domain and filling the gap between the two languages and enabling the bidirectional generation. This work also contributes the first high-quality protein instruction dataset, by designing an effective data generation framework."
            },
            "weaknesses": {
                "value": "For the first conclusion in 4.2: The results (comparing with OPT, LlaMa, Alpaca) demonstrate that training with the corpus where proteins and natural language coexist is beneficial to LLMs, enhancing their proficiency in protein language understanding. However, I think this argument can not be concluded based on these results. Because the performance of the InstructProtein is contributed by both pre-training and finetuning. Without finetuning LLMs on the instruction corpus, we can not conclude that the coexist of proteins and natural language is beneficial (even this conclusion is quite intuitive)."
            },
            "questions": {
                "value": "Do we have any quality evaluation on the generated instruction dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3320/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698956102547,
        "cdate": 1698956102547,
        "tmdate": 1699636281272,
        "mdate": 1699636281272,
        "license": "CC BY 4.0",
        "version": 2
    }
]