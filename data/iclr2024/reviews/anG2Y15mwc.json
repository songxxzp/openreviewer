[
    {
        "id": "YIfZnzxLrE",
        "forum": "anG2Y15mwc",
        "replyto": "anG2Y15mwc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1371/Reviewer_J6vY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1371/Reviewer_J6vY"
        ],
        "content": {
            "summary": {
                "value": "This paper unifies the task of anonymization and visual identity information hiding and proposes a novel diffusion-based face privacy protection method. Specifically, it learns a set of SDM format conditional embeddings through the MSI module. Then, the authors designed corresponding embedding scheduling strategies and energy functions to guide the denoising process to achieve different privacy protection tasks."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. This study analyzes the similarities and differences between anonymization and visual identity information hiding tasks and proposes the first work that can simultaneously achieve these two tasks.\n2. The authors utilize the powerful generation prior of the diffusion model and design reasonable guidance to help SDM complete privacy protection and identity recovery. It is a novel privacy protection framework with unique password and identity recovery patterns.\n3. This paper is well organized and written in general. Most of the claims are supported by ample experimental analysis."
            },
            "weaknesses": {
                "value": "1. The author learns a set of conditional embeddings through a few images. When using the LFW dataset for training, do different images under the same identity need to be trained separately or can they be trained together to obtain a set of conditional embeddings for encryption and decryption?\n2. In Sec.2.2, the description of obtaining conditional embeddings seems unclear. Does each time step correspond to a unique time embedding?"
            },
            "questions": {
                "value": "Please see the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1371/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698461892976,
        "cdate": 1698461892976,
        "tmdate": 1699636064757,
        "mdate": 1699636064757,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kouGBkoi7x",
        "forum": "anG2Y15mwc",
        "replyto": "anG2Y15mwc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1371/Reviewer_pv71"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1371/Reviewer_pv71"
        ],
        "content": {
            "summary": {
                "value": "Overall this is an interesting paper that proposes a novel diffusion-based method for face privacy protection. The method is flexible and can achieve both anonymization and visual identity information hiding. The results demonstrate state-of-the-art performance."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "See the summary in detail."
            },
            "weaknesses": {
                "value": "1. The network architecture shown in Fig.2 is not clear. As mentioned by the authors, the framework of the proposed method can be divided into three stages, which are not presented in Fig.2. Also, key-E, key-I, and the proposed energy function-based identity guidance module are not clearly shown in Fig.2. \n2. The energy function in Section 2.3.2 is introduced briefly - more details are needed on the formulation and how it enables identity guidance. In addition, the definition of $\\varepsilon$ which indicates energy function is not clearly defined.\n3. In the Require part of Alg.1, \"scheduling strategy for embedding $C_{T}$\" is confusing as the authors define $C_{T}$ as embedding used in time step t before. \n4. The writing should be improved. The manuscript is hard to read and there are occasional grammatical issues and unclear/repetitive statements."
            },
            "questions": {
                "value": "See the summary in detail."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1371/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1371/Reviewer_pv71",
                    "ICLR.cc/2024/Conference/Submission1371/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1371/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698670186308,
        "cdate": 1698670186308,
        "tmdate": 1701049408647,
        "mdate": 1701049408647,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bHyJAG4n4n",
        "forum": "anG2Y15mwc",
        "replyto": "anG2Y15mwc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1371/Reviewer_4Vnn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1371/Reviewer_4Vnn"
        ],
        "content": {
            "summary": {
                "value": "This paper develops a new paradigm for facial privacy protection based on the diffusion model. Once trained, this model can flexibly implement different facial privacy protection tasks during inference, such as anonymization and visual identity information hiding. Qualitative and quantitative experiments have demonstrated the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Strength:\n++ The authors innovatively propose a new paradigm for facial privacy protection based on diffusion models. Quantitative and qualitative experiments have demonstrated the effectiveness of the proposed paradigm.\n++ The authors propose an MSI module to learn a set of SDM formats conditional embeddings of the original image and demonstrate that the embeddings extracted by this module have better editability and decoupling.\n++ The authors specially design an embedded scheduling strategy and an energy-based identity guidance module to guide the diffusion model, which makes the diffusion model effectively meet the needs of facial privacy protection tasks at the human perception level and machine perception level."
            },
            "weaknesses": {
                "value": "Weakness:\n-- Although the author has significantly reduced the training cost of the model (including the need for high-quality facial datasets), the diffusion-based method for inference is still inefficient compared to the GAN-based method.\n-- I noticed that the author conducted an experiment on the security of keys. I think more interesting experiments can be conducted on key-I and key-E to explore their role in image generation."
            },
            "questions": {
                "value": "Please find the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1371/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699154674490,
        "cdate": 1699154674490,
        "tmdate": 1699636064619,
        "mdate": 1699636064619,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "5tAKrbo4MZ",
        "forum": "anG2Y15mwc",
        "replyto": "anG2Y15mwc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1371/Reviewer_jBnK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1371/Reviewer_jBnK"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a face privacy-preservation method based on diffusion models that claims to achieve both anonymization and visual information hiding within a unified framework."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The paper addresses an important problem of enhancing privacy for face images shared on the Internet.\n2) The proposed solution appears to be somewhat novel and feasible, but it is hard to judge because sufficient details have not been provided."
            },
            "weaknesses": {
                "value": "1) The paper is extremely hard to read and understand. A number of mathematical notations and terms (e.g., key-E, conditional embedding, etc.) are  not defined clearly, which makes the proposed approach hard to follow.\n\n2) First and foremost, the most basic requirement in a security/privacy paper is stating the threat model and assumptions explicitly. What information is being protected and from whom? What are the capabilities of the adversary? In this paper, no clear threat model has been presented. For example, the goals of anonymization and visual information hiding appear to be quite different. Is the proposed framework designed to meet both these objectives simultaneously? Or is the paper trying to propose a common framework that can achieve either one of these objectives at a time by slighting tweaking some parameter/loss?\n\n3) For anonymization (de-identification), it is not sufficient to show that \"anonymized\" faces cannot be recognized by a standard face recognition system. It is necessary to prove that the face cannot be \"deanonymized\" by a malicious adversary. In the proposed approach, it appears that complete recovery is possible provided the so-called \"keys\" are available. This makes the privacy dependent on the confidentiality of the \"key\". Even in the absence of the \"key\", it may be possible for an adversary to learn the inverse mapping between the original and anonymized faces if many training pairs of (original, anonymized) faces are available. Contrarily, if the face recognition system is finetuned with a few examples of anonymized faces as an augmentation, may be it will start recognizing anonymized faces correctly. It is important to discuss the feasibility of such attacks.\n\n4)  Similarly, in the case of identity recovery, it is not sufficient to show that reconstructed images have high perceptual similarity to the original images. It must shown that the reconstructed image matches with the original images with high probability using a face recognition system. \n\n5) The diversity component of the proposed solution is not well-motivated. What is the application need for ensuring diversity? If the diversity loss is removed completely, will the same facial identity be generated every time irrespective of the input noise pattern (added to the initial latent code). If yes, is the model learning a one-to-one mapping between the latent code and generated image irrespective of the noise?\n\n6) According to the introduction, \"face images processed by visual identity information hiding methods are unrecognizable to human observers but can be recognized by machine\". The images generated by the proposed method clearly shows the presence of a face image to a human observer. Only, the identity is partially hidden. In this case, how is this different from anonymization?\n\n7) What is meant by \"conditional embedding\" of an image? What is the role of the \"time modulation\" module, which has been prominently highlighted in Figure 2, but never described in the text?"
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1371/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1371/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1371/Reviewer_jBnK"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1371/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699251724067,
        "cdate": 1699251724067,
        "tmdate": 1699636064563,
        "mdate": 1699636064563,
        "license": "CC BY 4.0",
        "version": 2
    }
]