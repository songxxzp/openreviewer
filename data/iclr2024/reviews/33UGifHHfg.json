[
    {
        "id": "ORJ55luQY6",
        "forum": "33UGifHHfg",
        "replyto": "33UGifHHfg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1024/Reviewer_66Fq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1024/Reviewer_66Fq"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a multi-task architecture for tabular data. The proposed architecture includes a hypernetwork which is used to generate model weights for different tasks from task-specific embedding and metadata. The resulting multi-task model is a soft-parameter sharing network that can get good accuracy on datasets with metadata."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is easy to follow and the proposed method is easy to understand.\n- The experiments show the effectiveness of the proposed method especially the usage of meta in tabular data."
            },
            "weaknesses": {
                "value": "- Motivation and Practical Usage:\n  - Limited Applicability: One major issue pertains to the paper's motivation and practical usage. The proposed method is primarily suited for tabular data, severely restricting its versatility due to its reliance on metadata.\n  - Limited Advantages: Furthermore, the paper falls short in demonstrating notable advantages. It does not address key considerations, such as storage or computational efficiency. The motivation behind the trade-off between parameter efficiency and task accuracy, as mentioned in the abstract, is insufficiently explored. In many Multi-Task Learning (MTL) scenarios, like those involving multiple vision tasks in autonomous driving, one expects to reduce storage costs through parameter sharing and even lower computational costs through computation sharing. Regrettably, the proposed method offers no benefits in these two aspects, as it relies on soft-parameter sharing.\n\n- Novelty:\n  - Lack of Novelty: Another significant concern pertains to the novelty of the proposed approach. The paper introduces hypernetworks as a central component, which is not a novel concept in MTL. Hypernetworks have already been extensively explored in both Natural Language Processing (NLP) [1] and Vision MTL scenarios [2], diminishing the originality of the paper's contribution.\n  - Common Practice: Moreover, employing task embedding as input is a conventional practice in the field of MTL. This conventional approach further diminishes the uniqueness of the proposed method.\n  - Limited Generalization: While the paper introduces an insightful use of metadata, its applicability is severely constrained. This novel aspect can only be employed effectively in the context of tabular data, limiting its broader relevance and potentially affecting its acceptance at top-tier conferences.\n\n[1] Mahabadi, Rabeeh Karimi, et al. \"Parameter-efficient multi-task fine-tuning for transformers via shared hypernetworks.\" arXiv preprint arXiv:2106.04489 (2021).    \n[2] Liu, Yen-Cheng, et al. \"Polyhistor: Parameter-efficient multi-task adaptation for dense vision tasks.\" Advances in Neural Information Processing Systems 35 (2022): 36889-36901."
            },
            "questions": {
                "value": "- What do you think makes your method different from the existing methods? In other words, what novelty would you like to emphasize in your method?\n- Do you think it is possible to use metadata in general multi-task problems like vision tasks and NLP tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Reviewer_66Fq"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1024/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697500002453,
        "cdate": 1697500002453,
        "tmdate": 1699636028635,
        "mdate": 1699636028635,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rLzjKfYKtv",
        "forum": "33UGifHHfg",
        "replyto": "33UGifHHfg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1024/Reviewer_bXYN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1024/Reviewer_bXYN"
        ],
        "content": {
            "summary": {
                "value": "This article presents a method for multi-task learning using hypernetworks, specifically designed for small tabular datasets by leveraging their metadata. A common hypernetwork produces network weights derived from both learned embeddings and the task's metadata. These weights are tailored for each task and are utilized to produce the final predictions relevant to that task."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The article is well-composed and systematically arranged.\n\n- The concept of employing hypernetworks to produce weights specific to each task is intriguing, particularly with the incorporation of supplementary data (referred to as metadata in the paper). This approach holds potential for crafting robust multi-task networks.\n\n- The assessments are thorough, encompassing many statistical nuances."
            },
            "weaknesses": {
                "value": "- The evaluation size for the multi-task learning approach seems limited, with fewer than 1,000 training samples. Determining the efficacy of the suggested deep learning technique from such a compact dataset can be challenging. Other multi-task learning studies have set more expansive benchmarks such as PASCAL-Context, NYUD, and Cityscapes [1], \n\n- While the paper touches upon some older deep learning techniques (like Cross-stitch and Sluice), it misses out on discussing or comparing several recent deep learning-based multi-task learning methodologies. Notable omissions include InvPT [1], TaskPrompter [2], TaskExpert [3], MQTransformer [4], and MTFormer [5]. Notably, TaskExpert [3] adopts a strategy of learning task-specific gating networks for generating task-dependent weights during task-specific decoding, which bears a resemblance to the hypernetwork learning process to some extent.\n\n- The parameter size and computational efficiency of the methods listed in Table 2 are not shown. I understand that Fig. 6 provides some information about efficiency, but we would like to see the effectiveness vs. efficiency.\n\nReferences:\n\n[1] Inverted Pyramid Multi-task Transformer for Dense Scene Understanding. ECCV 2022\n\n[2] TaskPrompter: Spatial-Channel Multi-Task Prompting for Dense Scene Understanding. ICLR 2023\n\n[3] TaskExpert: Dynamically Assembling Multi-Task Representations with Memorial Mixture-of-Experts. ICCV 2023\n\n[4] Multi-Task Learning with Multi-Query Transformer for Dense Prediction. arXiv 2022\n\n[5] MTFormer: Multi-Task Learning via Transformer and Cross-Task Reasoning. ECCV 2022"
            },
            "questions": {
                "value": "- Can you provide a rationale for evaluating multi-task models using just a single tiny-scale multi-task benchmark? \n\n- How does the performance stack up against one or two of the aforementioned cutting-edge multi-task architectures?\n\n- How does the model perform on datasets such as PASCAL-Context?\n\nI would be open to revising my final score after reviewing the authors' response. Thank you."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1024/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697559139678,
        "cdate": 1697559139678,
        "tmdate": 1699636028567,
        "mdate": 1699636028567,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TIMswhQPFH",
        "forum": "33UGifHHfg",
        "replyto": "33UGifHHfg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1024/Reviewer_88C4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1024/Reviewer_88C4"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a hypernetwork to generate flexible task networks for each task from different task-specific embeddings and metadata. They show empirically that the proposed method outperforms many MTL architectures on small tabular data problems, and leverage metadata more effectively than existing methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The motivation of this paper is clear.\n2. The proposed method can generate flexible task networks."
            },
            "weaknesses": {
                "value": "1. The novelty of this paper is limited. The ideas of utilizing hypernetworks for MTL and learning task-specific embeddings have been extensively employed in existing MTL research. The proposed method of this paper is relatively straightforward and does not provide significant novel insights, just an application work not a research paper.\n2. The authors claim that \"We additionally show experimentally that the task embeddings learn \u201cmeaningful\u201d task representations, in that they are predictive of task-level knowledge.\" However, Section 3.3 only shows the task embeddings can be used to reconstruct metadata and is based on a  model that is needed to be learned. How can this demonstrates the meaningfulness of learned task embeddings? Furthermore, the reconstructed performance is poor.\n3. The authors only conducts experiments on small-scale datasets, with the maximum dataset size being 796. It seems challenging to generalize their method to address large-scale MTL tasks. This is because tackling large-scale MTL problems typically requires a target network model with a significantly larger parameter set, which becomes difficult to predict using the hypernetwork. Although the authors propose a method to reduce the dimension of parameters in the hypernetwork generator using an existing technique, it remains unclear whether this compression technique would successfully scale up the hypernetwork to effectively handle large-scale real-life MTL problems.\n4. The authors claim on the superior performance of their method paper, by saying the proposed method outperforms SOTA methods. However, the compared methods in this paper are not SOTA methods.  More recent SOTA methods are needed to discuss and compare."
            },
            "questions": {
                "value": "see Weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Reviewer_88C4"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1024/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697794168008,
        "cdate": 1697794168008,
        "tmdate": 1699636028472,
        "mdate": 1699636028472,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tnvEvdV7sD",
        "forum": "33UGifHHfg",
        "replyto": "33UGifHHfg",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1024/Reviewer_RnjU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1024/Reviewer_RnjU"
        ],
        "content": {
            "summary": {
                "value": "The paper presents Multi-Task Hypernetworks that aim to leverage the information from different tasks to improve the performance on each task. In particular, hypernetworks with weight compression are employed in this work to allow knowledge transfer across tasks while introducing a minimal number of trainable parameters. Furthermore, the authors propose to utilize the metadata, which could help during training. Experimental results on different tabular datasets validate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and easy to follow. The authors present their method in detail.\n- The proposed method outperforms other baselines on different experimental setups. Ablation studies are conducted thoroughly to understand the effectiveness of each component."
            },
            "weaknesses": {
                "value": "- The proposed method is a simple combination of employing hypernetwork and more informative inputs (using handcrafted metadata). Moreover, the idea of utilizing HyperNetwork for Multi-task learning is not novel. It has been studied in prior work (e.g. [1,2]).\n- The construction of metadata requires domain knowledge from ML practitioners and potentially includes target leakage features.\n- The number of trainable parameters in the proposed method is larger than the target network, which is inefficient for training. This is addressed by using chunk embeddings for different small parts of the main network.\n\n[1] Navon, Aviv, et al. \"Learning the Pareto Front with Hypernetworks.\" International Conference on Learning Representations. 2020.\n\n[2] Lin, Xi, et al. \"Controllable pareto multi-task learning.\" arXiv preprint arXiv:2010.06313 (2020).\n\n[3] von Oswald, Johannes, et al. \"Continual learning with hypernetworks.\" International Conference on Learning Representations. 2019."
            },
            "questions": {
                "value": "- Please add the number of trainable parameters/training budgets used for comparative methods in the main tables.\n- Can you compare your proposed hypernetwork with weight compression against the chunking technique?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1024/Reviewer_RnjU"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1024/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816881436,
        "cdate": 1698816881436,
        "tmdate": 1699636028396,
        "mdate": 1699636028396,
        "license": "CC BY 4.0",
        "version": 2
    }
]