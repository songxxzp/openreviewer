[
    {
        "id": "PvZ1zAAQYJ",
        "forum": "5RielfrDkP",
        "replyto": "5RielfrDkP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8015/Reviewer_PtSQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8015/Reviewer_PtSQ"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new method for graph representation learning leverage spectral graph representation learning and meta learning. Experiments show the proposed method shows superior performance on a variety of graph datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The method is relatively novel, combining several ideas from graph spectral filtering and meta learning.\n2. Adequate ablation studies are performed to show the importance of proposed components."
            },
            "weaknesses": {
                "value": "1. The datasets used in the paper are relatively small, given the fact that there are a numerous large-scale graph benchmark datasets nowadays. It may not be a large concern in the early days, e.g. 2016-2017 when GNN was originally proposed, but in today\u2019s standard more larger graphs are expected to evaluate the proposed approach rigorously and reliably.\n2. Lack of some well-known baseline methods such as GIN (Xu, Keyulu, et al. \"How powerful are graph neural networks?.\" arXiv preprint arXiv:1810.00826 (2018).) and graph transformers (e.g. Ramp\u00e1\u0161ek, Ladislav, et al. \"Recipe for a general, powerful, scalable graph transformer.\" Advances in Neural Information Processing Systems 35 (2022): 14501-14515.) Given the abundance of such existing methods, I encourage the authors to admit this fact and discuss about the pros and cons of using the proposed MM-FGCN approach in practice. \n3. There is no mentioning on the releasement of the code making reproducibility hard. \n4. Typo, e.g. \u201cdenseness, dilation property, and property (Mallat, 2006)\u201d in Section 3."
            },
            "questions": {
                "value": "1. Why Geom-GCN in Table 6 lacks std?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8015/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698629544794,
        "cdate": 1698629544794,
        "tmdate": 1699636988910,
        "mdate": 1699636988910,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RIyQI236pb",
        "forum": "5RielfrDkP",
        "replyto": "5RielfrDkP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8015/Reviewer_sJoC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8015/Reviewer_sJoC"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a Multiresolution Meta-Framelet-based Graph Convolutional Networks (MM-FGCN), which employs a diverse set of framelets for constructing graph convolution and learns meta-framelet generator networks via the meta-learning scheme. Since most GNNs depend on single-resolution graph feature extraction, they often fail to capture local patterns and community patterns simultaneously. To resolve it, some papers have proposed multi-resolution graph feature extraction-based GNNs. But, they use predefined and hand-crafted multiresolution transforms. To address these issues, this paper designs meta-learning based adaptive multiresolution graph convolution and they have shown the effectiveness with their experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The proposed paper deals with really important research problem. Simultaneously capturing high and low resolution with graph convolution is interesting and important.\n- The proposed method seems novel to me.\n- From their experiments, the proposed meta-framelet-based graph convolutional networks show good performance on various tasks. \n- The paper is well-written and easy to follow. In particular, the preliminary section provides the necessary and detailed information to understand the proposed method."
            },
            "weaknesses": {
                "value": "- One of the important details about how to split the meta dataset from the main dataset is missing. It should have been provided to fairly compare the proposed method with other graph neural networks.\n- In the same context, it would be better if you explain why meta learning framelet transforms is better than directly training them. From Table 3, it is easy to know that framelet transforms with meta-learning is more effective compared to the direct training scheme. But, why meta-learning scheme is better than the direct training scheme is mysterious. I think this is related to how to construct the meta dataset.\n- It would be better if the author provided the change of filters according to the training step since the author claimed that the limitation of existing multiresolution transforms works is that they remain fixed throughout the training process. So, I'd like to see the variations of filters during the training and the analysis about it."
            },
            "questions": {
                "value": "- I think MM-FGCN can also be applied to the graph classification tasks. Could you provide the performance of MM-FGCN with MM-FGPool and MMFGCN with the standard graph pooling?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8015/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8015/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8015/Reviewer_sJoC"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8015/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698677823147,
        "cdate": 1698677823147,
        "tmdate": 1700631424124,
        "mdate": 1700631424124,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sob3Fwnxsa",
        "forum": "5RielfrDkP",
        "replyto": "5RielfrDkP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8015/Reviewer_oTNL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8015/Reviewer_oTNL"
        ],
        "content": {
            "summary": {
                "value": "The Multiresolution Meta-Framelet-based Graph Convolutional Network (MM-FGCN) is a novel approach to graph representation learning that allows for adaptive multiresolution analysis across diverse graphs. It achieves state-of-the-art performance on various graph learning tasks. \n\nIn my opinion, adaptive multi-resolution is a promising yet difficult approach for the representation of graphs, lying in the intersection of graph signal processing and graph machine learning. In particular, I appreciate the construction of the framelet filters to satisfy the three properties (where denseness is different from the sparse and redundant representation in wavelet and framelet). The paper extends the framelet theory and presents the solution with relatively few parameters (only $\\Theta, \\omega$) to avoid a large number of parameters for the framelet system, yet achieves significant improvement in the experiments. The theories and proofs are solid in general, and though some of the writing could be improved, I think it is an excellent piece of work."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper proposes a novel approach to design an adaptive learnable set of multi-resolution representations on graphs, with solid theoretical motivation and proof.    \n2. The proposed method significantly improves node classification (especially on disassortative tasks) and graph classification tasks."
            },
            "weaknesses": {
                "value": "1.The paper lacks some necessary model  and data descriptions for the implementation, like the specification of neural network $M_\\xi$.    \n2. minor issues:  missing \"translation\" before property near \"Mallat, 2006\"."
            },
            "questions": {
                "value": "1. How is the neural network $M_\\xi$ formulated? What does the output $\\omega$ look like?     \n2. How is the graph data split to obtain $S_{meta}, S_{main}$?    \n3. Why is the meta training needed for the training procedure?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8015/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8015/Reviewer_oTNL",
                    "ICLR.cc/2024/Conference/Submission8015/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8015/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698766963035,
        "cdate": 1698766963035,
        "tmdate": 1700642408964,
        "mdate": 1700642408964,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "stCa35d4sd",
        "forum": "5RielfrDkP",
        "replyto": "5RielfrDkP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8015/Reviewer_nDyN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8015/Reviewer_nDyN"
        ],
        "content": {
            "summary": {
                "value": "This paper use meta-learning to build for adaptive framelet for GNN.\n\nThey evaluate the model's performance on various graph learning tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. MM-FGCN is can learn adaptive multiresolution representation.\n\n2. Achieve STOA performance on graph learning tasks.\n\n3. parameterization of the meta-framelet generator uses use fewer parameters than previous method."
            },
            "weaknesses": {
                "value": "1. Require additional meta training.\n2. The framelet is defined using a meta-band-pass filter based on polynomial splines, the model use Chebyshev approximation to circumventing the need for eigen-decomposition, but compared with graph-structure-based approach, Chebyshev approximation seems a more expensive.\n3. Following the previous point, it seems it's hard to use the model on large graphs. (ogbn tasks)\n4. The performance is not close to STOA, recent studies show better performance, e.g. [1],[2]\n\n[1] https://arxiv.org/abs/2305.10498\n[2] https://arxiv.org/abs/2105.07634"
            },
            "questions": {
                "value": "1. Could you provide details on the time cost for meta-learning as well as the inference time for the model?\n2. Would it be possible to evaluate the model on larger datasets like ogbn? I did observe ogbg-molhiv, but I'm referring to graphs with a larger number of nodes rather than the total number of graphs.\n3. An detailed introduction to meta-learning would help readers in gaining a clearer understanding of the experimental setup."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8015/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8015/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8015/Reviewer_nDyN"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8015/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698795103599,
        "cdate": 1698795103599,
        "tmdate": 1700686327984,
        "mdate": 1700686327984,
        "license": "CC BY 4.0",
        "version": 2
    }
]