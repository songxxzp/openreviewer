[
    {
        "id": "DJyrNHWrGg",
        "forum": "B3E8Y8g9GA",
        "replyto": "B3E8Y8g9GA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2946/Reviewer_PF2v"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2946/Reviewer_PF2v"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel framework, Dy-DCA, which combines a Dynamic Deep Neural Network with a Content-Aware data processing pipeline to enhance on-device super-resolution for videos. This approach aims to address the challenges of model switching overhead and memory footprint associated with traditional video super-resolution methods that rely on splitting videos into chunks and overfitting a super-resolution model to each chunk.\n\n**Key Contributions:**\n- Dynamic Neural Network with Content-Aware Data Processing: The paper proposes a scalable dynamic deep neural network paired with a fine-grained data processing method, significantly reducing the number of required models while maintaining high performance and reasonable model size. This is achieved by dynamically producing patches of different texture complexity and overfitting these patches with a designed dynamic neural network.\n\n- Compiler-Level Optimization: To accommodate the dynamic nature of the proposed neural network and to ensure real-time performance on devices, the paper introduces a compiler-level optimization framework. This framework optimizes dynamic features such as input shapes and control flow, enabling a series of compilation optimizations that result in faster execution and reduced memory consumption.\n\n- Enhanced Video Quality and Efficiency: By employing the proposed framework and optimizations, the paper claims to achieve better PSNR and real-time performance on mobile devices, along with significant improvements in speed (1.7\u00d7 overall speedup) and memory consumption (up to 1.61\u00d7 savings)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Originality:**\nThe paper introduces a novel framework, Dy-DCA, which combines a dynamic deep neural network with a content-aware data processing pipeline for on-device super-resolution. This approach is original as it addresses the common issue of model switching overhead in video super-resolution, reducing the number of required models to one. The integration of a compiler-level optimization framework to support the dynamic nature of the neural network adds a unique dimension to the work, showcasing an innovative solution to a well-known problem in video super-resolution.\n\n**Quality:**\nThe paper appears to be of high quality, providing a comprehensive and well-thought-out solution to enhance video quality and efficiency in transmission. The proposed Dy-DCA framework and the associated compiler-level optimizations are grounded in solid theoretical and practical considerations, with claims of significant improvements in PSNR, real-time performance on mobile devices, and resource efficiency.\n\n**Clarity:**\nThe paper is well-structured and articulates the problem, proposed solution, and contributions clearly. The use of figures and step-by-step explanations aid in understanding the complex concepts involved in the Dy-DCA framework and compiler-level optimizations. However, the depth of the content may require readers to have a substantial background in deep learning, computer vision, and compiler optimizations.\n\n**Significance:**\nThe paper holds significant potential to impact the field of video streaming and super-resolution, addressing critical issues of video quality and transmission efficiency on edge devices. By reducing model switching overhead and memory footprint, the paper presents a solution that could lead to more efficient and effective video super-resolution applications, especially in real-time scenarios on resource-constrained devices."
            },
            "weaknesses": {
                "value": "- It would be more comprehensive to add ablation studies to understand the contribution of each component of the Dy-DCA framework and the compiler-level optimizations would offer a clearer picture of their individual and combined effects on performance and quality.\n\n- The paper could benefit from experiments to evaluate the scalability and efficiency of the proposed framework on a variety of hardware architectures, including both high-end and low-end devices, would provide a comprehensive view of its applicability and performance across different scenarios.\n\n- The PSNR gain is marginal, though the speedup is shiny."
            },
            "questions": {
                "value": "Could you clarify how the PSNR gain in table 2 and 4 are *significant*? From Figure 4, visually the performance seems close to other approaches."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2946/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2946/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2946/Reviewer_PF2v"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2946/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816822224,
        "cdate": 1698816822224,
        "tmdate": 1699636238415,
        "mdate": 1699636238415,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EVvPYCFWyz",
        "forum": "B3E8Y8g9GA",
        "replyto": "B3E8Y8g9GA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2946/Reviewer_nwgm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2946/Reviewer_nwgm"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a Dynamic Deep neural network assisted by a Content-Aware data processing pipeline to reduce the number of models down to one (Dy-DCA), while still maintaining good performance. Meanwhile, the paper designs a framework that optimizes dynamic features (e.g., dynamic shapes, sizes, and control flow) in Dy-DCA to enable a series of compilation optimizations, including fused code generation, static execution planning, etc. The performance of the proposed solution is evaluated on two datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed solution achieves better PSNR and real-time performance compared to traditional video transmission, while reducing the number of models needed for high performance down to one and conserving computational resources.\n\n2. The proposed solution optimizes dynamic features (such as dynamic shapes, sizes, and control flow) to enable a series of compilation optimizations (including fused code generation, static execution planning, etc.), which helps achieve acceleration on the user end."
            },
            "weaknesses": {
                "value": "1. The paper lacks a detailed discussion of the limitations and potential drawbacks of the proposed solution.\n\n2. The paper does not provide a detailed comparison of the proposed solution with other state-of-the-art methods in terms of model size and computational complexity.\n\n3. The paper only provide PSNR performance. Additional subjective quality (such as MS-SSIM) should be measured.\n\n4. The paper does not provide ablation experiments."
            },
            "questions": {
                "value": "Please refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2946/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698996490737,
        "cdate": 1698996490737,
        "tmdate": 1699636238355,
        "mdate": 1699636238355,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mSlJEhdBPy",
        "forum": "B3E8Y8g9GA",
        "replyto": "B3E8Y8g9GA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2946/Reviewer_wfAU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2946/Reviewer_wfAU"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes dynamic processing of different regions in video frames. Furthermore, the authors propose a compiler that manages the dynamism of tensor shapes."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Real-time video super resolution on a mobile device at 1080p is an impressive result."
            },
            "weaknesses": {
                "value": "Rewriting the paper to be more accessible to non-expert readers would be beneficial. As it stands, the flow of information assumes the reader is familiar with compilers, the current state of SR, and the continuous model adaptation framework, which may not always be the case."
            },
            "questions": {
                "value": "1. The paper rightly points out that switching the Super-Resolution (SR) model from one chunk to another can be costly. Could the solutions proposing sparse incremental model changes address this issue (refer to [1] for an example)?\n\n2. The unique contributions in Section 2.3 are difficult to comprehend in their current form. How does this categorization of tensors encompass all use cases? What are the limitations of the proposed compiler? Is it applicable solely to SR or also to convolutional models?\n\n\n[1] Khani, Mehrdad, Vibhaalakshmi Sivaraman, and Mohammad Alizadeh. \"Efficient video compression via content-adaptive super-resolution.\" In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 4521-4530. 2021."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2946/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699245385710,
        "cdate": 1699245385710,
        "tmdate": 1699636238225,
        "mdate": 1699636238225,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ddNJBFEaeW",
        "forum": "B3E8Y8g9GA",
        "replyto": "B3E8Y8g9GA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2946/Reviewer_J3a9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2946/Reviewer_J3a9"
        ],
        "content": {
            "summary": {
                "value": "Deep neural networks (DNNs) are increasingly utilized for video resolution upscaling in modern video distribution systems, enhancing quality and efficiency by overfitting each video chunk with super-resolution (SR) models. However, the high number of models and chunks required causes substantial overhead in model switching and memory usage. To tackle this, a new method, Dy-DCA, employs a single dynamic deep neural network with a content-aware pipeline, significantly reducing the model count. This approach not only improves performance and quality (measured by PSNR) on standard mobile devices but also achieves a 1.7\u00d7 speedup and up to 1.61\u00d7 memory savings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* Reducing one dynamic DNN to minimizing the switching overhead is clever.\n* Significant improvement in FPS on off-the-shelf mobile phones while maintaining PSNR quality."
            },
            "weaknesses": {
                "value": "* The presentation of the paper, particularly in Section 2.2 and Section 2.3, needs significant improvement due to a lack of details."
            },
            "questions": {
                "value": "This is more of a general comment than a specific question. The on-device super-resolution application presented in this work is intriguing, as it enhances video quality using a single dynamic DNN and achieves high FPS through model-compiler co-design. While I understand the constraints of the page limit, the current description of the proposed system (incl. Sections 2.3.3 and 2.3.4) is overly terse and challenging to comprehend for a non-expert reviewer. Therefore, a substantial revision is required to improve the presentation. There are also typos, which requires more careful proofreading."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2946/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2946/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2946/Reviewer_J3a9"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2946/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699668138284,
        "cdate": 1699668138284,
        "tmdate": 1699668138284,
        "mdate": 1699668138284,
        "license": "CC BY 4.0",
        "version": 2
    }
]