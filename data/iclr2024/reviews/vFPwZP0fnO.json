[
    {
        "id": "SiH6mks3dV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_2LRv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_2LRv"
        ],
        "forum": "vFPwZP0fnO",
        "replyto": "vFPwZP0fnO",
        "content": {
            "summary": {
                "value": "This paper proposes AugUndo, a method to enable a wider range of (geometric) augmentations for unsupervised depth completion. The author pointed out that typical data augmentations have seen limited adoption for the task of unsupervised depth completion for the following reasons:\n1. certain augmentations either reduce co-visible image regions or create image artifacts\n2. resampling and interpolation of sparse depth maps will lose information\n\nThe work is motivated by applying more geometric augmentations to this task. The main idea is to apply a series of photometric and geometric transformations to predict a depth map, and then reverse these geometric transformations such that the predicted depth map is warped back to the original reference frame. Then, training can proceed with computing the photometric loss as usual."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper is well-motivated. Limiting the data augmentation to a small set of photometric transformations has been a long-standing pain point for unsupervised depth completion. The authors clearly identified this limitation and sought to address this problem. \n\n2. The proposed method is simple, effective, and technically sound. It can augment both the input image and the sparse depth map. The use of this method does not affect the network design and can be applied to many existing works. \n\n3. The paper provides a good set of experiments to support its claim. The authors showed consistent improvements on 3 different networks with 2 different datasets by applying AugUndo. Additional experiments on depth estimation also demonstrate the applicability of the proposed method. The authors also provide a detailed ablation study in supplemental materials."
            },
            "weaknesses": {
                "value": "1. The 2nd contribution on approximate inverse was not well discussed in the main paper. \n2. It seems like most of the geometric augmentations are image space transformations. This also applies to the sparse depth map. Would this still suffer the same problem of losing depth points after resampling and interpolation?\n3. As a general augmentation method, the paper could be made stronger by applying it to other geometric learning tasks. The current application to depth completion and depth estimation is a bit too narrow (this is just a suggestion)."
            },
            "questions": {
                "value": "See Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4435/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4435/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4435/Reviewer_2LRv"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4435/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697333979464,
        "cdate": 1697333979464,
        "tmdate": 1699636418461,
        "mdate": 1699636418461,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gPOCF2TCsC",
        "forum": "vFPwZP0fnO",
        "replyto": "vFPwZP0fnO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_naag"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_naag"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a simple yet effective method to successfully incorporate the geometrical augmentations into the UNSUPERVISED DEPTH COMPLETION and achieves consistent improvements under different datasets using various baseline models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The method is simple and reasonable. The experiments results demonstrate the effectiveness of the methods."
            },
            "weaknesses": {
                "value": "1. While the experiments have proved the effectiveness of the methods, yet, how to choose the set of geometrical transformations is still clear.\n2. Besides, the paper may lack theoretical analysis, which makes the paper more like a technique report. \n3. The contribution maybe insufficient. The idea of undoing the augmentations is common and trivial in the training of deep learning tasks such as in semantic segmentations. A theoretical analysis is needed to improve the paper contribution.\n4. The ablation studies are missing."
            },
            "questions": {
                "value": "What is the influence of using different kind of geometrical transformations?\nCan more geometrical transformation types further improve the results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4435/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4435/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4435/Reviewer_naag"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4435/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698574160313,
        "cdate": 1698574160313,
        "tmdate": 1699636418365,
        "mdate": 1699636418365,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "baw8zbxWiJ",
        "forum": "vFPwZP0fnO",
        "replyto": "vFPwZP0fnO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_qT32"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_qT32"
        ],
        "content": {
            "summary": {
                "value": "For data augmentation protocol in the task of unsupervised depth completion or monocular depth estimation, this paper proposes to undo the augmentation applied to the model input via applying inverse augmentation operations to the model output. So the supervision can be performed in the original ground-truth formats. This can avoid errors introduced by e.g. interpolation of sparse depth supervision. After carefully designed and optimized combination of data augmentation, improvements are achieved on indoor datasets (17.66%) and outdoor datasets (3.18%) for depth completion."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "[Originality]\nThis paper looks into a problem probably overlooked by previous work, i.e. data augmentation is limited and under-exploited in the task of depth completion. They either followed some default limited protocols or didn't mange to apply it successfully.\n\n[Quality]\nThe numerical improvement on indoor datasets looks good, even though the gain on outdoor dataset (KITTI) becomes limited;\n\n[Clarity]\nGenerally well-written (though the texts in method part are a bit hard to read);\n\n[Significance]\nThis paper shows a combination of carefully designed data augmentation that can be applied to several methods which brings improvements on all of them through extensive experiments."
            },
            "weaknesses": {
                "value": "Technically speaking, this method is somewhat limited in novelty, e.g. undoing the effects of data augmentation was explored in Digging Into Self-Supervised Monocular Depth Estimation before. They showed improvements in applying supervision in the full-resolution image is better than lower-res downsampled ground-truth. This paper extends it to a broader set of operations. But fundamentally speaking, The ideas of\n1) higher-resolution or higher-quality ground-truth can improve the performance; \n2) ensuring the data augmentation doesn't break the supervision signal w.r.t the input is important;\nare well-known. From that aspect, the technical contribution of this work looks incremental and weakened.\n\nAlso,  it looks unclear to me how critical the engineering of different data augmentation hyper-parameters is in the improvement. It's a pity that with such carefully designed augmentation protocols, the resizing augmentation is still limited in fact: resizing factor cannot be larger than 1 in VOID dataset; no resizing operation can work for KITTI dataset. This further weakened the claim."
            },
            "questions": {
                "value": "1. Have the authors tried applying this to scene flow estimation from sparse point cloud inputs plus images? If that works, it would greatly enhance the significance of this paper.\n2. Why does resizing factor greater than 1 harm performance on VOID dataset?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4435/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698708490953,
        "cdate": 1698708490953,
        "tmdate": 1699636418244,
        "mdate": 1699636418244,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hhgvsEuApT",
        "forum": "vFPwZP0fnO",
        "replyto": "vFPwZP0fnO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_WQDt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_WQDt"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a way to exploit various photometric and geometric augmentations for unsupervised depth completion and estimation tasks. Conventional methods for those tasks have been using only simple augmentations (eg., limited photometric transformation, random horizontal flip) due to their task characteristics (for example, random crop and resizing change the effective focal length of inputs and thus are not suitable for the monocular depth estimation task).\nThis paper proposes to apply diverse augmentations, infer depth, and undo those augmentations on the output to return it back to the original reference frame coordinate (Fig. 1).\nThe paper applies this idea to two tasks (depth completion and estimation) and shows decent accuracy improvement on public datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Self-contained\n\n  The paper is easy to follow. Pretty much details are self-contained (Fig. 1 and Algorithm 1 for the main idea). The experiment section provides sufficient details on its hyperparameter choices and makes the method transparent and reproducible.\n\n- Decent accuracy improvement\n\n  Table 1 to Table 4 shows that, when applying the proposed idea to baseline models, it brings decent accuracy improvement on both depth completion and estimation tasks on public datasets."
            },
            "weaknesses": {
                "value": "- Double-edge sword?\n  \n  Applying various geometric augmentation lets the network see diverse samples during training. On the other hand, pixels that go out-of-frames after the augmentation will not be used for training even after the undo operation, which reduces the number of supervision signals. How many pixels (in %) go out of the image frames after the augmentation? (One could simply calculate the mean of the validity map in Eq. (8)). Does heavy augmentation hurt the accuracy? How does the accuracy change over the level of augmentation (such as from weak augmentation to strong augmentation)?\n\n- Weak baselines\n\n  The paper adopts their method on three baselines for depth completion (VOICED, FusionNet, KBNet) and depth estimation (Monodepth2, HR-Depth, Lite-Mono). However, those baselines are outdated, and it questions whether the method can bring benefits to any method. For example, one baseline (VOICED) is ranked 144th out of 158 methods on [KITTI depth completion benchmark](https://www.cvlibs.net/datasets/kitti/eval_depth.php?benchmark=depth_completion). It would have been great if the paper demonstrated the effectiveness of the method on recent/top methods on benchmarks. \n\n- Limited evaluation \n\n  The paper evaluates the method on only two datasets (VOID and KITTI). For the monocular depth task, there are other popular datasets such as NYUv2, ScanNet, Make3D. Although the paper uses those datasets for zero-shot evaluation, it would be still good to train the method on one of the datasets (e.g., NYUv2) and compare it with other state-of-the-art methods.\n\n- Different hyperparameter choices on each baseline model\n\n  In the subsection \"Augmentations.\" in Sec 5.1, the paper uses different sets of hyperparameters for each baseline model (KBNet/FusionNet and VOICED). I wonder why it uses different parameters, and if this method is sensitive to the hyperparameter choices. If it's sensitive, this would decrease the practicality of the method."
            },
            "questions": {
                "value": "- Unclear sentence\n\n   In the 2nd paragraph of the introduction \"Zooming an object in the image domain implies a closer distance between the object and the camera, ...\". I am not so sure if it's true. Even if zooming an object in the image domain, I think the actual distance between the object and the camera still remains the same, but only the camera focal length changes. I wonder if that's the case or not.\n\n- Details of $R(\\hat{d_t})$ in Eq (2)\n\n  I wonder if the paper can provide the details on the regularizer term $R(\\hat{d_t})$ in Eq (2).\n\n- Wrong bold-faced\n\n  In Table 8, the best number for iRMSE is in the 3rd row."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4435/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698723609625,
        "cdate": 1698723609625,
        "tmdate": 1699636418172,
        "mdate": 1699636418172,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4l8KSaEuOH",
        "forum": "vFPwZP0fnO",
        "replyto": "vFPwZP0fnO",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_YqAp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4435/Reviewer_YqAp"
        ],
        "content": {
            "summary": {
                "value": "The paper describes several approaches to data augmentation when training monocular depth estimation or completion networks. The evaluation is done on the KITTI and VOID datasets, showing consistent improvement from the proposed data augmentation strategies."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Data augmentations are very important in self-supervised pipelines. Doing data augmentation is not easy in depth completion or estimation problems when depth channel should be transformed consistently with the transformation applied to the color or intensity channels. The paper is correct to highlight this issue. In other cases, such as DINO features, for example, data augmentation is the driver underneath learning a useful universal visual representation."
            },
            "weaknesses": {
                "value": "The paper proposes some augmentation strategies, however, there are references that use non-trivial data augmentation for depth completion or estimation, but they are not cited and not compared against. In particular, the work \"ADAADepth: Adapting Data Augmentation and Attention for Self-Supervised Monocular Depth Estimation\" from Kaushik et al., IEEE RAL 2021,  uses a less trivial approach than the proposed paper. While in the proposed paper a network is applied only to the augmented image, in the work I just mentioned the network is applied both to initial and to augmented images, and the outputs are required to be consistent. The ADAADepth method contains a number of augmentation strategies and shows good results on KITTI dataset. It is a question why we do not see a comparison to this method in the submission, and why the methods to augment data proposed in the ADAADepth work are not discussed in the submission.\n\nThere are also some issues with the mathematical formulation of the method, see below in the Questions section."
            },
            "questions": {
                "value": "1. Why the reference mentioned above is not cited and is not compared against?\n\n2. The paper says that the method is \"Aligning the training target with the augmented input\", but in other places it says the method \u201cundoes\u201d the augmentations during the loss computation.\u201d For me these approaches are distinct: either the target is transformed, or the output of the network is de-augmented. Looking at Algorithm 1 I see that most likely the method is not aligning training target, but aligning the output after the augmentation with the training target. The text should be made consistent.\n\n3. Mathematical definition of depth completion is incorrect: The depth completion is not a mapping from \\Omega x \\Omega_z \\to R_+, but a mapping from \\Omega \\to R_+. We do not put every pixel and every sparse point with depth in correspondence with depth prediction, but we just predict depth for every pixel, so it should be a function from pixels to depth values.\n\n4. What are \u201cgeometric transformations\u201d? from (4), it is a transformation defined on the homogeneous pixel coordinates, am I right? Should be explicitly said somewhere; in Algorithm 1, T_ge is applied to z_t, to image as well, but in the formulas T_ge is applied to the coordinates\n\n5. (5) incorrect, I\u2019 is also after a photometric transformation as written in the text"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4435/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698872968926,
        "cdate": 1698872968926,
        "tmdate": 1699636418110,
        "mdate": 1699636418110,
        "license": "CC BY 4.0",
        "version": 2
    }
]