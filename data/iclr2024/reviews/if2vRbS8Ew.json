[
    {
        "id": "w1uBQsTB93",
        "forum": "if2vRbS8Ew",
        "replyto": "if2vRbS8Ew",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5215/Reviewer_pdse"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5215/Reviewer_pdse"
        ],
        "content": {
            "summary": {
                "value": "This paper analyzes the representations learned by first-order ANIL (Almost-No-Inner-Loop), a representative gradient-based meta-learning algorithm. The analysis is performed in the context of two-layer linear networks in an overparameterized multi-task regression setting, where the width of the network is larger than the dimension of the ground-truth parameter subspace. The results generalize prior results from Collins et al. where it is assumed that the width of the network is well-specified and the number of samples in each task is sufficiently large."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-\tThe analysis is technically solid and in general well-presented.\n-\tThe discussion and comparisons with prior results are clear."
            },
            "weaknesses": {
                "value": "-\tAs suggested by the paper, the main conceptual message, as well as the key distinction induced by the network overparameterization, is that meta-learning not only learns the desired subspace spanned by the columns of $B_*$, but also \u201cunlearns\u201d the orthogonal complement of this subspace. However, the analysis is based on the fact that the number of inner-loop training samples $m_\\mathrm{in}$ is insufficient so the inner-loop gradient descent is prone to overfitting, which is then penalized by the outer-loop meta-training process. What if we use other techniques to mitigate overfitting such as weight decay as commonly used in practice?\n-\tIn the high level, the theoretical results in this paper show that overparameterization/more task-specific data provably _hurts_ generalization in their simplified meta-learning setting. I am not sure if this is consistent with the growing empirical evidence that overparameterization/more data usually _helps_ generalization in practical deep learning. Does this mismatch suggest that the linear model considered in this paper is somewhat over-simplified?"
            },
            "questions": {
                "value": "-\tWill it change the learned representations if we add l2 weight decay regularization to the meta-training objective to avoid overfitting (with finite/infinite samples per task)?\n-\tIs there any empirical evidence suggesting that having more samples in each task can be harmful to gradient-based meta-learning approaches in practice, beyond your numerical experiments?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5215/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698072249094,
        "cdate": 1698072249094,
        "tmdate": 1699636519361,
        "mdate": 1699636519361,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JTDih38GuW",
        "forum": "if2vRbS8Ew",
        "replyto": "if2vRbS8Ew",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5215/Reviewer_aoqC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5215/Reviewer_aoqC"
        ],
        "content": {
            "summary": {
                "value": "This work theoretically studies the ability of first-order ANIL to find useful generalisation points for a network trained on one subsequent gradient descent step. Firstly the authors show that ANIL is able to align to the same feature space as the ground-truth data generating model and also completely ignores the orthogonal complement of this feature space. This implies that ANIL is learning an appropriate representation space for the set of possible tasks, essentially affording the model an initialisation with useful features. The benefit due to this useful initialisation is then characterised by bounding the network's risk for a new task after a single gradient step. This is shown to have better scaling when the network hidden layer is smaller than the original input feature space. Experiments demonstrating the alignment of the features space learned by  ANIL to ground-truth are shown and some results showing the benefit of ANIL over ridge regression are also shown."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "## Originality\nThis work uses a teacher-student style of analysis where a ground-truth model generates data for the subsequent trained model. This is a well-established method of analysis but I have not seen it applied to ANIL or meta-learning. Thus, this work presents a sufficiently original setting for theory. It is also made clear how this work departs from other similar analysis in recent literature such as [1].\n\n## Quality\nAssumptions of this work are clearly stated and the limitations made explicit. The setup is also appropriate for studying the desired phenomena. The results and conclusions drawn from the theory are accurate and clear. Similarly, the interpretation of experimental results is also clear and direct from what is shown. The experimental design showing the approach of the meta-learned feature space singular values is also appropriate and supports and complements the theoretical results. The logical progression of the arguments made in Sections 2 and 3 is also intuitive and follows a clear structure which is appreciated.\n\n## Clarity\nThe paper is well written and figures are clear and neat. Notation is used appropriately and is intuitive. Of particular note is how the mathematics is discussed. The language is clear and precise. This results in the mathematics and notation supporting the written discussion very well. I don't feel like it is always the case that both forms of exposition are of a high quality and it does help this work greatly. The Introduction is also particularly clear and establishes the setting of the paper well.\n\n## Significance\nThe significance of this work is a particular strong points. The results shown here are practical and insightful. The fact that ANIL provably learns features is an important result and I can a lot of future work tying into these results - even just by analogy or inspiration, for example in work on the lottery ticket hypothesis and continual learning. Additionally, the result of a convergence rate provides a helpful degree of nuance to the results and one which I can see guiding practical intuition and future work which aims to converge quicker.\n\n[1] Liam Collins, Aryan Mokhtari, Sewoong Oh, and Sanjay Shakkottai. Maml and anil provably learn representations. arXiv preprint arXiv:2202.03483, 2022."
            },
            "weaknesses": {
                "value": "## Quality\nThere are unfortunately some weaker points to the quality of this work as well. I do not think enough is done to thoroughly guide a reader through the actual theory of this work. While I appreciate that presenting theory in a page limit is difficult - and I do not propose for full derivations or anything of the sort be moved out of the appendix - there is in general little discussion or proof sketches presented. As a result the theorems and propositions are stated and it is not clear how the statement is derived from the premise. This is better for Proposition 1 than Theorem 1, where Proposition 1 at least has some discussion in the paragraph following immediately where it is stated that the error is decomposed into three terms and then bounded by concentration inequalities. What is two lines of writing then lead to deeper insight and more of this is needed. I see in Appendix A that a proof sketch of Theorem 1 is given and it is quite long. But as far as I can tell sufficient space could be made for a condensed version in the main paper and this should be prioritised as Theorem is the main result of this work which even Proposition 2 relies on. As a result, some points which I think could be very impactful fall flat, such as those at the top of page 5.\n\nOn the point of making space for a proof sketch, I appreciate the in-depth discussion of this work. However I am not certain that it should be prioritised over more technical detail. Particularly the long comparison to [1] seems excessive for the main paper and could be deferred to the appendix along with much of this section. Another example would be the statement \"Theorem 1 answers the conjecture of Saunshi et al. (2020).\" but the conjecture is not stated and so this does not benefit the reader. I would also caution against phrases like \"More importantly, the infinite samples idealisation does not reflect the initial motivation of meta-learning, which is to learn tasks with a few samples. Interesting phenomena are thus not observed in this simplified setting.\". Once again, this is quite conversational and speculative for the main body of work. It also comes across as fairly combative and seems to belittle prior work. Thus, I think it would be best to compress the discussion, keeping mainly the limitations component and the component which introduces Burer-Monteiro since it is used in the experiments. This would make significance space for Appendix A in the main paper.\n\nFinally, I am concerned that the experiment summarised in Table 1 does not quite assess or demonstrate the truth of Proposition 1. Since a scaling law is given in Proposition 1, is it not possible to experimentally show how tight of a bound this is? Rather than just demonstrating that meta-learning can out-perform ridge regression on the input features but not ridge regression on the ground-truth representation?\n\n## Clarity\nI re-iterate that I think clarity is a strong point of this work. If possible, I would suggest a figure summarising the setup be presented. It would certainly be helpful and could significantly aid clarity. Once again space would need to be made, but I think the Introduction could also be compressed to make this possible. This is a minor point and I do think the setting is clear just with the notation. If such a figure could not fit in the main paper then one in the appendix would still be helpful.\n\nGiven the above. I would be inclined to increase my score to a 6 or 7 if the restructuring of Appendix A and Section 4 occurs and is done so clearly. I would increase my score further if experiments supporting Proposition 1 are shown and the figure summarising the setup included."
            },
            "questions": {
                "value": "1. Can Equation 7 not be simplified further since $\\Sigma_*$ is proportional to the identity matrix and $B_*$ is orthogonal?\n2. The scaling law on the generalisation error of FO-ANIL is based on $k$ while linear regression is based on $d$. This is used to justify that FO-ANIL outperforms regression, but does this only hold when ground truth representation space is smaller than the input space $k < d$? What if $k>d$?\n3. On the first line of the subsection titled \"Initialisation Regime\" the bounded initialisation for Theorem 1 is mentioned. This seems different to what is stated in the theorem. Where exactly does this need for bounded initialisation appear in the theorem or its assumptions?\n\n## Minor Points\n1. \"The goal of meta agnostic methods\" is a typo.\n2. Why is the highlighting misaligned for the pdf? There may be a rendering issue."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5215/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5215/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5215/Reviewer_aoqC"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5215/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698707326880,
        "cdate": 1698707326880,
        "tmdate": 1699636519259,
        "mdate": 1699636519259,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "eL48P4CZTr",
        "forum": "if2vRbS8Ew",
        "replyto": "if2vRbS8Ew",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5215/Reviewer_FVcv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5215/Reviewer_FVcv"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the shared representation learned by first-order ANIL in a linear multi-task model. It theoretically shows that in the case of infinite tasks and overparameterized width, FO-ANIL succeeds in extracting the low-rank ground-truth shared structure while learning to ignore orthogonal directions allowing for fast adaptation. It empirically validates these theoretical findings contrasting the low-rank FO-ANIL solutions with those found via multi-task learning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well motivated, presents its results clearly and is well embedded in existing literature.\nThe findings it presents are interesting and novel."
            },
            "weaknesses": {
                "value": "The paper clearly motivates the need to study a simplified linear, first-order, single gradient-step version of ANIL. Nevertheless, a small-scale empirical verification to the extent by which violating some of these assumptions affect the results could have further strengthened the paper.\n\nWhile proofs for all theoretical results are provided in the appendix, the code for reproducing the small empirical section was missing upon submission to the best of my knowledge. Providing it would increase my confidence in the reproducibility of the paper."
            },
            "questions": {
                "value": "1. In your theoretical analysis you assume matching depth in the model architecture. Since this is a linear model, is it possible to say something about the case where we have a mismatch in terms of the number of layers? (given that in the linear case this does not change the expressiveness of the model)\n2. Have you tried adding a nonlinearity to your model in the empirical experiments? I wonder to what extent this affects the main conclusion of learning the right subspace and unlearning the orthogonal one."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5215/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5215/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5215/Reviewer_FVcv"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5215/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698746652159,
        "cdate": 1698746652159,
        "tmdate": 1699636519168,
        "mdate": 1699636519168,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LRT7e4Mnyz",
        "forum": "if2vRbS8Ew",
        "replyto": "if2vRbS8Ew",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5215/Reviewer_4g2e"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5215/Reviewer_4g2e"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the ANIL meta-learning algorithm, and proves that the meta-learned feature extractor converges towards a fixed point.\nThis result is obtained under the following assumptions:\n\n- The learned architecture is a two-layer linear network, possibly over-parameterized.\n- The algorithm is ANIL with first-order gradient (ie, FO-ANIL where the adaptation loop is not differentiated).\n- There are infinite tasks but finite samples per tasks.\n- Each task is generated by with a ground-truth linear regressor and additive noise.\n\nAdditionally, it shows that such fixed point yields a good performance after only a single step of gradient descent adaptation. The authors provide an extensive (and insightful!) discussion of their results, and validate them empirically under similar assumptions as above."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Strong and correct theoretical analysis: the authors obtain non-trivial results for FO-ANIL and \u2014 to the best of my assessment \u2014 their analysis is correct. I especially like the two-steps approach, which first shows the existence of a fixed-point representation (Theorem 1), and then showing that this fixed-point achieves low excess risk (Proposition 1, Appendix C).\n- In-depth discussion of results: my favorite part of the paper is Section 4, where the authors discuss the implications of their results. For example, they clearly contrast their result with prior work and argue that, in the over-parameterized regime (large width), model-agnostic methods such as ANIL can outperform traditional multi-task methods. (See \u201cSuperiority of agnostic methods\u201d in Section 4.) They also show that this advantage does not appear with infinite samples thus motivating future work to pay attention to this regime. They also bring attention to the importance of a full-rank initializations, which is a generally understudied area in gradient-based meta-learning, potentially responsible for the many instabilities we observe in practice."
            },
            "weaknesses": {
                "value": "- Significance: while the analysis is strong, I wonder if it is relevant. FO-ANIL is almost never used in practice (ANIL is cheap enough), and definitely not with (two) linear layers. Thus, could the authors bring forward the insights that may apply to more realistic settings? I know others also consider this setting (eg, Tripuraneni et al., 2020) but they tend to include insights beyond parameter convergence (eg, effect of task diversity).\n- Limited scope of empirical results: since this paper studies a highly idealized setting, I would hope the authors could provide results echoing their theorems in settings where the assumptions are relaxed. For example, what about multiple non-linear layers? Or 2nd-order ANIL (or even MAML)? Or a cross-entropy loss, which would be relevant to classification problems? Or, better, could we validate these insights on benchmarks widely used in the literature for real-world algorithms? ANIL is easy and cheap enough to implement that these asks are not unrealistic and would strongly support the authors\u2019 results.\n- Novelty: the authors emphasize that their analysis is in the finite-sample regime, which they successfully argue is significantly more relevant than infinite-sample one. However they are not the first ones to study this setting: as they mention, Collins et al., 2022 already consider it, but Ji et al., 2022 (Theoretical Convergence of Multi-Step Model-Agnostic Meta-Learning) and Fallah et al., 2021 (Generalization of Model-Agnostic Meta-Learning Algorithms: Recurring and Unseen Tasks) also do, and provide convergence guarantees and generalization bounds for MAML, a more generic algorithm than ANIL. Neither of these works are mentioned in the paper, so I\u2019d encourage the authors to discuss the novel insights they bring to the meta-learning community which are not already available in these works."
            },
            "questions": {
                "value": "- While ANIL is typically motivated as an approximation to MAML, it much more closely resembles metric-based few-shot learning such as prototypical networks, metaoptnet, or R2D2 where the main difference is the algorithm to solve the linear head. How difficult would it be to extend your results for ANIL to these methods?\n- In section 4, you discuss overfitting at the end of the \u201cinfinite task models\u201d paragraphs. It isn\u2019t obvious to me how unlearning the orthogonal space reduces overfitting and why there\u2019s no need to unlearn it with infinite samples \u2014 could you expand on what is meant? I\u2019m trying to understand how this observation may translate to the other methods mentioned above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5215/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699245508073,
        "cdate": 1699245508073,
        "tmdate": 1699636519055,
        "mdate": 1699636519055,
        "license": "CC BY 4.0",
        "version": 2
    }
]