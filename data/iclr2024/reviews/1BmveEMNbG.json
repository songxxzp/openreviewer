[
    {
        "id": "06zc4YycKG",
        "forum": "1BmveEMNbG",
        "replyto": "1BmveEMNbG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4528/Reviewer_QmUh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4528/Reviewer_QmUh"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the challenging task of reasoning on knowledge graphs using neural link predictors. The prevailing method in this field is query embedding, which treats logic operations as set operations and has shown empirical success. However, the paper argues that many claims made in previous research lack a formal and systematic inspection. To address this, the authors characterize the scope of previously investigated queries, identify the gap between the formulation and the goal, and provide complexity analysis for the queries. They also introduce a new dataset with ten new types of queries and propose a new neural-symbolic method called Fuzzy Inference with Truth value (FIT) that combines neural link predictors with fuzzy logic theory. The empirical results demonstrate that FIT outperforms previous methods significantly in the new dataset and also surpasses previous methods in the existing dataset."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The paper shows many different opinions against previous series of works. The discussion firmly supports that TF query family is not even a subset of EFO1. In addition, the paper rethinks the traditional claim that \u201creasoning involves an exponential growth in computational time\u201d. The proposition and analysis finally found that the Tree-Form EFO1 reasoning complexity is linear to the number of variables in the query.\n2. The paper provides a comprehensive analysis of the prevailing method of query embedding and its limitations. It identifies the gap between the formulation and the goal, which adds clarity to the field and helps in understanding the limitations of existing approaches.\n3. The introduction of a new dataset with ten new types of queries is a significant contribution. This dataset allows for a thorough investigation of complex queries and provides a benchmark for evaluating future methods.\n4. The proposed method, FIT, which combines neural link predictors with fuzzy logic theory, is a novel approach. It addresses the limitations of previous methods and demonstrates improved performance in both the new and existing datasets.\n5. The paper presents empirical results that support the superiority of FIT over previous methods. The significant improvement in performance in both datasets strengthens the credibility of the proposed method."
            },
            "weaknesses": {
                "value": "Lack of introduction to related works: The paper lacks a section on related works, making it difficult for readers who are not familiar with the definitions and concepts in previous research. This can hinder the understanding of the paper and limit its accessibility to a broader audience."
            },
            "questions": {
                "value": "The paper could benefit from providing more examples and illustrations to aid in understanding the concepts and methodologies discussed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4528/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4528/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4528/Reviewer_QmUh"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4528/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698696170683,
        "cdate": 1698696170683,
        "tmdate": 1699636430022,
        "mdate": 1699636430022,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LZfOl0bItH",
        "forum": "1BmveEMNbG",
        "replyto": "1BmveEMNbG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4528/Reviewer_Z6xA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4528/Reviewer_Z6xA"
        ],
        "content": {
            "summary": {
                "value": "This paper shares author's rethinking over complex queries on knowledge graph with neural link predictor especially towards answering EFO_1 queries. Authors discussed the difference between previous widely researched tree-form queries and EFO_1 queries and their relationships, and pointed out that the tree-form queries are with unrigorous formulations. Thus they propose to pull the complex query answering research back to answering EFO_1 queries with rigorous formulations, and propose a method with neural link predictor based on fuzzy logic theory, called FIT. FIT outperforms baselines significantly in the new EFO_1 query dataset and also surpasses baselines in the existing dataset at the same time."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Authors rethink complex queries on KGs with theoretical analysis. \n2. A new EFO_1 dataset are created to evaluate the EFO_1 query answering task. \n3. And the proposed method FIT shows good performance over EFO_1 datasets and existing tree-form datasets."
            },
            "weaknesses": {
                "value": "The basic idea of the new proposed method is based on fuzzy logics and neural link predictor. This general idea is also introduced in FuzzQE[1]. But the key difference between FIT and FuzzQE is not clearly discussed and FuzzQE is not compared in Table 2.  \n\n[1] Xuelu Chen, Ziniu Hu, Yizhou Sun. Fuzzy Logic Based Logical Query Answering on Knowledge Graphs.  AAAI2022."
            },
            "questions": {
                "value": "1. Should the $r_1$ and $r_2$ be exchanged in Equation (3)? i.e. Should Equation (3) be $\\forall x. (r_3(b, y) \u2227 \u00acr_2(x, y)) \u2228 (r_3(b, y) \u2227 \u00acr_1(a, x))$ ?\n2. What is main difference between FuzzQE and FIT?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4528/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698830348717,
        "cdate": 1698830348717,
        "tmdate": 1699636429928,
        "mdate": 1699636429928,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "i5gl40fMsx",
        "forum": "1BmveEMNbG",
        "replyto": "1BmveEMNbG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4528/Reviewer_TtwJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4528/Reviewer_TtwJ"
        ],
        "content": {
            "summary": {
                "value": "The paper has 2 main contributions:\n\n1. Describing the gaps in EFO1 queries studied by past work\n- Past work [1] has studied a subset of existential first-order logic queries on knowledge graphs (KGs). In particular, past work has studied tree-form queries with negated atomic relations\n- Authors point out that the studied query types do not entirely cover the EFO1 query family and describe the missing families of query structures\n- They create a dataset Real-EFO1 that consists of EFO1 query structures not studied by past work and benchmark competitive graph query execution approaches\n\n2. Proposing a fuzzy-logic based approach for executing EFO1 queries on knowledge graphs\n- Authors propose a fuzzy-logic based query execution algorithm Fuzzy Inference with Truth values (FIT)\n- The algorithm extends QTO proposed by [2] in the following ways:\n    - It extends QTO to handle cycles in the query graph\n    - It sparsifies the neural link prediction matrices to improve the run-time complexity of the algorithm for certain query types\n    - It demonstrates that the link predictor can be trained end-to-end directly with the query execution training data\n\n[1] Hongyu Ren and Jure Leskovec. Beta embeddings for multi-hop logical reasoning in knowledge graphs. NeurIPS 2020\n[2] Yushi Bai, Xin Lv, Juanzi Li, and Lei Hou. Answering Complex Logical Queries on Knowledge Graphs via Query Computation Tree Optimization. ICML 2023"
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The paper clearly describes differently query families and establishes the query structures that are missing from past work\n2. The proposed Real-EFO1 dataset extends the family of query structures studied in the query execution literature with intuitive examples and connections to past work\n3. The proposed FIT approach shows consistent improvement over the baseline approaches and is properly ablated\n    - Experiments show that FIT reduces to QTO under the appropriate conditions and that the additional differences lead to performance improvements across all settings\n    - Examples show how past approaches (designed for tree-form queries) cannot easily handle the new query structures while fuzzy inference can handle them"
            },
            "weaknesses": {
                "value": "1. I believe that the paper misunderstands the definition of tree-form queries used by [1]\n    - [1] explicitly limit their definition of tree-form queries to only consider the negation of individual atomic formulae (i.e. they consider queries can by build from a query tree using $r(x, y)$ and $\\neg r(x, y)$. Therefore, the problem of introducing universal quantifiers is avoided by [1]\n    - However, definition 8 in this paper uses a different (broader) definition of tree-form queries. Under this new definitions, tree-form queries could require universal quantification and fall outside the EFO1 category\n    - I believe this mismatch shakes some of the grounded for Section 3 (Section 4 is still valid in my opinion, since it tries to describe EFO1 - TF)\n2. The connections between FIT and QTO are not sufficiently stressed in the main paper (and this analysis is pushed to the Appendix)\n    - I believe that making this connection is important for a fair comparison to QTO\n\n[1] Hongyu Ren and Jure Leskovec. Beta embeddings for multi-hop logical reasoning in knowledge graphs. NeurIPS 2020"
            },
            "questions": {
                "value": "Questions\n---\n1. I would like to reiterate Weakness 1 described above. I believe that the definition of tree-form queries used in this work differs from the definition used by past work and that the mismatch makes Section 3 obsolete. Please comment.\n\nTypos\n---\n1. (Important) Definition 6: Missing definition of EFO1 query family\n\nSuggestions\n---\n1. Eq 4: It would be good to have an intuitive definition of k here\n2. Overall, the paper pushes a lot of context to the Appendix. It would be helpful if the main paper summarized the corresponding Appendix section rather than just point to it"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4528/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699333344679,
        "cdate": 1699333344679,
        "tmdate": 1699636429857,
        "mdate": 1699636429857,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8nNtgNZH88",
        "forum": "1BmveEMNbG",
        "replyto": "1BmveEMNbG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4528/Reviewer_sXg1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4528/Reviewer_sXg1"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses neuro-symbolic execution of knowledge graph queries. The authors use a graph representation of a symbolic (first order logic) query, and for potentially incomplete knowledge graphs, the authors propose FIT, an algorithm to compute the answer to a query in a message-passing type of algorithm over the query graph, with probabilities of all possible relations. They argue that tree-form queries cannot represent queries with existential leaves, so they cannot cover the full space of first order logic. They show experiments where FIT outperforms existing query graph execution approaches on 10 sampled query types from 3 KGs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. For incomplete knowledge graphs, proposed algorithm FIT is essentially a custom message-passing algorithm over nodes and edges computing the probability of every possible relation and updating the neighboring node probabilities accordingly to reach the answer set. It may have the advantage of staying faithful to the allowed relations or combinations from the query graph and KG, since it builds the solution by exploring only those combinations, and using back-propagation to update the values from the actual answer.\n\n2. The experiments confirm improvements over existing first order logic neuro-symbolic methods for computing the answer set."
            },
            "weaknesses": {
                "value": "1. Baselines - Graph neural networks (based on message passing and backprop over the query graph) is likely a baseline to consider, since this follows a more controlled message passing approach to the solution. This was not considered in the paper. The overall performance in mean reciprocal rank is still low (~30) in two of the datasets. What would explain the difficulty or effectiveness in those cases?\n\n2. Presentation - The computation of the Cu(node) from the probability of the relations, is not provided in the paper (It should be in the main paper, not the appendix, to allow for key aspects to be presented as a whole). The introduction could be clearer about how or why this fuzzy approach (or neural symbolic approach) is required for incomplete KGs. Are there other benefits of it?\n\n3. The proof for tree-form not capturing all first order logic queries I am not sure about. The authors suggest that existential leaves cannot be represented, but that does not prove that any FOL query could not be converted into a potentially different tree form structure."
            },
            "questions": {
                "value": "See weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4528/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4528/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4528/Reviewer_sXg1"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4528/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699476349344,
        "cdate": 1699476349344,
        "tmdate": 1699636429785,
        "mdate": 1699636429785,
        "license": "CC BY 4.0",
        "version": 2
    }
]