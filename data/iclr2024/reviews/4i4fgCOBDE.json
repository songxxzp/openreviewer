[
    {
        "id": "94SuW60irW",
        "forum": "4i4fgCOBDE",
        "replyto": "4i4fgCOBDE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3726/Reviewer_LXYw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3726/Reviewer_LXYw"
        ],
        "content": {
            "summary": {
                "value": "This paper theoretically and empirically shows that graph convolutional networks (GCNs) can exhibit preferential attachment (PA) bias in link prediction, where GCNs tend to predict more links between high-degree nodes that belong to the same social group. The authors propose a simple training-time strategy, based on a fairness regularization term, to mitigate within-group unfairness in GCN link prediction. Experiments show this term reduces unfairness without severely impacting prediction performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1) This paper provides abundant theoretical analysis under the specified settings.\n\n(2) This paper proposes a new metric to quantify within-group unfairness in link prediction, which measures disparities in link prediction scores between social groups. The proposed fairness regularizer also provides a simple and effective way to address the newly characterized unfairness.\n\n(3) Experiments are comprehensive in terms of the number of datasets, showing the effectiveness of the proposed training time debiasing solution."
            },
            "weaknesses": {
                "value": "(1) This paper mainly analyzes the GCN model, failing to consider more widely used alternatives in LP tasks, e.g., SOTA contrastive methods. In addition, this paper relies on relatively simple settings. For example, this paper only considers performing LP with an inner-product decoder, while adopting an MLP classification model on top of the Hadamard product between a pair of node embeddings is more widely used.\n\n(2) There is no baseline adopted for comparison in this paper, and it is not reasonable to avoid such a comparison by claiming the studied problem is novel. It would be necessary to see whether the studied problem is a prevalent problem among different commonly used LP methods.\n\n(3) The evaluation of fairness regularizer utilizes the loss itself as a metric, which seems to be not convincing: the loss would be reduced as long as the gradient descent is effective in most cases."
            },
            "questions": {
                "value": "(1) Does this studied fairness issue widely exist in those commonly used link prediction models, such as those contrastive GNNs? Is the theoretical analysis in this paper generalizable to them?\n\n(2) Will those commonly used LP models naturally underperform or outperform the reported performance under fairness regularization?\n\n(3) Is there any particular reason why the analysis is performed on GCN? Since the vanilla GCN is not commonly used for LP tasks, this seems questionable to me.\n\n(4) What is the time complexity of the proposed regularization-based method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3726/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698416794520,
        "cdate": 1698416794520,
        "tmdate": 1699636329053,
        "mdate": 1699636329053,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KdA1gRBfwA",
        "forum": "4i4fgCOBDE",
        "replyto": "4i4fgCOBDE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3726/Reviewer_bJuY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3726/Reviewer_bJuY"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates the bias towards high degree nodes in link prediction when the underlying model is a  Graph Convolutional Network based on one of two filters: the symmetric normalized graph laplacian or on the random walk normalization. It does so by proving two theorems. For the first filter, it shows that the expected raw score output for an edge (i,j) is proportional to the geometric mean of the (\"in-block\") degrees of the adjacent nodes, under the assumptions of (1) social stratification, (2) expander graphs and that (3) each path from i to j in the computation graph is independently activated with a constant probability dependent on i. For the second filter, it did not uncover a direct relationship with degree. The authors conduct experiments on 10 datasets to validate their theoretical analysis (i.e., comparing the expected raw score with the actual GCN output for several pairs). Moreover, the work bridges this preferential attachment bias and within-group fairness in graph-based recommendation. It proposes a within-group (un-)fairness metric, which measures the disparity among (disjoint) social subgroups within a group. The paper proposes a simple regularization term based on the aforementioned metric to improve fairness and show its efficacy through additional experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "S1. The paper provides a theoretical analysis to explain preferential attachment biases in GCN-based link prediction.\n\nS2. The assumptions made in the proofs are either supported by experiments or based on empirical evidence from other papers that analyze social network graphs.\n\nS3. Based on the estimate derived for the raw output score, the paper proposes a within-group fairness metric and uses it a (in-processing) fairness regularization method to correct for bias.    \n\nS4. The work bridges preferential attachment bias in graph link prediction and current work in within-group fairness.\n\nS5. The text flows nicely and it is very well-written."
            },
            "weaknesses": {
                "value": "W1. The theoretical analysis is done for two types of filter (symmetric graph Laplacian and random walk), but only the first one is reasonably validated by the experiments. The second one still seems to yield a wide range of scores for different node pairs but this variance is not captured by the estimate.\n\nW2. Some aspects of the initial motivation can be clarified.\n\nW3. There are some other works that attempt to mitigate degree biases in GNN-based link prediction that have not been discussed."
            },
            "questions": {
                "value": "Q1. The authors offer a potential explanation as to why the theoretic LP scores are not strong predictors of the $\\Phi_r$ scores: the extra dependence on the square root of the maximum ration between (in-block) node degrees.\n- How to test this conjecture? Did you observe that the relative error is smaller for lower values of this ratio?\n- How is the variance in the prediction score related to the node degrees? Did you try plotting a similar graph where the y-axis is some function of $\\widehat{D}_i$, $\\widehat{D}_j$ or both? \n- What are the connections between this result and steady-state of the classic RW on a non-bipartite connected graph?\n\nQ2. Some excerpts were not entirely clear until later in the paper:\n- In the explanation for Figure 1, does \"social group\" refer to gender or discipline?\n- In the previous example, if men may receive more collaboration recommendations, why not to fix the maximum number of recommendations per individual? Fewer recommendations could be provided if the model is not very confident about some of them. Is it a problem of calibration (i.e., the model tends to make overconfident predictions for certain subgroups)?\n- In  Eq. (5), which ones takes precedence: exponentiation to the L-th power or subscripting ij? Consider using\n$[(D^{-1/2} A D^{-1/2})^L]_{ij}$ and $[( D^{-1} A)^L]_{ij}$.\n\nQ3. Are you familiar with these works? Please discuss whether they should be included as part of related work.\n- Kojaku, Sadamori, Jisung Yoon, Isabel Constantino, and Yong-Yeol Ahn. \"Residual2Vec: Debiasing graph embedding with random graphs.\" Advances in Neural Information Processing Systems 34 (2021): 24150-24163.\n- Harry Shomer, Wei Jin, Wentao Wang, and Jiliang Tang. 2023. Toward Degree Bias in Embedding-Based Knowledge Graph Completion. In Proceedings of the ACM Web Conference 2023 (WWW '23). Association for Computing Machinery, New York, NY, USA, 705\u2013715. https://doi.org/10.1145/3543507.3583544"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3726/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_bJuY",
                    "ICLR.cc/2024/Conference/Submission3726/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3726/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698634621476,
        "cdate": 1698634621476,
        "tmdate": 1700217688037,
        "mdate": 1700217688037,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gE55ZxJHKN",
        "forum": "4i4fgCOBDE",
        "replyto": "4i4fgCOBDE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3726/Reviewer_LDLM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3726/Reviewer_LDLM"
        ],
        "content": {
            "summary": {
                "value": "This paper explores the impact of degree bias in networks on Graph Convolutional Network (GCN) link prediction (LP). The authors investigate how the preferential attachment mechanism, which creates degree discrepancies between nodes, can impact link prediction scores. Moreover, they explore within-group fairness to investigate if the bias in link prediction is additionally enlarged by considering subgroups considering two attributes, such as ethnic background and gender. The research focuses on GCNs with symmetric and random walk normalized graph filters and examines their LP scores within the same social group. They find that GCNs with symmetric normalized filters exhibit within-group preferential attachment bias in link prediction. This bias can result in disparities in link prediction scores between social groups, potentially amplifying degree and power imbalances in networks. \n\nIn particular, the authors provide a theoretical analysis of a within-group preferential attachment bias in link prediction of GCNs with symmetric normalized graph filters. They empirically validate these findings on 10 real-world networks. For GCNs with a random walk normalized filter, the authors theoretically do not find a PA bias, which is however contradicted by empirical evidence. Building on these findings, the authors contribute a new within-group fairness metric for LP, which quantifies disparities in LP scores between social groups. Lastly, the authors propose a training-time strategy to alleviate within-group unfairness, which they assess on three real-world networks revealing its effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The manuscript is well written and, in my opinion, a valuable contribution to the literature. The authors carefully derive their theoretical results and perform experiments on real-world datasets which (mostly) back up their results. Even when the authors find discrepancies between their theoretical predictions and their experiments, the limitations are discussed appropriately. \nThe extension of the fairness assessment to within-group fairness is an important consideration that is often missing in the current literature. The authors also point towards intersectionality literature, which would be an interesting extension which is probably not possible due to space constraints."
            },
            "weaknesses": {
                "value": "Right before Section 4.2 the authors rightly state that \u201csuch \u201crich get richer\u201d dynamics can engender group unfairness when nodes\u2019 degrees are statistically associated with their group membership\u2026\u201d\n\nWhether or whether not nodes\u2019 degrees are statistically associated with their group membership largely depends on their group size and homophily of the interactions. Maybe a discussion of the impact of homophily would be appropriate here. \nThe authors only state in their future work, that it would be useful to study heterophilic networks as well, but never touch on the concept of homophily in the rest of the paper. \n\nMoreover, it would have been interesting if there would have been a larger discussion of the interpretation of the different intersections of groups in the within-fairness part and how marginalisation of certain social groups paper aligns or contradicts with social science literature.\n\nIn Figure 2, a legend of the colour code of the dots would be helpful.\n\nTo me, the adaption of node classification datasets to LP did not become as clear. Is it true, that the labels are associated to network structure and are now used as the group truth for the groups? If this is true, the networks would anyways be largely homophilic, that could be stated somewhere.\n\nVery minor: page 21 C: \u201cWe we row-normalise\u2026\u201d"
            },
            "questions": {
                "value": "see weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3726/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3726/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3726/Reviewer_LDLM"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3726/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698671876243,
        "cdate": 1698671876243,
        "tmdate": 1700318677329,
        "mdate": 1700318677329,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ruWrsm4qG6",
        "forum": "4i4fgCOBDE",
        "replyto": "4i4fgCOBDE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3726/Reviewer_qGCf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3726/Reviewer_qGCf"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the fairness of link prediction in Graph Neural Networks (GNN), focusing on within-group fairness and the \"rich get richer\" effect in networks. Its main result, as given in Theorem 4.3, is that GCNs with symmetric normalized graph filters exhibit a bias toward within-group preferential attachment. Numerical experiment verifies this theoretical result to a good extent."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper has good mathematical rigor, and the results are significant.\n2. I find Lemma 4.1 and Theorem 4.3 interesting and enjoyable to read. They should be of great interest to community interested in deciphering the societal implications of GNN-based LP when they are deployed on large-scale social systems.\n3. The experiments are well-designed and well support the theory."
            },
            "weaknesses": {
                "value": "1. The assumption about the independence of path activation probabilities (\u03c1s(i) and \u03c1r(i)) is rather strong and may not hold true in real world. This can have great effect on the theoretical result. It would be helpful to discuss more.\n\n2. Canonical GNNs nowadays are rarely used for link prediction task due to some of their inherent limitation. Some of the classical works on link predictions, like [1, 2, 3], all use some additional signals one top canonical GNNs. It would be great, if possible, to also give some theoretical discussions on these works.\n\n\n\n\n[1] Graph Neural Networks for Link Prediction with Subgraph Sketching, ICLR 2023\n[2] Link Prediction Based on Graph Neural Networks, NeurIPS 2018\n[3] Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning, NeurIPS 2020"
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3726/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698893776408,
        "cdate": 1698893776408,
        "tmdate": 1699636328805,
        "mdate": 1699636328805,
        "license": "CC BY 4.0",
        "version": 2
    }
]