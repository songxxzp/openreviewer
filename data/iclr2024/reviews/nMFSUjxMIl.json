[
    {
        "id": "ASg4N5li0y",
        "forum": "nMFSUjxMIl",
        "replyto": "nMFSUjxMIl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7365/Reviewer_StPZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7365/Reviewer_StPZ"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new dataset, CircuitNet 2.0, for prediction tasks in the EDA area. The dataset extends CircuitNet with new circuits, labels, and features. The dataset has been verified as effective by some realistic ML tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Nowadays, the dataset for ML on EDA is still very limited. This dataset can prompt research in this area.\n\n2. The dataset files are very complete, which can help researchers to use them.\n\n3. The paper also includes the analysis of the dataset, exploring some possible usage of it, such as the timing analysis. Also, it discusses some problems and solutions, such as the imbalance of data.\n\n4. The data acquisition is expensive. According to the paper, some designs cost over one week. The work can help researchers save their time and money."
            },
            "weaknesses": {
                "value": "1. The dataset can be seen as an extension of CircuitNet with a few new features and labels, which can be easily obtained from the synopsis tools. For the number of designs, CircuitNet 1.0 and 2.0 both contain about 10,000 designs. According to experience, doubling the amount of data has limited improvement in prediction accuracy.\n\n2. Prediction tasks using the dataset are not the final task for chip design tasks. In other words, the most significant tasks in EDA are decision tasks. Thus, the impact of this data set still appears to be limited."
            },
            "questions": {
                "value": "Will the trained parameters of the timing, routing, and IR-drop prediction models be open-sourced to reproduce the results of Table 3, B1, and B2?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Reviewer_StPZ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698319295221,
        "cdate": 1698319295221,
        "tmdate": 1699636880989,
        "mdate": 1699636880989,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OShyMu5zqP",
        "forum": "nMFSUjxMIl",
        "replyto": "nMFSUjxMIl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7365/Reviewer_Xf2K"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7365/Reviewer_Xf2K"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an advanced large-scale dataset for chip design called CircuitNet 2.0 which aims to motivate the ML development for EDA. Specially, over 10,000 samples including CPU, GPU, and AI Chip are collected and multi-modal features with labels in the dataset can be used in various prediction tasks, such as routability, timing, and power. Experiments on multiple realistic machine learning tasks, i.e., learning on imbalanced data and transfer learning are introduced to verify its potential."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The development of a large-scale public dataset is crucial for the advancement of ML algorithms in EDA area. This work provides rich design types for practical prediction tasks.\n2. The experiments on imbalanced data and transfer learning are reasonable and sound."
            },
            "weaknesses": {
                "value": "1. The large-scale dataset which contains more than 10000 samples is originated from only eight open-source designs, especially three smaller CPU designs. It is likely that samples from the same design share similar features.\n2. Note that most settings in the design flow are conducted in the floorplan and powerplan stages, some combination of parameters may be unreasonable compared to those realistic industrial designs."
            },
            "questions": {
                "value": "1. The t-SNE plot in section 4.2.2 is confusing. Where are the GPU and AI Chip?\n2. In the transfer learning experiment, how long does it take to train 20000 iterations?\n3. Could the authors verify the advantage of training with multi-modal data? It seems that only graph-based input is adpoted in section 4.1."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Reviewer_Xf2K"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698489779727,
        "cdate": 1698489779727,
        "tmdate": 1699636880879,
        "mdate": 1699636880879,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "caG0Ia4Ezo",
        "forum": "nMFSUjxMIl",
        "replyto": "nMFSUjxMIl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7365/Reviewer_uzNQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7365/Reviewer_uzNQ"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces CircuitNet2.0, an open-source EDA dataset, containing data to support multi-model prediction tasks in order to promote ML innovations in a realistic chip design."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Compared to previous efforts, CircuitNet 2.0 is a more advanced large-scale dataset: 1) provides data for large-scale CPU, GPU, and AI chips with millions of gates; 2) is based on advanced 14nm FinFET technologies; and 3) supports 3 kinds of tasks, including routability, IR-drop, and timing.  \n2. This paper explains the dataset (e.g., feature, label) generation flow along with the EDA tool flow, which can inspire the following works to contribute to the ML EDA dataset. \n3. This paper demonstrates two realistic ML tasks using CircuitNet2.0 to show the how to solve the potential challenges in ML EDA datasets."
            },
            "weaknesses": {
                "value": "1. The paper mentions that the current most efficient method for EDA problems is combining ML model with the classical heuristic optimization methods: using ML models to predict tool outcomes at early design stages and guide heuristic optimization has become a popular approach in EDA. In the evaluation part, only the pure ML prediction outputs are evaluated, the overall performance combining ML model with the classical heuristic optimization methods is not shown. It would be better if the authors could show such an overall performance. Since training ML models are also costly, there may be no need to introduce ML models to every P&R stage."
            },
            "questions": {
                "value": "1. If possible, can the author show several examples to demonstrate the benefit of the overall performance (e.g., P&R time) by combining ML model with the classical heuristic optimization methods? \n2. Considering this paper targets EDA problems, can conferences such as DAC and ICCAD be a more suitable platform for publishing this paper?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Reviewer_uzNQ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699222056915,
        "cdate": 1699222056915,
        "tmdate": 1699636880758,
        "mdate": 1699636880758,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AMjcqtaAxF",
        "forum": "nMFSUjxMIl",
        "replyto": "nMFSUjxMIl",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7365/Reviewer_XfNZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7365/Reviewer_XfNZ"
        ],
        "content": {
            "summary": {
                "value": "The main contribution of this work is to propose a dataset called CircuitNet 2.0. Due to the release prohibition and human overload, the research field of EDA lacks sufficient datasets. Even those existing datasets are mostly small. Huge and high-quality datasets are valuable, so the proposition of such datasets basically has value. Compared with the previous large dataset CircuitNet, this 2.0 version is more capable in design types, advanced technologies, and timing prediction tasks. The dataset has a total of 10,791 samples, which is similar to CircuitNet."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "+ Compared with CircuitNet which only considers CPU, CircuitNet 2.0 has more design types, including CPU/GPU/AI chip, which enriches the diversity of chip designs and benefits the approximation to the distribution of chip designs.\n+ The samples in CircuitNet 2.0 are absolutely different from the ones in CircuitNet, so these two datasets could be used simultaneously and might train a better model.\n+ CircuitNet 2.0 uses more advanced 14nm FinFET technologies and displays the additional timing prediction task that CircuitNet does not perform."
            },
            "weaknesses": {
                "value": "- Each sample in the same design has the same number of cells, nets, macros, pins, and IOs, so this dataset is not suitable, to some extent, for the majority of ML approaches since the training would easily lead to overfitting. The authors lack the discussion with regard to overfitting and latent negative impacts.\n- This is not a severe weakness but the author claims in Section 4.1.2 that the performance of MLP is lower than that of GNN, which leaves a doubt because the GNN is delicately devised but the devise of MLP seems to be arbitrary.\n- Please refer to some other concerns and questions in `Questions\u2019.\n- typo: line 12th in section 4.3, two `introduce\u2019."
            },
            "questions": {
                "value": "- I note that the samples took a very long time to generate. What is the total generation time? How many and what kind of machines are used to generate these samples?\n- What about the results of congestion prediction on the training set? For example, what about the NRMSE and SSIM on CPU cases when using CPUs as training data?\n- What does `details\u2019 mean in Table A.2? What are the numbers below?\n- Is the learning rate the same in transfer learning? (Figure 6)\n- In the experiments of congestion prediction and IR-drop prediction, models using CircuitNet 2.0 as training data have more advanced performance than those using CircuitNet. In these two experiments, what are the `unseen designs in the test set\u2019?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7365/Reviewer_XfNZ"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699330165515,
        "cdate": 1699330165515,
        "tmdate": 1699636880576,
        "mdate": 1699636880576,
        "license": "CC BY 4.0",
        "version": 2
    }
]