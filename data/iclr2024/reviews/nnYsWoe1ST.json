[
    {
        "id": "3ysW6pblOm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4322/Reviewer_1DSs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4322/Reviewer_1DSs"
        ],
        "forum": "nnYsWoe1ST",
        "replyto": "nnYsWoe1ST",
        "content": {
            "summary": {
                "value": "This paper provides comprehensive empirical studies in comparing self-supervised learning (SELF-SL) and semi-supervised learning (SEMI-SL). Specifically, this paper tries to answer the question \u201cWhen to favor one over the other?\u201d. In particular, the authors investigates the cases of in-domain, near-domain and out-of-distribution data, robustness to image corruptions and adversarial attacks, cross-domain few-shot learning, and the ability to learn from imbalanced data."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThe paper is generally written in a clear way.\n2.\tThe experiments are sufficient."
            },
            "weaknesses": {
                "value": "1.\tSome claims in this paper are not proper. For example, the authors claim that \u201cThese two lines of research (i.e., SELF-SL and SEMI-SL) have progressed largely independent of each other\u201d. However, to my best knowledge, many semi-supervised learning borrows the idea of contrastive learning, which is an important SELF-SL paradigm, e.g., CoMatch: Semi-supervised Learning with Contrastive Graph Regularization (ICCV 21), CLDA: Contrastive Learning for Semi-Supervised Domain Adaptation (NIPS 21), Class-Aware Contrastive Semi-Supervised Learning (CVPR 22), etc.\n2.\tI\u2019m not sure whether it is fair to directly compare SELF-SL and SEMI-SL. Firstly, it should be noted that in many practical cases, we can easily acquire the pre-trained large model from web, but the abundant data for training such large model are not released due to privacy issue (except the models pre-trained on ImageNet or other public datasets). When we come to the present problem, what we have are small amount of data-of-interests at hand and the available pre-trained model. At this time, we can only use SELF-SL. Secondly, even we have the training data (maybe unlabeled) for pre-trained model, the distribution of these data is different from that (maybe labeled) in the current task. SELF-SL perfectly fits this setting. However, for SEMI-SL, the labeled data and unlabeled data are usually generated from the same distribution, but SELF-SL will probably fail in this setting. Therefore, I think in many cases, SELF-SL and SEMI-SL are not directly comparable, as they have their own advantages in specific setting and application.\n3.\tThe number of tables in this paper is strange. The authors mentioned that \u201cThis matches with the empirical observations in Table 4.1.\u201d However, I cannot find Table 4.1 at all.\n4.\tThis paper conducts comprehensive experiments in comparing SELF-SL and SEMI-SL, which is good. However, it would be better if more analyses can be provided for the results in different investigated tasks."
            },
            "questions": {
                "value": "See my comments on weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4322/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697382863014,
        "cdate": 1697382863014,
        "tmdate": 1699636401403,
        "mdate": 1699636401403,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BBvz5dfiUO",
        "forum": "nnYsWoe1ST",
        "replyto": "nnYsWoe1ST",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4322/Reviewer_9YZg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4322/Reviewer_9YZg"
        ],
        "content": {
            "summary": {
                "value": "This paper compares semi-supervised learning (semi-SL) with self-supervised learning (self-SL) to establish when one should be used in place of the other in the context of 4 applications where unlabeled data is available: (1) In-domain, where labeled and unlabeled data sampled from same distribution, (2) near-domain, where the downstream task contains data with significant overlap as ImageNet and can use retrieval-based classification with previously-learnt features, (3) Out-of-distribution detection, and (4) natural corruption & adversarial robustness. Self-SL and semi-SL are described to differ mainly by the timeline at which unlabeled data is introduced as well as how the two frameworks select clusters. For each of self-SL and semi-SL, the authors choose 2 algorithms each and compares the performance on all of these tasks. Overall, semi-SL is shown to outperform self-SL on all tasks, or at worst performs comparably."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* With the increasing availability of pre-trained models, it is important to understand when semi-SL is beneficial. The experiments in this paper show that at least in the tasks considered, semi-SL still has an advantage over self-SL.\n* The paper does a good job of describing the similarities and differences between semi-SL and self-SL."
            },
            "weaknesses": {
                "value": "* As the authors mention, self-SL is typically used to learn \"generalizable representations\" and is often applied when there is a very large unlabeled dataset. Further, semi-SL is typically benchmarked against in-domain performance which, despite the names of the tasks considered, is what the paper focuses mostly on. Therefore, I think it's not too surprising that semi-SL outperforms self-SL on the set of tasks the authors focus on. \n* What I think would be more interesting is to understand (1) if semi-SL is still beneficial when using pre-trained models and (2) when one outperforms the other with respect to the unlabeled dataset's size. I.e. I don't think the set of tasks considered in this paper is the truly interesting ones that are relevant to practitioners. \n* While this paper shows that semi-SL outperforms self-SL, it doesn't really show *why* semi-SL outperforms self-SL. The closest this paper gets to explaining the observations is some intuitions or assumptions, but I think the authors should go a bit deeper, e.g. check if we can control the timeline at which unlabeled data is introduced or if the difference in how clusters are selected is truly impacting performance.  \n\nI'm open to discussion and think the problem addressed is very important, but at this stage I feel that there's not much \"new\" information that can be inferred from the experimental conclusions."
            },
            "questions": {
                "value": "* Comments under weaknesses: Why not use both semi-SL and self-SL? What are possible explanations for why semi-SL outperforms self-SL in these experiments?\n* What are the reasons for choosing the 2 semi-SL and 2 self-SL methods? Could the conclusions of this paper change if one chooses to use a different algorithm for semi-SL or for self-SL?\n* (Minor) Certain paragraphs could be broken up into smaller paragraphs with more relevant sentences together. There are some typos (Semil-SL after Eq. (2)), and the equation rendering could be improved. In-text references should appropriately use (Author, Year) vs. Author, year using the appropriate \\cite command variants."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Reviewer_9YZg"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4322/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697772764705,
        "cdate": 1697772764705,
        "tmdate": 1699636401317,
        "mdate": 1699636401317,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qLsCA71VSv",
        "forum": "nnYsWoe1ST",
        "replyto": "nnYsWoe1ST",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4322/Reviewer_TpWL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4322/Reviewer_TpWL"
        ],
        "content": {
            "summary": {
                "value": "This paper attempts to analyze both self-supervised learning and semi-supervised learning at the same time. The author does a lot of experiments to try to show that semi-supervised learning is useful. But there are many parts of the expression that are puzzling, which I will expand on below."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The perspective of this paper is a thoughtful, as both self-supervised learning and semi-supervised learning are indeed paradigms that can take full advantage of unlabeled data when there is insufficient labeled data."
            },
            "weaknesses": {
                "value": "1.This paper does not reveal the relationship between self-supervised learning  and semi-supervised learning on a theoretical level.\n\n2. All experiments should add results with only labeled data.\n\n3.There is a problem with the citation formatting in this paper."
            },
            "questions": {
                "value": "1. As for uniformity and alignment in self-supervised learning, how is it reflected in semi-supervised learning, and what does it do for semi-supervised learning; traditional semi-supervised learning loss is rarely used clustering obj, please explain in detail in combination with fixmatch, pseudo label and other methods.\n\n2. In self-supervised learning, there is a class called supervised contrastive  learning, whose definition of clustering is also on class-level, has this situation been considered in the article? In the case there is also a direct illustration of the early introduction of labels. \n\n3.For experiments with OOD, closed-set acc should be reported in addition to AUROC, which are two different measurement dimensions.\n\n4.The experiments on self-supervised learning and semi-supervised learning seem pretty cut and dry, and I don't doubt that both self-supervised learning and semi-supervised learning can be done well on tasks like in-domain, out-of-distribution data, but what does putting the results of these experiments together tell us about what's going on, and where's the connection?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed.",
                    "Yes, Privacy, security and safety"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Reviewer_TpWL"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4322/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697970706056,
        "cdate": 1697970706056,
        "tmdate": 1699636401125,
        "mdate": 1699636401125,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "smMSq4ALXD",
        "forum": "nnYsWoe1ST",
        "replyto": "nnYsWoe1ST",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4322/Reviewer_UA6u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4322/Reviewer_UA6u"
        ],
        "content": {
            "summary": {
                "value": "This paper explores how the choice of Self-SL versus Semi-SL framework affects performance on in-domain, near-domain and out-of-distribution data, robustness to image corruptions and adversarial attacks, cross-domain few-shot learning, and ability to learn from imbalanced data using two semi-supervised learning algorithms and two self-supervised learning algorithms."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The topic of the paper is attractive, and the chosen research direction is worth exploring.\n2. The writing of the paper is well-done, making it easy for readers to follow and finish quickly.\n3. The author has taken a comprehensive approach to experimental settings."
            },
            "weaknesses": {
                "value": "1. There are too few comparative algorithms in this paper. The author uses two algorithms each to represent semi-supervised learning and self-supervised learning, which is destined to yield less comprehensive conclusions.\n2. The contribution seems somewhat limited. Apart from the analysis of experimental results, the paper appears to lack new insights. The scope of the topic is broad, but the actual work done is relatively minimal.\n3. As an experimental paper without new theoretical, algorithmic, or conceptual contributions, there must be stringent requirements for the experiments. However, the current volume of experiments falls far short of the standards for an experimental paper. In addition to the issue of a limited number of comparative algorithms, there are several other concerns, such as the use of only one dataset for some settings, a narrow range of evaluation metrics, and seemingly running each experiment only once. The research direction of the paper is meaningful, but the amount of work and contributions fall far below the average standards for acceptance. Drawing significant conclusions from insufficient experiments is overly one-sided.\n4. The first 5 pages of the 9-page paper are devoted to summarizing and introducing the background, while halt of the last 4 pages are occupied by figures and tables. The remaining text primarily focuses on describing experimental settings, with only a small portion dedicated to vague summarization and analysis."
            },
            "questions": {
                "value": "I feel that not all semi-supervised learning algorithms and self-supervised learning algorithms can be generalized to Equation (1). Many algorithms do not involve clustering, and in most cases, the clusters are unknown. Please provide a more detailed explanation for this."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4322/Reviewer_UA6u"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4322/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699350443699,
        "cdate": 1699350443699,
        "tmdate": 1699636401020,
        "mdate": 1699636401020,
        "license": "CC BY 4.0",
        "version": 2
    }
]