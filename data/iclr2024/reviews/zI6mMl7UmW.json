[
    {
        "id": "aU1HIVQ5dk",
        "forum": "zI6mMl7UmW",
        "replyto": "zI6mMl7UmW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4497/Reviewer_k2v7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4497/Reviewer_k2v7"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the connection between spectral and spatial domains for graph neural networks (GNN). Starting from a graph optimization problem, the authors can interpret an adapted new graph (used for propagation) based on the graph filter. Due to the inversion operation applied to the graph filter and the range of the graph filter\u2019s eigenvalues, this new graph can express an infinite series of the graph Laplacian. Motivated by this advantage against truncated polynomial approximators, the authors design a novel paradigm of GNN, named SAF, which utilizes BernNet and attends to the local and global information. Extensive experiments show the advantages of SAF on various datasets and under different settings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThis paper is well-written. I can pick the core idea effortlessly.\n2.\tThe proposed paradigm SFA is theoretically motivated, and its advantages seem to be well attributed to the expressivity of the adapted new graph.\n3.\tThe empirical studies are comprehensive. It makes the results convincing to evaluate related methods on those recently introduced node classification datasets. The results in the ablation study confirm the source of end2end advantages is the more expressive spectral filtering."
            },
            "weaknesses": {
                "value": "1.\tIn my opinion, the most salient limitation of this work is the necessity to compute spectral decomposition. Although there have been many acceleration methods to conquer the O($N^3$) complexity (as the authors have also mentioned), such complexity will make SFA inapplicable to even moderate-sized graphs such as ogbn-products. Besides, there have been many more theoretical yet less practical graph filtering methods, where what limits their applications is mainly the necessity of spectral decomposition.\n2.\tI am a little confused with the so-called supervised setting. It is obvious that the split ratio is different from that of a semi-supervised setting. However, it seems that the node features of test nodes are also accessible to the compared methods during the training stage, which is the same as the semi-supervised setting.\n3.\tTheoretically, as the adapted new graph can express the power series of graph Laplacian, the most straightforward advantage of SFA, against existing spectral GNNs that use truncated polynomial approximation, is the capability of fitting specific graph filters. Thus, it is desirable to include such experiments in the main context of this paper as BernNet."
            },
            "questions": {
                "value": "Could you explain figure 1 for me? I cannot figure out what the x-axis means as well as how these figures imply your conclusion."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Reviewer_k2v7"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4497/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697703526549,
        "cdate": 1697703526549,
        "tmdate": 1700555158208,
        "mdate": 1700555158208,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NSQKhlSbVC",
        "forum": "zI6mMl7UmW",
        "replyto": "zI6mMl7UmW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4497/Reviewer_wm9b"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4497/Reviewer_wm9b"
        ],
        "content": {
            "summary": {
                "value": "The paper examines spectral GNNs from a spatial perspective, uncovering their interpretability in the spatial domain. It reveals that spectral GNNs implicitly transform the original graph into an adapted version, incorporating non-locality and signed edge weights for label consistency. Based on these insights, the authors propose a Spatially Adaptive Filtering framework that enhances spectral GNNs by leveraging the adapted graph structure for non-local aggregation. The SAF framework addresses issues related to long-range dependencies and graph heterophily by considering global node similarity and dissimilarity. Extensive experiments on 13 node classification benchmarks demonstrate the superiority of the proposed SAF framework over existing models. This work provides valuable understanding of spectral GNNs in the spatial domain and offers a promising approach for improving graph representation learning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tConnect spatial and spectral GNNs. Spectral filters modify the original graph into a new graph showing nice non-locality.\n2.\tIt proposes a novel Spatially Adaptive Filtering (SAF) framework. SAF can balance between spectral and spatial features. As a result, it can mitigate two problems of GNNs: long-range dependencies and graph heterophily.\n3.\tIt provides an analysis about the newly adapted graph. There are two properties: Non-locality and Discerning Label Consistency, which alleviates the long-range dependency and heterophily problems in graphs.\n4.\tComprehensive experiments show that the proposed SAF can promote the performance of BernNet on various datasets."
            },
            "weaknesses": {
                "value": "1.\tSAF is only compatible with BernNet due to its assumption of non-negative filtering. As a result, it raises questions about whether the observed good performance is attributable to BernNet or SAF?\n\n2.\tWhen compared to other spectral methods, SAF requires eigen decomposition, which incurs a time complexity of O(n^3). This is a computational cost that exceeds that of other baseline methods that does not need eigen decomposition (BernNet, ChebNetII)."
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4497/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698643722873,
        "cdate": 1698643722873,
        "tmdate": 1699636425719,
        "mdate": 1699636425719,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NxLrq1MiSm",
        "forum": "zI6mMl7UmW",
        "replyto": "zI6mMl7UmW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4497/Reviewer_WZnB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4497/Reviewer_WZnB"
        ],
        "content": {
            "summary": {
                "value": "This paper explores the significance of spectral graph neural networks (GNNs) in the spatial domain, highlighting their role in capturing non-local information and label consistency. To address limitations associated with fixed-order polynomials, the authors introduce the Spatially Adaptive Filtering (SAF) framework, enabling flexible integration of spectral and spatial features. SAF overcomes issues related to truncated polynomials, enhancing the model's ability to handle long-range dependencies and graph heterophility. Experimental results demonstrate substantial improvements, with SAF outperforming other spectral GNNs on average across various benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1) In this paper, the concept of bridging spectral GNNs and spatial GNNs via a graph optimization framework is a novel and innovative idea.\n2) The SAF framework introduced in this paper enhances the performance of BernNet, surpassing the performance of other baseline models in scenarios involving heterophilic graphs.\n3) Interestingly, the presence of negative edges in the new graph can provide insights into label consistency within heterophilic graphs.\n4) The experiments conducted in this paper are impressively comprehensive, encompassing a wide array of datasets, baseline comparisons, ablation studies, and visualizations."
            },
            "weaknesses": {
                "value": "1. My main concern is the use of explicit eigndecomposition, which I believe is unacceptable in spectral GNNs.\n- The time and space complexity of eigendecomposition for an $n$-dimensional square matrix is $O(n^3)$ and $O(n^2)$, respectively, severely limiting scalability in practice. Even as a preprocessing step, it becomes challenging to execute on graphs with millions of nodes and edges.\n- The primary advantage of spectral GNNs based on polynomials is their ability to avoid the need for eigendecomposition. If eigenvectors were readily available, the design of spectral GNNs would become trivial, rendering polynomial-based approaches unnecessary.\n- While certain works, such as Specformer, have used eigendecomposition, I believe their practical significance is quite limited.\n- Although the authors have conducted practical complexity experiments, preprocessing time and space complexity have not been included.\n\n2. Opting for the Bernstein basis as the backbone may not represent the optimal choice. On the one hand, ChebNetII can also guarantee filter non-negativity, and on the other hand, Chebyshev interpolation boasts lower complexity in comparison to Bernstein approximation."
            },
            "questions": {
                "value": "1) Please refer to the aforementioned weaknesses.\n2) My main concern is the practicality of explicit eigendecomposition, and I would welcome a discussion between the author and other reviewers on this issue."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Reviewer_WZnB"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4497/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698656738968,
        "cdate": 1698656738968,
        "tmdate": 1700488611738,
        "mdate": 1700488611738,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LUQZff6t8g",
        "forum": "zI6mMl7UmW",
        "replyto": "zI6mMl7UmW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4497/Reviewer_2DDa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4497/Reviewer_2DDa"
        ],
        "content": {
            "summary": {
                "value": "This paper investigated the relationship between spectral graph filters and spatial GNNs. The theoretical results suggest that the graph filter obtained in spectral space is able to construct a non-local new graph that contains global connectivity information. By combining the representation aggregating from this adapted new graph with the spectral embedding obtained from polynomial graph filters, a new framework SAF is proposed for node classification. \nThe experiments revealed what the adapt adjacency learned in spatial space. The ablation study shows the effectiveness of spectral filtering, and the node classification performance of SAF is competitive."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Overall, this paper is theoretically solid. The relationship between spatial and spectral is clearly uncovered with theoretical proofs.\n2. The experimental analysis of SAF can effectively demonstrate its capability for capturing heterophilous edges and punishing them with negative weights.\n3. The motivation for finding the correlation between spatial and spectral and combining them is clear and intriguing.\n4. The analysis of attention trends is consistent with intuition, showing the effectiveness of the proposed SAF."
            },
            "weaknesses": {
                "value": "Although the paper includes impressive theoretical analyses, there are some weaknesses as below:\n\n1. The correlation between spectral and spatial domain graph learning has been exposed by several previous works although they do not emphasize this. For example, the work cited in your paper, Interpreting and unifying graph neural networks with an optimization framework, has derived both spectral-domain graph filters and spatial-domain GNN frameworks from the denoising optimization target; some other works like GCNII have also endeavored to analyze their spatial GNN model in the spectral domain.\n\n2. The authors claim that the polynomial filters are limited in K hop, but they do not discuss how this problem is addressed by the proposed model. In my view, it is hard to understand why the combination of graph filter and adapted adjacent also derived from this graph filter can address this limitation.\n\n3. The ablation study should exclude each component.\n\n4. This paper lacks of parameter sensitive analysis regarding $\\tau, \\eta, \\epsilon$, and the experimental analysis regarding different $L$ and $K$."
            },
            "questions": {
                "value": "Please try to fix the questions stated above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4497/Reviewer_2DDa"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4497/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698861577366,
        "cdate": 1698861577366,
        "tmdate": 1699636425562,
        "mdate": 1699636425562,
        "license": "CC BY 4.0",
        "version": 2
    }
]