[
    {
        "id": "VVBsFqb4kG",
        "forum": "2l7g7zwC4z",
        "replyto": "2l7g7zwC4z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7741/Reviewer_ffWZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7741/Reviewer_ffWZ"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a method RENEMB, which employs transformers and CNNs to extract structural information from sentences. They conduct experiments on dialect detection, table understanding, and column type annotation tasks to demonstrate the effectiveness of RENEMB."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper introduces RENEMB, which uniquely combines transformers and CNNs, to extract structural information from sentences.\n2. RENEMB's effectiveness is demonstrated across multiple tasks - including dialect detection, table understanding, and column type annotation."
            },
            "weaknesses": {
                "value": "1. The problem definition in this paper is unclear. While the objective is to better represent the structural information of tabular files, a clear problem definition is absent. The final experiments are conducted on dialect detection, table understanding, and column type annotation tasks. What is the relationship between these three tasks and the paper's objective? Why were these specific tasks chosen? \n2. The motivation is unreliable. The paper claims that previous methods primarily focused on semantic improvements while neglecting textual structural information. However, language models like BERT and GPT, during their pre-training phase, learn both semantic knowledge and structural information. Given this, is there still value in training a separate model solely for recognizing text structural information?\n3. The paper asserts that \"In solving the structural masking task, RENEMB has to learn the difference between special characters that belong within a cell (e.g., a comma delimiting the digits of a number) and those with a structural role (e.g., a comma as a cell delimiter).\" However, the Structural Masking Modeling task simply instructs the model on where to output specific symbols; the model cannot differentiate the same symbol's different meanings based on its position.\n4. The pre-training task \"Same File Prediction\" is not clearly described. Firstly, how is this logistic regression classifier obtained? Furthermore, the process of training BERT through this classifier isn't elaborated upon. Additionally, is the task of classifying whether two rows come from the same file reasonable? Different files might have rows with the same structure.\n5. The paper lacks ablation studies. As a result, it's unclear how the two pre-training tasks and the CNN structure individually impact the final outcomes.\n6. The paper presents a limited number of baseline methods, and they are relatively outdated(between 2019 and 2021). Additionally, the paper lacks analytical experiments to substantiate that the proposed method has learned superior textual structural information."
            },
            "questions": {
                "value": "Please see the comments in the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7741/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698752068903,
        "cdate": 1698752068903,
        "tmdate": 1699636944902,
        "mdate": 1699636944902,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HU9Ac8vkfd",
        "forum": "2l7g7zwC4z",
        "replyto": "2l7g7zwC4z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7741/Reviewer_Wgj4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7741/Reviewer_Wgj4"
        ],
        "content": {
            "summary": {
                "value": "This work introduces a transformer-based model framework designed to embed complex tables in a structurally aware manner. The process begins with pattern tokenization, followed by the use of structurally aware modules to capture the unique structural features of tables. The authors pre-train this framework on a dataset of 1M tabular files and evaluate its performance against state-of-the-art baselines.\n\nHowever, the paper's contributions seem not so solid to me. The practice of employing structural features to encode structured text is not novel, as evidenced by prior research such as [1], and [2]. The authors' approach of utilizing a human-designed structural pattern tokenization to understand structures, followed by the use of basic modules for encoding, lacks technical novelty.\n\nMoreover, recent debates have emerged regarding the optimal way to encode structured text: a structurally aware approach, or grounding and understanding structured text directly using text language models. The latter method has demonstrated superior performance and versatility across various structural forms, including tables, SQLs, and code, as shown in studies by [3] [4]. \n\nReferences:\n\n[1] Li, Yulin, et al. \"Structext: Structured text understanding with multi-modal transformers.\" Proceedings of the 29th ACM International Conference on Multimedia. 2021.\n\n[2] Nassar, Ahmed, et al. \"Tableformer: Table structure understanding with transformers.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n\n[3] Roziere, Baptiste, et al. \"Code llama: Open foundation models for code.\" arXiv preprint arXiv:2308.12950 (2023).\n\n[4] Xie, Tianbao, et al. \"Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models.\" arXiv preprint arXiv:2201.05966 (2022)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The paper is written with clarity, and is easy to understand. \n2. RenEMB shows competitive performance with baselines on three diverse tasks. \n3. RenEMB provides unique solutions to a few stated problems with table representations, including dialect detection, and structural awareness. These experiments show that RenEMB exhibit good structural representation abilities."
            },
            "weaknesses": {
                "value": "1. My major concern is on technical novelty and whether the method is up-to-date and competitive with SOTA table understanding generalist LLMs, as stated in the summary. \n\n2. On pattern encoding method: In Section 2.1, I believe the patterns are not applicable to a multilingual setting. For instance, there are no upper/lower letters in Chinese or Korean language. Also, the pattern would be the same for tables with shared headings over a few columns, as the format of your table 1, and one that does not share headings. \n\n3. On experiment settings: I am not sure if dialect detection and row classification constitute challenging tasks for table understanding. I believe more downstream tasks and finetuning analysis would be necessary. For example, what is the performance of tasks on TableQA\n(WikiSQL, WikiTQ)."
            },
            "questions": {
                "value": "Q1: What is the advantage of RenEMB over methods that directly tokenize tables with bpe and encode the tokenized text as transformers, a practice commonly used in training LLMs, as in Llama, GPT-3, Galactica? \n\nQ2: Can this method apply to multilingual setting or could be used as a general method accross different kinds of table formats and languages?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7741/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767693937,
        "cdate": 1698767693937,
        "tmdate": 1699636944786,
        "mdate": 1699636944786,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dSnUegunbi",
        "forum": "2l7g7zwC4z",
        "replyto": "2l7g7zwC4z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7741/Reviewer_9VNy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7741/Reviewer_9VNy"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a model named RenEmb to embed the structure of the tabular data.\n\nThere are 3 components of the model, namely pattern tokenization, then structural transformer, and CNN."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper seems well written and clear. The target problem seems to have broad interest and very useful importance. The approach seems feasible to be used by many researchers."
            },
            "weaknesses": {
                "value": "The major concern of the paper could seem:\n\na) The model seems only BERT-style and there seems no comparison to real LLM's such as chatgpt. The comparison to LLM's should be a core result, as many researchers have observed the level of paradigm shift by those new LLM.\n\nb) The 1st step of pattern tokenization could make use of structure data that exclude the text content. Would it be enhanced if we have both structure and text? For the new hybrid approach of RenEmb + Strudel, can you let us know the reason that two concatenated models seem more advanced than just 1 stage?"
            },
            "questions": {
                "value": "Would the new method work for complex table, not full row and full column?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7741/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814384873,
        "cdate": 1698814384873,
        "tmdate": 1699636944673,
        "mdate": 1699636944673,
        "license": "CC BY 4.0",
        "version": 2
    }
]