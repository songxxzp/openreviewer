[
    {
        "id": "3GOAxfAR7n",
        "forum": "auguNUCto5",
        "replyto": "auguNUCto5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1741/Reviewer_u41A"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1741/Reviewer_u41A"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on temporal graph representation learning. Different from exiting works that utilize GNN-RNN frameworks or local subgraph information to learn effective node representations, this paper proposes to generate node embeddings by considering both global and local perspectives. Specifically, GCN-TCN is utilized to encode global graph information; TGN is used to model local graph information; Then, self-attention mechanism is employed to aggregate node representations from both global and local embeddings. Experimental results on seven datasets demonstrate that the proposed model can achieve satisfied performance on both link prediction and node classification tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1)\tThis paper investigates temporal graph representation learning, which is an important topic in the graph community.\n2)\tVarious ablation studies are given to show the effectiveness of the proposed components.\n3)\tTime complexity analysis is given, and model efficiency analyses are also presented in the experiment section."
            },
            "weaknesses": {
                "value": "1)\tThe technical contribution of this paper is quite limited. The three components in this paper are all from existing works. The global module is from TCN, and the local module is from TGN. The cross-perspective fusion is a self-attention module. No new module is proposed.\n2)\tIn the cross-perspective fusion module, it is not clear why query $Q_i$ is the linear projection of $Z^{Global}$. What if we use $Z^{local}$ to generate $Q_i$? In this case, $\\tilde{z}$ is the weighted combination of $Z^{global}$ and $z_u = FFN(\\tilde{z}_u \\Vert z_u^{local})$. More ablation studies should be conducted.\n3)\tIn Table 2, it is not clear why the performance of GraphMixer and TIGER are missing in the setting of historical and inductive negative sampling. \n4)\tThere are lots of other manners to combine both the global and local perspectives. For instance, $z_u$ is directly generated by concatenating $Z^{local}$ and $Z^{global}$. $z_u$ can also be aggregated with simple attention mechanism instead of self-attention.\n5)\tIn Equation 10, what if some of the nodes do not have $|\\mathcal{N}|$ neighbors? Are there any strategies to handle this situation? \n\nThere are lots of typos in the paper. For example,\n\nIn Figure 1, \u201cwhether nodes B and C will interact at t3\u201d should be \u201cwhether nodes B and D will interact at t3\u201d\n\n\u201cwe focus on further improve the model performance\u201d should be \u201cwe focus on further improving the model performance\u201d\n\n\u201cWheras, GLEN can keep\u201d should be \u201cWhereas, GLEN can keep\u201d"
            },
            "questions": {
                "value": "1)\tIn Table 2, it is not clear why the performance of GraphMixer and TIGER are missing in the setting of historical and inductive negative sampling. \n2)\tThere are lots of other manners to combine both the global and local perspectives. For instance, $z_u$ is directly generated by concatenating $Z^{local}$ and $Z^{global}$. $z_u$ can also be aggregated with simple attention mechanism instead of self-attention.\n3)\tIn Equation 10, what if some of the nodes do not have $|\\mathcal{N}|$ neighbors? Are there any strategies to handle this situation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics review needed."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1741/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698584396278,
        "cdate": 1698584396278,
        "tmdate": 1699636103357,
        "mdate": 1699636103357,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M8rGEUgEbK",
        "forum": "auguNUCto5",
        "replyto": "auguNUCto5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1741/Reviewer_farU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1741/Reviewer_farU"
        ],
        "content": {
            "summary": {
                "value": "This paper propose GLEN, an adventurous method for effective and efficient temporal graph representation learning. GLEN can generates embeddings for graph nodes by considering both global and local perspectives. Sufficient experimental results demonstrate that GLEN outperforms other baselines in both link prediction and dynamic node classification tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe paper clearly explain the motivation of the idea combining global and local perspectives in temporal graph representation learning, and the reason to use RNN-TCN and TGN correspondingly.\n2.\tThe experiments in this paper are comprehensive, and they provide ample evidence of the model's superiority in terms of performance and efficiency."
            },
            "weaknesses": {
                "value": "1.\tIn the specific components of the model, many aspects are not novel. For example, RNN-TCN and TGN are both derived from previous works. In Cross-Perspective Fusion Module, this module is a common transformer.\n\n2.\tI still have some doubts regarding the use of RNN-TCN for extracting global information. Both GCN and TGN employ similar information aggregation approaches, aggregating nodes up to n-hops away. Why is RNN-TCN considered to be more effective in representing global information?"
            },
            "questions": {
                "value": "See \u201cWeaknesses\u201d"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1741/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1741/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1741/Reviewer_farU"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1741/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698751840809,
        "cdate": 1698751840809,
        "tmdate": 1699636102865,
        "mdate": 1699636102865,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dmw1YrgyYm",
        "forum": "auguNUCto5",
        "replyto": "auguNUCto5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1741/Reviewer_K85V"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1741/Reviewer_K85V"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel Global and Local embedding Network (GLEN) for temporal graph representation learning, which captures both local and global information. Specifically, GLEN first generates both local and global embeddings, and then combine these embeddings via cross-perspective fusion module. The proposed GLEN is evaluated on several real-world datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea of local embedding and global embedding is novel and interesting. For a given window of the temporal graph, GCN is used to extract node embeddings for each time stamp. TCN is used to capture global node embeddings, and a temporal interval weighting module is used over a restricted neighborhood to capture the local embeddings. In the end, the local and global embeddings are combined via a cross-perspective fusion module.\n2. The proposed method could significantly outperform SOTA temporal graph embedding methods on several benchmark datasets, and the ablation study demonstrates that each of the proposed component is crucial for model's performance.\n3. The writing of the paper is clear in general."
            },
            "weaknesses": {
                "value": "1. The motivation of the cross-perspective fusion module needs further clarification. Why do you use the global embedding as the query but not the local embedding? Why not (1) use global embedding as query to obtain z1, (2) use local embedding as query to obtain z2 and (3) combine z1 and z2? \n2. What will happen if you only use the local embedding module but without restricting the size of neighbors?\n3. Some details need further improvement.\n(1). What are $\\hat{y}_0, \\hat{y}_1,\\dots$? (Between Eq. (8) and Eq. (9))\n(2). $\\mathbf{h}_v^{(0)} = \\mathbf{s}_v^{(t)}+\\mathbf{x}_v^{(t)}$?"
            },
            "questions": {
                "value": "Please refer to weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1741/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698758438186,
        "cdate": 1698758438186,
        "tmdate": 1699636102785,
        "mdate": 1699636102785,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PXhDGnz45s",
        "forum": "auguNUCto5",
        "replyto": "auguNUCto5",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1741/Reviewer_L1Kz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1741/Reviewer_L1Kz"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses the limitations of existing methods in temporal graph learning, which either focus on global or local perspectives but not both. To overcome this, the Global and Local Embedding Network (GLEN) is proposed. GLEN dynamically generates node embeddings by considering both global and local information. These embeddings are then fused using a cross-perspective module to capture high-order semantic relations. GLEN has been evaluated on multiple datasets and outperforms baselines in tasks like link prediction and dynamic node classification."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. Temporal graph is an important problem to address in practical world, yet majority of the research deals with static graphs only.\n\nS2. The analysis of existing RNN-based work and random walk/message passing models provides useful insights.\n\nS3. The writing/organization of the paper is generally clear, although some parts need more clarification. (See W2)"
            },
            "weaknesses": {
                "value": "W1. The proposed model, while technically valid and sound, is not sufficiently novel or exciting. Combining local and global perspectives are common ideas in graphs. Even on temporal graph, point process based modeling aims to capture the graph-wide evolution pattern from  a global perspective, such as (Lu et al., 2019) and the below paper [a]. A detailed discussion on temporal point processes for temporal graph is warranted, potentially with additional experimental comparison.\n\n[a] Trend: Temporal event and node dynamics for graph representation learning. WWW 2022.\n\nW2. Certain parts in the motivation of the paper are not clearly explained. For example, the following sentences:\n\"Pairwise interactions observed in different graphs or even the same temporal graph typically have different temporal properties.\"\n\"Since the endogenous and exogenous factors driving the generative process ...\" \nI'm not exactly sure how they directly connect to or motivate the proposed method.\n\nW3. In Table 2, Random tends to perform the best compared to historical/inductive strategies. It is surprising and more discussion is needed. (Also, I'm not confident of the results in Table 2, as it has some discrepancy with the results in Table 3 -- e.g. for UCI, the results in Table 2 and Table 3 are different."
            },
            "questions": {
                "value": "Please see Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1741/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698829362853,
        "cdate": 1698829362853,
        "tmdate": 1699636102685,
        "mdate": 1699636102685,
        "license": "CC BY 4.0",
        "version": 2
    }
]