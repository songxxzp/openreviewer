[
    {
        "id": "8gj53cZj8E",
        "forum": "A1z0JnxnGp",
        "replyto": "A1z0JnxnGp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_XjgB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_XjgB"
        ],
        "content": {
            "summary": {
                "value": "The noise tolerance of the quantum kernel method. The noise model considered in this paper is to apply a global depolarizing channel to each layer of the quantum encoding circuit. This paper shows a theoretical characterization of the prediction performance of the quantum kernel in terms of the number of training data, the number of qubits $N$, the strength of the noise $\\tilde{p}$, and the number of layers. It mainly studies three regimes of the training data size. For logarithmically small data, the kernel always fails. For $poly(N)$ size data, it fails when the number of layers is $\\Omega(\\log (N)/\\log (1-p))$. And for $\\exp(N)$ size data, the kernel fails when the number of layers is $\\Omega(N/\\log(1-p))$. Technically, it bounds the L1 distance between the hypothesis obtained from a noisy kernel and a constant function via the Rademacher complexity."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The problem investigated in this paper is a crucial and foundational problem in the field of quantum machine learning. In comparison with previous findings, the noise model considered in this paper is less restrictive. Furthermore, the result holds for quantum circuits of any depth and width and does not rely on strong constraints on the circuit architecture. It reveals some limitations in QML, especially in the NISQ era. Most of the theorems/lemmas appear to be mathematically sound to me."
            },
            "weaknesses": {
                "value": "This paper does not clearly state its differences from prior works, particularly in terms of technical detail. Moreover, most of the results are derived from classical kernel theory. Additionally, the result itself is not surprising. Depolarizing channels can be equivalent to a single depolarizing channel with noise strength that grows exponentially close to 1 as the number of layers increases. Therefore, the output state of the encoding circuit will converge to the maximally mixed state as the number of layers increases. As such, the characterization derived in this paper is quite natural and intuitive. This paper could be strengthened by considering more complicated and practical noise models, as well as the effect of error mitigation. It would be beneficial to conduct further experiments (e.g., testing on real quantum devices)."
            },
            "questions": {
                "value": "Do you have experiments showing the test errors and generalization errors for different numbers of training data (fixing other parameters)?\n\nLine -5 before Sec. 1.3: \u201c...required for probably successful training\u201d, what does \u201cprobably successful\u201d mean? \n\nPage 2, line -7: what is $q$ in \u201c$q^N$\u201d? Is it a circuit parameter or any constant?\n\nPage 3: \u201cindicate that good generalization alone does not necessarily guarantee good prediction for new data\u201d. Does \u201cgood generalization\u201d mean the generalization of the noiseless kernel?\n\nEq. (3): it is unclear whether the square is inside or outside of the expectation. \n\nSec. 2.2: the introduction to the quantum kernel method is not self-contained. A complete workflow should be given for the ease of readers who are unfamiliar with this field. And it should mention which part is quantum and which part is classical. \n\nPage 7, line 5: \u201cThe depolarization noise model in Theorem 3.1 is weaker than the noise model\u2026\u201d Weaker in what sense? Could you state it more explicitly?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1546/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697623078006,
        "cdate": 1697623078006,
        "tmdate": 1699636083079,
        "mdate": 1699636083079,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Z3d8o6gSP7",
        "forum": "A1z0JnxnGp",
        "replyto": "A1z0JnxnGp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_M7Gm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_M7Gm"
        ],
        "content": {
            "summary": {
                "value": "The authors examine the noise-resilience of quantum kernel methods. To achieve this, they first consider the performance of a quantum kernel method $\\overline{h}$ completely dominated by depolarizing noise. They then bound the expected difference in prediction between $\\overline{h}$ and a kernel method at a fixed rate of depolarizing noise, and study when this expected difference vanishes. They consider when the training sample size grows logarithmically, polynomially, and exponentially with the number of qubits used in the quantum kernel, and show that at a fixed depolarizing noise rate, there exist quantum kernels with depths of $\\Omega\\left(1\\right)$, $\\Omega\\left(\\log\\left(n\\right)\\right)$, and $\\Omega\\left(\\operatorname{poly}\\left(n\\right)\\right)$, respectively, where this expected difference vanishes."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "While there have been previous studies on the sensitivity of quantum machine learning algorithms to the effects of noise, to-date so-called \"variational\" methods have been the focus of these studies. Here the authors give explicit bounds for quantum kernel methods, and give nicely define how their bound depends on relevant hyperparameters such as the depolarizing noise strength, the number of qubits of the model, the number of training samples, and so on. The authors also do nice numerical experiments to confirm their theoretical results also hold in practice."
            },
            "weaknesses": {
                "value": "The work is confusingly written, and certain concepts are not fully defined. For instance, \"the kernel matrix\" $K$ is used in Eq. (7) though is never given an explicit definition. There are also typos that need to be corrected, e.g., the title of Sec. 2.2 reads \"qauntum\" rather than \"quantum.\" Furthermore, though Sec. 3 gives a concise rundown of the main Theorems proved in the paper, the implications are lost in the large algebraic expressions for the bounds---a quick explanation as to how these Theorems tie to Figure 1 would be extremely helpful in parsing the results. Finally, the overall picture is not too surprising---deep, noisy variational quantum machine learning algorithms also fail for similar reasons as the authors demonstrate quantum kernel methods fail."
            },
            "questions": {
                "value": "I think the main result is solid, and only recommend some structural changes in the paper for the main result to be clear. Currently Figure 1 is doing most of the heavy lifting in stating a clear result."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1546/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1546/Reviewer_M7Gm",
                    "ICLR.cc/2024/Conference/Submission1546/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1546/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697731852348,
        "cdate": 1697731852348,
        "tmdate": 1700606717281,
        "mdate": 1700606717281,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RcCFQ9fwKa",
        "forum": "A1z0JnxnGp",
        "replyto": "A1z0JnxnGp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_5XBn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_5XBn"
        ],
        "content": {
            "summary": {
                "value": "Quantum machine learning (QML) is an emerging field that explores the power of quantum models for machine learning tasks. Quantum kernel methods have shown promise in various applications. The paper focuses on the prediction capability and limitations of quantum kernel methods under quantum depolarization noise in the NISQ era. It aims to understand the impact of noise on the performance of quantum kernel methods. The paper also presents theoretical bounds and extends the analysis to quantum circuits with certain width and depth."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "One strength of this paper is its focus on the impact of noise on quantum kernel methods. The authors provide insights into the behavior of quantum kernels when exposed to noise, specifically global depolarization noise. They theoretically characterize the concentration speed of predictions of the optimal hypothesis inferred by noisy quantum kernels in terms of several basic factors. This result is meaningful to understand the limitation of quantum kernel model in the NISQ era."
            },
            "weaknesses": {
                "value": "- The noise model is too ideal and limited. It is just a global quantum depolarization noise. For guidelines on characterizing the power of quantum kernel models on noisy devices, it is important to consider more realistic noises. Such strong assumptions as global depolarization noise may not accurately represent real-world noise scenarios.\n- There are several previous works on noisy quantum kernels, such as Wang et al. (2021), Stilck Franca & Garcia-Patron (2021); De Palma et al. (2023), Thanasilp et al. (2022). It is not clear how this work compares to existing research and what new limitations are discovered in this paper. The advantages or significance of this work is not clear enough to me. It would be better if the authors could explain this angle in a more organized way."
            },
            "questions": {
                "value": "- What are the key new findings on the noisy quantum kernel model compared with previous works?\n- Why does the paper only consider the global depolarizing noise? Is this for theoretical convenience?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1546/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1546/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1546/Reviewer_5XBn"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1546/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698577019403,
        "cdate": 1698577019403,
        "tmdate": 1699636082935,
        "mdate": 1699636082935,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ABapGJGV0u",
        "forum": "A1z0JnxnGp",
        "replyto": "A1z0JnxnGp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_VA13"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_VA13"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the question of how having global depolarization noise in the quantum device impacts the prediction performance of a quantum kernel method. The paper provides comprehensive analytical results bounding the generalization errors and conduct numerical experiments to illustrate the analytical results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The problem of noise in quantum devices is a very significant one. Studying the impact of noise on quantum machine learning models is an important question.\n\nThe authors provide a detailed and comprehensive theoretical analysis of the impact of global depolarizing noise on quantum kernel methods (one of the most promising models for quantum machine learning)."
            },
            "weaknesses": {
                "value": "The paper focuses on global depolarizing noise, which is not considered realistic for quantum devices (as well as noisy quantum kernel methods). The natural noise model would be local depolarizing noise, where each qubit is subject to a small amount of noise.\n\nGlobal depolarizing noise has a simple algebraic structure. Hence, the generalization error bounds provided in this work are relatively straightforward to derive.\n\nThe key behaviors of noisy quantum kernel methods illustrated by the analytical results are expected. As the total noise increases, the generalization error decreases while the training error increases. Hence, the generalization error can be close to zero while the prediction performance is bad."
            },
            "questions": {
                "value": "- The authors should provide analytical results based on local depolarization noise. Techniques from https://arxiv.org/abs/2210.11505 and related works should be helpful in this case.\n\n- The numerical experiments can be improved to showcase the dependence on other parameters such as system size and noise rate."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1546/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698623255284,
        "cdate": 1698623255284,
        "tmdate": 1699636082858,
        "mdate": 1699636082858,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "O2Q00mwZPa",
        "forum": "A1z0JnxnGp",
        "replyto": "A1z0JnxnGp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_8JA5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1546/Reviewer_8JA5"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the effect of noise on the performance of quantum kernel methods.  Quantum kernel methods can perform kernel computation on a quantum computer potentially faster than classical computers. This paper studies the effect of NISQ noise and infidelity on kernel methods. Particularly, they study the depolarisation channel (as a noise model) on the power of quantum kernel computations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The main strength of this paper is a series of negative theoretical studies on the effect of depolarisation noise. This is an important topic, especially in near-term quantum computers. The paper looks solid, although I did not check all the proofs."
            },
            "weaknesses": {
                "value": "My major issue with the paper is the correctness of the main result (Theorem 3.1). I might be missing something, as I am not convinced this theorem is correct. Equation (20) in the theorem bounds the distance between the quantum kernel's choice $\\tilde{h}$ and the worst possible predictor $\\bar{h}$. The bound is in terms of the noise bias $p$, the number of samples (n), and the dimension (D). \nBased on this bound $|\\bar{h} -\\tilde{h}|$ converges to zero as $n$ and $D$ grow large regardless of the value of p<1!\n\nSurprisingly, if we set $p=0$, implying no noise, the bound converges to zero! This does not make any sense as we expect when $p=0$, the kernel method should work better than the worst predictor! Am I missing something?"
            },
            "questions": {
                "value": "Q1. Why does the bound in Theorem 3.1 still converge to zero as $p=0$? \nQ2. The samples are classical in this work, but the kernel is quantum. What can be done with your work for the quantum samples?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Not applicable"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1546/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1546/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1546/Reviewer_8JA5"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1546/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699508719363,
        "cdate": 1699508719363,
        "tmdate": 1699636082796,
        "mdate": 1699636082796,
        "license": "CC BY 4.0",
        "version": 2
    }
]