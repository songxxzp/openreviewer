[
    {
        "id": "WZv7jKCf7O",
        "forum": "W3VsHuga3j",
        "replyto": "W3VsHuga3j",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8185/Reviewer_q6an"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8185/Reviewer_q6an"
        ],
        "content": {
            "summary": {
                "value": "The paper tackles modeling bounded rational agents based on their trajectories. It focuses on determining $pi (a | s, R, \\beta)$, where $R$ represents the reward function and $\\beta$ denotes the computational budget. Contrasting the classical Boltzmann model that overlooks varying agent rationality, this work innovatively models $\\beta$ as a variable derived from an agent-centric distribution $p_{\\beta | \\eta}$, with $\\eta$ being inferred using MAP."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- **Originality**: One of the primary strengths of the paper is its original approach to model $\\beta$ using a learnable parameter. This innovation distinguishes it from prior works, offering a fresh perspective in the domain of modeling bounded rational agents. The perspective is novel and fresh.\n\n- **Significance**: The introduction of a learnable parameter for $\\beta$ can potentially change the way we perceive agent behaviors. This approach, if refined and built upon, could pave the way for more advanced and adaptive models in the future. It also hints at the possibility of its application across different domains, making the work potentially impactful."
            },
            "weaknesses": {
                "value": "- **Clarity and Presentation**: The paper often comes across as convoluted, making it difficult for readers unfamiliar with the domain to grasp its core concepts. Clearer explanations, along with better-organized sections, would significantly improve comprehension.\n\n- **Lack of Thorough Literature Review**: The paper does not delve deep into existing works, leaving readers unaware of the full landscape of related research. A dedicated literature review, even if placed in the appendix, would help contextualize the presented work better.\n\n- **Quality of Experiments**: The experimental section lacks rigorous validation on diverse datasets or scenarios, or providing substantial comparisons with more state-of-the-art existing models or methodologies, potentially limiting the generalizability of the proposed method. \n\n- **The Modeling of $\\beta$**: The paper models $\\beta$ in a manner that appears static across the trajectory. However, in realistic scenarios, it would be logical to assume that the distribution of $\\beta$ is adaptive (either in a Bayesian or frequentist manner) and may change at every time step, conditional on histories. This richer representation can offer a more meaningful interpretation of agent behaviors.\n\n- **Ambiguities in Parameter Inference**: While the idea of modeling $\\beta$ with a learnable parameter is commendable, the paper does not sufficiently justify or explain the underlying mechanisms behind the chosen methodology for inferring $\\eta$.\n\n- **Robustness Concerns**: Given the intrinsic variability in agent behaviors, how robust is the proposed method to outliers or erratic trajectories? Were there specific tests or validations done in this regard? I suggest the authors to provide some ablation study in future revisions.\n\nI am happy to raise my score if the authors address some of the concerns above."
            },
            "questions": {
                "value": "- **Literature Review**: Please provide a thorough literature review.\n\n- **Future Directions**: For example, are there plans to address the adaptability of $\\beta$ based on past trajectories? Or would you develop a rigorous theoretical guarantee for the model?\n\n- **Practical Implications**: How does the authors envision the practical implications of this work? In which domains or applications do they see this method having the most significant impact? For example, one of the hottest research recently with real-world impact is on large language models. How may the classical bounded rational agents study make contributions to this direction?\n\n- **Computational Complexity**: Can the authors comment on the computational complexity of their method, especially concerning the inference of $\\eta$ (also please provide more details on the inference methodologies being used)? How scalable is it for large-scale applications?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8185/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698553224294,
        "cdate": 1698553224294,
        "tmdate": 1699637015279,
        "mdate": 1699637015279,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nIlW5XHFWc",
        "forum": "W3VsHuga3j",
        "replyto": "W3VsHuga3j",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8185/Reviewer_KCR8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8185/Reviewer_KCR8"
        ],
        "content": {
            "summary": {
                "value": "The paper presents budget constrained bounded rationality models. In contrast with classic Boltzman rationality, deviations from rationality are formalized as (unknown) limitations on computation instead of simply noise in selection. A simple formulation of budgets constructed as a model over possible inference budgets, and it is observed that inference can be computed efficiently for anytime models. The approach is demonstrated in three domains: inferring goals from actions in navigation, inferring communicative intent, and predicting chess moves. The budgets model individual performance and have meaningful interpretations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper presents an interesting and intuitive formalization of bounded rationality based on constrained computation. \n- The empirical comparisons are nice. \n- The results are interesting."
            },
            "weaknesses": {
                "value": "- There are a few ad hoc decisions buried in the middle, which make the story less clear. \n- Comparisons with other proposals are a bit lacking. This is not the first paper to propose limitations on Boltzman rationality. \n- A more detailed set of results would be nice. \n\nDetailed comments: \n- \"consider again the trajectories depicted in Fig. 1(b\u2013c), which differ only in the difficulty of the search problem, and not in the cost of the optimal trajectory at all.\" There are some pretty big assumptions hidden in here. \n- \"learning a model of these agents ultimately learning reward parameters \u03b8 and agent-specific budget-generating parameters\" missing word?\n- The sampling algorithm for the speech task doesn't seem to be motivated by the idea of a budget. \n- I am not a fan of the visualization in figure 6. It is quite hard to parse."
            },
            "questions": {
                "value": "I would really love to see some additional comparisons. Other than that, I find the paper to be a nice contribution. \n\nI would rate this a 7, but I don't seem to have that option..."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8185/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698761962968,
        "cdate": 1698761962968,
        "tmdate": 1699637015119,
        "mdate": 1699637015119,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "noHjkEekEh",
        "forum": "W3VsHuga3j",
        "replyto": "W3VsHuga3j",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8185/Reviewer_egSD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8185/Reviewer_egSD"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors address the problem of modeling agents with bounded rationality and possibly unknown preferences. They begin by pointing out that the standard Boltzmann model depends only on the return of a particular action and doesn\u2019t account for the structure of a problem in determining the probability of a suboptimal outcome given a particular inference budget for an agent. \n\nIn (2), the agents present L-IBM, a MAP inference algorithm that allows us to infer the reward model and the parameters of the budget distribution for a particular agent from data assuming the agent follows an anytime inference algorithm. Then in the following sections they give instantiations of their setup in maze solving, language generation, and chess. \n\nIn maze solving, they assume the search algorithm is a truncated BFS algorithm with a known heuristic. They show that this is an anytime inference algorithm and then demonstrate on simulated inference data that the L-IBM method is able to entirely recover the correct data-generating parameters while the Boltzman model performs horribly. \n\nIn language, they use a reference game\u2013where one participant must try to communicate with another effectively and must model their understanding well enough to communicate. Here, they borrow a model of Bayesian listeners and speakers from the cognitive science literature. The primary feature of interest in this model is the number of \u201clayers deep\u201d to go in modeling that your partner can model that you know things and you can model that your partner can model that you know things and so on. They again show that this is an anytime inference model and demonstrate using a transformer and an existing dataset of human utterances and choices. Here, the bounded rationality model is able to determine that more skilled players behave in ways that would be considered \u201cdeeper\u201d than those that are less skilled. \n\nHere, the anytime inference algorithm is MCTS as used in AlphaGo and the recent Diplomacy works. In this setting, there are two budget parameters \\beta_UCT, and \\beta_runtime. The method is used to estimate each of these parameters. Using a dataset of human games of players with varying Elo ratings and time controls, the quality of moves is inferred to these two beta parameters and they are shown to correlate with a longer time control, stronger opponent, and stronger player (as one would expect a priori)."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "A substantive assessment of the strengths of the paper, touching on each of the following dimensions: originality, quality, clarity, and significance. We encourage reviewers to be broad in their definitions of originality and significance. For example, originality may arise from a new definition or problem formulation, creative combinations of existing ideas, application to a new domain, or removing limitations from prior results. You can incorporate Markdown and Latex into your review. See https://openreview.net/faq.\n\nI think this paper tackles an interesting question and gives a thorough and principled answer. As we introduce other cognitive agents into the world we ought to have a framework for evaluating their and our behavior on the same terms. This feels like a step towards a more general understanding of this. I think the boundedly rational agents as described in this paper are a substantial generalization of the Boltzmann model. \n\nThe evaluation on 3 domains is thorough and I appreciated the care taken to make them easy to understand and well presented. I found the figures and data presentation to be compelling and the ideas presented have had me update my model of how to think about this kind of thing going forward."
            },
            "weaknesses": {
                "value": "A substantive assessment of the weaknesses of the paper. Focus on constructive and actionable insights on how the work could improve towards its stated goals. Be specific, avoid generic remarks. For example, if you believe the contribution lacks novelty, provide references and an explanation as evidence; if you believe experiments are insufficient, explain why and exactly what is missing, etc.\n\nAt some point in the beginning of the paper the problem statement seemed too general to grab on to and I was mentally scraping around for how to add structure in order to come up with ideas for solutions. I think it would be a nicer reading experience to include a comment gesturing in the direction of anytime inference algorithms in the front part of the paper so as to anticipate this. \n\n\nI\u2019m not sure how to interpret the numerical figures for something like chess in Figure 5. Naively, I tend to think that the effects on predicting next actions are not very large. \n\nIt is not clear to me how much this can be used in the broad main thrusts of ML research today and this work might be of limited use to practitioners. However, I think it is interesting and probably valuable for subjects like reward-free Offline RL."
            },
            "questions": {
                "value": "How hard is it in general to predict the player\u2019s next move in chess?\nIs there an extension of anytime inference that can handle \u201camortized computations\u201d like dynamic programming for value functions or other pre-planning methods?\nWhat did you practically use to implement the inference procedures in this paper? I think the methods would be useful to comment on a bit."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8185/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698783867289,
        "cdate": 1698783867289,
        "tmdate": 1699637015008,
        "mdate": 1699637015008,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AxA7tNOra7",
        "forum": "W3VsHuga3j",
        "replyto": "W3VsHuga3j",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8185/Reviewer_PxXG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8185/Reviewer_PxXG"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a method for modeling bounded rational agents through the inference of latent budget. The method seeks to model an agent's computationally constrained inference by explicitly inferring the latent variable associated with the computational budget jointly with the agent's goals. This is used to both infer agent intent as well the underlying budget, which is correlated with agent competency. The proposed method is experimentally evaluated over three tasks: maze navigation, language understanding, and chess."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper is well-written and motivated. The variety of experimental settings is helpful for gauging model performance, and in particular the inclusion of an experiment with human-generated data (RSA) is valuable in showing performance when the exact underlying agent model is unknown.\n* The inference of agent budget and the correlation to skill is an interesting direction, and may have value in both agent-agent and human-agent interactions."
            },
            "weaknesses": {
                "value": "* The accuracy differences in the RSA and chess tasks are fairly marginal, and seem to indicate that it is difficult to jointly infer both latent budgets and intent in more complicated tasks.\n* The modeling of the latent budget requires fairly strong assumptions about the underlying reasoning mechanism of the agent. In addition to potential misalignment of assumptions, this also leads to situations like Sec. 5.3 where a constant of proprotionality is approximated over the set of all natural strings which are potential additional sources of error.\n* The results graphs are difficult to parse with the frequent reference to variable names that have unintuitive meanings. I realize these are referring to parameters in the agent models and corresponding sub-populations, but it is difficult for the reader to draw conclusions when the results are represented in terms of abstract terms such as beta_temp, beta_depth, beta_runtime, beta_puct, etc. This is compounded by the fact that terms like \"depth\" are used frequently and seem to have context-specific meanings that are not always fully defined."
            },
            "questions": {
                "value": "1) What exactly does beta_temp intuitively represent in the RSA task? This is not entirely clear to me, nor why the figures in Table 3a/b seem to show such uninformative results. Do you have any insight as to why the inferred beta_depth seems to be more informative than beta_temp (in the sense that it seems more correlated with player skill)?\n2) What is the relationship between beta_puct and ELO rating in Sec. 6? For time control it seems reasonable that longer time budgets would enable more exploration, but it seems there would be a trade-off between exploration and exploitation with respect to ELO rating. So it's not clear to me what this relationship is expected to be."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8185/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8185/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8185/Reviewer_PxXG"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8185/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698841773235,
        "cdate": 1698841773235,
        "tmdate": 1699637014873,
        "mdate": 1699637014873,
        "license": "CC BY 4.0",
        "version": 2
    }
]