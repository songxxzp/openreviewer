[
    {
        "id": "W5VxWNuHWT",
        "forum": "TPZRq4FALB",
        "replyto": "TPZRq4FALB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9339/Reviewer_kzfx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9339/Reviewer_kzfx"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of multi-modal test-time adaption (TTA) under the challenge of reliability bias, which refers to the information discrepancies across different modalities due to the distribution shifts between domains. The paper proposes a novel method, RFRA, which consists of two modules: a self-adaptive attention module for reliable fusion across modalities, and a confidence-aware loss function for robust adaption. The paper also provides two new benchmarks for multi-modal TTA with reliability bias based on Kinetics and VGGSound datasets. The paper shows that RFRA outperforms several state-of-the-art TTA methods on these benchmarks under various corruptions."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. This paper is well-written, well-organized, and easy to follow.\n2. The paper addresses a novel and important problem, i.e.,  multi-modal TTA with reliability bias, which has not been well-studied in the literature.  Accordingly, the paper proposes an effective method, RFRA, which leverages self-adaptive attention and confidence-aware loss to achieve reliable fusion and robust adaption across modalities.   Moreover, the confidence-aware loss is simple but effective and enjoy the non-monotonous gradient property.\n3. The paper provides two new benchmarks for multi-modal TTA with reliability bias, which could facilitate future research on this topic. The paper conducts extensive experiments and ablation studies on these benchmarks to demonstrate the effectiveness and superiority of RFRA over existing TTA methods."
            },
            "weaknesses": {
                "value": "1. The paper lacks some experimental details, such as clarifying the terms \u201cStatical\u201d and \u201cDynamic\u201d in Table 1 and explaining the distinctions between the proposed Self-Adaptive Attention and traditional self-attention. It is unclear what these terms mean and how they affect the performance of different methods. The paper should provide more definitions and discussions on these terms. Moreover, the paper should elaborate on how the Self-Adaptive Attention differs from the conventional self-attention in terms of design, implementation, and advantages.\n2. The confidence threshold $gamma$ work as the important parameter in the confidence-aware loss.  However, the influence of the confidence threshold $\\gamma$ on TTA performance is not explored, and it would be beneficial to understand its role more explicitly. The paper could conduct more experiments and analysis to show how different values of $\\gamma$ affect the accuracy and robustness of TTA. The paper could provide provide some insights on how to choose an appropriate value of $\\gamma$.\n3. How does the attention value in Figure 4 calculated? Some explanation is needed. The paper should provide more details on how to compute the attention value for each modality pair in Figure 4.\n4. An outlying problem, how does the audio information used in autonomous vehicle? As most scenarios of autonomous vehicle might use the visual sensor and could your method used in such case? \n5. There is a typographical error in Eq. (4); \u201cA\u201d should be bold. This is a minor mistake that can be easily corrected."
            },
            "questions": {
                "value": "The primary questions for the rebuttal primarily arise from the \"weaknesses\" section. It would be highly appreciated if the authors could provide further explanations regarding the experiments and address the raised concerns, which will strengthen the paper. Overall, I recommend accepting this paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9339/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698460588938,
        "cdate": 1698460588938,
        "tmdate": 1699637175430,
        "mdate": 1699637175430,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BmHoYJ7HBA",
        "forum": "TPZRq4FALB",
        "replyto": "TPZRq4FALB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9339/Reviewer_9FmQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9339/Reviewer_9FmQ"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel approach for addressing reliability bias in multi-modal test-time adaptation (TTA), a challenge arising from information disparities between modalities due to distribution shifts. To investigate the impact of reliability bias, the authors conduct comprehensive analyses involving various multi-modal fusion strategies and state-of-the-art TTA methods. The results underscore two pivotal aspects of effective TTA against reliability bias: dynamic information integration across modalities and noise-resilient adaptation across domains. To tackle these challenges, the authors devise a self-adaptive attention module to facilitate reliable cross-modal fusion and a confidence-aware loss function to ensure robustness against noisy predictions. Furthermore, this paper contributes two benchmark datasets focusing on multi-modal action recognition and event classification. Extensive comparison experiments against existing TTA methods and imbalanced multi-modal learning methods validate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. This paper studies a new challenge (i.e., reliability bias) for multi-modal test-time adaption. Test-time adaption methods aim at adopting the pre-trained model from the source domain to the target domain in real-time and most existing of them focus on single-modality tasks against domain shifts. On the one hand, this paper takes the more complex multi-modal scenarios into consideration. On the other hand, the authors study and tackle the reliability bias challenge. \n\n2. The authors conduct extensive experiments to validate the importance of developing robust TTA methods against reliability bias. On the one hand, the existing cross-modal fusion methods (late fusion, attention-based fusion, etc.) would suffer from reliability bias and cannot achieve reliable cross-modal fusion. On the other hand, the existing TTA method cannot completely reconcile the distribution shifts by updating the parameters of normalization layers, leading to surviving reliability bias across modalities. Furthermore, the authors show that simply handling reliability bias during test time takes more superiority compared to the imbalanced multi-modal learning methods that alter the training process to handle the problem.\n\n3. The proposed method is novel and technically sound. First, the authors focus on the characteristics of multi-modal TTA and design the self-adaptive attention module that repurposes the attention layers during test time for achieving reliable cross-modal fusion. I think the design would inspire the community to design task-specific parameter modulation instead of solely updating the parameters of normalization layers following most existing methods. Second, to achieve robustness against heavy noise during adaption, the authors propose the robust loss function which not only eliminates the influence of noisy predictions but also boosts utilization of the clean predictions with theoretical guarantees."
            },
            "weaknesses": {
                "value": "Although this paper is well-motivated and extensively validated, I still have the following concerns or suggestions, hoping to make the paper more clear and solid.\n\n1. The experiment results are mainly obtained under the setting of severity 5. To establish the method's generality, it is encouraged to expand the empirical results across a spectrum of scenarios, including different severity levels. A broader array of experiments, encompassing various severity levels, would not only fortify the method's reliability but also enhance the comprehensiveness of this study. Moreover,  it would be beneficial to evaluate how the method performs in the context of test-time adaptation (TTA) under unbiased reliability conditions. Specifically, investigating the method's effectiveness in both (i.d.d. and non-i.d.d. scenarios would render it more practical and versatile.\n2. The paper contains extensive analysis and experiments, but some settings require further clarification. For instance, it's not entirely clear what \"Attention A-V\" means in Figure 4 and how the results demonstrate the method's robustness. In the analysis of Figure 5, claims are made about the importance of maintenance between audio and video modalities, but the contrast with clean results is not evident. Additional clarification or supplementary results are needed to support these claims.\n3. There are a few typos and vague statements in the paper, such as \"traf\ufb01c noise in the audio modality\" in the caption of Figure 1, \"information bias\" on Page 2, and inconsistent notations like \"(Stat. LN) & AF\" or \"Stat. (LN & AF)\" in Tables 1-3. These should be corrected for clarity and consistency."
            },
            "questions": {
                "value": "My questions mainly lie in some unclear experiment analysis and  the generalizability of the proposed approach to a broader range of severity levels."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9339/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9339/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9339/Reviewer_9FmQ"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9339/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698470666770,
        "cdate": 1698470666770,
        "tmdate": 1700642127278,
        "mdate": 1700642127278,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZzCyWF5w52",
        "forum": "TPZRq4FALB",
        "replyto": "TPZRq4FALB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9339/Reviewer_r3k4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9339/Reviewer_r3k4"
        ],
        "content": {
            "summary": {
                "value": "This paper delves into test-time adaption under the multi-modal setting and reveals an interesting and practical challenge, namely, reliability bias. In the wild, it is common that some modalities would suffer from distribution shifts compared to their counterparts in the source domain. As a result, the task-specific information across the modalities would be more inconsistent, thus contributing to the reliability differences for different modalities. Extensive empirical studies have been conducted to investigate the impact of the reliability bias using different cross-modal fusion strategies. To achieve robust multi-modal TTA against reliability bias,  the authors propose a novel method, dubbed reliable fusion and robust adaption (RFRA). Different from the existing TTA methods that mainly repurpose the normalization layers to achieve adaption, RFRA modulates the attention module to achieve reliable cross-modal fusion during test time. Besides, RFRA adopts a new objective function with desirable mathematical properties to combat with noise during adaption. To highlight the necessity of developing reliability-bias robust multi-modal TTA, the authors construct two new benchmarks with different settings of reliability bias based on the Kinetics and VGGSound datasets. Finally, the authors validate the effectiveness of the proposed method and give a deep analysis of the reliability bias challenge."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Revealing a new problem. This paper studies a new and practical challenge in the context of multi-modal test-time adaptation, namely, reliability bias. In the wild, it is evitably to introduce distribution shifts in some modalities.  As a result, the task-specific information across the modalities would be more inconsistent, thus contributing to the reliability differences for different modalities. The authors design extensive experiments to investigate the influence of reliability bias under different multi-modal fusion manners and the results validate the necessity of handling reliability bias for multi-modal TTA. I think the revealed challenge would bring some insights to the TTA community.\n2. Constructing meaningful benchmarks. To highlight the necessity of developing reliability-bias robust multi-modal TTA, the authors construct two new benchmarks with different settings of reliability bias based on the Kinetics and VGGSound datasets. Concretely, the benchmarks consist of both video and audio modalities and each modality is with corruptions of different levels so that the reliability bias is simulated. On the one hand, the corruption on video modality follows ImageNet-C, which ensures comparison fairness. On the other hand, the incorporation of audio corruption types extends the utility of this research to the audio domain with TTA. Besides,  the benchmarks encompass diverse multi-modal tasks, including action recognition and event classification, thus providing a comprehensive evaluation and supplementing existing multi-modal test-time adaptation tasks. \n3. Innovative paradigm for TTA. This paper proposes a new paradigm for TTA, namely, repurposing the attention layers during test time. Intuitively, the parameter updating of normalization layers like most existing TTA methods can only handle the distribution shifts between domains. In contrast, the parameter modulation of attention layers would help learn the importance difference between modalities, resulting in the reliable fusion for multi-modal TTA. The authors perform extensive experiments to show the superiority of the proposed new paradigm against reliability bias."
            },
            "weaknesses": {
                "value": "1. While the paper is well-written, it lacks essential details about CAV-MAE, such as the number of attention layers used for fusion. As many evaluations rely on the CAV-MAE framework, providing this information is crucial for the readers and reviewers to fully grasp the methodology. Additionally, visualizing the corruption types on both video and audio modalities would enhance the paper's clarity and help readers better understand the benchmarks.\n2. The paper introduces the modulation of Q, K, and V parameters to address reliability bias. However, it's not clear why the authors chose to update all parameters of Q, K, and V simultaneously. Explaining this choice and discussing the possibility of updating only the MLP parameters of Q and K would provide valuable insights. Furthermore, while the novel attention layer repurposing is effective for reliability bias, the paper should address whether this approach comes at the cost of efficiency for test-time adaptation.\n3. The paper introduces a crucial hyper-parameter, the confidence threshold ($\\gamma$) in Equation 6. While this threshold is fixed in all experiments, it's essential to include ablation studies to explore the sensitivity of the proposed method to variations in this hyper-parameter. A more comprehensive analysis would provide a deeper understanding of the method's robustness.\n\nMinor: Some of the figures, such as Figure 1c and Figure 3b, suffer from low image clarity. Improving the quality of these figures would enhance the paper's visual presentation and make the findings more accessible to readers.\n\nOverall evaluation, I think this paper is above the bar of ICLR, regarding motivation and novelty.\n\n\n----------------------------------\n\nUpon reviewing the response, I note that my concerns have been effectively addressed. Considering the consensus of other reviewers, I wholeheartedly recommend this work with a high level of approval."
            },
            "questions": {
                "value": "My primary concerns revolve around the lack of comprehensive experiment details and the design of the modulation strategies, as highlighted in the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9339/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9339/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9339/Reviewer_r3k4"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9339/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698557479625,
        "cdate": 1698557479625,
        "tmdate": 1700463680427,
        "mdate": 1700463680427,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tpk5GFU4AJ",
        "forum": "TPZRq4FALB",
        "replyto": "TPZRq4FALB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9339/Reviewer_Hrwp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9339/Reviewer_Hrwp"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a method for multi-modal test-time adaption (TTA) in the presence of cross-modal reliability bias. While there are numberer of works in test-time adaption, most of them focus on single-modality tasks and few works consider the practical multi-modal scenarios. In contrast, the authors investigate the characteristics of multi-modal TTA and reveal the task-specific cross-modal reliability bias setting where the information between modalities is unbalanced during test time derived from the distribution shifts across domains in some modalities. The authors conduct analysis experiments finding that the unreliable cross-modal fusion and noisy predictions hinder the robustness against cross-modal reliability bias. As a remedy, this paper proposes a novel method dubbed reliable fusion and robust adaption (RFRA). The idea of RFRA is straightforward. A self-adaptive attention is employed to achieve reliable cross-fusion during test time and a robust loss is adopted to prevent the prediction noise from dominating the adaption process. The authors experimentally validate their method on two new benchmarks against several baselines showing reasonable improvements."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. This paper has a good motivation. The authors focus on multi-modal test-time adaption and reveal a NEW task-specific challenge (i.e., cross-modal reliability bias) for the first time. This paper first empirically proves that the existing test-time adaption methods cannot tackle the cross-modal reliability bias problem. Furthermore, the authors also investigate the effect of adopting the existing unbalanced multi-modal learning methods to handle the cross-modal information discrepancy.  The unbalanced multi-modal learning methods handle the unbalanced multi-modal data during training time with the help of labeled data, which resembles the test-time training paradigm in the domain adaption community. The results indicate that the multi-modal learning methods cannot take superiority for the challenge. In other words, the authors support the claim that designing an elaborated method for the cross-modal reliability bias during test time is essential.\n\n2. The authors take an in-depth study on the cross-modal reliability bias challenge and find that robust cross-modal fusion and noise resistance are essential to achieve multi-modal TTA against reliability bias. To this end, the authors design a novel method dubbed reliable fusion and robust adaption (RFRA). On the one hand, RFRA achieves reliable fusion through the self-adaptive fusion module. On the other hand, RFRA employs an elaborately designed objective function to achieve noise-robust adaption. Figs. 1 and 2 clearly depict the motivation and key idea of the paper. Overall evaluation, this paper is with strong motivation, a technical sound approach, extensive experiments, and good writing."
            },
            "weaknesses": {
                "value": "1. The authors have conducted extensive evaluations on two newly constructed benchmarks regarding the most challenged setting (severity 5 in this paper), and the results indeed verify the effectiveness of handling the cross-modal reliability bias challenge. Even so, I think some challenging TTA settings that are orthogonal to the cross-modal reliability bias might help to improve the practicalness and impact of this work. First, in the practical multi-modal scenarios, the severity of distribution shifts might dynamically vary. It would make the work more practical if the authors could additionally investigate the robustness of the proposed method under the setting MIXED SEVERITIES. Furthermore, it is also common that the corruption types continually vary in the wild, resulting in the demand for continual test-time adaption (CTTA). The proposed approach would be more solid and universal if the proposed method could work in the MIXED DISTRIBUTION SHIFTS setting (i.e., continual TTA setting).\n\n2. Some details are missing. It is not clear how many layers of the attention module are used and repurposed during test time adaption in the proposed approach. And how many parameters do these self-attention layers account for? It is encouraged to supplement comparisons with the TTA baselines regarding the number of modulated parameters and the adaption time, which would make the comparisons more comprehensive.\n\n3. The results of the default setting can be added to the ablation tables for clear clarification. In the current form, the readers need to compare the main table (1,2,3) and the ablation tables for contrast.\n\n4. I carefully read the paper and found two potential mathematical typos. $\\theta_{s}^{m}$ in Line 5, page 4. $\\partial$ in Eq. 9."
            },
            "questions": {
                "value": "My questions are mainly in the efficiency comparisons between the proposed SAF module and the TTA baselines, and some clarification on statements. Moreover, I wonder about the effect of the proposed method on the settings of MIXED SEVERITIES and MIXED DISTRIBUTION SHIFTS. Certainly, this is optional during the rebuttal time because the settings are out of the scope of the paper, but I think the results would strengthen this work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9339/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698672190480,
        "cdate": 1698672190480,
        "tmdate": 1699637175066,
        "mdate": 1699637175066,
        "license": "CC BY 4.0",
        "version": 2
    }
]