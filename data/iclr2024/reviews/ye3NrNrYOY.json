[
    {
        "id": "o1FIBnsAFx",
        "forum": "ye3NrNrYOY",
        "replyto": "ye3NrNrYOY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission342/Reviewer_K1pA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission342/Reviewer_K1pA"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces temporal causal mechanism transfer (TCMT) for few-shot action recognition. It considers the action sequences from a generative model perspective. Specifically, it assumes that base and novel action videos share some common causal relationships. By learning these causal relationships, the model can work better with less training data (few-shot recognition). The overall causal learning framework is built as a variational autoencoder. After the training, only the encoder is kept to perform action recognition with the intermediate representations. The proposed TCMT is evaluated on benchmark datasets including UCF101, HMDB51, and SSv2."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1) The idea is easy to follow and modeling the causal relationship for few-shot action recognition is novel and reasonable\n2) This paper proposed to model the causal relationship between hidden variables and action sequences. By learning the invariant part of the relationship, the parameters of few-shot action recognition model can be reduced since only the auxiliary variable is needed to be considered at each time step. \n3) Comparison of non-causal and causal demonstrates the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "1) In the introduction part, there are no red arrows in Figure 2. But the explanation in the second last paragraph is explaining it using red arrows, which makes the time-delayed causal relations confusing. \n2) Based on the proposed causal modeling process, it seems only first-order dependency is modeled. However, the action sequences probably has high-order dependencies.\n3) The comparison is incomplete, missing many recent work such as:\n[1] Wang, Xiang, et al. \"MoLo: Motion-augmented Long-short Contrastive Learning for Few-shot Action Recognition.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n[2] Zheng, Sipeng, Shizhe Chen, and Qin Jin. \"Few-shot action recognition with hierarchical matching and contrastive learning.\" European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022.\n[3] Wang, Xiang, et al. \"Hybrid relation guided set matching for few-shot action recognition.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n4) There is no justification whether the causal relationship is learned correctly besides the performance improvement. \n5) For the comparison number of parameters, all parameters besides the parameters in the adaption process should be counted since they are needed for inference."
            },
            "questions": {
                "value": "0) It is very slow to open and scroll the submitted document locally. Perhaps Figure 1 (b) has too many objects. I don\u2019t know if this only happen on my site.\n1) For equation (11), is the ratio of L_{ELBO} and L_{cls} 1:1?\n\n2) Just for curiosity, does the hidden variable theta have interpretable meanings? If theta control certain aspects of the action generation process, it would be easier to justify the causal relationship.  \n\n3) To training the autoencoder, joint training may not be optimal. If the CVAE is firstly trained for causal modeling and then jointly trained for maximizing ELBO and classification, maybe the causal relationship can be better learned. In addition, the results from the first step can be used to verify if the causal relationship is correctly captured. \n\n4) In Table 5, what is the \u201cN\u201d used for non-causal, non-temporal, and without theta?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concerns"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission342/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission342/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission342/Reviewer_K1pA"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission342/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698642779848,
        "cdate": 1698642779848,
        "tmdate": 1699635961444,
        "mdate": 1699635961444,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AehPnaBEmJ",
        "forum": "ye3NrNrYOY",
        "replyto": "ye3NrNrYOY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission342/Reviewer_sFNL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission342/Reviewer_sFNL"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for solving few-shot action recognition, which utilises the idea of variational inference to solve the problem, effectively reducing the number of parameters to be learned during adapation phase."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Pros:\n1. The basic motivation is feasible.\n2. The paper gives a good theoretical analysis."
            },
            "weaknesses": {
                "value": "Cons:\n1. The paper mentions that TCMT is capable of \u201cadapt a base model effectively and efficiently when the base and novel data have significant distributional disparities.\u201d However, there is no experimental verification of such performance, and it is hoped that additional experiments in this area or further additions will be made to show that the existing dataset satisfies such conditions.\n2. The authors should add an experiment on the observed time frequency to the section on ablation experiments.\n3. This paper needs further improvement in the writing. For example, in Fig.2, $Z_{1,1}$  has an extra bracket around the variable. And all tables in the paper should be of a uniform size. There are numerous other grammatical errors that I have not mentioned but which take away from the reading experience significantly. I hope the author will review and correct these."
            },
            "questions": {
                "value": "As mentioned above, how does TCMT perform when the base and novel data have significant distributional disparities?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission342/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698765040388,
        "cdate": 1698765040388,
        "tmdate": 1699635961373,
        "mdate": 1699635961373,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wcuc2xrfTA",
        "forum": "ye3NrNrYOY",
        "replyto": "ye3NrNrYOY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission342/Reviewer_G3yX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission342/Reviewer_G3yX"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a few-shot learning for action recognition based on temporal casual representation, called Temporal Causal Mechanism Transfer. The method is built on an assumption that the base data and novel data share certain aspects of the temporal causal mechanism, transition function and mixing function. It conducts experiments on multiple datasets and achieves great performance. Thw writing is somehow good."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea of using temporal causal mechanism for few-shot video recognition is new to me.  \n2. The method is effective and achieves good results on multiple datasets."
            },
            "weaknesses": {
                "value": "1. The third paragraph in the Intro is very highlight and intuitive. The motivation of using casual representation for few-shot action recognition is not clear to me from the paper. \n2. Fig. 2 lacks illustration in both caption and main contents. I can not understand well the methods without much casual representation background. And there is less introduction for the causal representation.\n3. All datasets miss details.\n4. Miss conclusions for all figures of results. The statements for results only list numbers but lack analysis. For example, in Fig. 5, the paper compares the proposed method and a previous method VL-Prompting. What's the difference between the two methods? What makes difference between their results? Why the proposed one is better than the previous one?"
            },
            "questions": {
                "value": "I have two very serious question. Without clarification on the two points, I can not understand the paper well.\n\n1. What\u2019s the motivation/intuition to use causal representation learning for few-shot action recognition? I feel it is not clear to me from the paper.\n2. In the third paragraph in Intro, there is an assumption \"the base data and novel data share certain\naspects of the temporal causal mechanism \u2013 namely, transition function and mixing function \u2013 and\nthat an auxiliary variable captures the disparate aspects of the two data distributions\" which is the base of the method. However, I can not find why the assumption is acceptable?  Is there any support or reference?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission342/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission342/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission342/Reviewer_G3yX"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission342/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818090807,
        "cdate": 1698818090807,
        "tmdate": 1699654860320,
        "mdate": 1699654860320,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Jog8hPpouU",
        "forum": "ye3NrNrYOY",
        "replyto": "ye3NrNrYOY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission342/Reviewer_oCST"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission342/Reviewer_oCST"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes Temporal Causal Mechanism Transfer (TCMT), a new method for few-shot action recognition in videos. The key ideas and contributions are:\n\n- TCMT learns a generative model of a temporal causal process from the base data. This includes a transition function that models time-delayed causal relations between latent variables, and a mixing function that generates action representations from the latent variables.\n\n- For adaptation on novel data, TCMT updates an auxiliary context variable that captures distribution shifts between base and novel data, along with the classifier weights. The transition and mixing functions remain fixed. \n\n- TCMT is evaluated on standard few-shot action recognition benchmarks and achieves state-of-the-art or comparable accuracy with fewer parameter updates during adaptation. \n\n- The effectiveness of TCMT is attributed to the transferability of the learned causal mechanism. Ablations validate the benefits of modeling temporal relations and using auxiliary variables.\n\n- The approach demonstrates the promise of causal representation learning for few-shot action recognition. Limitations include assumptions on temporal delays and difficulty inferring the auxiliary variables.\n\nIn summary, the key contribution is a new few-shot learning method based on learning and transferring temporal causal mechanisms, which is shown to be accurate and efficient for adapting models to new action recognition tasks with limited labeled video data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Originality: The idea of learning and transferring a temporal causal mechanism is highly original. Causal representation learning has not been applied in this way for few-shot action recognition before. Modeling latent causal variables, time-delayed transitions, and mixing functions is creative.\n\n2. Quality: The method is technically sound, with reasonable assumptions justified from first principles of causality. Experiments across multiple datasets demonstrate state-of-the-art accuracy and efficiency. The ablation study provides insight into design choices.\n\n3. Clarity: Overall the paper is clearly written and easy to follow. The background gives sufficient context, and the methodology explains the approach in detail. More intuition could be provided for how the causal mechanism aids adaptation.\n\n4. Significance: This provides a new paradigm for few-shot video understanding based on causal representation learning. The ability to adapt models with fewer updates could enable deploying action recognition systems to new domains with limited labeled data. Limitations around temporal delays and auxiliary variables indicate interesting directions for future work."
            },
            "weaknesses": {
                "value": "1. The motivation for why the causal mechanism transfers well could be clarified. Intuition or analysis on how the transition and mixing functions capture invariances would strengthen the core hypothesis.\n2. The inference of the auxiliary context variables \u03b8 seems coarse. More details on this convolutional LSTM approach and why it is effective would be helpful. Alternate ways to model \u03b8 could improve performance.\n3. Assumptions like time-delayed transitions between latent variables may not hold for data with low time resolution. Discussion of this limitation and ways to incorporate instantaneous effects would make the model more broadly applicable.\n4. More comparisons to understand tradeoffs versus other representation learning approaches like self-supervision may be informative."
            },
            "questions": {
                "value": "Please see the 'weaknesses' above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission342/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698832950910,
        "cdate": 1698832950910,
        "tmdate": 1699635961201,
        "mdate": 1699635961201,
        "license": "CC BY 4.0",
        "version": 2
    }
]