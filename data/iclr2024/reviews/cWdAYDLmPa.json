[
    {
        "id": "H0a99LJDab",
        "forum": "cWdAYDLmPa",
        "replyto": "cWdAYDLmPa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2451/Reviewer_Ww1x"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2451/Reviewer_Ww1x"
        ],
        "content": {
            "summary": {
                "value": "Authors propose to use multiple heads at the end of an encoder for\ncontrastive learning, instead of one. These heads are considered to\nmodel different charts in an atlas, mapping the data manifold to the\nembedding space. For a given sample, a score is computed to determine,\nprobabilistically, which chart should be used to encode\nit. A theoretical discussion is presented to support outputting a\nweighted average of charts based on scoring function, which relies on\nMinkowski sum of open sets to which charts map. The scoring function\nis forced to be different than a uniform distribution, thus the\nunbalanced nature of the mapping. Experiments are conducted to\nunderstand whether using multiple heads and weighted averaging at the\noutput leads to better representations than using a single head with\nthe same number of latent dimensions."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. More expressive models for contrastive learning are very relevant\n   and interesting for the community. Here authors point out that when\n   the embedding dimension is very high, naive contrastive learning\n   may not use the embedding space very well. Instead of using a\n   single projection head, authors proposal to use multiple projection\n   heads seem to lead to better results according to Tables 1\n   and 2. This is a simple yet - seems to be - an effective\n   modification.  \n2. Results of the ablation study shown in Figure 2 are very\n   convincing. This simple approaches surely uses the dimensions much\n   more efficiently, and provides the expected gains in accuracy.\n3. The difference between +MMD and the proposed version, which I\n   assume is -MMD, is striking.\n4. This reviewer appreciates the experiments with CIFAR."
            },
            "weaknesses": {
                "value": "1. Technical contribution is not at a very high level, but the\n   contribution is focused and pertinent.\n2. In the ablation study, the model \"-UA\" is not clearly specified. If\n   authors do not use the modifications of 7, that means the -MMD loss\n   is also void. What does that yield? Are authors using a single\n   projection head in this case?\n3. CIFAR experiments show that the gains are much lower in these\n   experiments compared to the ones obtained in ATARI games. A\n   discussion towards this end is not provided but it would be very\n   valuable for the readers.\n4. Notation in the presentation of the method seems a bit\n   inconsistent. I recommend authors to improve the consistency in the\n   notation."
            },
            "questions": {
                "value": "1. can authors discuss further why the CIFAR experiments do not show a\n   similar improvement?\n2. can authors please improve the notation consistency in the\n   presentation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2451/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2451/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2451/Reviewer_Ww1x"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2451/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698761247902,
        "cdate": 1698761247902,
        "tmdate": 1700659415932,
        "mdate": 1700659415932,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bd2tvXazp2",
        "forum": "cWdAYDLmPa",
        "replyto": "cWdAYDLmPa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2451/Reviewer_ES5Q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2451/Reviewer_ES5Q"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the problem of learning a low-dimensional manifold from high-dimensional data in the context of state representation learning. A new approach based on self-supervised learning is proposed in order to learn an unbalanced atlas representation. The proposed approach is called DeepInfomax with an unbalanced atlas (DIM-UA) and is evaluated on 19 Atari games of the AtariARI benchmark. The evaluation shows good performance in this benchmark."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper addresses an important topic in the area of state representation learning. The proposed algorithm seems novel and yields good performance in the tested benchmarks."
            },
            "weaknesses": {
                "value": "I am struggling to understand the rationale behind the DIM-UA algorithm. What is the motivation for redefining the score function L_GL? Equation 9 has a hyperparameter for L_Q but not for L_GL or L_LL. Why? The writing of the paper is not clear in several points as some parts are difficult to follow. For example, Figure 1 is not quite clear to me and the caption is not very explicit. Additionally, the results could be presented in a more concise fashion (esp. Table 1 and 2 - showing the best results in bold would increase the readability)."
            },
            "questions": {
                "value": "- What is the motivation for redefining the score function L_GL? \n\n- Equation 9 has an hyperparameter for L_Q but not for L_GL or L_LL. Why?\n\n- The improvements reported in table 2 seem relatively small. Can you comment on this further?\n\n- Why is the linear evaluation accuracy on CIFAR10 a suitable evaluation metric? The improvements shown here (table 3) are very marginal at best."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2451/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698841545872,
        "cdate": 1698841545872,
        "tmdate": 1699636181004,
        "mdate": 1699636181004,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6FAj3Iv5tn",
        "forum": "cWdAYDLmPa",
        "replyto": "cWdAYDLmPa",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2451/Reviewer_hci6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2451/Reviewer_hci6"
        ],
        "content": {
            "summary": {
                "value": "This paper developed a state representation learning method leveraging an unbalanced atlas (UA). The authors have modified the ST-DIM algorithm to align with the proposed UA paradigm. Although the main contribution is not stated intuitively, empirical evaluations on 19 games of the AtariARI benchmark suggested an improved performance compared with three established baseline methods (many existing self-supervised methods are omitted for comparison). Furthermore, the authors performed a comprehensive ablation study for the design choices of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The experiments are conducted across 19 games of the AtariARI benchmark, covering a variety of vision tasks.\n\n+ There are comprehensive ablation studies for the technical components of the proposed method."
            },
            "weaknesses": {
                "value": "- The clarity of the introduction could be enhanced by providing a more explicit context for the specialized terminology introduced (see Q1-3).\n\n- The comparison would benefit from the inclusion of key baseline models which are currently absent (see Q4).\n\n- Tables 1 and 2 appear to be redundant, presenting analogous results through different evaluative metrics (F1 score and Accuracy, respectively). Although a comprehensive evaluation is encouraged, putting these two sizable tables back to back in the main paper gives the impression of lacking sufficient materials for the paper. It would be more appropriate to consolidate these findings, perhaps through a combined analysis or in supplementary materials, to avoid repetition and maintain the conciseness of the paper.\n\n- the paper lacks a clear statement of its underlying motivation and significance, which is pivotal for readers to comprehend the value and potential impact of the research (see Q5)."
            },
            "questions": {
                "value": "1. The introduction used specialized terminology that may not be universally familiar, necessitating additional clarification for a broader audience. Specifically, the first sentence of the third paragraph introduces concepts such as *manifold*, *atlas*, *local structure*, and *chart*, which would benefit from further exposition to contextualize the study and its objectives.\n\n2. The paper's motivation remains unclear, partly owing to the use of undefined terms. The concept of an *atlas*, and particularly the distinction between *unbalanced* and *balanced* atlases within this framework, needs clarification. The terms *prior distribution* and *membership probability distribution* introduced later also lack clear definitions, impeding the reader's understanding.\n\n3. In the 3rd paragraph of Section 4, *d* and *n* are used without proper definition.\n\n4. This paper suggests that pre-training a model using a reinforcement learning task and then fine-tuning it on downstream reinforcement learning tasks is beneficial. However, this point is not fully demonstrated because the authors did not compare the proposed method with other self-supervised learning methods, as reviewed in the introduction, e.g., contrastive models (SimCLR is compared) and generative models (none is compared).\n\n5. From the introduction section, it is not intuitive to me why this study is important. For example, the last paragraph lists technical achievements but does not convey their broader significance. Specifically, (1) fitting the ST-DIM to UA paradigm (why UA paradigm is important?), (2) detailed ablations for better design choices (that's standard, not sure if it counts as a contribution), and (3) representing a manifold with a larger number (why this is important anyway?). Not limited to the introduction section, the authors did not describe the significance of the proposed method and all these ablation studies in the entire paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2451/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2451/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2451/Reviewer_hci6"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2451/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698950881722,
        "cdate": 1698950881722,
        "tmdate": 1699636180911,
        "mdate": 1699636180911,
        "license": "CC BY 4.0",
        "version": 2
    }
]