[
    {
        "id": "hiL2ieuzw4",
        "forum": "YkR9UFlQ1s",
        "replyto": "YkR9UFlQ1s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_apAV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_apAV"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates the message-passing scheme of GNNs and introduces non-backtracking GNNs, which avoid that a message passed from a node $u$ to a node $v$ contributes to the message that is passed from $v$ to $u$ in the next layer. The authors introduce established concepts for random walks and their analysis to GNNs and make formal connections to oversquashing. The experimental evaluation shows clear improvements of the approach over their standard counterpart and SOTA results on various data sets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. An established and well-investigated concept from other fields is used to improve GNNs.\n2. The experimental evaluation is convincing and shows improvements, particularly for long-range task datasets and heterophilic node classification.\n3. The paper is well written and illustrated by figures."
            },
            "weaknesses": {
                "value": "1. The novelty of the introduced techniques is limited. The authors do not sufficiently discuss closely related works:\n   - Non-backtracking concepts in walk-based graph learning: The problem of backtracking has been investigated for random walk kernels, see:  \n      * Pierre Mah\u00e9, Nobuhisa Ueda, Tatsuya Akutsu, Jean-Luc Perret, Jean-Philippe Vert: Extensions of marginalized graph kernels. ICML 2004\n      * Furqan Aziz, Richard C. Wilson, Edwin R. Hancock: Backtrackless Walks on a Graph. IEEE Trans. Neural Networks Learn. Syst. 24(6): 977-989 (2013)\n\n      The first paper by Mah\u00e9 et al. proposes a transformation of an undirected input graph to a directed graph, where each undirected edge is represented by two nodes reflecting the two ways of traversing the edge. These nodes are connected such that walks with backtracking are not possible. The construction and the idea are highly similar to the method described in the paper under review.\n   - The paper \"Zhengdao Chen, Lisha Li, Joan Bruna: Supervised Community Detection with Line Graph Neural Networks. ICLR 2019\" (cited but not sufficiently acknowledged) introduces a similar idea of avoiding backtracking to GNNs. A GNN implicitly performing message-passing on a directed line graph is proposed, conceptually highly similar to the technique proposed in the paper under review. Moreover, its strength for learning on graphs generated via the stochastic block model is investigated and explored.\n   - The paper \"Rongqin Chen, Shenghui Zhang, Leong Hou U, Ye Li: Redundancy-Free Message Passing for Graph Neural Networks. NeurIPS 2022\" is closely related to the proposed method but only cited among others on page 4 and not sufficiently acknowledged. The approach uses simple paths (and cycles), allowing no repeated vertices at all instead of no repetition in subpaths of length two as the non-backtracking approach. Moreover, it investigates the link to oversquashing via the same techniques based on the Jacobian. A more detailed discussion of the differences compared to this work is necessary.\n\n2. Analysis of expressive power: The section argues that spectral analysis of GNNs overcomes the issues of Wesifeiler-Leman-based expressivity results. I cannot follow the reasoning. While focusing on spectral analysis allows to draw from existing results on non-backtracking walks, I have difficulties understanding Theorems 2 and 3. What exactly is the learning task in Theorem 2? How to interpret \"can accurately map from graph $\\mathcal{G}$ to node labels\"? What is the influence of the learnable parameters of the GNN? Most importantly, it is unclear whether standard GNNs with WL expressivity cannot solve these learning tasks, at least theoretically. \n\n3. The authors argue that non-backtracking GNNs reduce redundancy. However, it is not discussed to what extent this is possible using the proposed method. While the illustrating examples are trees, in graphs with cycles, redundancy still occurs. A natural generalization would be to avoid backtracking within $k$ hops. A discussion of this could strengthen the paper.\n\n4. The space and time complexity increases compared to standard GNNs.\n\n5. Experimental evaluation:\n   - The reported results in the tables are the maximum of two variants, which is slightly unfair. Please report the results separately.\n\nMinor remarks:\n  - The caption of Figure 3 contains several repetitions"
            },
            "questions": {
                "value": "1. How does the expressivity of NBA-GNNs (e.g., NBA-GIN) compare to GIN? \n2. Can you clarify the relation to other works (see weaknesses 1)?\n3. Can the approach be extended to avoid backtracking within $k$ hops?\n4. What is the intuition as to why begrudgingly backtracking should work better? Does this mean that redundancy is not inherently problematic?\n5. LapPE enhances the performance for the long-range task. Are there results for GIN/GCN with LapPE?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9111/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698743826944,
        "cdate": 1698743826944,
        "tmdate": 1699637146690,
        "mdate": 1699637146690,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3wnumOgkDC",
        "forum": "YkR9UFlQ1s",
        "replyto": "YkR9UFlQ1s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_ayH6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_ayH6"
        ],
        "content": {
            "summary": {
                "value": "The article proposes an architecture of graph neural network that is based on the non-backtracking operator on graphs. The authors explain what non-backtracking walks are and define a GNN based on them. They give some theoretical insights proving this model is less sensitive to mixing far features (over-squashing) than ordinary GNNs and that it is expressive enough to be able to classify sparse binary SBMs. They provide a few experiments on benchmarks showing their network does better or as good as benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The results in table 2 are promising and using non-backtracking updates for GNN seems relevant. This is also supported by theory, in particular on SBM.\n\nThe article is well-written."
            },
            "weaknesses": {
                "value": "I think the contribution this article brings is too small.\n\nMainly it seems the authors do not know about the work \u00ab Supervised Community Detection with LGNN \u00bb Chen et al. ICLR19 arxiv:1705.08415. In this article a GNN based on the non-backtracking operator is proposed ; it has features on the edges that are aggregated via the non-backtracking matrix B ; and, if I am right, it is very similar to the NBA-GNN the authors propose. The differences are that it is formulated directly as a GCN and not a generic permutation-invariant GNN ; and it seems more expressive since it also has features on the nodes (which, for instance, permits not to use the trick of begrudgingly updates) and it applies powers of B to aggregate the features (which, as they show, increases the performance).\n\nThe theoretical analysis the authors propose is quite light in the sense that theorems 2 and 3 come straightforwardly from Bordenave 15 and Stephan and Massouli\u00e9 22. In the sensibility analysis (theorem 1) the improvement given by non-backtracking is quite modest ; considering the spectral properties of B on a model seems better than analyzing the sensibility.\n\nMy point of view is that the novelty of this article is restricted to the experiments it proposes and its broader theroretical frame, that was less developped at the time of Chen 19."
            },
            "questions": {
                "value": "About NBA-GNN on SBM : the theoretical results are only about its expressiveness ; what about the training ? do the authors actually observe that a trained NBA-GNN can correctly classify the nodes ? They could compare to the conjectured optimal performances given by BP on sparse SBM. I guess they would obtain the same as Chen 19.\n\nIt would have been interesting to consider NBA-GNN on the CSBM since this model has features.\n\nAnother reference the authors may not know : arxiv:1306.5550, that first used the non-backtracking matrix for node classification."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9111/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698747598981,
        "cdate": 1698747598981,
        "tmdate": 1699637146573,
        "mdate": 1699637146573,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PLdVPwN0Xn",
        "forum": "YkR9UFlQ1s",
        "replyto": "YkR9UFlQ1s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_Q7oz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_Q7oz"
        ],
        "content": {
            "summary": {
                "value": "In the submitted manuscript, the authors notice that representations learned via standard message passing schemes in graph neural networks (GNNs) are dependent on all walks present in graphs. They propose to remove redundancy from the message passing process by considering non-backtracking (and begrudgingly non-backtracking) walks only. This leads them to propose the NBA-GNN, which learns two embeddings per edge, and analyse the potential impact of the over-squashing phenomenon on NBA-GNNs and perform an expressivity analysis. The NBA-GNNs are found to outperform state-of-the-art baselines on several real-world datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is clear and well-written.\n- The considered idea is interesting and some theoretical understanding of it is offered by the theoretical results in Section 4.\n- The performance in practice of your NBA-GNNs is impressive and compared against a set of relevant baseline models."
            },
            "weaknesses": {
                "value": "- Comparison to seemingly closely related previous work appears to be lacking (see Question 1).\n- NBA-GNNs are prohibitively expensive and the additional expense in terms of computation time is insufficiently explored (see Question 2). \n- The theoretical result in Theorem 1 is only a weak indication of alleviated over-smoothing (see Question 3)."
            },
            "questions": {
                "value": "1) There appears to be previous work proposing the use of non-backtracking operators in GNNs, also investigating their model in the context of stochastic blockmodels [1]. I believe it to be pivotal for you to firstly, discuss the differences between their proposed Line Graph Neural Networks and your NBA-GNNs and to secondly, include their LGNN in your experimental baselines to demonstrate whether/which empirical differences exist. \n\n2) The NBA-GNNs you propose are rather expensive in the sense that you learn two embeddings per edge. While it is very good, that you have included a discussion of the additional memory cost in the \"Limitations\" paragraph, I also believe a discussion of the time complexity of your method to be necessary. Ideally you should evaluate both the time complexity in theory and also provide experimental evaluation of the computation time of your NBA-GNNs compared to the baseline methods. \n\n3) Your result in Theorem 1 appears to be of limited importance to me. The fact that your upper bound on NBA-GNNs is larger than the bound on standard GNNs could either mean that one of the bounded quantities is indeed larger than the other as you suggest, but it could equally well be the case that one of the two bounds is looser than the other in practice, i.e., given the bound on standard GNNs any larger upper bound is trivially also true and would surpass your larger bound, which might put the conclusions you drew from the magnitude of the two upper bounds in jeopardy. It would significantly strengthen your result if you could observe (even if just experimentally) that the considered derivatives are indeed larger for the non-backtracking operator than for the normalised adjacency matrix. \n\n\n[1] Chen, Zhengdao, Xiang Li, and Joan Bruna. \"Supervised community detection with line graph neural networks.\" ICLR. (2019)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9111/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9111/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9111/Reviewer_Q7oz"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9111/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698767034376,
        "cdate": 1698767034376,
        "tmdate": 1699637146425,
        "mdate": 1699637146425,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QAOhl4kSOG",
        "forum": "YkR9UFlQ1s",
        "replyto": "YkR9UFlQ1s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_WPCH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_WPCH"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes the Non-Backtracking Graph Neural Network (NBA-GNN) to address the redundancy issue in message-passing updates of conventional  GNNs.  NBA-GNN updates messages without incorporating the message from the previously visited node. They also provided a theoretical analysis of the over-squashing phenomenon in the setting of NBA-GNN. The proposed NBA-GNN is empirically evaluated on long-range graph benchmarks and transductive node classification problems, demonstrating competitive performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1) The proposed NBA-GNN addresses an important issue in GNNs related to the redundancy of message flows and its impact on downstream tasks. Using non-backtracking updates to reduce redundancy is a novel and well-motivated approach.\n\n2) The paper provides a thorough analysis of the redundancy issue, linking it to the over-squashing phenomenon in GNNs.\n\n3) The empirical evaluation of NBA-GNN on long-range graph benchmarks and transductive node classification problems demonstrates its effectiveness and competitive performance compared to conventional GNNs."
            },
            "weaknesses": {
                "value": "1) The paper lacks a detailed description of the construction of the non-backtracking operator/walk/update and the related implementation in NBA-GNN.\n\n2) The time complexity of processing the non-backtracking seems high, and the preprocessing time is not reported. Additionally, the run time and memory usage of NBA-GNN compared with other GNNs is not reported, making it difficult to evaluate the proposed method comphensively."
            },
            "questions": {
                "value": "What is the performance of NBA-GNN on the other two datasets in LRGB?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9111/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9111/Reviewer_WPCH",
                    "ICLR.cc/2024/Conference/Submission9111/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9111/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826123869,
        "cdate": 1698826123869,
        "tmdate": 1700450263772,
        "mdate": 1700450263772,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YaXrBFoZmY",
        "forum": "YkR9UFlQ1s",
        "replyto": "YkR9UFlQ1s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_w5ts"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9111/Reviewer_w5ts"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces non-backtracking GNNs, which only send messages through non-backtracking paths. A theoretical analysis of their sensitivity and of their expressive power in comparison with conventional GNNs is conducted. Numerical experiments demonstrate the superiority of non-backtracking GNNs in a number of graph machine learning tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The experiments are sufficiently convincing of the superiority of NBA-GNNs in the considered tasks.\n- The paper is generally clear and well-written."
            },
            "weaknesses": {
                "value": "- The paper misses important related work, specifically:\nZhengdao Chen, Lisha Li, Joan Bruna. Supervised Community Detection with Line Graph Neural Networks. ICLR 2019.\nThis paper was the first to propose the use of the non-backtracking operator in GNNs. \n- In light of the above, the proposed architecture is somewhat incremental.\n- The theoretical results are not convincing. \n    * The claim that NBA-GNNs might help with oversquashing is supported by the assumption, backed only by empirical evidence, that NBA-GNNs have shorter access time than BA-GNNs. A proposition is provided stating that non-backtracking random walks have shorter access times, but it only holds for trees. The conditions of this proposition are too far away from the setup of NBA-GNNs to make a conving claim.\n     * As the authors themselves note, Lemma 1 and Theorem 1 only provide upper bounds on the sensitivity of conventional and NBA-GNNs.  It is a stretch to conclude that, because the upper bound for conventional GNNs is lower than the upper bound for NBA-GNNs, the sensitivities behave similarly. I understand that tighter results/lower bounds may not be possible, but considering that this is the main contribution of this paper, it falls somewhat short.\n     * The authors do not comment on the fact that for moderate-to-large degree d, the decay rates of the sensitivity upper bounds for conventional and NBA-GNNs will become very close. Moreover, this finding is not in agreement with the empirical findings from Table 1, which show that NBA-GNNs lead to significant performance improvements on dense graphs. This could be regarded as evidence that the sensitivity upper bounds are not very tight.\n     * The second theoretical analysis, from Section 4.2, is not very novel, as it is essentially a restatement of theoretical results from the spectral clustering community.\n\nMinor: \n\n- Important references on the expressivity of GNNs from spectral considerations are missing. See e.g. Kanatsoulis et al., and the work of Ribeiro, A.\n- The paper can be quite wordy, and repeat many of the same observations.\n- While the limitations are briefly discussed, they perhaps deserve a more extensive treatment as the increase in computational complexity is quite high."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9111/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698856359359,
        "cdate": 1698856359359,
        "tmdate": 1699637146180,
        "mdate": 1699637146180,
        "license": "CC BY 4.0",
        "version": 2
    }
]