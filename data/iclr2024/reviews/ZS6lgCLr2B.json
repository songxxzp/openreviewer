[
    {
        "id": "X29sKiD4cR",
        "forum": "ZS6lgCLr2B",
        "replyto": "ZS6lgCLr2B",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7186/Reviewer_xdhf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7186/Reviewer_xdhf"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of Byzantine clients in federated learning (FL) under client sampling and local steps. The analysis is done under a definition of robustness (specifically, Definition 2) borrowed from reference Allouah et al., 2023 in the paper. A joint condition on the number of sampled clients $\\hat{n}$ and maximum number of Byzantine clients $\\hat{b}$ (out of $\\hat{n}$) is derived such that the robustness condition in Definition 2 is satisfied for all the rounds (with high probability), thereby ensuring convergence. The authors also show that if $\\hat{n}$ is too small, then convergence cannot be ensured. Additionally, increasing $\\hat{n}$ beyond a certain threshold does not yield any further improvement. Further, it is shown that multiple local steps reduce the asymptotic error. The theoretical claims are corroborated by some experiments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "**1.** It appears that this is the first paper analyzing the problem of Byzantine clients with partial-device participation and local steps, and the extension is not trivial. However, I'm not very familiar with related works in this particular area.\n\n**2.** I like the insights in Sections 5.1 and 5.2 namely that if $\\hat{n}$ is too small, then convergence cannot be ensured, and increasing $\\hat{n}$ beyond a certain threshold does not yield any (order-wise) improvement. (Although I also have some concerns regarding the first insight which I have mentioned in Weakness #1).\n\n**3.** Solid theoretical analysis and the overall presentation is decent."
            },
            "weaknesses": {
                "value": "**1.** The results in this paper are under the condition in Definition 2 which requires that the number of Byzantine clients in each round (out of $\\hat{n}$ total sampled clients) is no more than $\\hat{b}$; I think this is a bit stringent. For e.g., it is hard for me to imagine that convergence will suddenly fail instead of becoming slightly worse if there are $\\hat{b}+1$ bad clients in only one round (especially if the client updates are bounded). Alternatively, I feel that $\\kappa$ in Definition 2 should be a function of $\\hat{b}$; for e.g., it is mentioned that $\\kappa$ for coordinate-wise trimmed mean is $O(\\frac{\\hat{b}}{\\hat{n}})$. To show the dependence of $\\hat{b}$ on $\\kappa$, let us denote it as $\\kappa(\\hat{b})$ instead. In that case, it should be possible to obtain a convergence bound in terms of $\\kappa(\\hat{b}_1), \\kappa(\\hat{b}_2),\\ldots, \\kappa(\\hat{b}_T)$ (the subscript denoting the round index).\n\n**2.** The statement of Theorem 1 needs clarification. There is an expectation term in the equation but the line above that says \"*with probability at least $p$...*\". Is the expectation only over the randomness in stochastic gradients and the randomness in the sampled clients, whereas the probability is over the randomness in the number of Byzantine clients in the set of sampled clients (across all rounds)?\n\n**3.** The lower and upper bound for $\\hat{n}$ in Lemma 2 and 4 depend on $T$, but how do you know $T$ in advance in practice?\n\n**4.** In Section 5.2, the authors claim that reference Karimireddy et al., 2021 obtain a matching lower bound of $\\Omega(\\frac{b}{n}(\\frac{\\sigma^2}{K} + \\zeta^2))$ but looking at their result, it appears that their result is for strongly convex problems and not non-convex problems. So the tightness of Corollary 1 is not clear.\n\n**5.** The $\\zeta^2$ term in Corollary 1 doesn't decrease with the number of local steps $K$ and that is usually larger than $\\sigma^2$."
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7186/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698727135249,
        "cdate": 1698727135249,
        "tmdate": 1699636853068,
        "mdate": 1699636853068,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "k4euJS3cFe",
        "forum": "ZS6lgCLr2B",
        "replyto": "ZS6lgCLr2B",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7186/Reviewer_jgKT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7186/Reviewer_jgKT"
        ],
        "content": {
            "summary": {
                "value": "The paper studies robust Federated Learning (FL) algorithms for the setting of byzantine clients. In particular, the authors consider FedRo, which is a variant of the standard FedAvg with the simple averaging operation being replaced by a robust averaging mechanism. Then they analyze the complexity of FedRo while taking into account client subsampling and local steps. To circumvent the impossibility of obtaining convergence of FedRo in scenario where the number of sampled clients $\\hat{n}$ can be too small (thereby being flooded by a majority of byzantine clients), the authors also obtain a sufficient condition on the client subsampling size and subsequently demonstrate how to set such threshold. Experiments were provided to validate their results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The work is one of the few that consider client subsampling and local steps; the literature for byzantine FL with both of these seems nascent. The results in the paper indeed are better than the latest work of Data & Diggavi (2021) in this specific direction."
            },
            "weaknesses": {
                "value": "Experiments do not consider other baselines in the literature and are thus very weak.\nThis work seems like a quite natural (and mechanical) extension from  (Allouah et al., 2023), which had already addressed the harder problem of heterogeneity than client subsampling and local steps considered in this paper on top of the setting. Along this way, perhaps the arising requirement of a sufficient condition on the client subsampling size is interesting (a bit new) and well treated by the authors."
            },
            "questions": {
                "value": "It would be nice if the authors can elaborate more on the contribution/novelty in view of the comments on the Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7186/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814487490,
        "cdate": 1698814487490,
        "tmdate": 1699636852944,
        "mdate": 1699636852944,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "F392LVevxa",
        "forum": "ZS6lgCLr2B",
        "replyto": "ZS6lgCLr2B",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7186/Reviewer_iQ55"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7186/Reviewer_iQ55"
        ],
        "content": {
            "summary": {
                "value": "The paper studied the effect of client sampling and local steps in FedRo in dealing with adversarial clients. It theoretically validated the empirical observation of poor performance given a small sampling size, as well as the diminishing gain when the sample size exceeds a threshold."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The theory and empirical study matches well. \n2. It provides a strong understanding and practical guidance in designing robust FL algorithms in dealing with adversarial agents.\n3. The paper is well-presented."
            },
            "weaknesses": {
                "value": "1. Apart from local steps and client sampling, how do communication compression and local data sampling impact FedRo?"
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7186/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826651654,
        "cdate": 1698826651654,
        "tmdate": 1699636852826,
        "mdate": 1699636852826,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "96qTOfVVBX",
        "forum": "ZS6lgCLr2B",
        "replyto": "ZS6lgCLr2B",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7186/Reviewer_gVud"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7186/Reviewer_gVud"
        ],
        "content": {
            "summary": {
                "value": "The authors explore sampling and local update strategies to combat Byzantine clients in a federated setting. In particular, the authors characterize how many clients the central server should subsample if an upper bound of the number of Byzantine clients is known, among with a characterization of how the # of local client updates diminishes error. The authors empirically support their theory via experiments on FEMNIST."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors characterize a sampling strategy for near-convergent FedRO given an upper bound on number of Byzantine clients. The theory uses very most and common assumptions to FL. \n\n2. The authors theoretically demonstrate that increased local # update steps diminishes error in a Byzantine setting. This is a nontrivial and useful conclusion. \n\n3. The authors provide practical theoretical bounds (lower bounds on subsampling size). if the number of Byzantine clients is less than 1/2. \n\n4. Perhaps most importantly, this appears the first Byzantine setup which admits client subsampling and more than one local update."
            },
            "weaknesses": {
                "value": "1. Though increasing the number of local update steps reduces error, the total error is vanishing even with optimal sampling. I\u2019m wondering if the result of Theorem 1 can be improved perhaps with additional mild assumptions. \n\n2. The paper assumes a Byzantine-defensive aggregation scheme is being used and thus does not propose any truly novel strategy beyond improved sampling (which apparently does not necessarily lead to full convergence).\n\n3. Further empirical corroboration of the proposed theory is likely needed to convince the FL community to seriously explore subsampling strategies."
            },
            "questions": {
                "value": "See weaknesses. What further assumptions may lead to a fully vanishing error term?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7186/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7186/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7186/Reviewer_gVud"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7186/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699058670277,
        "cdate": 1699058670277,
        "tmdate": 1699636852701,
        "mdate": 1699636852701,
        "license": "CC BY 4.0",
        "version": 2
    }
]