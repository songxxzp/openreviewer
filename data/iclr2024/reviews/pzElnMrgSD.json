[
    {
        "id": "bxgUDtCuXN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3760/Reviewer_tVGv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3760/Reviewer_tVGv"
        ],
        "forum": "pzElnMrgSD",
        "replyto": "pzElnMrgSD",
        "content": {
            "summary": {
                "value": "This paper studied the influence of initialized noise when adopting diffusion based image model to video model.\n\nA new initialization method called integral noise is propose, which is composed of a conditional upsampling, rasterization, and aggregation stage. It can maximizing the correlation between the warped and the original sample and maintain the independence of pixels in each sample."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The method is well illustrated in Figure 2 and is easy to understand.\nA deep and comprehensive theoretical analysis is provided in the method and supplementary material.\nThe method is evaluated on several tasks, including rerendering (SDEdit), pose-to-person, and video restoration.\nGood video illustration in supplementary material."
            },
            "weaknesses": {
                "value": "I guess most experiments in this paper are conducted in zero-shot way which applies the image processing model and method to video processing problems. Looking forward to seeing whether this helps when training a video model, like the PYoCo model\nConsidering video restoration (**Zeroscope Text-to-Video**) and pose-to-human (dreampose) already have good performance, I wonder the gap between image model+ integrate noise and these video models.\nAs stated in Appendix E, integrat noise does not work well in latent diffusion model. I wonder if this is applicable to other pixel-level diffusion models like the open-sourced deepfloyd from stabilityAI, whose capacity is comparable or better than stable diffusion."
            },
            "questions": {
                "value": "I am happy to see the comparison with the video processing model and the integration with DeepFloyd"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3760/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3760/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3760/Reviewer_tVGv"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3760/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697434409292,
        "cdate": 1697434409292,
        "tmdate": 1699636332376,
        "mdate": 1699636332376,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XOCBTdMMgw",
        "forum": "pzElnMrgSD",
        "replyto": "pzElnMrgSD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3760/Reviewer_H5Nc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3760/Reviewer_H5Nc"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for warping Gaussian noise while preserving its Gaussian properties. \nTo achieve the goal, the authors consider a mathematical model of the Brownian sheet (i.e. the distributional derivative of the two-dimensional Brownian motion) and develop a noise transport equation for that model. \nIn applications, the following approximation is applied. First, the input noise map is conditionally up-scaled so that it remains Gaussian. Second, the up-scaled map is warped according to the equation derived for the Brownian sheet. \nFinally, the warped noise is down-scaled to the original size.\n \nThe method is tested on a number of vision problems. According to the provided evaluations, typically it produces better temporal coherence than the baseline methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "From my point of view, this paper tackles a pretty important problem for the community, since the application of image translation models to videos is a popular direction which still suffers from flickering and other artifacts. It seems to me that the Brownian sheet model and conditional Gaussian upscaling both are a very good fit for that problem as they take into account the intrinsically hierarchical nature of image resolution. The video results in the supplementary demonstrate that the amount of flickering and, vice versa, texture sticking in videos is reduced."
            },
            "weaknesses": {
                "value": "1. From the theoretical point of view, the presented approach relies on the warping field being a diffeomorphism, while in practice to the best of my knowledge optical flows estimated with off-the-shelf methods are rarely invertible mappings.\n1. As the authors themselves admit (Appendix E.3), \"the impact of the noise scheme is negatively correlated with the amount of constraints given to the model\", and, in particular, the method has a limited impact on latent diffusion models. However, it is obviously still useful for cascaded models.\n1. As mentioned in the paper (Sec. 6) the method is computationally less efficient than other techniques.\n1. According to Tab. 1, while the proposed method typically increases temporal coherence, at the same time it worsens frame-wise image plausibility metrics such as LPIPS or FID.\n1. None of the video samples in the supplementary except for fluid dynamics provides the results of noise handling with the method proposed by Control-A-Video model. Please note that this model more close to the presented method in spirit since it also takes input video into account while PYoCo does not."
            },
            "questions": {
                "value": "1. As indicated in Tab. 1, bilinear interpolation often results in quite decent quality (excl. Video SR task). Haven't the authors considered a small modification of bilinear interpolation which is able to preserve the variance of pixels, namely, replacing the commonly used weighting coefficients with their square roots? Probably, this simple modification can even further improve its performance. Also note that Eq. 5 is also essentially \"Gaussian averaging\" of subpixels, i.e. averaging using variance-preserving weighting coefficients of $1/\\sqrt{k}$ instead of $1/k$.\n1. As mentioned above, the presented method is less computationally efficient than the baselines. It would be nice to provide a quantitative evaluation of that (in)efficiency.\n1. From the manuscript, it is a bit unclear how the 9 triangulation points are warped in Fig. 1a. How exactly is the estimated optical flow $\\mathcal{T}^{-1}$ which typically has the same resolution as the image itself, applied to non-integer pixel coordinates? In other words, how is the operation $\\textrm{WARP}_{\\infty}$ from Algorithm 2 implemented?\n1. I suggest adding an explicit proof of why $\\textbf{Z}$ is a Gaussian vector (Appendix B.2). Probably, the shortest proof is the one considering the linear combinations $\\kappa^T \\textbf{Z}$ for all possible $\\kappa$, which are obviously Gaussian random variables.\n1. I recommend adding more comments on how Eq. 24 for the continuous case turned into Eq. 5 for the discrete case. Why is it valid to still rely on the first-order approximation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3760/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697908057566,
        "cdate": 1697908057566,
        "tmdate": 1699636332261,
        "mdate": 1699636332261,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2aJQPL7qKT",
        "forum": "pzElnMrgSD",
        "replyto": "pzElnMrgSD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3760/Reviewer_3JNo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3760/Reviewer_3JNo"
        ],
        "content": {
            "summary": {
                "value": "This work attempts to mitigate the lack of temporal correlation seen in diffusion based video generation models. The proposed method attempts to generate new noise samples that preserve the correlations induced by motion vectors. To this end, first, this work reinterprets individual noise samples used in diffusion models as a continuously integrated noise field called integral noise. With the help of the derived noise transport equation, a transport algorithm is developed to generate noise with temporal correlation between samples while preserving the desired properties of noise samples. Results are demonstrated to indicate the potential of the proposed method for tasks such as video restoration and editing, surrogate rendering, and conditional video generation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The problem tackled in this work has significant practical impact.\n2. The paper is written very well.\n3. Motivation is clear, ideas are well formulated with theory, and the results are impressive."
            },
            "weaknesses": {
                "value": "1. The proposed method is computationally inefficient as compared to prior arts. Quantitative comparisons on this aspect would have been more helpful for future research works."
            },
            "questions": {
                "value": "1. Figure 5 illustration is hard to follow, it\u2019s not clear how to judge the performance based on the images shown. It\u2019s mentioned that, the Random Noise creates incoherent details while Fixed Noise suffers from sticking artefacts. Our R -noise moves the fluid in a smoother way. However, I find this explanation hard to map to the results shown. Maybe the authors can highlight based on the image contents the reasons for each of these conclusions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3760/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698561407019,
        "cdate": 1698561407019,
        "tmdate": 1699636332183,
        "mdate": 1699636332183,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JgyloWVjJY",
        "forum": "pzElnMrgSD",
        "replyto": "pzElnMrgSD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3760/Reviewer_13WQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3760/Reviewer_13WQ"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces the novel problem of Gaussian noise warping. Therein, the authors raised the interesting question of \"how to properly warp the Gaussian noise such that the warped noise map still has the Gaussian distribution preserved?\". To this end, the authors discussed why applying conventional warping operation on the noise map is not suitable, and they proposed a mathematically grounded solution to the problem with their \u222b-noise formulation. The authors motivated the practical value of this problem with the applications of lifting image diffusion models to perform temporally consistent video editing. Experiment results with different video editing tasks demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The research question \u201chow to properly warp a Gaussian noise map\u201d introduced by this paper is interesting scientifically.\n\nThe problem is well motivated with clear explanations on why the problem is not trivial, i.e. why the conventional warping operations are not suitable. The proposed solution is technically sound and well-grounded mathematically.\n\nThe practical aspects of the problem are also well-motivated, with interesting video editing applications."
            },
            "weaknesses": {
                "value": "The major weakness from the practical point of view is the implicit assumption that temporally correlated noise maps can induce temporally consistent video editing results, which is often not true. This limitation, however, has been acknowledged and explained by the authors in the paper."
            },
            "questions": {
                "value": "Other than the comments above, there are a couple of questions I\u2019m curious about:\n+ I\u2019m wondering how sensitive the method is with respect to the underlying estimated flow map? In other words, how do the errors in the estimated optical flows affect the results?\n+ One principled way to obtain a sequence of correlated noise maps is to perform inverse DDIM on the reference video frames (assuming such video is available, which is true in most of the use cases demonstrated in this paper). The authors did mention that technique in the paper, but did not elaborate further and did not show visual results or comparison. I\u2019m wondering how will the noise maps obtained that way compare to the ones obtained from the \u222b-noise in terms of the final video quality?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3760/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814275453,
        "cdate": 1698814275453,
        "tmdate": 1699636332101,
        "mdate": 1699636332101,
        "license": "CC BY 4.0",
        "version": 2
    }
]