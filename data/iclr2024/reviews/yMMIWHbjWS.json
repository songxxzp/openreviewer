[
    {
        "id": "aIwF85if9p",
        "forum": "yMMIWHbjWS",
        "replyto": "yMMIWHbjWS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5486/Reviewer_nfkX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5486/Reviewer_nfkX"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the hypothesis that the complexity of a concept is linked to its generalizability in machine learning models. This is significant for bridging the worlds of machine learning and human psychology since it is hypothesized (Gardenfors 2014) that human concepts are geometrically convex. The paper defines a generalized notion of convexity for non-Euclidean spaces using graph geodesics, and investigates the convexity of various categories within different modalities of data, both before and after fine-tuning on human annotations. Results suggest that convexity of human concepts does indeed increase after fine-tuning and that convexity may be linked to predictive performance.\n\nNote: I previously reviewed this manuscript, and I checked to pdf to see if the authors made any revisions since then."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The motivation of the paper is relatively well-explained given the novelty of the question. The measure of convexity appears to be novel, and a variety of experiments are conducted. The analysis of the experiments appears sound. The variety of modalities investigated (images, audio, text, motion data) is impressive. I did not check the proofs in detail, but the overall proof strategy makes sense to me."
            },
            "weaknesses": {
                "value": "~~While the concept of graph convexity is novel and interesting, it is not clear how much of a contribution it provides to the field, since there may be existing concepts (such as linear separability) which may or may not achieve the same goal in terms of characterizing representations.~~\n\nEDIT: A remaining weakness, as pointed out by other reviewers, is the lack of practical applications to improve the performance neural networks."
            },
            "questions": {
                "value": "How does the measure of graph convexity give more insight in practical cases than an existing method for measuring linear separability (https://arxiv.org/pdf/2307.13962.pdf)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5486/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5486/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5486/Reviewer_nfkX"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5486/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698326852516,
        "cdate": 1698326852516,
        "tmdate": 1699999685156,
        "mdate": 1699999685156,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sn9Zmj5jJR",
        "forum": "yMMIWHbjWS",
        "replyto": "yMMIWHbjWS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5486/Reviewer_f5N3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5486/Reviewer_f5N3"
        ],
        "content": {
            "summary": {
                "value": "The authors delve into the exploration of the convexity of machine learning latent spaces, developing tools to measure the convexity in sampled data. The paper is motivated by the observation that representational spaces in the human brain frequently form in convex regions. The authors aim to showcase that state-of-the-art deep learning models also exhibit convexity in decision regions. Experiments spanning multiple domains such as images, human activity, audio, text, and medical imaging are conducted. The findings suggest that neural networks with higher performance tend to exhibit greater convexity in their decision regions."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The paper is clear and easy to understand.\n+ The idea of linking human thinking and computer learning is interesting and could be important for understanding the mind and contributing to cognitive science.\n+ The experimental analysis in the paper is comprehensive and varied."
            },
            "weaknesses": {
                "value": "- The concept of measuring convexity in NNs appears to be somewhat circular. It doesn\u2019t seem like the convexity in NNs spontaneously emerges from the data or is an unexpected outcome; rather, it seems intentionally designed. Take the \"graph convexity\" prominently featured in the paper, for example. If we view the final softmax layer as the classifier (setting the decision boundary) and the feature vector inputted into this final layer as a data point on a manifold, it's almost always a given for a 100% accurate NN to possess a graph-convex decision boundary, owing to the intrinsic convexity of the softmax function. Essentially, the core function of the feature extractor is to map the data onto a (potentially) high-dimensional space where a simple linear or convex layer like the softmax can efficiently segregate data with varied labels, a strategy evidently seen in methods like SVM. Hence, the design of convexity seems more of an intentional architectural choice rather than a novel, data-driven emergence.\n\n- The methodology used in constructing graph estimates, a critical element in the paper, seems somewhat imprecise. In Defn.3 on Page 3, graphs are formulated based on Euclidean nearest neighbors, referencing the \"local Euclidean\"-ness of the manifold. This representation appears somewhat misconstrued. Manifolds are locally Euclidean within the subspace topology, not the standard topology in R^n. More explicitly, \"local Euclidean\" nature implies the presence of a continuous map that maps between the manifold's local subspace and R^n, but it doesn\u2019t inherently suggest that a graph formed by Euclidean nearest neighbors will replicate the manifold's \"similar\" structure, as this neighbor determination occurs in R^n\u2019s full space rather than in a subspace. The proposed graph construction method is vulnerable, for example, it will transform an open ring with closely positioned endpoints into a closed ring. I believe this is also the major reason why KNN performs better than epsilon-Neighbor as the former is more robust in handling these tricky topology cases. The paper could benefit from refinement in these foundational aspects to ensure mathematical precision and conceptual clarity.\n\n - The paper, dense with detailed proofs and extensive explanations, feels somewhat overloaded. Elements like Theorem 2 and 3 seem somewhat simple, potentially to individuals with an initial graduate-level understanding. A more streamlined approach, possibly through referencing standard convex optimization textbooks for such foundational concepts, could enhance the paper's readability and focus.\n\n- The connection between human representation and NN convexity isn\u2019t entirely lucid. While there\u2019s a notable reference to numerous papers on human representation in the introduction, the subsequent sections don\u2019t seem to elucidate a substantial link beyond a generalized notion of convexity. It leaves room for doubt regarding whether the human-related assertions are primarily theoretical embellishments or if they hold significant, intrinsic connections and inspirations.\n\n- The experiments predominantly focus on the evaluations of convexity. An expansion of the experimental design to include algorithmic innovations that utilize these analysized insights to enhance training and learning processes could be quite valuable. Questions like whether explicitly incorporating convex boundaries during NN training could expedite convergence remain unexplored. Without such practical explorations and demonstrations, the applicability and impact of these observations seem somewhat limited."
            },
            "questions": {
                "value": "See the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5486/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5486/Reviewer_f5N3",
                    "ICLR.cc/2024/Conference/Submission5486/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5486/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698375137151,
        "cdate": 1698375137151,
        "tmdate": 1700494853226,
        "mdate": 1700494853226,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "C9Dj3pBSdf",
        "forum": "yMMIWHbjWS",
        "replyto": "yMMIWHbjWS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5486/Reviewer_Rwrg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5486/Reviewer_Rwrg"
        ],
        "content": {
            "summary": {
                "value": "Motivated by insights from geometric psychology and neuroscience, this paper proposes measuring the generalization ability of models based on the convexity of decision regions. To achieve this, the paper investigates the learned latent space of various models and measures their convexity using Euclidean convexity and graph convexity. Experimental results demonstrate that the convexity of different models generally increases layer by layer, suggesting that deeper features exhibit better generalization ability. Additionally, the paper establishes a strong correlation between the convexity of models and their fine-tuned accuracy."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The investigation of model convexity is intriguing."
            },
            "weaknesses": {
                "value": "1. The organization of the paper's content is unreasonable. For instance, the introduction section dedicates substantial space to discussing the relationship between convexity and generalization, while neglecting to mention the specific objectives of the paper. This section should be reorganized by moving background information to the related work or appendix while focusing on introducing the main content and contribution of the paper.\n\n2. The experimental setup in the paper has significant issues. To demonstrate the claimed relationship between convexity and generalization, the paper should provide comparisons of convexity and performance among multiple different models within the same domain, thus proving that convexity indeed facilitates generalization. However, the paper only conducts experiments with a single model for each modality, which fails to reveal the impact of convexity on generalization.\n\n3. This paper fails to provide any meaningful conclusions. Despite emphasizing the relationship between convexity and generalization, as mentioned above, the existing experiments fail to demonstrate this point or draw any valuable conclusions, rendering the contributions of the paper trivial.\n\n4. Some experiments raise questions. For example, Figure 3 employs t-SNE to visualize the feature space, but due to the inherent instability of t-SNE, this experiment lacks persuasiveness. In Figure 5, why are there multiple points for each modality? And why is the vertical axis using recall rate instead of accuracy?\n\n5. Although the authors mention that one of their contributions is proving the stability of convexity to relevant latent space re-parametrization and provide a formal proof in Appendix A, I was unable to find it. Appendix A only mentions the robustness to affine transformations, which is different from re-parametrization. Furthermore, in 2.1.3, there is an anonymous citation. From the context, it seems that the authors may have inadvertently revealed personal information in this citation."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5486/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698766390667,
        "cdate": 1698766390667,
        "tmdate": 1699636560441,
        "mdate": 1699636560441,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AIgYG4mVYf",
        "forum": "yMMIWHbjWS",
        "replyto": "yMMIWHbjWS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5486/Reviewer_NRVi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5486/Reviewer_NRVi"
        ],
        "content": {
            "summary": {
                "value": "The paper presents some properties of recent neural networks that they found -- convexity emerges everywhere in layers of neural networks. The paper develops a tool for this purpose based on graphs and the Euclidean method. The paper studies the model pre-trained on multiple domains."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "In recent years, the large language model has been demonstrating a huge potential to realize AI whilst humans don't clearly understand how it works, which makes the papers that aim  to interpret deep neural networks more important.  I like the idea of the paper to demystify the learned representation in terms of convexity.\n\nAlso the paper derived a set of tools from convex theory and made it possible to analyze the convex property learned inside neural network. \n\nAlso the paper analyzes neural networks in different domains, which make their conclusion about neural network more convincing."
            },
            "weaknesses": {
                "value": "I have concerns about the paper. Before I lay out the weaknesses list, I would like to mention that I\u2019m not an expert of this domain. And so my suggestions and comments are possibly incorrect.\n\nIs the conclusion of the paper about neural networks new? Scientists who have been developing artificial neural networks are trying to follow the conclusions like convexity found by neural scientists. I think we, as developers of artificial neural networks, would naturally consider this property by design and the conclusion is thus obvious. So when the paper claims that pre-trained neural networks have emergent convexity. I\u2019m not very surprised. So I think the paper might want to clarify whether the conclusion is different from before. In other words, I\u2019m suggesting the paper justifying that it contributes some new paper-worthy observations/conclusions. \n\nHow can this conclusion be used to improve neural networks? It\u2019s interesting to know the convex property of learned representation. But, as a researcher in computer vision,  I\u2019m not sure how this can be used --- e.g., to improve the model. I would suggest authors finding a proper application. For example, the work can inject the conclusion to some other neural network to improve the explanation ability or generalizability etc. \n\nThe paper doesn\u2019t analyze the convex property of neural networks that might be sub-optimal. \nIt might be also interesting to analyze the sub-optimal network  (shallow/smaller networks). From my perspective, it can give you an idea about how much convexity is enforced in different neural networks. \n\nIn short, while the paper presents a tool to analyze the convexity of learned representation, it\u2019s hard to know if the conclusion can inspire future works -- is this a new observation for neural networks or can this conclusion be applied to improve neural networks? Therefore, I tend to reject this paper. \n\nBut again, I\u2019m not the expert in this domain, so I would be happy to hear back from authors during rebuttal in case I misunderstand anything."
            },
            "questions": {
                "value": "please address the questions that I raised above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5486/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698770363647,
        "cdate": 1698770363647,
        "tmdate": 1699636560330,
        "mdate": 1699636560330,
        "license": "CC BY 4.0",
        "version": 2
    }
]