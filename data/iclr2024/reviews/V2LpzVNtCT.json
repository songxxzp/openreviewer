[
    {
        "id": "WK6uwcY7w5",
        "forum": "V2LpzVNtCT",
        "replyto": "V2LpzVNtCT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6969/Reviewer_afMq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6969/Reviewer_afMq"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors present an extension to the structure risk minimization.\nHere the authors present proofs for the impact of effective predicates on learning for data and model complexity.\nThe authors then provide an empirical evaluation for direct and statistical invariants."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Starting from effective predicates, the authors then build proofs showing a reduction in data and model complexity."
            },
            "weaknesses": {
                "value": "From the paper, it does not seem like finding effective predicates is easy, nor integrating them into the learning algorithm. \n\nThe empirical examination does not properly support the claims of the paper, nor serve as a good example of the proofs working and this is the weakest part of the paper."
            },
            "questions": {
                "value": "Does it make sense and invert the problem, i.e., ask, what data points are needed for learning based on the predicates? This could be useful for use cases where exploration is feasible."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6969/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698800294081,
        "cdate": 1698800294081,
        "tmdate": 1699636814416,
        "mdate": 1699636814416,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Nrqh8Oti5S",
        "forum": "V2LpzVNtCT",
        "replyto": "V2LpzVNtCT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6969/Reviewer_ufoZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6969/Reviewer_ufoZ"
        ],
        "content": {
            "summary": {
                "value": "This paper may have a good idea, but is not ready for publication. There are too many assumptions made by the authors that are not made explicit. (Caveat: I am not a researcher in the area of the paper, but I should be able to understand it). The experiments are not up to the standard of a top conference. They seem to show that the proposed idea does not work."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "see above"
            },
            "weaknesses": {
                "value": "First, I think what you call predicates should be called meta-predicates, as they are predicates about the data, not predicates in the data (e.g., as you might find in relational data). I had assumed that you meant predicate as in logic that is a Boolean function, rather than as in the predicate of a sentence. In any case you need to tell us what a predicate is.\n\nThere are lots of problems with notation:\nIn pseudocode 1 (and surrounding text). Are the w_i are probabilities? Are the hypotheses disjoint? But then in theorem 1, the weight update is assume to be positive; surely it can't be positive for all hypotheses. (I think the problem is that there is an explicit quantification that is not given. For it mean \"for all n\" or \"there exists n\"? - as I don't see what n is). In the equation after equation (1), \\Delta w_i is always positive; w_i needs to be explained better,\n\nYou are assuming much more of the reader than can be assumed. You tell us that <f,\\phi> is a pair. And then a very strange sentence in bold; I'm not sure why we would assume any interaction between f and \\phi; it is just a pair.  I think you mean a function of f and \\phi with some properties that you don't state. It is then fine to use the inner product as example.\n\nIn equation (2) why is it only \"approximately equal\"? Surely it should be =\n\nPlease don't say \"which resembles human learning\" without saying how it resembles human learning and providing evidence (eg, a reference) that says that human learning is like that.\n\nOn the bottom of page 5, how can there not be \"countable many data points\"? (I'm having trouble with \"without much loss of generality; I'm thinking of one of the dimensions is time, and we want to predict the future from that past; I'm guessing that is a case that is not covered ;^)\n\nOn the top of page 6, \"Naturally, if we have...\" seems to imply there is no noise in the data. If that is an assumption it should be made explicit.\n\nOn definition 2, please don't use epsilon for two different concepts -- I see now that the epsilon in expsilon-ball is a different font than the < epsilon  (they have to be different as they different units), but it was very confusing. This should be called an equivalent relation as it is not transitive.\n\nDefinition 3 doesn't make sense. I don't think you want \"Let\".\n\nDefinition 5 doesn't make sense. What is \"they\"? I can't see a definition of sub-cover here. Definition 6 seems to also make a claim \"Then, there is a...\" which isn't obvious.\n\nWhy is the union not unique? I don't think I understand what it is then.\n\nPage 8, at the bottom \"same prediction\" seems to imply that y is discrete. If that is the case, it should be made explicit. (Or what does \"same\" mean; do you want some epsilon? ) \n\nThe experiments are not up to the standards of a top conference. The experiments are the average of 10 or 5 runs. No error bars are given, but I would expect the variance to be so high that the results are meaningless. (All the numbers in table 1 look the same to me)."
            },
            "questions": {
                "value": "There is no explicit definition of a predicate. I think it is a function on examples. But isn't that a property? What makes these properties special in that they can be treated differently from the other properties in the data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6969/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699042395969,
        "cdate": 1699042395969,
        "tmdate": 1699636814296,
        "mdate": 1699636814296,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ev4kP0kH60",
        "forum": "V2LpzVNtCT",
        "replyto": "V2LpzVNtCT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6969/Reviewer_kdak"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6969/Reviewer_kdak"
        ],
        "content": {
            "summary": {
                "value": "This paper develops a theory to prove that predicate-powered learning reduces data complexity to build models (not many instances are needed for training) and reduces model complexity."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Attempt to formalize the use of predicates on learning tasks\n- Attempt to prove data and model complexity reduction"
            },
            "weaknesses": {
                "value": "- Lack of background on some of the concepts used\n- Domain knowledge is hard to code and your work depend on domain knowledge\n- Only one experiment with one dataset."
            },
            "questions": {
                "value": "I found this paper very hard to read maybe because the concept of predicate used in this paper does not match the concept of logic predicate (knowledge) I have in mind. The title of this paper mentions the use of predicates. I could not find any predicate example and how they are used/encoded in this work. It'd be ideal to give an example. Authors mention mean and variance, but these can be well used for numerical data. What about categorical data, where predicates are actually useful?\n\nTheorem 1: talks about experditing the learning rate by providing useful predicates, however, the proof mentions number of samples required for learning of SRM being smaller than for ESRM. What is the relation between the reduction in number of samples and learning rate (smaller data?) and how about quality of the model with the reduction in data?\n\nIn Pseudocode 1, line 4, what are the predicates? How do you obtain them?\n\nS2.2: ESRM rule proposed earlier: are you talking about Pseudocode 1? Is it a rule? Or are you talking about some rule used in the original SRM?\n\nThere are some works that embed expert knowledge to learn new models (e.g., https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4525246/ or https://www.jmlr.org/papers/volume17/15-444/15-444.pdf). Knowledge can be embedded through propositionalization or using (first-order) relational models. I guess one of your contribs is to formalize the way knowledge is embedded. However, it looks like your method is limited to numerical or image data.\n\nTypos etc:\nto differentiate the among those hypothesis classes. --> to differentiate among those hypothesis classes.\n\na structure risk minimization rule that we allow the weights -->  a structure risk minimization rule that allows (will allow?) the weights\n\nhat the model should predicate the same --> hat the model should predict (??) the same"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6969/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6969/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6969/Reviewer_kdak"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6969/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699153456115,
        "cdate": 1699153456115,
        "tmdate": 1699636814172,
        "mdate": 1699636814172,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uNQIiRUw7J",
        "forum": "V2LpzVNtCT",
        "replyto": "V2LpzVNtCT",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6969/Reviewer_oViS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6969/Reviewer_oViS"
        ],
        "content": {
            "summary": {
                "value": "The paper considers extending work of Vapnik on learning using statistical invariants. Particularly, they propose an extension of structural risk minimization in which the weights $w_i$ associated to classes $H_i$ are updated to favor those $H_i$ that are closer to satisfying desired invariants. They also try to formalize how predicates can divide the data into equivalence classes, leading to reduced data and model complexity requirements."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea of adjusting weights in SRM to reflect adherence to invariants offers an interesting and straightforward approach for integrating prior knowledge. And it seems worthwhile to explore quantifying how predicates can reduce the need for additional data."
            },
            "weaknesses": {
                "value": "Various typos (e.g. p.2 \u201cthe ability to differentiate the among those hypothesis classes\u201d, p.3 \u201ccontrol the modeling behavior more granular\u201d) and nonstandard terminology (e.g. \"structure risk minimization\", \"equivalent relation\") make the paper hard to read.\n\n\nThe weight update scheme for ESRM is not rigorously developed:\n\n-The pseudocode for ESRM is hard to follow: Perhaps the intention was for $\\epsilon_i$ to be the minimum of the set rather than the set itself. Since $h$ may belong to multiple $H_i$, the objective is also ambiguous as written.\n\n-Theorem 1 seems to only handwave that if we are able to update SRM weights to favor the class $H_i$ containing an optimal model, then we expect the performance of SRM to improve. The subsequent section does not adequately clarify how this would be achieved.\n\nSection 2.3 is hard to contextualize with the rest of the paper:\n\n-The proposed aim is to connect statistical invariants as defined by Vapnik to the concept of invariants elsewhere (e.g. models that require the same output on the orbit of $x$ under some group action). How the analysis achieves this is fuzzy, perhaps due to a lack of definitions. Might be nice to look at the recent work https://proceedings.mlr.press/v128/vapnik20a.html, which has more examples of predicates describing symmetries.\n\nAs written, the definitions and proofs in section 4 and 5 are not rigorous or correct. For example, in Definition 1 the meaning of $P(y_k | \\mathcal{B})$ is not clear, perhaps intended to be an expected value over $\\mathcal{B}$. It is also confusing that the definition seems to be trivially satisfied by setting $\\tilde{D}=\\mathcal{B}$. This confusion is exacerbated in Definition 2, where the meaning of $P(y_k | e_i; \\phi)$ is ambiguous. The proof of Theorem 2 is not rigorous, affecting the proof of Theorem 3. Similar problems with Proposition 1.\n\nThe experiments in section 6 would be improved by graphics comparing the baseline to the invariant augmented models, and employing some form of uncertainty quantification. The connection to ESRM could also be better developed."
            },
            "questions": {
                "value": "-In section 2.2, it is suggested to update weights for $H_i$ proportional to $|\\sum f(x_i) \\phi(x_i) - y_i \\phi(x_i)|$. Is $f$ an arbitrary element of $H_i$? The purpose of subsequently decomposing $f$ and $\\phi$ is also unclear.\n\n-In section 2.3, could you clarify the definition and domain of the linear functional $L_f$? It reads as if $L_f$ might map $\\phi$ to composition $f \\circ \\phi$, but it is not clear to me why this would be linear.\n\n-In section 4, what precisely are $P(y_k |\\mathcal{B})$ and $P(y_k|e_i; \\phi )$? Why do you assume the difference is less than $\\varepsilon$ for all $\\varepsilon$, rather than equal to zero? \n\n-In the proof of Proposition 1, why do you require the axiom of choice when we're dealing with finite samples?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6969/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6969/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6969/Reviewer_oViS"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6969/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699469586823,
        "cdate": 1699469586823,
        "tmdate": 1699636814029,
        "mdate": 1699636814029,
        "license": "CC BY 4.0",
        "version": 2
    }
]