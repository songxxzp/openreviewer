[
    {
        "id": "ojGOc3eMnw",
        "forum": "JkMAlN3YcI",
        "replyto": "JkMAlN3YcI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2391/Reviewer_BVZT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2391/Reviewer_BVZT"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the sources of error in training neural networks for prediction or correction tasks in PDE simulations.  The authors compare three different training paradigms which are ONE (training only by simulating one step forward at a time and evaluating the error after this step), NOG (to train with sequences of length m but to have gradients only flow backward a single step while training) and WIG (use full back propagation through the m steps of simulation time). Unsurprisingly, the WIG method works the best on a suite of tasks, but in many cases NOG can perform almost as well. While the NOG and MIG methods get slightly better with m > 1 , the NOG and MIG methods can be sensitive for large m due to data shift and exploding gradients respectively. Surprisingly the authors report a much more systematic trend with respect to model size: they report a scaling law for simulation accuracy which falls as a power law with model parameter count."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper studies an important problem of using deep networks as simulation/prediction engines for PDE simulation. By examining the difference between these three training paradigms, the authors were able to disentangle the effects of data distribution shift and backpropagation errors.  This allows one to evaluate which types of errors are more important in simulation settings of interest including several popular PDEs. The set of experiments is quite extensive with many additional tests in the appendix."
            },
            "weaknesses": {
                "value": "Some concepts are introduced without explicit definition. I think that the NOG + MIG could be explained more clearly, specifically giving a longer explanation of how the gradients are computed and defining what the authors mean by \u201closs landscape changes\u201d and \u201cdata distribution shifts.\u201d  I think I understand what the authors mean, but it could be helpful to have this more explicitly explained somewhere."
            },
            "questions": {
                "value": "1. Based on the provided experimental results would the authors conclude that the scale of the model is more important in determining good performance than the specific error scheme?\n2. Why do the authors think that learning rate schedules or unrolling curricula are so important for stability in these settings?\n3. How does the compute of the best performing deep learning models compare to direct solvers?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2391/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698678532152,
        "cdate": 1698678532152,
        "tmdate": 1699636174369,
        "mdate": 1699636174369,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M2J3ivLFWf",
        "forum": "JkMAlN3YcI",
        "replyto": "JkMAlN3YcI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2391/Reviewer_CxuR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2391/Reviewer_CxuR"
        ],
        "content": {
            "summary": {
                "value": "The paper attempts to disentangle the possible benefits of temporal unrolling for training neural PDE solvers. The authors focus their investigations on two possibilities: (1) unrolling improves simulators by increasing their resilience to distribution shift when applied over many time steps (2) propagating gradient information through the many steps of the simulation leads to better modeling of long-term interactions. With experiments on several non-linear chaotic systems the authors show that unrolling without gradients can lead to significant improvements over one-step evolution but that unrolling with gradients leads to even greater improvements, especially over longer horizons (e.g. 8 or greater). However, despite notable difference between these two approaches to unrolling, simply increasing the parameter count of the model often has an equivalent or greater impact on the ultimate test loss."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I really admire the goals of this paper. Using physics-inspired neural networks often requires many subtle but important design decisions, and the consequences of the decisions aren't always clear. The authors do a good job of isolating an important and interesting research question and present results for several key ablations on a few popular datasets. The results themselves are fairly interesting, as they suggest, somewhat counterintuitively, that back-propagating through the unrolling process if sometimes unnecessary or at least of minimal marginal benefit. Likewise, in other cases, the results suggest that gradients have an extremely significant effect on the ability of the training to converge when simulating over long horizons."
            },
            "weaknesses": {
                "value": "While I think the goals of the paper are good, when I finished reading it, I wasn't sure exactly what to take away from the experience. Is the primary take-away that gradients are largely unnecessary if training is conducted with an appropriate curriculum? Is this primarily significant because it makes the training process easier for practitioners in some way and thereby facilitates scaling to larger models and systems?  It's not totally clear how much the proposed ablations matter when the effect of model scaling seemed to significantly outweigh the investigated effects of unrolling, so I'm left wondering what the practical impact is. \n\nNovelty and significance: Does this paper have any prescriptions that go beyond prior work, or is it simply a description of ablating several methods from prior work on a collection of datasets and model sizes? Could you turn any observations into an improved method that would outperform an established baseline? There are essentially no baselines in this paper, so I have no sense for how the effect of the ablations compare to the effect of swapping methods. \n\nDepth of insight: There does seem to be some indication that gradients are very helpful in some cases and but not in others, but the authors don't dig deeper into this observation. What is captured my the multi-step gradients that might not be captured by training without gradient on data derived from unrolling (data that captures the distribution shift)? You note that a curriculum is necessary to scale learning to longer rollouts. How would you explain the observation in Figure 6 (left) that gradients aid convergence on longer rollouts whereas training without gradients completely fails? Is one possible explanation that gradients lead to a form of reweighting on the earlier steps in the trajectory, giving them more significance in the learning process, whereas training without gradients on long rollouts inadvertently upweights later parts of the trajectory before the model has learned to fit the beginning of the trajectory well? Could such observations be converted into a method that provably performs better than existing methods. The authors offer a few concrete take-aways, but they don't seem to significantly expand upon insights/methods from prior work."
            },
            "questions": {
                "value": "I've provided a few questions in my response in the weaknesses section that could start a valuable discussion."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2391/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698684413801,
        "cdate": 1698684413801,
        "tmdate": 1699636174277,
        "mdate": 1699636174277,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tOoEyM7ckx",
        "forum": "JkMAlN3YcI",
        "replyto": "JkMAlN3YcI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2391/Reviewer_9oEF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2391/Reviewer_9oEF"
        ],
        "content": {
            "summary": {
                "value": "This paper analyzes the methods of using neural networks to unroll PDEs. Specifically, based on the unrolling steps and differentiability, three variations of methods are tested under different setups. The conclusion is drawn empirically that multi-step differentiable unrolling increases the PDE solution accuracy."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper presentation is high quality. \n\nThe experiment setup is comprehensive, providing varying scenarios to compare different training methods for unrolling PDE."
            },
            "weaknesses": {
                "value": "The motivation for training with a non-differentiable unrolling method is not very clear.  \n\nSome test details are unclear, e.g., the experiment setup behind Figure 1 and the quantification of data shift in different cases. As the paper focuses on benchmarking the training methods, the details are essential for empirical analysis.\n\nThe empirical results lack theoretical support. The reviewer doubt if the results are convictive over different physical systems and NN models."
            },
            "questions": {
                "value": "Figure 1 is intuitive, but how do you get the curves? If it shows the result of a toy example, what is the specific setup, e.g., physical system, NN models, available data?\n\nFor correction setup, physics priors are available. The later experiments include changing the prior\u2019s accuracy to show the performance variation. With priors, can physics-informed NN be used to solve the problem? Then, how about comparing the three variants of unrolling training with SOTA physics-informed NN for solving PDE?\n\nThe average improvement on different testing scenarios using non-differential and differential unrolling training methods looks promising, but is there any theoretical analysis behind it to support the performance so that it can be generally applicable?\n\nThe training of multi-step unrolling seems to be more effective than one-step unrolling. How should the step m be chosen? Figure 6 shows the results with different m values in the Kuramoto-Sivashinsky equation. How about the other systems? Will the step size be decided from validation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2391/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2391/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2391/Reviewer_9oEF"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2391/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699433809694,
        "cdate": 1699433809694,
        "tmdate": 1699636174206,
        "mdate": 1699636174206,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "D7l5uiMSYc",
        "forum": "JkMAlN3YcI",
        "replyto": "JkMAlN3YcI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2391/Reviewer_GanK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2391/Reviewer_GanK"
        ],
        "content": {
            "summary": {
                "value": "This work studies the effect of different training strategies for predicting the long-term dynamics of physical systems. Specifically, three approaches are presented, namely, training for only one step (ONE) of unrolled trajectory, training on a trajectory with no gradient backpropagation throughout (NOG) due to non-availability of a differentiable solver, and training with gradient (WIG) using a differentiable solver. Several experiments are conducted on four different systems in terms of different architectures, system sizes, and tasks. Overall, the work is a benchmarking and dataset track work, although the authors have not mentioned it as the primary area."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* S1: Several useful insights are provided, such as training on a longer horizon trajectory is better, differentiable solvers provide improved accuracy in comparison to their non-differentiable counterparts, curriculum learning helps, and a medium-sized architecture is better. \n\n* S2: Experiments are conducted on several complex and non-trivial systems, albeit on a smaller size (four) for benchmarking and dataset track."
            },
            "weaknesses": {
                "value": "* W1: Codes are not made available, and there is no reproducibility statement. Thus, it is unclear if the work will be reproducible, which is not congruent with the ICLR author guide.\n\n* W2: The details of implementation are not completely mentioned in terms of how the differentiability of the solver was ensured. Was it implemented in PyTorch or JAX? Considering that the main contribution of the work is to understand the effect of training strategy based on differentiable and non-differentiable approaches, these details are important.\n\n* W3: The statistical significance of the results is not clear. In many cases, the error bars are overlapping while claims on one method being better than the other are made. Statistical significance tests such as paired T-tests might be required to validate the claims.\n\n* W4: Many of the claims in the manuscript are fairly trivial or shown in previous works. (1) Large networks yield better results. (2) Learning on trajectory is better (a large family of works on Lagrangian and Hamiltonian Neural Networks have already implemented this and demonstrated it. For example, see https://proceedings.neurips.cc/paper/2020/hash/9f655cc8884fda7ad6d8a6fb15cc001e-Abstract.html ) where they have also used a horizon of 4 timesteps while training the systems, (3) differentiable solvers are better for training ML models of dynamical systems (there is a family of works on JAX and specifically JAX-MD which demonstrates this extensively).\n\n* W5: The experiments are performed on an extremely limited number of datasets and architectures. For a benchmarking and dataset paper, more extensive studies are expected, especially in a dense area where a large number of models and datasets are available. The architectures used are not state of the art (see questions for details)."
            },
            "questions": {
                "value": "1. In Figure 2, both for prediction and correction, the same $f_\\theta$ is shown. The same applies to the text as well. It is unclear how the same $f_{\\theta}$ can act as predictor and corrector. The  $f_{\\theta}$ in predictor takes $u^t$ and predicts $u^{t+1}$. Whereas the  $f_{\\theta}$ in corrector takes $\\hat{u}^{t+1}$ predicted by the physics-based solver and corrects it to  $u^{t+1}$. How can both be performed by the same $f_\\theta$? More explanation, perhaps with the help of an example solver $\\mathcal{S}$, can give some clarity.\n\n2. It is mentioned that across architectures and network sizes, WIG has the lowest error. From the results, it seems to not be clear statistically as the error bars are mostly overlapping. A paired t-test or so may be conducted to establish the statistical significance of the result.\n\n3. In Fig. 4, NOG is giving poorer results than ONE for large network sizes (0.2 M and 1.0M). Why so? Moreover, this is not aligned with the claims in the manuscript in the section \"Disentangling Contributions\".\n\n4. There are two approaches for predicting the long-term dynamics of systems known as Deep Koopman operators, and Fourier Neural Operators. Both of them have shown superior performance in predicting the long-term dynamics of physical and chaotic systems. Especially, FNO with vision transformers has shown promise in predicting extremely complex systems, such as weather forecast at a planetary scale. For benchmarking work, it is important to consider the SOTA models. Moreover, such models may raise additional questions, as outlined in the next question.\n\n5. In the context of neural operators and transformer architectures (which employ all pair attention), do the conclusions made in the paper still hold true? This is important as the SOTA \nmodels rely on these architectures, and commenting on the applicability of these approaches toward the newer architectures is important."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2391/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699495879347,
        "cdate": 1699495879347,
        "tmdate": 1699636174109,
        "mdate": 1699636174109,
        "license": "CC BY 4.0",
        "version": 2
    }
]