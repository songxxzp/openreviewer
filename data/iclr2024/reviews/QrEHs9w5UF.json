[
    {
        "id": "zl9Z4xVRpc",
        "forum": "QrEHs9w5UF",
        "replyto": "QrEHs9w5UF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2058/Reviewer_eU94"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2058/Reviewer_eU94"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a novel approach for identifying and describing failure modes in image classification models. The authors prioritize interpretability by analyzing the model's behavior based on the presence or absence of human-understandable concepts (tags) associated with images in the dataset. The method aims to generate high-quality text descriptions of failure modes while avoiding redundancy and noise. The paper presents experimental results on different datasets to demonstrate the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Novel approach: The paper introduces a new method that prioritizes interpretability in failure mode extraction. By analyzing the presence or absence of human-understandable tags, the proposed approach aims to provide more accurate and meaningful descriptions of failure modes. \n2. Experimental validation: The authors conduct experiments on different datasets to evaluate the effectiveness of their method. The results demonstrate that the proposed approach successfully identifies failure modes and generates high-quality text descriptions associated with them. \n3. Importance of interpretability: The paper highlights the significance of prioritizing interpretability in understanding model failures. By providing human-understandable descriptions, the proposed approach enables easier identification and diagnosis of failure modes, leading to improved model reliability."
            },
            "weaknesses": {
                "value": "1. The authors mention comparisons with other studies (e.g., Eyuboglu et al., 2022; Jain et al., 2022) in the text but do not elaborate on the strengths and weaknesses of these studies and how this study compares favorably to them. It is suggested that the authors provide a more detailed explanation in this regard.\n2. This paper mentions the impact of using different hyperparameter values on the results when discussing generalizability, but does not explicitly state the specific range and selection methods for these hyperparameter values. It is suggested that the authors provide detailed explanations in the paper regarding this so that readers can better understand and apply these methods.\n3. Lack of comparison with state-of-the-art: The paper does not compare the proposed method with the current state-of-the-art methods for failure mode detection and description, making it difficult to assess its advancement. It is recommended that the authors perform a quantitative comparison with the latest methods."
            },
            "questions": {
                "value": "Please check the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2058/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698649552796,
        "cdate": 1698649552796,
        "tmdate": 1699636137721,
        "mdate": 1699636137721,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uxZ7I9qfMN",
        "forum": "QrEHs9w5UF",
        "replyto": "QrEHs9w5UF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2058/Reviewer_j2ri"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2058/Reviewer_j2ri"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the problem of understanding misclassifications in image classifiers. It proposes an approach called PRIME, that uses a set of tags that correspond to human understandable concepts, and finds what combinations of tags align (using a vision-language model) with misclassified subgroups of images. This contrasts with prior work that first clusters misclassified images and then attempts to label them with human understandable concepts, but suffers from the problem that similarity in feature space might not necessarily imply similar features in the image, leading to noisy concept descriptions. A comprehensive experimental evaluation is performed to demonstrate the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The paper addresses the important problem of understanding failure modes in deep networks. Given the black-box nature of such models, this is crucial building trust and deploying such models safely.\n1. It recognizes and addresses a drawback in prior clustering based approaches, that similarity in representation space need not imply similarity in semantic space. This corroborates findings reported in other contexts in prior work (e.g. [1]). It proposes a simple alternative, i.e. tagging all images and finding subgroups that perform poorly, and shows that it is much more effective.\n1. By labelling tags first, PRIME finds exactly what combinations of tags cause the model to fail, instead of just finding what is common in failure cases. The latter may not answer whether every tag in the set is necessary, and so the set may not be minimal. This represents more faithful explanations for the failure modes.\n1. The evaluation performed is comprehensive and across a variety of dimensions, including generalization to generated images, unseen images, and for the quality of the tags. The evaluation also shows the effectiveness of PRIME as compared to prior work.\n1. The paper is well-organized and easy to follow.\n\n\n[1] Hoffmann et al. This Looks Like That... Does it? Shortcomings of Latent Space Prototype Interpretability in Deep Networks. ICML-W 2021."
            },
            "weaknesses": {
                "value": "1. The method seems highly reliant on being able to find all relevant tags first. Failure modes caused by concepts not in the tag set $T_c$ would remain undetected. Given that low frequency tags are filtered out, this could miss potentially important but less frequently occurring failure modes, such as spurious correlations. Broadly, there seems to be a tradeoff involved in choosing the size of the tag set -- larger the set, more the failure modes that can be caught, but also more computationally expensive the method is.\n1. The effectiveness of the method also depends on ensuring that a tag for a concept is actually matched exactly to images containing the concept (i.e., to the accuracy of the Recognize Anything Model). An evaluation of whether this actually happens would have been helpful, especially with datasets that have attribute labels that could potentially be matched to generated tags.\n1. The results in Figure 4 and other similar plots could be more rigorously shown by reporting the correlation between the accuracy drop in the training and test sets for each subgroup."
            },
            "questions": {
                "value": "Discussion on the points raised in Weaknesses would be helpful."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2058/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2058/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2058/Reviewer_j2ri"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2058/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698877635589,
        "cdate": 1698877635589,
        "tmdate": 1699636137657,
        "mdate": 1699636137657,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bqhRUp0GDc",
        "forum": "QrEHs9w5UF",
        "replyto": "QrEHs9w5UF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2058/Reviewer_dBy1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2058/Reviewer_dBy1"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce PRIME, a new method to identify (text descriptions of) coherent groups where a trained image classifier underperforms. PRIME works by (1) \"tagging\" each image using a pretrained model, and (2) performing an exhaustive search over the sets defined by all possible combinations of tags, for the sets which are \"minimal\", larger than some threshold, and have accuracy lower than some threshold. Like past methods, PRIME is \"unsupervised\" in that it does not need a HIL or a comprehensive existing set of tags.\n\n\nThe authors evaluate PRIME in Section 4 by reporting the \"generalization\" of the generated text descriptions (when used to retrieve matching unseen images from a test set or new generated images), and propose three new \"metrics\" that compare the CLIP embeddings of the text description to the images in each group.  They also run additional experiments in Section 5 that further support their claims by demonstrating the \"value\" of defining more specific subgroups using combinations of tags, and also exploring properties of pretrained embeddings such as CLIP."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The authors contextualize related work on error discovery well in the Introduction, and clearly motivate gaps in the existing literature (i.e., that generating text descriptions of groups where an image classifier underperforms is difficult). This problem is timely and significant.\n2. The authors' instructive figures (e.g., Figures 1, 3, and 5) clearly illustrate the benefits of their proposed approach.\n3. The authors' proposed PRIME method is straightforward, and explained in a way that is clear and reproducible as a reader. I specifically like how the authors motivated why they are interested in searching for a minimal set \u2013 to my knowledge, this criteria, while intuitive, has never been discussed in the context of error discovery.\n4. I appreciated the author's exploration of potential limitations with clustering-based approaches by running experiments using CLIP in Section 5.2.  Given the popularity of such embeddings in the field of error discovery, I thought this analysis was particularly timely and significant."
            },
            "weaknesses": {
                "value": "My primary critique of this work is that I believe the authors should directly address potential limitations of their proposed method in their paper.  In the present draft, many important limitations are excluded completely.  I am willing to adjust my score if my below concerns are addressed.\n\n* **Weakness #1: Understanding limitations of relying on a pre-trained tagging model (Step 1)**. PRIME relies on a pre-trained tagging model (in this case, RAM) to provide a set of tags for each image. However, relying on a pre-trained model may have several limitations: \n  * As a simple example, when we consider the \"fox+white+zoo\" group in Figure 1, it is completely possible that RAM may fail to tag a large number of images in the dataset that are in a \"zoo\" (false negatives), or include images that are not taken in a zoo in the group (false positives), etc.  \n  * The tags output by RAM also are likely not comprehensive \u2013 there are some objects that perhaps RAM is worse at recognizing due to their absence in the pretraining data.  \n  * I may be missing something but the present draft is also unclear on how many tags are sampled for each image in this first part, and how the tags are sampled (do you only look at the 100 \"most likely\" tags for each image?).  \n  * All of the authors' evaluation experiments in Section 5 appear to assume that the tags generated by RAM identify groups of images that \"match\" them; however, without further evidence I believe that this assumption is unfounded. I would be interested in whether the authors can perform any kind of small-scale evaluations where they report the precision/recall of the RAM tagger \u2013 perhaps you can even compare its performance at tagging some classes that you already have metadata labels available for.\n* **Weakness #2: Clarify how the \"tags\" should be interpreted (moving from tags to descriptive captions)**.  \n  * Each group is defined as the intersection of a set of tags that are all present in that group's images. But, some ambiguity remains in how to interpret the tags.  While the example groups that the authors selected in Figures 1 and 2 have clear and natural interpretations, in general I think the ambiguity of modifiers, attributes, and propositions (relationships between multiple objects) may be difficult to interpret.  Even for the group \"fox + white\" (which the authors interpret as foxes with white fur), it's unclear to me if this is a correct interpretation because the tagging model may include any photo that has \"white\" anywhere at all in it (ex, an orange fox in the snow).  I believe that leaving this point unaddressed may mislead users of PRIME to draw the wrong conclusions.\n\n* **Weakness #3:  Clarify experimental methodology.**  I would like to see more detail in the main text about some parts of the experimental methodology to ensure that the examples provided in the paper are indeed representative of PRIME's performance (instead of being cherry-picked to make PRIME look good).  \n  * Specifically, how exactly did you \"use ChatGPT\" to move from sets of tags, to semantically meaningful captions, in Section 4.2 (and did you do any qualitative verification that these generated captions indeed seemed to \"match\" their corresponding groups of images)? \n  * How did you select the images that you're visualizing for each of the groups in Figures 1, 3, and 5 \u2013 were they randomly selected, or chosen (related to my Weakness #1)?"
            },
            "questions": {
                "value": "See Weaknesses above.\n\nIn addition my listed weaknesses (which are more important to address), I had a few remaining clarifying questions/suggestions:\n* Make clear in the introduction that your method doesn't rely on human-labeled tags, but rather uses a pre-trained model\n* nit (p2): \"images who match group of tags identified as a failure mode\" => \"the images that match a failure mode\"...\n* nit (Section 4): rather than saying \"difficulty (of the detected failure modes)\", explicitly use terms like \"accuracy\" or \"performance gap\", as \"difficulty\" is vague\n* Section 5.2: I want to see more nuance in this discussion about how it seems like your method will always incentivize choosing a higher-error subclass (rather than a larger superclass), when in reality it may be of interest to return the superclass.  I don't think that \"smaller\"/\"more specific\" is always better in practice.  I think what's interesting about the exhaustive search here is that you can present the performance over all of the possible subgroups to the model developer/user, who can then choose which ones they would like to prioritize for fixing or further evaluation moving forward. \n* Two helpful references to consider adding to your related work section that illustrate the difficulty of generating high-quality text descriptions for error discovery are (1) Appendix C of AdaVision [1], and (2) the user study in Johnson et al. [2], \n\n[1] https://arxiv.org/abs/2212.02774\n[2] https://arxiv.org/abs/2306.08167"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2058/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2058/Reviewer_dBy1",
                    "ICLR.cc/2024/Conference/Submission2058/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2058/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698905530825,
        "cdate": 1698905530825,
        "tmdate": 1700497130960,
        "mdate": 1700497130960,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "u8rPvyGc9z",
        "forum": "QrEHs9w5UF",
        "replyto": "QrEHs9w5UF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2058/Reviewer_WEiw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2058/Reviewer_WEiw"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method to find human-understandable descriptions of situations under which a given image classification model fails. The authors argue that prior works obtain these descriptions using clustering in latent spaces which results in poor identification of shared attributes. In their method, they first obtain _tags_ for images using a SOTA model, and then find combinations of tags for which the model performs poorly to understand failure modes. They claim that this _interpretability-first_ approach results in a more robust failure mode extraction method."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Experiments done on multiple datasets to support the approach.\n2. Visual examples of the method working look promising. The proposed method maybe a good practical method to generate descriptions of failure modes in a general purpose entity recognition models."
            },
            "weaknesses": {
                "value": "1. The method relies heavily on an auxiliary model (like Recognize Anything Model). Although this makes an important tool for describing failure modes, everything that the proposed method can do is bottlenecked by this auxiliary model's capability. For example, the authors present this method as a tool to describe \"failure modes in trained image classification models\". However, what happens when the image classification model is trained on a domain-specific dataset like chest X-Rays? How can we expect the auxiliary general purpose model to provide tags for this dataset? This is a practical paper but we do not see ablation studies with other general purpose auxiliary models (apart from RAM), or other experiments with domain-specific image classification models.\n2. The tag generation process requires a threshold hyper-parameter. Similarly, there a lot of hyper-parameters in the proposed method's setup like $b_i$, $a$, $s$, $l$, etc. Some of them look more sensitive than others. However, no insights are given on how they are selected apart from saying \"we generally\" use these values. \n3. In 4.1 paragraph 1, the authors say that $D$ and $D'$ are from the same distribution, and hence the accuracy drop should translate. This is not what generalization means. Generalization applies to the scenario when unseen data is from a shifted distribution. As the authors clearly mention that the unseen dataset is drawn from the same distribution (and not explicitly curated in some way like selective sampling), this dismisses all claims of generalization. The generalization on generated data is an interesting experiment but the fact that authors fine-tuned the generated model on the training data simply nullifies all claims of generalization. \n4. The authors say, \"We utilize language models to create descriptive captions for objects and tags associated with failure modes in images\". It is unclear how this is done. And how is the quality of the generated captions measured?\n5. Regarding the quality of descriptions metrics: Firstly, I have no idea what the AUROC metric means at all. Moreover, these \"three\" metrics are again based on another auxiliary model. It suffers from all the same issues as mentioned in point 1. The authors don't talk about this potential pitfall. Additionally, this evaluation goes through multiple models to come up with embeddings to calculate a distance metric. First, the tags are generated using RAM. After the failure mode tags are identified, they are passed through a language model to generate captions. Then, the caption is passed through another foundation model to generate text embeddings while the original image is passed through the same foundation model to generate image embeddings. I don't see how we could make any definitive claim about these metrics (which don't seem to be very different from the corresponding values of DOMINO).\n6. Regarding the similarity between representation space and semantic space: This analysis is confusing and potentially flawed. The representation space may carry nuanced information which is not captured by the tags. For example, a common tag which says \"water\" may have very different representations depending on whether it is ocean blue water or river green water. Therefore, it can not be expected that closeness in representation space should closely align with closeness in semantic space. The semantic space is formed after (potentially several) layers of abstraction on the representation space which is supposed to store all fine-grained details. The fact that table 5 still shows a significant number of overlapping tags in nearby images is something that I would expect to begin with. The images that share maximum number of tags might have very different subtle differences that make them distant in the representation space."
            },
            "questions": {
                "value": "See weaknesses.\n\nOverall, I feel that although the presented approach may yield good failure mode descriptions for some general purpose models, the study is not sound enough. Moreover, the paper lacks a section on limitations (in my view, there are many). All this fails to excite me to support of the paper for acceptance."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2058/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2058/Reviewer_WEiw",
                    "ICLR.cc/2024/Conference/Submission2058/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2058/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699491585710,
        "cdate": 1699491585710,
        "tmdate": 1700539970694,
        "mdate": 1700539970694,
        "license": "CC BY 4.0",
        "version": 2
    }
]