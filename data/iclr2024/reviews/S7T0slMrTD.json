[
    {
        "id": "jQyJDcQAZJ",
        "forum": "S7T0slMrTD",
        "replyto": "S7T0slMrTD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4797/Reviewer_PtZ2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4797/Reviewer_PtZ2"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors introduce KNOWLEDGE CONFLICT, an evaluation framework for simulating contextual knowledge\nconflicts and quantitatively evaluating to what extent LLMs achieve the following goals: 1) identify knowledge conflicts, 2) pinpoint conflicting information segments, and 3) provide distinct answers or viewpoints in conflicting scenarios."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1)  The authors design a series of knowledge conflict tasks to measure the performance of existing LLMs to generate response based on conflicted knowledge\n2\uff09The developed framework is technically sound and easy to follow"
            },
            "weaknesses": {
                "value": "The most shorting is the orginize of the whole article and detailed questions can be found in the following part"
            },
            "questions": {
                "value": "First of all, I really apprecitate the author start to investigate the problem of knowlege confilct in LLMs, which is urgent need to be solved in practical Chatbot. And the authors also developed a knowledge confilct framework equipped with a series of tasks to solve this question.\n\n\nHowever, the originize of this paper is really poor, the authors mixed the design of each taskd and their method in the same part, which will confuse the readers. I really suggest the authors to pay more attention to the writting of this paper.\n\nFor technical details, in Task 1, I wonder which kind of pomprt you used in other baselines, like Few-shot prompting and Chain-of-Thought prompting (CoT), and your method in Table.1 indicates using the prompt ``Does the given context conflict with what you know? Yes/No''. \nThen, for each experimental result, I wonder if your method will include some examplers as demonstrations or just the prompt mentioned in your article?\n\nFurther, for NER in the first step, I wonder how you deal with the senario of there are multiple entity term in a sentence, will you enumerate them and generate context of parmetric knowledge for them?\n\nOverall, the method is simple but will be useful in my understanding, but I wonder author have idea to how to combine your method with existing prompting method, like CoT, because there are still a lot of multi-hop question in practice and you will not know the knowledge confilct happens in which step, just like when you solve a math problem, you don't which confictled knowledge leads to a wrong intermediate result"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4797/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698394526667,
        "cdate": 1698394526667,
        "tmdate": 1699636462265,
        "mdate": 1699636462265,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "LOkLxYjnLt",
        "forum": "S7T0slMrTD",
        "replyto": "S7T0slMrTD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4797/Reviewer_pvzs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4797/Reviewer_pvzs"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new evaluation framework called KNOWLEDGE CONFLICT to assess the abilities of large language models (LLMs) to handle knowledge conflicts. Knowledge conflicts arise when there is a discrepancy between the LLM's internal parametric knowledge and external non-parametric knowledge provided in the prompt context. \nTo evaluate this, the framework includes tasks to test LLMs on:\n-Detecting contextual knowledge conflicts\n-Pinpointing conflicting spans in QA settings\n-Generating distinct answers drawing on conflicting knowledge\n\nThe authors find that while LLMs can identify knowledge conflicts, they struggle with localizing conflicts and producing distinct responses. New instruction-based methods are proposed that improve performance on conflict detection and distinct answer generation. The analysis also reveals factors impacting conflict handling abilities."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The topic is an important open problem of handling knowledge conflicts in LLMs.\n- Writing is clear and well-presented. \n- Introduces a comprehensive evaluation framework with diverse, complex test cases"
            },
            "weaknesses": {
                "value": "-Framework limited to word-level knowledge edits, more complex conflicts may be harder\nThe hallucination is possible in LLM's answer. It seems that this is not well addressed in the paper."
            },
            "questions": {
                "value": "- Could the assumption of a single parametric knowledge answer be relaxed? How would results change?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4797/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4797/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4797/Reviewer_pvzs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4797/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698812568262,
        "cdate": 1698812568262,
        "tmdate": 1699636462166,
        "mdate": 1699636462166,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qpREIIvCPg",
        "forum": "S7T0slMrTD",
        "replyto": "S7T0slMrTD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4797/Reviewer_o2Z4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4797/Reviewer_o2Z4"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a framework to evaluate LLMs\u2019 ability to handle knowledge conflicts, which includes: 1) identifying contextual knowledge conflicts, 2) pinpointing conflicting knowledge segments, and 3) providing distinct answers or viewpoints amidst conflicts. Under the setting the authors proposed above, the instruction-based approach is introduced to alleviate these problems."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThis article breaks down the evaluation aspects of knowledge conflict issues in a fine-grained manner and proposes a reasonable idea that LLMs should not rely solely on either parametric or non-parametric information, but grant LLM users the agency to make informed decisions based on distinct answers.\n2.\tFor the three proposed tasks, this paper designed plenty of experiments for verification. The motivation is clear and the prompt templates are straightforward."
            },
            "weaknesses": {
                "value": "1.\tThe experimental settings are not rigorous. The data sets corresponding to the three knowledge conflict tasks are generated according to several rules (entity substitution and shuffling), and then the proposed approaches (prompt templates) are strongly related to these artificial rules. That is my main concern: with those settings, the experiments in the paper might have limited value and provide limited insights. Besides, this paper seems to lack a connection to previous works in the field of knowledge conflict. The organization of the entire article is isolated and does not introduce other benchmarks/analysis[1] or other method comparisons that specifically address knowledge conflict issues.\n2.\tThe limited size of the knowledge conflict dataset proposed in this paper makes the analysis unconvincing. Take Figure 4 as an example, the authors argue that the ability to tackle knowledge conflict varies across knowledge domains. However, according to Table 7 in the appendix, on average there are only about 100 test cases per domain, which I think is far from enough to claim that knowledge conflict varies across knowledge domains.\n\n[1] DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering. ACL 2023"
            },
            "questions": {
                "value": "No more questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4797/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699430902971,
        "cdate": 1699430902971,
        "tmdate": 1699636462093,
        "mdate": 1699636462093,
        "license": "CC BY 4.0",
        "version": 2
    }
]