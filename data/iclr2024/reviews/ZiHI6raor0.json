[
    {
        "id": "fm9cyt9jnz",
        "forum": "ZiHI6raor0",
        "replyto": "ZiHI6raor0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7771/Reviewer_ECyq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7771/Reviewer_ECyq"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a multi-agent reinforcement learning (MARL) algorithm CAMMARL, where each agent's policy is not only conditional on its own observation, but also on the estimate of other agents actions. Specifically, it uses conformal predictions to learn confident sets containing other agents' probable action estimates. CAMMARL consider two agents setting and is tested on two MARL tasks, cooperative navigation and level-based foraging."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-motivated. Modeling other agent's actions is intuitively helpful for learning a good policy.\n- There are some relevant  statistical analysis over how CAMMARL works, such as the averaged set sizes outputted by the conformal predictor. \n- A range of related baselines are considered."
            },
            "weaknesses": {
                "value": "- The predicted conformal sets is exponentially growing with respect to $|\\mathcal{A_{other}}|$, which may not be scalable when $|\\mathcal{A_{other}}|$ is large.\n- The paper is restricted to the two agents setting. It is not clear if the proposed method can generalize to more complex tasks with potentially many agents.\n- The experiment results are preliminary in only two tasks. Further, the improvement over the baselines is not obvious, especially in CN in Figure 4."
            },
            "questions": {
                "value": "- Can CAMMARL work in settings with more than two agents? If so, it is beneficial to show its effectiveness in some more complex MARL benchmarks with more agents.\n- Does $\\mathcal{N_{other}}$'s action also condition on $\\mathcal{N_{self}}$'s action?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7771/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7771/Reviewer_ECyq",
                    "ICLR.cc/2024/Conference/Submission7771/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7771/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698094071877,
        "cdate": 1698094071877,
        "tmdate": 1700709701562,
        "mdate": 1700709701562,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9BJbKiWSTa",
        "forum": "ZiHI6raor0",
        "replyto": "ZiHI6raor0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7771/Reviewer_8c8j"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7771/Reviewer_8c8j"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes CAMMARL, a novel multi-agent reinforcement learning algorithm that uses conformal predictions to model the actions of other agents in the environment as sets that contain their true actions with high probability. The paper claims that these sets can inform the decision-making of an agent and improve its performance in cooperative tasks. The paper demonstrates the effectiveness of CAMMARL in two multi-agent domains and compares it with several baselines that use different types of information about other agents."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper addresses an important and challenging problem of reasoning about other agents in partially observable environments. The paper introduces a novel way of using conformal predictions to model the uncertainty and confidence of other agents' actions. The paper presents extensive experiments on two challenging cooperative tasks and demonstrates that CAMMARL improves over various baselines in terms of returns, learning speed, set sizes, and coverage. The paper also discusses some limitations and future directions for extending CAMMARL to more complex scenarios. The paper is well-written, clear, and well-structured. The code is provided for reproduction."
            },
            "weaknesses": {
                "value": "The paper has some limitations and possible areas for improvement.\n\n- The paper could provide more thorough discussions on experiment details. For example, the paper does not explain how the regularization term in the conformal prediction model is chosen or tuned, or how it affects the performance of CAMMARL. A more transparent and rigorous analysis of this aspect would enhance the credibility and generalizability of CAMMARL. Also, what are the differences of the settings between different baseline algorithms compared in the paper? Since they have different dimensions of input, maybe they also need slightly different training settings to achieve their own best performance.\n- The paper uses learning curves as the only evaluation metrics but does not provide any qualitative analysis or visualization of the learned policies or behaviors of CAMMARL agents, which would help to illustrate how they leverage conformal predictions to cooperate effectively.\n- The paper only considers fully cooperative settings and does not explore how CAMMARL would perform in competitive or mixed scenarios where other agents' intentions may not be aligned or predictable. Especially, in the competitive robust RL setting, the conformal set could potentially be used for worst-case analysis.\n- The paper does not discuss any potential drawbacks or challenges of using conformal predictions, such as computational costs, calibration issues, or sensitivity to hyperparameters."
            },
            "questions": {
                "value": "- Intuitively, the idea of using conformal predictions to model the actions of other agents is to augment the agent\u2019s state with the historical memory of other agents' behavior, which is similar to fictitious play in game theory. However, fictitious play only converges in some specific game settings, and MARL is known to be hard to converge in general settings. Moreover, the conformal predictions are based on previous observations but the other agent\u2019s policy is also evolving. Is there any observation where the algorithm does not converge well or even has cycling behavior?\n- In the paragraph of Global-Information-Agent-Modeling (GIAM), the paper states that this can be infeasible in real-world scenarios. Why is that? Seems like the information used in this algorithm is the same as CAMMARL. The difference is that, the historical trajectories are used to first train a prediction model and then feed into the agent\u2019s policy network, whereas in GIAM, it is directly used in the policy network in an end-to-end way.\n- How does CAMMARL handle different set sizes produced by the conformal model? How does it encode them into input features for policy learning? How does it affect the stability and convergence of policy learning?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7771/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7771/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7771/Reviewer_8c8j"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7771/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698618889651,
        "cdate": 1698618889651,
        "tmdate": 1700681355095,
        "mdate": 1700681355095,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9dGGy5Z6iy",
        "forum": "ZiHI6raor0",
        "replyto": "ZiHI6raor0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7771/Reviewer_Jmhr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7771/Reviewer_Jmhr"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a multi-agent reinforcement learning algorithm that uses conformal prediction to explicitly reason about the behavior of other agents. To evaluate their proposed algorithm two experiments using cooperative simulated environments are conducted. The experiments show that CAMMARL outperforms alternative methods though is still short of a model with access to global information."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Applying conformal prediction to reason about agents in a MARL problem is a simple but straight-forward idea that doesn't suffer from the drawbacks of alternatives methods which require considerable more compute and data (e.g., inverse reinforcement learning).\n* The conformal approach not only supports reasoning about others but also provides confidence measures around its reasoning"
            },
            "weaknesses": {
                "value": "* Beyond the idea of using conformal modelling for action prediction there does not appear to be large algorithmic advancements in solving the conformal problem in this setting\n* The simulated environments used in the experiments are quite simple \n* Algorithm 1 is difficult to follow. For example, there are many lines with multiple assignments and updates."
            },
            "questions": {
                "value": "* What is $b_{conformal}$ in Algorithm 1?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I have no concerns."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7771/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7771/Reviewer_Jmhr",
                    "ICLR.cc/2024/Conference/Submission7771/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7771/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698802510875,
        "cdate": 1698802510875,
        "tmdate": 1700503363303,
        "mdate": 1700503363303,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6NWSwbeIMm",
        "forum": "ZiHI6raor0",
        "replyto": "ZiHI6raor0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7771/Reviewer_XZg9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7771/Reviewer_XZg9"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors propose a multi-agent reinforcement learning (MARL) algorithm CAMMARL, which models the actions of other agents in different situations. The the estimates are used to inform an agent's decison-making. The experimental results illustrate that the proposed method elevates the capabilities of an autonomous agent in MARL."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The motivation of this paper is reasonable.\n+ This paper is well-organized and well-written.\n+ The main idea of the proposed method is described in great details."
            },
            "weaknesses": {
                "value": "+ It seems that the proposed method does not improve the performance greatly compared with other methods.\n+ The scenarios selected in this paper are not so convincing to some extend. More experiments should be conducted to demonstrate the superiority of the proposed method against other methods.\n+ The assumption of this paper is too ideal. Commonly, it is hard to obtain observations from other agents in MARL especially in the context of decentralization."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7771/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698835820344,
        "cdate": 1698835820344,
        "tmdate": 1699636949259,
        "mdate": 1699636949259,
        "license": "CC BY 4.0",
        "version": 2
    }
]