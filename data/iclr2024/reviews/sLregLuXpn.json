[
    {
        "id": "JE0TeH9cDh",
        "forum": "sLregLuXpn",
        "replyto": "sLregLuXpn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2235/Reviewer_YTga"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2235/Reviewer_YTga"
        ],
        "content": {
            "summary": {
                "value": "## Summary\n* This paper studies the problem of noise-resistent I2I generation. Particularly, it studies the noise injection approach both theoretically and practically. The paper shows that the joint f-divergence does not change too abruptly when the source is polluted by Gaussian noise. Further, the paper finds optimal noise level for training when the source is Gaussian, and verify their results on Gaussian source and real images."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "## Strength\n* The result of optimal training level in __Corollary 1__ is useful to practical training of noise resistent generative model, if it is not limited to Gaussian source. It provides theoretical justification to a  intuitative practice.\n* The empirical result show that their approach improves the noise-robustness in various cases."
            },
            "weaknesses": {
                "value": "## Weakness\n* The discussion after __Lemma 1__ only convers non-Gaussian noise, but the majority of experiment is about non-Gaussian source. The gap of source distribution should at least be explicitly discussed in the main text not appendix, if not well addressed. Currently the proof of __Corollary 1__ seems to rely on Eq. 6 of __Lemma 1__, which holds only when the source is Gaussian. If I understand correctly, in that case, it becomes unreasonable to derive the optimal noise level $0.08$ for actual image generation, which is obviously non-Gaussian. If the theory is not connected to the experiment, then this paper becomes a little bit unconvincing. As no new empirical approach is proposed and the empirical results alone is not enough for accepting this paper."
            },
            "questions": {
                "value": "## Questions\n* Is it possible to extend current theory (__Lemma 1__, __Theorem 2__, __Corollary 1__) to non-Gaussian source with known $\\mu,\\Sigma$? As Gaussian is the max-entropy distribution with known 1st and 2nd moment, can similar results be obtained?\n* Is it possible to extend current theory (__Lemma 1__, __Theorem 2__, __Corollary 1__) to mixture of Gaussian source? As we can approximate any distribution, including natural image distribution with GMM, it would be much better if we can extend the theory to GMM, even for finite mixture. In this way, the distance between the current theory and empirical results on natural image can be reduced.\n* Current analysis on joint distribution looks quite general, can it be extended into any conditional GAN, beyond I2I?\n* What about more real-life noise, e.g. JPEG compression?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2235/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2235/Reviewer_YTga",
                    "ICLR.cc/2024/Conference/Submission2235/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2235/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698141347676,
        "cdate": 1698141347676,
        "tmdate": 1700547521893,
        "mdate": 1700547521893,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xnXXlMHasJ",
        "forum": "sLregLuXpn",
        "replyto": "sLregLuXpn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2235/Reviewer_Ceu7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2235/Reviewer_Ceu7"
        ],
        "content": {
            "summary": {
                "value": "This work provides a robust theoretical framework elucidating the role of Gaussian noise injection in I2I translation models. They address critical questions on the influence of noise variance on distribution divergence, resilience to unseen noise types, and optimal noise intensity selection."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper thoroughly investigates the Gaussian noise in I2I area from both the theory and experiment. \n- Extensive experiments and analysis make the effects of the Gaussian noise more clear to us."
            },
            "weaknesses": {
                "value": "- Analysis of the Gaussian noise has been widely investigated, the authors should give some comparison or analysis about them in related works."
            },
            "questions": {
                "value": "- How do you quantize the real and predictive distribution? Furthermore, how do you measure the diff between them?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2235/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2235/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2235/Reviewer_Ceu7"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2235/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699075854229,
        "cdate": 1699075854229,
        "tmdate": 1699636156711,
        "mdate": 1699636156711,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9oYd0HMg15",
        "forum": "sLregLuXpn",
        "replyto": "sLregLuXpn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2235/Reviewer_SHt1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2235/Reviewer_SHt1"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a robust theoretical framework for understanding the role of Gaussian noise injection in image-to-image (I2I) translation models. The key contributions of this work include:\n\n(i) Analyzing the influence of noise variance on distribution divergence and resilience to unseen noise types.\n\n(ii) Proposing a method to choose an optimal training noise level for consistent performance in noisy environments.\n\n(iii) Connecting f-divergence and score matching to explain the impact of Gaussian noise on aligning probability distributions."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "(i) The writing is clear and easy to follow. The presentation is well-dressed.\n\n(ii) This paper conducts a detailed theoretical analysis in Section 3 to understand the role of Gaussian noise injection in I2I models from the perspective of alignment distribution.\n\n(iii) To validate the conjecture proposed in this paper, the authors conduct sufficient experiments including three types of I2I models, i.e., cat to dog, photo to sketch, and human face super-resolution, covering five types of noise: Gaussian, Uniform, Color, Laplacian, and Salt & Pepper."
            },
            "weaknesses": {
                "value": "(i) This paper has a fatal theoretical flaw, i.e., the authors think too simply and naively about real-world degradations. They set up additive Gaussian noise in the training phase and five synthetic degradations (Gaussian, Uniform, Color, Laplacian, and Salt & Pepper.) in the testing phase. However, the real-world degradations are much more complex and fundamentally different from these degradations. To be specific, as for the noise term, the real-camera raw noise produced by photon sensing comes from multiple sources (e.g., short noise, thermal, noise, dark current noise, etc.) [1, 2, 3] and is further affected by the in-camera signal processing pipeline to become spatio-chromatically correlated. The real-camera noise contains both signal-dependent and -independent terms. However, the authors only consider very naive and simple signal-independent noise types, which is far from their motivation because the degradation patterns they studied simply do not exist in real-world images. Similar to the face super-resolution problem, the blur kernel cannot be explicitly estimated. \n\n[1] CycleISP: Real Image Restoration via Improved Data Synthesis. In CVPR 2020\n\n[2] Variational denoising network: Toward blind noise modeling and removal. In CVPR 2019\n\n[3] Dual adversarial network: Toward real-world noise removal and noise generation. In ECCV 2020\n\nIf you want to continue studying this topic, which I think is valuable too, I suggest you to conduct experiments in real degraded images. Here are some suggested datasets:\n\n[4]  A high-quality denoising dataset for smartphone cameras. CVPR 2018\n\n[5] Deep retinex decomposition for low-light enhancement. BMVC 2018\n\n[6] Ntire 2020 challenge on real-world image super-resolution: Methods and results. In CVPRW 2020\n\n(ii) This work does not have any technical contributions. Training with additive Gaussian noise has been studied in the image denoising I2I task for a long time. It is a very common setting. The robustness of noise has also been validated by many prior works. This paper does not propose any new method.\n\n(iii) The idea of adding Gaussian noise and aligning distribution is highly similar to a prior work [7] that also studies real-camera degradations in I2I tasks. There is no discussion or comparison.\n\n[7] Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware Adversarial Training. In NeurIPS 2021.\n\n(iv) Code and pre-trained models are not submitted. The reproducibility cannot be checked."
            },
            "questions": {
                "value": "(i) For the theoretical noise analysis part, if considering signal-independent and -dependent noise terms, what will happen to the analysis? How does it change?\n\n(ii) To measure the domain discrepancy, why not using the metric PSNR Gap proposed by the prior work DANet [3]?\n\n[3] Dual adversarial network: Toward real-world noise removal and noise generation. In ECCV 2020"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2235/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2235/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2235/Reviewer_SHt1"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2235/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699412645678,
        "cdate": 1699412645678,
        "tmdate": 1699636156649,
        "mdate": 1699636156649,
        "license": "CC BY 4.0",
        "version": 2
    }
]