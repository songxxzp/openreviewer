[
    {
        "id": "MbReHLrJMM",
        "forum": "tsbdcgaCtk",
        "replyto": "tsbdcgaCtk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7489/Reviewer_9pCm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7489/Reviewer_9pCm"
        ],
        "content": {
            "summary": {
                "value": "they propose to make the NMT models themselves quality-aware by training them to estimate the quality of their own output. During decoding, they can use the model\u2019s own quality estimates to guide the generation process and produce the highest-quality translations possible. They demonstrate that the model can self-evaluate its own output during translation, eliminating the need for a separate quality estimation model."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper trains the so-called quality-aware NMT models, which is somewhat novel."
            },
            "weaknesses": {
                "value": "- This paper is not well written, I mean, they just train the model with two tasks at the same time, i.e., translation and sentence-level QE. Their model does not have the ability to evaluate the output's quality, which is their argued contribution.\n- From the training procedure, I can not get how the model is aware of the translation quality. The method and experiments are not convincing enough.\n- The results listed in the experiments are not enough. Why not report the BLEU score? I guess, the BLEU score is not improved as this paper uses the BLEURT-QE as the quality estimation."
            },
            "questions": {
                "value": "- See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7489/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7489/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7489/Reviewer_9pCm"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7489/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697977718635,
        "cdate": 1697977718635,
        "tmdate": 1699636903899,
        "mdate": 1699636903899,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zzNNjgMQjh",
        "forum": "tsbdcgaCtk",
        "replyto": "tsbdcgaCtk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7489/Reviewer_SaRa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7489/Reviewer_SaRa"
        ],
        "content": {
            "summary": {
                "value": "This paper presents methods for training an NMT model to perform quality estimation along with translation. One benefit of this paradigm is that the MBR decoding could be performed with a high efficiency. The experiments show that the translation quality could be improved."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The methods are: appending the QE label to the source segment; appending the QE label to the target segment, which are both quite easy to perform.\n\nWith the proposed method, the MBR decoding could achieve competitive performance with 10-20 candidates, which is much smaller than reported in previous paper."
            },
            "weaknesses": {
                "value": "1. generating a quality label does not necessarily mean that the model has the ability to predict it. I am wondering if there is some disturbances are made to the sentence in the training data, will the proposed model generate the correct quality label (showing the quality goes down)?\n\n2. according to fig.1 , the prediction of quality labels is not good at all. The model seems not to be able to discriminate candidates with different qualities.\n\n3. using QE label as the generation labels seems to be an interesting idea. Will you please give some examples of the same source sentence translated with different QE labels? It would be nice to see the effect demonstrated.\n\n4. I am not quite sure how is the quality difference between two translations with 1 point difference in MetricX or Comet score. It will be better to give some examples to show how the translation quality is improved indeed."
            },
            "questions": {
                "value": "See the weakness part for the details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Research integrity issues (e.g., plagiarism, dual submission)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The paper is based on one anonymous paper, presenting BLEURT-QE. The paper is under review, which is not accessible. \n\nSec. 3.1 use BLEURT-QE as its core method to assign quality score to each sentence of the training set, which I believe is very important to the success of the whole paper.\n\nThe attribution of the method BLEURT-QE is unclear.\n\nThe effects of BLEURT-QE is not demonstrated, which makes part of this work unclear."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7489/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698806770001,
        "cdate": 1698806770001,
        "tmdate": 1699636903761,
        "mdate": 1699636903761,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vzByuAT6ZY",
        "forum": "tsbdcgaCtk",
        "replyto": "tsbdcgaCtk",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7489/Reviewer_e2tN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7489/Reviewer_e2tN"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed two methods to make the NMT model quality aware. One is to prompt the NMT model with a quality score during training, but using the best score during inference time. The other is similar to multi-task learning but in a more unified way by appending the quality score in the target side. Both approaches show promising improvements in translation quality and one of them can work well with the MBR decoding to boost the translation quality further."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper targets an interesting and essential problem for NMT, which is both related to the translation safety and quality. It proposes two novel and efficient methods. Both methods are very simple but effective according to the experiments. The paper is also well written and clear to me mostly. I believe the proposed methods have the potential to be applied to large scale translation systems."
            },
            "weaknesses": {
                "value": "My concerns are in the questions. If they can be addressed properly, they won't be weakness to me."
            },
            "questions": {
                "value": "In conclusion, which one between QA prompting and prediction approaches is your recommendation in the situations including latency sensitive inference and large scale distillation. Please also describe how do you scale your methods in large scale multilingual machine translation system. The experiments highly relies on the model best evaluators. How do you make a cold start on a low resource setting?\n\nOn discretizing the quality scores, what if the distribution of the scores are very skew? What issues can you see in this case and how would you resolve them?\n\nIs it possible that the quality score won't be generated during sampling in the prediction approach because it's not guaranteed? How do you handle this situation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7489/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7489/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7489/Reviewer_e2tN"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7489/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814719448,
        "cdate": 1698814719448,
        "tmdate": 1700329225822,
        "mdate": 1700329225822,
        "license": "CC BY 4.0",
        "version": 2
    }
]