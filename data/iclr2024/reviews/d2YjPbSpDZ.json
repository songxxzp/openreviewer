[
    {
        "id": "FpiNKEu99v",
        "forum": "d2YjPbSpDZ",
        "replyto": "d2YjPbSpDZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8031/Reviewer_snNy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8031/Reviewer_snNy"
        ],
        "content": {
            "summary": {
                "value": "The paper analyzes the convergence of models in federated learning to the optimum in a convex scenario with standard normal features and Gaussian noise."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- generalization bounds for Federated Learning are an interesting and largely open problem (the only existing generalization bound for FL for deep learning I know relies on the NTK framework [6]).\n- the paper analyzes both stationary and non-stationary targets"
            },
            "weaknesses": {
                "value": "- the contribution beyond existing results is unclear\n- relevant related work is not discussed\n- the results are presented in a convoluted and unintelligible way with an unnecessary function $\\mathcal{F}$ that hides the actual result and is not interpretable to me\n- there are no experiments (e.g., on simulated data) to evaluate the tightness of the bounds\n- the proofs provided in the Appendix are not well presented"
            },
            "questions": {
                "value": "**Questions:**\n\n- How do the results for $K>1$ in this paper relate to the results on model averaging for linear regression in [5]?\n- Why do you need the assumption of standard normal features? While Gaussian noise is a common assumption in the analysis of linear regression, this assumption appears to strong to me. Even the analysis in [1] only assumes that data is generated by a process using a covariance operator and a random variable whose components are independent and subgaussian. Shouldn't such an already strong assumption suffice?\n- Why do you not use (a variant of) the notion of (shifting-)regret to analyse the non-stationary case? For this case (i.e., online learning), the (shifting-)regret is typically used as a success measure, since it captures the nature of the task better than the loss [3].\n\n**Detailed Comments:**\n\n- the paper uses a myriad of newly defined symbols which makes it very hard to follow the writing, if one hasn't learned the symbols by heart. The presentation could be greatly improved by reminding the reader what certain symbols stand for.\n- The K=1 case of FL is equivalent to simple distributed SGD, i.e., it can be considered to be a centralized SGD with larger batch size and smaller learning rate  [cf. Prop. 2 in 8]. For convex problems, this has been extensively studied [2]. How does the case in this paper differ?\n- Since the paper investigates convex problems, standard convergence results even for non-convex FL (where, e.g., it is shown that $||\\nabla L|| = 0$) imply that $w^* = w$. This includes, e.g., [4, 12, 14]. Please elaborate on the contribution beyond these works.\n- The problem of heterogeneous local data in FL and its impact on convergence has also been extensively studied [7, 11, 15]. Please elaborate on the contribution beyond these works, in particular to Lemma 3 in [6] which seems to be a generalization of the results in this paper for deep learning.\n- The results for the overparameterized case are not discussed wrt. benign overfitting for linear models [1]. The results of [1] should at least be discussed for the K=1 case, where FL boils down to distributed SGD. \n- model averaging for stationary and non-stationary models in convex environments have been studied extensively [9, 10, 13]. How do the results in this paper relate to this previous work?\n\n\n\n[1] Bartlett, Peter L., et al. \"Benign overfitting in linear regression.\" Proceedings of the National Academy of Sciences 117.48 (2020): 30063-30070.\\\n[2] Boyd, Stephen P., and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.\\\n[3] Cesa-Bianchi, Nicolo, and G\u00e1bor Lugosi. Prediction, learning, and games. Cambridge university press, 2006.\\\n[4] Charles, Zachary, and Jakub Kone\u010dn\u00fd. \"Convergence and accuracy trade-offs in federated learning and meta-learning.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2021.\\\n[5] Edgar Dobriban. Yue Sheng. \"Distributed linear regression by averaging.\" Ann. Statist. 49 (2) 918 - 943, April 2021. https://doi.org/10.1214/20-AOS1984\\\n[6] Huang, Baihe, et al. \"Fl-ntk: A neural tangent kernel-based framework for federated learning analysis.\" International Conference on Machine Learning. PMLR, 2021.\\\n[7] Li, Xiang, et al. \"On the convergence of fedavg on non-iid data.\" arXiv preprint arXiv:1907.02189 (2019).\\\n[8] Kamp, Michael, et al. \"Efficient decentralized deep learning by dynamic model averaging.\" Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018.\\\n[9] Kamp, Michael. Black-box parallelization for machine learning. Diss. Universit\u00e4ts-und Landesbibliothek Bonn, 2019.\\\n[10] Kamp, Michael, et al. \"Communication-efficient distributed online prediction by dynamic model synchronization.\" Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014.\\\n[11] Karimireddy, Sai Praneeth, et al. \"Scaffold: Stochastic controlled averaging for federated learning.\" International conference on machine learning. PMLR, 2020.\\\n[12] Koloskova, Anastasiia, Sebastian U. Stich, and Martin Jaggi. \"Sharper convergence guarantees for asynchronous sgd for distributed and federated learning.\" Advances in Neural Information Processing Systems 35 (2022): 17202-17215. \\\n[13] Mcdonald, Ryan, et al. \"Efficient large-scale distributed training of conditional maximum entropy models.\" Advances in neural information processing systems 22 (2009).\\\n[14] Yu, Hao, Sen Yang, and Shenghuo Zhu. \"Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. No. 01. 2019.\\\n[15] Yuan, Xiaotong, and Ping Li. \"On convergence of FedProx: Local dissimilarity invariant bounds, non-smoothness and beyond.\" Advances in Neural Information Processing Systems 35 (2022): 10752-10765."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "no ethics concerns."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8031/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698684165829,
        "cdate": 1698684165829,
        "tmdate": 1699636991343,
        "mdate": 1699636991343,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Ny2QrQMQuY",
        "forum": "d2YjPbSpDZ",
        "replyto": "d2YjPbSpDZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8031/Reviewer_ocpm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8031/Reviewer_ocpm"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the generalization error of the Federated Learning algorithm under a simple linear model and i.i.d. data. The results characterize the behavior of the generalization error in FL with respect to many factors, including the heterogeneity of the data, the number of local updates and communication, and by considering the model size, in under-parametrized and over-parametrized regime."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Very little is known about the theoretical understanding of generalization performance in FL. This paper is one of the first to address this issue. The authors provide several interesting insights into the generalizability of FL and study the effects of various parameters, such as the heterogeneity of the data, the number of local updates and communication, etc. Moreover, the authors provided the first explanation of the double-descent behavior in FL setup. The technical level of the paper also looks high, although I have not verified it carefully."
            },
            "weaknesses": {
                "value": "Despite its clear strengths, the paper suffers from several problems, which are listed below. I would increase my rating if the major concerns can be addressed, as the paper is among the few works that provides insight into the generalization performance of FL.\n\n1.\tThe model, i.e. the consideration of a linear model with i.i.d. Gaussian data, is very simple and unrealistic. However, as mentioned by the authors, this is now a commonly used model as a first step in understanding the theory.\n\n2.\tIn particular, there is an inherent alignment between empirical risk and generalization error in the considered setup. That is, they are somehow simultaneously minimized, which is in sharp contrast to most real-world scenarios. In fact, throughout the paper, the authors study \"model error,\" a quantity that one would also study for empirical risk. For this reason, I am not sure if the findings on generalization behavior using this setup can be extended or useful for realistic setups.\n\n\n3.\tIn addition, the authors stated that the model error can be shown to be equal to the expected test error for noise-free data. What happens if the data is not noise free? (I guess this is the interesting case, right?). How does the \"model error\" relate to the generalization performance in this case?\n\n4.\tContinuing the point 2, a good \u201cgeneralization bound\u201d typically decreases with the total number of used symbol (here, it would be $m\\times n \\times t$ at the end of iteration $t$, in the simple case). How does the provided bounds behave with these quantities?\n\n\n5.\tIt was observed and partially shown in previous papers (e.g. Gu et al. 2022 or arXiv:2306.05862) that the generalization error of the federated learning is smaller than that of centralized one (i.e. if we keep $m\\times n$ fixed). Do authors observe similar phenomena using these theoretic results?\n\n6.\tAll plots provide the numerical evaluation of the bounds on the model errors. It would be useful to plot the estimated model error as well as the estimated generalization error in the plots to observe how well the provided bounds capture the correct behavior of both the model error and the generalization error.\n\n7.\tSome relevant references are missing, e.g. arXiv:2306.03824 and arXiv:2306.05862.\n\n8.\tThe constants defined in equations (10) to (12) require some explanation and intuition. What is each term made of and what do they represent? In its current form, it's very hard to parse and understand. Similarly, theorem 1 is very hard to parse (except for the simple form of (14)). Similarly, for other theorems.\n\n9.\tTheorem 1 (and other results) suggest that increasing the learning rate $\\alpha$ increases the model error. While this behavior makes sense from an empirical risk point of view, it's often the opposite for generalization behavior: larger learning rates, at least in some cases and for the classical centralized setup, lead to better generalization performance.\n\n10.\tFurthermore, Theorem 1 suggests that more heterogeneity leads to higher generalization error. This is also counterintuitive to me. After all, this is exactly what I would expect for empirical risk, but I would expect the opposite for generalization. \n\n11.\tIf I'm not mistaken, equation (16) (and Proposition 1) is developed for the \"constant learning rate\" scenario. While for this scenario the existence of an optimal $K$ makes sense, I was wondering what would be the behavior with respect to $K$ for the carefully tuned decreasing learning rates?\n\n12.\tThe bound of Theorem 3 interestingly suggests a double descent phenomenon. However, the paper would greatly benefit from a numerical verification of this.\n\n\n13.\tIt is written that \"In Figure 3, we plot the model error against p...\". However, the caption of Figure 3 states that \"The curves are theoretical values from Theorem 3\". It is a bit confusing whether the exact \"model error\" is plotted or the established bound on it? It would be useful to plot both (as well as the generalization error).\n\n14.\tThe proofs are very long and technical, and it takes a lot of time to go through them. I think it would be helpful (and perhaps even necessary) to give a proof sketch in the main text, explaining the main steps, ideas, and tools used from the literature, and what the authors have added. In the current format, it is not clear what technical novelty the authors bring to this work.\n\n15.\tThe supplementary material (in particular Appendix A) may be more appropriately organized, with a table of contents to guide the reader to the various sections.\n\n16.\tIt would be good to summarize the provided insights in the contribution part of the introduction."
            },
            "questions": {
                "value": "Mentioned above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8031/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698756999439,
        "cdate": 1698756999439,
        "tmdate": 1699636991225,
        "mdate": 1699636991225,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wp8mocqjF7",
        "forum": "d2YjPbSpDZ",
        "replyto": "d2YjPbSpDZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8031/Reviewer_uk5o"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8031/Reviewer_uk5o"
        ],
        "content": {
            "summary": {
                "value": "This work investigates how data heterogeneity and the number of local update steps affects the performance of federated learning. The authors study the problem using a linear model with possibly time-varying ground truths. They quantify the $\\ell_2$-estimation error in three different regimes: $K=1, K<\\infty$, and $K=\\infty$, where $K$ denotes the number of local update steps. The results characterize the optimal choice of $K$ in some cases and validate the \u201cdouble descent\u201d phenomena when $K = \\infty$."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This work considers a very general setting where the ground truth parameter of each agent may vary with time.\n- This paper brings novel theoretical results of the effect of local update steps on federated learning. There is not much existing literature on this problem. \n- The results provide insights on the optimal choice of local update steps for FL.\n- The presentation is clear and well-organized, with plenty of discussion after each theoretical result."
            },
            "weaknesses": {
                "value": "- A major concern is the parameter defined by Equation (3). It does not seem like a suitable measurement for heterogeneity.  \n  Consider the case where $w_{(i), t} = w_{(j),t} = w^* + v$ with $\\Vert v \\Vert$ very large. In this case, all agents\u2019 ground truth are the same, *i.e.* the data are homogeneous. However, the *level of heterogeneity* is very large by the definition in the paper."
            },
            "questions": {
                "value": "**Major**  \nPlease see the Weaknesses section.\n\n**Minor**  \nIs there a reference for Equation (25)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8031/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8031/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8031/Reviewer_uk5o"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8031/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828312341,
        "cdate": 1698828312341,
        "tmdate": 1699661758124,
        "mdate": 1699661758124,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3HecNj3c5B",
        "forum": "d2YjPbSpDZ",
        "replyto": "d2YjPbSpDZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8031/Reviewer_Rcvy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8031/Reviewer_Rcvy"
        ],
        "content": {
            "summary": {
                "value": "This paper studies optimizing a distributed linear regression problem with local SGD. The aim is to capture the effect of data heterogeneity and provide upper bounds on the $L_2$ estimation error of the ground truth predictor shared across the clients. To do so, the paper considers three settings: $K=1$ (i.e., MB-SGD update on the average objective), $K<\\infty$ (i.e., vanilla local SGD), and $K=\\infty$ (i.e., convergence on each machine between communication rounds). The first two settings are considered with a single pass on the data, while the third setting converges to the ERM solution on the machine. Closed-form upper bounds are provided in each of these settings for both \n- **the online/non-stationary setting** (when the predictor on each machine changes across time); and \n- **the stationary setting** (when the predictor on each machine is fixed over time but is potentially different across the machines).  \n\nSeveral insights are drawn from these closed-form expressions in a more straightforward setting, where the shared solution concept across the machines is the average of the machines' model for that communication round."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper is clearly written, making it easy to follow the mathematical details. All the expressions are fully worked out and the proofs are also easy to verify."
            },
            "weaknesses": {
                "value": "The paper claims to be general enough to provide results for the non-stationary setting. However, it is unclear if measuring the distance from $w^\\star$ is useful in the non-stationary setting. In particular, it is never discussed what $w^\\star$ is and why the machines would want to recover it in a general setting, as opposed to minimizing regret with respect to a fixed best model in hindsight. Due to this reason, it seems that the simple setting for presenting results, where $w^\\star$ is the average optimum of different machines, is the only reasonable setting. As a result, the generality of the results in this paper is not very useful, without further motivation. \n\nThere are some issues even if we consider all the results in the simple setting. In the most challenging setting, that is, for a general $K<\\infty$, $\\bar{||\\gamma||}^2$ is conveniently assumed to be zero. This implies that all the machines have the same optimum as $w^\\star$. We already know the min-max optimal algorithms for quadratic functions in the homogeneous setting due to [Woodworth et al.](https://arxiv.org/abs/2002.07839). Thus, theorem 2 is not interesting. Similarly, Theorem 1 is not interesting as without any local update steps, there is no consensus error, and the update looks exactly like the mini-batch SGD update on the averaged objective across the machines. Resultwise, insights 1-3 are not interesting either. Finally, Theorem 3 is interesting but it is very easy to obtain using standard arithmetic. \n\nOverall, I do not believe this paper is novel enough, and adds to the existing theory of local update methods."
            },
            "questions": {
                "value": "- How are the step sizes tuned in all the experiments? In particular, in Figure 2, are step sizes tuned separately for each experiment? \n\n- (23) also has null risk, depending on the order of taking limits. For instance if $p\\to \\infty$ before $t\\to\\infty$, then there is a residual null risk. As a result, Insight 4 seems wrong. Figure 3 also seems to show this. What is the insight here then?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8031/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699508407086,
        "cdate": 1699508407086,
        "tmdate": 1699636990985,
        "mdate": 1699636990985,
        "license": "CC BY 4.0",
        "version": 2
    }
]