[
    {
        "id": "Du1rqrQHMN",
        "forum": "gXFoaqQgEI",
        "replyto": "gXFoaqQgEI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7056/Reviewer_hH1j"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7056/Reviewer_hH1j"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a dual-target point cloud registration model that combines multiple features learned from PointNet, DGCNN, and an attention module. The model aims to address the challenge of aligning partially visible point cloud data by introducing a new target point cloud obtained through rotation. The authors claim that their method achieves state-of-the-art performance compared to other learning-based methods on the ModelNet40 dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper proposes a new perspective on point cloud registration by incorporating a dual-target model and emphasizing the alignment of attitude.\n2. This paper combines multiple features learned from PointNet, DGCNN, and an attention module, allowing it to capture both global shape information and local geometric structures."
            },
            "weaknesses": {
                "value": "1. Lack of comparison with traditional methods.\nThis paper focuses on comparing the proposed method with other learning-based methods but does not provide a comparison with traditional point cloud registration algorithms [cite1-2].\n\n[cite1] Zhou Q Y, Park J, Koltun V. Fast global registration[C]//Computer Vision\u2013ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14. Springer International Publishing, 2016: 766-782.  \n[cite2] Yang H, Shi J, Carlone L. Teaser: Fast and certifiable point cloud registration[J]. IEEE Transactions on Robotics, 2020, 37(2): 314-333.\n\n\n2. Experimental results are not convincing. This paper only conducts experiments on the small-scale and synthetic datasets. However, point cloud registration methods focusing on large-scale and real-world datasets[cite3, cite4] are more meaningful.\n\n[cite3] Zeng A, Song S, Nie\u00dfner M, et al. 3dmatch: Learning local geometric descriptors from rgb-d reconstructions[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2017: 1802-1811.  \n[cite4] Shengyu Huang and et al., \u201cPredator: Registration of 3d point clouds with low overlap,\u201d in CVPR, 2021, pp. 4267\u20134276.\n\n3. Lack of ablation studies. This paper needs to do some ablation studies to validate the effectiveness of each component in the proposed method. For example, investigating the impact of different hyperparameters or variations of the model architecture."
            },
            "questions": {
                "value": "1. Please compare with the traditional point cloud registration method[cite1-2].\n\n2. Please conduct experiments on large-scale real-world datasets[cite3-4].\n\n3. Please conduct ablation studies to validate the effectiveness of each component."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7056/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697986300812,
        "cdate": 1697986300812,
        "tmdate": 1699636830324,
        "mdate": 1699636830324,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sQzF40wWXa",
        "forum": "gXFoaqQgEI",
        "replyto": "gXFoaqQgEI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7056/Reviewer_5tja"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7056/Reviewer_5tja"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a point cloud registration framework, in which a series of techniques are integrated. A coarse registration between the two point clouds is first performed, in which a second second target point cloud is generated to assist the initial registration. Then, in the fine registration step, overlap-estimation and mismatch filtering modules are designed to improve correspondences. Experiments are conducted on ModelNet 40 dataset."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The idea of generate a second target point cloud to assist registration is novel. The study of the relation between rotation and translation error is valuable."
            },
            "weaknesses": {
                "value": "1. The technical contribution is limited. The idea of generating a second target point cloud to assist registration is interesting but it is quite simple. Other techniques, such as overlap-ratio prediction and correspondence filtering have been widely used in this field, and specific comparison to similar components of the same purpose is needed to demonstrate the superiority of the designed models.\n\n2. Experiments are conducted on one synthetic dataset, ModelNet40, is far from being enough. The performance on real and challenging datasets are needed.\n\n3. There are some typos in the manuscript."
            },
            "questions": {
                "value": "1.At least, experiments on 3DMatch and 3DLoMatch are needed to demonstrate the applicability of the proposed method on real data.\n\n2.Is the generated target point cloud used in the fine registration after initialization?\n\n3.Can other baseline methods be used after the initialization step for fine registration? What would the results be? \n\n4.It\u2019s not clear how N_keep is used and why the partial point clouds are more realistic situation by using  N_keep. It is suggested to use the same way of generating experimental data if possible for easy and direct comparison with existing research. \n\n5.\u201calignment of attitude\u201d should be further explained since for easier understanding for it is not widely used in point cloud registration."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7056/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698679030430,
        "cdate": 1698679030430,
        "tmdate": 1699636830054,
        "mdate": 1699636830054,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4OGbLd13NT",
        "forum": "gXFoaqQgEI",
        "replyto": "gXFoaqQgEI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7056/Reviewer_XE5g"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7056/Reviewer_XE5g"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a dual-target model for point cloud registration, which combines features of PointNet and DGCNN. It first utilizes an initialization module for coarse registration, then uses a two-step attention-based representative overlapping-point selection module to determine the overlapping points. The experimental results demonstrate that the proposed method could perform well on ModelNet40."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. High performance is achieved on ModelNet40 dataset."
            },
            "weaknesses": {
                "value": "1. This paper lacks novelty. For example, the initialization module is very similar to ROPNet, combining high-level and low-level features is not new. For the two-step attention-based representative overlapping-point selection module, the inter-transformer module is the same as the attention module in DCP, the Point-Feature Augmentation module is used following ROPNet, and the two-step process for selecting the representative overlapping points is still followed ROPNet. The overlap prediction is not new for point cloud registration task, many works have been done on it, such as Predator[1], Cofinet[2], Geotransformer[3], PEAL[4] and so on. I do not identify any significant differences between this paper and these approaches. Therefore, I think that this paper is not sufficiently innovative enough to be accepted by ICLR. \n2. The paper is overall poorly written and it is a terrible reading experience. See Questions for specific issues. I think the writing of this paper needs a major improvement. \n3. The authors utilize a Res-PointNet module to concatenate the output of each convolution block in the MLPs, why the outputs of fourth convolution block are not used? Is this a decision based on empirical evidence? If yes, I think giving some experimental verification is necessary. \n4. The experimental results of this paper are only tested on ModelNet40. However, the widely adopted 3DMatch, 3DLoMatch and KITTI benchmarks should also be considered. I suggest that the authors should conduct more comprehensive and extensive experiments. So far, the performance of the proposed method is not convincing enough. \n5. The ablation studies about the AFMR module is not given. And what is AFMR module? Is it the Attention-based Mismatched-point Removal?  \n[1] Huang S, Gojcic Z, Usvyatsov M, et al. Predator: Registration of 3d point clouds with low overlap[C]//Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition. 2021: 4267-4276.  \n[2] Yu H, Li F, Saleh M, et al. Cofinet: Reliable coarse-to-fine correspondences for robust pointcloud registration[J]. Advances in Neural Information Processing Systems, 2021, 34: 23872-23884.  \n[3] Qin Z, Yu H, Wang C, et al. Geometric transformer for fast and robust point cloud registration[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2022: 11143-11152.  \n[4] Yu J, Ren L, Zhang Y, et al. PEAL: Prior-Embedded Explicit Attention Learning for Low-Overlap Point Cloud Registration[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 17702-17711."
            },
            "questions": {
                "value": "1. Confusing use of mathematical symbol. For example, the font formatting of cat(\u00b7) needs to be standardized. What is $F_{X^{\u2217}}$ and $F_{X^{\u2217}}^{g}$? What does the augmented feature $F_{m_{i}}^{L}$ means? And what is the $m_{i}$? \n2. The authors state that \u201cthe transformation to the newly added target point cloud is formulated as $X^{'} = X \u00b7 R_{1}$\u201d. What is the $X^{'}$? \n3. \u201cThrough this module, non-overlapping points will be removed and a new transformed source point cloud $X_{ro1}^{*}$ is obtained.\u201d How to remove the non-overlapping points? And how to obtain the new transformed source point cloud? \n4. What are the input and output of DGCNN?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7056/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7056/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7056/Reviewer_XE5g"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7056/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698719004862,
        "cdate": 1698719004862,
        "tmdate": 1699636829914,
        "mdate": 1699636829914,
        "license": "CC BY 4.0",
        "version": 2
    }
]