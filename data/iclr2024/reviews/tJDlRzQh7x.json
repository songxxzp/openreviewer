[
    {
        "id": "jJwnm0HUQk",
        "forum": "tJDlRzQh7x",
        "replyto": "tJDlRzQh7x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7375/Reviewer_YTUE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7375/Reviewer_YTUE"
        ],
        "content": {
            "summary": {
                "value": "- This paper investigates \"amortizing Solomonoff Prediction into a neural network\". \n- They then \"introduce a generalized Solomonoff prior\". \n- Lastly, they conduct experiments to show predictive performance on sequence prediction tasks, where they use meta learning with log-loss on a heterogeneous set of string related tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper draws connections between Solomonoff Prediction and meta learning.\n\nThe paper seems to have a formal grasp on some concepts in computational complexity that are useful formalism for describing tasks in machine learning, for example ranking them according to the Chomsky hierarchy (does the task require a stack to solve? or a more complicated data structure)"
            },
            "weaknesses": {
                "value": "Overall, the paper is hard for me to follow. In summary the issues are:\n\n- Many definitions given up front (up to beginning of page 4) are fairly non-standard, given the general body of work that shows up at ICLR. At the same time, the presentation features little discussion of definitions after they are given, with most details relegated to appendix. \n\n\n- Theorem statements in main text contain uncommon terms \"probability gap\" without definition. \n\n- Definitions that are given contain other undefined terms within definition, e.g.:\n  - An algorithmic data generating source \u00b5 is simply a computable data source by\" A \"data source\" was not defined.\n  - SI: Inductive inference aims to find a universally valid approximation to \u00b5. What's \"universally valid\"?\n\n- Propositions (e.g. prop 4, prop 8) are given and followed immediately  by a next section with no concluding sentence on what the takeaway should be or what the theorem means in words.\n\n- Many data details (e.g.\"Variable-order Markov Source\", one of the 3 experiments) are not defined in main text and details are relegated to appendix, and, as mentioned, are generally not particularly well known within the ICLR community.\n\n- Many baselines / models not defined in main text: Stack-RNNs, Tape-RNNs,  Context Tree Weighting, where the last one is used as the main baseline.\n\n- Important experimental details that are glossed over, e.g. there is a test distribution described as \"out-of-distribution\" in passing in the analysis of results without a formal experimental setup given for precisely what the shift between in- and out-distribution is.\n\n\nI will be glad to raise my score if a major rewrite of this paper is undertaken. In particular it must be readable to wider audience without having to refer to the appendix for interpretation of main contributions or for understanding basic setup like datasets and baselines. As mentioned in \"Questions\" below, it is also necessary to clarify whether the experimental results are something distinct from running basic meta-learning on existing datasets. If not, is the significance in the connection to the theoretical results? If so, what is that connection?"
            },
            "questions": {
                "value": "- It is stated that $\\pi_\\theta$  approximates the predictive distribution for each task $p(x_{t+1}|x_{\\leq t}, \\tau)$ for each task $\\tau$ . However $\\pi_\\theta(x_{\\leq t})$ is not notated to be a function of $\\tau$. If $\\pi_\\theta$ is optimized with log loss it will learn a mixture of the predictive distribution across tasks rather than each task, unless extra assumptions are stated, such as that the support of $x_{\\leq t}$ is disjoint across tasks for each $t$. Could the authors clarify  whether $\\pi_\\theta$ is also a function of $\\tau$, and if not, what are the assumptions on the data that make this statement true?\n\n\n- \"Out-of-distribution\" appears twice in the main text, including in the qualification of a test distribution. However, no particular definition of what is in versus out, or what the distribution shift is precisely, was given. A few sentences later, length-generalization is mentioned in passing, so I had to infer what in versus out meant. Usually it's really important to mention training versus test distribution details up front rather than in passing in the results. Could you please explain the precise experimental setup including data generation in more detail, in the main text?\n\n\n- Finally, experimentally, it's not clear that the experiments run were anything different than running log likelihood optimization on a mixture of datasets. What's the practical/algorithmic difference or significance in what was run, and what should the takeaways be? If there is no difference, is the significance in the connection to the theoretical results? If so, what is that connection?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7375/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698810089688,
        "cdate": 1698810089688,
        "tmdate": 1699636882219,
        "mdate": 1699636882219,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uIFe6ssSNe",
        "forum": "tJDlRzQh7x",
        "replyto": "tJDlRzQh7x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7375/Reviewer_iUvX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7375/Reviewer_iUvX"
        ],
        "content": {
            "summary": {
                "value": "In this work, authors theoretically investigate how universal approximators using a dataset converge to SP in some limit and show that universality is maintained even when underlined distribution shifts. They experiment with Transformers and LSTM NNs to show model complexity increases with increase in parameters, such that convergences can be seen on challenging dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well written\n2. Good set of experiments"
            },
            "weaknesses": {
                "value": "1. Novelty is limited\n2. Several key papers are not cited\n\nBelow, I provide my detailed review."
            },
            "questions": {
                "value": "It is true only for first-order RNNs that they are Turing complete with infinite precision and time, however, tensor RNNs with and without memory are shown to be equivalent to TM with finite precision [5,6] and also UTM\n\nLemma 10, Corollary 11, Lemma 12-14 [ 1-2] \u2013 Theorem 9 in paper shares some similarities, slightly different ways to prove the same property. \n\nTheorem 3 Linear separation [4] \u2013 the paper could benefit by showing how various layers in transformers cause linear separation using hard attention and would lie in Banach space dual. Again, with some assumption, it is trivial to show how their approach is also universal. \n\nGeneralized Solomononff semimeasures definition and Theorem 9 in the paper also share similarity with [3]; second majority of suggestions and claims are given in [3]. Furthermore they have shown some experiments and multiple hypothesis generation can be seen as a case of meta-learning. There are several lemmas on recursive functions, that can be extended with modern RNNs such as LSTM and even for Transformers (assuming within a finite length, they approximate RNN).\n\nAuthors should cite these line of work. Thus it seems the current manuscript is more incremental aligned with the experimental setup in the meta-learning space using modern NNs.\n\nFinally, it is hard for me to see what values the current method provides to the community; I will briefly discuss why I feel this,\n\n* theorem 11 in [7] proves that equivalence between two RNN is undecidable, Theorem 6 shows that consistency problem in RNN is also undecidable, Theorem 7 shows 2 layer RNN using BPTT on a finite corpus is necessary not consistent, furthermore Theorem 11 and 8 points out best string problem is NP-hard and in some cases undecidable. Given we know above properties for RNN, that is also true for transformers with some conditions, thus I am not sure Solomonoff induction would help in getting universal capability of the modern day NNs\n\n* Second RNN and transformers are turing complete comes from a unrealistic assumptions where entire tape is encoded into a tape. Based on bignum arithmetic we can see there is infinitely many hierarchies across various natural numbers, and works in infinite space. Therefore, what practical benefits it offers is still a open question.\n\n* Third when we move to UTM space and show RNN is equivalent to UTM will also work in infinite space and time\n\n* Fourth Solomonoff induction also requires infinite samples, given everything or in simple words all components are working in infinite space, how can one show practical universality? Nor can it be claimed that the model trained on the dataset is universal. So, I would advise authors to lower down the claim as it is highly misleading.\n\n\nIt would benefit if authors can provide insight how transformers and RNNs LM can benefit. For instance, by showing how they work when state space is small vs large, symbols are increased, model is trained on short strings and tested on longer. How do attention weights attend in such scenarios, how does LSTM memory adapt to these changes? Do you observe any tape-like or even stack-like behaviour etc. showing these analyses would further benefit the paper and will help understand how using SI can help LLMs reason about the world in some finite space. \n\n\n\n1.\tSterkenburg, T.F., 2017. A generalized characterization of algorithmic probability. Theory of Computing Systems, 61, pp.1337-1352.\n\n2.\tWood, I., Sunehag, P. and Hutter, M., 2013. (Non-) equivalence of universal priors. In Algorithmic Probability and Friends. Bayesian Prediction and Artificial Intelligence: Papers from the Ray Solomonoff 85th Memorial Conference, Melbourne, VIC, Australia, November 30\u2013December 2, 2011 (pp. 417-425). Springer Berlin Heidelberg.\n\n3.\tLi, M. and Vitanyi, P.M., 1992. Inductive reasoning and Kolmogorov complexity. Journal of Computer and System Sciences, 44(2), pp.343-384.\n\n4.\tSunehag, P. and Hutter, M., 2013. Principles of Solomonoff induction and AIXI. In Algorithmic Probability and Friends. Bayesian Prediction and Artificial Intelligence: Papers from the Ray Solomonoff 85th Memorial Conference, Melbourne, VIC, Australia, November 30\u2013December 2, 2011 (pp. 386-398). Springer Berlin Heidelberg.\n\n5.\tStogin, J., Mali, A. and Giles, C.L., 2020. A provably stable neural network Turing Machine. arXiv preprint arXiv:2006.03651.\n\n6.\tMali, A., Ororbia, A., Kifer, D. and Giles, L., 2023. On the Computational Complexity and Formal Hierarchy of Second Order Recurrent Neural Networks. arXiv preprint arXiv:2309.14691.\n\n7.\tChen, Y., Gilroy, S., Maletti, A., May, J. and Knight, K., 2017. Recurrent neural networks as weighted language recognizers. arXiv preprint arXiv:1711.05408."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7375/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699023219927,
        "cdate": 1699023219927,
        "tmdate": 1699636882071,
        "mdate": 1699636882071,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "O34rH4HpgL",
        "forum": "tJDlRzQh7x",
        "replyto": "tJDlRzQh7x",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7375/Reviewer_Mfzf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7375/Reviewer_Mfzf"
        ],
        "content": {
            "summary": {
                "value": "The authors explore approximate versions of Solmonoff induction via meta-learning and neural networks.  Their experimental setup compares the performance of a variety of deep neural network architectures within their framework on several algorithmically generated data sets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is clearly written and motivates the general problem.\n\nThe discussion, although it is primarily focused on Turing machines, is relevant broadly to themes in modern ML, e.g., large language models and other increasing large DNNs trained on massive data sets.  As a result, this work might help make connections between more classical AI and modern ML."
            },
            "weaknesses": {
                "value": "While the discussion is clear in many places, it also assumes quite a bit a background without references, e.g., \"Kolmogorov's probability axioms\".  As this is a submission to an ML conference, I suggest that the authors provide the necessary context to aid unfamiliar readers.  In the same vein, not many participants at ICLR are likely to be familiar with Solmonoff induction. So, the fit might be better at a more traditional AI venue -- the advances here are more from about using existing NN tools rather than pushing the state-of-the-art in deep NNs.\n\nThe experimental setup is missing some details, e.g., how many training examples are there?"
            },
            "questions": {
                "value": "- I don't really have good intuition about how varied the prediction tasks are.  Can you provide a bit more intuition here?\n\n- Like large language models, I expected that you would need a significant amount of data for training in this case.  Can you talk a bit more about data sizes, and why the results are or are not expected?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7375/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699419592082,
        "cdate": 1699419592082,
        "tmdate": 1699636881950,
        "mdate": 1699636881950,
        "license": "CC BY 4.0",
        "version": 2
    }
]