[
    {
        "id": "fZ2ApNIOTm",
        "forum": "Gk75gOjtQh",
        "replyto": "Gk75gOjtQh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL"
        ],
        "content": {
            "summary": {
                "value": "The work introduced a new reparameterization scheme for the training parameters of planar flows, effectively eliminating the initial singularity issues. This new approach ensures that the parameter $v$ does not escalate to infinity as $||w||$ approaches zero, potentially enhancing the stability during the training of Planar flow.  Empirical results demonstrate that the new parameterization scheme improves the performance of planar flows in variational inference applications."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This work delivers a concise and straightforward description of a well-defined problem, and the logic behind the proposed solution is easy to follow.\n\nThe solution itself, while simple, effectively addresses a known issue in planar flow, representing a practical contribution that the community is likely to find useful."
            },
            "weaknesses": {
                "value": "- The primary concern with this work lies in the significance of the problem it addresses.  While the problem focused in the paper is very well-defined (as mentioned in the Strength section), the importance of this problem is hard to justify for the following 2 reasons:\n1. Planar flow, the focus of this work, is one of the earliest methods introduced in the normalizing flow literature, and numerous advanced normalizing flows such as affine coupling flows, neural spline flows, etc., have been developed, showcasing superior performance.  Given this context, the contribution of this work appears quite limited.  To justify its contribution,  it would be imperative to demonstrate that the modifications introduced significantly enhance the performance of planar flow. Ideally, it should now be on par with, or outperform, the more recent flow methods. This point leads to the second concern.\n\n2. The empirical experiments conducted in the study lack a comprehensive comparison with a variety of recent flow methods. Moreover, the paper only delves into variational inference applications, omitting performance evaluations on density estimation and the quality of synthetic data generation. To solidify the work's standing and importance, an expansion of the experimental section to include these aspects is necessary.\n\n- Furthermore, this work falls short in providing a thorough and rigorous exploration of the singularity issue. The connection between the presence of a singularity and its detrimental impact on the performance of planar flow remains unclear to readers. The paper asserts that the proposed approach enhances the stability of model training, setting the expectation for a detailed analysis. \n\nTo meet this expectation, the paper should ideally include a comparative analysis of the gradient variance in planar flow, employing both the original and the new parameterization schemes. Additionally, a theoretical examination of the training dynamics in a deep planar flow setup would contribute to a more comprehensive understanding. The paper should also offer a conclusive answer to whether issues such as gradient explosion or vanishing are effectively circumvented with the proposed modifications. Without these elements, the paper's exploration of the singularity issue feels incomplete, leaving readers with unanswered questions and a lack of clarity on the significance of the proposed solution."
            },
            "questions": {
                "value": "no questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5682/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_ndCL",
                    "ICLR.cc/2024/Conference/Submission5682/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5682/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698279876459,
        "cdate": 1698279876459,
        "tmdate": 1700595050569,
        "mdate": 1700595050569,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YuhMagot7w",
        "forum": "Gk75gOjtQh",
        "replyto": "Gk75gOjtQh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5682/Reviewer_seL3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5682/Reviewer_seL3"
        ],
        "content": {
            "summary": {
                "value": "The authors proposed a new parameterization for planar flows that removes the singularity. Experiments on a range of problems validate the effectiveness of the proposed methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The observation of a singularity in the original parameterization of planar flows is new and important. The authors have done a nice job that motivates the new parameterization and the writing is clear."
            },
            "weaknesses": {
                "value": "1. No theoretically justification why the new parameterization that removes the singularity would makes the approximation better.\n\n2. The experiments are all in relatively low dimensional space (the VAE example uss a latent dimension D=20). It is not clear if the benefit of the proposed method would extend to higher dimension problems."
            },
            "questions": {
                "value": "1. It seems that SNF has similar issue in its parameterization. How did you implement it in your experiments?\n\n2. Figure 6 shows an interesting result. First, it is an unfair comparison between planar flows and IAF in terms of number of layers since each layer in IAF is more complicated and requires more parameters, and this makes the performance of planar flows even better. Second, it seems that the more powerful IAF does not do well in terms of posterior estimation in this case. Is it because the training is not long enough? Was the KL reported in the right plot the average over all test images? Can the author provide more direct posterior comparison (e.g., scatter plot of samples) to a ground truth MCMC run?\n\n3. It seems that the advantage of the new parameterization decreases as the number layers increase, any explanations? Also, for planar flows, a large number of layers are often used in practice which makes the benefit of new parameterization a bit less attractive."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5682/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698315332166,
        "cdate": 1698315332166,
        "tmdate": 1699636593407,
        "mdate": 1699636593407,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MnRQJvlahI",
        "forum": "Gk75gOjtQh",
        "replyto": "Gk75gOjtQh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5682/Reviewer_KdQZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5682/Reviewer_KdQZ"
        ],
        "content": {
            "summary": {
                "value": "This paper identifies a non-removable singularity in the original planar flow's parameterization, and proposes an new parameterization that removes this singularity and stabilizes the flow training. Empirically, they have shown this new parameterization leads to faster training and superior performance against the original parameterization on several synthetic experiments. In addition, they apply their new planar flow to VAE training on MNIST and find that the planar flow with the proposed parameterization achieves competitive performance against more advanced flow methods like IAF and SNF."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This method is simple and plausible. Despite its simplicity, the experiments in the paper do demonstrate the improved performance of the planar flow. Although it is not clear whether this method is comparable to the latest flow methods on density estimation, this method could be useful in certain variational inference problems where a simple flow model is needed.\n- The paper is well-written and easy to understand."
            },
            "weaknesses": {
                "value": "- The particular choice of the $m(\\cdot)$ function seems a bit arbitrary. As argued in the paper, all we need is $m(x) = \\mathcal{O}(x)$ when $x \\to 0$. There are many functions that satisfy this condition. To confirm that the issue of the original parameterization is indeed the singularity, the authors should pick a few other $m(\\cdot)$ functions satisfying $m(x) = \\mathcal{O}(x)$ and check if they share similar performance.\n- The idea is so simple that it is merely a parameterization trick. I am not sure if something similar has been done before. However, this may not be an actual weakness of this paper, as the reviewer is not particularly familiar with the literature on the planar flow.\n- One advantage of the planar flow in this paper is that its performance is comparable to the IAFs and SNFs but the planar flow has fewer parameters. One experiment to further strengthen this point is to compare the wall-clock running time of each flow."
            },
            "questions": {
                "value": "- Have the authors generated images from the trained VAEs on the MNIST as a sanity check?\n- Have the authors tried other function forms of $m(\\cdot)$ that satisfy the condition $m(x) = \\mathcal{O}(x)$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5682/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5682/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_KdQZ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5682/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698644102007,
        "cdate": 1698644102007,
        "tmdate": 1699636593309,
        "mdate": 1699636593309,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VSWP5I6mQW",
        "forum": "Gk75gOjtQh",
        "replyto": "Gk75gOjtQh",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5682/Reviewer_Z1xs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5682/Reviewer_Z1xs"
        ],
        "content": {
            "summary": {
                "value": "The authors consider the original formulation of normalizing flows parameterized by neural networks presented in the work by Rezende et al. They note that this parameterization has a deficiency (the function can become singular) that limits its expressivity/trainability. \n\nThey propose a patch to it and test it on standard benchmarks -- density estimation for challenging 2d densities, a Bayesian inference task, and the variational autoencoder formulation of the VI problem where an equivalent Evidence Lower Bound (ELBO) can be optimized."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I am a believer that a paper does not need to be groundbreaking to be a meaningful contribution to the literature. This paper does not try to be groundbreaking or to sell itself as such. It notes a deficiency in a foundational method, and patches that deficiency, and it justifies it with experiments. \n\nThose experiments are thorough -- and for once it seems like the comparison they make to other methods is reproducible (often papers will make numerical comparisons to other works, claiming such and such number is better than such and such other number, but the experimental conditions leading to those discrepancies in numbers is not clearly causally related to the proposed method). While the experiments are simple and low dimensional, this can actually be a nice feature for a paper to suggest that things are indeed reproducible in a reasonable sense."
            },
            "weaknesses": {
                "value": "The other perspective on the simplicity of the proposal is that it is not necessarily quite intellectually rich. I say this in the following sense - the related works points to many papers that choose different parameterizations for the coupling functions in normalizing flows. A pushback then is to say that changing a parameterization in the form they've done here is not that conceptually different from just proposing other transformations that don't have the original issue in the planar flows. The authors make a remark about the parameter efficiency of this method (which is true, it's a very simple function), but hopefully there'd be a bit more here.\n\nOf particular relevance is the Sylvester Flows paper, which presents itself as a generalization of the planar flows that this paper is addressing. \n\nSome related work that the authors should include:\n\n**Other works that lay the groundwork for flow-based variational inference in scientific computing:**\n- Boltzman Generators, *Frank No\u00e9, Simon Olsson, Jonas K\u00f6hler, Hao Wu*, 2019\n- Flow-based generative models for Markov chain Monte Carlo in lattice field theory, *Michaels S. Albergo, Gurtej Kanwar, Phiala E. Shanahan*, 2019."
            },
            "questions": {
                "value": "- Can the authors explain if their patch is relevant to the generalization of planar flows (Sylvester flows)?\n- Can the authors justify their claim of parameter efficiency by providing parameter counts and pushing e.g. the number of parameters in the neural networks in the neural spline flows down to their minimum to maintain performance? Splines are for example clearly more expressive, the question is just what is the minimal network size that makes them competitive with the proposal here. This doesn't seem like that hard of an experiment to run either, but of course I am sympathetic to the overhead of more experimentation. \n- Are there any higher dimensional experiments that the authors could run? The downside of low-d is it's hard to understand if the observations are generic or circumstantial."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5682/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5682/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5682/Reviewer_Z1xs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5682/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698857684283,
        "cdate": 1698857684283,
        "tmdate": 1700683854964,
        "mdate": 1700683854964,
        "license": "CC BY 4.0",
        "version": 2
    }
]