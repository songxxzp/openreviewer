[
    {
        "id": "VyEobgXm2s",
        "forum": "DmD1wboID9",
        "replyto": "DmD1wboID9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4365/Reviewer_wpkj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4365/Reviewer_wpkj"
        ],
        "content": {
            "summary": {
                "value": "Prompt-tuning is a fine-tuning paradigm based on large-scale pre-trained language models (PLMs), which can reduce the gap between downstream tasks and pre-training objectives. This paper focus on the challenge of poor generalization to specific few-shot patterns of the Prompt-tuning. Through distribution analysis, they reveal that the root cause of this issue is the overabundance of conceptual knowledge in PLMs and the truncated knowledge for target downstream domains. This collective effect misaligns the knowledge distributions corresponding to the target domains in the universal knowledge embedding space. To address this issue, they propose BayesPrompt, an approach that intuitively explores debiased approximation of unabridged target domains of downstream tasks. BayesPrompt generates domain-discriminative prompts to provide unambiguous guidance for PLMs. Further, they theoretically show that BayesPrompt tightens the upper bound of the classification error on PLMs' downstream inference on classification error bounds. The experimental results show that the proposed method achieves SOTA performance on benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe paper reveals the principles of the challenge of prompt-tuning on pre-trained large models for few-shot tasks.\n2.\tThe methodology of using the Bayesian prompt is novel and effective.\n3.\tThe theoretical guarantees the performance of the proposed method.\n4.\tThe evaluation presents the benefits of the proposed method."
            },
            "weaknesses": {
                "value": "1.\tThis paper utilizes the GMM to approximate the distribution of the target domain which may not be unabridged. The real distribution of the target domain is complex and unknown.\n2.\tThe PLMs utilized in the evaluation are not clear. Using various PLMs may be better to show the generality of the proposed method."
            },
            "questions": {
                "value": "1.\tWhy can GMM approximate the target domain? What are its benefits than a learnable generator (VAE or GAN)?\n2.\tIs it required to train a specific GMM for each input sentence (X, Y)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "no"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Reviewer_wpkj"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698497181215,
        "cdate": 1698497181215,
        "tmdate": 1699636408849,
        "mdate": 1699636408849,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JXKPMbV4ft",
        "forum": "DmD1wboID9",
        "replyto": "DmD1wboID9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4365/Reviewer_ox7r"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4365/Reviewer_ox7r"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes BayesPrompt, a Bayesian approach to approximate the factual distributions of downstream domains \nand thereby generating discriminative prompts for PLMs. The authors articulate that the intrinsic issues behind the poor performance of finetuned PLMs on few-shot downstream tasks roots from two main shortcomings: (i) over-multitudinous of conceptual knowledge contained in PLMs, (ii) an abridged knowledge for target downstream domains. The paper takes a stride in addressing this challenge with both theoretical (tailored towards a classification problem) as well as experimental results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is well written, well structured and has a clear narrative. \n- The authors pay utmost attention to details, from notations and math to presentation of the results, making the paper easy to follow.\n- The paper has a healthy mix of a (simplified) theoretical and qualitative arguments, based on which the approach is devised. \n- The results seem to be promising, comparing against some recent baselines. \nOverall, it seems like a solid contribution."
            },
            "weaknesses": {
                "value": "- The paper is essentially a shortened version of a much longer manuscript, where the authors are constantly cutting the content short and referring the reader to different sections of the appendix (appendix is referred to 11 times throughout the paper!). So, the main body of the paper is not really self-contained and heavily relies on the appendix. By the same token, the main algorithm of the paper had to be pushed to the Appendix, which could be a natural choice in the main text to clarify the end-to-end procedure. \n- The impact of the proposed approach is rather marginal when compared to the closest competitors (say RetrievalRE), especially on standard RE performance in Table 3, while at the same it comes at the cost of extra training complexity. Any reason behind this?  \n- No Ablation studies. There are design choices that could potentially establish the basis for Ablation studies (such as Kernel size and so)."
            },
            "questions": {
                "value": "No further questions (beyond what's already raised in weaknesses), and after reading through the Appendix."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Reviewer_ox7r"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777904048,
        "cdate": 1698777904048,
        "tmdate": 1699636408761,
        "mdate": 1699636408761,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KjsRhanczu",
        "forum": "DmD1wboID9",
        "replyto": "DmD1wboID9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4365/Reviewer_JjWU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4365/Reviewer_JjWU"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a prompting method named BayesPrompt to generate prompts for PLMs. The authors argue that the over-multitudinous knowledge implicit in PLMs can hinder the performance of prompt-tuning methods in few-shot settings. Thus, BayesPrompt aims to approximate the unbiased target distribution to generate discriminative prompt for specific domains.\nExperimental results show the effectiveness of BayesPrompt on relation extraction (RE) tasks. Also, the authors provide theoretical analysis over BayesPrompt on lowering the classification error upper bound."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The task that improves the generalization capabilities of PLMs is challenge in the prompt tuning community. The authors provide a new view from the \"mislocated knowledge distributions\" between PLMs and target domain, which is interesting. \n\n2) The motivation that adopts the Bayesian approaches to model dataset-specific information and performing prompting on the latent space is novel.\n\n3) The provided theoretical analyses and extensive experiments help readers to understand the method."
            },
            "weaknesses": {
                "value": "1) As can be seen from Tables 1 and 3, the proposed BayesPrompt presents a completely different improvement. Can the authors provide a detailed explanation?\n\n2) Please provide more discussion about the ablation results at Figure 4(c)."
            },
            "questions": {
                "value": "BayesPrompt's training complexity is higher than its baseline, is there any potential for optimization?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4365/Reviewer_JjWU"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826624941,
        "cdate": 1698826624941,
        "tmdate": 1699636408665,
        "mdate": 1699636408665,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1Mxd6Sfdlo",
        "forum": "DmD1wboID9",
        "replyto": "DmD1wboID9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4365/Reviewer_32zy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4365/Reviewer_32zy"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes BayesPrompt  to inject the semantic knowledge about the label into the label prompt to adjust the knowledge learned from pretraining to better fit downstream tasks. The method is to learn prompts that contain the domain discriminative information for the interference from the domain-irrelevant knowledge by approximating the factual distributions of downstream domains. The approach learns a representative model that injects the latent knowledge contained in labels into the prompt construction, thereby empowering the inference of relations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper works on a very interesting problem to adjust pretraining knowledge of LLM to downstream tasks. The paper provides theoretical analyses demonstrates that BayesPrompt can tighten\nthe upper bound of the classification error on the downstream inference of PLMs. Table 2 provide standard deviations over multiple runs."
            },
            "weaknesses": {
                "value": "The paper may benefit a lot from better writing, including more clear presentation of the motivation and methods. \n- what does author refer to for \"unabridged Domain\", \"partial domain\", in figure 2? \n\n\"Thee over-multitudinous conceptual knowledge contained in PLMs and the abridged knowledge for target downstream domains, which jointly result in that PLMs mis-locate the knowledge distributions corresponding to the target domains in the universal knowledge embedding space. \n\"\n- what does the author refer as \"over-multitudinous conceptual knowledge\" and \"the abridged knowledge \"?\n\nIt is not fully convinced to the reviewer that the problem motivates the method can be solved by the method proposed. \nIt is unclear that how by \"leveraging Gaussian mixture distribution BayesPrompt is able to approximate the debiased factual distributions of downstream domains and further uniformly samples certain representative features from the approximated distributions to generate the ultimate prompts for PLMs\". Why the proposed approach can better approximate the downstream tasks distribution? by injecting label -related information? What is the bias referred here? Is there any produces to reduce the bias? The author may refer the bias as \"irrelevant pretraining knowledge\" that is confounding for the downstream tasks ? not very clear why introducing \"Gaussian mixture distribution\" can help solve the problem? is it for sampling and easy injecting label-related knowledge? \n\nby injecting label dependent knowledge, the PLM may learn a PLM distribution that is useful for the downstream task, which makes sense. but is it unfair, as BayesPrompt already uses label information but other methods don't?\n \nIt is not very clear how Figure 2 motivates the paper.  Figure 1 (domain knowledge is helpful ) and Figure 2 (domain knowledge may lead to negative impact?) seem not to align well. \n\nMethod section: how does  label prompt word lp and type prompt word tp fit in eq(6)? Can the author also bring some clarify to training? \n \nWhy does the approach focus on relation extraction tasks (used in method section)? how about other tasks? Is this method currently specific for relation extraction tasks? \n\nTable 2: the improvement seems not to exceed one standard deviation over other baselines. The category of tasks seem limited. not very convinced on the effectiveness of the methods."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4365/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699331014627,
        "cdate": 1699331014627,
        "tmdate": 1699636408593,
        "mdate": 1699636408593,
        "license": "CC BY 4.0",
        "version": 2
    }
]