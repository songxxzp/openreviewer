[
    {
        "id": "BTBNUkSXpU",
        "forum": "Naiy1jf8UA",
        "replyto": "Naiy1jf8UA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6320/Reviewer_sKkf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6320/Reviewer_sKkf"
        ],
        "content": {
            "summary": {
                "value": "They introduce MGDC-UNet, a multi-group deformable convolution network for 3D volumetric medical image segmentation. Their MGDCUNet employs deformable convolution operators with learnable spatial offsets to improve attention on semantically important regions.\n\n\nThey use three challenging segmentation tasks using public datasets: \n\n1) brain tumor segmentation (BraTS21)\n\n 2)  CT multi-organ segmentation (FLARE21) \n\n 3)  cross-modality MR/CT segmentation (AMOS22)\n\nMGDC-UNet demonstrated superior performance accuracy in the three challenging segmentation tasks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Well organized and clearly written.\n\nThe effectiveness of proposed method has been well supported by experiments."
            },
            "weaknesses": {
                "value": "The did not mention the limitation of their method.\n\nThey did not add results of their model for small dataset like MRBrainS dataset and MICCAI iSEG dataset (minor issue)."
            },
            "questions": {
                "value": "could you change your title?  Because (This paper only uses the three datasets, and it cannot represent all medical image segmentation tasks.)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6320/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6320/Reviewer_sKkf",
                    "ICLR.cc/2024/Conference/Submission6320/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6320/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698888211522,
        "cdate": 1698888211522,
        "tmdate": 1700450290681,
        "mdate": 1700450290681,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0UaWN2N8OH",
        "forum": "Naiy1jf8UA",
        "replyto": "Naiy1jf8UA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6320/Reviewer_Ateq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6320/Reviewer_Ateq"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces MGDC-UNet, a method for 3D volumetric medical image segmentation that combines multi-group deformable convolution with transformer components. The goal is to address limitations in capturing complex spatial and semantic structures inherent in existing methods. MGDC-UNet employs deformable convolution operators with learnable spatial offsets, enhancing attention on semantically important regions. The approach leverages the stable spatial distribution across subjects to improve semantic learning.\n\nWhile MGDC-UNet demonstrates superior accuracy on three challenging segmentation tasks\u2014brain tumor segmentation (BraTS21), CT multi-organ segmentation (FLARE21), and cross-modality MR/CT segmentation (AMOS22)\u2014it does have some limitations. \n\nThe novelty of the multi-group deformable convolution might be somewhat constrained, as it's a widely used technique in segmentation. In Figure 1, the results suggest that the proposed method's performance is comparable to self-attention. Similarly, in Figure 3, the results indicate that MGDC-UNet may not significantly outperform previous methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "MGDC-UNet demonstrates superior accuracy on three challenging segmentation tasks."
            },
            "weaknesses": {
                "value": "The novelty of the multi-group deformable convolution might be somewhat constrained, as it's a widely used technique in segmentation. In Figure 1, the results suggest that the proposed method's performance is comparable to self-attention. Similarly, in Figure 3, the results indicate that MGDC-UNet may not significantly outperform previous methods."
            },
            "questions": {
                "value": "See comments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6320/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699499290303,
        "cdate": 1699499290303,
        "tmdate": 1699636695276,
        "mdate": 1699636695276,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xOQIjSZXLL",
        "forum": "Naiy1jf8UA",
        "replyto": "Naiy1jf8UA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6320/Reviewer_spqz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6320/Reviewer_spqz"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors introduced MGDC-UNet, a multi-group deformable convolution network for 3D volumetric medical image segmentation. MGDCUNet employs deformable convolution operators with learnable spatial offsets to improve attention on semantically important regions. Meanwhile, they leverage stable spatial distribution across subjects to enhance semantic learning. In addition, they also incorporate transformer components to augment feature learning and reduce inductive biases inherent in traditional CNNs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The network can adaptively adjust the offset of sampled locations, concentrating its attention on semantically relevant organ positions. Furthermore, the authors dynamically adjust offsets and modulation scalars to mitigate the inductive biases inherent in traditional CNNs, achieving transformer-like spatial aggregation. Also introduced MGDC blocks with a hybrid deformable convolution and multi-layer perceptron (MLP) structure for effective channel scaling and enhanced feature learning."
            },
            "weaknesses": {
                "value": "1. The originality of the algorithm's contribution remains ambiguous. Both deformable convolution and MLP are well-established application techniques, and while the authors have successfully combined them to achieve improved performance, their original contribution appears relatively modest.\n2. More experimental details should be provided to facilitate replication of the proposed method as well as a fair assessment of the performance of all comparison methods, e.g. batch size, learning rate, loss function, etc.\n3. The authors should have given more details about the data strategy, how the training dataset, validation set, and test set were divided, and how the optimal model was selected for performance comparison.\n4. The datasets utilized in the experiments of the paper all feature objects with clear boundaries that are easy to segment. Given the authors' claim that their method can better capture complex pathological features, for a more comprehensive evaluation of the algorithm's performance, it would be advisable for the authors to attempt performance assessment on datasets with complex pathological and morphological characteristics, such as retinal OCT image segmentation, for example the dataset of RETOUCH -The Retinal OCT Fluid Detection and Segmentation Benchmark and Challenge."
            },
            "questions": {
                "value": "1. The originality of the algorithm's contribution remains ambiguous. Both deformable convolution and MLP are well-established application techniques, and while the authors have successfully combined them to achieve improved performance, their original contribution appears relatively modest.\n2. More experimental details should be provided to facilitate replication of the proposed method as well as a fair assessment of the performance of all comparison methods, e.g. batch size, learning rate, loss function, etc.\n3. The authors should have given more details about the data strategy, how the training dataset, validation set, and test set were divided, and how the optimal model was selected for performance comparison.\n4. The datasets utilized in the experiments of the paper all feature objects with clear boundaries that are easy to segment. Given the authors' claim that their method can better capture complex pathological features, for a more comprehensive evaluation of the algorithm's performance, it would be advisable for the authors to attempt performance assessment on datasets with complex pathological and morphological characteristics, such as retinal OCT image segmentation, for example the dataset of RETOUCH -The Retinal OCT Fluid Detection and Segmentation Benchmark and Challenge."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6320/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699563358582,
        "cdate": 1699563358582,
        "tmdate": 1699636695155,
        "mdate": 1699636695155,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Oi9e5ZVQYo",
        "forum": "Naiy1jf8UA",
        "replyto": "Naiy1jf8UA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6320/Reviewer_kXxV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6320/Reviewer_kXxV"
        ],
        "content": {
            "summary": {
                "value": "MGCD-UNet is introduced in this paper as a multi-group deformable convolution network for 3D volumetric image segmentation. The network modifies UNet by using deformable convolution operators, learnable spatial offsets, and a transformer-like architecture. The aim of this work is to address the limitations in semantic learning, especially with long-term dependencies, attention to important areas, inductive biases, stability, and complexity. The method was tested on three segmentation datasets where it demonstrated superior performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper addresses a challenging problem in medical image segmentation, and it demonstrates improvement in the three tested datasets in terms of accuracy."
            },
            "weaknesses": {
                "value": "The novelty of the paper is very limited as the method is a combination of many widely used techniques. Specifically, on page 5, the authors claim to develop a new architecture that includes a reverse bottleneck; however, this design is just similar to the inverted residual block used in MobileNetV2 [1]. Also, the authors mention on page 2 that they have developed a deformable convolution approach for 3D volumetric images, however, 3D deformable convolution has been applied before for videos in [2]. Moreover, the authors claim on page 3 that their method is improving computational efficiency, however, the only component that seems to decrease complexity is the depth-wise convolution. Following that, many components are added such as linear layers, SoftMax, transformer components, and an extra loop over \u201cgroups\u201d which adds to the complexity of the network.  Tables 1 and 2 suggest that there is not much improvement in time and memory usage as other methods are comparable in performance (SegResNet inference time is 0.78 with memory usage of 3.3G while MGDC-UNET has inference time of 2.08 with 9.4G memory). \nTime and memory usage were not mentioned in Table 3 which is inconsistent with the previous tables. \nIn Figure 1, we can clearly see that self-attention is comparable to the proposed MGDC. Figure 3 suggests a very small improvement but not significant. Similarly, in Figures 4 and 5, the improvement does not seem significant. \nOn page 6, the authors claim that increasing kernel size from 3 to 7 causes enhancements, however, some results in Table 2 disprove this claim.\nThe title is too general and gives a sense that the method is tested on many image segmentation tasks to prove its applicability, however, the method is only tested on 3 datasets, and it is not generalizable. \n\nReferences:\n[1] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen.\nMobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference\non computer vision and pattern recognition, pages 4510\u20134520, 2018.\n\n[2] Xinyi Ying, Longguang Wang, Yingqian Wang, Weidong Sheng, Wei An, and Yulan Guo.\nDeformable 3d convolution for video super-resolution. IEEE Signal Processing Letters, 27:1500\u2013\n1504, 2020.4"
            },
            "questions": {
                "value": "Please refer to the above concerns."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6320/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6320/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6320/Reviewer_kXxV"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6320/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1700152341370,
        "cdate": 1700152341370,
        "tmdate": 1700615834721,
        "mdate": 1700615834721,
        "license": "CC BY 4.0",
        "version": 2
    }
]