[
    {
        "id": "NosUqB4aRy",
        "forum": "SBoRhRCzM3",
        "replyto": "SBoRhRCzM3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1597/Reviewer_yu29"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1597/Reviewer_yu29"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new LLM prompting strategy, Thought Propagation (TP), which generates analogies to the input problem, generates solutions to them, evaluates the solutions (using the LLM itself), and then uses the correct solutions either to directly solve the input problem, or to derive a high-level plan to solve the input problem. TP is evaluated against relevant baseline methods on three tasks:  shortest-path reasoning, creative writing, and planning in ALFWorld. The results show that TP consistently obtains higher scores than the baseline methods tested."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The surprising and potentially exciting finding is that this reasoning-through-generated-analogies helps solve the input problem even without ground-truth validation of the correctness of the solutions to the analogies. It's surprising because of the counterintuitive nature of the finding; one might have expected ToT to outperform TP since ToT spends its compute on the input problem rather than on analogies which are, by definition, somewhat different than the input problem.\n\nThe work deals with an important topic, is carefully motivated, and the results are analyzed in detail."
            },
            "weaknesses": {
                "value": "Since TP outperforms ToT by a surprising and counterintuitive amount, it is critical to compare the two methods in terms of token cost, which is a controllable quantity for both TP and ToT. The authors acknowledge the importance of comparing token cost in their discussion of Figure 5:  \u201c1-layer TP outperforms ToT by a large margin in different LLM backends but shares similar token expenses.\u201d However, this figure applies only to the shortest-path task, which is highly problematic for evaluating LLMs. The task is contrived in the sense that one would never actually use an LLM to solve a shortest-path task, and one would not expect much LLM training data to be relevant to solving such tasks. Even more importantly, the results of this evaluation are likely to depend very sensitively on the details of how the graph definition is represented in natural language for insertion into the prompt. Therefore one would expect that making subtly different choices in representation could make very large differences in performance, and some of those choices would just happen to favor certain prompt approaches (like TP) over others (like ToT). For these reasons, it seems hard to conclude much from the shortest-path experiments. Unfortunately, no token costs are provided for the other two experiments. This leads me to doubt the validity of the paper\u2019s central finding.\n\n**Post-Rebuttal Comments**\n\nI commend the authors for the extra experiments providing token-level comparisons between prompting techniques on the non-graph tasks. Other additional experiments explored different ways of encoding graphs, and TP maintained advantages over ToT. For these reasons, I am raising my evaluation from 5 to 6.\n\nI still question the relevance of the shortest-path experiments. In rebuttal, the authors argued that the shortest-path task is a good testbed for evaluating LLM reasoning for 3 reasons:\n- It is a challenging task, requiring many steps to solve over a variety of graphs.  \n- Some concurrent work has applied LLMs to graphs. \n- Generated graphs avoid data contamination.\n\nI agree that application of LLMs to graphs is an interesting line of investigation, where these 3 reasons make sense. But the goal of this work, as staked out in the title and abstract, is to compare different prompting techniques across a broader range of LLM applications. If the paper\u2019s claims were confined to the graph domain, the significance of the work would be greatly limited."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1597/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1597/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1597/Reviewer_yu29"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1597/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698803075350,
        "cdate": 1698803075350,
        "tmdate": 1700446834223,
        "mdate": 1700446834223,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "anKb2utvVY",
        "forum": "SBoRhRCzM3",
        "replyto": "SBoRhRCzM3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1597/Reviewer_39VY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1597/Reviewer_39VY"
        ],
        "content": {
            "summary": {
                "value": "This text introduces Thought Propagation (TP), an approach to enhance Large Language Models' (LLMs) reasoning abilities. TP leverages insights from solving analogous problems to improve complex reasoning. It prompts LLMs to propose and solve related analogous problems, reusing their solutions and problem-solving strategies. Experiments show that, TP outperforms existing methods such as Chain-of-Thought and Tree-of-Thought on three challenging tasks by large margins."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea that exploring analogous problems and leveraging the solutions to prompt the reasoning task of LLMs is interesting and with broad interests to the research and application of LLMs. The authors provide many analyses and examples to show the efficacy of the proposed thought propagation (TP), which are convicing.\n\n2. The method does not require to train the LLMs with sophisticated strategy or careful design of datasets in some previous works, but is a plug-and-play approach in inference, which is efficient and environment friendly, and can be generalize to various LLMs.\n\n3. The performance improvements are significant."
            },
            "weaknesses": {
                "value": "1. TP is training-free, but compared to train-of-thought, it requires more action steps to propose, solve, and aggregate analogous problems, which is more computationally-costly and complex.\n\n2. Some typos: in page 9, the last sentence of section 6, the quotation marks should be `` ''."
            },
            "questions": {
                "value": "1. Can we combine TP with CoT to achieve further performance improvements?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1597/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698835508948,
        "cdate": 1698835508948,
        "tmdate": 1699636088117,
        "mdate": 1699636088117,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QmJQ41SQjm",
        "forum": "SBoRhRCzM3",
        "replyto": "SBoRhRCzM3",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1597/Reviewer_VZuc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1597/Reviewer_VZuc"
        ],
        "content": {
            "summary": {
                "value": "Current prompt-based methods limit LLMs from using past knowledge, making complex tasks difficult. This work alleviates this issue and improving the reasoning performance of LLMs on complex problems with a novel Thought Propagation (TP) framework, which is rooted in the fundamental analogical reasoning ability of human cognition. Given an input problem, TP prompts LLMs to seek for its analogous problems. Then, it initializes the solutions to the input problem and its analogous counterparts with existing prompting methods such as standard prompt, CoT etc. Finally, TP instantiates analogical reasoning to update the initial solution to the input problem in two ways: 1. directly develops a refined solution to the input problems and 2. devise a knowledge-intensive plan to improve input problem solving. All these steps are automated with LLMs by prompting. Thus, TP teach LLMs to reason in an analogical way and achieves plug-and-play enhancement to current prompt methods without extensive labor in task-specific prompt engineering. Experiments on three challenging tasks validate the generality and significant performance gain of the proposed TP framework."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* Originality: This work introduces the novel TP framework to enhance LLMs' reasoning by reusing experience in solving similar problems. While previous research explored analogical reasoning on knowledge graphs, a generalized analogical reasoning framework for LLMs was missing until TP. It includes three automated modules: LLM Propose, LLM Solve, and LLM Aggregate, providing a plug-and-play advantage over existing \"reason-from-scratch\" methods. TP also extends the success of neighborhood propagation in Graph Neural Networks to analogical problem-solving, an innovative and non-trivial generalization, sparking new directions in LLM reasoning. \n\n* Clarity: This paper is overall well-structured and easy to follow. The general setup in the section of methodology helps readers to understand the proposed TP framework. Additionally, the detailed information on TP for task instantiation in the Experiment and Appendix sections facilitates implementation and reproducibility.\n\n* Evaluation: Extensive evaluation across three tasks demonstrates TP's substantial performance improvement compared to baseline methods across various LLM backbones.\n\n* Significance: TP's modular design exhibits impressive generality across various tasks. It has great chances to benefit researches in diverse directions."
            },
            "weaknesses": {
                "value": "Authors should enhance the related work section for a more thorough comparison.\n\n* The authors are encouraged to compare TP with Self-refined LLM reasoning methods [1,2] since TP also manages to refine the solution to the input problems in LLM Aggregation module.\n* In shortest path reasoning tasks, does TP sometimes deteriorate the solutions to some testing instances instead of improving them? \n\n[1] Self-Refine: Iterative Refinement with Self-Feedback.\n\n[2] Large Language Models Can Self-Improve."
            },
            "questions": {
                "value": "Please refer to weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1597/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699013803585,
        "cdate": 1699013803585,
        "tmdate": 1699636088023,
        "mdate": 1699636088023,
        "license": "CC BY 4.0",
        "version": 2
    }
]