[
    {
        "id": "kpFU4J4xCF",
        "forum": "g1oP6DjgFs",
        "replyto": "g1oP6DjgFs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4937/Reviewer_ovkC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4937/Reviewer_ovkC"
        ],
        "content": {
            "summary": {
                "value": "In this study, the authors address the challenge associated with generating pseudo samples from generators in the adversarial data-free knowledge distillation framework. They introduce the Noisy Layer Generation method (NAYER), an innovative approach that shifts the source of randomness from the input to a designated noisy layer. Instead of traditional inputs, the authors utilize label-text embedding (LTE), which encapsulates significant inter-class distinctions. This strategic incorporation of LTE enables learning high-quality samples faster. Simultaneously, the noisy layer augments sample diversity, ensuring that the model doesn't overly fixate on the label."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This research stands out as one of the first efforts in DFKD that harnesses a foundational model like CLIP.\n\n2. While current state-of-the-art DFKD methods are often time-intensive and require prolonged training periods for knowledge transfer, the authors convincingly demonstrate in Table 2 that they achieve a marked acceleration. This efficiency is attributed to their use of latent text embeddings, which encode nuanced interclass relationships, thereby enhancing the generation process by exploiting these relationships.\n\n\n3. Figure 3(d) highlights the generator's undue emphasis on labels within the Adversarial DFKD framework. This observation then drives the authors to inject randomness using noisy layers into the label-text embeddings sourced from CLIP, addressing the identified limitation.\n\n\n4. Notably, the authors present comparisons and results on expansive datasets like ImageNet, seldom seen in similar works.\n\n\n5. The 'Extended Results' section, located in the appendix, offers profound insights. It includes rigorous ablation studies, examining various language embeddings and their respective noise-embedding strategies."
            },
            "weaknesses": {
                "value": "Major Weaknesses:\n1. Clarity on Noisy Layers: The proposed method heavily relies on the noisy layers. However, in its present form, the manuscript does not elucidate the mathematical intricacies of the noisy layer, denoted as $Z$. The authors seem to present this layer as an opaque entity. It remains unclear whether the noisy layer employed is analogous to the one proposed by Fortunato et al. [1]. Given the rarity of noisy layer implementations in literature, the authors should elucidate its underpinnings, possibly drawing comparisons to prior work. The primary novelty appears to stem from the introduction of this noisy layer, and without deeper insight into its operations, the paper seems to lack substantial technical contributions.\n\n\n2. Ambiguities in Section 3.3: The closing remarks of Section 3.3, where the generation of MK synthetic images is broached, seem nebulous. A more comprehensive and systematic exposition of this segment would be beneficial. Furthermore, the authors' decision to employ BatchNorm with embeddings is not clearly justified. It would be insightful to understand the rationale and the potential implications of omitting this step.\n\n\n3. Memory Overhead Concerns: While the study commendable reduces student training time, there's no discussion on the potential increase in memory overheads that might be attributed to the introduction of noisy layers.\n\n\nMinor Weaknesses:\n1. Citation Misrepresentation in Section 3.1: The initial sentences of the second paragraph of Section 3.1 mistakenly attribute an adversarial mechanism to Nayak et al. (2019). In reality, Nayak and his collaborators proposed a strategy for generating class impressions from pretrained teachers, leveraging these for knowledge distillation.\n\nReference:\n\n[1] Fortunato, Meire, et al. \"Noisy networks for exploration.\" arXiv preprint arXiv:1706.10295 (2017)."
            },
            "questions": {
                "value": "See Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4937/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4937/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4937/Reviewer_ovkC"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4937/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698716216811,
        "cdate": 1698716216811,
        "tmdate": 1699636480032,
        "mdate": 1699636480032,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Cqmym1gbe6",
        "forum": "g1oP6DjgFs",
        "replyto": "g1oP6DjgFs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4937/Reviewer_m3cF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4937/Reviewer_m3cF"
        ],
        "content": {
            "summary": {
                "value": "This paper explores a more effective data-free knowledge distillation. The authors believe that the previous DFKD-based generation generated samples from random noises, so no very effective information was extracted. Therefore, in the paper, the authors introduce a novel Noisy Layer Generation method (NAYER) that relocates the randomness source from the input to a noisy layer and utilizes the meaningful label-text embedding (LTE) as the input. Based on this method, this work It can achieve high efficiency while ensuring the diversity of data generation. Extensive experiments illustrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The authors focus on the relationship between the diversity and efficiency of sample generation, which is important for DFKD.\n\n2. The code is released."
            },
            "weaknesses": {
                "value": "1. CLIP is introduced in this paper, and the training of CLIP requires a large amount of additional data. Other comparison methods do not seem to introduce additional data and only use teachers, which seems to be an unfair comparison. More explanation is needed here.\n\n2. Lack of comparison with sampling-based methods [1][2]. More importantly, there is also design about noise in DFND[1]. Although not exactly the same, it should warrant comparison and discussion.\n\n3. There is a lack of comparison with [3] in terms of generation efficiency. In addition, the distillation performance is not as good as [1][2].\n\n[1] Learning Student Networks in the Wild, CVPR 2021\n\n[2] Sampling to Distill: Knowledge Transfer from Open-World Data, arxiv 2023\n\n[3] Up to 100$\\times$ Faster Data-free Knowledge Distillation, AAAI 2022"
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4937/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4937/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4937/Reviewer_m3cF"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4937/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698915287890,
        "cdate": 1698915287890,
        "tmdate": 1699636479922,
        "mdate": 1699636479922,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "yenfPALZRV",
        "forum": "g1oP6DjgFs",
        "replyto": "g1oP6DjgFs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4937/Reviewer_Dv9s"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4937/Reviewer_Dv9s"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new method for data free KD method, Noisy Layer Generation (NAYER), which relocates the randomness source from the input to a noisy layer and utilizes the meaningful label-text embedding (LTE) as the input. LTE, generated by a pretrained text encoder, contains meaningful inter-class information, that enables the generation of high-quality samples with only a few training steps. LTE layer is initialized in each iteration for the diversity of generated images. Experiments suggest the proposed method outperforms other counterparts while being training faster too."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea of using pretrained text encoder to generate label-text embeddings as input for distillation is interesting and sounds novel to me.\n\n2. To achieve diverse generated samples (which is a key problem in DFKD), they propose a noisy layer between the input and the generator. The noisy layer is initialized in each iteration, which effectively introduces more diversity for the synthetic samples.\n\n3. The proposed method not only outperforms other DFKD approaches in terms of student performance but also is much faster in training."
            },
            "weaknesses": {
                "value": "1. Since this paper utilizes the pretrained text encoder in CLIP model, I think a similar idea for DFKD is to use pretrained text-to-image generation models, such as stable diffusion to generate pseudo data for distillation. It is advisable to add a set of comparison experiments to show the performance difference.\n\n2. What is the effect of reinitializing the noisy layer in each iteration? What if it is not reinitialized? This key ablation study is missing now.\n\n3. The presentation has some small issues to fix:\n\n3.1 The text in Fig. 4 is too small, hard to make out.\n\n3.2 Eq. (6) and (7) should have some punctuation. Make them in a sentence, not orphaned.\n\n3.3 Missing period in the caption of Fig. 5."
            },
            "questions": {
                "value": "How many images are stored in the memory module M in each epoch? Does this affect the performance significantly (any ablation study about it)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4937/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698983771909,
        "cdate": 1698983771909,
        "tmdate": 1699636479851,
        "mdate": 1699636479851,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "pEPcMhF9dU",
        "forum": "g1oP6DjgFs",
        "replyto": "g1oP6DjgFs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4937/Reviewer_axyR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4937/Reviewer_axyR"
        ],
        "content": {
            "summary": {
                "value": "Data-Free Knowledge Distillation (DFKD) has made significant strides in recent years, with its core principle of transferring knowledge from a teacher neural network to a student neural network without requiring access to the original data. However, existing approaches face a major challenge when attempting to generate samples from random noise inputs, which lack meaningful information. As a result, these models struggle to effectively map this noise to the ground-truth sample distribution, leading to low-quality data and substantial time requirements for training the generator.\n\nTo address this issue, this paper proposes al Noisy Layer Generation method (NAYER) that relocates the randomness source from the input to a noisy layer and utilizes the meaningful label-text embedding (LTE) as the input. The significance of LTE lies in its ability to contain substantial meaningful inter-class information, enabling the generation of high-quality samples with only a few training steps. Simultaneously, the noisy layer plays a key role in addressing the issue of diversity in sample generation by preventing the model from overemphasizing the constrained label information. By reinitializing the noisy layer in each iteration, this work aims to facilitate the generation of diverse samples while still retaining the method\u2019s efficiency."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper introduces a DFKD method called Noisy LAYER Generation (NAYER) that relocates the source of randomness from the input to the noisy layer and utilizes label-text embedding (LTE) as the input. Using LTE as input allows for proficient generation of high-quality samples that closely mimic the distributions of their respective classes with only a few training steps. \n- Extensive evaluation is presented on standard benchmark datasets like CIFAR10, CIFAR100, TinyImageNet, and ImageNet. It achieves superior performance against the prior arts."
            },
            "weaknesses": {
                "value": "1) In the introduction section, paragraphs 4 and 5 seem disconnected from the rest of the introduction and disrupt the flow of reading. There are seveal references to different figures and experimental results that are presented in other pages and also in supplementary. This disturbs the flow of reading. The authors should rewrite these paragraphs in a way that simplifies the key ideas, potentially using examples to make them more accessible to a broader audience. It's important for the introduction to provide a smooth and coherent overview of the paper's content to engage a wider audience.\n\n2) The paper proposes the use of label-text embedding (LTE), which may have a disadvantage compared to other methods that do not rely on such embedding. For example, in cases like classifying chemical compounds, where label-text embedding, like CLIP, may not be applicable. Other data-free knowledge distillation methods do not rely on such joint image-text embedding knowledge thus they world perform reasonably well for a wide variety of classification modalities (such as audio, chemical-compund, etc.). Highlighting the limitations of the proposed approach is essential for a balanced evaluation of its potential use cases.\n\n3) The paper uses label-text embedding (LTE) obtained from a pre-trained model CLIP that is trained on image-text pairs from the internet. Drawing a comparison to CLIP, which also has knowledge of common objects and corresponding text, suggests that the proposed method is not entirely data-free. This raises doubts about whether it can be truly considered \"data-free\" distillation.\n\n4) Limited novely: The proposed approach builds upon CLIP embedding for data-free knowledge distillation but offers limited innovation. Section 3.1 appears to reiterate the existing Data-free knowledge distillation framework without introducing fresh perspectives or insights beyond what has been discussed in prior works. Further, the use of label-text embedding followed by a randomly initialized layer makes the generator resemble a conditional GAN. There are various alternative ways to achieve the desired setup, such as: a) employing a conditional GAN where a noise vector-based embedding and an LTE-based embedding are concatenated to form the initial part of the generator network, b) using an equation like e + beta*(z~ N(0, I)) to model intra-class diversity and span the embedding space between classwise LTE embeddings, or c) exploring some form of linear combination of LTE embedding with specialized weight sampling. The inclusion of the proposed Noise Layer appears unnecessary and lacks clear justification."
            },
            "questions": {
                "value": "Please see the Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4937/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699599028599,
        "cdate": 1699599028599,
        "tmdate": 1699636479751,
        "mdate": 1699636479751,
        "license": "CC BY 4.0",
        "version": 2
    }
]