[
    {
        "id": "jvdzl5B5LN",
        "forum": "XXpH3D0TVP",
        "replyto": "XXpH3D0TVP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6016/Reviewer_ujFU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6016/Reviewer_ujFU"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a framework for data attribution in diffusion models to attribute generated images back to the training data, allowing for identification of influential training examples. The framework attributes each step of the diffusion process, providing targeted attributions for specific features of the final generated image. The paper introduces metrics for evaluating the attributions and presents a method for computing them."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Strengths:\n1) The paper clearly conveys the significance of data attribution in diffusion models, the theoretical validation of the framework, and the development of metrics for evaluating attributions.\n2) The paper also demonstrates the practical applicability of the framework through experiments on real datasets.\n3) Detailed implementation settings and code are provided, which makes for easy reproducing the study."
            },
            "weaknesses": {
                "value": "Weaknesses:\n1) The structure of the paper is a bit confusing and not easy to follow.\n2) The paper formulated a novel research problem, but the proposed method appears to be relatively primitive compared to the complexity of the problem at hand."
            },
            "questions": {
                "value": "Please refer to the weakness part. Further, the fine-grained analysis in section C.2 is intriguing. It appears that the model has a tendency to generate images by referencing specific semantic parts of the training images rather than generating the entire images. Therefore, does it still make sense to attribute these generated images to image-level data?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6016/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6016/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6016/Reviewer_ujFU"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6016/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698217593182,
        "cdate": 1698217593182,
        "tmdate": 1699636645973,
        "mdate": 1699636645973,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "djvJfJIYt8",
        "forum": "XXpH3D0TVP",
        "replyto": "XXpH3D0TVP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6016/Reviewer_XavF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6016/Reviewer_XavF"
        ],
        "content": {
            "summary": {
                "value": "In this work, authors introduce an extension of the Trek method that provides data attribution measurement to the family of diffusion methods. The goal of the analysis is to show that with the proposed methodology we can attribute which training images (and how) influenced the final generation. The evaluation is performed on CIFAR10 and MS COCO dataset with DDPMs and latent diffusion models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This submission tackles an interesting and important problem that to my knowledge was not yet approached in the context of diffusion models\n- The proposed method is a direct application of the Trek method to diffusion models. However, this extension is non-trivial and might have significant impact on some areas of research such as machine unlearning.\n- The evaluation is performed on a big scale (although it is mostly presented in the appendices)"
            },
            "weaknesses": {
                "value": "-In general, there is a significant mismatch between the goal of the method as expressed at the beginning of the submission and the final experiments being evaluated. This is due to a series of approximations that make the computation possible. The interesting question is how those approximations influence the final observations (e.g. using one-step approximation of $\\hat{x}_0^t$ as an approximation of the distribution\u2019s expectation $E[x_0|x_t]$). If I understand it correctly, this assumption indicates that there would be no change in the final distribution due to later diffusion steps. For some cases with higher t values (e.g. timesteps>600 in Figure 3) this approximation might be wrong.\n- \u201cHowever, the effect of a single time step on the final distribution may be small and hard to quantify. Hence, we assume that attributions change gradually over time and replace the denoising model for a small interval of time steps (i.e., between steps t and t \u2212 \u0394).\u201d - This assumption is counterintuitive to the previous derivations on what authors consider attributions for diffusion models in their framework.\n- The submission is hard to follow without in-depth understanding of the Trak method (Perk et al. 2023) it is heavily based on. It is also almost impossible to understand the experiments without reading the appendix.\n- The presentation of the submission seems ad hoc and sloppy. There are multiple different thoughts that lack cohesion. For example Figure 4 appears on page 5 without any connection to the text, while it is referred to on page 8.\n- The provided code in its current form is far from being useful for the full reproduction of the results presented in this work. It is a total of ~200 useful lines of code (excluding imports and  comments) with some definitions of functions that should be connected to something in an unclear way.\n- The submission does not follow ICLR guidelines - the margins are significantly smaller (1 in instead of required 1.5) and the font is different."
            },
            "questions": {
                "value": "- Are the CIFAR10 models evaluated in this submission conditioned on the class identity? Otherwise, how for example the plot in Fig 3 (left) calculated - using only 15 examples presented on the right?\n- \u201cThus, if we treat this likelihood as a function of t, the steps at which there is the largest increase in likelihood (i.e., the steepest slope) are most responsible for the presence of this feature in the final image. In fact, it turns out that this likelihood often increases rapidly\u201d -  The example presented in Fig 3 is rather extreme. Do you have any intuition why it is so?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Other reasons (please specify below)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "The submission does not follow ICLR guidelines - the margins are significantly smaller (1 in instead of required 1.5) and the font is different."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6016/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698758932600,
        "cdate": 1698758932600,
        "tmdate": 1699636645828,
        "mdate": 1699636645828,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WoI3eplfK2",
        "forum": "XXpH3D0TVP",
        "replyto": "XXpH3D0TVP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6016/Reviewer_KmFt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6016/Reviewer_KmFt"
        ],
        "content": {
            "summary": {
                "value": "This work focuses on attribution for diffusion models, i.e. understanding how the underlying training data influences the generation of a sample. This work proposes an approach based on TRAK [1] to attribute a single denoising step back to the training data. The work also proposes metrics based on counterfactual estimation to evaluate attribution approaches and shows comparisons against simple baselines on multiple datasets (CIFAR-10 and MS-COCO).  \n\n[1] Park, Sung Min, et al. \"Trak: Attributing model behavior at scale.\"\u00a0_arXiv preprint arXiv:2303.14186_\u00a0(2023)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The work focuses on an important and timely problem. Attribution for models is an important technical problem to address as generative models become more ubiquitous. This has implications for regulation, copyright, and fair compensation to artists [1].\n2. The proposed solution is reasonably motivated and builds on prior work that achieves SOTA attribution results for discriminative models. The work also compares against reasonable baselines for data attribution and shows results across two different datasets namely CIFAR-10 and MS COCO.\n3. The proposed attribution results look reasonable and are quantitatively supported well via counterfactual evaluation.  Evaluation for attribution approaches is difficult since there exists no ground truth label. The counterfactual evaluation metrics proposed in this paper (inspired via TRAK [2] and DataModels [3]) will be useful for future research.\n4. The writing quality of the paper is good. It was easy to follow the main contributions of the paper and understand the background of data attribution.\n\n[1] https://www.klgates.com/Recent-Trends-in-Generative-Artificial-Intelligence-Litigation-in-the-United-States-9-5-2023 \n[2] Park, Sung Min, et al. \"Trak: Attributing model behavior at scale.\"\u00a0_arXiv preprint arXiv:2303.14186_\u00a0(2023).\n[3] Ilyas, Andrew, et al. \"Datamodels: Predicting predictions from training data.\"\u00a0_arXiv preprint arXiv:2202.00622_\u00a0(2022)."
            },
            "weaknesses": {
                "value": "1. A limitation of the proposed approach is the fact that attribution scores are only provided for a single denoising step. This is unintuitive, as it requires multiple steps to be analyzed to understand how an image was generated. It would be good to obtain a single-shot attribution score for the entire diffusion trajectory. While simple heuristics can be employed to obtain this from the current approach, it's unclear if these are useful and interpretable.\n\n2. There is little analysis regarding how attributions change throughout the diffusion trajectory. It would be interesting to analyze more how ranking b/w attributions stay consistent b/w different timesteps. For example, what's the correlation coefficient b/w attributions of two timesteps close to each other v/s further away? How many of the +ve influence samples in the initial/middle timesteps stay positive throughout the diffusion trajectory?\n\n3. The claim regarding conditioning likelihood increasing in small time intervals is a bit weak (i.e. features appear in specific timesteps). This should be more rigorously studied for multiple generated images on CIFAR-10 and MS-COCO. \n\nMinor - \n1. The font, and margins of this submission violate ICLR guidelines. This should be corrected in the next version of the paper."
            },
            "questions": {
                "value": "1. This is merely a suggestion and could help strengthen the paper. It would be interesting to compare attributions using a similar framework as [1] by fine-tuning large text-to-image models such as Stable Diffusion on a few images using a dreambooth-like approach. In this case, the attributions should have a higher +ve influence on the fine-tuning dataset. This can be done even for a small random subset of LAION images, instead of the entire dataset.  This can also be done for text-conditioned models on MS-COCO.\n\n2. Several important details are missing regarding the attribution approach. TRAK uses a random projection matrix to compress gradients to low dimensional space, the dimension hasn't been mentioned at all. Is this random projection step not done for attributing diffusion models? Are multiple checkpoints used to estimate attribution scores? Are these trained on different subsets of training data? How much storage and compute is required for estimating the attribution scores? \n\n[1] Wang, Sheng-Yu, et al. \"Evaluating Data Attribution for Text-to-Image Models.\" arXiv preprint arXiv:2306.09345 (2023)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6016/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6016/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6016/Reviewer_KmFt"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6016/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698808644170,
        "cdate": 1698808644170,
        "tmdate": 1699636645687,
        "mdate": 1699636645687,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "p8WQshVRZx",
        "forum": "XXpH3D0TVP",
        "replyto": "XXpH3D0TVP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6016/Reviewer_Kccm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6016/Reviewer_Kccm"
        ],
        "content": {
            "summary": {
                "value": "This work attempts to explain the effect of training data points and their features on the synthesized images in a diffusion model. They suggest a framework to first define the notion of attribution for diffusion models and then study the validity of the attributions. The method is tested on two dataset along side two diffusion models (DDPM and LDM)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The choice of problem is a point of strength in this work. To understand the role of the training data in the final sampling result sheds light on the nature of the learned distribution and its properties. Also this question is tightly related to memorization and interpolation of training data which has practical implications such as data privacy."
            },
            "weaknesses": {
                "value": "The clarity of the writing can be significantly improved. The flow can be more streighforward. At its current form, the paper is too wordy to the extent that the main points are not clearly conveyed. \n\nRelying on a classifier to find emergence of features that are important throughout the diffusion trajectory is problematic. The sharp increase in classification performance under Fig3 might be due to this particular classifier and dataset. For example, for a more nuanced dataset with images with more details, and more categories, the improvement in classification could become more gradual, due to the gradual appearance of large to fine features. \n\nThe results presented under figure 5 although show a significant effect on FID, it is not obvious what the effect shows and how it can be used. What is the relationship between the top k important training examples which are removed and the learned distribution or synthesis? How do we ensure that the increase in FID is not simply the effect of training on a smaller dataset? \n\nIn general, it is not clear to me what we learn from this result. The attribution qualitative results under fig 6 seem to me anecdotal. The results in Fig 7 are too low quality, so it is not easy to judge the effectiveness of the method."
            },
            "questions": {
                "value": "In order to reduce the cost of generating a distribution of generated conditional samples from $p(.|x_t)$, the conditional sampling is approximated with a one step denoising. We know that if the noise level is high (for larger values of t) the difference between iterative and single step denoising is significant. How is this approximation justified for the large sigma?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6016/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826808302,
        "cdate": 1698826808302,
        "tmdate": 1699636645577,
        "mdate": 1699636645577,
        "license": "CC BY 4.0",
        "version": 2
    }
]