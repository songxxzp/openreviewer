[
    {
        "id": "lzcfpM4cIp",
        "forum": "PYdk0V880P",
        "replyto": "PYdk0V880P",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2379/Reviewer_6Yvs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2379/Reviewer_6Yvs"
        ],
        "content": {
            "summary": {
                "value": "Neural Architecture Search (NAS) automates DNN architecture design. Existing training-free NAS methods aim to reduce search costs but often rely on training error, not generalization error. We propose NAS-NGE, using bias-variance decomposition of the normalized generalization error, outperforming SOTA training-free NAS in short search times with NAS Benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is readable and well-written. It demonstrates a clear sense of purpose, emphasizing the importance of focusing on generalization performance rather than training performance when conducting NTK-based NAS. The paper then provides a mathematical framework for this approach and demonstrates it effectively. The overall structure, from the statement of purpose to the specific approach, is well organized. The experiments also report that the proposed approach often outperforms existing methods."
            },
            "weaknesses": {
                "value": "I'm not sure about the significance of the contribution. Although the experimental results appear promising, the derivation of the bias-variance decomposition and its associated equations (Eq. 3 and Eq. 4) seems relatively straightforward, which could imply that the contribution is somewhat incremental to previous works. If the novelty of what you're doing can be highlighted even more, I believe it has the potential. \n\nI believe it's important to carefully explain how much the behavior of models trained outside the NTK-regime can be accounted for by theoretical analysis using NTK, as unrealistic settings like lazy training are implicitly imposed. Currently, only the performance of NAS is reported, but a more direct analysis would increase the level of confidence. Specific points are listed in the \"Questions\" section."
            },
            "questions": {
                "value": "1: I believe that NAS-Bench stores performance at multiple checkpoint epochs (e.g., 4, 12, 36, 108 epochs). In this paper, empirical evaluation is conducted with the shortest training time, both for NAS-Bench-101 and NAS-Bench-201. Do you think that extending these checkpoint epochs significantly impacts the results? Do you have results under such settings? Since NTK theory assumes that NTK does not change during training, I imagine that as training epochs increase, it may deviate somewhat from the theory of infinite width. I'm interested in understanding this deviation. If possible, demonstrating its superiority based on differences in trends on epochs compared to other methods using NTKs could potentially strengthen the paper.\n\n2: Like the TE-NAS paper (Chen et al. (2021)), can you visualize a scatter plot of the current metrics against the actual generalization performance? This might be a more direct way to validate the effectiveness compared to conducting NAS."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2379/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2379/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2379/Reviewer_6Yvs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2379/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697689355802,
        "cdate": 1697689355802,
        "tmdate": 1699636172646,
        "mdate": 1699636172646,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "nHsyAQGVeJ",
        "forum": "PYdk0V880P",
        "replyto": "PYdk0V880P",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2379/Reviewer_vdk2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2379/Reviewer_vdk2"
        ],
        "content": {
            "summary": {
                "value": "The paper concerns train-free Neural Architecture Search (NAS). This concerns the task of automatically determining the architecture for a prescribed task, i.e. image classification in this case. In this paper, a core stated motivation concerns devising a NAS method with theoretical guarantees based on the generalization error. The bias-variance decomposition analysis of the normalized generalization error is used for NAS. Concretely, they use the (normalized) 2nd order moment of the NTK along with the normalized bias. The standard benchmark of Nasbench-201 is used for the comparison."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Automatically designing architectures is an important task and currently it is very costly. The train-free methods that can indeed reduce the cost of search have yet to demonstrate the capacity of DARTS or more recent models. At the same time, theoretical understanding of architectures and their inductive bias is important, therefore I do consider that the broader area is important and relevant for the ICLR audience. The analysis of the moments of NTK conducted in this work is something I have not seen before. Having said that, I am not sure of the precise conditions that this analysis holds."
            },
            "weaknesses": {
                "value": "- A strong motivation is built upon the premise that generalization guarantees are missing in train-free NAS. However, the papers Generalization guarantees for neural architecture search with train-validation split (ICML'21), Generalization Properties of NAS under Activation and Skip Connection Search (NeurIPS\u201922) are precisely providing generalization guarantees for different cases. Given those papers, I believe one of the core motivations is less clear to me. Could the authors elaborate on the differences from those? \n\n- The experimental validation seems rather weak, using the dated nas-bench-201 as the main comparison platform. If the method scales so well in terms of time, why not use benchmarks with larger search space?\n\n- The paper skips many important details and intuitions that make it quite hard to understand. For instance, why is the second-order moment used in the analysis and why is the NTK assumed here?"
            },
            "questions": {
                "value": "- It seems the reported accuracies in this work are lower than existing standard networks, e.g. ResNets. Even if we do not account for those cases, the aforementioned Neurips\u201922 paper on the same benchmark reports results closer to standard accuracies on cifar10/100. Could the authors elaborate on those discrepancies? \n\n- Given that one of the main claims is built around the generalization error, I would expect to see how the proposed model extends beyond the test data of the dataset, which is one of the critical points in NAS overall. \n\n- One of the messages repeatedly relayed throughout the manuscript is the speed of the proposed method. However, I find that the reporting of \u201cabout 10 sec.\u201d to be quite rough; could the authors conduct a refined analysis on this? \n\n- Continuing on the aforementioned point, does the reported time include the time to compute the NTK of each architecture? \n\n- In condition 3.2 it mentions the NTK, however the papers cited mostly focus on Relu-nets, so are there any additional conditions that should hold for the neural network in order for this analysis to hold? \n\n- One of the sentences in the first paragraph of the introduction claims that \u201cArchitectures found in NAS are even surpassing the performance of manually designed architectures\u201d. Is there a reference for this? How does the proposed method perform in imagenet that is the standard benchmark in image classification?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2379/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697735067754,
        "cdate": 1697735067754,
        "tmdate": 1699636171989,
        "mdate": 1699636171989,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "OxaAydHnOw",
        "forum": "PYdk0V880P",
        "replyto": "PYdk0V880P",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2379/Reviewer_C4Cd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2379/Reviewer_C4Cd"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed a novel surrogate of the generalization error of neural networks for training-free Neural Architecture Search(NAS). By normalize the estimation of generalization error on different data samples and random initialization, proposed NAS-NGE outperform the other training-free pruning based NAS methods on NAS-Bench-1Shot1, and NAS-Bench-201."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors analyzed the output of the model by decomposing it into bias and variance. As far as I know, this approach is new and novel.\nIn particular, the authors' method of normalizing the variation in output due to random initialization to provide a more reliable measure of generalization error is reasonable and well explained in the paper."
            },
            "weaknesses": {
                "value": "The purpose of NAS is to find the optimal architecture within a reasonable cost. The architecture found by the proposed method in the experiments seems to be far from optimal (even considering that it was explored in a very short time). For example, the optimal architectures in NAS-Bench-201 had accuracies of 94.37, 73.51, and 47.31, respectively, and many training-free methods discover architectures with only 1-2% accuracy difference from the optimal architectures in less than an hour [1]. The proposed method explored architectures that lagged behind the optimal architecture by 2-8% in less than a minute of search time. I am not sure how this result can be utilized. This concern would be alleviated if the authors reported the variation in the accuracy of the found architectures for different search times, or if they indicated how good the found architectures were within the overall architecture pool. It would also be helpful to compare the proposed method with other methods for training-free NAS (NASWOT[2], KNAS[3]), or to compare it with other (more expensive) NAS algorithms.\n\n[1] Shu, Y., Cai, S., Dai, Z., Ooi, B. C., & Low, B. K. H. (2021). Nasi: Label-and data-agnostic neural architecture search at initialization. arXiv preprint arXiv:2109.00817.\n\n[2] Mellor, J., Turner, J., Storkey, A., & Crowley, E. J. (2021, July). Neural architecture search without training. In International Conference on Machine Learning (pp. 7588-7598). PMLR.\n\n[3] Xu, J., Zhao, L., Lin, J., Gao, R., Sun, X., & Yang, H. (2021, July). KNAS: green neural architecture search. In International Conference on Machine Learning (pp. 11613-11625). PMLR."
            },
            "questions": {
                "value": "It seems that the training set is used to calculate the NTK, why is it acceptable to calculate it with the training set alone without using the validation set?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2379/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2379/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2379/Reviewer_C4Cd"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2379/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698763013388,
        "cdate": 1698763013388,
        "tmdate": 1699636171506,
        "mdate": 1699636171506,
        "license": "CC BY 4.0",
        "version": 2
    }
]