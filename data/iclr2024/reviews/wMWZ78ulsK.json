[
    {
        "id": "FJSXupLKNU",
        "forum": "wMWZ78ulsK",
        "replyto": "wMWZ78ulsK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_yTyJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_yTyJ"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel algorithm for the Interaction Grounded\nLearning (IGL) problem based on an information theoretic\nobjective. The algorithm is shown to demonstrate superior performance\nunder several noise-corrupted adaptations of a standard benchmark\nrelative to the state of the art."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper presents a well-motivated algorithm for a relatively new\nproblem in ML. This algorithm addresses the challenge of dealing with\nsignificant randomness in the feedback given to the learner, and the\nempirical results confirm the benefits of the proposed\napproach. Ablations are also given to provide more insight about which\nparts of the algorithm had notable effects on performance."
            },
            "weaknesses": {
                "value": "The main weaknesses that I can imagine are with respect to the\norganization of the paper. Perhaps I am biased, since I had not\npreviously been aware of the IGL framework, but I had trouble\nunderstanding both the motivation behind the problem framework and the\nalgorithm. Given that IGL is a relatively new and unexplored topic, I\nbelieve the paper can be improved by giving less abstract examples of\nthe IGL framework early on (for instance, everything became quite a\nbit more clear to me once I saw the benchmark in the experimental\nsection).\n\nMoreover, I did not find the argument for the necessity to include the\nregularization term particularly convincing. I would have liked to\nhave seen stronger evidence (particularly before the regulization term\nwas introduced) to suggest that the mode of overfitting discussed in\nthe paper actually occurs. Notably, without the regularization term,\nthe algorithm/optimization problem is considerably simpler.\nHaving said that, since the algorithm still\nappears to be novel even without the regularization term, I think this\nis mostly an issue of organizing the content to improve clarity."
            },
            "questions": {
                "value": "Does the context distribution have to be fixed throughout training (or\ncan it, for example, be adversarial)?\n\nI believe there is a mistake in the notation of $V(\\pi)$, particularly\nwith $(x, a)\\sim d_0\\otimes\\pi$. This looks like $x, a$ are sampled\nindependently, but really $a$ sampled conditionally on $x$. I believe\nit should be more like $x\\sim d_0,a\\sim\\pi(\\cdot\\mid x)$.\n\nAdmittedly I am not intimately familiar with MI optimization, but it\nis not obvious to me why we should expect minimization of the standard\nMI objective to \"overfit\" to maximize $I(Y; R_\\psi)$ as you claim. I\nsee that the objective can be decreased by increasing this term, but I\nsee now reason why thi wouldn't be balanced by a decrease of the $I(Y;\nX, A, R_\\psi)$\nterm. Has this been demonstrated experimentally? If so, can you\nprovide citations? If this paper is the first demonstration of this\noverfitting phenomenon, it might be nice to show those results\nbefore defining the regularized objective, it would help motivate your approach.\n\nWhy is it that the experiments with $\\beta=0$ exhibited the most\nvariance? In this case, I would expect variance to be lower, since\nyou're optimizing over fewer neural network parameters / the\noptimization has one less level of nesting.\n\nIn Algorithm 1, what does \"Ensure: Policy $\\pi$\" mean?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3239/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3239/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3239/Reviewer_yTyJ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3239/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699041619717,
        "cdate": 1699041619717,
        "tmdate": 1699636272337,
        "mdate": 1699636272337,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cNVurXmTIo",
        "forum": "wMWZ78ulsK",
        "replyto": "wMWZ78ulsK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_Jvuq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_Jvuq"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors proposed to leverage information-theoretical quantities to solve the interaction grounded learning in the noisy scenarios. The main contribution of this paper is a new objective based on the mutual information. However, how to estimate the mutual information has been heavily studied in the literature, and I don\u2019t see any new components here. Finally, the authors do not provide the appendix."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "N/A."
            },
            "weaknesses": {
                "value": "* Although the intuition of such objective is sound, I don\u2019t think there are any rigorous theoretical justification, e.g. the statistical error on estimating the reward with different level of noise.\n* I believe the authors ignore large amounts of work on (conditional) mutual information estimation, that covers most of the theoretical derivation in the paper, e.g. [1][2].\n\n[1] Song, Jiaming, and Stefano Ermon. \"Understanding the limitations of variational mutual information estimators.\" arXiv preprint arXiv:1910.06222 (2019).\n[2] Poole, Ben, et al. \"On variational bounds of mutual information.\" International Conference on Machine Learning. PMLR, 2019.\n\n* The authors do not provide the appendix, which should be a crucial issue that can lead to the rejection."
            },
            "questions": {
                "value": "To echo the weakness, I would like to ask:\n* Is there any rigorous theoretical guarantee for motivating this objective?\n* Can the authors discuss the relationship between the proposed estimation method and the existing work, not limited to the references I provide?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3239/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699190225419,
        "cdate": 1699190225419,
        "tmdate": 1699636272271,
        "mdate": 1699636272271,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "z9rPAfPk6u",
        "forum": "wMWZ78ulsK",
        "replyto": "wMWZ78ulsK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_8FsD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_8FsD"
        ],
        "content": {
            "summary": {
                "value": "this paper proposed an information-theoretical method for enforcing conditional independence between Context and A, given latent reward variable. The method is generalize to f -Information measures."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "an interesting problem is considered. the Preliminaries section provided a good background."
            },
            "weaknesses": {
                "value": "many steps in the derivation / explanation are not explained. For example, in my option the quantity (without an equation number) after Eq (4) does not follow from Eq 4. Is Theorem 3 trivial that it does not require proof?"
            },
            "questions": {
                "value": "Why is it important to show results for a few different f-divergences? \nWhy were these f-divergences chosen? \nHow to chose \"f-divergences\"? Table 2 show that different scenarios requires different \"f-divergences\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3239/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699252902846,
        "cdate": 1699252902846,
        "tmdate": 1699636272184,
        "mdate": 1699636272184,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jRGMHuFi1w",
        "forum": "wMWZ78ulsK",
        "replyto": "wMWZ78ulsK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_kBCY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_kBCY"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses the challenges and solutions in the context of reinforcement learning (RL) algorithms when the agent lacks complete knowledge of the reward variable. When there is no explicit reward, the agent must infer the reward from observed feedback, increasing the computational and statistical complexity of the RL problem.\n\nTo address these challenges, the Interaction-Grounded Learning (IGL) framework is introduced. In IGL, the agent observes a context, takes an action, and receives feedback, aiming to maximize the unobserved return by inferring rewards from this interaction. The key to this approach is a properly inferred reward decoder, which maps the context-action-feedback tuple to a prediction of the latent reward. However, learning such a reward decoder can be information-theoretically infeasible without additional assumptions on the relationship between context, action, feedback, and reward variables.\n\nOne such assumption, known as Full Conditional Independence, posits that feedback is conditionally independent of context and action given the latent reward. Existing IGL methods use this assumption and propose joint training of the policy and decoder. However, noisy feedback in real-world scenarios may challenge the validity of this assumption.\n\nThe paper introduces Variational Information-based IGL (VI-IGL) as an information-theoretic approach to IGL-based RL tasks. VI-IGL aims to ensure conditional independence between feedback and context action by minimizing an information-based objective function. It includes a regularization term to make the reward decoder robust to feedback noise.\n\nThe challenge of optimizing this objective is addressed by leveraging the variational representation of mutual information (MI) and formulating the problem as a min-max optimization. This allows gradient-based algorithms to efficiently solve it. The paper also extends the approach to f-Variational Information-based IGL (f-VI-IGL), creating a family of algorithms for the IGL-based RL problem.\n\nEmpirical results suggest that VI-IGL outperforms existing IGL RL algorithms, particularly in noisy feedback scenarios. The key contributions of the paper include the introduction of an information-theoretic approach to IGL-based RL, a novel optimization technique for handling continuous random variables, and the extension of the approach to f-VI-IGL."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper proposes a novel method to solve a real problem when we need to apply RL algorithms in real applications.\n\n- The paper provides a clear context of what is already done in previous literature and what are the main challenges.\n\n- The authors explain appropriately the novel method, providing the preliminary to understand the proposed approach. The novel algorithm uses a regularized information-based IGL objective. Then they provide a more tractable objective using the variational information-based approach. \n\n- The authors compare the proposed algorithm with SotA method, showing that the proposed approach outperforms previous ones when there is noise."
            },
            "weaknesses": {
                "value": "- The paper does not theoretically discuss how the changes in the (4) objective can lead to worse performances. How much the KL approximation optimum can be far from the original optimal solution?\n\n- The paper is lacking theoretical results (e.g. sample complexity or regret analysis). Xie et al. provide a sample complexity result for their proposed algorithm. Could you derive similar results?\n\n- Experimental evaluation: \n\n    - Why does the proposed method achieve worse results in the No noises setting compared to Xie et Al.?\n\n- In the conclusion the authors mentioned that the algorithm is computationally expensive. Could you compare the computational complexity of the proposed method with the one of Xie et Al.?"
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3239/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699450629570,
        "cdate": 1699450629570,
        "tmdate": 1699636272118,
        "mdate": 1699636272118,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BgoaLky5ZC",
        "forum": "wMWZ78ulsK",
        "replyto": "wMWZ78ulsK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_1D19"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3239/Reviewer_1D19"
        ],
        "content": {
            "summary": {
                "value": "This paper designs an algorithm for inverse RL using the properties of f-divergence. It conducts experiment to validate the algorithm."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea of using f-divergence is novel.\n\n2. The results of the experiment validates their algorithm."
            },
            "weaknesses": {
                "value": "1. The proposed algorithm does not have finite-sample theoretical guarantee."
            },
            "questions": {
                "value": "See the 'weakness' section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3239/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699592142734,
        "cdate": 1699592142734,
        "tmdate": 1699636272046,
        "mdate": 1699636272046,
        "license": "CC BY 4.0",
        "version": 2
    }
]