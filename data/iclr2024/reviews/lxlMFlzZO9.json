[
    {
        "id": "PZFN8ppGjB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8049/Reviewer_MSm4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8049/Reviewer_MSm4"
        ],
        "forum": "lxlMFlzZO9",
        "replyto": "lxlMFlzZO9",
        "content": {
            "summary": {
                "value": "The paper fine-tunes a language model on Lean3 state-tactic pairs and uses it to search for proofs on college-to-university-level mathematical problems. The main innovations are an augmentation of the training data and an inference-time technique that dynamically chooses how many branches to expand depending on the remaining time."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The proposed methods are straightforward and easy to implement. They bring performance improvement on the miniF2F benchmark."
            },
            "weaknesses": {
                "value": "I'm not entirely convinced by the claims that these changes are truly beneficial, or how much improvement to the baselines there is:\n- Data augmentation: In table 1, one can actually see that the data augmentation helps for problems in miniF2F, but is actually detrimental to performance for problems in ProofNet (which are harder) and problems in Mathlib (which cover wider mathematical domains). Therefore, the conclusion ought to be that the data augmentation might improve things for certain problems, but cannot increase performance across the board or in general.\n- Without the data augmentation, which I think should be considered as a non-general method as the above point suggests, the proposed method proves 29.0\\% of problems on miniF2F test, which is lower than Lean + Expert Iteration by Polu et al. (2022).\n\nI have more detailed comments and suggestions below:\n\n1. > End of page 1. \"To overcome the issue of limited data for training the model, various alternative attempts have been explored to improve the performance of automated theorem provers, such as reinforcement learning Polu & Sutskever (2020)\"\n\n    (Minor) It is slightly strange to refer to it as an alternative attempt since Polu & Sutskever (2020) is arguably the first work to use generative transformer with interactive theorem provers.\n\n2. (Major) One of the major contributions is \"we also release a public theorem prover website\", but this website is not provided and therefore it is impossible to assess this claim.\n\n3. (Minor) Scholarship needs improving: the related works should not be a simple stack of papers covering related topics, but should rather compare and contrast other works with this current work.\n\n4. (Minor) Citation style: A lot of instances where the citation is glued to the text with no separation, e.g., Leande Moura et al. (2015) on page 3. Use ~\\citep to cite the paper and ~\\citet to cite the authors.\n\n5. > Page 4 assumption: The assumption tactic is used to prove the goal by assuming it\u2019s true based on the available hypotheses\n\n    (Minor) This is clearly not accurate. One never assumes the goal to be true. Rather, one matches the goal with the assumptions with this tactic.\n\n7. (Critical) Misleading claim: I'm surprised that the authors mentioned the HTPS paper by Lample et al., but not their results. The HTPS paper achieved a success rate of >40\\% on the miniF2F with pass@64, compared to 30\\% in this paper with pass@1. Of course, the success rates between pass@1 and pass@64 are very different, but one should be very careful before making the claim **We achieve a new state-of-the-art performance of 30.6% on MiniF2F using Lean** if its success rate is 10\\% (absolute), or 25\\% (relative) lower than a paper published 17 months ago. Some experiments for DS-solver at a higher pass@k should be performed before such claims can be verified."
            },
            "questions": {
                "value": "For how many steps was the model trained for? What are the training and validation metrics? What is the experimental wallclock time limit per problem for miniF2F, ProofNet and Mathlib?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8049/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697273666733,
        "cdate": 1697273666733,
        "tmdate": 1699636994761,
        "mdate": 1699636994761,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "O3Mg4jGXSx",
        "forum": "lxlMFlzZO9",
        "replyto": "lxlMFlzZO9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8049/Reviewer_6Nhd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8049/Reviewer_6Nhd"
        ],
        "content": {
            "summary": {
                "value": "Aiming to generate tactics for interactive theorem provers (ITPs) with the help of large language models (LLMs), the paper proposes two methods: the dynamic sampling that determines how many tactics are investigated depending on the remaining time, and the data augmentation that splits an application of a specific tactic with multiple arguments into multiple applications of the tactic with one argument. The effect of the proposed methods is experimentally shown on certain datasets of mathematical theorem proving."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper provides several examples of proof code and tactics in Lean. It would help readers unfamiliar with Lean find the aim and method studied in the paper.\n- The experiments show that the proposed approaches can improve the proof search with LLMs."
            },
            "weaknesses": {
                "value": "- The improvement by the dynamic sampling seems incremental. The \"Original data\" columns in Table 1 shows only the improvement of 0.4 points against the optimized LeanDojo.\n- The effect of the data augmentation is not entirely clear because there is no experiment that employs only it.\n- Not all the experimental settings are clear. Specifically, I cannot find how many tactics are sampled in the fixed sampling.\n- I'm not convinced by the discussion for Figure 2. It shows that the difference between the dynamic and fixed sampling methods are almost fixed. I suspect it means that the dynamic sampling is effective only for theorems with short proofs because, even when the time budgets are increased, the difference is retained (rather, becomes small).\n- The paper cites other works without parenthesizing the author names. It lowers the readability."
            },
            "questions": {
                "value": "- How many tactics are sampled in the fixed sampling? Does changing the number of sample tactics influence the result?\n- Does Figure 2 mean that the dynamic sampling is effective only for theorems with short proofs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8049/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698464848815,
        "cdate": 1698464848815,
        "tmdate": 1699636994553,
        "mdate": 1699636994553,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VuZkKjNNMF",
        "forum": "lxlMFlzZO9",
        "replyto": "lxlMFlzZO9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8049/Reviewer_FKE8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8049/Reviewer_FKE8"
        ],
        "content": {
            "summary": {
                "value": "In this submission, the authors consider automatic theorem proving with Transformer models. They introduce a dynamic way of sampling from a tactic space while take total time left for proving the theorem into account. They show that this makes proof search more efficient by balancing exploration vs exploitation. They additionally provide a data augmentation by decomposing tactics with multiple premises.\nThey conducted experiments by training a ByT5 model on formalized theorems in Lean (mathlib repo) and evaluating their model on MiniF2F and ProofNet, two standard datasets in the literature. The results show that they approach is resulting in performance gains."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Interactive theorem proving (especially in Lean) has gained a lot of attention recently. With more and more mathematicians picking it up and more and more machine learning support to ease the construction of the proofs, the paper is certainly relevant for ICLR and the problem is interesting.\n- Although the models are fairly small, they provide a new state of the art\n- The approach is straightforward and well-explained. Datasets are open-source; and they seemed to released their models on a public website (this makes the experiments reproducible for academics and students)"
            },
            "weaknesses": {
                "value": "- The comparisons in Table 1 seem to be slightly unfair: (time used by LeanDojo and the optimized version vs. the proposed method is unclear)\n- Not clear from the paper, if model weights and code will be open-sourced\n- The contribution is straightforward and more on the minor side\n- Interesting ablations and more in-depth analysis is missing (more detailed analysis of time tradeoff in Figure 2)\n- The related work is highly insufficiently discussed"
            },
            "questions": {
                "value": "- Will the code and models be open-source?\n- Would the authors consider expanding the related work section a bit including highly influential, but more non-lean related research?\n- what is the time used by LeanDojo and the optimized version vs. the sampling? Can this be added to Table 1\n- Where are the tradeoffs in exploration vs exploitation; Table 2? For example, what size are the proofs where the sampling strategy works well? Are there cases where fixed sampling is better?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8049/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698714427693,
        "cdate": 1698714427693,
        "tmdate": 1699636994355,
        "mdate": 1699636994355,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PI55OuYxec",
        "forum": "lxlMFlzZO9",
        "replyto": "lxlMFlzZO9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8049/Reviewer_X3v4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8049/Reviewer_X3v4"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces DS-Prover, a automated theorem proving framework in the Lean proof assistant. The main feature of this framework is that it dynamically determines the number of tactics to explore taking into account the remaining time resources. Performance gain has been demonstrated against the previous Fixed Sampling strategy in the LeanDojo paper."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea of taking time into the explore-exploit tradeoff is novel and of practical significance. I especially appreciate the authors' effort of pushing the boundary of low-budget neural theorem proving, which could be much more useful to daily ITP users."
            },
            "weaknesses": {
                "value": "- The writing can still be improved. For example, the \\cite or \\citep should not be used interchangeably, and there should be a space before each inline citation. Also, some sentences can use some polishing, e.g., 'where anyone can put the formal statement in Lean for their mathematical theorem' on page 2.\n- Related prior work in tactic prediction in other systems (Coq, HOL4) should have been mentioned and compared. In particular, some considerations between atomic and compound tactics have been discussed in prior work in Coq (https://arxiv.org/abs/1905.09381, https://proverbot9001.ucsd.edu).\n- The claim of 'a new state-of-the-art performance of 30.6% on MiniF2F using Lean' is not entirely accurate, as the HyperTree Proof Search (HTPS) paper has already achieved over 40% success rate over the same dateset. I understand that your approach does not use reinforcement learning nor the same amount of computation resources as in the HTPS paper, but it might be better to make those assumptions clear and perhaps draw a more detailed comparison against HTPS."
            },
            "questions": {
                "value": "- Table 1: one of the contributions of LeanDojo was to propose the novel_premises benchmark, which is believed to better reflect the generalization ability of the proof agent. Is is possible to have DS-Prover also run on it? \n- Discussions: would it be possible to have a length distribution comparisons between the generated proofs from Dynamic Sampling and Fixed Sampling models? Some qualitative examples to illustrate the differences between these two sampling methods would be highly appreciated."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8049/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698854274777,
        "cdate": 1698854274777,
        "tmdate": 1699636994244,
        "mdate": 1699636994244,
        "license": "CC BY 4.0",
        "version": 2
    }
]