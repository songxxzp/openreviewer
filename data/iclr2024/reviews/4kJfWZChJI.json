[
    {
        "id": "VkNCUzEgG5",
        "forum": "4kJfWZChJI",
        "replyto": "4kJfWZChJI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7081/Reviewer_6gJi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7081/Reviewer_6gJi"
        ],
        "content": {
            "summary": {
                "value": "This paper points out limitations in existing multi-source domain generalization methods, which struggle to generalize by training a model with diverse source domains. The authors propose a new technique for effectively filtering and ensembling individual expert models. Specifically, they introduce an unsupervised spectral ensemble approach, expanding on the Spectral Meta-Learner by using a one-vs-rest paradigm for multi-class classification. This proposed method significantly outperforms traditional single model approaches and even surpasses self-ensembling and multiple model ensemble techniques."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "- The paper boasts high-quality writing that is very readable. It provides detailed comparisons with existing methods. Especially commendable is the clarity and precision in potentially challenging statements.\n\n- The proposed method is both intuitive and powerful, and the paper thoroughly describes the underlying assumptions and preliminaries supporting its feasibility.\n\n- In a multi-source domain generalization setting, the proposed approach notably surpasses not only the performance of a single model but also that of self-ensembling and multi-model ensemble methods."
            },
            "weaknesses": {
                "value": "The paper should compare the computational overhead of the proposed spectral meta estimation with other ensemble methods. Even if a direct measurement of all test times isn't possible, including a discussion on computational complexity would be beneficial. Without such comparisons or analyses, it's hard to gauge the practicality of the proposed method."
            },
            "questions": {
                "value": "There is no question."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7081/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7081/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7081/Reviewer_6gJi"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7081/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698592629156,
        "cdate": 1698592629156,
        "tmdate": 1699636834920,
        "mdate": 1699636834920,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3MvkonLXdD",
        "forum": "4kJfWZChJI",
        "replyto": "4kJfWZChJI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7081/Reviewer_52us"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7081/Reviewer_52us"
        ],
        "content": {
            "summary": {
                "value": "In contrast with the conventional single-model domain generalization framework, the paper proposes an alternative perspective that the knowledge of the unseen target domain is transferred from multiple source domains. Specifically, the prediction of unseen target data is an aggregate of the predictions from each individual source domain model, and a spectral unsupervised ensembling method is used to determine the contribution of each source model to the target. To further facilitate the selection of source models, the paper proposes a meta performance estimation technique that aims to filter out the underperformed models within the ensemble. The proposed method's effectiveness is validated across multiple benchmark datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "* The paper extends the Spectral Meta-Learner (SML) unsupervised ensemble learning approach from binary to multi-class classification as a way to aggregate the knowledge from multi-source domain models to the unseen target domain."
            },
            "weaknesses": {
                "value": "* The research lacks novelty in its claim. The problem addressed in this paper, namely Test-time adaptation for Distribution shifts, was comprehensively discussed in [1]. Furthermore, the approach of aggregating knowledge from multiple source domains to an unseen target domain, often using techniques like Mixture-of-Experts or ensemble, is not a novel concept either [2, 3]\n\n* Conceptually, the research presented in this paper bears a significant resemblance to [3]. Both works utilize a similar approach, pretraining individual models on multiple source domains using ERM and subsequently transferring the knowledge from this ensemble (akin to a mixture of experts) to the target domain. Additionally, while the authors introduce a complex method named ' multi-class SML' to determine the aggregation of predictions from the source models, [3] employs a more straightforward, learnable transformer encoder for the same purpose, with parameters learned through meta-learning. Notably, this paper omits citations and comparisons to [3].\n \n* The paper lacks a comprehensive 'related work' section, leading to the omission of some pivotal prior research. For instance, meta-learning, a critical concept for addressing domain generalization, was introduced in [4]. Given that \"meta\" appears in the paper's title, the authors should clarify how this concept ties into their proposed method, using standard terminology such as 'support' and 'query' sets. Additionally, it would be beneficial for the authors to draw comparisons between their work and other studies that have also employed meta-learning for domain generalization. \n\n\n[1] A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts. 2023\n\n[2] Multi-Source Domain Adaptation with Mixture of Experts. EMNLP 2018\n\n[3] Meta-DMoE: Adapting to Domain Shift by Meta-Distillation from Mixture-of-Experts. NeurIPS 2022\n\n[4] Adaptive Risk Minimization: Learning to Adapt to Domain Shift. NeurIPS 2021"
            },
            "questions": {
                "value": "* Please make a comparison with [3] and identify the differences in detail. At the conceptual level, they are the same. Specifically, they both model source domain knowledge using the ensemble of models and softly determine the contribution of each source domain to the target. At the technical level, the paper proposes a different method to aggregate the source knowledge in the ensemble with an additional  \"meta-performance estimation\" to select the source models within the ensemble. \n\n* Please clarify how the concept of \"meta\" relates to the proposed approach. Is it the same with \"meta-learning\"? If yes, please explain what are the support set and query set. What is the meta-knowledge is learned during meta-training?\n\n* Please provide more explanation of the design of \"Meta model selection\", especially from the perspective of intuition. It is a little bit confusing with what is described in the paper \"In this way, the instability of stochastic optimization can be accommodated,\"\n\n* Please add a related work section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7081/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7081/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7081/Reviewer_52us"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7081/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698607301745,
        "cdate": 1698607301745,
        "tmdate": 1699636834800,
        "mdate": 1699636834800,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bCcYLWJGUj",
        "forum": "4kJfWZChJI",
        "replyto": "4kJfWZChJI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7081/Reviewer_X4Bt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7081/Reviewer_X4Bt"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of domain generalization. The proposed method employs domain-specific expert models and leverages un- supervised ensemble learning to create a combination of these experts for better predictions. Experiments are performed on the DomainBed benchmark to show the effectiveness of the proposed method in terms of accuracy and inference efficiency."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper introduces an interesting approach to tackle the domain generalization challenge, utilizing an unsupervised ensemble learning technique that improves model selection, with an emphasis on elevating specificity over generalization\n\n- This paper is generally well-structured and easy to follow."
            },
            "weaknesses": {
                "value": "- The novelty of this paper is somewhat limited, since both mixture-of-experts or spectral meta-learner is not new in this area.\n\n- Some important references are missing, e.g., \n   + [1] Sparse Mixture-of-Experts are Domain Generalizable Learners, ICLR2023.\n   + [2] Learning mixture of domain-specific experts via disentangled factors for autonomous driving, AAAI2022\n   + [3] Generalizable person re-identification with relevance-aware mixture of experts, CVPR2021"
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7081/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698760618000,
        "cdate": 1698760618000,
        "tmdate": 1699636834664,
        "mdate": 1699636834664,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aIKom0EyU5",
        "forum": "4kJfWZChJI",
        "replyto": "4kJfWZChJI",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7081/Reviewer_ExFD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7081/Reviewer_ExFD"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles domain generalization (DG) aiming to construct a uni\ufb01ed model trained on diverse source domains, with the goal of achieving robust performance on any unseen test domain.  This paper proposes using individual ERM models for each source and aggregating their predictions during the test phase, by a meta performance estimation technique for model selection within the sources. Furthermore, an approach based on spectral unsupervised ensemble learning to assess the transferability of each source model to test samples is proposed."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ Observation and Motivation: the finding is quite important, and the motivation is quite clear by showing Figure 2 and Figure 3: the transferability of any source domain remains unpredictable without access to the speci\ufb01c test domain information, leading to the inherent instability witnessed in current DG approaches. The solution is to use domain-speci\ufb01c experts to prioritize speci\ufb01city over generalization. \n+ Methodology: the introduction of a spectral ensemble for source models is both innovative and practical, effectively enhancing the robustness of the DG framework. This approach incurs the additional task of recalculating the covariance matrix with cumulative test set data, but the trade-off is well justified by the benefits.\n+ Presentation: the clarity and precision of the writing, complemented by well-crafted figures, make the content not only accessible but also engaging. The overall presentation is of high quality, effectively conveying complex concepts in a coherent manner.\n+ Experiments: the experimental design is thorough and multifaceted, convincingly demonstrating the efficacy of the proposed method from the following perspectives: 1) meta model selection before ensemble 2) domainbed benchmark 3) test-time ensemble 4) test-time transferability estimation. The performance is outstanding."
            },
            "weaknesses": {
                "value": "- Computation Complexity: while the proposed spectral ensemble-based method offers the advantage of being applicable in online incremental settings without the need for re-training, adaptation, or iterative optimization, it still presents certain limitations. Specifically, the need to recalculate the covariance matrix and compute the Singular Value Decomposition (SVD) may result in lower computational efficiency compared to other Domain Generalization (DG) methods that do not require any post-hoc computations, such as MIRO and Fishr. This increased computational overhead could potentially slow down inference speed, posing a challenge for deploying the model in real-world scenarios.\n\n---- After Rebuttal ------\nWe thank the detailed comparisons on inference time provided and the clarification on pseudo-code. After carefully reading Reviewer 52us's comments, I think I have missed a few relevant works in this domain and comparably the originality of this work is somewhat limited. The main technical component derived is originated from another paper and there are already a few emsemble-based DG methods in the past. But the good side is that the proposed method indeed increases the performance on most of benchmark datasets. Based on the comments above, I would like to change my score to weak accept."
            },
            "questions": {
                "value": "1. Refer the weakness, I am wondering the actual inference time for each target sample compared with the baselines (MIRO and Fishr). \n2. In Algorithm 1, M is the number of total models been kept after meta ranking, However, for meta estimation, \u201cfor i = 1 : S\u201d means for each source domain, \u201cRank and select the best performing M models\u201d. Does it mean each source domain will have M best performing models, so the total number of models becomes S*M. It is confusing here, because M is the predictors are available to make predictions on test samples (Sec 3.2). Could you please clarify the number of models chosen from each source domain, and explain how to get M in both Algorithm 1 and Section 3.3?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7081/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7081/Reviewer_ExFD",
                    "ICLR.cc/2024/Conference/Submission7081/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7081/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698820463416,
        "cdate": 1698820463416,
        "tmdate": 1700616739726,
        "mdate": 1700616739726,
        "license": "CC BY 4.0",
        "version": 2
    }
]