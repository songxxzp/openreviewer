[
    {
        "id": "O54Ag7xaQw",
        "forum": "aKivEaIbN2",
        "replyto": "aKivEaIbN2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6348/Reviewer_UMqx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6348/Reviewer_UMqx"
        ],
        "content": {
            "summary": {
                "value": "- The authors propose a novel, cheap, training-free, and data-agnostic neural architecture search (NAS) method.\n- The proposed method converts an architecture to a graph and utilizes extracted graph measures such as average degree as a proxy for the performance of the architecture.\n- The empirical results show that the proposed method can find architectures with better performance in computational costs compared to the baseline methods.\n- Surprisingly, the proposed method can find the best architecture among 200 randomly sampled architectures from NAS-Bench 201 dataset in 217 CPU seconds without any GPU computations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed method is simple and easy to understand.\n- The proposed conversion method seems novel.\n- The authors suggest techniques for further speeding up the proposed method by using surrogate models.\n- The empirical results show the superiority of the proposed method.\n- The paper contains the comparison among various graph measures in its appendix."
            },
            "weaknesses": {
                "value": "- I think the paper needs more justification about the importance of the training-free data-agnostic NAS.\n- The experimental results are evaluated on only simple benchmarks. To show the practicality of the proposed method, I think a it would be more helpful if you provide a comparison with other non-training-free NAS methods such as DARTS-PT on a larger search space such as DARTS space."
            },
            "questions": {
                "value": "- I am curious about the correlation between model inference time and proxy metrics. Since the proposed \"average degree\" measures the connectivity between channels, a higher average degree may lead to a slower inference speed.\n- The ultimate goal of NAS is to find the optimal architecture in any way possible. Even if the proposed method has a high correlation with model performance, it is uncertain whether it will be significantly helpful in quickly finding the best architecture. This is because one must train selected architectures to evaluate the actual performance and verify whether it is a good architecture, and it seems that most of the time will be spent in this verification process during the NAS procedure. Can you kindly and elaborately explain why training-free NAS is an important issue, along with practical scenarios?\n- Of course, unlike existing non-training-free NAS methods, since the proposed method has near-zero search cost, most of the time can be spent on validation. Nonetheless, I am curious whether it can find a better architecture than baselines such as DARTS-PT within the same computational budget in the DARTS space.\n\nIf my concerns are addressed, I promise to raise the score."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "There aren't any ethical concerns related to this paper."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Reviewer_UMqx"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6348/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698789613652,
        "cdate": 1698789613652,
        "tmdate": 1699636699669,
        "mdate": 1699636699669,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ssRRbjzjuj",
        "forum": "aKivEaIbN2",
        "replyto": "aKivEaIbN2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6348/Reviewer_EKQj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6348/Reviewer_EKQj"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes NASGraph, a training-free Neural Architecture Search (NAS) method that relies on a graph-based interpretation of neural architectures. NASGrPh first converts neural architectures to computational graphs and then utilizes properties of the generated graphs as proxy of validation accuracies of corresponding architectures. NASGraph utilizes graph blocks to modularize neural architectures and determine the connectivity of graph nodes. The proposed conversion method allows NASGraph to construct a computational graph that reflects the forward propagation process of a neural architecture. The effectiveness of NASGraph is verified across various NAS benchmarks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- While this is not the first work to perform architecture search with graph-based representations of neural architectures, I believe the proposed approach is far more thorough in incorporating the actual computations that occur within neural architectures. NASGraph goes above and beyond simply converting neural architectures into DAGs by considering how the inputs are being processed and mapped to outputs during the forward propagation process.\n- The final proxy metric to the validation accuracy of neural architectures (the average degree of the graph measure) makes sense and is theoretically-grounded.\n- The experiments that span various NAS benchmarks are extensive and comprehensive."
            },
            "weaknesses": {
                "value": "- It appears that NASGraph assumes the inputs to the neural architecture and subsequent graph blocks is non-negative. Does the analysis hold even with non-negative inputs? Many of modern neural architectures utilize activation functions that could yield negative inputs/outputs (e.g., gelu activation). Can NASGraph generalize beyond relu-based architectures?\n- In a similar vein, can the proposed method generalize to non-conv-based architecture spaces? Such as ViTs and MLPMixers?\n- The authors define the final score of neural architectures (the average degree of the graph measure) in Section 4.2 under the performance evaluation section. I think it would be more appropriate to move this definition to somewhere towards the end of Section 3 because by the end of Section 3, the reader is left hanging without the knowledge of how NASGraph actually ranks neural architectures.\n- In Section 4.2, the authors mention that they explore other graph measures as well. Any idea why the average degree works best out of the compared graph measures? Also, intuitive explanation to what each one of these graph measures actually indicates/implies would be helpful."
            },
            "questions": {
                "value": "Please refer to the Weaknesses section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Reviewer_EKQj"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6348/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698982330645,
        "cdate": 1698982330645,
        "tmdate": 1699636699553,
        "mdate": 1699636699553,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HqxFrLD5MP",
        "forum": "aKivEaIbN2",
        "replyto": "aKivEaIbN2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6348/Reviewer_bWfm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6348/Reviewer_bWfm"
        ],
        "content": {
            "summary": {
                "value": "Neural Architecture Search (NAS) is inherently as expensive task. Zero cost proxies aim at bypassing this compute by using cheap to evaluate statistics on architectures to predict the most optimal architectures. This paper proposes a novel graph-based zero cost proxy based on properties of graph representations of architectures.  The method is evaluated on multiple NAS-Bench-Suite Zero tasks yielding competitive performance.  The method overcomes several issues with current zero cost proxies e.g. data dependency, GPU requirement, and operation preference."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper in general is well written and the results/evaluation well presented\n- Results on the NAS-Bench-Suite-Zero tasks are quite competitive. Evaluation of complementary nature of the proxy, from table 5 is interesting. \n- The method is fairly novel and interesting"
            },
            "weaknesses": {
                "value": "- I went through the example in Figure 1 and the caption and the example itself is still unclear to me. Could the authors please elaborate on this?\n- I find the evaluation of the method quite weak especially since the authors do not compare against the MeCo proxy https://openreview.net/pdf?id=KFm2lZiI7n. On an initial glance it seems that MeCo outperforms the proposed proxy on most of the benchmarks. The code for MeCo is publicly accessible and I encourage the authors to compare their work with MeCo in terms of the correlation metric and search time. \n- I currently find the search spaces to be very limited to cell-based spaces or benchmarks. Since recently there have been efforts to scale Neural Architecture Search to weight-entangled spaces like AutoFormer [1], OFA [2] and HAT[3], it would be great to evaluate the method on these spaces. Note though these spaces don't have a tabular benchmark for evaluation, they do provide a pre-trained surrogate model for fast evaluation. \n- Since there has been growing interest in transformer spaces, is the proxy search space agnostic and directly applicable to transformer spaces? This was unclear to me from the paper.\n\n[1] Chen, M., Peng, H., Fu, J. and Ling, H., 2021. Autoformer: Searching transformers for visual recognition. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 12270-12280).\n\n[2] Cai, H., Gan, C., Wang, T., Zhang, Z. and Han, S., 2019. Once-for-all: Train one network and specialize it for efficient deployment. arXiv preprint arXiv:1908.09791.\n\n[3] Wang, H., Wu, Z., Liu, Z., Cai, H., Zhu, L., Gan, C. and Han, S., 2020. Hat: Hardware-aware transformers for efficient natural language processing. arXiv preprint arXiv:2005.14187"
            },
            "questions": {
                "value": "- Check weaknesses: Could the authors compare against MeCo (https://openreview.net/pdf?id=KFm2lZiI7n) and could the authors evaluated on weight entangled macro-architecture spaces like AutoFormer[1], OFA[2] and HAT[3]?\n- How does the cuda memory consumption and search time of the method compare against other proxies?\n- Reproducibility is still am important challenge in the NAS literature . For reproducibility, could the authors make the code publicly available?\n\n\n[1] Chen, M., Peng, H., Fu, J. and Ling, H., 2021. Autoformer: Searching transformers for visual recognition. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 12270-12280).\n\n[2] Cai, H., Gan, C., Wang, T., Zhang, Z. and Han, S., 2019. Once-for-all: Train one network and specialize it for efficient deployment. arXiv preprint arXiv:1908.09791.\n\n[3] Wang, H., Wu, Z., Liu, Z., Cai, H., Zhu, L., Gan, C. and Han, S., 2020. Hat: Hardware-aware transformers for efficient natural language processing. arXiv preprint arXiv:2005.14187"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6348/Reviewer_bWfm"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6348/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699437622997,
        "cdate": 1699437622997,
        "tmdate": 1699636699441,
        "mdate": 1699636699441,
        "license": "CC BY 4.0",
        "version": 2
    }
]