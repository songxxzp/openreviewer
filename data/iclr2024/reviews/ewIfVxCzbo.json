[
    {
        "id": "rhKlyPFrgH",
        "forum": "ewIfVxCzbo",
        "replyto": "ewIfVxCzbo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3952/Reviewer_FurC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3952/Reviewer_FurC"
        ],
        "content": {
            "summary": {
                "value": "This work introduces a gradient-based model for prompt optimization in text-to-image generation. Experiments are performed over collected prompts to evaluate the proposal."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "++ Both adversarial attack and prompt improvement tasks are included for evaluation.\n\n++ The main idea is novel and interesting."
            },
            "weaknesses": {
                "value": "-- The figure 1 should be professionally re-shaped by highlighting the main contributions, instead of listing each block.\n\n-- Only one metric of CLIP loss is used for evaluation, which makes the experimental results somewhat unconvincing. As pointed in [A], clip score does not correlate well with human choices. It is necessary to report the results under more metrics (e.g., Aesthetic Score, Human Preference Score [A], or Human Preference Score v2 [B]).\n\nMoreover, the prompt dataset in this work contains only 300 prompts for each task. It is better to evaluate the  3200 prompts on HPS benchmark [B].\n\n[A] Human Preference Score: Better Aligning Text-to-Image Models with Human Preference, ICCV 2023.\n[B] Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis[J]. arXiv preprint arXiv:2306.09341, 2023.\n\n-- Authors select an earlier version of Stable Diffusion 1-4 as the base model. I am curious to see the results when applying the proposal into superior version of Stable Diffusion (SDXL).\n\n-- It is not safe to evaluate the prompt improvement task with clip loss in Table 1 (b), where the state-of-the-art method (Promptist) even shows worse performance than user input. I checked the Promptist paper, where extensive human study is performed to validate the effectiveness compared to user input. Thus I have to say the comparison in Table 1 (b) is somewhat not fair, and this work does not give enough credit to existing work of Promptist.\n\nMoreover, following Promptist paper, it is also necessary to perform human study to evaluate the proposal.\n\n-- Examples in Figure 2 seem to be cherry-picked."
            },
            "questions": {
                "value": "Please check the details in Weaknesses section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3952/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698757560366,
        "cdate": 1698757560366,
        "tmdate": 1699636355986,
        "mdate": 1699636355986,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6uIb2WQeYk",
        "forum": "ewIfVxCzbo",
        "replyto": "ewIfVxCzbo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3952/Reviewer_emXz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3952/Reviewer_emXz"
        ],
        "content": {
            "summary": {
                "value": "This paper explores the domain of text-to-image diffusion models with a focus on a gradient-based prompt optimization framework. Given the vast optimization spaces in text and the memory inefficiency of computing text gradients, the author introduces two innovative workarounds to address these challenges. First, they create a compact subspace that is most relevant to the user input. Then, they propose the use of \"Shortcut Gradient,\" which abstains from gradient computation for large timesteps and instead conducts smaller steps. Finally, the paper suggests predicting the final image through denoising from the last gradient-computed timestep. This approach is versatile and can be employed for tasks such as generating adversarial prompts for model diagnosis or enhancing prompts to improve user-input fidelity."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "A noteworthy strength of this paper is its investigation into the impact of prompts on text-to-image diffusion models. It contributes to the field by improving prompt optimization efficiency and introduces several techniques to address this issue."
            },
            "weaknesses": {
                "value": "While the proposed method effectively tackles the challenges of prompt optimization, it does rely on several heuristics, which could be considered a limitation. For instance, the \"Shortcut Gradient\" method necessitates tracking the CLIP loss throughout timesteps, which introduces complexity. Moreover, the negative prompt library relies on human-crafted prompts, potentially making it highly dependent on the choice of diffusion models. Another limitation is evident in Table 1, where the evaluation solely reports the CLIP loss. The absence of metrics measuring the relevance between the modified prompt and the user-provided prompt raises concerns about the comprehensiveness of the evaluation. Additionally, in adversarial prompt experiments, the evaluation is limited to the CLIP loss, which may not capture the full scope of the method's performance, considering its primary focus on maximizing CLIP loss."
            },
            "questions": {
                "value": "The paper raises questions about comparisons with the \"Hard Prompts Made Easy\" paper [https://arxiv.org/abs/2302.03668]. It would be valuable to understand how the proposed DPO-Diff method performs in comparison to simply optimizing the CLIP loss. This comparison could shed light on the relative advantages and disadvantages of each approach.\n\nIn Table 1, it would be helpful if the author could provide more context regarding the difference in the number of User Inputs for Table 1 (a) and Table 1 (b). An explanation of the reasons behind this discrepancy in the experimental setup would enhance the reader's understanding of the results."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3952/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698773594438,
        "cdate": 1698773594438,
        "tmdate": 1699636355883,
        "mdate": 1699636355883,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "o6ZfExGniI",
        "forum": "ewIfVxCzbo",
        "replyto": "ewIfVxCzbo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3952/Reviewer_3K8N"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3952/Reviewer_3K8N"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a systematic study of prompt optimization for text-to-image diffusion models. Two tricks are proposed to solve two challenges: 1) searching for synonyms/antonyms to mitigate the problem of enormous domain space; 2) shortcut gradient to mitigate the problem of backpropagating the inference chain. The proposed methods are straightforward but results are promising."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper studies an important problem of prompt optimization. The paper, to the best of the authors' knowledge, provides the first exploratory work on automated negative prompt optimization.\n- The presented results look promising."
            },
            "weaknesses": {
                "value": "- Clarification question: how are the compact domain space contacted and shortcut gradient related? Do we dynamically select words to search for synonyms/antonyms based on the gradients?\n- Clarity: 1) The asterisk symbol in eq 6 seems not usually used in this case; 2) it seems that the main issue with backproping through the entire inference chain is the prohibitive memory cost, so abbreviating it as \"text gradient\" is a little misleading and inaccurate.\n- Shortcut gradient: 1) is it necessary to use estimated x_0 from t-K? is there any ablation to support the claim? 2) would strategies like randomizing the truncation lengths [1] be helpful in this case?\n\n[1] Prabhudesai, Mihir, et al. \"Aligning Text-to-Image Diffusion Models with Reward Backpropagation.\" arXiv preprint arXiv:2310.03739 (2023)."
            },
            "questions": {
                "value": "How can we make sure that the synonym-swapped sentence is still semantically similar to the original sentence and how do we choose the distance d? e.g. in Fig 2 (a) \"grease picture\" is different from \"oil painting\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3952/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3952/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3952/Reviewer_3K8N"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3952/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698870224101,
        "cdate": 1698870224101,
        "tmdate": 1700756080738,
        "mdate": 1700756080738,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9gaftey05i",
        "forum": "ewIfVxCzbo",
        "replyto": "ewIfVxCzbo",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3952/Reviewer_BFJd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3952/Reviewer_BFJd"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces the first gradient-based framework for optimizing prompts for text-to-image diffusion models. Two main challenges are addressed: 1) the enormous search space of possible prompts, and 2) the high computational cost of computing text gradients through the full diffusion model. To tackle these issues, dynamically generated compact subspaces of only the most relevant words are used to restrict the search space. A \"Shortcut Gradient\" is introduced to efficiently approximate the true text gradient with constant memory and runtime. Experiments show the framework can enhance or adversarially attack diffusion model faithfulness by discovering improved or destructive prompts respectively. Overall, this represents a novel gradient-based approach for prompt optimization that restricts the search space and enables efficient approximation of text gradients. The key innovations are the compact subspaces and Shortcut Gradient which make prompt optimization tractable."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper identifies an important problem that is not well-addressed \n2. The paper clearly shows two challenges and proposes effective solutions and the results look promising \n3. The experiments seem solid to support the claims on multiple sources and tasks."
            },
            "weaknesses": {
                "value": "1. The paper is not well written and easy to follow. Some core sections are not fully explained. \n2. The paper structure in the method section can be better organized to clearly show the components step by step \n3. The paper provides several remarks, and definitions but does not present more proof with detailed discussions. \n4. All of the above issues make this work hard to be reproduced. \n5. The experiments lack important baselines for comparison, such as instructzero [1] \n6. The ablation study can be further improved with more discussions. \n\n[1] Chen, Lichang, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou. \"InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models.\" arXiv preprint arXiv:2306.03082 (2023)."
            },
            "questions": {
                "value": "Most of questions are listed in the weakness section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3952/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698990817038,
        "cdate": 1698990817038,
        "tmdate": 1699636355632,
        "mdate": 1699636355632,
        "license": "CC BY 4.0",
        "version": 2
    }
]