[
    {
        "id": "p65M5la1mO",
        "forum": "Lxc4nBkJuq",
        "replyto": "Lxc4nBkJuq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7175/Reviewer_AzXU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7175/Reviewer_AzXU"
        ],
        "content": {
            "summary": {
                "value": "Theoretically, we illustrate how a purification system with randomness can cause gradient masking, which can not be addressed by the standard expectation-over-time (EOT) method. Experimentally, we verify that gradient masking indeed happens under previous evaluations of diffusion models. This paper studies an interesting phenomenon in the adversarial purification based on diffusion models. However, I am still concerned about the experiments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The idea of studying the connection between Diffusion-based adversarial purification and gradient masking is novel.\n2. The theoretical result provide some new insights."
            },
            "weaknesses": {
                "value": "1. I am not fully convinced by the experiments that the diffusion-based adversarial purification causes the gradient masking. Here, the problem is whether there is measure of the gradient masking phenomenon.\n2. The datasets are limited. Can the authors provide further experiments to verify their theoretical findings, i.e. performing experiments on other datasets, like Imagenet and MNIST?"
            },
            "questions": {
                "value": "See the question above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Reviewer_AzXU"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7175/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698569936390,
        "cdate": 1698569936390,
        "tmdate": 1699636851285,
        "mdate": 1699636851285,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sxV8aQeqlW",
        "forum": "Lxc4nBkJuq",
        "replyto": "Lxc4nBkJuq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7175/Reviewer_gWaG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7175/Reviewer_gWaG"
        ],
        "content": {
            "summary": {
                "value": "This paper theoretically reveals the phenomenon that purification system with randomness provides false sense of robustness. A method named \"randomness replay\" is further proposed to better estimate the robustness. Experiments on Diffusion Models verify the proposals."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The theoretical analysis is sound and easy to understand (e.g., illustration in Figure 1).\n- The paper is easy to read."
            },
            "weaknesses": {
                "value": "- The structure of the paper is somewhat confusing. Diffusion models and gradient masking appear and mentioned in Abstract and Introduction, but most of the theoretical analysis are irrelevant with them. \n- The experimental results shown in Tables seem weak. It will be better if more results are provided.\n\n- Overall, this work is based on the DiffPure framework and present its one limitation. Moreover, attack on a system with randomness has been sudied. Therefore, I think the novelty is limited.\n\n- Writing issue:\n   - \"Since the successful rate of applying the attack is the cdf of \u03c72(n), and n is the dimensionality of the data, which is typically very high for images (i.e., for CIFAR-10, n = 32 \u00d7 32 \u00d7 3 = 3072).\""
            },
            "questions": {
                "value": "- It is mentioned \"Gradient masking has been defined as \u201cconstruct a model that does not have useful gradients\u201d. Could you please explain how do you illustrate that a purification system with randomness can cause \"a model does not have useful gradients\"?\n- It seems that the theoretical analysis are general and can be used for any preprocess-based defense methods. Could you please discuss more about the difference between this analysis and related work? \n   - For example, Carlini etal. 2019 proposes \"Verify that attacks succeed if randomness is fixed.\". What is the difference between randomness replay and this method?\n\n- Could you please provide more explanation if the forward and reverse process in Diffusion Models? Why DiffPure proposed to utilize both the two processes while only use the reverse process is also workable?\n\n- Could you please explain that how does the observation that \"The reverse process indeed gradually removes the projection on the original adversarial direction...\" further support that \"forward process may not be useful for robustness\"? I think it will be better if you can also illustrate the forward process in Figure 4a."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Reviewer_gWaG"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7175/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698672704965,
        "cdate": 1698672704965,
        "tmdate": 1699636851107,
        "mdate": 1699636851107,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "PT8ydOkYoH",
        "forum": "Lxc4nBkJuq",
        "replyto": "Lxc4nBkJuq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7175/Reviewer_AHc3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7175/Reviewer_AHc3"
        ],
        "content": {
            "summary": {
                "value": "Besides generating stunning images, diffusion models have been shown to be very suitable defense for adversarial robustness, which later became an area of research called \"Adversarial Purification\". This paper first theoretically distinguishes the role of individual components: randomness (gradient masking) of synthesis process and learned generative prior. Then they experimentally (on CIFAR-10) show that previous adversarial purification methods rely on gradient masking. Finally they propose new method RevPure that better controls the effect of randomness, and thus provides better robustness. Interestingly, authors also found that denoising process in diffusion models is orthogonal to original perturbation."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) Solid theoretical analysis of the key mechanisms in diffusion-based adversarial purification methods. Illustrations and theorems are clear and interesting.\n2) Easy-to-follow writing with good introduction, motivation, related work, and theoretical methodology.\n3) Interesting observation that sequential denoising processes in diffusion models transform an adversarial example in the direction orthogonal to the original adversarial perturbation.\n4) Interesting finding that forward process of diffusion models is unnecessary for adversarial purification, although it was observed previously in DensePure."
            },
            "weaknesses": {
                "value": "1) The closest works (DiffPure, DensePure) validated their experiments not only on CIFAR-10, but on large-scale datasets such as ImageNet. To make the method closer to real world, ImageNet experiments are necessary.\n2) Only one architecture (WideResNet-28) is studied, while other works studied diverse set of architectures such as ViTs, ResNets, etc.\n3) Effect of generation quality of the model (FID) on the robustness is only studied using two models (EMA DDPM and Non-EMA DDPM). You can't conclude anything from two points. More diverse set of models (maybe checkpoints from different epochs) should be studied.\n\nMinor weaknesses:\n1) $\\chi^2$ should be properly introduced."
            },
            "questions": {
                "value": "1) \"Consider we run an adversarial attack on a dataset and get an accuracy of 80%. Assume the attack is perfect, thus we can always find an adversarial example if there exists one in the region, which is the ultimate goal for adversarial attack research. Then the accuracy means for 80% of the data, we manage to find at least one adversarial example within the region. Thus, the empirical robustness with a perfect attack is a good approximation of the absolute robustness\" \nCan you elaborate more on this example? What is accuracy here (accuracy of the model on perturbed data or attack success rate)? How based on first 3 sentences we can claim that empirical robustness is a good approximation?\n2) How does your method affect the inference time of the classifier?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Reviewer_AHc3"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7175/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698696679173,
        "cdate": 1698696679173,
        "tmdate": 1699636850974,
        "mdate": 1699636850974,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bs6Sf4Jx1k",
        "forum": "Lxc4nBkJuq",
        "replyto": "Lxc4nBkJuq",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7175/Reviewer_9RSr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7175/Reviewer_9RSr"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors revealed that diffusion models gain robustness from randomness, which causes gradient masking. They showed that randomness challenges the traditional expectation-over-time (EOT) method, leading to an overestimate of robustness. Addressing this, they proposed \"randomness replay\" for a more accurate robustness measure. They also found that robustness in diffusion models doesn't require a forward process; a reverse-only process is sufficient. Importantly, they demonstrated that diffusion models improve robustness by altering perturbed samples in a direction orthogonal to adversarial perturbations, thus weakening the strong attacks by removing the adversarial projections."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) The experimental results support the claim that randomness in the diffusion model can cause gradient masking, which cannot be addressed EOT method. The simple example in section 4.2 provides good intuition behind the claim.\n\n(2) The exploitation of the purification power of diffusion by removing the adversarial projection is novel and insightful for future work."
            },
            "weaknesses": {
                "value": "(1) The study, while insightful, falls short of providing fundamental theoretical analysis. The example in section 4.2 is overly specific, leaving a gap in the broader understanding. A more general, perhaps probabilistic, theoretical exploration of how randomness leads to gradient masking and how randomness replay enhances robustness would significantly strengthen the work. Additionally, a theoretical validation of the diffusion model's ability to remove adversarial projections would be a valuable addition.\n\n(2) The presentation of the theorems requires clearer explanations for each notation. For instance, in Theorem 1, the precise meaning of each symbol is unclear without delving into the proof. Providing meaningful explanations alongside the statement of each theorem would enhance comprehension."
            },
            "questions": {
                "value": "Can the authors explain why the diffusion model can remove adversarial projection? I believe this would be insightful for future work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7175/Reviewer_9RSr"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7175/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698794845878,
        "cdate": 1698794845878,
        "tmdate": 1699636850808,
        "mdate": 1699636850808,
        "license": "CC BY 4.0",
        "version": 2
    }
]