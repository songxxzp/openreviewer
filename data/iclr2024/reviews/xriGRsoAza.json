[
    {
        "id": "ebJKsudcJ3",
        "forum": "xriGRsoAza",
        "replyto": "xriGRsoAza",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3547/Reviewer_Yc2u"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3547/Reviewer_Yc2u"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a new framework that leverages Multiple Instance Learning to make deep learning TSC models inherently interpretable without compromising predictive performance. The authors evaluate MILLET on 85 UCR TSC datasets and show that it produces sparse explanations quickly and of higher quality than other interpretability methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The strengths of this paper include:\n\n1.\tIntroducing a new MILLET framework that makes deep learning TSC models inherently interpretable by leveraging the MIL approach without compromising predictive performance. In particular, the authors proposed exploring four MIL (attention, instance, additive and conjunctive) pooling methods to increase interpretability while replacing GAP. Moreover, including positional encoding ensures the modelling of time series constraints.\n2.\tProposing a new synthetic dataset called WebTraffic to explore the MILLET concept and evaluate the inherent interpretability of their models. The authors compared the four proposed MIL pooling approaches for MILLET with GAP on their WebTraffic dataset. Each pooling method is applied to the FCN, ResNet, and InceptionTime backbones.\n3.\tEvaluating MILLET on 85 UCR datasets and showing that it produces sparse explanations quickly and of higher quality than other interpretability methods. The authors found that \nwhile Conjunctive InceptionTime is the best approach for balanced accuracy (outperforming the HC2 and Hydra-MR SOTA methods), it is not quite as strong on the other metrics. However, it remains competitive, and for each backbone, using MILLET improves performance across all metrics. Moreover, the authors found that the Conjunctive has the best interpretability performance."
            },
            "weaknesses": {
                "value": "The major weaknesses are summarized below:\n\n1.\tThe paper does not provide a detailed comparison of MILLET with other state-of-the-art TSC models. Although the authors claim that \u201cWe design three MILLET DL models by adapting existing backbone models that use GAP: FCN, ResNet, and InceptionTime. While extensions of these methods and other DL approaches exist (see Foumani et al., 2023), we do not explore these as none have been shown to outperform InceptionTime (Middlehurst et al., 2023).\u201d the application of MILLET to other models and further comparisons with other state of the art TSC is missing and is relevant better to measure the effectiveness and generalizability of the proposed approach.\n\n2.\tThe paper does not provide a detailed comparison with other TSC interpretability methods. (e.g.LIME)\n\n3.\tThe paper does not provide a detailed algorithm complexity analysis. While the authors provide information on the run time of MILLET (see E.3), a more detailed analysis of the algorithm complexity would help establish its scalability and feasibility in large-scale applications."
            },
            "questions": {
                "value": "1.\tHow does MILLET perform with other TSC models?\n2.\tHow does MILLET compare with other TSC interpretability methods?\n3.\tCan you provide a more detailed analysis of the algorithm complexity?\n4.\tHave you considered the potential impact of the choice of hyperparameters on the performance of MILLET?\n5.\tHave you considered the potential impact of class imbalance on the performance of MILLET?\n\nAfter reading the author's rebuttal and discussions I am more incline to accept the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3547/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3547/Reviewer_Yc2u",
                    "ICLR.cc/2024/Conference/Submission3547/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3547/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698137126370,
        "cdate": 1698137126370,
        "tmdate": 1700642716268,
        "mdate": 1700642716268,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "thBfylEXdt",
        "forum": "xriGRsoAza",
        "replyto": "xriGRsoAza",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3547/Reviewer_uQF7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3547/Reviewer_uQF7"
        ],
        "content": {
            "summary": {
                "value": "The paper presents MILLET a model for Multiple Instance Learning for Locally Explainable Time series classification."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ The paper is well written and all the choices are justified and carefully explained\n+ The experimentation is deep\n+ The proposal is novel (to the best of my knowledge)\n+ The references are updated"
            },
            "weaknesses": {
                "value": "- I would have appreciated a comparison with LIME or with LIMESegments\n- I would have appreciated a comparison against ROCKET or MiniROCKET at least as competitor for the TSC task. Further usage of MILLETS also for ROCKET will completely fulfill the purpose of proposing this approach as a model-agnostic one.\n- To fully understand the paper the reader is constrained to refer to the Supplementary Material. A suggestion is to save some space and anticipate in the main paper some of the details of the Supplementary Material.\n- Experiments with the synthetic dataset should have been performed by varying the number of records, time stamps, classes."
            },
            "questions": {
                "value": "Questions can be derived from the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3547/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698227070856,
        "cdate": 1698227070856,
        "tmdate": 1699636308827,
        "mdate": 1699636308827,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4UnilFr9aX",
        "forum": "xriGRsoAza",
        "replyto": "xriGRsoAza",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3547/Reviewer_pSU6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3547/Reviewer_pSU6"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel intrinsically interpretable deep learning model. The authors framed time series classification as a Multiple Instance Learning (MIL) which can highlight the most influential time points in the outcome of the model. This method employs a various techniques such as attention, instance pooling, additive pooling, and conjunctive pooling across an ensemble of deep methods where each method offer different interpretability."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Nicely written. Well evaluated. Novelty."
            },
            "weaknesses": {
                "value": "I was not able to identify any weakness."
            },
            "questions": {
                "value": "Overall, this paper could be a significant algorithmic contribution and I think the authors done amazing job on presenting it. I wonder if the method can be applied to other domains."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3547/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698644393437,
        "cdate": 1698644393437,
        "tmdate": 1699636308750,
        "mdate": 1699636308750,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "K6OGLddFsF",
        "forum": "xriGRsoAza",
        "replyto": "xriGRsoAza",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3547/Reviewer_NeUd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3547/Reviewer_NeUd"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a framework based on Multiple Instance Learning to enhance the interpretability of time series classification models. The framework, MILLET, proposes passing the extracted feature embeddings from any backbone (e.g. FCN, ResNet) through a positional encoding, dropout, and a final pooling layer. Depending on the pooling structure, the method can make the underlying model more interpretable in some settings while also improving performance in others. The authors propose a new pooling method, conjunctive pooling, specifically for time series. MILLET is evaluated through the construction of 12 new models on 85 UCR datasets and a newly introduced synthetic dataset for interpretability evaluation. This approach represents a novel application of MIL to TSC and offers improved interpretability in various domains."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Thanks to the authors for their submission: it contains useful research that shows good research practices while explaining an interesting and novel idea within multivariate time series classification and interpretability. The results of this work will be informative to other researchers and are significant in improving our understanding of applying deep learning methods with time series. Some specific strengths of this research:\n\n- The Multiple Instance Learning presented in this work has more general applications within time series classification than previous work and provides a more robust evaluation of the benefits and drawbacks across a range of tasks, both synthetic and real.\n- MILLET model design adds very little complexity to existing models while contributing improved interpretability. It is flexible enough to work with any backbone model (FCN, ResNet, InceptionTime, and more) while maintaining performance. \n- The proposed synthetic dataset, WebTraffic, provides a helpful contribution to the task of benchmarking time series interpretability. With the ability to scale up to large sizes and the replication of a common time-series use-case it could be a helpful foundation to build-on in the future.\n- Performance of Conjunctive Pooling shows improvements across the class of neural network models for time series classification."
            },
            "weaknesses": {
                "value": "While the results and paper are generally strong, there are a few areas for improvement particularly as regards to interpretability claims:\n\n- Lack of comparison against previous benchmarks for saliency maps for feature attribution in time series classification from TSR [1], DynaMask [2], WinIT [3], and TimeX [4]. All of these works provide additional synthetic datasets for evaluating interpretability methods and show performance against more general methods like Feature Occlusion and Integrated Gradients. While MILLET seems like to improve on such methods due to the better computational efficiency, it is not thoroughly evaluated in the paper, except in counting the number of forward passes in the difference between SHAP, CAM, and MILLET.\n\n- Interpretability evaluation metrics. It is not clear that AOPCR and NDCG@n can be strictly ported over to the time-series setting. For example, as pointed out, with NDCG@n the time points in the middle of a region of missing data may be considered important by the ground truth, but may not be highlighted by the interpretability method, instead the beginning or end may be highlighted. These scores may be weighted differently for similar outcomes. More discussion around the impact of this is relevant to researchers.\n \n[1] https://arxiv.org/pdf/2010.13924.pdf \n[2] https://arxiv.org/pdf/2106.05303.pdf \n[3] https://arxiv.org/pdf/2107.14317.pdf \n[4] https://arxiv.org/pdf/2306.02109.pdf"
            },
            "questions": {
                "value": "These questions will help clarify my understanding of the paper. Some of these could benefit from additional analysis in the paper itself:\n\n1/ What is the author\u2019s intuition for the added performance of conjunctive pooling over other pooling methods?\n2/ In Figure 6, are the x\u2019s referring to different pooling methods for MILLET or multiple runs of the Conjunctive pooling model?\n3/ One of the most interesting things about the WebTraffic dataset is the different signatures grounded in real-world patterns. The authors note that the Conjunctive InceptionTime model identifies regions around Spikes and only the start and end of Cutoffs. Does classifier or pooling selection change how the interpretability functions or performs across these various class types? Can this tell us anything more about how the Conjunctive Pooling functions or why it performs better?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3547/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698825588840,
        "cdate": 1698825588840,
        "tmdate": 1699636308651,
        "mdate": 1699636308651,
        "license": "CC BY 4.0",
        "version": 2
    }
]