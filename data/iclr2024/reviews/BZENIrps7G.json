[
    {
        "id": "9leChtlq6Z",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6300/Reviewer_wYqY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6300/Reviewer_wYqY"
        ],
        "forum": "BZENIrps7G",
        "replyto": "BZENIrps7G",
        "content": {
            "summary": {
                "value": "Authors present the results of a new procedural fairness auditing framework for explainable AI tools by evaluating Stealth.\nAuthors audited Stealth\u2019s decision-making process outside of its notable performance outcomes.\nThe procedural fairness audit reports that Stealth\u2019s global surrogate models are impressive and a successful application of recursive bi-clustering for representative data downsampling."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The idea of procedural fairness, even if not completely clear, may be interesting."
            },
            "weaknesses": {
                "value": "Novelty of the paper is limited\nThe technical contribution of the paper is limited.\nThere is heavy repetition of know material.\nPaper is hard to grasp and read."
            },
            "questions": {
                "value": "It is not clear\n- the contribution of the paper\n- the novelty of the paper \n- the result that do not prove a point"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "none"
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6300/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697127492817,
        "cdate": 1697127492817,
        "tmdate": 1699636691962,
        "mdate": 1699636691962,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UPZtEBP1vY",
        "forum": "BZENIrps7G",
        "replyto": "BZENIrps7G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6300/Reviewer_VbpT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6300/Reviewer_VbpT"
        ],
        "content": {
            "summary": {
                "value": "This study conducts a procedural fairness auditing for Stealth's decision-making process. The findings indicate Stealth has several fairness issue."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The research question is interesting. Auditing the fairness of the decision-making process is crucial to ensure procedural fairness of ML decision-making."
            },
            "weaknesses": {
                "value": "The scalability of the proposed framework is a concern, as all the current conclusion and design is only from one case study of Stealth."
            },
            "questions": {
                "value": "What motivates the 11 questions in your framework?\nHow this proposed procedural fairness audit can be used for other AI-supported decision-making systems?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6300/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698842304180,
        "cdate": 1698842304180,
        "tmdate": 1699636691851,
        "mdate": 1699636691851,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GqqqXxxsB7",
        "forum": "BZENIrps7G",
        "replyto": "BZENIrps7G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6300/Reviewer_g6MX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6300/Reviewer_g6MX"
        ],
        "content": {
            "summary": {
                "value": "The article discusses the application of machine learning (ML) auditing, particularly focusing on procedural fairness in explainable AI (XAI) methods. Procedural fairness emphasizes the fairness of the decision-making process rather than the outcomes. The authors introduce a procedural fairness auditing framework applied to an XAI tool called Stealth, which integrates a novel global surrogate model with local explanations from LIME, aiming to be undetectable by deceptive models. The audit assesses Stealth's decision-making process independently from its performance outcomes. Findings show that while Stealth's global models and data downsampling techniques are effective, there are inherent biases in its training data. This leads to a critical examination of Stealth's fairness claims, which appeared to be skewed towards \"fairer outcomes\" rather than actual fair processes. The framework outlined in the study serves as a guide for ensuring procedural fairness in ML decision-making."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper provides a novel application of procedural fairness through an \"auditor-in-the-loop\" auditing framework. The iterative audit process allows for a more comprehensive evaluation of an AI system's decision-making process and fairness properties.\n2. The framework is a significant step forward in ML auditing because it focuses on the fairness of the decision-making process itself, rather than just the outcomes. \n3. The case study on Stealth exposes how its claims of \"fairness\" were misguided, demonstrating the importance of looking beyond metrics to truly evaluate procedural fairness."
            },
            "weaknesses": {
                "value": "1. The rationale for choosing Stealth as the tool to study procedural fairness could be clarified.\n2. The paper would benefit from being more self-contained. Currently, readers need to consult the cited Alvarez & Menzies (2023) paper and find the reference to Stealth in the abstract. Providing more context about Stealth (e.g., its Github link) within this paper would make it more accessible for readers.\n3. The audit relies on some evaluation results reported in the original Stealth paper without full independent verification. Reproducing those experiments could further validate the analysis."
            },
            "questions": {
                "value": "Please refer to the Weakness section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6300/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698890329301,
        "cdate": 1698890329301,
        "tmdate": 1699636691743,
        "mdate": 1699636691743,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xWqsU76Icr",
        "forum": "BZENIrps7G",
        "replyto": "BZENIrps7G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6300/Reviewer_VwFX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6300/Reviewer_VwFX"
        ],
        "content": {
            "summary": {
                "value": "The paper focuses on one particular explainable AI method, Stealth, and aims to present auditing results for procedural fairness. The paper is more of a meta analysis, instead of a detailed technical treatment. Empirical results are also presented."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper attempts to draw connection between two important topics: XAI and procedural fairness."
            },
            "weaknesses": {
                "value": "The weakness of the paper comes from the lack of organization of the material, as well as the unclear presentation of the problem of interest. The paper is not easy to follow. Multiple different topics are discussed at the same time. Readers can benefit from a more organized presentation, and a more developed solution towards the problem of interest."
            },
            "questions": {
                "value": "Q: what is the intended connection between XAI and fairness that authors would like to draw?\n\nSection 3 presents the motivation of case study. Section 4 lists multiple questions in procedural fairness audits. Section 5 introduces in detail the Stealth approach for XAI. Readers can benefit from a more organized way of presenting/investigating the connection between XAI and fairness. The current version invites more questions than answers, and the takeaway message is not clear."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6300/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698896950369,
        "cdate": 1698896950369,
        "tmdate": 1699636691639,
        "mdate": 1699636691639,
        "license": "CC BY 4.0",
        "version": 2
    }
]