[
    {
        "id": "CkwY17hDb2",
        "forum": "hC4GdMOqvU",
        "replyto": "hC4GdMOqvU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission984/Reviewer_Pvo6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission984/Reviewer_Pvo6"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an novel approach for predicting environment map under complicated circumstances by introducing knowledge distillation. Using the backbone of Neural-PIL, the proposed algorithm utilizes information acquired from Neural-PIL to form light distribution and stacked light probes under the guidance of the illumination MLP in order to calibrate the loss function. Experiments are conducted on NeRD dataset compared with several baselines, as well as checking the method with additional ablation studies."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method is simple, while the structure of which shows some interesting motivation and insights.\n2. The related work show section is concrete, which shows the necessary backgrounds of the field."
            },
            "weaknesses": {
                "value": "1. This paper\u2019s illustration of its proposed method is not sufficient. The author uses a simple verbal explanation of the methodology of the proposed method with overview graphs, without specific instructions on the detailed specification.\n\n2. One of my biggest concerns about this paper is its experiment, which is not convincing enough. All tests are only conducted on a single dataset, with some experimental results being either unsatisfying or missing.\n\n3. The section 3.2.3, which introduces stacking light probes, is vague and not well organized. For example, as illustrated in eq. 5, \u2018P\u2019 should be a vector with the size of 3, while it is interpreted as a (u,v) matrix in section 3.3.\n\n4. The experiment seems confusing to me. As shown in the paper, the results of the proposed approach are not good enough on the average scores compared with other baselines. For instance, the average scores of the proposed method on both metrics are not the best, while the score on PSNR is worse than that of NeRD and Neural-PIL(Ori.).\n\n5. When it comes to the statistics of specific classes, the results of NeRF and NeRD are not applicable. Considering that this dataset was originally been used by NeRD, it would be more suitable to test these baselines on every class in your tables and reproduce them if you lack these results in the Nerual-PIL\u2019s paper. If the reproduction is too time-consuming, you should find other baselines, as only one baseline is not enough to show your work\u2019s effectiveness.\n\n6. The reproduced results on Neural-PIL are much lower than the original ones. Please double-check your code\u2019s correctness to minimize this gap to an acceptable level.\n\n7. The title of NeRF misses an \u201cF\u201d in table. 2."
            },
            "questions": {
                "value": "What are the meanings of \u2018c\u2019 and \u2018c^(hat)\u2019 in eq. 6? Please make sure that every symbol in your equations is well defined."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission984/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698631803126,
        "cdate": 1698631803126,
        "tmdate": 1699636024501,
        "mdate": 1699636024501,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Pgc05HQGhR",
        "forum": "hC4GdMOqvU",
        "replyto": "hC4GdMOqvU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission984/Reviewer_nhSg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission984/Reviewer_nhSg"
        ],
        "content": {
            "summary": {
                "value": "This work improves the nvdiffrec method to decompose the object geometry, material and scene illumination given multi-view images with varying illuminations. The key strength is to optimize view-dependent environment maps during scene decomposition, and an illumination mlp to render environment maps under single input image with different illuminations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Extending nvdiffrec to a more practical scenarios with varied input illumination.\nA compact pipeline to achieve decomposition and rendering with varied illuminations."
            },
            "weaknesses": {
                "value": "Handling varied appearances has been widely investigated in NeRF methods, such as [1]. The problem from NeRF to [1] is very similar to the proposed method. Instead of comparing to NeRF, a very straight forward approach is to apply [1] (with only appearance embeddings), and render novel views for the task of novel view synthesis. And if we want to measure the accuracy of decompositions, we can also apply [1] to obtain for each training view the rendering under varied illuminations, and then apply nvdiffrec on the rendered training views (with adjusted illuminations) to obtain the final decomposition. I think missing this naive and straight forward baseline in the comparison makes the advantage of the proposed method unclear.\n\nI would increase my score if the above problem can be properly addressed.\n\n[1] NeRF in the Wild."
            },
            "questions": {
                "value": "N.A."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission984/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698638327905,
        "cdate": 1698638327905,
        "tmdate": 1699636024420,
        "mdate": 1699636024420,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zspZKp8yw8",
        "forum": "hC4GdMOqvU",
        "replyto": "hC4GdMOqvU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission984/Reviewer_cpaY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission984/Reviewer_cpaY"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce a novel method for the reconstruction and reflection decomposition in multi-view image collections under varying illumination. Starting with a construction process to determine geometry and material, they subsequently train an illumination MLP to predict the environment map from a target image. Their approach is based on nvdiffrec, in its first stage produces a triangular mesh, neural texture, and individual environment maps. This provides the groundwork for the second-stage training of the illumination MLP. The authors report improvements in performance over both synthetic and real datasets. Moreover, they accomplish this in a more time-efficient manner than other existing techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper extends nvdiffrec, which was initially intended for fixed lighting conditions. Their adaptation to varying lighting conditions presents a good step forward in the domain.\n2. Unlike many contemporary methods that deploy Gaussian spheres to approximate the integral of the incident light for reflection decomposition, this work explicitly represents the distribution of the light probe on a tensor that matches the environment map's size. This could potentially offer a more accurate representation of real-world scenarios.\n3. The method presented is more efficient in both the training and inference stages than alternative methods requiring iterative optimization. This efficiency is crucial for practical applications in real-world scenarios."
            },
            "weaknesses": {
                "value": "1. It's puzzling why the authors did not illustrate a direct comparison with other baselines (e.g. traditional, NeRF based, spherical gaussian based methods). Such a comparison could have provided a more comprehensive understanding of their method's advantages or shortcomings.\n2. The use of a physically-based simulation might occasionally omit details when generating the complete environment map from sampled light probes. This could be a potential direction for further research.\n3. The paper doesn't sufficiently address the generalization capability of their method across diverse scenarios. There is an underlying concern: is the proposed method mainly efficacious in scenarios where nvdiffrec performs well?"
            },
            "questions": {
                "value": "1.Are there any insights or preliminary results on how the method generalizes across different types of scenes or lighting conditions not covered in the datasets used?\n2. Can the authors comment on scenarios where nvdiffrec might not perform optimally and how this might affect the robustness of their proposed method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission984/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission984/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission984/Reviewer_cpaY"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission984/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821735718,
        "cdate": 1698821735718,
        "tmdate": 1699644285407,
        "mdate": 1699644285407,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NaXVtT6sYI",
        "forum": "hC4GdMOqvU",
        "replyto": "hC4GdMOqvU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission984/Reviewer_zAh2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission984/Reviewer_zAh2"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed a two-stage approach to learn a direct mapping from an image to its environment map.\nThe first stage involves learning the scene's geometry and texture as well as the environment map using a differentiable rendering framework (by using the established nvdiffrec framework).\nThe second stage trains an MLP to directly map a single image to its environment map by learning (distilling) from the model trained in the first stage.\nThe experiments show that the method is comparable to the state of the art in terms of PSNR and SSIM metrics on a few synthetic and real-world datasets while being much more efficient."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea of learning to directly predict the environment map given an image by distilling what has been learned in the first stage seems valid."
            },
            "weaknesses": {
                "value": "1. The writing of the paper could be improved. The first stage of the proposed method built on nvdiffrec, but it may still be useful to explain how the first stage works with more details. Section 3.1.1 lists the rendering equations, and section 3.1.2 explains how nvdiffrec is applied. But both sections missed the opportunity to explain clearly how the first stage works. For example, what's the loss function? How are the rendering equations Eq(1) and Eq (2) involved in the loss function? What are being optimized? Section 3.1.2 somewhat tries to explain what has been optimized in texts, but how does the reader relate the texts with the equations? Both Figure 1 and Figure 2 can use a more detailed caption.\n\n2. It's very hard to follow the description of stage 2. (1) Maybe a little motivation about Eq. 4 could help? (2) Section 3.3, I found it really hard to follow: \"where D_sample is the summation of the sampled light probes\u2019 distributions as in Equation 5 ...  D_total is calculated as a weighted average by the number of light probes from each direction\". Maybe show the equation of D_sample and D_total can help. The consistency of the notation could also be improved. In Eq. (5), subscript is used to indicate the sample index, and in Eq. (6), superscript (u, v) is used to indicate the sampling location.\n\n3. Experiments are not very thorough. The proposed method is mostly only compared against the reproduced Neural-PIL which has inferior performance compared to the original Neural-PIL as can be seen in Table 1 (original implementation registers average PSNR of 29.24 and SSIM 0.96 whereas the reproduced version has PSNR of 26.33 and SSIM 0.88). That said, it's not clear if the author's method is actually better than the original version of Neural-PIL. In Table 1, not sure why NeRF, NeRD, and Neural-PIL (Orig.) do not have results on Car Chair, and Globe datasets. In Table 2, \"NeR\" (typo? should be NeRF), NeRD, and Neural-PIL (Orig.,) do not have results on Gnome and MotherChild dataset. In Table 3, NeRF, NeRD, and Neural-PIL (Ori.) do not have results on Head, and Cape dataset."
            },
            "questions": {
                "value": "See Weakness section above, it can greatly help if the authors could clarify the method more -- especially the second phase which seems to be the main differentiator of the work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission984/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission984/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission984/Reviewer_zAh2"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission984/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699147293528,
        "cdate": 1699147293528,
        "tmdate": 1699636024278,
        "mdate": 1699636024278,
        "license": "CC BY 4.0",
        "version": 2
    }
]