[
    {
        "id": "4tsNLxvRk0",
        "forum": "PuRhqpBTmj",
        "replyto": "PuRhqpBTmj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2786/Reviewer_r3ea"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2786/Reviewer_r3ea"
        ],
        "content": {
            "summary": {
                "value": "n/a - The paper does not meet minimum standards for presentation quality."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "n/a - The paper does not meet minimum standards for presentation quality."
            },
            "weaknesses": {
                "value": "The paper requires significant improvements in presentation and it is currently nearly impossible to understand its contribution. \n\nThe following need to be defined formally in the main body of the paper: the M-score, when a concept is considered forgotten (how are CLIP embeddings used precisely?), ConceptBench, the loss function used for erasure. \n\nIn addition, the paper reads more like a sequence of jotted down notes without logical connections between most paragraphs. \n\nOverall, I believe the paper does not meet a minimum bar of presentability and, therefore, I cannot adequately review it and recommend a rejection."
            },
            "questions": {
                "value": "n/a - The paper does not meet minimum standards for presentation quality."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698442536599,
        "cdate": 1698442536599,
        "tmdate": 1699636221461,
        "mdate": 1699636221461,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UcAIT31h9b",
        "forum": "PuRhqpBTmj",
        "replyto": "PuRhqpBTmj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2786/Reviewer_Tnea"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2786/Reviewer_Tnea"
        ],
        "content": {
            "summary": {
                "value": "In response to the challenge of forgetting specific concepts, the proposed Forget-Me-Not, a cost-effective and efficient solution. This tool is designed to safely eliminate designated IDs, objects, or styles from a well-tailored text-to-image model in just 30 seconds, all while preserving its capacity to generate other content. In conjunction with the approach, two new metrics: the Memorization Score (M-Score) and ConceptBench were introduced. These metrics evaluate the model's ability to generate broad concepts, categorized into three main groups: ID, object, and style. By using M-Score and ConceptBench, Forget-Me-Not effectively removes targeted concepts while keeping the model's performance intact for other concepts."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Easy to implement and low computational cost.\n2. The introduction of the Memorization Score (M-score) and ConceptBench, quantitative instruments designed to evaluate the models' competency in both concept generation and exclusion."
            },
            "weaknesses": {
                "value": "1. There is no evaluation of CLIP scores and M-Scores of Previous methods such as ESD.\n2. As there is no theoretical justification for the method proposed, only qualitative evaluation with previous benchmarks is not enough. More quantitative evaluations need to be reported.\n3. More experimentation of different styles, and object removal should be done as shown in the previous methods."
            },
            "questions": {
                "value": "1. As per my understanding, the CLIP scores can be evaluated for the proposed method and ESD. Is there  any specific reason that it is not done?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698557597858,
        "cdate": 1698557597858,
        "tmdate": 1699636221394,
        "mdate": 1699636221394,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JcSZ95FEI5",
        "forum": "PuRhqpBTmj",
        "replyto": "PuRhqpBTmj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2786/Reviewer_hT3k"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2786/Reviewer_hT3k"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an innovative, cost-effective strategy for eliminating specific concepts or objects from text-to-image models. To assess the efficacy of the unlearned text-to-image models, the authors present the memorization score (M-score) and introduce the ConceptBench."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Exploring Concept Correction and Disentanglement offers a captivating avenue for advancing diffusion model unlearning.\n2. The introduced method is both efficient and cost-effective, streamlining the process.\n3. This paper presents a novel metric, the M-score, and unveil a new dataset tailored for evaluation purposes."
            },
            "weaknesses": {
                "value": "1. The manuscript lacks comprehensive descriptions of the algorithms, making it challenging to understand and replicate the proposed method.\n2. While the paper asserts that the introduced method can remove the target concept without affecting other concepts, it does not provide any experimental evidence to support this claim.\n3. The paper does not offer a quantitative analysis specifically on the nudity concept. I recommend utilizing NudeNet as a nudity detection tool and employing a subset of the I2P dataset for a more robust evaluation."
            },
            "questions": {
                "value": "There exist adversarial attacks targeting unlearned diffusion models. These attacks challenge the robustness of these models by asserting that they remain vulnerable. Specifically, attackers can manipulate the unlearned diffusion models to produce images with concepts purportedly unlearned. This is achieved by appending or inserting adversarial text tokens, thereby raising concerns about the model's safety and efficacy."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698806604550,
        "cdate": 1698806604550,
        "tmdate": 1699636221250,
        "mdate": 1699636221250,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Egrk0YrtUg",
        "forum": "PuRhqpBTmj",
        "replyto": "PuRhqpBTmj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2786/Reviewer_Kf75"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2786/Reviewer_Kf75"
        ],
        "content": {
            "summary": {
                "value": "This work focuses on unlearning specific targeted concepts from large pre-trained diffusion models. The approach used by the paper minimizes the attention map activation for a target concept, and updates the parameters accordingly. Two metrics, M-score and CLIP score are used to measure how well the model has forgotten a concept. In addition, the work proposes a benchmark named ConceptBench to check how well models can forget specific concepts such as objects, identities and styles."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This work focuses on a timely and important topic. With ongoing debate regarding copyrights and regulation for generative models, how specific (copyrighted) concepts can be deleted from generative models is highly relevant.\n2. The proposed approach seems reasonable and is easy to understand intuitively. The approach also seems to be faster, and less cumbersome than prior approaches that require other concepts as \"anchors\" [1].\n\n[1] Kumari, Nupur, et al. \"Ablating concepts in text-to-image diffusion models.\"\u00a0_Proceedings of the IEEE/CVF International Conference on Computer Vision_. 2023."
            },
            "weaknesses": {
                "value": "1. The writing quality of the paper is not good.  Generally, the paper also uses difficult prose in several places and this decreases the quality of the paper significantly. Also, it would be good to provide references to the different sections using hyperlinks. There are several typos, confusing language, and misplaced citations. For example in the first paragraph of the introduction itself:\n- Midjourny -> Midjourney \n- The citation, Somepalli et al. seems misplaced. The paper has nothing to do with the sentence.\n\nOverall, the paper would require a significant rewrite. \n\n2. It's unclear how to understand the proposed metrics for ConceptBench used by the paper.\n\t- What would qualify as a good M-score or CLIP score after forgetting? Conceptually while decrease in the score is good, it's unclear if too much decrease implies catastrophic forgetting with respect to the concept. \n\t- How many samples are generated from the diffusion models to compute these scores? \n\t- How is it measured that the model doesn't forget concepts \"drastically\"? For example forgetting \"Elon Musk\" should still generate a human with face unlike Elon Musk. As far as I can understand, none of the metrics capture coherent generations after forgetting a concept."
            },
            "questions": {
                "value": "1. Are there fundamental issues that can arise by using attention resteering loss? Does the generation's alignment to any prompt start degrading when multiple concepts are forgotten?\n2. How is model performance such as CLIP accuracy on similar concepts after removing a concept? This metric can be used to ensure the model fidelity is not deteriorated [1]. \n\n[1] Kumari, Nupur, et al. \"Ablating concepts in text-to-image diffusion models.\"\u00a0_Proceedings of the IEEE/CVF International Conference on Computer Vision_. 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2786/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2786/Reviewer_Kf75"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699500699160,
        "cdate": 1699500699160,
        "tmdate": 1699636221175,
        "mdate": 1699636221175,
        "license": "CC BY 4.0",
        "version": 2
    }
]