[
    {
        "id": "59QKIWoz09",
        "forum": "j1SktNMHA7",
        "replyto": "j1SktNMHA7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4690/Reviewer_4KU5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4690/Reviewer_4KU5"
        ],
        "content": {
            "summary": {
                "value": "Intuitively, as data augmentation introduces more data, the annotations for this additional data must be adapted beyond the one-hot label. The author utilizes label smoothing to produce labels for the augmented data, specifically estimating confidence levels based on perturbation levels. To assess the effectiveness of the proposed technique, the authors carry out both empirical and theoretical analyses. They show that the method results in an expanded decision boundary and flatter minima. Furthermore, empirical tests on four benchmarks reveal performance enhancements using the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The studied problem is important and the proposed method is reasonable. \n2. The author conducts both empirical analyses and theoretical analyses to demonstrate the effectiveness of the proposed method. \n3. Ablation studies have been conducted to assess the contribution of different components."
            },
            "weaknesses": {
                "value": "My major concern for this study is the lack of a proper baseline in the experiment section. \nSpecifically, the authors mainly conduct experiments by applying SPIDER to four different settings (no aug. AugMix, DeepAug, PixMix) and make comparisons with the original setting. \nAs the proposed method is an improvement over label smoothing, I think it is necessary to make comparisons with the original label smoothing method. \nFor example, one reasonable baseline is to add the same constant label smoothing to all images in the original setting."
            },
            "questions": {
                "value": "I find the title to be a bit misleading. I feel the word \"rethinking\" implies the study sheds insights into the mechanism of label smoothing, while the study mainly focuses on adapting label smoothing to the augmentation-based methods. I would suggest the author change it to a different word. \n\nI think the related work on estimating the label distribution/uncertainty is highly related to this study and would suggest the authors discuss this connection[1,2]. \n\n1. Towards Understanding Ensemble, Knowledge Distillation, and Self-Distillation in Deep Learning\n2. Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4690/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698431287900,
        "cdate": 1698431287900,
        "tmdate": 1699636450810,
        "mdate": 1699636450810,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wUmo17E3Fz",
        "forum": "j1SktNMHA7",
        "replyto": "j1SktNMHA7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4690/Reviewer_Gg61"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4690/Reviewer_Gg61"
        ],
        "content": {
            "summary": {
                "value": "In this paper, a new form of label smoothing technique named SPIDER is introduced, which connects data perturbation strength with smoothing confidence of true labels. Authors measure improvements of SPIDER by reflection of changes in flat minia and boundary thickness, with theoretical proof and empirical results. Additionally, SPIDER effectively enhances performance on robustness benchmarks, e.g., common corruptions, and L2 adversarial robustness."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method, SPIDER, is concise and effective.\n2. Authors provide detailed theoretical proof and validate theories with sufficient empirical experimental results. SPIDER effectively enhances robustness models without hurting the clean accuracy."
            },
            "weaknesses": {
                "value": "1. SPIDER can be considered a variant of LS. In the meantime, standard LS can be seen as a specific example of a monotonically decreasing function (yet without a clearly defined definition in the paper). Nevertheless, it remains unclear whether and why SPIDER outperforms standard LS. The results shown in Table 6 demonstrate that standard LS actually performs worse than the baseline in terms of mCE metrics, which raises my doubts about whether the thickness of boundaries is necessarily linked to robustness against common corruptions. Also,  there is a lack of comparisons between standard LS and SPIDER in Tables 1-5 and Figure 2.\n2. SPIDER improves flat minia compared with ''No LS'',  yet not to a sufficiently large extent. The empirical evaluation in Figure 2 indicates that compared with SPIDER, Augmix achieves flatter minia.\n3. Multiple previous works have explored strategies for improving flat minia and boundary thickness, e.g., noisy mixup[1], HAT[2]. However, authors do not include them as baselines to compare.\n\n[1] Boundary thickness and robustness in learning models, Yang et al. NeurIPS 2020.\n[2] Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off, Rade et al. ICLR 2022."
            },
            "questions": {
                "value": "Please refer to weakness first, an additional question is listed below.\n1. In Table 6,  ''No LS'' corresponds to adversarial training with noise bounded with L2 norm and outperforms the baseline. I am curious about the outcomes when perturbations are applied while employing standard label smoothing, which more rigorously demonstrates the gap between standard LS and SPIDER"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4690/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4690/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4690/Reviewer_Gg61"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4690/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698679922303,
        "cdate": 1698679922303,
        "tmdate": 1699636450729,
        "mdate": 1699636450729,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wym27Aai8M",
        "forum": "j1SktNMHA7",
        "replyto": "j1SktNMHA7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4690/Reviewer_DLcS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4690/Reviewer_DLcS"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes \"SPIDER\", an adaptive label smoothing method with regard to the input perturbation intensity. More specifically, SPIDER perturbs input $x$ to $x + \\delta$; the intensity of the target true label is defined as $s( \\| \\delta \\|)$ where $s( \\cdot )$ is a monotonically decreasing function. There are two theoretical results for the proposed method\n- SPIDER increases boundary thickness (Yang et al) -- for any monotonically decreasing smoothing function $s( \\cdot )$. This result holds for an optimal solution of each optimization method (SPIDER vs. perturbation only). Note that this result does not include comparisons between SPIDER vs. vanilla label smoothing vs. the non-perturbed version of SPIDER. Also, this result is orthogonal to the choice of $s$ where SPIDER uses an exponential decay function.\n- SPIDER encourages flat minima (defined as the worst case loss function following Cha et al) where the theorem holds for a linear classifier with softmax activation. As far as the reviewer understood, this theorem showed that the solution space with input perturbations is a subset of the \"flat\" solution space; Again, this theorem is invariant to the choice of $s$ and, even invariant to label smoothing.\n\nExperimental results include that (1) empirical boundary thickness on CIFAR-10/100 for non-SPIDER methods, SPIDER methods and input perturbation only methods, (2) empirical flatness on CIFAR-10/100 for non-SPIDER methods and SPIDER methods and (3) CIFAR-10/100, Tiny-ImageNet and ImageNet results with corrupted images, PGD attack and clean accuracy."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "As far as the reviewer understood, the theoretical contribution of this paper is non-trivial. Note that I did not have enough time to understand the whole theorem thoroughly (especially, I couldn't check whether any error is in the proof, as well as any non-trivial assumption is in the proof), but I just skimmed the main proof techniques, and statements. Although the theorems cannot explain the design choice of the proposed method (e.g., exponential $s$), I think the theorems could be helpful in understanding the effects of label smoothing on boundary thickness and the input perturbation for flatness."
            },
            "weaknesses": {
                "value": "Many important details are missing in the main text. Even worse, although information is provided in the Appendix, there is no pointer in the main text (even at the beginning of the Appendix). Therefore, just reading the main text only provides very limited information. While reading the paper, I frequently faced trouble to understand the text. For example, there is no definition of $c$ in the main text, where the definition is introduced in E.1.1. The main text also did not provide detailed information on which architecture is used for the experiments, as well as optimization hyperparameters. I also think that in terms of the presentation, this paper has a large room for improvement. The current version is very difficult to understand.\n\nFor the theoretical results, I think each theoretical result needs nontrivial effort, but the link between the proposed method and the theoretical results is unclear to me. First, none of the theorems can explain the design choice of $\\delta$ and $s$ which looks very complicated and requires two hyperparameters. If the theorems cannot explain the design choice, there should be an extensive ablation study for the choice of $\\delta$ and $s$. Second, the second theorem is orthogonal to label smoothing but only depends on input perturbations. Considering that the second theorem needs a very limited situation (linear classifier), I think that it will be great if the second theorem is more related to the proposed method. Also, the reviewer presumes that the theorems also hold when $s$ is a constant function, i.e., the vanilla label smoothing. Please check my question in the below section.\n\nSimilarly, I think this paper needs more extensive empirical justification. For example, Theorem 1 shows that a scenario with perturbed input with monotonically decreasing label smoothing satisfies better thickness than vanilla training, and Theorem 2 shows that the solution space with the input perturbation is a subset of the \"flat\" solution space. These theorems do not show that the proposed method is an optimal method for solving each task (thickness, flatness), or better methods than other methods. Hence, I think this paper should compare the proposed method with other regularization methods. I doubt that increasing boundary thickness or flatness is a special property of the proposed method. For example, Yang et al. showed that L1 regularization, L2 regularization, large learning rate, early stopping, and cutout increase boundary thickness empirically. It may imply that a proper regularization method tends to increase boundary thickness. It means that, although this paper shows some theoretical results, it does not guarantee that the proposed method is actually a better method than other regularization methods.\n\nIn terms of the empirical contribution, the proposed method always needs input perturbations. Although adding an input perturbation is helpful in terms of theoretical properties, I think it limits the usage of the method to the recent state-of-the-art methods. For example, recent SOTA methods employ many strong augmentations, such as RandAug, many strong image view manipulations or mixed data sample augmentations (e.g., Mixup, CutMix). It is unclear whether the proposed method and the recent strong augmentations can work at the same time.\n\nFinally, I think that the experimental results are based on very few baselines and weak backbones. A weak network has a large room for improvement, which could be a just issue of optimization. For example, as shown in \"ResNet strikes back: An improved training procedure in timm\", a different optimization setting invariant to other improved techniques can boost the performance by about +4%p for ResNet-50. Similarly, in the ImageNet classification field, it is important to show the generalizability of the method for various backbones, rather than a specific backbone. In terms of the comparison methods, the method should be compared with other methods targeted to robustness, such as Mixup, CutMix and ANT. There can be more related works to the generalizability, but I think this method should be compared to data augmentation methods and many label smoothing variants rather than the proposed design choice."
            },
            "questions": {
                "value": "Please check my comments on weakness. I have additional questions:\n\n- I wonder if theorem 1 holds when $s$ is a monotonically non-decreasing function as well, for example, a constant function. It will make $\\gamma_j$ is a constant function. From my gut feeling, Theorem 1 also holds for a constant function because a constant function is also a monotonic function, and the proofs only use the property of a monotonic function. If this is true, it means that Theorem 1 is also true for input perturbation + vanilla label smoothing; it will weaken the justification of the adaptive label smoothing because Theorem 2 is irrelevant to the adaptive label smoothing.\n- Thm 4 subscription seems to be a typo. Maybe it is not $\\cup_{i\\in [n]}$, but $\\cup_{R_i\\in [n]}$, considering the Appendix.\n\nOverall, I think this paper needs a non-trivial revision in the presentation (to make the submission clearer and self-contained), in empirical supports for each theorem, in the link between the theorem and the method, and the empirical contribution of the method."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4690/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4690/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4690/Reviewer_DLcS"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4690/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698778451376,
        "cdate": 1698778451376,
        "tmdate": 1700732661040,
        "mdate": 1700732661040,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "y7amTAKozY",
        "forum": "j1SktNMHA7",
        "replyto": "j1SktNMHA7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4690/Reviewer_M1mD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4690/Reviewer_M1mD"
        ],
        "content": {
            "summary": {
                "value": "This paper targets the problem of training robust neural networks on image datasets. To achieve this, the authors propose to use data augmentation for input images as well as label smoothing for augmented images. Specifically, a new perturbation function for augmentation sampling and a label smoothing function are proposed to augment input images and labels. Experiments on some image datasets show that compared with no augmentation and previous input data augmentations, the proposed method is capable of increasing robustness in terms of common corruptions and adversarial attacks."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "(1) The paper is well written and easy to follow.\n\n(2) This work presents two new techniques, a perturbation function for augmentation sampling and a label smoothing function. The proposed new technique is supported by the findings that smoothed labels can increase boundary thickness and input perturbations are related to parameter perturbations in the linear case, which can facilitate flatter minima through empirical verification."
            },
            "weaknesses": {
                "value": "(1) It is mentioned in the manuscript that robustness is important in terms of different kinds of distributional shift including domain shift. I understand that the main goal is to mitigate perturbations, but according to the description of the corruption types in the appendix, it seems that some corruptions are quite strong and humanly perceptible. Therefore, the robustness with respect to domain shift also worth studying but such experiments are missing. It is also mentioned in section 3.3.1 that flat minima, which can be achieved by the proposed method according to both theoretical and empirical verifications, can improve robustness with respect to domain shift, but this is not empirically verified for the proposed method.\n\n(2) The proposed method can also improve robustness with respect to adversarial attacks. However, there is no comparison with other popular adversarial learning algorithms.\n\n(3) If I\u2019m understanding correctly, the main baselines used in the experiments are pure image-based augmentation strategies. Class labels are not used in these baselines for augmentation. In my opinion, it is possible to incorporate augmented labels for these baseline methods as well. For example, it could be labels with reduced confidence for the ground-truth class for augmented images. It seems that comparing with these non-label augmentations looks unfair for the proposed label-smoothing method as it can leverage more information. Apart from this, ablation results in Table 6 do not show universal improvements under each component.\n\nOther questions and minor issues: \n\n- In the empirical verification of the flatness of SPIDER, I\u2019m not sure how good the models are in Figure 2. What are the final accuracies of these models and are they the same models used to report the performance in Table 3?\n- I understand that the theoretical properties for input perturbations in the non-linear case is difficult to handle. The provided results in the linear case may not hold for deep neural networks and they are not rigorously connected with the real experiments."
            },
            "questions": {
                "value": "See weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4690/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698831636600,
        "cdate": 1698831636600,
        "tmdate": 1699636450582,
        "mdate": 1699636450582,
        "license": "CC BY 4.0",
        "version": 2
    }
]