[
    {
        "id": "OzYnWkH1sF",
        "forum": "tth2qXY7RU",
        "replyto": "tth2qXY7RU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4943/Reviewer_gb1N"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4943/Reviewer_gb1N"
        ],
        "content": {
            "summary": {
                "value": "This work introduces the super floating-point format (SuFP) which uses a piece-wise quantizer that better fits the standard distributions shown in modern deep neural networks. It defines these three modes for representing three regions of values and demonstrates that they outperform recently proposed floating-point formats. They evaluate across vision, language, and text-to-image models and show lower memory, area, and power than other approaches."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Figure 3 and Figure 4 clearly show the different data modes and hardware outlines.\n\nThis work includes evaluations across vision, language, and text-to-image models.\n\nThis work also evaluates the efficiency of its method across many performance categories."
            },
            "weaknesses": {
                "value": "Form 3 seems strange since by its bitwidth alone it seems to be strictly worse than Form 3. Does the different bias matter here?\n\nThe advantage of supporting difficult modes is not clear when the PEs seem to need to process the largest exponent and mantissas. It might be useful to show where the coverage is for each mode in a figure similar to Figure 2.\n\nWhat is the definition for exponent baseline? Initially I thought the exponent would be added to these but the baseline for mode 2 includes the exponent bits themselves.\n\nThe paper seems to over-sell itself in many places and that space could be used to add more detail.\n\n-- Minor --\nIt would be clearer to show the bitwidth in the formats in the tables since these comparisons are across 32, 16, and 8 bits.\n\nEquation 1 can could be explained better in the text. For example, are the X elements an arbitrary tensor? It is unclear what the purpose of this equation is overall\n\nEquations 2-5 could be aligned to make them more readable."
            },
            "questions": {
                "value": "Are there any additional floating-point quantization scale factors with this method? FP8 method often still use additional higher-precision quantization scales still.\n\nWhat is the typical distributions of the SuFP modes? To justify sacrificing the bitwidth to handle different modes, it would be useful to see how often the modes are needed. The encoding seems to be a variable-bitwidth encoding so does it reflect the mode distribution? Does mode 3 show up the least often?\n\nWhat FP8 variant is used for comparison? E4M3 typically has the highest accuracy.\n\nWhy not show all the formats for each category evaluation? Formats like BF16 should be simple to evaluate in the PyTorch setup for each and there is significant room in the tables.\n\nWhy is the BSFP datatype only 7 bits in Figure 2 while the others are 8 bits?\nWhat granularity does the method operate at? For example, the bias is shared per tensor but since distributions cluster in channels why not make it shared per channel? The hardware diagram seems like there can potentially be bias per 16 elements. Is this true? Also, it seems possible to share the mode over a block of data depending on the variation there.\n\nThe ALU seems like it is purely doing standard floating-point multiplication? Or does it support additional functionality to justify its name?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4943/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817767313,
        "cdate": 1698817767313,
        "tmdate": 1699636480654,
        "mdate": 1699636480654,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cg4Sj3L4dF",
        "forum": "tth2qXY7RU",
        "replyto": "tth2qXY7RU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4943/Reviewer_CpEu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4943/Reviewer_CpEu"
        ],
        "content": {
            "summary": {
                "value": "To solve the huge dynamic ranges for outliers problems in quantization, this paper introduces a new data type and corresponding quantization method to improve both memory footprint and logic efficiency. The key idea of SuFP is multi-region piecewise\nquantization using a tensor-wise scalable bias which offers flexible adaptability to diverse data distributions. Furthermore, the tailored\nhardware for SuFP is also provided which employs only integer arithmetic units and shifters. The evaluation has been processed in different tasks, such as vision, language, and generative models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Good writing style. The paper is easy to follow.\n2. The paper focuses on a great problem of quantization \"outlier\" which is critical to the quantization accuracy.\n3. Multiple tasks are included in the experiments, which proves the method's flexibility.\n4. The works incorporate both the algorithm with the hardware into consideration."
            },
            "weaknesses": {
                "value": "1. The paper mainly compares different quantization schemes but does not incorporate different quantization frameworks in the experiment comparisons. \n2. The hardware setup details are not clear.\n3. The hardware efficiency evaluation only provides a normalized result without a specific number, which may cause additional difficulty for future works' comparison."
            },
            "questions": {
                "value": "Please refer to the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4943/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4943/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4943/Reviewer_CpEu"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4943/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699240387146,
        "cdate": 1699240387146,
        "tmdate": 1699636480579,
        "mdate": 1699636480579,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4zNU6GdHd6",
        "forum": "tth2qXY7RU",
        "replyto": "tth2qXY7RU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4943/Reviewer_tqWQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4943/Reviewer_tqWQ"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new data type, Super Floating-Point (SuFP), to improve both memory footprint and computational efficiency for deep neural network quantization. SuFP utilizes multi-region piecewise quantization with tensor-wise scalable bias, allowing for optimized precision for different data regions and adaptability to various data distributions. Experiments show that compared to FP8, SuFP achieves 1.58x and 1.30x improvement in computational capability and energy efficiency, respectively, without losing model accuracy performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The paper is well-written and easy to follow. Illustrative figures are well plotted and easy to understand.\n+ Co-designing the hardware MAC architecture for the proposed data type SuFP enables better hardware efficiency.\n+ The evaluation benchmarks are diverse, including both vision and language tasks."
            },
            "weaknesses": {
                "value": "+ The ablation study lacks the improvement breakdown on piecewise data representation and tensor-wise scalable bias.\n+ The accuracy evaluation experiments lack results on MSFP and BSFP for larger models (Table 3). The efficacy of the proposed SuFP on Large Language Models such as LLaMa2 is also unclear.\n+ The proposed SuFP saves 6% memory, with 1.05x throughput improvement and 1.03x energy savings over MSFP (MX9). The improvement is marginal.\n+ MSFP have multiple versions: MX4, MX6 and MX9. It is unclear how SuFP narrows its bit width."
            },
            "questions": {
                "value": "Please answer the questions in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4943/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699320807994,
        "cdate": 1699320807994,
        "tmdate": 1699636480470,
        "mdate": 1699636480470,
        "license": "CC BY 4.0",
        "version": 2
    }
]