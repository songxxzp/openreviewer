[
    {
        "id": "T0ft37cVZE",
        "forum": "2XwBIcywWM",
        "replyto": "2XwBIcywWM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3902/Reviewer_4tVC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3902/Reviewer_4tVC"
        ],
        "content": {
            "summary": {
                "value": "This paper considered test domain adaptation, where this paper considered variational latent labels (through a latent variable w) to better estimate pseudo-labels in the test time. Through a variational objective and meta-learning framework, different variables such as latent auxiliary variable (w_t) and target pseudo-labels (\\hat_y_t) are estimated. \nFinally, the model is deployed in standard benchmarks with improved performance.\n\n========Post rebuttal\n\nThanks for the rebuttal. I would think paper still needs major revisions to improve the clarity."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper considered a reasonable solution in test time domain generalization. Through better estimating pseudo-labels, this paper obtained better results in different benchmark dataset."
            },
            "weaknesses": {
                "value": "The main issue in this paper is the **clarity** part. This paper considered probabilistic method and variational inference. Many parts are not clear or seemingly not correct in my viewpoint. I do think a major revision is required for the resubmission. \n\n1. As for the graphical model in Fig 1, I feel quite confused at first glance. In fact, it is not a real probabilistic graphical model for the data, but rather a model/data interaction graph. I think this should be clarified for the potential misunderstanding. \n\n2.  Could authors provide detailed explanations on the followings:\n\n  (1) How to estimate the following conditional probabilities?\n-  P_\\phi (w_t | X_t, \\theta_s)\n- Why is a data batch written as a random variable X_t? \n- q_\\phi (w_t | X_t, Y_t \\theta_s)\n- We never observed Y_t, right ?\n\n(2)  What is the rationale of meta-generalization? What is the corresponding graph?\n\n(3) If a model parameter is updated through gradient descent like equation (11), it should not be considered as a formal variational inference. Indeed, the gradient flow could make it hard to construct a probabilistic term. \n\n3. I still could not understand the specific reason to use variational inference based methods. I think many math equations could be replaced by deterministic updates and significantly simplified. \n4. The quality of pseudo-label is still unknown and hard to understand. Why could such a method improve the pseudo quality? When will it happen?"
            },
            "questions": {
                "value": "See the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Reviewer_4tVC"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3902/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698283233722,
        "cdate": 1698283233722,
        "tmdate": 1700858065219,
        "mdate": 1700858065219,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vnQg69aH0i",
        "forum": "2XwBIcywWM",
        "replyto": "2XwBIcywWM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3902/Reviewer_CA6h"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3902/Reviewer_CA6h"
        ],
        "content": {
            "summary": {
                "value": "In the presented paper, the authors advocate for domain generalization by developing models trained meticulously on source domains and subsequently deploying them on unexplored target domains. The authors unfold their contributions through strategies like probabilistic pseudo-labeling and meta-generalization stages, which seem instrumental in optimizing the performance of source-trained models when introduced to target domains.\n\nThe paper claims superior algorithmic performance in comparison to preceding methodologies. Experiments conducted seem to underpin the effectiveness of the proposed strategies, attesting to their potential relevance in domain generalization. \n\nDespite its merits, the paper's exposition of integrating uncertainty with meta-generalized neighborhood information appears somewhat ambiguous. While leveraging neighborhood information for generalization has been a commonplace strategy in prior studies, the paper could benefit from a clearer elucidation of the novelty in their approach, particularly concerning the integration of uncertainty.\n\nFurthermore, the validation scope of the proposed model seems narrowly focused, lacking a diverse spectrum of benchmarks for thorough evaluation. Inclusion of broader benchmarks could enhance the rigor of the validation process, presenting a more holistic view of the model\u2019s adaptability and performance across varied scenarios. Such an extended validation would embolden the research\u2019s integrity, offering a more comprehensive insight into its applicability and effectiveness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- **Superior Performance:** The authors have claimed that the proposed algorithm outperforms previous methods, showcasing its effectiveness and superiority in achieving enhanced results in the conducted experiments and evaluations."
            },
            "weaknesses": {
                "value": "- **Ambiguity in Contribution regarding Meta-generalization and Uncertainty Utilizing Neighborhood Information:** Table 1 suggests that meta-generalization is the key step. The utilization of neighborhood information with uncertainty as a tactic for generalization is not novel. Such strategies have been previously explored and applied in various studies. The paper should explicitly articulate the unique contributions made in terms of incorporating uncertainty with meta-generalization. Delineating how uncertainty with meta-generalization has been applied or integrated in this study as a key contribution is essential for understanding the paper's novelty and significance.\n\n- **Limited Validation:** The paper lacks extensive validation across a diverse range of benchmarks. Including additional benchmarks such as **STL10, CIFAR10-C, or CIFAR100-C, etc..** at least would strengthen the evaluation process and enhance the generalizability and applicability of the proposed model. **For this exercise, I suggest not to utilize other corrupted domains for CIFAR10-C or CIFAR100-C, then, it's a good validation of the proposed algorithm with single source domain input with unseen target samples.** i.e., $S=1$ in Algorithm 1. For this validation, it doesn't have to show superior performance, but such an expansion in validation datasets would provide a more comprehensive and rigorous assessment of the model's performance and robustness in various scenarios, helping to establish its efficacy and reliability more convincingly."
            },
            "questions": {
                "value": "- **Regarding meta-generalization training, does the process utilize information from the target domain \"training\" samples?** This critical question arises due to a statement on page 4, page 5, and Algorithm 1 mentioning the accessibility of actual labels of the meta-target data during training. I need confirmation and understanding this aspect is essential for assessing the generalizability and **the source of superior performance** of the proposed algorithm.\n\n- What advantages does meta-generalization offer when compared to a general domain adaptation, including source-free domain adaptation? For example, SHOT (Liang et al. 2020) is a source-free domain adaptation. The meta-generalization steps require the leverage of various source domains. Could the authors elucidate the unique benefits that meta-generalization brings to enhance the model's performance or adaptability in domain generalization tasks? This clarification would help in understanding the specific improvements or innovations that meta-generalization contributes beyond the capabilities of existing source-free domain adaptation approaches. **I suggest providing a more detailed and concrete discussion of the benefits of the proposed method beyond what is explained in Section 4.** For example, it's better to include the ablation study regarding hyperparameters of $\\lambda_1,\\lambda_2,\\lambda_3$ indicating the contribution of each factor.\n\n- For the update of the variational neighbor label generator, could the authors clarify the rationale behind employing the difference of two losses in $L_{CE}-\\mathcal{L}_{meta}$? I am curious about the motivation for the negative sign of meta loss.\n\n- Could the authors elaborate on why there is a **noticeable performance degradation in the Office-Home dataset** as shown in Table 3, especially when compared to the results reported by Xiao et al. (2022)? An explanation regarding this discrepancy would be helpful for a more comprehensive understanding of the algorithm\u2019s performance across different datasets.\n\n- Algorithm 1 indicates the use of $n$ samples for each domain. Could the authors provide guidance on how to effectively balance these samples across various domains to ensure a harmonized and representative dataset for each domain involved?\n\n- Are there any other hyper-parameters, aside from the learning rates $\\lambda_1, \\lambda_2, \\lambda_3$, that are crucial in the model's implementation and performance? \n\n- For further validation of the proposed algorithm, consider including **exercises in single source domain generalization**. Utilizing additional benchmarks, such as STL10, CIFAR10-C, or CIFAR100-C, would not only strengthen the evaluation process but also enhance the model's **generalizability** and applicability. Specifically, applying the algorithm in scenarios with a single source domain input and unseen target samples could provide a comprehensive validation of its effectiveness and robustness. For example, if the target domain is highly distorted (like some of the corruptions in CIFAR10/100-C), the selected hyperparameters might not suit the (unseen) target domain.\n\n- **The supplementary code provided appears to be non-executable in its current form**, and it lacks essential implementations pivotal to this concept. For example, in \"dg_adapt_sampler.py\", it seems that there are missing/or modified segments of code crucial for execution. I could find a lot more missing pieces, so it's impossible to validate the key implementation. To facilitate a better understanding and application of the idea presented, please consider supplying a more comprehensive and runnable version of the code that includes all key implementations and necessary details for successful execution."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Reviewer_CA6h"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3902/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698556536342,
        "cdate": 1698556536342,
        "tmdate": 1699636350099,
        "mdate": 1699636350099,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "VYDbGyZ254",
        "forum": "2XwBIcywWM",
        "replyto": "2XwBIcywWM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3902/Reviewer_JCc1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3902/Reviewer_JCc1"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors propose a test-time domain generation method from a probabilistic perspective by modeling pseudo labels as distributions. Specifically, variational neighbor labels are incorporated to generate more robust pseudo labels, and meta-learning-based algorithms are proposed to boost the performance. The experiments on seven datasets show its effectiveness."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The experiments conducted on seven datasets show its superiority over SOTA, with subtle improvement. \n+ code is provided for reproducibility."
            },
            "weaknesses": {
                "value": "- The experiments are limited to small-scale datasets.  Some commonly adopted large-scale datasets are missing, e.g. CIFAR10-C, CIFAR100-C, ImageNet-C, VisDA.\n- The amount of improvement is limited. Ablation study on variational neighbor labels shows a subtle improvement from neighbor-labeling.   \n- Presentation:\n   - The paper writing needs improvement, which is hard to follow. \n   - I suggest labeling the proposed approach with a meaningful code instead of \"this paper\".  \n   - It is better to move section 4, \"related work\" ahead the following introduction. \n- The hyperparameter selection, e.g. learning rate,  for experiments on every dataset are not explained. \n-  what is the inference speed. How much computation cost does this neighbor pseudo label introduce?"
            },
            "questions": {
                "value": "please check the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3902/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821113932,
        "cdate": 1698821113932,
        "tmdate": 1699636350022,
        "mdate": 1699636350022,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wbv7yScTLn",
        "forum": "2XwBIcywWM",
        "replyto": "2XwBIcywWM",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3902/Reviewer_Hsmr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3902/Reviewer_Hsmr"
        ],
        "content": {
            "summary": {
                "value": "This paper presents three novel contributions aimed at addressing the issue of unreliable test-time domain generalization using pseudo labels. The authors' first contribution involves defining pseudo labels as stochastic variables and estimating their distributions, enabling the modeling of uncertainty in the predictions obtained from the source-trained models. Secondly, the authors propose the learning of variational neighbor labels to enhance the robustness of the pseudo labels. Lastly, they introduce a meta-generalization method that allows for the learning of variational neighbor labels during training, enabling the models to adapt to domain shifts. The authors support their claims with comprehensive empirical experiments, demonstrating the effectiveness of their proposed approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Overall paper is well-written and easy to read. \n2. The proposed method uses stochastic variables to represent pseudo labels and estimates their \ndistributions. In addition, it learns variational beighbor labels to enhance the robustness of pseudo labels.\n3. The method introduces a meta-generalization method to solve the problem of domain shifts.\n4. The experiments conducted in the article are highly intuitive and sufficiently comprehensive."
            },
            "weaknesses": {
                "value": "1. Behind the Equation 2, the authors don\u2019t explain the symbol delta.\n2. Shoule include more ablations, such as pseudo-labeling with meta-generalization and meta-generalization with probabilistic pseudo-labeling."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3902/Reviewer_Hsmr"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3902/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699007286565,
        "cdate": 1699007286565,
        "tmdate": 1700644340630,
        "mdate": 1700644340630,
        "license": "CC BY 4.0",
        "version": 2
    }
]