[
    {
        "id": "QQ5lW2BMGl",
        "forum": "uvq4Nh8eZB",
        "replyto": "uvq4Nh8eZB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5684/Reviewer_UQKJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5684/Reviewer_UQKJ"
        ],
        "content": {
            "summary": {
                "value": "The authors use federated co-training, in which local hard labels on the public unlabeled datasets are shared and aggregated into a consensus label. Then, the server forms a consensus, while clients use this consensus as pseudo-labels for the unlabeled dataset in their local training. For data protection, the idea is to integrate XOR-mechanism for achieving differential privacy over binary data. At last, the authors provide empirical experiments over multiple datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The authors conducted many experiments."
            },
            "weaknesses": {
                "value": "+ The idea seems to be just a combination of different modules.\n+ The explicit motivation is unclear.\n+ The writing logic should be improved."
            },
            "questions": {
                "value": "What is the explicit motivation of this paper?\nWhy is this idea important?\n\n### Abstract\n- The first half introduces some general and basic knowledge of federated learning, data privacy, applications, and co-training. The logic is not smooth. Several sentences have no much relation here. What is the explicit problem that you target here? What are the explicit problems of prior research?\n- The proposed idea seems to have better model quality and privacy. However, the ambiguious language makes me confused. What is the definition of privacy or quality?\n\n### Introduction\n- The introduction mentions differential privacy, unlabeled datasets, and gradient-based methods? What are the problems of these research areas? Do the authors improve each of them?\n- The authors detailed what they have done. I feel confused that why the idea of combination (co-training, differential privacy, federated learning) is meaningful. What are your insights?\n\n### Construction\nSection 3 combines the prior research and the new idea.\nSection 4 starts with introduction of differential privacy.\nCould the authors elaborate what is new here? What research line do you follow?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Reviewer_UQKJ"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5684/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697964173305,
        "cdate": 1697964173305,
        "tmdate": 1699636593775,
        "mdate": 1699636593775,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uaNHBnKMHO",
        "forum": "uvq4Nh8eZB",
        "replyto": "uvq4Nh8eZB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5684/Reviewer_W2md"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5684/Reviewer_W2md"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes an algorithm to protect the privacy of shared soft predictions on a public dataset used to achieve consensus in the server in semi-supervised learning. In particular, the server owns a unlabeled dataset and clients own private labeled datasets. Client utilizes local model to infer on the public dataset and compute the soft predictions on the unlabeled data, then sends those information to the server in a differentially private manner. The server aggregates those local knowledge into consensus and matigate the over-fitting in local trainings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper attempts to solve an important problem: semi-supervised federated learning.\n2. The paper provides theoretical guarantee of the privacy confidence.\n3. utilizing a different differential privacy mechanism (XOR) instead of Gaussian mechanism, which is interesting."
            },
            "weaknesses": {
                "value": "1. The novelty is limited. There are many prior studies have explored semi-supervised federated learning [1-3] and knowledge distillation [4-6]. The paper does not propose a new framework of FedSSL but just naively combining differential privacy techniques. The paper does not illustrate the difference between FedCT and those previous work.\n2. The motivation to protect the privacy of soft predictions is weak. Comparing to raw data/ features map, the soft predictions are not likely to leak privacy.\n3. The paper is not well-organized and using non-standard terminology. For example, the term 'semi-honst' in section 4. Usually, we use 'honest-but-curious' to descrtibe the server which can not modify the local updates but trys to infer private information of clients. \n4. The baselines are not comprehensive. DP-FedAvg is using DP to the updated gradients but the proposed FedCT is using DP in the soft  predictions, it is not comparable. FedCT should compare other FedSSL methods [1-3] and conduct attach on the method to verify the effect of FedCT.\n5. Setting for data heterogenity is not sufficient. With beta = 2 for non-i.i.d setting is not good. Most of papers set beta = 0.01 or 0.1 to create heterogeneous data partitions.\n\nReference:\n\n[1] Diao E, Ding J, Tarokh V. SemiFL: Semi-supervised federated learning for unlabeled clients with alternate training[J]. Advances in Neural Information Processing Systems, 2022, 35: 17871-17884.\n\n[2] Lin H, Lou J, Xiong L, et al. Semifed: Semi-supervised federated learning with consistency and pseudo-labeling[J]. arXiv preprint arXiv:2108.09412, 2021.\n\n[3] Itahara S, Nishio T, Koda Y, et al. Distillation-based semi-supervised federated learning for communication-efficient collaborative training with non-iid private data[J]. IEEE Transactions on Mobile Computing, 2021, 22(1): 191-205.\n\n[4] Li D, Wang J. Fedmd: Heterogenous federated learning via model distillation[J]. arXiv preprint arXiv:1910.03581, 2019.\n\n[5] Zhu Z, Hong J, Zhou J. Data-free knowledge distillation for heterogeneous federated learning[C]//International conference on machine learning. PMLR, 2021: 12878-12889.\n\n[6] Chen H, Vikalo H. The Best of Both Worlds: Accurate Global and Personalized Models through Federated Learning with Data-Free Hyper-Knowledge Distillation[J]. arXiv preprint arXiv:2301.08968, 2023."
            },
            "questions": {
                "value": "1. What is the main difference between FedCT and the previous FedSSL methods?\n\n2. what's the motivation to use XOR mechanism instead of Gasussian mechanism? What's the benefit?\n\n3. I don't understand the last discussion of Interpretable Models? Why there is only FedCT and Centralized in the experimental results?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Reviewer_W2md"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5684/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698523633988,
        "cdate": 1698523633988,
        "tmdate": 1699636593678,
        "mdate": 1699636593678,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "u1JOmgloZP",
        "forum": "uvq4Nh8eZB",
        "replyto": "uvq4Nh8eZB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5684/Reviewer_e9mW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5684/Reviewer_e9mW"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a federated learning framework namely FedCT to provide a privacy-preserving collaborative learning by sharing \u201chard labels\u201d for unlabeled dataset. The authors theoretically demonstrate the convergence of FedCT. Besides, they propose an XOR-Mechanism to protect the privacy of sharing labels. Experiments on 7 datasets showcase the superiority of FedCT compared to some baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. The proposed FedCT is technically sound. \n\nS2. This paper provides a sufficient theoretical analysis of convergence and privacy guarantees. \n\nS3. The writing is generally good and easy to understand."
            },
            "weaknesses": {
                "value": "W1. The contribution is trivial. There are a lot of federated learning frameworks, to name a few [1,2,3,4,5], based on sharing knowledge via a public unlabeled dataset. It seems that the only difference is that clients in FedCT upload \u201chard label\u201d while other works\u2019 clients share soft labels. \n\nW2. The motivation is not clear. According to the basic idea of knowledge distillation, soft labels should potentially contain more useful information than hard labels. The authors are encouraged to clarify the reason for replacing soft labels with hard labels.\n\nW3. More representative baselines are needed. As mentioned in W1, there are many similar works; it would be more convincing to conduct experiments to compare them.\n\nW4. The appendix mentioned in the paper cannot be found; maybe it is just for me.\n\n\n[1] FedMD- Heterogenous Federated Learning via Model Distillation.\n\n[2] Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning\n\n[3] Communication-Efficient and Model-Heterogeneous Personalized Federated Learning via Clustered Knowledge Transfer\n\n[4] Model-contrastive federated learning\n\n[5] Ensemble distillation for robust model fusion in federated learning"
            },
            "questions": {
                "value": "See Weeknesses. Addressing these weaknesses (especially W1 and W2) will improve the convincing and quality of this paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5684/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698663829394,
        "cdate": 1698663829394,
        "tmdate": 1699636593559,
        "mdate": 1699636593559,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uGNmEJkO1t",
        "forum": "uvq4Nh8eZB",
        "replyto": "uvq4Nh8eZB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5684/Reviewer_NCnb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5684/Reviewer_NCnb"
        ],
        "content": {
            "summary": {
                "value": "In order to achieve privacy under a federated learning setting, this paper proposes the use of a form of federated co-training called FEDCT, where local hard labels on the public unlabeled datasets are shared and aggregated into a consensus label. This consensus label is then used in training each local model. The paper analyzes the convergence of the proposed FEDCT and further develops a privacy version of FEDCT based on the XOR-Mechanism. The paper compares the proposed method with two baseline methods on several datasets for both iid and non-iid settings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper considers the privacy issue in training machine learning models, which is a very important problem.\n\n2. This paper employs the membership inference attack to practically demonstrate the model's ability to resist real-world attacks.\n\n3. This paper conducts the convergence analysis for the proposed algorithm FEDCT."
            },
            "weaknesses": {
                "value": "1. This paper does not discuss the difference between the proposed method and PATE (Papernot et al., 2016). In PATE, each teacher model can be viewed as a local model, and a majority vote is also utilized to reach a consensus for learning from each other's knowledge. The key distinction is that PATE transfers this knowledge to a student model, while the method in this paper circulates the knowledge back to each teacher/local model. Without further discussion, it's challenging to ascertain whether the contribution of this paper is incremental when compared to PATE and DD (Bistritz et al., 2020).\n\n2. The experimental results are not promising. As depicted in Table 1, only in 1 out of 5 datasets does the proposed method outperform the baselines in terms of ACC, and on none of the datasets does the proposed method achieve the best privacy utility trade-off, that is the best ACC, while at the same time, having the best VUL compared to baselines.\n\n3. This paper lacks clarity on the algorithm's scalability in relation to the number of clients, as it only reports the impact of client numbers on one dataset, and default settings of m (client numbers) for other datasets are only 5."
            },
            "questions": {
                "value": "1. How does FEDCT compare with PATE in terms of the underlying mechanism design?\n2. Besides differentially private distributed SGD (Xiao et al., 2022), are there any other related works that can be utilized as baselines for comparison with DP-FEDCT on the Privacy-Utility Trade-Off with Differential Privacy?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5684/Reviewer_NCnb"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5684/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698729887882,
        "cdate": 1698729887882,
        "tmdate": 1699636593431,
        "mdate": 1699636593431,
        "license": "CC BY 4.0",
        "version": 2
    }
]