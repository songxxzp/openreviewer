[
    {
        "id": "SNvIylynr4",
        "forum": "GqI4fTVUXC",
        "replyto": "GqI4fTVUXC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1956/Reviewer_cgm5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1956/Reviewer_cgm5"
        ],
        "content": {
            "summary": {
                "value": "This paper empirically verifies the linearization effect of wide neural networks and the challenges of applying it to practical neural networks in downstream applications. Specifically, the authors demonstrate the gap between theory and practice across three domains: Optimization (Section 3.1), Uncertainty Quantification (Section 3.2), and Continual Learning (Section 3.3). One of the fundamental reasons for this phenomenon is that practical neural networks do not satisfactorily meet the Stable Jacobian condition (Equation 8). Based on this issue, the authors highlight potential pitfalls that can arise from ideas rooted in linearization for each task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The paper is easy-to-follow, and its intended claims are clear.\n* The empirical gap between linearized NNs and practical NNs tackled in this paper is timely. Additionally, the authors' approach to the problem (Stability of Jacobian) is intriguing.\n* The claims made by the authors are adequately supported through experiments.\n* The authors have clearly delineated the potential and limitations of their claims."
            },
            "weaknesses": {
                "value": "* While each of the authors' claims is clear, the connections between them are somewhat disjointed. Specifically, it is challenging to perceive Section 3.1-3.2's issues as problems since, in reality, wide NNs experience less catastrophic forgetting, as suggested in Section 3.3. Therefore, combining Sections 3.1 and 3.2 into one section and separating Section 3.3 might help avoid this confusion.\n\n* The title of Section 3.1, \"Training: Second-order Optimization\", doesn't accurately convey the content discussed within. The empirical evidence in Section 3.1 (Figures 2-3) primarily supports the instability of the Jacobian in finite NNs. While this might be one of the reasons second-order optimization methods fail when applied to NNs, the paper doesn't seem to present direct experiments that validate this. Moreover, second-order optimization can fail for more than one reason: Slow convergence and Poor generalization. The authors do not specify which of these reasons is attributed to the unstable Jacobian. To avoid confusion, it's recommended that the title of Section 3.1 be revised."
            },
            "questions": {
                "value": "* Have you considered restructuring the sections to more coherently present the content, possibly merging Sections 3.1 and 3.2, and separating Section 3.3?\n* Second-order optimization can exhibit issues like slow convergence and poor generalization. Could you specify which of these issues the unstable Jacobian directly contributes to, based on your research?\n\nIf the issues in Weakness & Questions are addressed appropriately, I will raise the score."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1956/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698214859091,
        "cdate": 1698214859091,
        "tmdate": 1699636127069,
        "mdate": 1699636127069,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "W6uorCPJti",
        "forum": "GqI4fTVUXC",
        "replyto": "GqI4fTVUXC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1956/Reviewer_PQv1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1956/Reviewer_PQv1"
        ],
        "content": {
            "summary": {
                "value": "The paper is experimental. It is dedicated to testing assumptions of several previous papers (mostly theoretical). These previous papers exploit the NTK theory and make a number of predictions about the behavior of NNs. The main claim of the paper is that these predictions do not hold in a practical setting. Three examples of such predictions are considered: 1) the claim that second-order optimization algorithm has some advantages over 1st order in the infinite width limit (the claim from Zhang et al. (2019)); 2) setting the exploration parameter in Neural Uncertainty Quantification according to a formula by Zhou et al. (2020), that was inspired by the NTK theory, 3) the claim that \"increasing\nthe width of a neural network reduces catastrophic forgetting\"."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The setup of experiments is clear, their description is complete. Experimental results are convincing."
            },
            "weaknesses": {
                "value": "I doubt the main claim of the paper: \"observed disconnect between theory and practice calls into question the practical relevance of the infinite-width limit\". It seems to me that this claim does not follow logically from the reported experiments.\n\nThe experimental results of Section 3.1 seem to refute the theory of Zhang et al. (2019), rather than the NTK theory. Experimental evidence that Stable Jacobian conditions (7) and (8) are never satisfied does not \"call into question the practical relevance of the infinite-width limit\". It refutes the claim that NGD is better than GD, but not the NTK theory. Logically, the NTK theory does not claim that (7) and (8) should be satisfied. \n\nThe same holds for the Neural Contextual Bandits experiments. It seems that Section 3.2 shows that the formula for the exploration parameter from Zhou et al. is not very good in a practical setting (probably, because the assumptions of Zhou et al are not satisfied). But this does not mean that \"the practical relevance of the infinite-width limit\" is in question.\n\nConcerning catastrophic forgetting, there is no discussion of why the previous research (e.g. Mirzadeh et al. (2022)) somehow contradicts to experimental results of the paper."
            },
            "questions": {
                "value": "The general question is: how the irrelevance of the NTK theory follows from the fact that certain assumptions of a theory developed in a previous paper (e.g. Stable Jacobian conditions (7) and (8)) are not satisfied in current experiments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1956/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698584116722,
        "cdate": 1698584116722,
        "tmdate": 1699636126992,
        "mdate": 1699636126992,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sNBkUw1rL5",
        "forum": "GqI4fTVUXC",
        "replyto": "GqI4fTVUXC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1956/Reviewer_59VJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1956/Reviewer_59VJ"
        ],
        "content": {
            "summary": {
                "value": "This paper empirically investigates whether the theoretical predictions and assumptions based on infinite width NTK theory holds for practical widths encountered in common architectures on relevant tasks. In particular, the authors consider three areas - optimization, uncertainty quantification, and continual learning.\n\n* For optimization, second-order methods like natural gradient are hypothesized to have faster convergence compared to first-order methods like SGD when networks approach the kernel regime. However, the authors find that common architectures do not satisfy the necessary conditions (such as Jacobian stability) for this to hold.\n* In uncertainty quantification, controlling the exploration-exploitation tradeoff in neural bandits via the NTK theory leads to poor performance, while other methods like online evidence maximization work better.\n* In continual learning, wide networks appear to forget less catastrophically only if not trained to high accuracy per task. So increasing width does not mitigate forgetting for practical architectures."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is very well written and easy to follow, even if the reader does not have a very strong background in kernel and gaussian process theory. The question it addresses in an important one. Although prior papers (Fort et al arxiv.org/abs/2010.15110, Atanasov et al arxiv.org/abs/2212.12147) have studied the distinctions between infinite and finite width networks, this paper contributes novel insights. I do however recommend that the authors do a more thorough literature review and cite prior papers studying infinite vs finite width networks, and cite the above mentioned papers. The reviewer especially appreciates the empirical tests in the neural bandit and catastrophic forgetting settings, which are not commonly encountered by theorists working on NTK-related analysis."
            },
            "weaknesses": {
                "value": "My primary critique is the lack of distinction made between width and feature learning strength. Although it is true that in standard/NTK parameterization, wide networks converge to the NTK (as in Jacot et al), alternative parameterizations have since been considered. Firstly, (Chizat et al http://arxiv.org/abs/1812.07956) have shown even finite width networks can be reparameterized to make them behave as kernels and have identified a \"laziness\" parameter $\\alpha$ that can control feature learning strength at any width.  \n\nMost importantly, the mean field parameterization (Mei & Montanari https://arxiv.org/abs/1804.06561, several other concurrent works) also known as $\\mu$-parameterization (Yang and Hu https://arxiv.org/abs/2011.14522) allows networks to learn features at infinite width. Moreover, (Vyas et al http://arxiv.org/abs/2305.18411) have shown that finite width networks approach the infinite-width feature learning limit very quickly and efficiently. This would imply that in that parameterization such a distinction between wider and narrower networks would be substantially less prominent. One consequence of this is hyperparameter transfer across widths (Yang and Hu http://arxiv.org/abs/2203.03466 ). \n\nI do not expect the authors to redo experiments in this alternative parameterization (though that would certainly be an interesting follow up). It would be very good, however, to distinguish between *overparameterized theory* not being representative of realistic finite-width networks (which I think is an incorrect claim) vs *lazy training at large widths* being non-representative of realistic finite-width networks (which is the claim that the paper very nicely supports). A few sentences in the introduction making this explicit would be very welcome."
            },
            "questions": {
                "value": "For optimization, besides stability conditions, were there other signs like faster convergence that second-order methods may work better? Or was SGD consistently better?\n\nWhat happens if you make the tasks more similar in the continual learning setting? Does the NTK theory begin to hold?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1956/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1956/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1956/Reviewer_59VJ"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1956/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698713489774,
        "cdate": 1698713489774,
        "tmdate": 1699636126921,
        "mdate": 1699636126921,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iPXFbTAiGk",
        "forum": "GqI4fTVUXC",
        "replyto": "GqI4fTVUXC",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1956/Reviewer_9JCy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1956/Reviewer_9JCy"
        ],
        "content": {
            "summary": {
                "value": "The paper tests the practical validity of the theoretical connection between overparameterized (infinitely-wide) neural networks and the NTK regime. It is shown empirically that in many setups used in practice, this connection does not hold for practical network widths.\nIn turn, this has interesting consequences in several important fields (faster optimization, reliable uncertainty quantification and continual learning)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Important research question and implications. Relevant to many recent studies.\n- Well written. Clear.\n- Interesting finding in CL showing that early stopping might significantly affect the conclusions drawn from CL experiments where the width is increased."
            },
            "weaknesses": {
                "value": "1. **Theoretical applicability.** The theory of NTKs requires not only an infinite width, but also a small step size and a large initialization scale (see the original paper by Jacot and \"On Lazy Training in Differentiable Programming\").  \nThe paper submitted here only considers the effect of increasing the width.\n1. **Novelty**: It was hard for me to understand how novel the submitted paper is.  \nI would appreciate a comparison to \"Empirical Limitations of the NTK for Understanding Scaling Laws in Deep Learning\".\n\n\nMoreover, some points were not completely clear to me. See the questions in the following section.\n\n  ---\n\n### Minor remarks (I don't expect any response for the rebuttal on these issues)\n- It seems the authors are unaware of [Goldfarb and Hand, AISTATS 2023] that proved theoretically that forgetting decreases with overparameterization for linear models under a random data model. I advise citing that paper.\n- In Figure 1(c), perhaps a log-scale is more suitable for the y-axis as well. Also, consider drawing $\\frac{1}{\\sqrt{m}}$.\n- In Figure 2, I suggest writing the depth (i.e., $L=10$) in the legend for the real world architecture as well.\n- In Figure 4, consider using a log-scale for the x-axis.\n- On page 8 (experimental setup), the authors say they use WideResNets but don't specify the number of layers)."
            },
            "questions": {
                "value": "1. In Section 3.1, can the authors explain in what sense does NGD have \"favorable convergence over GD\" in theory? Does the paper refer to an appropriate source for this statement? Is this ``strict'' in some way? (otherwise it's unclear why testing only NGD is sufficient to draw conclusions on GD).\n1. In Section 3.1 (Page 6), why do the authors use only a subset of the data for the CNN regression experiment?  \n   (this should be explained in the paper as well).\n1. Still in Section 3.1, does it make sense to somehow plot in Figure 2 (e.g., with a horizontal line) the $\\lambda_{\\min}$ and $C'$ in the limit where the width$\\to\\infty$ (i.e., in the NTK regime)? Is there perhaps a way to compute that theoretically rather than numerically? I believe it may complete the picture for this experiment."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1956/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698784083275,
        "cdate": 1698784083275,
        "tmdate": 1699636126836,
        "mdate": 1699636126836,
        "license": "CC BY 4.0",
        "version": 2
    }
]