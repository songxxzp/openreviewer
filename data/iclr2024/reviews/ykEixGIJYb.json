[
    {
        "id": "quekXUhdk1",
        "forum": "ykEixGIJYb",
        "replyto": "ykEixGIJYb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6"
        ],
        "content": {
            "summary": {
                "value": "This paper extends the recent work on incentivized linear federated bandits (Wei et al. 2023) to one where the clients\u2019 communication costs are unknown, and the server must devise a mechanism for payments that is incentive-compatible. The authors use ideas from mechanism design to design such a scheme while keeping the total payments small."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Novel setting that combines multi-armed bandits with mechanism design \n- Theoretical results seem correct and non-trivial \n- I appreciate the numerical simulations that were conducted to corroborate theory"
            },
            "weaknesses": {
                "value": "I find the main weakness of this paper to be the model. It is a very complex model that combines many different aspects (linear bandits, multiple clients, communication cost, incentivizing payments, truthfulness). The paper did not provide any motivating application for studying this complex model.\n\nRegarding the motivation for the model, one of my main points of confusion is in how the reward/regret of the bandit algorithm can be compared to the incentive payment paid out by the server. Relatedly, what incentive does the server have, to pay the clients (out of pocket) to get them to participate? From my understanding, it is each client that is performing some action, and hence it is in the client\u2019s best interest that the bandit algorithm chooses the best actions. Now, federated learning will improve the learning algorithm since more data is collected, so it is in the agent\u2019s best interest to participate in federated learning. If the \u201ccommunication cost\u201d is higher than the benefits of participating in federated learning, then the agent can simply choose not to participate. In this paper, the server will pay such a client to participate - but what benefit does the server get when the agent participates? What if the true \u201ccommunication costs\u201d are exorbitant (e.g. $1M per communication)? The algorithm in this paper still makes the server pay, regardless of the scale of these costs. \n\nIf one is considering the problem in this paper purely for theoretical interest, the fact that the model was so complex makes it difficult to identify how the results contribute to the theory of multi-armed bandits. Most of the paper was about mechanism design, but it took a long time for me to understand the underlying federated linear bandit model - and it wasn\u2019t clear to me which parts of the underlying bandit model were crucial and which were not."
            },
            "questions": {
                "value": "- A client\u2019s utility, $u_{it}$ was not defined, so truthfulness (definition 1) is not well defined. Does a client\u2019s utility involve both the regret as well as the payment? If so, how are these combined?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_Jfq6",
                    "ICLR.cc/2024/Conference/Submission5786/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698326525050,
        "cdate": 1698326525050,
        "tmdate": 1700662427063,
        "mdate": 1700662427063,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "q6BiaW5yKs",
        "forum": "ykEixGIJYb",
        "replyto": "ykEixGIJYb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN"
        ],
        "content": {
            "summary": {
                "value": "The work builds on, as an extension of Wei et al. (2023), to incentivize the truthful participation of clients to improve overall utility for each client. The authors show the developed communication protocol TRUTH-FEDBAN enjoys near-optimal theoretical guarantees on regret and communication costs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This work presents a mechanism design to ensure the truthful participation of clients, where the client's only beneficial strategy is to share their true costs in a federated bandit learning setting. The incentive-compatible communication protocol offers near-optimal theoretical guarantees on regret and communication costs. Numerical evaluations validate the method's efficacy."
            },
            "weaknesses": {
                "value": "1. I am a bit unsure of the contribution and the motivation for the developed solution of this work, particularly considering how this work is built (as an extension) on Wei et al. (2023); hence, the claim for making this work a first attempt in mechanism design for federated bandit learning seems incorrect? Also, for the method developed, several recent works on federated settings, such as FL, tackle such issues for truthful and fair participation, employing economic tools. Contract Theory-based methods or Auction-based methods have been \"extensively\" employed in mechanism design for truthful interaction between the clients and the server. For instance, [R1, R2]. \n\n[R1] Karimireddy, Sai Praneeth, Wenshuo Guo, and Michael I. Jordan. \"Mechanisms that incentivize data sharing in federated learning.\" arXiv preprint arXiv:2207.04557 (2022).\n[R1] T. H. Thi Le et al., \"An Incentive Mechanism for Federated Learning in Wireless Cellular Networks: An Auction Approach,\" in IEEE Transactions on Wireless Communications, vol. 20, no. 8, pp. 4874-4887, Aug. 2021, doi: 10.1109/TWC.2021.3062708\n\nIn that reference, I am not sure relaxing the data sharing cost with a valuation function, commonly used in standard economic analysis, is a sufficient contribution to this work. Can you explain more about the missing guarantees on the social cost of Wei et al. (2023)? Later, after Def. 2, you mentioned the definition of social cost in this work is different than theirs.\n\n2. Following my earlier comment, the setup and the interaction procedure is unclear to establish the contribution, again, as compared to Wei et. al., 2023. The preliminary model is not rigorous to that end. For instance, what exactly is pulling the arm characterised in Section 3 in a federated bandit setting? How to interpret y_t following it? what is w in footnote 1? and so on. This can be significantly improved.\n\n3. Can the authors support the claim that \"more frequent communication leads to lower regret\"? (and the line that follows in pg. 3) It is understandable in terms of the communication overhead, but this is also the fact that you gain in training efficiency. This leads back to my earlier confusion regarding how \"regret\" is quantified.\n\n4. Is the critical value defined in Def. 4 unique?\n5. I must admit the proof of monotonicity has not been conveyed clearly in its current form; can you provide a discussion on this?\n6. Simulations:\n- The methods build on Wei et. al. 2023 but didn't use it as a baseline.\n- What about the time-complexity analysis and the overall learning performance following the proposed approach? Also, how well the method scales.\n- The general setup with \"sequential interaction\" is limiting in itself, in my understanding."
            },
            "questions": {
                "value": "Please consider the questions raised in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_3EFN",
                    "ICLR.cc/2024/Conference/Submission5786/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698595340835,
        "cdate": 1698595340835,
        "tmdate": 1700637894762,
        "mdate": 1700637894762,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XkkO8FeGbm",
        "forum": "ykEixGIJYb",
        "replyto": "ykEixGIJYb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5786/Reviewer_ihns"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5786/Reviewer_ihns"
        ],
        "content": {
            "summary": {
                "value": "The paper studies a federated learning problem with N strategic, individually rational agents that repeatedly interact with an environment over T rounds to receive rewards. Every agent faces the same environment characterized by a common latent parameter and stochastic rewards that are linear in the action with additive zero mean sub-Gaussian noise. Each agent wants to minimize her regret over the T rounds of interaction, subject to communication costs. The authors propose a truthful mechanism that incentivizes agents via payments (by a central server) to communicate and report their true participation costs, and simultaneously guarantees $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ individual regret."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The main contribution, in my assessment, is an improvement over Wei et al. (2023) in proposing a truthful incentive mechanism (for reporting participation costs) that simultaneously guarantees $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ near-optimal learning loss."
            },
            "weaknesses": {
                "value": "Given that this work is based off of the model of Wei et al. (2023) who essentially formulate all of the problem setting and the optimization problem being solved, the contributions could run the risk of being seen as incremental. \n\nHowever, I believe this paper provides an improved and richer solution concept in comparison to that proposed in Wei et al. (2023) by factoring in regret, social cost and as well as the incentives involved in reporting participation costs."
            },
            "questions": {
                "value": "Is the bi-criteria approximation in Theorem 9 best possible or it can possibly be improved to $[1+\\epsilon, 1-\\delta(\\epsilon)]$, where $\\delta(\\epsilon)$ decreases in $\\epsilon$ with $\\delta(\\infty) = 0$. Also, is $\\delta(0) = \\frac{1}{e}$ best possible?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698816579089,
        "cdate": 1698816579089,
        "tmdate": 1699636608723,
        "mdate": 1699636608723,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Q7cjk3BiZE",
        "forum": "ykEixGIJYb",
        "replyto": "ykEixGIJYb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the problem of learning the unknown parameter in linear parametric bandits via federated/distributed learning (FL) with a central server and multiple clients, when each client must be incentivised to participate in the learning task. More specifically, each client possesses an intrinsic participation cost (e.g., amount of local computational resources at the client required to execute its share of the FL task), and participates only when its incentive for participation exceeds its participation cost. The paper studies the interesting and practically relevant setting when each client may potentially misreport its participation cost (in the interest of exploiting the system or maximising its utility), a setting that is not studied in the prior works. The authors borrow the ideas of *truthfulness* and *social cost* (popular in economics) to design an FL algorithm in which each client can maximise its utility only if it reports the true participating cost. For such an algorithm, the authors obtain bounds on the communication cost and pseudo-regret for FL with incentivised communication, while also demonstrating that the optimal social cost may be achieved up to scaling factors."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper studies the interesting and practically relevant setting when each client may potentially misreport its participation cost (in the interest of exploiting the system or maximising its utility), a setting that is not studied in the prior works. For the problem of FL with incentivisation studied in the prior work of Wei et al. (2023), the paper brings in the ideas of *truthfulness* and *social cost* from economics to quantify the performance of a regret-minimisation algorithm. A formal demonstration of the monotonicity of Algorithm 1 is one of the key contributions of the paper; a similar result is missing in the prior works on FL. The experimental valuations are adequate and insightful."
            },
            "weaknesses": {
                "value": "1. The regret analysis seems to follow quite straightforwardly from Wei et al. (2023) with slight modifications in the hyper-parameter values (as indeed noted on page 17 of the supplementary material, in the description trailing Lemma 18). Therefore, it appears that there is not much novelty in the regret analysis, leaving the novelty to the demonstration of truthfulness and near-optimality of social cost. \n\n2. In continuation to the last sentence of the previous point, there appears to be no motivation to study the criterion delineated in (1). The authors simply proceed to analyse the objective function in (1), simply because it appears in Wei et al. (2023). No further explanation of the criterion in (1) or of its relevance to FL is provided in the paper.\n\n3. The authors consider a very specific form for the valuation function $f(\\Delta V_{i,t})$ without motivating the same. Has a similar valuation function been studied in the context of FL? More generally, what conditions must $f$ satisfy for the analyses to go through? These are not discussed in the paper. \n\n4. On the algorithmic side, the authors prove in Lemma 6 that if the selection rule (a rule for selecting a set $S_t$ of clients that would participate in the FL task at time $t$) can be computed in polynomial time, then so can the critical value associated with the selection rule. However, no explicit result stating how much time is taken by Algorithm 1/2 to compute the selection rule is provided in the paper. While the authors provide an explicit scheme to compute the critical value, the authors do not explicitly prove that their Algorithm 1/2 computes the selection rule in polynomial time. \n\n5. The statement of Lemma 7 appears to be contradictory to one of the statements made in its proof (presented in Appendix D). In the proof, the authors identify that $\\left(1+\\frac{t L^2}{\\lambda d} \\right)^{-d}$ is a lower bound on a certain ratio of determinants, and further note that \"if the hyper-parameter $\\beta$ is **greater** than the (preceding) lower bound, it is guaranteed that no client can be essential\". However, Lemma 7 states the contrary. Furthermore, the constants $L$ and $\\lambda$ appearing in the statement of Lemma 7 are not defined in the main text.\n\n6. There are no comments on the tightness of the bounds on the communication cost and pseudo-regret in relation to the bounds appearing in the work of Wei et al. (2023) (the key piece of work the current paper seems to be based upon). In the process of achieving near-optimal social cost, what is the impact on the communication cost / number of rounds of communication and regret? A formal comparison along these lines with Wei et al. (2023) is missing.\n\n7. Immediately following the statement of Lemma 18 in Appendix E, the authors state that \"In each communication round, **all** the clients upload $O(d^2)$ scalars to the server and then download $O(d^2)$ scalars.\" Why do **all** the clients participate in the communication and not just the ones from the selection set $S_t$ at the communication time instant $t$? This is a little confusing, and not discussed elsewhere in the paper.\n\nThe writing of the paper can be significantly improved. \n\n1. The *incentive* $\\mathcal{I}_{i,t}$ introduced in (2) does not appear to be used elsewhere in the paper. \n2. In Definition 4: $c\\_{i}(\\mathcal{M}, \\widehat{D}\\_{-i, t}) \\to c\\_{i, t}(\\mathcal{M}, \\widehat{D}\\_{-i, t})$.\n3. In the paragraph before Lemma 6: \"Lemma 5\" should be replaced with \"Proposition 5\".\n4. In the proof of Theorem 8: $i \\notin S\\_t \\to i \\notin S\\_t^\\prime$.\n5. The notion of \"communication threshold\" in Theorem 10 is not explained in the paper.\n\nThe paper is generally missing the overall feel of an FL paper (no details about the communication protocol, which set of clients participate in communication, what information is communicated from the clients to the server), and seems to only build upon the setting and results of Wei et al. (2023) on the social cost and truthfulness aspects."
            },
            "questions": {
                "value": "I have discussed the questions under \"Weaknesses\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5786/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5786/Reviewer_1gFC",
                    "ICLR.cc/2024/Conference/Submission5786/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5786/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699431937925,
        "cdate": 1699431937925,
        "tmdate": 1700628805237,
        "mdate": 1700628805237,
        "license": "CC BY 4.0",
        "version": 2
    }
]