[
    {
        "id": "vl1hZ4Xbmd",
        "forum": "w7BwaDHppp",
        "replyto": "w7BwaDHppp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission183/Reviewer_oDMF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission183/Reviewer_oDMF"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes manipulating the projective mapping to account for unbounded volume in training neural radiance fields (NeRF). The work proposes using a stereographic projection method but effectively on a deformed manifold by mapping with p-norm distance. It suggests manipulating the p value to adjust mapping for the current scene geometry. It also includes a ray parametrization technique to allocate samples effectively."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper includes an interesting analysis of the various mapping methods used to handle unbounded scenes. Then, the mapping functions are unified into a coherent formulation. \n\n- The proposed method can capture fine geometry in distant regions, which can be missed with sparse samples."
            },
            "weaknesses": {
                "value": "- It is not apparent when the proposed method will benefit. Even if you train a volume with an unbounded scene, the camera poses of the training image are bounded. The proposed mapping tries to cover the existing geometry, but the problem of undersampling or oversampling is not simple. While the authors claim that it can adapt the ray and sample distribution to the underlying geometry, there is a limitation on how much it can capture. If we consider the size of volume covered by a pixel from training images, the formulation is reasonable to have sparse samples in far objects. In other words, the mapping should consider both the training image rays and the scene geometry.  Trying to put more samples without detailed image evidence can result in undesired artifacts. Concurrently, there should be a constraint on valid testing views, which should align with the ray distribution of training rays. It also needs to consider where to put the scene origin, from which the mapping function is defined in a spherically symmetric function with a single parameter (p) to control. \n\n- I suspect most of the performance comes from adaptive sampling rather than the novel mapping function. The sampling shoould be compared againt other sampling methods suggested in conjunction with NeRF. (e.g., depth adaptive sampling, coarse-to-fine approach, etc.) Here are some suggestions:\n\n@article{fang2021neusample,\n    title={NeuSample: Neural Sample Field for Efficient View Synthesis},\n    author={Jiemin Fang and Lingxi Xie and Xinggang Wang and Xiaopeng Zhang and Wenyu Liu and Qi Tian},\n    journal={arXiv:2111.15552},\n    year={2021}\n}\n\n@InProceedings{Hu_2022_CVPR,\n    author    = {Hu, Tao and Liu, Shu and Chen, Yilun and Shen, Tiancheng and Jia, Jiaya},\n    title     = {EfficientNeRF  Efficient Neural Radiance Fields},\n    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n    month     = {June},\n    year      = {2022},\n    pages     = {12902-12911}\n}\n\n\n- The paper dedicates too much to explaining the mapping. While the analysis can be interesting, the two main contributions start on page 6. I think it would be better to position it around page 3. I would also recommend putting more qualitative results in the main paper and more comprehensive results in the appendix."
            },
            "questions": {
                "value": "- What is the computational complexity in evaluating p?\n\n- Although the paper dedicates a significant amount of space to discussing the mapping, it is not very clearly explained. Especially in Section 1, it is very obscure to understand the explanation associated with Figure 1. For example, in the figures, it is not obvious what the x and y axes are and how they relate to actual camera parameters. It is never clearly defined. I suggest condoning the explanation (Figures 1, 2, and 3 seem somewhat repeated) and clearly defining the depicted space. Also, please connect consistently with the actual projection function and the figures. I suppose $\\zeta$ and $\\mathbf{x}_m$ are the same; and $\\xi$ is $\\mathbf{x}_b$; and $\\psi$ is $\\mathbf{x}$. Please introduce them together with the corresponding equations. What do you mean by 'hyper-axis,' and how does it relate to homogeneous coordinates? Also, what are the x and y axes in Figure 9?\n\n- How do you decide the scene origin and choose 'r' in contract mapping?\n\n- What are x1 ... x8 in Table 2?\n\n- This paper might be relevant:\n@inproceedings{Choi_2023_CVPR,\n  author  = {Choi, Changwoon and Kim, Sang Min and Kim, Young Min},\n  title   = {Balanced Spherical Grid for Egocentric View Synthesis},\n  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},\n  month   = {June},\n  year    = {2023},\n  pages   = {16590-16599}\n}"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission183/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission183/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission183/Reviewer_oDMF"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission183/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697699712163,
        "cdate": 1697699712163,
        "tmdate": 1700641867430,
        "mdate": 1700641867430,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "U6AEd5qeaS",
        "forum": "w7BwaDHppp",
        "replyto": "w7BwaDHppp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission183/Reviewer_BLBe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission183/Reviewer_BLBe"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new mapping method to solve the problem of remote point sampling in unbounded scenes. Based on a p-norm distance, which allows to adaptively sample the rays. Furthermore, this paper introduces a new ray parameterization to properly allocate ray samples in the geometry of unbounded regions. In addition, analyzes the difference of mapping functions in bounded and unbounded scenes from the perspective of geometric understanding. Experimental results show that this mapping function can show better results in novel view results of unbounded scenes."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ Analyze the disparities in mapping functions employed in scenes with bounded and unbounded contexts from a geometric standpoint. This approach addresses issues with a more fundamental understanding, offering valuable insights.\n+ This paper introduces a novel mapping function and a novel ray parameterization technique that effectively transforms the unbounded space into a bounded representation, allowing for improved representation of distant regions within the scene.\n+ The organization of this paper is notably coherent, fostering a seamless progression of concepts that is easily accessible to readers."
            },
            "weaknesses": {
                "value": "- Confusion in understanding. To my understanding, since increasing the value of p can increase the capacity of the near space, further points can be mapped into the bounded region to achieve a better representation of the unbounded scene. Why is it from your ablation experiments that higher p-values are better for proximal expression?\n- Insufficient analysis of results. As can be seen from the results in Table 1, for the representation of NeRF, the effect of the p-norm mapping method proposed in this paper is not more significant than that of the voxel-based methods, and even the effect of the contract mapping function is better on NeRF. Is this method more effective for voxel grid representation?\n- From the results in Figure 6, it can be seen that the mapping function proposed in this paper can better express distant objects, but the effect of near objects is not very good. Could you please give an analysis to facilitate a better understanding of the advantages of this method?"
            },
            "questions": {
                "value": "- Since the value of $p- norm$ at $p$ less than 1 is a non-convex function, and the value of $p$ is greater than 1, does the value of $p$ have a certain upper limit?\n- Why is the mapping function proposed in this paper better for the lifting of voxel-based methods? Could you please give an appropriate analysis, that can help understand your contribution better?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission183/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698413133138,
        "cdate": 1698413133138,
        "tmdate": 1699635943959,
        "mdate": 1699635943959,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KUZtxL5X25",
        "forum": "w7BwaDHppp",
        "replyto": "w7BwaDHppp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission183/Reviewer_CBov"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission183/Reviewer_CBov"
        ],
        "content": {
            "summary": {
                "value": "The authors present a novel mapping function designed to estimate neural radiance fields (NeRFs) for unbounded scenes. This mapping function can be adapted to a particular scene geometry to optimize the NeRF performance. To work with this mapping function, the authors also introduce a new ray parametrization to accommodate a special ray sampling. The experimental results demonstrate state-of-the-art performance across multiple datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The positive aspects of the paper are:\n(1) While the paper may not always be well written, its content is in general simple to follow and understand.\n(2) The difficulties of traditional approaches in unbounded scenes are discussed, and the state-of-the-art literature is adequate and well explained.\n(3) The proposed adaptable mapping function, detailed in Section 4.3, demonstrates theoretical soundness, and exhibits potential for enhancing NeRF approaches for unbounded scenes. The use of the RANSAC strategy to select the p-value makes sense and yields effective outcomes.\n(4) The angular ray parametrization discussed in Section 4.4. is interesting and has the advantage of almost uniform ray sampling.\n(5) The experimental results are promising, being the top performer in the far regions of unbounded scenes."
            },
            "weaknesses": {
                "value": "The negative aspects of the paper are:\n(1) the experimental results show that the performance in the foreground areas is sometimes inferior compared to competing approaches. Even do this has a theoretical explanation (competing approaches use the identity mapping in nearby regions), it is a limiting factor of the proposed approach.\n(2) the mapping function is dependent on the COLMAP performance for computing an accurate sparse 3D point cloud. There are situations (e.g. low and/or repetitive textured scenes) where COLMAP may fail, and, hence, the proposed mapping function would be inferior to the inverted sphere or the contract approaches.\n(3) From what I can understand, one p-value is selected for each NeRF model. Since the distribution of the objects and structures in the scene might vary significantly, and the 3D point density also varies, the p-value is only a very coarse approximation of the 3D space distribution. The paper doesn\u2019t focus on selecting the optimal p value for a determined area, which would make the paper even more relevant for the community."
            },
            "questions": {
                "value": "(1) In Section 2.2, you assert that \"F2-NeRF Wang et al. (2023) models unbounded scenes with subdivided spaces and warping functions. However, this subdivision is intrinsically tied to camera poses and is sensitive to scene dependency.\"  This statement may imply a negative connotation toward scene-specific subdivision and sensitivity, even though these elements align with the objectives of your paper (ability to handle scene dependency; geometry aware mapping). Could you provide further insights on this?\n(2) In Section 4.1 you mention \"Since the original stereographic method (Fig. 2-(a)) maps points on the surface of the sphere, we cannot perform one-to-one orthogonal projection over the bounded region.\" While this statement is correct, providing a direct explanation for why this limitation exists would simplify the understanding of the reader.\n(3) In Section 4.3., how many RANSAC iteration are run to select the final p value?\n(4) As I mentioned in the weaknesses section, there are situations (e.g. low and/or repetitive textured scenes) where COLMAP may fail, and, hence, the proposed mapping function would be inferior to the inverted sphere or the contract approaches. Can you comment on this? Have you experimentally tested your approach in such scenes?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission183/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698687788823,
        "cdate": 1698687788823,
        "tmdate": 1699635943878,
        "mdate": 1699635943878,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "iPXv7gp3v3",
        "forum": "w7BwaDHppp",
        "replyto": "w7BwaDHppp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission183/Reviewer_es1p"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission183/Reviewer_es1p"
        ],
        "content": {
            "summary": {
                "value": "This paper tackles the problem of novel view synthesis with neural radiance fields for unbounded scenes. As studied by prior work, it's crucial to have a good mapping function to handle large free space and long-range distances for unbounded scenes. The authors first formulate NeRF++ and mip-NeRF 360 in a stereographic projection formulation and later propose their p-norm mapping function in the same framework.\n\nThe key insight of this p-norm mapping function is that the mapping is geometry-dependent. It has the potential of saving space in large free regions and meanwhile well utilizing the capacity for content-rich regions, if the p value is picked right. In practice, this p value is found via RANSAC, where the value leading to maximum distances among randomly sampled 3D scene points gets chosen. The authors argue that we have these points from COLMAP anyway for initializing the cameras.\n\nSince this is an adaptive mapping function, simply sampling ray samples uniformly is insufficient as that would lead to irregular spacing, causing either under- or over-sampling. As such, the authors propose an angle-based sampling strategy to promote more uniform sampling."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "An adaptive mapping function that depends on scene geometry makes sense, especially in the NeRF-land, where models are primarily trained per scene.\n\nUsing a unified framework to analyze prior approaches is also interesting and helps understand.\n\nThe paper did a good job presenting what was done -- the visuals are helpful and right to the point. I especially find the co-presence of 3D figures and 2D views helpful."
            },
            "weaknesses": {
                "value": "I am primarily concerned about the quality achieved. From both qualitative and quantitative evaluations, this approach does not appear to be better than prior approaches -- the improvement looks marginal, especially qualitatively. I suspect this is due to the suboptimal p value, which leads us to my next point.\n\nThe selection of the p value is unsatisfactory. COLMAP provides only an initial, sparse geometry, so its SFM points are not error-free. Then these points go through a randomized process -- RANSAC -- that provides no chance to recover from SFM's mistakes. Have the authors considered iteratively extracting geometry from the NeRF in training and adaptively update the p value? That would give the network a chance to recover from where SFM failed.\n\nRelatedly, I am unsure if the p value leading to the maximum distances among the points is the best p value. Imagine the case where two physically faraway points are used for estimating p, and there's nothing between them. Wouldn't we want to squash/compress the space between them? Why would we want a p that maximizes their distance?\n\nSome nits for the authors to improve their manuscript:\n(1) Figure 2 caption: pupple-colored -> purple-colored.\n(2) main-fold -> mani-fold."
            },
            "questions": {
                "value": "The main questions are the unsatisfying visual quality, suboptimal selection of the p value, and the maximum distance criterion for picking p, as discussed in \"Weaknesses.\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission183/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698774098202,
        "cdate": 1698774098202,
        "tmdate": 1699635943807,
        "mdate": 1699635943807,
        "license": "CC BY 4.0",
        "version": 2
    }
]