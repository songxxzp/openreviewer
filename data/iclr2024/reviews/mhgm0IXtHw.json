[
    {
        "id": "5ftky9Y2uN",
        "forum": "mhgm0IXtHw",
        "replyto": "mhgm0IXtHw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2287/Reviewer_pVhT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2287/Reviewer_pVhT"
        ],
        "content": {
            "summary": {
                "value": "The paper \"Noise Map Guidance: Inversion with Spatial Context for Real Image Editing\" presents a novel inversion method called Noise Map Guidance (NMG) for real-image editing using text-guided diffusion models. NMG addresses the challenges faced by existing methods, such as Null-text Inversion (NTI), which fail to capture spatial context and require computationally intensive per-timestep optimization. NMG achieves high-quality editing without necessitating optimization by directly conditioning noise maps to the reverse process, capturing the spatial context of the input image. The authors demonstrate NMG's adaptability across various editing techniques and its robustness to variants of DDIM inversions through empirical investigations"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper is well-written and provides sufficient background and analysis into the motivations and effectiveness of NMG. the overall framework is very straightforward, there should be no difficulty for other to reproduce. it demonstrates a strong adaptability across various editing techniques, including Prompt-to-Prompt, MasaCtrl, and pix2pix-zero.\n\nThe method is optimization-free, making it computationally efficient while preserving editing quality, it achieve a 20 times acceleration compares to null-text inversion.\n\ncomprehensive quantitative and qualitative comparison of NMG with other inversion methods, showcasing its superior performance in preserving spatial context and editing fidelity."
            },
            "weaknesses": {
                "value": "NMG impose a very strong spatial constraint during editing, as in the figure most showcase have almost the same geometry structure as the original picture, for case the modify geometry e.g. the cat in figure 4, the result shows an apparent artifacts in the modified region. There needs a further investigation on how will NMG perform when facing editing that requires modification on the spatial structure, for example removing a target (like \"two man ...\" ->\"one man...\") or change to a totally different object (\"...car\" to \"... bike \" ).    \n\nMoreover, there lack of discussion about possible failure cases of  NMG, the authors should add such discussion about in what circumstance NMG would fail and the reason why it fails to help the community better understand the proposed method."
            },
            "questions": {
                "value": "Why there are no quantitive and qualitative comparison with previous works about reconstruction? I think there should be a comparison with other methods in this aspect, or the author should explain why it is omitted.\n\nHow NTI + NMG  performs when dealing with actual editing task? it would be helpful to show the proposed method can combine with previous method to achieve a better result."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2287/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2287/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2287/Reviewer_pVhT"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2287/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698690205491,
        "cdate": 1698690205491,
        "tmdate": 1699636161337,
        "mdate": 1699636161337,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Vys7R2lg1F",
        "forum": "mhgm0IXtHw",
        "replyto": "mhgm0IXtHw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2287/Reviewer_9KmB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2287/Reviewer_9KmB"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a noise map guidance method to capture the spatial context information in the input image, addressing the challenge in Null-text Inversion (NTI).  The proposed method is designed for real image editing. Experiments are performed to demonstrate various image editing capabilities of NMG, such as face expression modification, style transfer, viewpoint alternation, among others."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The proposed method looks simple but effective;  \nBoth quantitative and qualitative experiments are performed to validate that NMG outperforms baselines;  \nExtensive experiments are performed to validate that NMG is able to achieve different image editing tasks."
            },
            "weaknesses": {
                "value": "I have the following comments about the weaknesses:\n\n1) Figure 2 seems confusing to me. Since this paper repeatedly mentioned that NMG address the challenges in Null-text Inversion, I think it would be nice to compare NMG to Null-text Inversion in this Figure, and demonstrate how NMG outperforms Null-text Inversion. In addition, it would be nice to add the corresponding text descriptions in the Figure. *E.g.*, it's unclear whether the caption indicate to change the blue fire hydrant to a red one or it's just some deviations during the reconstruction.\n\n2) Limitations and future work should be discussed. For example, whether NMG can address the relationship change task like SGC-Net [1]? Whether NMG can achieve various non-rigid image editing tasks like Imagic [2]? It seems that NMG can achieve some non-rigid editing tasks such as viewpoint alternation or face expression modification. However, spatial information between the output and input seems consistent in the majority parts, from my view. Thus, it would be great to see experiments exploring whether NMG can perform other operations (with more obvious spatial information change) such as \"from a tiger\" to \"a jumping/running tiger\".\n\n[1] Zhang, Zhongping, et al. Complex Scene Image Editing by Scene Graph Comprehension. BMVC 2023.  \n[2] Kawar, Bahjat, et al. Imagic: Text-based real image editing with diffusion models. CVPR 2023."
            },
            "questions": {
                "value": "See Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2287/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698738919962,
        "cdate": 1698738919962,
        "tmdate": 1699636161246,
        "mdate": 1699636161246,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sZSuH8Hq6r",
        "forum": "mhgm0IXtHw",
        "replyto": "mhgm0IXtHw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2287/Reviewer_yyX5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2287/Reviewer_yyX5"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces NOISE MAP GUIDANCE (NMG), a new method for real-image editing. NMG uses noise maps derived from latent variables of DDIM inversion to capture spatial context effectively. By conditioning these noise maps to the reverse process and using both noise maps and text embeddings for image editing, NMG eliminates the need for time-consuming optimization. The results show that NMG preserves spatial context better, works faster, and integrates well with various other editing techniques while maintaining high edit quality. Furthermore, it demonstrates robust performance across different versions of DDIM inversion."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The presented concept is intriguing and efficient. It details an uncomplicated yet effective method of using noise map conditioning during real image inversion, which streamlines the reverse process and eradicates path divergence between the reconstruction path and inversion trajectory. This leads to a more precise reconstruction.\n\n- Moreover, the experiments carried out are robust. They demonstrate superior performance in real-image editing both qualitatively and quantitatively. Additionally, the tests focusing on spatial context utilization are crucial, effectively proving enhanced spatial context preservation capabilities."
            },
            "weaknesses": {
                "value": "- The visualization results depict many recurring stylization outcomes, such as the \"oil painting style\" and \"Van Gogh style\". It would be beneficial for the paper to exhibit a broader variety of more challenging editing instances.\n\n- The user study could benefit from providing more accurate directives in its questions; if it pertains to local editing, for instance, the question should contemplate including \"evaluate original preservation in unedited areas\u201d."
            },
            "questions": {
                "value": "- How about the editing performance of adding or deleting elements in the images?\n\n- While both global and local editing in the ProxNPI paper seem promising, the editing capability in this paper doesn't appear as effective. For instance, in Figure 3, the second row shows an edited result with a clear boundary between two types of backgrounds. In the third row, under \"Van Gogh,\" the overall style seems to have undergone minimal change. Can you provide an explanation for these observations?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2287/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2287/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2287/Reviewer_yyX5"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2287/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762520212,
        "cdate": 1698762520212,
        "tmdate": 1699636161167,
        "mdate": 1699636161167,
        "license": "CC BY 4.0",
        "version": 2
    }
]