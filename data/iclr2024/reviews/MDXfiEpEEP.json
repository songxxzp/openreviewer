[
    {
        "id": "apoejwwX6o",
        "forum": "MDXfiEpEEP",
        "replyto": "MDXfiEpEEP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_D5C9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_D5C9"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a solution to enhance learning with noisy labels using the knowledge of noise source. It presents a few extensions from current solutions to add the noise source knowledge.  Basically, if the sample is more likely to belong to a noise source, then the label can be considered a noisy label. Experimental results show the method works to some extent."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper presents a simple and straightforward method to detect noisy label under a very strong and unrealistic assumption. Multiple datasets are evaluated to conduct the experiments to show the idea work."
            },
            "weaknesses": {
                "value": "There are several major limitations of the paper.\n\n(1) The novelty of the paper is very limited. The idea is established under a very strong assumption that the noise source is known. Moreover, mathematically, the method is also unjustified.\n\n(2) The depth of the paper is not strong enough. There is no theory to support the claims. The method also looks ad-hoc. The level of depth is too far away from ICLR paper.\n\n(3) The paper is also not well-written in the sense that the motivation of the paper is not clear."
            },
            "questions": {
                "value": "In addition to very limited novelty and not enough technical depth, it is also unclear that how is the probability that labels is clean computed and how the noise source is being identified.\n\nFor instance, the noise label created by different people with different levels of experience can be mixed without the knowledge of source. It is a more general case. It is important to solve a more general more instead of an edge case."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5761/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5761/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5761/Reviewer_D5C9"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5761/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697888460915,
        "cdate": 1697888460915,
        "tmdate": 1699636605006,
        "mdate": 1699636605006,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Up6U36u05V",
        "forum": "MDXfiEpEEP",
        "replyto": "MDXfiEpEEP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_3qaZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_3qaZ"
        ],
        "content": {
            "summary": {
                "value": "The paper explores an overlooked task of learning with noisy labels utilizing noise source knowledge. The paper proposes a simple wrapper method that can be used on top of existing methods for noise labels. Overall, the paper studies an interesting setup and the proposed method is practical. However, there are some concerns on the applicability of the method and also the experiment evaluation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Intuitively, using noise source knowledge can indeed be helpful.\n2. The paper proposes a simple method that can be plugged into existing base models.\n3. Experiments shows improvement from the proposed method."
            },
            "weaknesses": {
                "value": "1. Writing can be improved. There are simple errors that should have been avoided by proof reading. For example. \u201cwhen considering the presence of the noise source yellow class, it becomes evident that these noisy samples are closer to their true label class.\u201d Where is \u201cyellow\u201d class in the figure? This causes confusion as \u201cyellow\u201d class is also referred in Equation 2. \n2. The applicability of the method should be made more clear and more intuition should be provided. \n3. Experiment setup can be improved to better justify the claims."
            },
            "questions": {
                "value": "1. It seems the method works in the scenaio where there are confusing class pairs on which examples are miss labeled. However, in real-world, there can be many more noise label patterns in a same dataset, for example random white noise. How does the method work with the coexistence of other noise patterns?\n2. It is mentioned that the proposed method \"are effective on datasets where noise represents the majority of samples\". Given a new dataset at hand with only noisy ground-truth labels, how should one decide whether to use the proposed method? and how would one know whether noise represents the majority of samples?\n3. How often and also when is equation 2 different from selecting the highest probability class? Can you provide some numbers and examples from experiments? This can be helpful to understand the method better.\n4. How is the model trained after detecting the noise examples? Do you just drop the noise examples?\n5. It would be the best to also consider baselines that uses robust loss functions/regularization/etc"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5761/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698601285417,
        "cdate": 1698601285417,
        "tmdate": 1699636604901,
        "mdate": 1699636604901,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lLx11mxu6T",
        "forum": "MDXfiEpEEP",
        "replyto": "MDXfiEpEEP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_X4gK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_X4gK"
        ],
        "content": {
            "summary": {
                "value": "The work focuses on a very practical problem - learning with label noise. It introduces the concept of LNL+K, which incorporates additional 'noise source knowledge' into existing sample selection methods. Specifically, this work utilizes additional 'noise source knowledge' to identify potentially confusing noise classes $D_{c-ns}$. Instead of considering the probability of the annotated class being clean~($P_{c}$), the proposed approach compares the probability of a given label being clean with that of the confusing classes. The proposed strategy is combined with various existing sample selection methods and evaluated on several datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The presentation is clear.\n2. Multiple existing sample selection methods are considered for evaluation."
            },
            "weaknesses": {
                "value": "1. The novelty is somewhat limited. As quoted in the paper - \"The selected sample\u2019s probability may not be the highest\", indeed current sample selection methods, such as the widely-applied GMM style, possibly lead to false positives (hard negatives), as they only consider whether the annotated label is 'clean enough or not' while ignoring its relative 'cleanness' versus other classes. Upon this, though introduced as 'noise source knowledge', the core idea of this work is to compare the 'cleanness' of the annotated class versus other classes, which is straightforward and trivial in existing sample selection heuristics, and been applied already ('consistency measure in [1], probablity difference in [2], there should be more work in major venues). This may sounds a bit stringent, but I expect more insights rather than rephrasement, especially for venues like ICLR.\n\n2. I expect more 'real noise source knowledge' to be considered, rather than current ones (transition matrix, etc.), which still rely on the noisy labels and current in-training models, leading to self-confirmation again. \n\n3. The confusion class set \\(D_{c-ns}\\) induced by 'noise source knowledge' involves new hyperparameters. More ablations are necessary. \n\n4. For a sample selection strategy, there always exists a dilemma of precision and recall, especially when extra hyperparameters are involved. This requires more detailed analysis.\n\n5. The considered real-world noisy datasets lack persuasiveness. Experiments should be conducted on at least Clothing1m and WebVision. \n\n[1] SSR: An Efficient and Robust Framework for Learning with Unknown Label Noise, BMVC2022\n[2] P-DIFF: Learning Classifier with Noisy Labels based on Probability Difference Distributions, ICPR2020"
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5761/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698676279087,
        "cdate": 1698676279087,
        "tmdate": 1699636604798,
        "mdate": 1699636604798,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IiDN2ip48W",
        "forum": "MDXfiEpEEP",
        "replyto": "MDXfiEpEEP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_kCaM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_kCaM"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed incorporating noise source knowledge into some sample selection methods by comparing the confidence of noisy labels and noise source label. The proposed method is simple and easy to be integrated into multiple existing LNL methods. Experiments confirm the effectiveness of the proposed method in certain cases."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The studied problem that how to exploit noise source knowledge in noisy label learning is novel and interesting.\n2. The proposed method is very simple but reasonable, which can be integrated into many methods.\n3. The datasets include cell datasets which shows the potential of the proposed method in scientific research."
            },
            "weaknesses": {
                "value": "1. As shown in the experiments, in some cases, the proposed method will lead to a decrease in performance. The authors should offer a deeper analysis about the reason of the decrease in performance and when could the performance gain be ensured.\n2. The real-world datasets are small-scale and special. It would be better to test the performance of the proposed methods with estimated noise source knowledge in more large and general benchmarks, e.g., Clothing1M and WebVision.\n3. Some writing need further clarification. First, how to generate dominant noise is still unclear.  Are there multiple noise sources for each recessive label. And why is the dataset still balanced after mislabeling in these cases? It seems that the number of examples labeled by dominant classes is less than recessive classes. Second, how to use DualT to estimate noise source knowledge is not clear.\n4. (Minor) The related works can include more recent classifier-consistent methods, e.g. [1,2,3].\n5. (Minor) What does the \"noise supervision\" mean?\n\n[1] Estimating Noise Transition Matrix with Label Correlations for Noisy Multi-Label Learning. NeurIPS 2022\n\n[2] A holistic view of noise transition matrix in deep learning and beyond. ICLR 2023\n\n[3] Identifiability of label noise transition matrix. ICML 2023"
            },
            "questions": {
                "value": "See above weaknesses.  I am happy to increase my score if my concerns are addressed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5761/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698750442287,
        "cdate": 1698750442287,
        "tmdate": 1699636604709,
        "mdate": 1699636604709,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tjNxz11pfc",
        "forum": "MDXfiEpEEP",
        "replyto": "MDXfiEpEEP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_unqu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5761/Reviewer_unqu"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a new task and method for the task of Noise Source Knowledge Integration. They assume that a set of possibly confusing classes for a given other class is made available e.g. the knowledge that trucks and automobiles are easily confused with each other. They integrate this knowledge in the learning process and demonstrate improved results on synthetic and real world datasets when their method is combined with various selected methods from the noisy labels literature which currently do not integrate noise source knowledge."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The authors report broadly positive results with improvements on most datasets in most settings.\n\n- The authors demonstrate that their method can be successfully combined with a range noisy labels learning methods.\n\n- The use of the CIFAR-10 and CIFAR-100 synthetic noise datasets is relatively standard in the noisy labels literature, and the authors introduce some non-standard evaluation datasets with interesting scientific applications (BBBC036, CHAMMI-CP)."
            },
            "weaknesses": {
                "value": "- I found the presentation extremely hard to follow, with many terms' definitions unclear to me and/or errors in the notation and presentation that made following the paper very difficult. I have listed what I regard as errors below and have deferred to the questions section various unclear terms for clarification. I am open to substantially improving my score if it is clear I have misunderstood the paper and it is clarified to me, but at present given my careful reading of the presentation I find the entire method definition and hence its evaluation unconvincing as I cannot understand it.\n    - There are repeated references to a yellow class in Figure 1 e.g. \"the noise source yellow class\", \"p(yellow | x_i) > p(red ? x_i)\", there is no yellow class as far as I can see.\n    - The output of algorithm 1 is denoted P(X) = {p(\\tilde{y}_i | x_i)}, this neither seems to be the correct definition of P(X) or the algorithm output.\n\n\nSmall points:\n- $\\tilde{Y}$ is used in the literature and in section 2 to signify noisy labels, yet in paragraph 2 of section 3, this notation is flipped and now $\\tilde{y}$ are the \"true labels\"."
            },
            "questions": {
                "value": "- The definition of noise sources is unclear to me. Can you please confirm if my understanding based on the definition at the end of the second paragraph in section 3 is correct: noise sources for a given class c, is the set of all other classes such that there is a non-zero probability of a data point that is truly in class c being mislabeled as that class?\n    - If my understanding is correct, then I find it hard to understand how this information is useful to the extent demonstrated in the experiments. Firstly, strictly based on this definition, all classes should be in the noise source set as there is a non-zero probability that a class c is mislabelled to any other class. However it seems to be the case that the definition of this set is in fact more loosely applied in the experimental section of the paper where the noise sources set for class c are really classes that have a relatively high probability of being confused for class c. Nonetheless I struggle to see how this information would be as useful as some of the experimental results seem to show, as essentially this additional information would merely say on a dataset level which classes are reasonably likely to be confused for each other. This is not per sample/input dependent nor does it convey as much information as the true transition matrix which would contain transition probabilities and not merely binary values for each class pair. Could the authors please comment?\n\n- Figure 1 is very unclear to me, based on my understanding of noise sources above, then noise sources are not data points but classes, yet Figure 1 presents new data points as noise sources? In addition could the authors please clarify the meaning of red, blue, circles and triangles in the figure. For example, what is the meaning of a blue triangle?\n\n- I do not understand the arguments leading to equation 2 in section 3.1. In particular:\n    - \"Fig. 1 has a high probability of belonging to the red class, i.e., p(red|xi) > \u03b4, then it is detected as a clean sample in LNL. However, compared to the probability of belonging to the noise source yellow class, p(yellow|xi) > p(red|xi), so the red triangle is detected as a noisy sample in LNL+K.\" As in this paper, noisy labels methods are usually evaluated on multi-class classification tasks. Hence I do not understand how a standard LNL method would fail in this case when p(yellow|xi) > p(red|xi), then while p(red|xi) > \u03b4 it must be the case that p(yellow|xi) >> \u03b4 and hence the sample would be labelled as yellow by the standard LNL method. Fundamentally I fail to see how standard LNL methods would not satisfy equation 2, please explain?\n\n- How the method is incorporated into the various LNL methods is unclear to me. I can understand how the various methods currently identify clean labels. But a very short description is given of the integration in each of the 5 cases. I do not think the level of detail would be sufficient to replicate your results or to combine the method with another LNL method. For example: \"To estimate the likelihood of a sample label being clean in CRUST+k, we mix this sample with all other noise source class samples and apply CRUST to the combined set. If the sample is selected as part of the noise source class cluster, we assume its label is noisy.\" What does it mean to mix the \"samples\"? What are the samples in this case? The noise sources as defined above are simply a set of classes, they are not input dependent nor can I see how they can be mixed with training examples?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5761/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698792814944,
        "cdate": 1698792814944,
        "tmdate": 1699636604605,
        "mdate": 1699636604605,
        "license": "CC BY 4.0",
        "version": 2
    }
]