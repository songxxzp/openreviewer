[
    {
        "id": "cVgXmSbaOq",
        "forum": "upVI6V81Qn",
        "replyto": "upVI6V81Qn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3531/Reviewer_XvEG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3531/Reviewer_XvEG"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a self-supervised representation learning method for GANs that involves additional structural modeling responsibilities and a smoothness regularizer imposed on the network. The method encourages the discriminator to structure features at two scales by aligning distribution characteristics (mean and variance) and grouping local clusters. The proposed method is free from hand-crafted data augmentation schemes and is shown to produce effective discriminators that compete with networks trained by contrastive learning approaches in terms of representation learning."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Studying representation learning from a generative perspective is interesting and promising.\n- The overall organization and writing of the paper are well, making it easy to understand the work.\n- The effectiveness of the method was experimentally verified on small datasets."
            },
            "weaknesses": {
                "value": "- The motivation behind the proposed method is not sufficiently clear for me. Despite the authors providing an ablation study, the principles behind the different losses are not well explained. I expect the authors to provide a more reasonable motivation to help readers understand the necessity of the proposed method beyond experimental results.\n- The paper is the lack of discussion and comparison with the relevant work, ContraD [1], which splits the discriminator into feature learning and real/fake discrimination, similar to the motivation of the work.\n-  The generation performance of the proposed method is unsatisfactory, according to the FID results in Table 4. While there is an improvement compared to the outdated BigGAN, it is not an appropriate baseline for current comparison. Since the authors have compared their proposed method to StyleGAN2-ADA, to substantiate their claim of improved image generation quality, it would be beneficial for them to compare it to StyleGAN2-ADA on the same architecture.\n\n[1] Jeong, Jongheon, and Jinwoo Shin. \"Training gans with stronger augmentations via contrastive discriminator.\" arXiv preprint arXiv:2103.09742 (2021)."
            },
            "questions": {
                "value": "- Why did the authors choose to implement JSD as the loss function? Could a distance metric like Wasserstein-2 distance, commonly used in FID, also based on the assumption of Gaussian distributions, can be used?\n- Given that the loss function involves the computation of covariance and Jacobian matrices, which can be computationally expensive, could the authors provide a comparison of training time and overheads with the baselines?\n- Can the authors conduct parameter analysis experiments to provide guidance on the selection of hyperparameters?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3531/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3531/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3531/Reviewer_XvEG"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3531/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698658525575,
        "cdate": 1698658525575,
        "tmdate": 1699636307190,
        "mdate": 1699636307190,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RucyYmSdJB",
        "forum": "upVI6V81Qn",
        "replyto": "upVI6V81Qn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3531/Reviewer_HQAz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3531/Reviewer_HQAz"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a self-supervised framework with adversarial objectives and a regularization approach. The proposed framework does not rely on hand-crafted data augmentation schemes, which are prevalent across contrastive learning methods. The proposed method achieved competitive performance with recent contrastive learning methods on CIFAR-10, CIFAR-100 and ImageNet-10."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Interesting Topic. Getting rid of hand-crafted data augmentation schemes is undoubtedly beneficial for contrastive representation learning.\n\n- Nice ablations. The paper includes comprehensive ablations on data augmentation dependence, other generative feature learners and system variants."
            },
            "weaknesses": {
                "value": "My main concern is about the main experiments on representation learning performance (Table 1).\n\n- It is not clear why the authors only include toy datasets (CIFAR-10, CIFAR-100 and ImageNet-10) in this table, while they have include experiments on larger datasets(e.g., ImageNet-100) in other tables. Given that the representation learning benchmarks in the baseline methods are all conducted on ImageNet-1k, I don't believe Table 1 is a fair comparison. \n\n- It is also not clear why the authors use SVM and K-M for evaluating the learned representations in Table 1 and do not include linear probing, which is commonly used in the representation literature. \n\nOthers:\n- The reconstruction-based self-supervised methods (e.g., MAE), which have been shown to outperform contrastive learning methods on ImageNet-1k, also do not rely on hand-crafted data augmentations. Hence, to demonstrate the contribution of this work, it is necessary to show that the proposed method can provide performance gain over them on large-scale datasets.\n\n- I think the authors missed a very relevant related work (not my paper) which should be discussed and compared with: Li et al. MAGE: MAsked Generative Encoder to Unify Representation Learning and Image Synthesis. CVPR 2023."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3531/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698696858970,
        "cdate": 1698696858970,
        "tmdate": 1699636307090,
        "mdate": 1699636307090,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3EWHPIBxu3",
        "forum": "upVI6V81Qn",
        "replyto": "upVI6V81Qn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3531/Reviewer_QTsv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3531/Reviewer_QTsv"
        ],
        "content": {
            "summary": {
                "value": "Authors propose a approach within the framework of generative adversarial networks (GANs) to enhance self-supervised representation learning. They introduce objectives for the discriminator that include additional structural modeling responsibilities. These objectives guide the discriminator to learn to extract informative representations while still allowing the generator to generate samples effectively. The proposed objectives have two targets: aligning distribution characteristics at coarse scales and grouping features into local clusters at finer scales. Experimental results on datasets  demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1)  This paper successfully combines two objectives into GANs to learn a good represenation. \n\n2) The paper shows good figures which is easy to follow.\n\n3) Authors compare with strong baselines, and support the effectiveness of the proposed method."
            },
            "weaknesses": {
                "value": "My concerns include the following:\n\n1) The cluster property is well-known in the discriminator. Since DCGAN already show it, so I think it is not new in this paper to present it.\n\n2) The presented method is not two much interesting, even authors give a comprehensive analysis. \n\n3) The used datasets are small.I would like to use big datasets to support the proposed method.\n\n4) Also the frameworks are out of fashion. I think the well-known architecture (e.g., stylegan) is more convincing. \n\n5) There are not much visualization results ."
            },
            "questions": {
                "value": "My main question is about the proposed method. The paper is not new, and has less contribution to this community."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3531/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698945374490,
        "cdate": 1698945374490,
        "tmdate": 1699636307030,
        "mdate": 1699636307030,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "lFkBl7i3qO",
        "forum": "upVI6V81Qn",
        "replyto": "upVI6V81Qn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3531/Reviewer_VSHz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3531/Reviewer_VSHz"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces novel regularization for training GANs to improve the representation learning capability of the discriminator. The representation is competitive with popular contrastive techniques, demonstrated by a variety of experiments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "originality\nquality \nclarity \nsignificance\n\n* This paper proposes a reasonable extension to GAN training, clustering rather than real/fake prediction, with novelty in the application to GANs.\n* The spectral norm of the Jacobian seems novel.\n* The paper is generally well-written\n* The use of GANs for representation learning is compelling"
            },
            "weaknesses": {
                "value": "The aims of the paper are not constantly clear throughout:\n* From the intro: \"...also improves the quality of samples produced by the generator.\"\n* From 3.1 \"their motivation is to improve image generation quality rather than learn semantic features \u2014 entirely different from our aim.\"\nSomewhat weakening this contribution of the paper.\n\nThe biggest issue is lack of the major comparison dataset in vision representation learning: full ImageNet. I was quite surprised to see this data missing for a few reasons:\n1) It's commonly used in existing literature.\n2) BigGAN (of which the proposed works architecture is inspired by) is trained on ImageNet.\n3) The compared methods are significantly hampered with such small data. \n\nI'd like going to focus on the Masked Auto Encoder (MAE) paper, as I'm quite familiar with that work. The reduced training dataset size of ImageNet10, as well as smaller patch size, is a fairly large deviation. Furthermore, there's no mention of what representation space is used from the MAE: all image patches? the CLS token? While these are fine details, they are crucial for fair comparison. I'm not as familiar with the other compared methods, but given the issues with MAE, I am concerned for the those other methods as well.\n\n\nIt's not clear to me if the proposed method is successful at achieving good representation learning on only small datasets, or broadly. As noted in the StyleGAN2-ada paper, CIFAR-10 is a data limited benchmark. \n\n\nMinor:\n* The use of z,z^g is a little confusing, as z usually refers to the generators input and z^g even moreso."
            },
            "questions": {
                "value": "The Fine-grained clustering is a bit confusing, can you explain how the memory bank works in greater detail? Is z^b the discriminator representation of the real images encoded into the latent space? The nomenclature is not clear. A plain english explanation as to what the loss function is accomplishing would be illuminating as well."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3531/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698991220047,
        "cdate": 1698991220047,
        "tmdate": 1699636306937,
        "mdate": 1699636306937,
        "license": "CC BY 4.0",
        "version": 2
    }
]