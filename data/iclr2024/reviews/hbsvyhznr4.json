[
    {
        "id": "hH1w3APYAD",
        "forum": "hbsvyhznr4",
        "replyto": "hbsvyhznr4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4472/Reviewer_qavn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4472/Reviewer_qavn"
        ],
        "content": {
            "summary": {
                "value": "The paper propsoed a joint training to imporve the roboustness of image-based maneuvering models. The proposed method improve the roboustness of the two modules jointly, the decoder and steering angle prediction model."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper focuses on an interesting and important issue of deep nueral networks, especially for autnomous driving systems."
            },
            "weaknesses": {
                "value": "There are several issues with the paper:\n1- The issue of adversarial attack is well-known in the field. However, it is not well explained how this issue might be the case for application discussed in the paper. I think it is important to provide real-world scenarios for this purpose. \n2- The proposed method has not been evalauted on general benchmarks and as such it is difficulat to understand the effectivenss of the proposed method. \n3- There are several new state-of-the-art adversarial defense mechanisms in the field currently, and they are missed to be included in the paper. \n4- It is diffult to understand what is the main novelity of the proposed method."
            },
            "questions": {
                "value": "1- How deoes this problem might take palce in real-world scenarios?\n2- How does the proposed method comapred with state-of-the-art adversarial training and defence mechanisms?\n3- What is the main novelity of the propsoed method? new perturbation training or proposing a new roboust model for steer angle prediction?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4472/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4472/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4472/Reviewer_qavn"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4472/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697762677610,
        "cdate": 1697762677610,
        "tmdate": 1699636423012,
        "mdate": 1699636423012,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NG1pUAw4FC",
        "forum": "hbsvyhznr4",
        "replyto": "hbsvyhznr4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4472/Reviewer_7kUe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4472/Reviewer_7kUe"
        ],
        "content": {
            "summary": {
                "value": "This paper is on the topic of robust maneuvering in view of autonomous driving. The authors propose to augment the training images with gradient-free perturbations. Furthermore, they propose to regularize the model training by adding a denoising task where a decoder should reconstruct the original images without the gradient-free perturbations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall, the paper is clear. A wide range of experiments are conducted to support their claim, including experiments on several datasets, an ablation study, and experiments showing that gradient-free perturbation and denoising auto-encoder regularization are helpful in improving performance."
            },
            "weaknesses": {
                "value": "More analysis regarding why the proposed method works is important. For high-level tasks, adding a task of reconstructing the input image or its variant usually degrades the performance on clean data.\n\nBesides, the limitations of this paper discussed at ICLR 2013 seem to still exist, and there seem no significant changes from the last submission."
            },
            "questions": {
                "value": "Please see the weakness part"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4472/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698672116494,
        "cdate": 1698672116494,
        "tmdate": 1699636422916,
        "mdate": 1699636422916,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XOZGFkfozw",
        "forum": "hbsvyhznr4",
        "replyto": "hbsvyhznr4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4472/Reviewer_vA9d"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4472/Reviewer_vA9d"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to improve the perception robustness of a self-driving system. Specifically, this paper propose a joint learning method, to regress the learning target and to reconstruct the clean image at the same time. With solid evaluation, the proposed method can significantly improve the robustness of the model."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The experiments of this paper is solid. The experiments are conducted on a number of datasets, and compared with a number of methods to improve model robustness.\n\nThis research topic is very interesting, and aligns well with the real world needs. Before this paper, I didn't see many papers working on this topic."
            },
            "weaknesses": {
                "value": "There is no enough context information about the task this paper working on. Predicting steering angle from camera image seems not a very popular task, so it is worth introduce this a little bit more.\n\nIt is very interesting to see the sensitivity of the hyper-parameters. IIUC, if we set the weights of the reconstruction loss as 0, I suppose the performance will regress back to Standard (FSRI). Please correct me if my understanding is wrong.\n\nFor equation (1), I am wondering what's the reason why we times $\\lambda_1$ with $l_2$, and times $\\lambda_2$ with $l_1$? It seems very counter intuitive so would like to learn the reason.\n\nLooks like the proposed method is not specifically design for the steering angle prediction task, so I am wondering why choose this task, and if the propose method can benefit other self-driving related tasks."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4472/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698800766732,
        "cdate": 1698800766732,
        "tmdate": 1699636422824,
        "mdate": 1699636422824,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7olxJa4E76",
        "forum": "hbsvyhznr4",
        "replyto": "hbsvyhznr4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4472/Reviewer_gYbZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4472/Reviewer_gYbZ"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a novel approach to enhancing the robustness of 'perception-to-control' systems, which are increasingly prevalent due to the integration of machine learning algorithms and ubiquitous sensors. The proposed method, AutoJoin, is a gradient-free adversarial training technique specifically designed for image-based maneuvering tasks. AutoJoin stands out from other state-of-the-art methods, demonstrating significant performance improvements when tested on a substantial dataset of over 5 million images. The technique showcases up to a 40% increase in performance against perturbations, while also achieving a remarkable 300% improvement in clean performance. This indicates that AutoJoin not only enhances the system's resilience against adversarial attacks but also boosts its overall effectiveness in standard operating conditions. In terms of efficiency, AutoJoin proves to be highly advantageous, saving up to 86% of the time per training epoch and requiring 90% less training data compared to other leading techniques. This efficiency makes AutoJoin a practical choice for real-world applications, where resources and time are often limited. The core innovation of AutoJoin lies in its unique architecture, which incorporates a decoder attachment to the original regression model, resulting in a denoising autoencoder integrated within the system. This design enables the simultaneous and synergistic learning of both maneuvering and denoising sensor input tasks. As a result, the performance of each task is enhanced, leading to a more robust and reliable 'perception-to-control' system. In conclusion, AutoJoin emerges as a groundbreaking technique in the field of adversarial training, offering substantial improvements in both performance and efficiency. Its unique architecture and gradient-free approach make it a promising solution for developing trustworthy 'perception-to-control' systems, capable of operating effectively in diverse and challenging environments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-- AutoJoin is a gradient-free adversarial training technique.\n\n-- AutoJoin  achieves significant performance increases up to the 40% range against perturbations while improving on clean performance up to 300%.\n\n--AutoJoin is also quite efficient in computation cost, saving up to 86% time per training epoch and 90% training data over other state-of-the-art techniques.\n\n-- The paper is well written and easy to follow."
            },
            "weaknesses": {
                "value": "Main weakness is from how the robustness is evaluated. In verifying the robustness, it would be better to explore more types of perturbations. Such perturbations could be from both common image manipulations and adversarial perturbations. Although several image corruptions are applies, they mainly focus on color perspective. What will happen if other types of image corruptions, such as image rotation, perspective warping, JPEG compression. Such robustness evaluation can be referred from [1]\n\n[1]. Xinhua et al. Only For You: Deep Neural Anti-Forwarding Watermark Preserves Image Privacy. 2023\n\nIn addition, such evaluation can also be executed  on adversarial perturbation, such as from FGSM, PGD, Autoattack etc.  \n\nSeveral minor issue:\n\nThere are some typos need to pay attention. For instance, the first sentence in introduction, \"have\"-->\"has\".\n\nIn the conclusion section, the citation is incomplete. Line 5: a full stop is missing at the end of a sentence."
            },
            "questions": {
                "value": "-- Adversarial training is largely dependent on how the images are perturbed, which determines how the adversarially trained model will generalize its robustness. The FID is used only minimally to determine the maximum intensity value of a perturbation. What will happen or be expected if perturbations are kept consistent with [Shen et al, 2021] and [Bengio et al 2009]?\n\n-- Given the mentioned possible add-on evaluations, the transferability of claimed adversarial robustness can be further tested?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4472/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699226204151,
        "cdate": 1699226204151,
        "tmdate": 1699636422736,
        "mdate": 1699636422736,
        "license": "CC BY 4.0",
        "version": 2
    }
]