[
    {
        "id": "5irkWxbvSh",
        "forum": "hOxgrGM63n",
        "replyto": "hOxgrGM63n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission20/Reviewer_gtQ6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission20/Reviewer_gtQ6"
        ],
        "content": {
            "summary": {
                "value": "The authors considered Langevin Monte Carlo method in the problem of sampling from a target distribution that has a smooth strongly log-concave density. Specifically, the authors developed a novel proof technique that led to nonasymptotic $W_2$ error bounds for the randomized midpoint method for the Langevin Monte Carlo (RLMC) and the randomized midpoint method for the kinetic Langevin Monte Carlo (RKLMC). The upper bounds are competitive with the best available results for LMC and are free from a term that\u2019s linearly dependent on the sample size. The authors also provided a nonasymptotic $W_2$ error bounds for the kinetic Langevin Monte Carlo (KLMC) algorithm that has an improved dependence on the condition number. Numerical experiments were conducted."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well-organized and clearly written. The authors did a good job discussing backgrounds and intuitions. The proposed error bounds improved upon existing results, and the novel proof technique itself has the potential to be used to re-examine other existing analyses. The paper includes sufficient comparison with and reference to related results/literature. The authors also addressed several limitations."
            },
            "weaknesses": {
                "value": "A major part of this paper\u2019s contribution is removing the (square root of) $mnh$ for the error bounds of RLMC and RKLMC, yet I\u2019m not clear on how important this is. The removal of this term, claimed by the authors, is an important step toward extending these results to potentials that are not strongly convex. Similarly, in the comments for the result for RKLMC, the authors claimed that not requiring the algorithm to be initialized at the minimizer of the potential is important for extending the method to non-convex potentials. However, as the authors pointed out in the discussion, strong convexity seems to be an essential assumption for these results. Therefore, I\u2019m a bit unclear on the significance of this paper\u2019s contribution."
            },
            "questions": {
                "value": "Please see the weakness part. In particular, how would the extension to non-convex or non-strongly convex potentials depend on the authors\u2019 proposed methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Reviewer_gtQ6"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission20/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697593810630,
        "cdate": 1697593810630,
        "tmdate": 1699635925447,
        "mdate": 1699635925447,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oGQF9m24lF",
        "forum": "hOxgrGM63n",
        "replyto": "hOxgrGM63n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission20/Reviewer_FzXn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission20/Reviewer_FzXn"
        ],
        "content": {
            "summary": {
                "value": "The paper is an in-depth study on the randomized Langevin algorithms, particularly emphasizing the Randomized Midpoint technique in LMC. It is claimed that the bounds are superior to those previously established in the literature."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper consider widely-used randomized midpoint discretizations, offering notable enhancements over current standards, particularly in terms of condition number dependency and the stability of bounds. A key advantage of these bounds is their explicit numerical constants. The Randomized Midpoint is important  to achieve optimal convergence rates in first-order algorithms. The potential of extending this technique to other domains also presents an intriguing avenue for exploration."
            },
            "weaknesses": {
                "value": "While the paper presents some intriguing results, most of them primarily offers incremental advancements in the field. It applies the Randomized Midpoint technique to lessen discretization errors, which in turn marginally enhances the rate of convergence. However, the mathematical methods employed are not particularly interesting or surprising.\n\nThe empirical evidence looks weak to justify the criticality of the Randomized Midpoint in standard LMC."
            },
            "questions": {
                "value": "Can you provide any empirical evidence that the current algorithm improves in real world?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Reviewer_FzXn",
                    "ICLR.cc/2024/Conference/Submission20/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission20/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698546589352,
        "cdate": 1698546589352,
        "tmdate": 1700692374954,
        "mdate": 1700692374954,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "i2mMFQ2cy5",
        "forum": "hOxgrGM63n",
        "replyto": "hOxgrGM63n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission20/Reviewer_4YVq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission20/Reviewer_4YVq"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the randomized midpoint discretization for the kinetic Langevin diffusion for sampling from a target distribution with smooth and strongly log-concave density. A non-asymptotic upper bound on the W_2 error of this discretization is obtained. A bound on Euler discretization for the kinetic Langevin process is also obtained."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper provides strong error bounds on randomized midpoint discretization for the kinetic Langevin diffusion for sampling from a target distribution with smooth and strongly log-concave density. The bounds substantially improve upon earlier results, have explicit constant and transparent reliance on the initialization, and don't require starting at the minimizer of the potential. The proof technique is novel and is based on summation by part."
            },
            "weaknesses": {
                "value": "It would be nice if some simulations in higher dimensions p could be included in Section 5."
            },
            "questions": {
                "value": "In the second paragraph after (7), \"a close\" might be \"close\"?\n\nWould the qualitative behavior of numerical experiments change when the dimension p increases?\n\nIt seems that two notations d and p are used for dimension in Section 5."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Reviewer_4YVq"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission20/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698810693135,
        "cdate": 1698810693135,
        "tmdate": 1699635925264,
        "mdate": 1699635925264,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vZG3Io3Xra",
        "forum": "hOxgrGM63n",
        "replyto": "hOxgrGM63n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission20/Reviewer_Y55L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission20/Reviewer_Y55L"
        ],
        "content": {
            "summary": {
                "value": "This paper revisits the problem of sampling from strongly log-concave continuous distributions in high dimensions. A classical sampling algorithm for this task is the \u201cLangevin Monte Carlo\u201d  MCMC method which uses Langevin diffusion, a stochastic differential equation (SDE) that models the motion of a particle in a fluid. This paper provides an improved analysis of the randomized discretization scheme called \u201crandomized midpoint method\u201d for the aforementioned SDE. The results rely on the assumption that the magnitude of the eigenvalues of the potential function (i.e logarithm of the distribution\u2019s density function) is both upper and lower bounded, while the ratio $\\kappa$ between these upper and lower bounds appears in the bounds presented. Specifically, faster convergence of the randomized midpoint method for Langevin diffusion is shown for sufficiently small ratio $\\kappa$. Similarly, the authors analyze the randomized midpoint method for the kinetic Langevin Monte Carlo method to obtain improved bounds, although with some slightly stronger conditions and with the advantage of not having to find a minimizer of the potential function for initialization."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This is a well written paper that provides improved results on existing algorithms for Langevin sampling, which can be potentially applicable in a wide range of problems."
            },
            "weaknesses": {
                "value": "Some of the results are potentially still not optimal as the authors also suggest. It would also be nice to see how the improved bounds can be applied to some more concrete problems even for theoretical results. \n\n\nMinor comments:\n-Page 2, line 8: \u201cstrongly\u201d->\u201dstrong\u201d\n-Page 2, line 22: \u201cat\u201d->\u201da\u201d\n-Page 2, \u201cnotation\u201d paragraph, line 4: \u201csemi-definite positive\u201d->\u201dpositive semi-definite\u201d\n-Page 6, line 5: \u201cdesignatex\u201d->\u201ddesignate\u201d"
            },
            "questions": {
                "value": "Do you an example application of the improved analysis do get better results for a specific problem?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission20/Reviewer_Y55L"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission20/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699354212526,
        "cdate": 1699354212526,
        "tmdate": 1699635925186,
        "mdate": 1699635925186,
        "license": "CC BY 4.0",
        "version": 2
    }
]