[
    {
        "id": "83psgEmEos",
        "forum": "Z91rwXnJsw",
        "replyto": "Z91rwXnJsw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7976/Reviewer_gNN6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7976/Reviewer_gNN6"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method for object navigation. The agent is equipped with an RGBD camera and GPS+compass. The proposed approach uses a skill fusion decider that selects whether to execute steps from an RL policies or classical map-based approaches. As the agent traverses the environment, it builds a semantic map of the environment that is robust to noise, achieved through image dilation/erosion and temporal accumulation of confidence. They benchmark their approach on the Habitat 2023 object navigation challenge and show the proposed approach outperforms the challenge winner on the validation scenes."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The authors propose an interesting approach for object navigation that outperforms the baselines. Because it uses both classical map-based approaches and learned approaches, it is able to leverage the best of both worlds.\n* Approach is robust to segmentation noise\n* Writing is generally clear with a few gaps here and there (see below).\n* Useful and reasonable experiments.\n    * The proposed approach outperforms the baselines on a recent object navigation challenge, though the improvement is marginal under the OneFormer setting.\n    * Ablation study is useful. We can see how different parameter setups affect performance (e.g. number of frames, agent turn angle)."
            },
            "weaknesses": {
                "value": "* The motivation for the work is not very clear. Why do we think it's necessary to have the 4 combinations: classical exploration, classical goal reaching, RL-based exploration, RL-based goal reaching? What's the benefit over having just classical or just RL?\n* Writing is generally clear with a few gaps here and there, such as the definition of L_{fusion}, or when RL-based exploration is used (it is in Fig. 2 but not mentioned in Sec. 4.1 Skill Fusion Decider).\n* Navigation Image Sequences in 4.2 is not very well motivated. Is it to generally increase prediction accuracy by providing more contextual information about the scene/visuals? It's not clear how this relates to the segmentation model being trained on offline data.\n* Very similar to SkillFusion (Staroverov et al.). The contributions over this prior work seem minor."
            },
            "questions": {
                "value": "* What kind of sensor noise occurs at test time? Does the agent use ground truth odometry and depth?\n* The proposed method is very similar to SkillFusion (Staroverov et al.). What are the main differences and contributions over this prior work?\n* Please clarify the definition of L_{fusion}\n* When is RL-based exploration used?\n* There is a missing ablation on the proposal in 4.3. What happens when there is no erosion/dilation/accumulation/fading?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7976/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7976/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7976/Reviewer_gNN6"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7976/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698735993405,
        "cdate": 1698735993405,
        "tmdate": 1699636981485,
        "mdate": 1699636981485,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "X1MoON4dMp",
        "forum": "Z91rwXnJsw",
        "replyto": "Z91rwXnJsw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7976/Reviewer_H7Mw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7976/Reviewer_H7Mw"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes SkillTron, a navigation approach that uses a newly proposed two-level representation of interactive semantic map with robot skill selection for the object goal navigation task. Experiments are conducted on Habitat Matterport3D challenge."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper presents a valid and reasonable system for the ObjectGoal Navigation task.\n- Experiments show some improvement over baselines."
            },
            "weaknesses": {
                "value": "- The paper writing needs significant improvement for both English and the writing flow. I cannot understand a lot of sentences. And I can barely read into understanding the paper details.\n- The paper is more like an experiment report after participating the Habitat ObjectGoalNav challenge than a paper. The problem formulation is very specific for the specific challenge. I'm not sure if the paper has any generality that makes it interesting for general ICLR paper readers.\n- The proposed system mostly uses previous works as its components. It's unclear if there is any technical contribution in the method.\n- Experiments are weak, only comparing to 2 team submissions."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7976/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698825025740,
        "cdate": 1698825025740,
        "tmdate": 1699636981377,
        "mdate": 1699636981377,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "D3LX50O3a9",
        "forum": "Z91rwXnJsw",
        "replyto": "Z91rwXnJsw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7976/Reviewer_85u7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7976/Reviewer_85u7"
        ],
        "content": {
            "summary": {
                "value": "This work presents a new semantic map representation combined with leveraging a planning policy which uses multiple prior methods in a single system to explore and reach semantic targets in novel environments. The correctness of the 2D semantic map is measured as well as semantic navigation performance in novel environments in simulation."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The authors do a good job of performing ablations of their own method to determine the relative contribution of each of the components of their pipeline. The diagrams of their proposed pipeline are well made and clear. The description of the approach is also presented clearly and the motivation and details explained well."
            },
            "weaknesses": {
                "value": "The experimental results have substantial errors. The proposed method, SkillTron+SegmATRon, is evaluated on a manually selected subset of validation episodes from the HM3D dataset. Then, numbers from the Habitat Challenge are input in comparison which evaluate on a completely different set of test episodes which are not public. SkillTron+SegmATRon is not accurately compared (on one shared test set!) against published state-of-the-art methods for semantic navigation.\n\nIf the authors want to have a 1-1 comparison with alternate approaches without manually rerunning baselines on their custom testset, they should evaluate SkillTron+SegmATRon on the full test set for HM3D (the dataset they use) and then numbers from other papers which evaluate on this standard and public test set can be directly input into the comparison table. If they would like to evaluate against methods which run in the Habitat Challenge, they should submit their code to the Habitat Challenge so that they have also run on the same secret test set. However, running on the challenge should not replace running on a standard publicly available test (i.e. the HM3D test set) so that their paper has publicly reproducible evaluation results.\n\nAlso, the authors claim \u201csignificant improvement\u201d in the experiment section of SkillTron+SegmATRon over SkillTron+OneFormer (which seem to have been evaluated on the same test set) when the change in both success rate, SPL, and SoftSPL is 0.02 or less in every case and no standard error metrics are reported. So, it is not clear in the ablations whether the semantic map method actually yields a statistically significant change in performance at all.\n\nIn addition to the experimental errors, there are many statements throughout the paper in comparisons to related work which also are conjectures stated as facts. For example, in the introduction \u201csuch approaches are not correctly linked to the algorithms for planning map trajectories\u201d regarding the approach in (Ramakrishnan et al., 2022). Why is the RL approach used to plan a map trajectory in this paper \u201cincorrect\u201d?\n\nAlso, the authors should consider in the presentation of their method motivation: If the goal of their work is to find a highly accurate semantic map of the observed area, why should highly performant semantic SLAM methods not be used?"
            },
            "questions": {
                "value": "Note: the correct review template is not used. The heading says \u201cPublished as a conference paper at ICLR 2024.\u201d instead of \u201cUnder review as a conference paper at ICLR 2024\u201d. The authors are using the camera ready template with the author names deleted - not the anonymized submission template."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7976/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699187477311,
        "cdate": 1699187477311,
        "tmdate": 1699636981253,
        "mdate": 1699636981253,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TG3HjZHUSX",
        "forum": "Z91rwXnJsw",
        "replyto": "Z91rwXnJsw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7976/Reviewer_Xvsx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7976/Reviewer_Xvsx"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the problem of visual object navigation by combining active visual exploration and visual navigation with classical map exploration approaches. Regarding visual based navigation, it builds on SegmATRon, using an adaptive loss function to improve object segmentation during inference and create interactive semantic map representations. The proposed method improves the state-of-the-art (sota) on simulated data from the Habitat simulator and the Habitat challenge."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper proposes a complete architecture containing both learning-based and classic map-based planning methods to improve the performance on the visual object navigation task. The two approaches are combined using a decision module. Navigation is performed either by choosing actions based on a reinforcement learning pipeline fed by semantic segmentation of the scene, or by classical map-based navigation actions achieving both exploration and goal reaching. In the case of visual based navigation, the proposed method exploits the advantages of SegmATRon to achieve more reliable segmentation of the scene via online modification of the segmentation model weights during inference by using a buffer of frames collected during the execution of the actions."
            },
            "weaknesses": {
                "value": "The writing quality of the paper and the use of English could be improved. The paper also suffers from the quite tight page limit as the descriptions both of the full model and the individual modules are quite brief without covering crucial details regarding their motivation and the relative design choices. In fact, it appears to be very hard to reproduce this work based on the content of the paper, as many details regarding the architecture and the parameters of each module are not provided. \n\nAnother crucial aspect regards relation to prior work. It appears that the proposed architecture is heavily based on the SkillFusion paper, including a more powerful semantic segmentation approach (SegmATRon). This is not clearly stated in the text. It is crucial to make a detailed comparison between the SkillFusion model and the one presented in this work (SkillTRon). In general, it seems that the proposed method is a combination of sota methods. This is not a problem in general, but a comprehensive comparison with the corresponding methods should be provided, clarifying what are the relative improvement and contributions of the proposed work with respect to previous ones."
            },
            "questions": {
                "value": "- Please describe the difference with respect to the SkillFusion model."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7976/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699349106520,
        "cdate": 1699349106520,
        "tmdate": 1699636981149,
        "mdate": 1699636981149,
        "license": "CC BY 4.0",
        "version": 2
    }
]