[
    {
        "id": "1odIqVH99H",
        "forum": "Z59Rb5bPPP",
        "replyto": "Z59Rb5bPPP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1477/Reviewer_mABk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1477/Reviewer_mABk"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method called Trajeglish to generate future trajectories for traffic participants in a scenario. In particular, they propose a method to tokenize trajectory data using a small vocabulary. Besides, they propose a transformer-based architecture for modeling the action tokens on map information as well as initial states of traffic participants. To evaluate Trajeglish, the authors compare it with a behavior cloning method and a baseline that only models single agent trajectories. The result shows that their method achieves superior performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "### 1.The idea of tokenization using a small vocabulary is moderately novel.\n\n### 2.The visualization and illustration are well made and help the readers to understand the paper."
            },
            "weaknesses": {
                "value": "## Major:\n\n### 1.motivation of using tokenization (compared with using the actual values as in most of existing work in Appendix B) is not very clear.\n\n### 2.the experimental results are not very impressive\n\n(1) Improvements in Table 1 seem quite small. Can you show standard deviations for the results? \n\n(2) only evaluate on open-loop simulation but not on close-loop simulation\n\n(3) the baseline details are not given (e.g., \u201cThe \u201cmarginal\u201d baseline is an equally important baseline designed to mimic the behavior of models such as Wayformer (Nayakanti et al., 2022) and MultiPath++ (Varadarajan et al., 2021) that are trained to model the distribution over single agent trajectories instead of multi-agent scene-consistent trajectories.\u201d However, it is unclear if this baseline really can achieve similar performance as Wayformer / MultiPath++ as the authors did not give further details) and it is hard for one to assess if they are really strong baselines.\n\n### 3.motivation of having a model that take order into account is not very convincing\n\nIn particular, the idea of having this order seems very unnatural. For example, in the real world the likelihood of equally capable drivers (whether human or AI) to have collisions should be equal?\n\n## Minor:\n\n### 1.missing some relevant work on multi-agent trajectory prediction:\n\nHivt: Hierarchical vector transformer for multiagent motion prediction, Z. Zhou, L. Ye, J. Wang, K. Wu, and K. Lu.\n\nLanguage-Guided Traffic Simulation via Scene-Level Diffusion, Z. Zhong, D. Rempe, Y. Chen, B. Ivanovic, Y. Cao, D. Xu, M. Pavone, B. Ray\n\n### 2.did not discuss the limitations of the current work"
            },
            "questions": {
                "value": "-What\u2019s the motivation of using a small vocabulary compared with using the actual values as in most of existing work (as in Appendix B)?\n\n-The provided video is a bit confusing. How do you control other vehicles that are neither replay nor trajeglish? In some videos the legends only show these two types but there are vehicles of other colors.\n\n-Can you also show the variance for Figure 8?\n\n-Figure 9 why the collision rate decreases when the rollout becomes longer?\n\n-Trajgelish behavior under longer horizon rollout (e.g., 200 timesteps)?\n\n-For the experiments, 16 scenarios are sampled for every clip in WOMD? Or only 16 clips in total?\n\n-Can you also provide some qualitative visualization for nuscenes in Appendix?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1477/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1477/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1477/Reviewer_mABk"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1477/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697569667489,
        "cdate": 1697569667489,
        "tmdate": 1700755713620,
        "mdate": 1700755713620,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8G2LC3gKzk",
        "forum": "Z59Rb5bPPP",
        "replyto": "Z59Rb5bPPP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1477/Reviewer_qzEz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1477/Reviewer_qzEz"
        ],
        "content": {
            "summary": {
                "value": "\u201cTrajeglish: Learning the Language of Driving Scenarios\u201d proposes a model that can create scene-consistent rollouts for a subset of agents in a scene. In particular, the proposal consists of a tokenization algorithm, \u201ck-disks\u201d, for tokenization an agent\u2019s motion, and a transformer-based model architecture that autoregressively and causally rolls out agents\u2019 future trajectories. The authors provide competitive results on WOMD and transfer to nuScenes."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Strong tokenizer k-disks outperforming kMeans baselines with low discretization errors and convincing ablation study\n* Autoregressive and casual rollouts\n* Experiments demonstrating the benefits of intra-timestep dependence of agents\n* Experiments demonstrating the transfer to nuScenes"
            },
            "weaknesses": {
                "value": "* Missing WOMD baseline results from other models\n* Similar contributions as the recently published \u201cMotionLM: Multi-Agent Motion Forecasting as Language Modeling\u201d (https://arxiv.org/pdf/2309.16534.pdf)"
            },
            "questions": {
                "value": "* How does your approach compare to the recently published \u201cMotionLM: Multi-Agent Motion Forecasting as Language Modeling\u201d (https://arxiv.org/pdf/2309.16534.pdf)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1477/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698446791989,
        "cdate": 1698446791989,
        "tmdate": 1699636076715,
        "mdate": 1699636076715,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NqBIX5lL1W",
        "forum": "Z59Rb5bPPP",
        "replyto": "Z59Rb5bPPP",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1477/Reviewer_KYot"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1477/Reviewer_KYot"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a language modeling inspired approach to data-driven traffic simulation. The key step involved is tokenizing future driving scenario data into a sequential, language-style format, for which this paper compares several tokenization schemes. Once tokenized, a simple transformer encoder-decoder architecture is proposed to encode the initial scene state and autoregressively decode the tokenized scene future. Training the model follows the standard next token prediction objective as in language modeling, with an optional noise term on the ground truth tokens to deal with distribution shifts caused by teacher forcing. A diverse set of experiments on the Waymo Open Motion Dataset (WOMD) provide several insights on how design choices for this new formulation impact simulation quality."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The key strengths of this work lie in its conceptual and architectural simplicity in comparison to existing methods. The idea is well-motivated and the presentation is clear. Besides this, the paper provides a detailed experimental analysis on different aspects of the proposed design space."
            },
            "weaknesses": {
                "value": "1. The benchmarking in Table 1 follows a much simpler setting with fewer max agents (24 vs. 128) and a shorter time horizon (6 seconds vs. 8 seconds) than prior work on WOMD [1,2,3]. \n2. As a result of this simpler benchmark and missing comparisons to any prior architecture, this paper does not address the key question of whether the proposed method is competitive to the current state-of-the-art despite its simplicity. At a glance, it seems to be much worse, with a minADE >3m in comparison to the SoTA methods with minADE < 1m on the more challenging standard WOMD setting. \n3. The paper is not self-contained, with important details (e.g., related work and several figures referenced during discussions in the main paper) only available in the appendix\n\n[1] https://arxiv.org/abs/2209.13508\n\n[2] https://arxiv.org/abs/2306.17770\n\n[3] https://arxiv.org/abs/2309.16534"
            },
            "questions": {
                "value": "1. Please see \u201cWeaknesses\u201d - these are the key points with the most influence on my rating. If addressed via a fair and direct comparison to existing work, I am inclined to improve my rating.\n2. Given the simple and scalable architecture, it would be interesting to analyze the importance of scale (in terms of #parameters in the encoder/decoder) towards the performance of the proposed model.\n3. The clarity of Figure/Table captions and their placement within the document could be improved, currently, they are often very far from the text referencing them.\n4. How are actors ordered in the decoder? Is this randomized for each scene during both training and inference?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1477/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1477/Reviewer_KYot",
                    "ICLR.cc/2024/Conference/Submission1477/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1477/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698944558818,
        "cdate": 1698944558818,
        "tmdate": 1700811255661,
        "mdate": 1700811255661,
        "license": "CC BY 4.0",
        "version": 2
    }
]