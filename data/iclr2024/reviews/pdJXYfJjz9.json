[
    {
        "id": "fC4ZnwgtWd",
        "forum": "pdJXYfJjz9",
        "replyto": "pdJXYfJjz9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_rX1q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_rX1q"
        ],
        "content": {
            "summary": {
                "value": "Summary.\n\nThis paper proposes the CoIC algorithm to train CNN and Transformer based models to be instance-specific, using mixed datasets, for single image rain removal. The CoIC algorithm includes a Context-based Instance-specific Modulation (CoI-M) mechanism and a rain-/detail-aware contrastive learning strategy."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Strengths.\n\nThe paper is generally easy to read and follow.\nThe proposed approach seems to work well for CNN based models.\nExperiments (with tables and figures) are provided to analyze the proposed method.\nThe proposed method seems to work well on the RealInt (Wang et al., 2019), in terms of NIQE.\nThe idea of generating negative examples for both rain and background and modulating the image-specific information into networks sounds interesting."
            },
            "weaknesses": {
                "value": "Weaknesses/Questions.\n\n\nThe Introduction mentions that there is a long-tail distribution across mixed datasets. As most (if not all) datasets are synthetic, would it be easier/better to synthesize more rain images to handle such an unbalanced distribution? Another question is whether training using a mixed dataset improves the individual performance of one model on each dataset. These answers are not easily found in this paper. \n\nFigure 1(b) shows one observation of this paper that the image is gradually dominated by rain when rain density increases, which, however, sounds superficial. The resulting (from this observation) learning of a joint embedding space for both rain and detail information is based on contrastive learning, while it is not explained why using contrastive learning here as it seems that rain density is the most important factor. Meanwhile, the paper simply says it is distinct from previous instance-discriminative contrastive learning (He et al., 2020) without explanation.\n\nThe Introduction mentions that the embedding space of this paper is not instance-level discriminative, which is hard to understand as the paper aims to learn instance-specific deraining features (If not discriminative enough, how can one model learn the specific information?) The second point it mentions is that the background content is not discriminative, which I do not know whether it is correct, does not explain why it is not suitable for a standard contrastive learning strategy. After I read the method section, it seems to me that the main difference is to construct negative examples based on rain types (selected from another dataset) and Gaussian blurred background. The authors may correct me if I misunderstood but it seems to me that the discussion in the introduction does not match what they do in the method.\n\nThe paper uses Gaussian blur to construct negative exemplars of the background image, which needs further justification as it may not represent the degraded backgrounds. Usually when rain streaks are large or dense, there are more occlusions than blur, which the Gaussian blur may not model.\n\nThe related work section should be expanded. 1. There are certainly several rain removal methods not cited, especially for heavy rain restoration, although they do not combine multiple datasets for training. 2. The modulation is one of the key techniques in the proposed method but there is no literature review on it.\n\nIn Table 1, the performance gain over DRSformer (Chen et al., 2023) is rather limited. The paper needs to show more advantages, otherwise, it seems not worth doing considering the efforts and the performance gains.\n\nThe visual results are not impressive, as we may easily see the remained rain streaks in, e.g., Figure 4, Figure 12. I understand that there are improvements by comparing the results of methods with and without CoIC. However, it seems to me that these visual results are still failure cases (due to obvious rain streaks, in Figure 12, (g) is comparable to or even better than (h)). Combining it with Table 1, really makes others wonder about the necessity of using the proposed approach."
            },
            "questions": {
                "value": "Please see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7082/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697531309650,
        "cdate": 1697531309650,
        "tmdate": 1699636835322,
        "mdate": 1699636835322,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JypIx7ZrgT",
        "forum": "pdJXYfJjz9",
        "replyto": "pdJXYfJjz9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_iZXv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_iZXv"
        ],
        "content": {
            "summary": {
                "value": "Existing de-raining methods tend to overlook the inherent differences between datasets. To address this limitation, this paper develops a rain-/detail-aware contrastive learning strategy to extract a representation, and proposes a Context-based Instance-specific Modulation mechanism, which uses the representation to modulate models. This approach helps existing methods boost the de-raining ability."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper focuses on training de-raining models on amalgamated datasets.\n2. The experiments are sufficient and the results are better than others.\n3. Visualization results on RealInt demonstrate the generalization capability of this method on real scenes."
            },
            "weaknesses": {
                "value": "1. The main concern is the necessity of the proposed method. In fact, when the deraining model is strong enough, it may be able to learn the differences between datasets. For example, in Table 1, the proposed method has limited performance improvement on DRSformer and DGUNet.\n2. The novelty of the method may be limited. The method of representation extraction based on contrastive learning has been widely explored in the blind super-resolution field [1]. The paper needs to further explain the differences with them.\n[1] Unsupervised Degradation Representation Learning for Blind Super-Resolution. CVPR 2021.\n3. It would be better to show the increase in the number of parameters and changes in inference time brought by the proposed method."
            },
            "questions": {
                "value": "Please see 'Weaknesses'."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7082/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7082/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7082/Reviewer_iZXv"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7082/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698741129568,
        "cdate": 1698741129568,
        "tmdate": 1699636835175,
        "mdate": 1699636835175,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "INisDd7Nwl",
        "forum": "pdJXYfJjz9",
        "replyto": "pdJXYfJjz9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_v7hb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_v7hb"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a context-based instance-specific modulation (CoI-M) method for learning adaptive image de-raining models with mixed datasets. The goal is to exploit the commonalities and discrepancies among datasets for training. This mechanism can efficiently modulates both CNN and Transformer architectures. CoI-M is also verified to improve the performances of existing models when training on mixed datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ As to the paper structure, I think it is clear and easy to follow. \n\n+ The authors claims that images with light rain are primarily characterized by background detail, while heavy rainy images are distinguished more by the rain itself. The statistical analysis in Figure 1 is suitable.\n\n+ The experimental results indicate that the proposed method can further improve performance."
            },
            "weaknesses": {
                "value": "- It is not clear how to select the positive and negative exemplars. The author should discuss the differences with relevant contrastive learning-based deraining methods [1-2].\n[1] Chen et al, Unpaired deep image deraining using dual contrastive learning, CVPR2022.\n[2] Ye et al, Unsupervised deraining: Where contrastive learning meets self-similarity, CVPR2022\n\n- I suggest the author conduct further validation on the mixed dataset Rain13K.\n\n- The figures included in the manuscript are rendered with small font sizes and low resolution, which makes them challenging for reviewers to examine and comprehend. I recommend revising the figures to meet these requirements to improve the overall quality and accessibility of the visuals in the manuscript.\n\n-----------------------After Rebuttal---------------------------\n\nThank you for your feedback. The rebuttal addressed my concerns well. I have decided to increase my score."
            },
            "questions": {
                "value": "See the above Weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7082/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7082/Reviewer_v7hb",
                    "ICLR.cc/2024/Conference/Submission7082/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7082/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699201141901,
        "cdate": 1699201141901,
        "tmdate": 1700746582538,
        "mdate": 1700746582538,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mdSflDdsWQ",
        "forum": "pdJXYfJjz9",
        "replyto": "pdJXYfJjz9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_zqPW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_zqPW"
        ],
        "content": {
            "summary": {
                "value": "The paper focuses on tackling the single image deraining problem, wherein the authors introduce instance-specific de-raining models. These models are designed to delve into meaningful representations that capture the distinct characteristics of both the rainy elements and the background components in images affected by rain. Authors propose Context-based Instance-specific Modulation (CoI-M) mechanism which can modulate CNN- or Transformer-based to learn the representations specific to rain details and background. Authors also propose  rain-/detail-aware contrastive learning strategy to help extract joint rain-/detail-aware instance-specific representations. Integrating these modules authors claim that the proposed method can handle multiple different rain datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- proposed Context-based Instance-specific Modulation (CoI-M) mechanism which can modulate CNN- or Transformer-based to learn the representations specific to rain details and background\n     - employed feature extractor E,  and a Global Average Pooling (GAP) operation to capture rich spatial and channel information related to rain and image details.\n- proposed contrastive learning strategy to help extract joint rain-/detail-aware instance-specific representations\n     - to make the encoder discriminate the rain in (x,y) pair of rainy images they use leverage a rain layer bank noted a D_{R}\n     - proposed contrastive learning based loss to learn the difference in representations of different rains and also image representations.\n- Proposed Context-based Instance-aware Modulation (CoI-M) mechanism to modulate features at different layers in CNN, and attention layers in transformer based networks, to learn the embedding space spanned by all instance-specific representations."
            },
            "weaknesses": {
                "value": "- the comparisons are inadequate. There is rich literature in semi-supervised and continual learning that focuses on representation learning for different types of rain and image representations. Authors failed to compare with the existing methods.\n    -  Memory Oriented Transfer Learning for Semi-Supervised Image Deraining, CVPR 2021.\n        proposes a representation learning based approach where they learn basis vectors (which called memory) to represent the rain and adapt them using them for different datasets to minimize the differences the datasets. The proposed Col-C is also doing similar to this, so it will be easy for the reader to understand the benefits of CoI-C if authors can compare with this method.\n    - Syn2Real Transfer Learning for Image Deraining using Gaussian Processes, CVPR 2020.\n        proposes a Gaussian process based pesudo labeling approach where enable the encoder to learn representation rain and image using generated pesudo label. Note the here in Syn2Real they formulate the joint Gaussian distribution to generated a pesudo label for the unknown or unlabeled image, in way they selecting the k-nearest labeled images and maximizing correlation between unlabeled and labeled  similar type of rain images. Also minimizing correlation between k-nearest farthest labeled images and  unlabeled and labeled  similar type of rain images. Thus Syn2Real approach can be compared to proposed contrastive loss and CoI-C approach, to understand benefits of CoI-C.\n     - Unpaired Deep Image Deraining Using Dual Contrastive Learning, CVPR 2022.\n       proposed a contrastive based approach to learn the representation of rain and image and guide the networks to learn removal network and image generator networks in an unsupervised cyce-GAN approach. Thus, it would be great to see comparisons of CoI-C against this method."
            },
            "questions": {
                "value": "Please refer weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "not aplicable"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7082/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699218980106,
        "cdate": 1699218980106,
        "tmdate": 1699636834929,
        "mdate": 1699636834929,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "g69gjAjqye",
        "forum": "pdJXYfJjz9",
        "replyto": "pdJXYfJjz9",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_nGEY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7082/Reviewer_nGEY"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an instance-specific de-raining models by exploring representations that characterize both the rain and background components in rainy images. The authors first propose a rain-/detailaware contrastive learning strategy to explore joint rain-/detail-aware representations. Leveraging these representations as instructive guidance, the authors furhter introduce CoI-M to perform layer-wise modulation of CNNs and Transformers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1, The paper is well-written. \n\n2, The paper may be meaningful to some extent for the deraining community.\n\n3, The results reveal that the proposed method consistently improves previous baselines.\n\n4, The proposed instance-specific method may be useful to other low-level vision tasks, e.g., dehazing, desnowing, super-resolution, etc."
            },
            "weaknesses": {
                "value": "Although this paper has some strengths, I am still confused by following questions:\n\n1, The proposed techniques seem to be a guidance for deraining, i.e., the authors attempt to constrain an instance-specific representation to guide the deraining.\n\nAlthough this, the reviewer would like to know the increased parameters and FLOPs.\n\n2, Whether the training iterations of the proposed method are the same with the applied method? i.e., BRN, RCDNet, DGUNet, IDT, DRSformer. If not, the comparisons are unfair.\n\n3, The reviewers would like to see the training curve comparisons, e.g., BRN, RCDNet, DGUNet, IDT, DRSformer vs. BRN+ CoIC, RCDNet+ CoIC, DGUNet+ CoIC, IDT+ CoIC, DRSformer+ CoIC.\n\n4, The paper title is the  INSTANCE-SPECIFIC IMAGE DE-RAINING, the reviewer thinks that this is not suitable since the authors also train the deep models on Rain13K. The dataset can be regarded as one entirety. It is hard to reflect the 'INSTANCE'. Whether it has a better title? The reviewer thinks that if the paper does a continual learning for deraining and demonstrates the CoIC can consistently improve the  performance on each dataset, the 'INSTANCE' may be suitable.\n\n5, Deraining methods with high PSNR and SSIM usually tend to overfit to synthetic datasets. Hence, deraining performance would be worse on real datasets. Whether the authors can further solve this problem? \n\n6, Can the rain-aware negative exemplars be images with real rain streaks? Whether the authors consider to explore the real images to participate in training to improve the generalization to real scenes? \n\n7, I have observed that the authors mention the generalization many times. However, only training on synthetic dataset is hard to improve the generalization because of overfitting."
            },
            "questions": {
                "value": "See Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7082/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7082/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7082/Reviewer_nGEY"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7082/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699538272290,
        "cdate": 1699538272290,
        "tmdate": 1699636834826,
        "mdate": 1699636834826,
        "license": "CC BY 4.0",
        "version": 2
    }
]