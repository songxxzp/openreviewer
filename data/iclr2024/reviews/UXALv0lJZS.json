[
    {
        "id": "EdzRPGS77p",
        "forum": "UXALv0lJZS",
        "replyto": "UXALv0lJZS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3618/Reviewer_9rFE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3618/Reviewer_9rFE"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a single-channel speech separation method using a combination of deterministic and generative models. An upper bound on the signal distortion ratio (SDR) of this combined method is derived, suggesting that it has the potential to be better than the deterministic model alone."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The authors innovatively integrate deterministic models with generative models for speech separation and theoretically demonstrate the performance boundaries of this approach.\n2. To address the phase shift issue between the output estimates of the deterministic and generative models, an alignment network is employed to estimate two parameters for the fusion of the outputs from both models.\n3. Results across multiple datasets and models indicate that this method can further improve the performance of existing models."
            },
            "weaknesses": {
                "value": "1. **Generative Model Selection:** The authors' choice of utilizing only one diffusion-based generative model to validate the performance enhancement brought by noise introduction appears to be limiting. Although the theoretical incapacity of deterministic generative models to achieve performance enhancement has been demonstrated, the naturalness in generation by HiFiGAN is inherently lower than that of DiffWave. This raises concerns about whether this disparity is the reason for HiFiGAN's lack of improvement. I would recommend the authors consider incorporating other diffusion-based generative models, such as FastDiff [1], or superior deterministic models like UnivNet [2], to bolster the robustness of their results.\n2. **Deterministic Model Upper Bound:** I disagree with the notion that deterministic models possess an upper bound. Recently, TF-GridNet results surpassed the so-called upper bound of deterministic models, attaining an SI-SDRi of 23.4, which is strikingly close to the SepFormer + DiffWave model. It would be prudent for the authors to include results on TF-GridNet to underscore the necessity of noise introduction in diffusion-based generative models. Training a generative model alone can be computationally demanding, and might not be the optimal solution just for a marginal performance gain.\n3. **Alignment Network Concerns:** Regarding the alignment network, the authors utilize the relative phase difference between $V_g$ and $V_d$ as well as the phase of $V_d$ as inputs to align the phase of the fused output with $V_d$. This poses a question: Is the observed enhancement in model performance a result of the phase alignment between $V_g$ and $V_d$, or is it due to the introduction of additional parameters, i.e., the alignment network? Another hypothesis worth considering is if the alignment network, when directly using the phase of $V_g$ and $V_d$ as inputs, would produce a similar effect.\n4. **Testing on Noisy Datasets:** One notable observation from the manuscript is its primary focus on clean datasets for evaluation. It would be beneficial to see how the proposed combined model performs on noisy datasets, such as WHAM! or the noisy version of Librimix. Evaluating on these datasets can provide insights into the model's robustness in more realistic scenarios, where environmental noise might significantly impact the performance of the generative model. Such an evaluation will offer a more comprehensive understanding of the model's real-world applicability and its ability to tackle inherent challenges posed by noisy environments.\n5. **Training Concerns:** The manuscript should clearly specify whether the separation and generative models were involved in the training of the alignment network $F$.\n6. **Symbol Representation:** Please ensure a consistent and standardized representation of symbols throughout the paper. Conventionally, vectors are denoted in boldface.\n\n[1] Huang R, Lam M W Y, Wang J, et al. Fastdiff: A fast conditional diffusion model for high-quality speech synthesis[J]. arXiv preprint arXiv:2204.09934, 2022.\n\n[2] Jang W, Lim D, Yoon J, et al. Univnet: A neural vocoder with multi-resolution spectrogram discriminators for high-fidelity waveform generation[J]. arXiv preprint arXiv:2106.07889, 2021."
            },
            "questions": {
                "value": "My detailed questions are as described above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3618/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3618/Reviewer_9rFE",
                    "ICLR.cc/2024/Conference/Submission3618/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3618/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697641792994,
        "cdate": 1697641792994,
        "tmdate": 1700563188772,
        "mdate": 1700563188772,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "B2E4s4EViS",
        "forum": "UXALv0lJZS",
        "replyto": "UXALv0lJZS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3618/Reviewer_d285"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3618/Reviewer_d285"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new method for the source separation problem. First, a discriminative model is used to produce output sources. Then a generative model is used to refine those signals conditioned on the output of the discriminative model. Finally, a learned mixing coefficient is used to blend between the generative and discriminative outputs."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Overall I appreciate the method and the author's approach to using generative models. Generative models have shown strong performance in many areas and their use in source separation has been somewhat limited. I also appreciate the theoretical analysis which provides solid justification for the choices and results.\n\nThe ablation study shows that the the mixing network is in fact helpful, since the naive approach would be to just use the generative output v_g directly.\n\nIt is also nice that the authors use a variety of discriminative models and compare them, which shows that the method is general. \n\nThe output audio examples provide a good sense to the listener of the model's performance"
            },
            "weaknesses": {
                "value": "The main issue I have is the usefulness of the theoretical bounds given the underlying assumptions. The paper build heavily on the analysis in Lutati et al. where the bounds were derived by making assumptions on the context used. These assumptions provide a bound that is not realistic, as evidenced by the fact that the bound for WSJ2 mix is 23.1dB but TF-Gridnet achieved 23.4dB gain using purely a discriminative complex valued model. This is something that should be discussed in the paper more."
            },
            "questions": {
                "value": "I would like to see an ablation where only the generative output is used after conditioning on the discriminative output (not a simple average like the current ablation). Have you done those experiments and how did they perform?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3618/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698712522165,
        "cdate": 1698712522165,
        "tmdate": 1699636316998,
        "mdate": 1699636316998,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qMWjDjkF7i",
        "forum": "UXALv0lJZS",
        "replyto": "UXALv0lJZS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3618/Reviewer_fbeS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3618/Reviewer_fbeS"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a diffusion-based post-processing module for single-channel speech enhancement. The authors present a mathematical derivation of the upper-bound of the source-to-distortion for generative methods, proving an improvement over the bound derived for deterministic models in prior work. They also present an architecture that combines the discriminative estimation and the generative estimation in the Fourier domain, which consists of a separation module, a generative module, and a mixing weights prediction module. Empirical results on a number of popular speech separation architectures on two speech separation datasets with multiple speaker numbers demonstrate the effectiveness of the proposed approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea of diffusion-based separation has been applied in speech separation, but the primary novelty of this work lies in the mathematical perspective of improving the SDR upper-bound with the generative approach by combining the output of the discriminative and generative estimations.\n\nThe experiments are conducted across several different separation architectures and for two popular source separation datasets (with several speaker-number settings), and an ablation study of the mixing network is performed. The empirical results demonstrate the improvement of the proposed method with deterministic SOTA on speech separation."
            },
            "weaknesses": {
                "value": "My major concern about the current version of this manuscript is the clarity of the writing. There are a number of notations (e.g., $v_r, v_{gr}, v_{dr}$) that are used across multiple sections of the paper, but these notations are not easy to follow and the consistency could be improved. In particular:\n\n- Introduction could be clearer with all variables properly defined with types (real vs complex), and dimensions. Additionally, I suggest beginning with some motivation (reiterating parts of Section 2) but focusing on the bottleneck of the existing (deterministic and discriminative) approaches.\n\n- Please make sure to define the acronyms at the first usage (e.g., SDE in Section 2, GM in Section 3.1).\n\n- Please resolve the inconsistency\n  - notations between the opening paragraph ([$\\alpha_i, \\beta_i$] = F($\\bar{v}_d^i, \\bar{v}_g^i$) vs ([$\\alpha_i, \\beta_i$] = F($\\bar{V}_d^i, \\bar{V}_g^i$) in (4).\n  - $I(m_r, v_r)$ --> $I(m_r; v_r)$ in (6).\n  - $p(v_{d}r) --> p(v_{dr})$ in Section 3.1.\n  - The notations of $v_{gr}, \\bar{v}_{gr}$ and $v_{dr}, \\bar{v}_{dr}$ in Section 3.\n\n- In (10): it seems there is overloading of the notation $p(v_{gr})$ on LHS and RHS of the equation.\n\n- The font size of the equations and figure labels could be improved.\n  - In Figure 4 (a), the x-label \"MSE\" is in italics, whereas for (b) it is not.\n  - I would recommend disabling the italics for function names such as \"argmax\", \"ELBO\", \"SDR\", \"log\", etc."
            },
            "questions": {
                "value": "- I'm uncertain on how the two inequalities in (11) are derived. For the first inequality, how is $I(v_r; v_{gr})$ related to $I(v_r; v_{dr},v_{gr})$ in (9)? The necessary condition for the second inequality is $I(v_r; v_{gr}, v_{dr}) \\leq I(v_r; m_r)$, but this is not implied from (7) or (9). It would be helpful if the authors could clarify the steps. Also, it'll be helpful to explain how the \"3.0\" db is obtained in (21).\n\n- Any reason for transposing the horizontal and vertical axes for the visualizations in Figure 5? It is conventional to display the spectral information in the vertical axis and temporal dimension horizontally.\n\nUpdate after rebuttal: I'd like to thank the authors for addressing the questions. The scores have been updated."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3618/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3618/Reviewer_fbeS",
                    "ICLR.cc/2024/Conference/Submission3618/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3618/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699177281027,
        "cdate": 1699177281027,
        "tmdate": 1700639752116,
        "mdate": 1700639752116,
        "license": "CC BY 4.0",
        "version": 2
    }
]