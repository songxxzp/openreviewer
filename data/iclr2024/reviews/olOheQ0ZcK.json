[
    {
        "id": "xHXJwU4eFD",
        "forum": "olOheQ0ZcK",
        "replyto": "olOheQ0ZcK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission651/Reviewer_F6ny"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission651/Reviewer_F6ny"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of estimating the distances between two distributions $P$ and $Q$ over the $n$-dimensional Boolean hypercube. Since the problem is known to require $\\Omega(2^n/n)$ samples from $P$ and $Q$ to estimate the distance up to an additive constant, this paper considers the subcube conditioning query model, where each query can be made from $P$ and $Q$ conditioned on a specified subcube of the domain. This paper gives an algorithm for estimating the distance to additive $\\varepsilon$ using $\\tilde{O}(n^3/\\varepsilon^5)$ queries as well as a lower bound showing that $\\Omega(n/\\log n)$ queries are necessary in the subcube conditioning model for constant $\\varepsilon$."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "+ To the best of my knowledge, the problem of distance estimation has not previously been studied in the subcube conditioning model. \n+ The polynomial query complexity in the subcube conditioning model is an exponential improvement over the known $\\Omega(2^n/n)$ query complexity lower bound in the standard model."
            },
            "weaknesses": {
                "value": "- Although there is good intuition for parts of the main result, I think the paper could benefit from additional algorithmic/analytic intuition rather than the full formal proofs. For example, I would have liked to see more details about how the tamed distribution could be accessed using subcube conditioning queries. I would have also liked to see intuition on where the $n^3$ and $1/\\varepsilon^5$ factors come from.\n- It is not clear to me that the applications of distance estimation with subcube conditioning queries is well-suited for the particular learning theory community at ICLR.\n- Although I do not think experiments are necessary for a paper with solid theoretical foundations, I think the experimental section of this paper is a bit unclear (see questions below).\n\nIn summary, my concern is that the current presentation of the paper may not supply sufficient context for a theoretical audience but the applications/experiments are also not extensive enough for an applied audience. Hopefully the authors can respond to this concern in the discussion phase."
            },
            "questions": {
                "value": "1) How is the distance estimation problem applied to constrained samplers? \n2) How was the scalable benchmark generated and how are the real-world circuits represented by the Boolean formulas?\n3) How does the tradeoff between sample complexity and TVD look like for these datasets?\n4) What are additional applications of distance estimation with subcube conditioning queries?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission651/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697607608670,
        "cdate": 1697607608670,
        "tmdate": 1699635992711,
        "mdate": 1699635992711,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vyZUVlspEH",
        "forum": "olOheQ0ZcK",
        "replyto": "olOheQ0ZcK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission651/Reviewer_SPku"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission651/Reviewer_SPku"
        ],
        "content": {
            "summary": {
                "value": "This paper claims itself presents the first polynomial sample distance estimator in the conditional sampling model. This paper provides detailed proofs and simple experiments for this paper."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This paper presents the first polynomial sample distance estimator in the conditional sampling model. I roughly check the proof, and they are OK to me at this time. Consequently, in theory aspect, I am satisfied with authors' contributions."
            },
            "weaknesses": {
                "value": "Although I am satisfied with authors' theoretical contributions, I am \"extremely' unsatisfied with experiment part of this paper. Figure 1 and Table 1 just do not make any sense to me. If authors could improve that part, I will largely raise my rating.\n\n1. Please conduct 'enough' experiments to justify your theorem. This can be plots of repeated experiments showing the relationships between $n$, $\\delta$, and $\\epsilon$, which is widely used in this area. \n\n2. Dimensions in your experiments are not high enough, and $\\epsilon$ is too large. \n\n3. If possible, provide a comparison of your method with other existing methods, which could further demonstrate the significance of your method."
            },
            "questions": {
                "value": "Is that possible to provide a high probability bound with respect to the number of queries? If not, could your provide the technical hardness?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission651/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission651/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission651/Reviewer_SPku"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission651/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698007334198,
        "cdate": 1698007334198,
        "tmdate": 1700810205868,
        "mdate": 1700810205868,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KA7ousTHcS",
        "forum": "olOheQ0ZcK",
        "replyto": "olOheQ0ZcK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission651/Reviewer_4aJb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission651/Reviewer_4aJb"
        ],
        "content": {
            "summary": {
                "value": "It is known that estimating TV distance between two discrete probability distributions over $\\{0,1\\}^n$ has a sample complexity lower bound of $\\Omega(2^n/n)$. In this work, the authors focus on a more powerful model, namely SUBCOND, which takes a prefix as input and returns the full string according to the conditional distribution. With this model, the authors design DistEstimate algorithm that makes $\\tilde{O}(n^3\\log(1/\\delta)/\\varepsilon^5)$ calls to SUBCOND and returns an estimate of the TV distance with margin of error $\\varepsilon$ with probability $1-\\delta$."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The authors provide clear motivation in terms of why a stronger model is needed for distance estimation.\n- The explanation of the algorithm is clear.\n- The proof of the main theorem is mostly self-contained. The proofs, from a quick read, seem sound. The technique of computing expectation of number of queries using properties of negative binomial distributions is really nice.\n- A direction for future research is also discussed."
            },
            "weaknesses": {
                "value": "- There needs to be an example in the introduction that describes scenarios in which the SUBCOND query is available. Personally, I have been very curious in such scenarios until I read the Application section.\n- In the experiment, $\\varepsilon=0.5$ is too large considering the scale of the TV distances. Also, there should be error bars in Figure 1, at least for small numbers of dimensions in order to demonstrate the stability of the algorithm."
            },
            "questions": {
                "value": "- Algorithm 1 returns the average of  $1-p_i-q_i$. Should the definition of $Z$ in Lemma 1 be divided by $m$ as well?\n- I suggest the authors add a simulation to confirm that DistEstimate attains $\\varepsilon$-estimation error with probability at least $1-\\delta$.\n\nMinor comments:  \n- The notations for the probability distributions are not consistent. Some times they are $P,Q$, the other times they are $\\mathcal{P},\\mathcal{Q}$. Please check throughout the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission651/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698750330500,
        "cdate": 1698750330500,
        "tmdate": 1699635992559,
        "mdate": 1699635992559,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uWT35gWcT2",
        "forum": "olOheQ0ZcK",
        "replyto": "olOheQ0ZcK",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission651/Reviewer_YTK5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission651/Reviewer_YTK5"
        ],
        "content": {
            "summary": {
                "value": "This paper considers the problem of estimating the total variation distance between distributions $P$ and $Q$ on $\\{0,1\\}^n$. This problem is known to require $\\exp(n)$ samples if we only get access to queries. This paper considers the SUBCOND model, where you are allowed to sample from a distribution conditioned on a certain prefix. It proves that one can estimate the TV distance with query complexity $poly(n, 1/\\epsilon)$. I found this statement surprising (although I am not familiar with the literature in the area which is vast).   In terms of techniques, the paper seems to make use of prior results which adding some new ingredients of its own. I think this is a nice contribution that ought to be accepted."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. The problem of TV estimation is important. The existing lower bounds are very strong, which motivates looking for other models where it is easier to estimate. The SUBCOND model is fairly natural for the Boolean hypercube setting.\n\n2. I found the result in itself surprising, though I am not an area expert. After understanding the paper better, maybe I am a little less surprised, but I still think its a great result. \n\n3. Technically, the paper is sound, and above the bar for acceptance. There seem to be two novel ideas, the simpler one is to  \"tame\" the distribution so that there is some non-trivial probability on both the subcubes $x_i = 0$ and $x_i =1$. This is achieved essentially by adding some noise to the distribution. The second is using the conditioning oracle to get a multiplicative approximation to the probability of string, using the formula $\\Pr[x =a] = \\Pr[x_1 =a_1]\\cdot \\Pr[x_2 =a_2|x_1 =a_1] \\cdots$.  It is simple and elegant. They plug this into a previous result that lets you estimate the total variation distance given good enough estimates of the importance weights."
            },
            "weaknesses": {
                "value": "1. The title promises too much compared to what the paper delivers. When most people think of high dimensional distributions, they don't have the Boolean hypercube in mind as the domain, they would think of $\\mathbb{R}^n$. I would suggest adding \"discrete distributions\" to the title, and possibly mentioning the need for conditional samples.\n\n2. On a related note, the SUBCOND model is very natural in the discrete setting (for product domains). I wonder to what extent these techniques can extend to other domains, and what a reasonable analog of this model might be."
            },
            "questions": {
                "value": "- It appears that your results allow you to estimate the importance weights  $Q(x)/P(x)$ for $x \\sim Q$. If so, this might be useful for estimating various other divergences such as KL and Renyi."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "none"
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission651/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission651/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission651/Reviewer_YTK5"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission651/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699384813949,
        "cdate": 1699384813949,
        "tmdate": 1699635992419,
        "mdate": 1699635992419,
        "license": "CC BY 4.0",
        "version": 2
    }
]