[
    {
        "id": "IZhwiZT5UV",
        "forum": "uJVHygNeSZ",
        "replyto": "uJVHygNeSZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission257/Reviewer_nfN9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission257/Reviewer_nfN9"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on enhancing the attention mechanism by incorporating geometric information. The motivation behind this is the observation that existing positional encoding techniques are not optimally suited for vision tasks. In particular, the authors encode the geometric structure of tokens by representing them as relative transformations and introduce a novel geometric-aware attention mechanism. Experiments are conducted on novel view synthesis tasks, where the proposed method achieves state-of-the-art performance among transformer-based neural video synthesis (NVS) methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper introduces a novel attention mechanism grounded in geometric information, and the motivation is reasonable.\n2. The paper is well-written and the experiments yield compelling qualitative results compared to baseline models."
            },
            "weaknesses": {
                "value": "- Lack of comparisons with the latest NeRF-based models, except Pixel-NeRF which is proposed in 2021."
            },
            "questions": {
                "value": "The resolution of training images used in the experiment seems to be not high. How does this method perform on high-resolution data, and what is the impact of different numbers of training views?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission257/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission257/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission257/Reviewer_nfN9"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission257/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697534109418,
        "cdate": 1697534109418,
        "tmdate": 1699635951370,
        "mdate": 1699635951370,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SfF2zadF9t",
        "forum": "uJVHygNeSZ",
        "replyto": "uJVHygNeSZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission257/Reviewer_LyNT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission257/Reviewer_LyNT"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses the limitation of existing positional encoding designs in 3D vision tasks, which do not consider task-relevant 3D geometric structures. The authors propose a geometry-aware attention mechanism that encodes the geometric structure of tokens for the novel view synthesis task. Extensive experiments demonstrate the effectiveness of the proposed method, and qualitative comparisons with previous state-of-the-art techniques highlight significant improvements."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed GTA consistently outperforms existing state-of-the-art methods on multiple datasets, including RealEstate10k, ACID, CLEVR-TR, and MSN-Hard.\n\n2. The authors provide extensive qualitative comparisons and analyses, effectively supporting the superiority of the proposed method over previous state-of-the-art techniques."
            },
            "weaknesses": {
                "value": "1. This paper's organization could be improved. For instance, placing the related work (Section 5) after the introduction would help readers understand the difference between conventional positional encoding schemes and the proposed relative transformation encoding scheme. The authors should summarize existing geometric-related positional encoding techniques (not only in novel view synthesis, but also in many 3D vision tasks), and conduct a comprehensive comparison. Since the background information of transformer (the first half of section 2 Background) is already well-known, it can be moved to the appendix. \n\n2. The paper's contribution appears to be incremental, offering limited insights from the proposed relative transformation positional encoding alone.\n\n3. While the paper introduces GTA as a novel positional encoding scheme, it seems to function more like a transformer block (consisting of positional encoding and the attention block) than just a positional encoding scheme. A more detailed ablation study of each component within GTA is needed.\n\nIn general, improving the paper's organization and conducting a more comprehensive comparison with existing techniques would strengthen its contributions. Additionally, more detailed analysis of the components within GTA would enhance the paper's overall quality."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission257/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission257/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission257/Reviewer_LyNT"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission257/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698551320434,
        "cdate": 1698551320434,
        "tmdate": 1699635951283,
        "mdate": 1699635951283,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "l1xZ16edeK",
        "forum": "uJVHygNeSZ",
        "replyto": "uJVHygNeSZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission257/Reviewer_ZuJ5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission257/Reviewer_ZuJ5"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new methodology for encoding positional information and camera transformations in 3D vision tasks. It employs a special Euclidean group to encode the geometric relationship between queries and key-value pairs within the attention mechanism. Experimental results demonstrate the effectiveness and efficiency of the proposed method, achieving top performance on the novel view synthesis dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The geometric relationship is crucial for multi-view geometry tasks. The proposed method straightforwardly and reasonably encodes transformation and position information into the attention mechanism. The method has demonstrated superior results on several novel view synthesis datasets.\n2. The involvement of the special Euclidean group in encoding transformations is interesting and useful for capturing geometric relationships.\n3. The proposed method requires minimal computation, making it easy to implement and integrate."
            },
            "weaknesses": {
                "value": "1. Geometry-aware attention for transformers has been extensively explored, and the idea of encoding position and transformation information to improve 3D vision tasks has been discussed previously. While the detailed implementation of the encoding process (such as applying transformations to value vectors) differs from existing works, they share a similar underlying concept, thereby diminishing the novelty of this paper. \n2. The evaluation and ablation study primarily focus on the novel view synthesis task. However, since the proposed method is easily integrable into existing attention-based 3D vision tasks, I highly recommend validating the approach on other 3D vision tasks, such as multi-view 3D detection. \n3. Unlike the feature warping approach, the encoded transformation information relies on matrix multiplication. To be honest, I don't fully grasp the physical meaning behind this."
            },
            "questions": {
                "value": "1. Table 4 validates that the method proposed in the paper effectively improves accuracy.  I am curious about the performance of other similar methods when evaluated against the same baseline and the same settings. Are they still inferior to the approach presented in the paper?\n2. Additionally, since geometry-aware attention is a general method, can it also enhance accuracy in other perceptual tasks apart from novel-view synthesis?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission257/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698753763576,
        "cdate": 1698753763576,
        "tmdate": 1699635951189,
        "mdate": 1699635951189,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1xaIU3Gml4",
        "forum": "uJVHygNeSZ",
        "replyto": "uJVHygNeSZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission257/Reviewer_myD9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission257/Reviewer_myD9"
        ],
        "content": {
            "summary": {
                "value": "This work proposes an attention mechanism for multi-view transformers which factors in the geometry information, such as camera pose and image position, of the inputs. This differs from most previous work that often condition Transformers using absolute positional encoding of that information. A key intuition given by the authors is that attention from one token to another should happen in a canonical coordinate space. \nSparse-view novel-view synethesis results on a number of datasets show that the proposed method is state-of-the-art compared against other recent methods as well as a number of baselines. These datasets include synthetic yet challenging scenes (like MSN-Hard) as well as real world indoor and outdoor scenes (ACID and RealEstate10k)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This is a very well written and for the most part clear paper, with a clear motivation and intuition behind their method, as well as a proper literature review of relevant prior works.\n\nIt aims to tackle an important and challenging problem of novel view synthesis in the sparse (few input images) and wide-baseline (long-range camera variation) case; as such, strong results in challenging benchmarks imply a significant contribution to the community. \n\nThe method and claims are sound. The method itself does not involve a big departure from the standard Transformer architecture, which means it's easy to implement and widely applicably potentially to other problems.\n\nThe experimental set-up is generally thorough. A number of SoTA method are included for comparison and different synthetic as well as real-world datasets are used for evaluation."
            },
            "weaknesses": {
                "value": "While I agree with the intuition behind this method, what the actual implementation does, and how it affects attention, is somewhat unclear to me. It makes sense to transform features of different views to canonical reference space during attention, and that's obvious only when those are actual coordinates (e.g. points in 3D space); it's not so obvious when features are linear projections of other features. \n\n\nIt's also not obvious that block concatenation of multiple group representations, each with a certain multiplicity, is the best way to achieve it, and I believe this work could do with a bit more discussion on these points, and potentially further ablations/baselines of other ways one could implement the same intuition."
            },
            "questions": {
                "value": "A number of questions/suggestions:\n\n- As suggested above, I would like to see a variant of GTA that does not involve block concatenation of the geometry representations matrices along with their multiplicites (to mnatch the transformation to the input dimensionality `d`). Have the authors explored a variant such as: concatenate the flattened representation of all groups, followed by a linear projection up to `d`, element-wise multplication with input features (with the rest of the GTA method as proposed)?\n\n- The definition of $\\rho_{g_i g_j}$ in Eq. 4 I believe is missing, which makes it difficult to understand how the authors go from Eq 4. to Eq. 5, as well as their claims regarding the quadratic complexity in Eq 4.\n\n- While some results are provided on real world datasets, these are fairly limited in both size and quality (from looking at the videos). It's therefore difficult to conclude that this method is SoTA more generally in real-world cases. For instance, results would be strengthened if a study of the sensitivity of the model's predictions are to camera errors during training and/or test time. This is relevant given that other methods in the literature have carried out these types of experiments (see e.g. SRT paper, Fig 6)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission257/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698780466166,
        "cdate": 1698780466166,
        "tmdate": 1699635951072,
        "mdate": 1699635951072,
        "license": "CC BY 4.0",
        "version": 2
    }
]