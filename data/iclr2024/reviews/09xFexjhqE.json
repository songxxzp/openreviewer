[
    {
        "id": "iepKR6e3l5",
        "forum": "09xFexjhqE",
        "replyto": "09xFexjhqE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission538/Reviewer_qytY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission538/Reviewer_qytY"
        ],
        "content": {
            "summary": {
                "value": "**Summary Of The Paper:**\n\nThis paper introduces AutoLoRa, a parameter-free automated robust fine-tuning framework to improve adversarial robustness in downstream tasks that disentangles the optimization process into two distinct components: (1) optimizing natural objectives via the LoRa branch, (2) and adversarial objectives via the FE. It addresses the issue of divergent gradient directions, when optimizing both adversarial and natural objectives through the feature extractor (FE), in existing robust fine-tuning methods and achieves state-of-the-art results across various tasks without the need for hyperparameter tuning."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "**Strength:**\n\n-   The motivation that optimizing both adversarial and natural objectives through feature extractor yields divergent gradient directions make sense. The proposed disentangling of the training objective by introducing the LoRA branch is consistent with the motivation.\n-   Extensive empirical evaluation (including the P-test) demonstrates the improvements in Robust Fine-Tuning on various tasks."
            },
            "weaknesses": {
                "value": "**Weakness:**\n\n-   The reason for automating scheduling hyper-parameters is not well illustrated, and the ablation study in Table 5 can not show its superiority, especially for the *RA* metric.\n-   In Formula 7, the constant factor $6$ is not well-explained, and it could be considered as a hyper-parameter with further ablation study.\n-   Table 4 is confusing. Specifically, when the adversarial budget is set to $8$ which is the default configuration, the resulting metric is supposed to be that in Table 2. However, this is not true.\n-   Typo in Section 5.2 Ablation Study, the end of adversarial budgets paragraph says \"consistently achieves consistently\".\n-   Diverse network backbone architectures are encouraged to be considered beyond ResNet."
            },
            "questions": {
                "value": "Refer to the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission538/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698535701854,
        "cdate": 1698535701854,
        "tmdate": 1699635981185,
        "mdate": 1699635981185,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4pSdqfh9Tj",
        "forum": "09xFexjhqE",
        "replyto": "09xFexjhqE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission538/Reviewer_4DPH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission538/Reviewer_4DPH"
        ],
        "content": {
            "summary": {
                "value": "Robust fine-tuning (RFT) is an efficient method to obtain a robust model on a downstream task by robustly fine-tuning a robust model that is adversarially trained on a large dataset. \nHowever, this paper shows that the existing methods (vanilla RFT, TWINS [Liu et al. 2023]) suffer from the same issue that optimizing both adversarial and natural objectives yields significantly divergent gradient directions.\nThis paper points out that this divergence can hinder obtaining high robustness and make the training unstable.\n\nTo resolve the issue of the divergent gradient directions, this paper proposes a robust fine-tuning framework called AutoLoRa using the low-rank adaptation (LoRA) technique. \nThe idea is to have separate branches for adversarial and natural objectives: the adversarially pre-trained encoder is trained by the adversarial objective, and the LoRa branch is trained by the natural objective.\n\nAdditionally, AutoLoRa introduces automatic scheduling of hyperparameters, in contrast to vanilla RFT and TWINS, which require expensive hyperparameter searches. The balance between adversarial and natural objectives is determined by natural accuracy on the train set: as the standard accuracy increases, the weight on the natural objective decreases. The learning rate decays automatically with a condition of the validation accuracy.\n\nIn this paper, the pre-trained models are adversarially trained on ImageNet-1k. \nOn the six downstream datasets (CIFAR10, CIFAR100, DTD-57, DOG-120, CUB-200, and Caltech-256), AutoLoRa achieves higher adversarial robustness compared to vanilla RFT and TWINS."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "S1. This paper points out the common issue of vanilla RFT and TWINS [Liu et al. 2023] that optimizing both adversarial and natural objectives yields significantly divergent gradient directions, which is beneficial knowledge for the adversarial robustness research community.\n\nS2. The application of LoRA for the adversarial robustness problem is novel, and separating the branches for adversarial and natural objectives with the low-rank branch is interesting. The results show that their method can effectively improve adversarial robustness.\n\nS3. The proposed automatic strategy to determine hyperparameters is useful since adversarial training is time-consuming."
            },
            "weaknesses": {
                "value": "W1. A more careful ablation study is needed.\n\n- (W1-1.) It remains unclear how much each of the two proposed components contributes to the performance: (1) the automatic hyperparameter scheduling and (2) the LoRa branch. To clarify, does AutoLoRa without automatic scheduling (utilizing grid search) yield a similar result to AutoLoRa with dynamic hyperparameter scheduling? In other words, does the dynamic hyperparameter scheduling contribute to the robustness improvement, or is it only for avoiding grid search? \n\n- (W1-2.) In line with (W1-1), it is also not evident how significantly the learning rate scheduling and the scalar parameter ($\\lambda$) scheduling impact performance. While it appears that dynamic learning rate scheduling might not have the benefit of improving robustness, as seen in Table 5, I assume that dynamic scalar ($\\lambda$) scheduling could contribute positively to performance, in addition to the benefit of avoiding grid search.\n\nW2. The paper's claim regarding divergent gradient directions and training stability needs clarification.\n\n- (W2-1.) The paper lacks evidence to support the claim that Vanilla RFT and TWINS are sensitive to hyperparameters. It would be helpful to specify which hyperparameters these methods are sensitive to and to what extent.\n- (W2-2.) Since AutoLoRa employs automatic hyperparameter scheduling, it remains unverified whether the use of the LoRa branch indeed contributes to training stability regarding hyperparameters. To discuss the hyperparameter sensitivity, I would expect experiments comparing the different magnitudes of a specific hyperparameter and the corresponding performances for compared training methods.\n\nW3: Natural accuracy trade-off in AutoLoRa compared to TWINS.\n- For all cases in ResNet-18 and the three cases in ResNet-50, AutoLoRa exhibits a slightly lower natural accuracy compared to TWINS, despite achieving higher robust accuracy. Further discussion or insights on this trade-off would be valuable."
            },
            "questions": {
                "value": "Q1. Related to W1-2, it's worth considering the possibility of applying automated hyperparameter scheduling to Vanilla RFT and TWINS.   The scaler $\\beta$ in Vanilla RFT or $\\gamma$ in TWINS can be scheduled, by simply replacing $\\lambda_2$ with $\\beta$ or $\\gamma$ in Equation 7. It would be interesting to see whether \"Vanilla RFT + scaler scheduling\" or \"TWINS + scaler scheduling\" can be better than the original methods. Additionally, comparing \"Vanilla RFT + scaler scheduling\" or \"TWINS + scaler scheduling\" with AutoLoRa could provide insights into the benefits of the LoRa branch.\n\nQ2. How exactly is the gradient similarity calculated? A feature encoder has multiple layers to measure the gradient similarity. \n\nMinor comment:\n- It appears that TWINS in this paper corresponds to the TRADES version of TWINS, known as TWINS-TRADES [Liu et al. 2023]. It might help clarify the paper's context by explicitly mentioning this relationship.\n\n-------\n[Liu et al. 2023] Twins: A fine-tuning framework for improved transferability of adversarial robustness and generalization. CVPR2023"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission538/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission538/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission538/Reviewer_4DPH"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission538/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698580151495,
        "cdate": 1698580151495,
        "tmdate": 1699635981101,
        "mdate": 1699635981101,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MOU33ucSMy",
        "forum": "09xFexjhqE",
        "replyto": "09xFexjhqE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission538/Reviewer_kvxv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission538/Reviewer_kvxv"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces AutoLoRa, an automated robust transfer learning framework. The authors present empirical evidence showing a significant divergence in the gradients of adversarial and natural objectives with respect to the feature extractor (FE), leading to unstable optimization. This observation motivates the authors to propose an auxiliary low-rank (LoRa) branch to disentangle the robust fine-tuning process, enabling the optimization of natural objectives through the LoRa branch and adversarial objectives through the FE.\n\nAdditionally, the authors introduce automatic schedulers for adjusting the learning rate and loss weights. The empirical results demonstrate that AutoLoRa achieves state-of-the-art robustness in downstream tasks without the need for hyperparameter search."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well-organized and well-written, making it easy to follow most parts of the paper.\n\n2. The proposed method is well-motivated. The authors empirically discover that optimizing the natural and adversarial objectives leads to divergent optimization directions, which serves as the motivation for the LoRa branch.\n\n3. The comprehensive results across various datasets provide strong support for the effectiveness of AutoLoRa.\n\n4. AutoLoRa is parameter-free, offering practical utility. Additionally, the automated learning scheduler is adaptable to different methods."
            },
            "weaknesses": {
                "value": "1. The backbone models are pre-trained through robust supervised learning. It would be beneficial to demonstrate the performance of various backbone models pre-trained using robust self-supervised learning with AutoLoRa.\n\n2. Robustness is currently assessed using AutoAttack. It would be more informative to assess the robustness under various attackers."
            },
            "questions": {
                "value": "Refer to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission538/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission538/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission538/Reviewer_kvxv"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission538/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698726224214,
        "cdate": 1698726224214,
        "tmdate": 1700584660896,
        "mdate": 1700584660896,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "deEv3TQoyY",
        "forum": "09xFexjhqE",
        "replyto": "09xFexjhqE",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission538/Reviewer_pJnK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission538/Reviewer_pJnK"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a decoupled fine-tuning framework for learning adversarially robust features. Specifically, a conventional robust finetuning pipeline consists of two losses: a natural objective and an adversarial objective. The paper shows that the divergence in gradients from the two objectives is correlated with downstream accuracy on robustness benchmarks. Therefore, it proposes to decouple a model into two branches where the second branch is constructed using Low-rank adaptation (LORA). In the decoupled training scheme, the main model (first branch) is only exposed to the adversarial objective and the LORA branch (second branch) is only exposed to the natural objective. The paper claims that the disentanglement avoids gradient divergence and leads to better downstream robustness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* **Clear presentation**: the paper uses clear and concise notations for equations. The method section is easy to follow.\n\n* **Good ablation study**: the paper conducts ablation study on important hyper-parameters such as the rank in LORA and the LR scheduler."
            },
            "weaknesses": {
                "value": "* **Missing ablation on Equation 5**: Equation 5 is the main loss function of the proposed method, which has three terms. The second cross-entropy term is a new addition $L_{KL}(h_{\\theta}(\\tilde{x}),y)$ in this paper and is not motivated and ablated in the experiments.  \n* **Doubt on mitigating divergence**: a main motivation of the method is that it can avoid divergent gradient updates on the main model parameters. However, this is not validated through experiments explicitly. For example, even though the main model parameters are not directly trained on the natural objective, it is indirectly affected by the natural objective through the KL divergence. Moreover, the unexplained second cross-entropy term $L_{KL}(h_{\\theta}(\\tilde{x}),y)$ can be seen as a natural objective on perturbated input. \n* **Why parameter-free**: the claim on parameter-free can be confusing. The model not only fine-tunes the main model parameters but also additional LORA parameters. So, it is not parameter-free in the sense of fine-tuning. Even though the method reduces the need for extensive hyper-parameter tuning, the design choices of the automated scheduler and the rank selection for LORA are all hyper-parameters. It\u2019s not clear what aspect of the proposed method is parameter-free."
            },
            "questions": {
                "value": "* Could the authors provide the cosine similarity between the two terms in the adversarial objective in Equation 5 and comment on the functionality of the second cross-entropy term $L_{KL}(h_{\\theta}(\\tilde{x}),y)$? \n\n* Could the authors clarify the parameter-free characteristic? It could be that I misunderstood the meaning here."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission538/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission538/Reviewer_pJnK",
                    "ICLR.cc/2024/Conference/Submission538/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission538/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698772887917,
        "cdate": 1698772887917,
        "tmdate": 1700492923885,
        "mdate": 1700492923885,
        "license": "CC BY 4.0",
        "version": 2
    }
]