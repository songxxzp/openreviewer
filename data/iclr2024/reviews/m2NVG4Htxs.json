[
    {
        "id": "XRVbsbQxXL",
        "forum": "m2NVG4Htxs",
        "replyto": "m2NVG4Htxs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission11/Reviewer_yfjE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission11/Reviewer_yfjE"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates data contamination of GPT-3.5-Turbo and GPT-4 with problems from Codeforces and Project Euler. It does so by analysing the passrates in relation to the GitHub presence and notes a positive correlation for data before the cutoff, but no significant correlation after this date."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Identifying data contamination is an important issue, especially for evaluation datasets that are often used to create rankings.  \n2. Including problem difficulty as an independent variable is an important step in isolating the confounding effect of item difficulty on pass rates.\n3. I appreciate the openness in referencing blog posts and tweets that anecdotally suggested possible contamination prior to this work"
            },
            "weaknesses": {
                "value": "1. The methodology is only applied to GPT-3.5/GPT-4, where training details are unknown. In particular, as noted in footnote 1, OpenAI has admitted to using a small amount of data beyond the cutoff date. While I understand the choice of the GPT family as a commonly used model, it would have been better to verify the approach with fully open models where more training details are available (and more trustworthy).\n2. The methodology requires underlying datasets that are longitudinal in nature, i.e. release problems/individual tasks over time; this limits the applicability to sources other than Project Euler / Codeforces."
            },
            "questions": {
                "value": "### Minor Comments\n* Particularly in section 2, some citations are formatted differently, with the author names outside the parentheses; in sequences of different citations, readability could be improved by using the same citation format as in section 1."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission11/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission11/Reviewer_yfjE",
                    "ICLR.cc/2024/Conference/Submission11/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission11/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697974261321,
        "cdate": 1697974261321,
        "tmdate": 1700680099572,
        "mdate": 1700680099572,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gb4bzg4HXx",
        "forum": "m2NVG4Htxs",
        "replyto": "m2NVG4Htxs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission11/Reviewer_EfiM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission11/Reviewer_EfiM"
        ],
        "content": {
            "summary": {
                "value": "Assess whether GPT performance at coding (sometimes called program synthesis) was possibly affected by contamination of pretraining data using a naturally occurring experiment (i.e. comparing scores before and after the pretraining knowledge cutoff dates)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Overall, I really liked this paper. I thought it was well motivated, clearly conceptualized, well executed and somewhat thorough. I have a small number of requested changes, and if the authors and I agree that the changes are sensible and if the authors agree to make the changes, I would be happy to increase my score."
            },
            "weaknesses": {
                "value": "> Figure 1: Marginal Effects of Pass Rate Metric \n\nI think this is an amazing figure. 5 comments, ordered from minor to major:\n\n1. easy: Stacking log(Github Presence) and log(Difficulty) at the bottom makes reading the figure tricky. I might suggest moving log(Difficulty) to the right side.\n\n2. easy: GitHub is stylized \"GitHub\", not \"Github\"\n\n3. medium: Where is the equivalent plot for Project Euler? I might have missed this, but I cannot find it in the main text or appendix.\n\n4. hard: The pass rate is significantly lower for easy and medium problems, even for log(Github Presence) = 0. I understand that GitHub Presence is a proxy, but I would think that log(GitHub Presence) = 0 is our best guess for \"low or no contamination\", but there's still a 10-20% decrease in pass rate. Why? I can think of 2-4 possible answers: (a) GPT-4 genuinely becomes much worse after the knowledge cutoff; (b) GitHub presence is inadequate and/or misleading, (c) the distribution of Codeforce problems changed after GPT-4 was finished pretraining, or (d) something changed in how the pass rate is calculated on generated outputs. More explanations might also be possible. Is there some way for the authors to try to investigate the cause of this shift?\n\n5. hard: I was hoping for either a qualitative or quantitative analysis about what GPT-4 is outputting on Codeforces problems released after the cutoff, but I can't find even a single example of the raw generated outputs. Could the authors please provide some manual examples, even in the appendix, to convincingly demonstrate that GTP-4 is indeed outputting worse code? I want to rule out that silly possibilities (e.g., a shift in formatting) are affecting the results.\n\n> Table 1\n\nI personally find Tables are less effective at communicating than Figures. Since these are regression tables, could you possibly consider switching to a Forest plot of regression coefficients? Some random examples here:\n\n- https://www.researchgate.net/figure/Forest-plot-of-regression-coefficients-95-confidence-interval-for-the-association_fig1_331119872\n- https://www.researchgate.net/figure/Coefficient-plots-from-linear-regression-predicting-what-makes-an-interaction-meaningful_fig1_343608677 \n- http://www.strengejacke.de/sjPlot/reference/plot_models.html.\n\nTo make my suggestion as concrete as possible, using terminology from matplotlib & seaborn (assuming you're using Python, but I'm sure R could do this as well), I'm specifically thinking that your X axis should be the estimated parameters and confidence intervals, Y would be the covariates (i.e. Difficulty & GitHub presence), the Hue is either Before Cutoff or After Cutoff, and you have two side-by-side axes, one for GPT4 and the other for GPT3.5.\n\nI personally would prefer all regression tables to be visualized as such (Tables 1, 2, and those in the appendix)."
            },
            "questions": {
                "value": "Not a question, but I want to note that:\n\n1. I like the use of Pass Rate in lieu of pass@1. I think that's a very sensible choice.\n\n2. I like the citation of Horace He's and Chris Cundy's tweets. Very good scholarship, even if Tweets aren't \"published\" in a traditional sense."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission11/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission11/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission11/Reviewer_EfiM"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission11/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698684490826,
        "cdate": 1698684490826,
        "tmdate": 1699635924418,
        "mdate": 1699635924418,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M4jPZxVj0f",
        "forum": "m2NVG4Htxs",
        "replyto": "m2NVG4Htxs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission11/Reviewer_XbnJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission11/Reviewer_XbnJ"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a detailed investigation into data contamination in large language models (LLMs), using GPT model training cutoffs to analyze benchmarks released over time. It examines two datasets, Codeforces and Project Euler, revealing clear patterns that suggest contamination based on the LLMs' pass rates correlated with benchmarks' GitHub popularity and release dates. The authors provide a comprehensive dataset, findings, and a framework for future analysis, promoting better practices for benchmark releases in the era of web-scale LLM training."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The idea to investigate data contamination in LLMs via cutoff datasets makes sense and is interesting, which guarantees that the testing data are not available in the training set of LLMs. And the findings are surprising, revealing that people should deal with the ability of LLMs more carefully. This study shows that LLMs are likely to have generalization problems as well as traditional ML models and deep neural networks. And I think this should raise the attention of ML researchers."
            },
            "weaknesses": {
                "value": "I am not quite familiar with LLMs, and I only have one question about the design of cutoffs. What if a code problem released later is exactly similar as some problems that has already existed? And how to measure the data contamination problem is also important."
            },
            "questions": {
                "value": "Please refer to Weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission11/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698873037377,
        "cdate": 1698873037377,
        "tmdate": 1699635924329,
        "mdate": 1699635924329,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mQVSo5ovS7",
        "forum": "m2NVG4Htxs",
        "replyto": "m2NVG4Htxs",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission11/Reviewer_VA65"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission11/Reviewer_VA65"
        ],
        "content": {
            "summary": {
                "value": "The paper conducted longitudinal analysis of data contamination in large language models (LLMs), a problem where models are evaluated using data that they may have been trained on, thus overstating their capabilities.  The authors leveraged natural experiments provided by the training cutoff dates of models like GPT-3.5 and GPT-4 to study contamination. They analyzed Codeforces and Project Euler, websites that release code problems over time, and find evidence of contamination based on the pass rate of LLMs for problems released before their training cutoff dates. The study demonstrates statistically significant associations between a problem\u2019s presence on GitHub and LLM performance for pre-cutoff problems."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1: The analysis from longitudinal perspective is novel. \n2: The comprehensive experiments, large-scale dataset and code base provided by this work will definitely benefit the community of contamination analysis.\n3: This paper is well organized and easy to understand."
            },
            "weaknesses": {
                "value": "1: The results are interesting but not that surprising. Many blogs or discussion in the community about Data Contamination has involved similar results.\n2: There is lack of depth analysis about how implicit contamination is possible. If some real examples can be extracted to show how this could happen, it will be much better.\n\nOverall, I do appreciate the effort to investigate the Data Contamination problem from longitudinal side and open-source data/codes. The experiments also show intriguing results. But I believe the contribution of this paper is not enough to be accepted by ICLR, for its limited scope and technical novelty. It's limited to Code datasets. And the only novelty is how to split the \"train\" and \"test\" set."
            },
            "questions": {
                "value": "N/A"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission11/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission11/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission11/Reviewer_VA65"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission11/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699203471923,
        "cdate": 1699203471923,
        "tmdate": 1699635924234,
        "mdate": 1699635924234,
        "license": "CC BY 4.0",
        "version": 2
    }
]