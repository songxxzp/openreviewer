[
    {
        "id": "Xxw9uGF4I3",
        "forum": "AMDKqZcZbi",
        "replyto": "AMDKqZcZbi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6292/Reviewer_KBVt"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6292/Reviewer_KBVt"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the challenge of catastrophic forgetting in the context of continual learning. The proposed study focuses on the sequential Morris Water Maze (sWM) task which is inspired by several mechanisms used by biological systems. It combines a content-addressable memory system and a convolutional network architecture to implement these mechanisms in the context of ANNs. This model excels at fast learning, generalization, and continuous learning, outperforming baselines in both continuous and few-shot learning settings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper reads well and can be followed straightforwardly."
            },
            "weaknesses": {
                "value": "1. It is not clear that the proposed task is of practical importance.\n\n\n2. Comparison is extremely limited and considers old methods such as EWC.\n\n3. The code is not provided which makes judgment about reproducibility challenging."
            },
            "questions": {
                "value": "The major novelty that I see in this paper is building connections between biological systems and ML. However, it is not clear how relevant the proposed task is and how effective it will be in the context of CL. The question is then why the paper has not done an evaluation according to the precedent given the fact that CL is an extremely well-established field by including SOTA methods.\n\n\n============Post Rebuttal=============\nThanks for the rebuttal. I changed my rating accordingly. I don't find this work compelling and mostly find a proof-of-concept level work which is not clear whether it will be of practical relevance. The task is a limited synthetic task and I cannot think of a major benefit for future research."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6292/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6292/Reviewer_KBVt",
                    "ICLR.cc/2024/Conference/Submission6292/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6292/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698576804265,
        "cdate": 1698576804265,
        "tmdate": 1700994895474,
        "mdate": 1700994895474,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8IWSrAuGMd",
        "forum": "AMDKqZcZbi",
        "replyto": "AMDKqZcZbi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6292/Reviewer_3WUm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6292/Reviewer_3WUm"
        ],
        "content": {
            "summary": {
                "value": "The paper focuses on catastrophic forgetting in lifelong learning scenarios. Inspired by inspiration from the spatial learning mechanisms observed in biological neurons,  this paper introduces a new task, sequential Morris Water Maze (sWM), for rapid adaptation and continual learning.  Furthermore, the paper presents a lifelong learning approach built upon the Memory Scaffold with Heteroassociation (MESH) architecture, designed to promote generalization within the Water Maze environments.  However, the description of the proposed method requires further clarity."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper studies a practical and important problem: lifelong learning without catastrophic forgetting, focusing on the performance in sequential Morris Water Maze tasks.  \n\nThe proposed method, a bio-inspired lifelong learning framework based on MESH, provides a reasonable method to mitigate catastrophic forgetting in changing environments.\n\nFurthermore, in the experimental evaluation conducted on sequential Morris Water Maze tasks, the proposed method demonstrates superior performance compared to previous approaches, as reported in the paper."
            },
            "weaknesses": {
                "value": "1) Enhancing the paper's readability, especially for readers less familiar with neuroscience, would improve its significance. This could involve providing clearer (maybe more intuitive) explanations of certain concepts, such as the entorhinal cortex, the neocortical-entorhinal-hippocampal circuit, the memory scaffold, Hebbian learning, and grid cell patterns.\n\n2) The description of the Morris Water Maze environment lacks clarity. What are the observations and sensory-cells in Figure 2. Is the observation meant to represent the agent's view as high dimensional vector? What are place and grid cells, and what are their dimensionalities? Does the memory store grid cells?  What are the differences between various environments, apart from variations in the goal positions?\n\n3) The description of the proposed method requires further clarity. An explanation of the design architecture for the policy is needed. Additionally, specify which parts of the MESH incorporate attention mechanisms. How is the entire network trained? Is it trained using Reinforcement Learning? Define the objective function for training. Does the statement \"The policy requires no further training\" imply that the displacement network also doesn't require training?\n\n4) The experimental evaluation lacks comprehensiveness. It would be valuable to compare the proposed method with more state-of-the-art continual learning approaches, such as ER [1] and A-GEN [2]. Moreover, in the paper [3], a strategy involving the replay of similar experiences is used for continual learning. It would be insightful to discuss the relationship between the proposed method and the paper [3] on memory replay.\n\n[1] A. Chaudhry, et al \u201cOn tiny episodic memories in continual learning\u201d, arxiv 2019.  \n[2] A. Chaudhry, et al \u201cEfficient lifelong learning with a-gem\u201d, ICLR 2018.  \n[3] A. Abulikemu, et al \u201cOnline Model Adaptation with Feedforward Compensation\u201d, CoRL 2023."
            },
            "questions": {
                "value": "1) It is beneficial to provide clearer (maybe more intuitive) explanations of some concepts, such as neocortical-entorhinal-hippocampal circuit, memory scaffold, and grid cell patterns.\n\n2) What are the observations and sensory cells in Figure 2? Does the memory store grid cells?  What are the differences between various environments, apart from variations in the goal positions?\n\n3) How is the entire network trained? Is it trained through Reinforcement Learning?  What is the training objective?  Additionally, specify which part of the network utilizes attention mechanisms.  \n\n4) Consider highlighting the unique aspects of the proposed method compared to replay-based approaches, such as ER [1], A-GEM [2], and Feedforward [3]."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6292/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6292/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6292/Reviewer_3WUm"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6292/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698728935904,
        "cdate": 1698728935904,
        "tmdate": 1699636690661,
        "mdate": 1699636690661,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DD4GyTowRB",
        "forum": "AMDKqZcZbi",
        "replyto": "AMDKqZcZbi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6292/Reviewer_ndgr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6292/Reviewer_ndgr"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel continual learning benchmark based on the Morris Water Maze test of spatial learning in animals, as well as a dedicated neuroscience-inspired continual learning method combining Memory Scaffold with Heteroassociation framework, a randomly-initialised CNN, and an attention module. Through experiments on the sequential Morris Water Maze benchmark, the authors show their method outperforms standard continual learning baselines by effectively retaining past knowledge and quickly adapting to new environments."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The new benchmark is a valuable contribution to the continual learning community. The method has a strong neuroscientific grounding and it brings together existing components in an original way. The paper is well presented and nicely structured. The writing is clear and the figures are very helpful in conveying the main points of the argument. The ablation study provides sufficient justification for the individual design choices."
            },
            "weaknesses": {
                "value": "The empirical evaluation is the main weakness of the paper. The authors compare their method to only two continual learning baselines, both of which are quite old. In addition, the replay buffer sizes that are used in the experiments are rather small (200-1800) The proposed method seems to be custom-designed for the navigation task, so while it can serve as a model of how rodents learn to navigate in new environments, it is not a practical continual learning method that could be applied to an arbitrary task. To give existing baselines a fighting chance, I would recommend having two separate networks: one mapping observations and goal position into some latent representation and another mapping these to actions. In the first environment, train both networks. For each new environment, re-train only the first network."
            },
            "questions": {
                "value": "Why does replay buffer exhibit such poor performance on the last task?\n\nWill the benchmark be made available? Is it a framework to produce random environments or just a fixed dataset?\n\nAre the associations between displacement representations and actions simply memorised by the attention module?\n\nIs the grid code of the goal location available to your method straight away?\n\nHow is the goal location provided to the network for replay and naive methods?\n\nWhat exactly is stored in the rehearsal buffer? Observation-action pairs?\n\nHave you tried increasing the grid size of the environment?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6292/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698795546365,
        "cdate": 1698795546365,
        "tmdate": 1699636690521,
        "mdate": 1699636690521,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZPx6qXfRPU",
        "forum": "AMDKqZcZbi",
        "replyto": "AMDKqZcZbi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6292/Reviewer_h9UH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6292/Reviewer_h9UH"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a task-specific maze path-finding network that is suitable for continual learning. The key contribution is to decouple the policy, and the localization module, and the memorized goal location. The experiments show that the proposed network can learn 5 environments with no forgetting, whereas the baseline policy network completely forgets the previous task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The idea of an end-to-end network that is capable of continual learning is interesting, even if it can only handle path finding tasks.\n- The results suggest that the proposed network clearly solves continual learning."
            },
            "weaknesses": {
                "value": "- It makes sense that the policy network is invariant across tasks, since given true localization and goal location it only needs to learn a good search algorithm. But the place cell and grid cell may still suffer from catastrophic forgetting. Does the model get another set of newly initialized place cells and grid cells when switching to a different environment? Otherwise, how does it prevent forgetting? I would appreciate further clarification on this part.\n- I understand that the proposed method is tailored to a path finding task, however, to make it more generalizable, it would be better to test on other types of maze tasks (perhaps with more complex visual features and map topology). Moreover, I don\u2019t see why the task needs to be a water maze (with no walls) vs. a real maze.\n- I would appreciate more clarity on model training and loss functions. An algorithm block can also strengthen the presentation clarity of the paper."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6292/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699101315931,
        "cdate": 1699101315931,
        "tmdate": 1699636690417,
        "mdate": 1699636690417,
        "license": "CC BY 4.0",
        "version": 2
    }
]