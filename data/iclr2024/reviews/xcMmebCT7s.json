[
    {
        "id": "bfXV4RNeg5",
        "forum": "xcMmebCT7s",
        "replyto": "xcMmebCT7s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
        ],
        "content": {
            "summary": {
                "value": "This work focuses on predicting binding affinity changes of protein complexes upon mutations, namely, it intends to solve $\\Delta\\Delta G$ prediction, which is critical in protein binder design. It has three major contributions: (1) They exhaustively mine PDB to build a large-scale non-redundant PPI dataset. (2) A novel transfer learning algorithm is introduced to bridge the conventional masked residue modeling and $\\Delta\\Delta G$ prediction. (3) A new state-of-the-art performance has been achieved at the standard Skempi2 dataset with a more reasonable data-splitting strategy. Overall speaking, I would recommend an acceptance to the ICLR committee but expect the author to elucidate more clearly about the new splitting mechanism."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1) The paper built the largest and non-redundant dataset named PPIRef for representation learning of PPI. \n\n(2) The study proposes a reasonable mechanism to transfer a masked language modeling (MLM)-pretrained PPI model to predict mutation effects. This abandons the traditional bidirectional forward scheme to enforce the antisymmetry. \n\n(3) The author points out the flaws of previous methods' data splitting strategies and formulated a new one, which should be a good contribution to the machine learning community (but there are also some parts in the new splitting strategy that puzzle me, see questions).\n\n(4) PPIFormer exhibits great potential in distinguishing the binding affinity change after mutations than existing algorithms such as RDE-Net and MSA-Transformer."
            },
            "weaknesses": {
                "value": "(1) My major concern is that neither the code nor the data is publicly available. Are authors willing to release them? If possible, I would recommend authors upload the necessary part of the method to an anonymous GitHub (https://anonymous.4open.science/) during the review phase.\n\n(2) I value this study's effort in formulating a more comprehensive evaluation paradigm for mutation effect prediction, particularly in dataset splitting. However, the new splitting strategy is somehow unclear. For instance, the test set has only 5 samples, which are too small. And 3 cross-validation does not align with 5 test folds. \n\n(3) In the task of retrieving 5 human antibody mutations effect against SARS-CoV-2, the performance of PPIFormer is not good enough, it only outperforms RDE-Net in 3 of 5 samples and is worse in P@5% and P@10% than RDE-Net."
            },
            "questions": {
                "value": "(1) I am a little confused about the evaluation of test folds. As mentioned in Appendix B.2, the author splits the dataset into 3 cross-validation folds based on the \"hold-out-proteins feature\" and then sets aside 5 random outlier PPIs to form 5 distinct test folds. Firstly, what is the \"hold-out-proteins feature\"? Please explain that term. Secondly, why are there 3 cross-validation folds but 5 test folds? Commonly, $k$ cross-validation would result in $k$ training sets as well as $k$ validation sets, and usually do not have a so-called test fold. In my understanding, these 5 extra outliers are excluded from both the training and validation sets and are used to evaluate models alone. So here comes the question: how does the author compute the $\\Delta\\Delta G$ for these 5 outliers? Notably, 3 cross-validation will lead to 3 sets of models that achieve the lowest losses in 3 different validation sets. Does the author just take an average of these 3 models' output to obtain the binding affinity change? If not, please specify the computational process. \n\nBesides, how does the author split the Skempi2 by 3 cross-validation? I want to know more details. Also, why do these 5 outlier PPIs are selected randomly? I am afraid that a test set of merely 5 samples is so small. Is there any possibility to increase the test size?    \n\n(2) I understand that the splitting strategy of RDE-Net introduces data leakage. However, its 3 cross-validation is implemented without any technical mistakes. Therefore, can the author please just examine PPIFormer in the same splitting way as RDE-PPI and report the performance to help me better understand the superiority of PPIFormer over RDE-PPI?\n\nBesides, can you report the performance of PPIFormer in the same way as RDE-Net? Namely, the Spearman and Pearson of PPIformer and different baselines in single-mutation and multiple-mutation cases. I hope to see that PPIFormer remains excellent in the multiple-mutation circumstance, which is more challenging and more likely to result in successful protein design. \n\n\n(3) In the ablation study, the author claims the benefit of 80% 10% 10% masking proposed by BERT. However, I remember that BERT masked 15% of input tokens and tried to recover them. What does 80%, 10%, 10% mean? \n\nWhat's more, in Figure (4), what is the difference between a3 and PPIFormer? It seems a3 is better than PPIFormer, but it is said PPIFormer is the best model. Please specify the difference between the upper and bottom subfigures. \n\n(4) During the phase of mutant effect prediction, the author adopts a simple summation of all log odds ratios. In other words, each substitution of residue is considered independently. I suppose it may be a better solution to calculate the joint probability as $\\log p (\\hat{M} = M | \\mathbf{c}_{\\backslash M})$. Does the author agree with my point?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_Sjjh"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697618682224,
        "cdate": 1697618682224,
        "tmdate": 1700708168991,
        "mdate": 1700708168991,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aQeUunUheH",
        "forum": "xcMmebCT7s",
        "replyto": "xcMmebCT7s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_Kuay"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_Kuay"
        ],
        "content": {
            "summary": {
                "value": "The manuscript presents a novel data splitting technique aimed at mitigating data leakage and generating a fresh dataset. Additionally, it introduces a new loss function for the equiformer, enhancing its ability to effectively undergo self-supervised training."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is easy to read.\n\n2. The authors present a novel splitting method to prevent data leakage in the PPI dataset.\n\n3. They propose an innovative training scheme for EquiFormer, enabling self-supervised training.\n\n4. Additionally, the paper introduces a new feature generation technique to capture more information both within and outside the residue itself.\n\n5. Comprehensive experiments are conducted to evaluate the proposed method and the presented dataset."
            },
            "weaknesses": {
                "value": "When considering the data, it's important to note that the DIPS dataset may not have broad applicability for Protein-Protein Interaction (PPI) tasks. This is because PPI tasks involve not only binding, as observed in DIPS, but also encompass other aspects such as reaction, Ptmod, and activation labels, as described in reference [1].\n\n[1] Learning Unknown from Correlations: Graph Neural Network for Inter-novel-protein Interaction Prediction"
            },
            "questions": {
                "value": "1. In the optimization of a human antibody against SARS-CoV-2 and engineering staphylokinase for enhanced thrombolytic activity, how were the mutation pools obtained?\n\n2. Can you explain the process used to identify the five PPI outliers mentioned in Datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698604860413,
        "cdate": 1698604860413,
        "tmdate": 1699637038511,
        "mdate": 1699637038511,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "TA5ZNMbgu3",
        "forum": "xcMmebCT7s",
        "replyto": "xcMmebCT7s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_brhp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_brhp"
        ],
        "content": {
            "summary": {
                "value": "They first build an algorithm to approximate similarity between ppi interfaces and use it to assess the redundancy in existing datasets, like DIPS. Then they curate the available pdbs in protein data bank to create their dataset PPIREF, which reduces data leakage in train/test splits. The model architecture is comprised of Equiformer and it is first trained to predict masked residues with a regularised cross-entropy loss and then finetuned to predict the effects of mutations on binding affinity, using a thermodynamic-inspired loss."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-written and organized in a logical manner. It is easy to follow and the visualizations are informative.\n- The authors put effort on choosing their metrics/loss functions/splits. Especially for the latter, they developed an algorithm to detect dataset redundancy and reduce data leakage in their splits. Overall, their design choices are well addressed. \n- The model shows good performance on the benchmarks. it is nicely compared to different state of the art methods (both force field and ml methods) and using many metrics."
            },
            "weaknesses": {
                "value": "- IDIST could significantly improve the computation time needed to assess dataset redundancy, which can make redundancy tests a part of every dataset curation. However, I believe that establishing IDIST as part of dataset curation, requires more validation than comparing it against iAlign and for 100 pdbs. You should compare with more methods (eg Tm-align and US align) and repeat it for more pdbs (especially because you define the threshold of IDIST from the iAligh comparison)\n- The novelty is a bit limited, especially in the model architecture.\n- Appendix Figure 3/B: You mistakenly have the same pdb code in both subfigures."
            },
            "questions": {
                "value": "- I am worried that the F1 features introduce a data leakage and I would like to clarify it a bit:\nDauparas et al. describe utilizing distances between N, C\u03b1, C, O, and a virtual C\u03b2 placed based on the other backbone atoms, but their down-streaming task is predicting protein sequences in an autoregressive manner from the N to C terminus.\nIn your case, you mask a few amino acids, so with high probability neighbors of a masked residue will not be corrupted. \nSo I am worried that the F1 features can provide information regarding the \"available space\" in a certain position, biasing the model towards specific amino acids that fit well the available space. Is that a concern of yours?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_brhp"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698686250985,
        "cdate": 1698686250985,
        "tmdate": 1699637038384,
        "mdate": 1699637038384,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jfNTtLMy5P",
        "forum": "xcMmebCT7s",
        "replyto": "xcMmebCT7s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_ZbAC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_ZbAC"
        ],
        "content": {
            "summary": {
                "value": "The authors construct PPIRef, the largest, non-redundant PPI dataset, using a proposed fast interface align method iDist for deduplication. The proposed SE(3)-equivariant model, PPIformer, based on Equiformer, is pretrained in a thermodynamics-motivated way on PPIRef and fine-tuned on SKEMPI. Experiments show that the pretrained PPIformer achieves new SOTA on non-leaking SKEMPI splits."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1. Novelty: A novel structural pretraining loss is proposed for mutation effect prediction.\n2. Performance: New SOTA on SpearmanR on SKEMPI with non-leaking (harder) splits. Notably, this method does not rely on pre-computed mutant structures.\n3. Clarity: The contributions are clearly stated and the paper is well-written.\n4. Effort: The amount of work in this paper is quite comprehensive."
            },
            "weaknesses": {
                "value": "Please see questions."
            },
            "questions": {
                "value": "1. Would be nice if you could also compare your methods with baselines on the normal PDB-disjoint split, as this is also useful in real world cases. If PPIformer also performs best, the results would be more consistent and persuasive.\n2. What is the logic behind your architecture choice? What is the size (#params) of your model?\n3. In table 6, we can observe a high SpearmanR but the lower performance on precision and recall. What's your comment on this?\n4. For real-world case studies, I suggest you try your model on deep mutational scanning (DMS) data, where the enrichment ratios of all single-point mutations are measured (though with higher noise). Ranking mutations on a single protein where only a few mutations have been experimentally measured is less convincing IMHO."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_ZbAC"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698818316326,
        "cdate": 1698818316326,
        "tmdate": 1699637038272,
        "mdate": 1699637038272,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0tshmegDww",
        "forum": "xcMmebCT7s",
        "replyto": "xcMmebCT7s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_hYdu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8349/Reviewer_hYdu"
        ],
        "content": {
            "summary": {
                "value": "This article established a machine learning model to predict protein-protein interactions. The authors constructed a three-dimensional protein-protein interaction database and pre-trained the model based on it. They then made predictions on two existing examples and compared the performance with other baseline methods, yielding better performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Protein-protein interaction is important for protein design and engineering. The authors established a new machine learning model to predict the $\\Delta\\Delta G$. The paper is well-organized and easy to follow."
            },
            "weaknesses": {
                "value": "1. Evaluations on a broader range of datasets are preferred in terms of PPI and mutational effect predictions. Currently, all the test samples are selected from a larger benchmark dataset, making it skeptical that the results might be cherry-picked. \n2. Comparison of baseline methods is limited. At least some other deep learning methods should be included. For instance, for mutational effect prediction, the authors might refer to https://github.com/OATML-Markslab/ProteinGym.\n3. The prediction results are not reported with standard deviation, which makes it hard to tell whether the performance is statistically significant."
            },
            "questions": {
                "value": "1. Would it be possible to construct the message passing between interfaces with GVP, another MPNN model that aggregates with protein scalar and vector features? \n2. Why use log odds ratio for predicting $\\Delta\\Delta G$, instead of training a regressor to directly predicting the $\\Delta\\Delta G$ values?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8349/Reviewer_hYdu"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8349/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698845603225,
        "cdate": 1698845603225,
        "tmdate": 1700637402527,
        "mdate": 1700637402527,
        "license": "CC BY 4.0",
        "version": 2
    }
]