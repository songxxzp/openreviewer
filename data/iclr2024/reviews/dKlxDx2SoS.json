[
    {
        "id": "oN7sKiP8Gt",
        "forum": "dKlxDx2SoS",
        "replyto": "dKlxDx2SoS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4459/Reviewer_Rjda"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4459/Reviewer_Rjda"
        ],
        "content": {
            "summary": {
                "value": "This paper devised a method that combines a pre-trained model to achieve high performance in VL tasks even in situations where there is no training data. It also achieved excellent benchmark results in three validation tests: base-to-novel generalization, cross-dataset transfer, and domain transfer scenarios, even compared to MaPLE, one of the latest models."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "Benchmark tests have been conducted and it has achieved excellent results compared to SOT methods. The benchmarks are also reasonable and provide excellent comparisons."
            },
            "weaknesses": {
                "value": "The structure of the model shown in Figure 2 is poorly explained, making it difficult to understand the difference between it and other models. I also got the impression that there was a lack of consideration as to why MaPLE achieved such excellent results. I would have liked a more detailed chapter to explain why this model is so good."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Reviewer_Rjda"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4459/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698581264847,
        "cdate": 1698581264847,
        "tmdate": 1699636421365,
        "mdate": 1699636421365,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NdUySpfynw",
        "forum": "dKlxDx2SoS",
        "replyto": "dKlxDx2SoS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4459/Reviewer_jgw2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4459/Reviewer_jgw2"
        ],
        "content": {
            "summary": {
                "value": "This work aims to improve the performance of a multi-modal pre-trained foundation model via prompt tunning. This work proposes to use Quaternion Networks to align the semantics across modalities while finetuning. Quaternion Network projects feature quaternion hidden space, where three mutually orthogonal imaginary axes, namely i, j, and k, allocate unique weights to various distribution features from diverse perspectives. Compared to previous prompt learning works, the major difference is introducing quaternion hidden space to fuse data modalities. This work conducts experiments on more than 10 datasets which is solid to some extent.\n\nPros:\n- This work introduces quaternion hidden space to prompt learning for foundation models, which is new.\n- Experiments cover a wide range of datasets.\n\nCons:\n- Comparing the proposed method with previous prompt learning methods on computation overhead and latency is needed.\n- Quaternion hidden space seems to be more sophisticated than linear space which might be better than linear projection. However, it's not obvious why Quaternion Networks is better than the previous prompting technique; or why tunning multimodal pre-trained networks needs quaternion hidden space. \n\n\nIn-depth comparison with previous prompting methods and analysis of this quaternion network improve this work."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Pros:\n- This work introduces quaternion hidden space to prompt learning for foundation models, which is new.\n- Experiments cover a wide range of datasets."
            },
            "weaknesses": {
                "value": "Cons:\n- Comparing the proposed method with previous prompt learning methods on computation overhead and latency is needed.\n- Quaternion hidden space seems to be more sophisticated than linear space which might be better than linear projection. However, it's not obvious why Quaternion Networks is better than the previous prompting technique; or why tunning multimodal pre-trained networks needs quaternion hidden space."
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Reviewer_jgw2"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4459/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698683960463,
        "cdate": 1698683960463,
        "tmdate": 1699636421272,
        "mdate": 1699636421272,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ykE5wJSwHB",
        "forum": "dKlxDx2SoS",
        "replyto": "dKlxDx2SoS",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4459/Reviewer_xbTq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4459/Reviewer_xbTq"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses the challenges and limitations of multimodal pre-trained models in capturing diverse and complementary features across different modalities. It introduces a novel approach called QNet, which utilizes quaternion networks to improve the modality fusion capacities of pre-trained models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The use of quaternion networks to capture the intricate relationships among different modalities is a novel idea that sets this paper apart from existing methods. The paper provides a thorough analysis of the proposed method, including experimental results on various datasets and comparison with existing methods. The results are presented in a clear and concise manner.\n\nThe paper is well-written and organized, making it easy to follow the proposed approach and understand the experimental results."
            },
            "weaknesses": {
                "value": "Overall, this paper presents a sound framework. My main concern is that the authors should compare to the baseline scombining Quaternion Networks and the existing prompt learning method clearly. Besides, the benefits of QNet can be evaluated on more multimodal tasks."
            },
            "questions": {
                "value": "Please see my comments on the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4459/Reviewer_xbTq"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4459/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1700383069337,
        "cdate": 1700383069337,
        "tmdate": 1700383069337,
        "mdate": 1700383069337,
        "license": "CC BY 4.0",
        "version": 2
    }
]