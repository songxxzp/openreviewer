[
    {
        "id": "hKypAdfhFI",
        "forum": "lBUUNj0Fnz",
        "replyto": "lBUUNj0Fnz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission752/Reviewer_eZUf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission752/Reviewer_eZUf"
        ],
        "content": {
            "summary": {
                "value": "**This paper proposes an active learning algorithm that simplifies the task of data labeling in image segmentation. The proposed algorithm utilizes binary queries, asking about the existence of semantic classes in images, which appears to be a streamlined approach compared to conventional detailed annotation processes.** However, while the methodology is novel and the binary query concept intriguing, the paper might benefit from a more robust evaluation of its practical implications and limitations. \n\nThe empirical studies presented seem promising but might not fully encapsulate the algorithm's efficacy and applicability. Additionally, while the focus on reducing human effort is commendable, there appears to be **a critical assumption that binary queries are sufficient for image segmentation tasks, which might not always hold**. A crucial aspect to consider is the algorithm's reliance on an initial dataset. The effectiveness of the proposed method may be compromised if not furnished with a large number of images initially. This significant dependence on initial data volume underscores a vulnerability in its design, potentially restricting its practical applicability where acquiring ample relevant images is problematic. While the paper's innovative approach to reducing manual labeling efforts is noteworthy, its successful implementation seems contingent upon the availability of a robust initial image dataset. Such a requirement necessitates a thoughtful appraisal of its practical adaptability and overall efficacy in real-world scenarios.\n\nFurthermore, the generalizability of this algorithm to other domains, such as object detection, is mentioned as a future direction, but it remains speculative without empirical validation. In conclusion, the paper presents an active learning for image segmentation but leaves room for a more comprehensive exploration of its practical potential and limitations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper presents a new active learning algorithm for image segmentation in deep learning, boasting several notable strengths. \n\n- The algorithm is characterized by a thoughtfully designed linear programming formulation. However, it's important to note that this design is primarily grounded in heuristics. This basis may influence the robustness and predictability of the algorithm, possibly affecting its overall efficacy and application in various contexts.\n\n- The algorithm is user-friendly, making the annotation process considerably more manageable for humans. Simplifying the labeling task through binary queries regarding semantic classes in images fosters an environment where annotators can work more efficiently and effectively, reducing the complexity and burden of the annotation process.\n\n- Performance-wise, the algorithm exhibits reasonable outcomes when furnished with an ample initial set of labeled images. With a sufficient starting dataset, the algorithm illustrates a notable level of effectiveness and utility, positioning itself as a potent tool for image segmentation tasks in deep learning. These observations affirm the viability and functionality of the proposed concept, indicating that the underlying idea holds merit and applicability."
            },
            "weaknesses": {
                "value": "This paper presents several notable areas for improvement and consideration. \n\n- There is a concern regarding the Linear Programming (LP) formulation, as opposed to some aspects of my statements in strengths, which, while crucial, seems to necessitate significant memory, especially when handling large datasets with extensive semantic classes. This could potentially hinder the algorithm\u2019s efficiency and applicability in broader contexts.\n\n- The theoretical foundation of the proposed framework seems somewhat lacking. Since the formulations primarily rely on heuristics-based LP formulation, there\u2019s an inherent uncertainty regarding the algorithm\u2019s reliability and the specific conditions under which it might fail. A more robust theoretical backing would enhance the algorithm\u2019s credibility and predictability.\n\n- It\u2019s essential to highlight the algorithm\u2019s pronounced dependence on a considerable initial dataset for optimal functionality. This dependency could limit its utility in scenarios where access to such extensive initial data is restricted or impractical.\n\n- The algorithm presented in this paper aims to reduce human labeling efforts, enhancing ease and efficiency in the data annotation process. However, it appears that this simplification comes at a cost, with the algorithm showing a certain level of compromised performance according to Figure 2 and Figure 3. The effort to make the labeling process more user-friendly and less labor-intensive seems to inadvertently lead to a trade-off, affecting the overall efficacy of the algorithm. This aspect suggests a delicate balance between facilitating human involvement and optimizing algorithm performance.\n\n- The paper appears to omit consideration of recent advancements in active learning techniques. Notably, very few pixel annotation strategies, such as \"PixelPick\" [1], which emphasizes minimal pixel-based annotations in each image, and \"BADGE\" [2], \"Balanced Entropy\" [3], or \"PowerBALD/PowerEntropy\" [4], potentially offering a more effective approach than CoreSet, are overlooked. These examples, while not exhaustive, underscore the breadth of contemporary methodologies that could be instrumental in enriching the algorithm\u2019s framework and applicability. By integrating these current developments, the paper could ensure a comprehensive alignment with the evolving landscape of the field, thereby bolstering the algorithm\u2019s relevance and efficacy in the context of modern active learning paradigms.\n\n[1] All you need are a few pixels: semantic segmentation with PIXELPICK, ICCVW 2021 - https://openaccess.thecvf.com/content/ICCV2021W/ILDAV/papers/Shin_All_You_Need_Are_a_Few_Pixels_Semantic_Segmentation_With_ICCVW_2021_paper.pdf\n\n[2] Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds, ICLR 2020 - https://openreview.net/forum?id=ryghZJBKPS\n\n[3] Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle, ICLR 2023 - https://openreview.net/forum?id=ZTMuZ68B1g\n\n[4] Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning, TMLR 2023 - https://openreview.net/forum?id=vcHwQyNBjW\n\n**Minor Comment**\n\nPage 4, Eq (1): The sign of entropy has been reversed. It should be $H_{ij}=-p_{ij}\\log p_{ij} - (1-p_{ij})\\\\log (1-p_{ij})$. Otherwise, $H_{ij}$ would be a negative value."
            },
            "questions": {
                "value": "1. The proposed algorithm necessitates significant memory resources for the Linear Programming (LP) formulation. **Could the authors provide clarification regarding the memory consumption associated with the algorithm, particularly as the volume of unlabeled images increases?** Understanding how the algorithm's memory usage scales in response to larger datasets would be crucial for assessing its practical applicability and efficiency.\n\n2. In evaluating Image Redundancy, i.e., Eq (3) on page 4, the authors have assigned a value of $0$ to negative cosine similarity values. However, it is worth considering whether this approach effectively captures the essence of redundancy. Negative cosine similarity values indicate an inverse redundancy, which suggests that setting these values to $0$ might not be the most informative choice. Using the absolute value of the cosine similarity could be a more reasonable alternative, as it would allow for a better understanding of redundancy relationships. **Could the authors please clarify the rationale behind assigning a $0$ value in this context and why it is deemed essential for accurately capturing redundancy in images?**\n\n3. **Please elucidate the impact of the number of initially labeled images on the algorithm's performance.** This aspect is a pivotal assumption in this study, playing a crucial role in the algorithm\u2019s effectiveness. It is essential to either validate this assumption or provide recommendations regarding the requisite quantity of initial images necessary for the algorithm to function optimally. Clarifying this matter will enhance the algorithm\u2019s practical applicability and reliability in real-world scenarios."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Reviewer_eZUf"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission752/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698464419698,
        "cdate": 1698464419698,
        "tmdate": 1699636002556,
        "mdate": 1699636002556,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "A7EE2Upo3x",
        "forum": "lBUUNj0Fnz",
        "replyto": "lBUUNj0Fnz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission752/Reviewer_ZnPV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission752/Reviewer_ZnPV"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an active learning algorithm for image segmentation. The new method identifies a batch of informative images and a list of semantic classes for each image by a constrained optimization problem. The human annotator merely needs to answer whether a given semantic class is present or absent in a given image. The experimental results show that the proposed method consumes less time than pixel-level annotations and region-level annotations, and its annotation results are better than other comparative binary-level annotations."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper applies an active learning framework to image segmentation, which poses only binary (yes/no) queries to the users."
            },
            "weaknesses": {
                "value": "(1) Algorithm 1 does not include all the details of the method.\n\n(2) The article focuses on how to sample images and provide object classes through optimization models, and there is less and vague introduction on how to iteratively achieve pixel level annotation of images."
            },
            "questions": {
                "value": "(1)\t Algorithm 1 does not include all the details of the method, that is, Algorithm 1 only introduces the method of selecting the unlabeled images and the corresponding semantic classes, but does not mention how the annotator answers yes/no, nor does it mention how to achieve higher precision pixel level annotation iteratively after obtaining M.\n\n(2)\tHow to annotate an image at the pixel level only by determining the classes of the objects in the image? In other words, if all the classes of the objects in the image are correct, how to accurately locate these objects and achieve pixel level annotation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Reviewer_ZnPV"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission752/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698583176819,
        "cdate": 1698583176819,
        "tmdate": 1699636002485,
        "mdate": 1699636002485,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "yRGHdUIG59",
        "forum": "lBUUNj0Fnz",
        "replyto": "lBUUNj0Fnz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission752/Reviewer_cBzD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission752/Reviewer_cBzD"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors proposed an active learning algorithm for image segmentation, which queries binary feedback to ascertain the presence or absence of a semantic class within an unlabeled image. The authors identified the informative image-class pairs by considering both the class presence uncertainty and image redundancy. Furthermore, they conduct experiments and user studies on three image segmentation benchmarks to assess the efficacy of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Compared to pixel-wise or region-wise annotations, binary (yes/no) queries are more time-efficient and less labor-intensive."
            },
            "weaknesses": {
                "value": "Weakness\n1.Both metrics of uncertainty and diversity are lack of novelty. Besides, in computing class presence uncertainty, the calculation of the probability that image i contains the semantic class j remains unclear. Is it the average probability of pixels belonging to the semantic class j within image i?\n2.The rationale of selecting informative image-class pairs through an optimization problem, rather than designing a sampling strategy, lacks clarity.\n3.The authors employed 1,500 images with pixel-wise annotations to construct the initial training set. Despite the efficiency gains from binary queries in subsequent AL rounds, the annotation cost for the initial training set remains substantial. Moreover, I have reservations about the impact of the initial training set size on AL performance. In other words, if there are fewer pixel-wise annotated samples in the initial training set, will the binary-query-based AL still yield effective results?\n4.The authors did not investigate recent advancements in active learning (AL), and the related work section should be updated accordingly. Besides, the authors did not compare with state-of-the-art AL methods."
            },
            "questions": {
                "value": "see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Reviewer_cBzD"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission752/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698743773086,
        "cdate": 1698743773086,
        "tmdate": 1699636002406,
        "mdate": 1699636002406,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rC8M2NYo1H",
        "forum": "lBUUNj0Fnz",
        "replyto": "lBUUNj0Fnz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission752/Reviewer_nZpY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission752/Reviewer_nZpY"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to use Active Learning (AL) to query for weak labels for the task of semantic segmentation. The proposed approach is evaluated on three different datasets with two different backbones for the chosen architecture. Additionally a small user study is performed to motivate the benefits provided by the proposed approach."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Interesting idea to combine existing AL techniques with weak labels. \n\nVery helpful to motivate the proposed approach with a user study and actual labelling effort measured in annotation time. \n\nThe proposed approach is evaluated on multiple datasets of varying difficulty/scope, additionally two different backbones are used in the experiments."
            },
            "weaknesses": {
                "value": "# General comments\nOverall the idea is interesting, while incremental in novelty. The presentation and language of the submission have room for improvement. As the paper touches weak-labelling and active learning, it could be better embedded especially in the literature/related work on semi-supervised learning, self-supervised learning and especially learning from weak labels.\n\nMinor hints on language, there are more of those, i suggest to consider an additional proof reading step by a native speaker:\n* \"to induce a neural network\" not sure what this formulation refers to, it is used at multiple places.\n* \"which entails much lesser annotation effort\" consider rephrasing\n* \"furnishing the highest prediction entropy\" not sure 'furnishing' is an optimal choice of wording here\n\n# Related work\nWhile (Settles, 2010) is certainly an important reference, however, there are more current survey papers that can be cited here, e.g. https://arxiv.org/pdf/2203.13450.pdf\n\n\"Active learning for image segmentation has been comparatively less explored than other applications.\"\nI disagree with that statement, with semantic segmentation being algorithmically very close to classification, I'd argue semantic segmentation is one of the prime applications of AL methods. See e.g. the references the authors themselves use, (Casanova et al., 2020), (Kasarla et al., 2019), (Mackowiak et al., 2018), (Vezhnevets et al., 2012), (Golestaneh & Kitani, 2020) and more, like\n\nSiddiqui, Yawar, Julien Valentin, and Matthias Nie\u00dfner. \"Viewal: Active learning with viewpoint entropy for semantic segmentation.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\nXie, Shuai, et al. \"Deal: Difficulty-aware active learning for semantic segmentation.\" Proceedings of the Asian conference on computer vision. 2020.\n\nLearning from weak labels seems to be missing from the comparisons, i suggest adding a discussion or better experimental comparison, some suggestions below. \n\nOlmin, Amanda, et al. \"Active Learning with Weak Labels for Gaussian Processes.\" arXiv preprint arXiv:2204.08335 (2022).\n\nWu, Jian, et al. \"Weak-labeled active learning with conditional label dependence for multilabel image classification.\" IEEE Transactions on Multimedia 19.6 (2017): 1156-1169.\n\nYounesian, Taraneh, et al. \"Qactor: Active learning on noisy labels.\" Asian Conference on Machine Learning. PMLR, 2021.\n\nWu, Jian, et al. \"Weak-labeled active learning with conditional label dependence for multilabel image classification.\" IEEE Transactions on Multimedia 19.6 (2017): 1156-1169.\n\nLu, Zhiwu, et al. \"Learning from weak and noisy labels for semantic segmentation.\" IEEE transactions on pattern analysis and machine intelligence 39.3 (2016): 486-500.\n\n# Implementation Details\n\n## User Study\nVery valuable to provide some evidence on the time required for manual labelling.\nUnfortunately the user study has been conducted with a relatively low number of Annotators (3) and images (10) and only the mean was reported, potentially averaging over very extreme differences in annotator performance.\n\nThe reported numbers are still valuable, but the study could be improved. To understand the results better it would help to elaborate on the proficiency of the annotators (un-trained?) and give a reference to the annotation tool used. Different tools can have very varying suitability for the three different tasks that were compared.\n\nWith the low number of images and annotators exhaustive statistics seem non-appropriate, but providing some guidance on the spread of the values, e.g., standard-deviation (across all dimensions or across images), would help in interpreting them.\n\n## Experimental setup\nFor a study as the presented one the split into train, test and pool is actually very important, however details on how the split was realized are lacking. Additionally there is no validation set mentioned, usually i'd assume the validation was used to tune the training of the chosen architecture on the chosen dataset. \n\nCityscapes provides 20k weakly annotated frames, given, that the authors propose a AL + weak label scheme, those would be a prime candidate for more exhaustive experiments. \n\nSide-note: i find the graphs a bit hard to read due to the chosen style of presentation, different line styles and markers, as well as larger images could help."
            },
            "questions": {
                "value": "* Which labelling tool was used for the user study?\n* Were the annotators trained at the task or did they do labelling for the first time?\n* How was the train, test, pool split realized? Same strategy for the different datasets?\n* Why is the test set rather small?\n* Was there no validation set? \n* How were the parameters for the training of the DNN chosen? \n* The reported numbers do not seem to match the full size of e.g., Cityscapes, any reason to not using the full dataset for the experiments?\n* How do the results compare to a random baseline?\n* How do the results compare to a baseline (same architecture) trained on the full set (train + pool) evaluated on the custom test split?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission752/Reviewer_nZpY"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission752/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699451556923,
        "cdate": 1699451556923,
        "tmdate": 1700833621005,
        "mdate": 1700833621005,
        "license": "CC BY 4.0",
        "version": 2
    }
]