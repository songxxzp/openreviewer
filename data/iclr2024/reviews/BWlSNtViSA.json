[
    {
        "id": "EqQGcWaDbh",
        "forum": "BWlSNtViSA",
        "replyto": "BWlSNtViSA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6101/Reviewer_5ZBL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6101/Reviewer_5ZBL"
        ],
        "content": {
            "summary": {
                "value": "The submission presents Bi-level Fair Pruning (BiFP), a new approach to neural network pruning that ensures fairness (with another convex relaxation to efficient training). BiFP optimizes the pruning mask and network weights simultaneously under fairness constraints.  The experimental results on two benchmark datasets show some interesting performances."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The submission is in good shape, and the writing clearly conveys the novelty and contribution. \n\n- The problem setting (i.e., neural network pruning with fairness constraints) is novel to the best of my knowledge. \n\n- The proposed bi-level pruning is sound and reasonable, and experimental results show some interesting findings."
            },
            "weaknesses": {
                "value": "- My main concern is the random initiation of the mask. It is not clear what kind of randomization is used in the experiment, and whether different randomization strategies will lead to different performances. \n\n- The paper presents a bi-level pruning method (i.e., optimizing one variable while fixing another one). How do you guarantee the convergence theoretically. Again, since the mask is randomly initialized, will different randomization lead to different convergences? Noted that different randomization could also impact the objective function (leading to different landscapes), thus, both theoretical and experimental studies regarding the issue of convergence should be conducted. \n\n- Based on the results in Fig. 3 and 4, the improvement seems to be very marginal. It is not clear to me whether the improvement is significant.\n\n- The adopted datasets and models for evaluation seem to be toy to me, perhaps more realistic dataset (e.g., healthcare) and more advanced model should be evaluated. \n\n- The motivation of using conves relaxation in 4.3 is not clear to me. Based on the submission, it seems the advantage of using convex relaxation is to let the fairness constraint convex and differentiable, but noted that our deep neural network is non-convex in nature (e.g., ReLU, maxpooling, etc.), the argument above is not convincing to me."
            },
            "questions": {
                "value": "Please see above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "This submission focused on the problem of fairness."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6101/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698574439912,
        "cdate": 1698574439912,
        "tmdate": 1699636658187,
        "mdate": 1699636658187,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7JsN1FlwMN",
        "forum": "BWlSNtViSA",
        "replyto": "BWlSNtViSA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6101/Reviewer_Wsp2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6101/Reviewer_Wsp2"
        ],
        "content": {
            "summary": {
                "value": "This work studies the problem of exacerbating biases in neural networks upon pruning. In particular, the authors propose a bi-level optimization based unstructured pruning algorithm to mitigate the biases. The core idea is to optimize for the pruning mask and weights in an alterating fashion to jointly minimize the classification loss and fairness metric. \n\nThe approach proposed demonstrates better accuracy-fairness tradeoff with respect to pruning methods that do not optimize for fairness at different sparsity levels."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "S1. The problem is important and has been gaining some traction in the recent years.\n\nS2. Overall the paper is well written - especially the preliminaries."
            },
            "weaknesses": {
                "value": "W1. The idea of using bi-level optimization is not new to pruning. [a] uses it in a very similar fashion to that in the paper. While [a] is cited in the manuscript, it is not explicitly called out that they also use a very similar bi-level optimization framework - which looks misleading.\n\nW2. Definition 2 (Compressed Model Performance Degradation) and Definition 3 (Performance Degradation Fariness) seems unnecessary, since the authors essentially use only the fairness perfromance metric (definition 1) in practice when pruning the model.\n\nW3. Experiments are limited across dimensions such as datasets, models. More datasets (including larger ones) should be included such as in [b]. Larger models such as ResNets should also be included in the study.\n\nW4. Stronger baselines need to be used. At the moment, none of the baselines used optimize for fairness. However, there are other works such as [b] that optimize for fairness and should be used as a baseline to show the benefit of bi-level optimization over existing pruning approaches.\n\n\nOverall, I feel that the paper is still incomplete and is not yet ready for publishing. Moreover, I observe limited novelty in this work due to lack of difference from [a]'s pruning objective (Equation 1). Instead of the regulariser, the authors have replaced it with equation 8 of the manuscript which is directly bought in from [c].\n\n\n[a] Advancing Model Pruning via Bi-level Optimization. Zhang et al. NeurIPS 2022.\n\n[b] Fairgrape: Fairness-aware gradient pruning method for face attribute classification. Lin et al. ECCV 2022\n\n[c] On Convexity and Bounds of Fairness-aware Classification/ Wu et al. WWW 2019."
            },
            "questions": {
                "value": "1. As stated above equation 8, $u(.)$ is a surrogate function for the indicator function. What is your choice of $u(.)$?\n2. As stated in section 4.3.2 $m$ is taken to be continuous. It is not clear how the mask is selected when pruning the network. Do you select the sparsity level at the start of the pruning procedure and try to identify appropriate indices in the mask that should be made 0. Or do you gradually increase the sparsity level. Also, what if the mask value becomes, say -2.5. What would you do in that case?\n\n\nMinor comments:\n\n- In Definition 3 and beyond, $\\mathbb{F(f_c, \\mathcal{D}; \\mathbb{R})}$ should be  $\\mathbb{F(f, f_c, \\mathcal{D}; \\mathbb{R})}$\n- In equation 5, what are you minimizing with respect to in the upper optimization problem?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6101/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6101/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6101/Reviewer_Wsp2"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6101/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698669008440,
        "cdate": 1698669008440,
        "tmdate": 1699636658074,
        "mdate": 1699636658074,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dEcpCORToY",
        "forum": "BWlSNtViSA",
        "replyto": "BWlSNtViSA",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6101/Reviewer_SMS5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6101/Reviewer_SMS5"
        ],
        "content": {
            "summary": {
                "value": "The authors of this paper investigate the algorithmic bias issue in neural network pruning. A joint optimization framework is proposed. It is called Bi-level Fair Pruning (BiFP) based on bi-level optimization to ensure fairness in both the weights and the mask. Extensive experiments demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper studies a novel and interesting problem. Addressing demographic disparity challenges has received much attention in the recent works on deep learning. However, most works on pruning do not address this issue.\n2. The proposed method is reasonable. \n3. This paper is organized well."
            },
            "weaknesses": {
                "value": "1. The experiment suffers from samll scale. Only small models (ResNet10 and Mobilenetv2) are used as an uncompressed model. The used datasets (CelebA and LFW) are also small. \n2. Althogh the propsed method is reasonable, it seems trivial. Eq 5 defines the joint optimization framework. It simply combines two constrains. This paper is short of novel techniques."
            },
            "questions": {
                "value": "None"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6101/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6101/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6101/Reviewer_SMS5"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6101/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698730997175,
        "cdate": 1698730997175,
        "tmdate": 1699636657956,
        "mdate": 1699636657956,
        "license": "CC BY 4.0",
        "version": 2
    }
]