[
    {
        "id": "jfKpI2zxI2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4629/Reviewer_SX6K"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4629/Reviewer_SX6K"
        ],
        "forum": "KSvRZFCy7s",
        "replyto": "KSvRZFCy7s",
        "content": {
            "summary": {
                "value": "The paper proposes a method to generate DP synthetic data that projects the data into a low-dimensional linear subspace, generates synthetic data there, and projects it back. Projecting to a low-dimensional subspace improves the dimension dependency of the accuracy if the data actually lies close to that subspace. The paper proves a Wasserstein distance accuracy guarantee, and conducts a single experiment on an image dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is fairly easy to understand, despite being theory-heavy. Using PCA in this way to get around the curse of dimensionality in DP synthetic data generation is novel to my knowledge."
            },
            "weaknesses": {
                "value": "## Major Issues\nThe Laplace mechanism should be introduced in the paper, and its privacy guarantee should be stated. The parameter of the Laplace mechanism should be $\\frac{\\Delta_1}{\\epsilon}$ for $\\epsilon$-DP, where $\\Delta_1$ is the $L_1$-sensitivity (Dwork and Roth 2014, Definition 3.3). The paper uses the Laplace mechanism to release $\\bar{X}$ in Algorithms 1 and 3 with $\\Delta_1 = \\frac{1}{n}$. However, if the data is $d$-dimensional, the $L_1$ sensitivity of $\\bar{X}$ is $\\frac{d}{n}$, so it looks like Algorithm 1 does not have the advertised privacy bound. The incorrect sensitivities are used in the accuracy analysis (for example equation C.7), so they are unlikely to be just typos.\n\nThe \"private covariance matrix\" and \"private linear projection\" steps in Algorithm 1 should have $\\epsilon / 4$, not $\\epsilon / 2$.\n\n## Minor Issues\nThe paper should mention that the experiment considers the image labels to be public information in the experiment, so they don't have privacy protection.\n\nThe generated images look very poor compared to images showcased in the DP-MERF paper (Harder et al. 2021) for MNIST. As the datasets are different, it would be good to compare with DP-MERF on the dataset used in the paper."
            },
            "questions": {
                "value": "- You claim that the Wasserstein distance bound gives accuracy guarantees for many machine learning algorithms. How strong are these guarantees in practice? For example, what is the accuracy guarantee for the SVM in the experiment of the paper (if there is one)?\n- What is the accuracy of the SVM on the real data, without DP?\n- Assuming that the data lies close to a low-dimensional linear subspace (instead of a more general manifold) sounds very restrictive. Do you have some idea on what settings would this assumption be realistic in?\n- Is $\\sigma_i(M)$ the $i$-th largest eigenvalue in Theorem 1.2, or is the order something else?\n- How could $d'$\u00a0chosen in practice?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4629/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4629/Reviewer_SX6K",
                    "ICLR.cc/2024/Conference/Submission4629/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4629/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697237166606,
        "cdate": 1697237166606,
        "tmdate": 1700584310997,
        "mdate": 1700584310997,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "V7tLBDVvTP",
        "forum": "KSvRZFCy7s",
        "replyto": "KSvRZFCy7s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4629/Reviewer_7H6Q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4629/Reviewer_7H6Q"
        ],
        "content": {
            "summary": {
                "value": "it is known that the expected utility loss of $\\varepsilon$-DP synthetic dataset in 1-Wasserstein distance is $\\Omega((\\varepsilon n)^{-1/d})$. However, if the data lies in a $d'$-dimensional subspace, then one can construct DP synthetic data with $\\tilde{O}((\\varepsilon n)^{-1/d'})$ utility bound. However, the the previous work's algorithm (Donhauser et al., 2023) has runtime complexity of $O(d^{d'}n + poly(n^{d/d'}))$. \n\nIn this work, the authors propose a polynomial-time algorithm for low-dimensional synthetic. The authors also claim that it has a better utility bound that that in Donhauser et al., 2023.\n\nMainly, the proposed algorithm employs (1) private PCA to project the data to a low-dimensional subspace and (2) hierarchical partition, where Laplacian noise is added to the count in each subregion in order to create a synthetic probability measure.."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The authors proposed a polynomial-time algorithm for DP synthetic data that can be more accurate than previous methods if the data is lying in a low dimensional subspace.\n- The value of $d'$ can be chosen adaptively by looking at the singular values of the privatized covariance matrix.\n- Privacy and utility analysis of the algorithm are provided."
            },
            "weaknesses": {
                "value": "- The experimental against the full-dimension algorithm is convincing, but I also would like to see how it perform against the method of Donhauser et al. (2023), especially when the authors claim that their method is more accurate than that of the previous work.\n- There should be a discussion on the $\\sqrt{\\sum_{i>d'}\\sigma_i(M)}$ term, especially when $d'$ is unknown (which occurs in most use cases). How do we make sure that this term does not dominate the rest of the error bound?\n\nRight now, I am mainly focusing on the soundness of the paper, but I am not fully convinced that the proposed method performs *strictly* better than that of Donhauser et al. (2023). Also see Questions below."
            },
            "questions": {
                "value": "- In the Conclusion, the authors claim that Donhauser et al. (2023)'s accuracy rate is $(\\varepsilon n)^{-1/(d'+1)}$. I skimmed the said paper and couldn't found the exact bound. Can the authors point me to where the said bound is located?\n- I think the upper bound can be used to find an \"optimal\" value of $d'$ by comparing $\\sqrt{\\sum_{i>d'}\\sigma_i(\\hat{M})}$ and the rest of term (we also might have to take the bias of $\\sigma_i(\\hat{M})$ into account. Can the authors make some comments on this approach?\n\nMinor comments:  \n- In Algorithm 1: \"Let $\\overline{X}$ be the mean value of the dataset\". Is this the original or the synthetic dataset?\n- Continuing from above, if it is the mean of the original dataset, can't we just save the privatized mean from the Linear Projection step and add it back after Low-dimensional Synthetic Data? This would help save the privacy budget by $\\varepsilon/4$.\n- In Algorithm 1, I see two mechanisms with privacy budget $\\varepsilon/2$, and two with $\\varepsilon/4$. I am not sure if I am interpreting this correctly since total privacy budget is larger than $\\varepsilon$.\n- In Algorithm 2, the definition of $\\boldsymbol{A}_{ij}$ when $i>j$ is missing."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4629/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698744882611,
        "cdate": 1698744882611,
        "tmdate": 1699636442233,
        "mdate": 1699636442233,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "tdAGCiUqsT",
        "forum": "KSvRZFCy7s",
        "replyto": "KSvRZFCy7s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4629/Reviewer_nzub"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4629/Reviewer_nzub"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the problem of generating low-dimensional synthetic datasets under the constraint of differential privacy (DP) accurately with respect to the Wasserstein distance. Their algorithms are computationally efficient and make no assumptions on the distribution of the underlying data. They provide both (primarily) theoretical and empirical results to demonstrate their findings.\n\nTheir algorithms is decomposed into a few steps. Private PCA followed by projections of data. Then they have an adaptation of the work from He et al (2023). The adding back the private mean vector to shift the subspace correctly."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The writing of this paper is quite good. The paper was easy enough to follow, and the results were cleanly written.\n2. Working in low-dimensions is an important theme for computational and sample efficiency, so their work makes sense in that regime.\n3. They don't require the data to have large eigenvalue gaps, so it is general enough by itself."
            },
            "weaknesses": {
                "value": "1. The expected Wasserstein distance is $poly(d)$. The second term is still alright if we have enough samples, but the third terms is the one that concerns me. When $d$ is large, the third terms does not really help a lot, especially when $d'$ is not too small. That said, the second term becomes too large if $d'$ is large, so there seems to be quite a trade-off over there.\n2. More empirical evaluation would have been nice for this venue. I understand that this is mainly a theoretical work, but given that it might have very practical applications, more experimental work would have made sense.\n3. The empirical accuracy is not significant when $\\varepsilon$ is small, even when as small as $1$, although it does better than a direct application of the work from He et al (2023)."
            },
            "questions": {
                "value": "1. Where are the empirical comparisons with He et al (2023) shown in the paper?\n2. At the bottom of page 2, what are $\\delta_{X_i}$ and $\\delta_{Y_i}$? Should define them somewhere earlier.\n3. How does the accuracy improve when the data is actually low-dimensional? It could be approximately low-dimensional, like in Singhal and Steinke (2021) or it could be exactly low-dimensional. How would the results change?\n4. How do your results compare with the **lower bounds** on DP synthetic data generation?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4629/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699043489966,
        "cdate": 1699043489966,
        "tmdate": 1699636442160,
        "mdate": 1699636442160,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "n9E9IPFRMP",
        "forum": "KSvRZFCy7s",
        "replyto": "KSvRZFCy7s",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4629/Reviewer_BUYC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4629/Reviewer_BUYC"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a differentially private algorithm to generate low-dimensional synthetic data with theoretical utility guarantees over the accuracy of the resulting data. Proof-of-concept experiments are given on MNIST, demonstrating the approach can yield synthetic data that provides reasonable utility on downstream tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper attempts to tackle and important problem which I agree has not been solved by existing DP literature. The theoretical analysis is rigorous and thorough and I have limited criticisms if this is pitched primarily as a theory paper. With that being said, I'm not convinced the most interesting problems in DP synthetic data create are theoretical at this stage."
            },
            "weaknesses": {
                "value": "My main criticism is that it is unclear how a practitioner looking to use this approach would know whether their data fits the regime in which the utility theorems hold. In particular, the experiments are very limited and in my view provide little information into the practical utility of the approach to most real-world datasets.  For instance it is very unclear that the inferences about the impact of choosing a smaller d' would generalize to other data. In my view the experiments need to be extended to a much wider set of datasets and downstream tasks. Currently the only evaluation is on the accuracy of a prediction, but one of the main benefits of sharing synthetic data is that in principle it could be used for a large stream of data analysis tasks, beyond training ML models (e.g. descriptive stats and regression tasks). \n\nRelated to my previous point, why is this the appropriate baseline approach in Figure 2? I would like to see this compared to training the classifier with DP-SGD directly without ever creating the synthetic data for instance and a classifier trained without DP. If the argument is that this approach lends itself to multiple training and analysis tasks, then a broader set of tasks should be included in the experiments. \n\nFinally, I would encourage the authors to include further intuition and descriptions of the algorithms in surrounding text to make the paper more readable. Currently the paper explains what each part of the algorithm does but I feel it lacks explanation of why this is a good idea."
            },
            "questions": {
                "value": "Why was such a high privacy budget chosen in the experiments? Did you try other values and how did this change the results?\n\nHow were hyper-parameters chosen in the experiments?\n\nHave you thought about whether statistical inference is feasible from the output of your algorithm?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4629/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4629/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4629/Reviewer_BUYC"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4629/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699570096926,
        "cdate": 1699570096926,
        "tmdate": 1699636442060,
        "mdate": 1699636442060,
        "license": "CC BY 4.0",
        "version": 2
    }
]