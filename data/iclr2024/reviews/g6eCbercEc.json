[
    {
        "id": "aX8VwZddno",
        "forum": "g6eCbercEc",
        "replyto": "g6eCbercEc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4476/Reviewer_v8jc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4476/Reviewer_v8jc"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for extracting different manipulation concepts (i.e. grasp, align, insert) from expert trajectories of robot manipulation tasks. In essence, the algorithm unsupervisedly learns relevant subgoals to accomplish a task, and in addition, also provides a gradient signal for actions to achieve these (sub)goals. This is done by training two components: predicting the next subgoal given the current state, and training a compatibility function that indicates how \"compatible\" a state is with the desired subgoal, using contrastive learning. The gradient of the compatibility function can then be used to select actions, i.e. which action increases the goal compatibility given the current state. The method is evaluated on 4 tasks of the ManiSkill2 benchmark, and some qualitative examples are provided of the discovered subgoals."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Interesting ideas and approach to go from expert trajectories to subgoals, and in addition obtain policies to accomplish those subgoals."
            },
            "weaknesses": {
                "value": "- The experimental results don't provide standard deviations, which makes it difficult to assess if there is any significant improvement compared to the presented baselines."
            },
            "questions": {
                "value": "- What are the standard deviations on the results in Table 1. To what extent is InfoCon actually significantly better than the other baselines?\n\n- For some tasks (i.e. P&P Cube) the GT key states underperform the other approaches. Any insight on why the ground truth key states are insufficient to efficiently execute the task, and which are the \"extra\" subgoals identified by InfoCon that might explain this gap?\n\n- The model is trained on only 500 trajectories. To what extent is this overfitting to the train set, and does this explain the large gap between seen and unseen scenarios? Would this gap be closed by just adding more trajectories?\n\n- The VQ-VAE is pretrained on the trajectories without any task-related signal. Hence, the learned subsequences are merely clustered by visual appearance, rather than semantic relevance of being a valid \"subgoal\" for a task?  Wouldn't it make sense to also adjust the codes in the codebook based on e.g. how good one can predict a particular goal and/or how well-behaved a compatibility function is?\n\n- The policy is conditioned on the current state and the gradient of the compatibility function. Wouldn't it make sense to also condition the policy on the goal state, i.e. similar to e.g. https://arxiv.org/abs/2211.13350"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4476/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4476/Reviewer_v8jc",
                    "ICLR.cc/2024/Conference/Submission4476/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4476/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698396003261,
        "cdate": 1698396003261,
        "tmdate": 1700659997860,
        "mdate": 1700659997860,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "q06iAHfduQ",
        "forum": "g6eCbercEc",
        "replyto": "g6eCbercEc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4476/Reviewer_WSFG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4476/Reviewer_WSFG"
        ],
        "content": {
            "summary": {
                "value": "This work, InfoCon, uses self-supervised learning method to discover the manipulation concepts in robotic tasks. The concepts are verified with semantic meaning in terms of human linguistics while saving much manual annotation efforts. This can be used as auxiliary task to support the encoding in the policy optimization. Experiements demonstrate that the policy trained based on these learned concepts can achieve the state-of-the-art results."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. InfoCon can be self-supervised given state-action trajectory without human annotation, guided by network architecture VQ-VAE and informativeness objectives. Surprisingly, the self-supervised key states even performs better than the human GT in the COTPC for policy generation.\n\n2. The robot with InfoCon can discover abstract concepts themselves other than struggling with the grounding of concepts that are manually defined.\n\n3, The concepts of generative goal and discriminative goal are novel and beneficial to the trajectory encoding, which serves as the auxiliary task for self-supervision.\n\n4. Strong results in simulation comparing to extensive baselines."
            },
            "weaknesses": {
                "value": "1, The proposed approach and concept of self-supervised manipulation concepts and key states seems closely related to the COTPC, as COTPC needs the key states. However, in the method description, there is no mention of COTPC. It may be possible to achieve co-optimization between policy generation and self-supervised manipulation concept. Moreover, can the proposed approach be general beneficial to policy optimization beside COTPC?\n\n2. The experience portion is a bit weak where only few tasks are evaluated. For the baseline, it should also include COTPC + other manipulation concept discovery for fair comparison.\n\n3. Lack of real robotic experiments. It is hard to judge if the proposed self-supervised approach works for the real-world complex tasks and videos."
            },
            "questions": {
                "value": "1. As generative models, there are many VAE variants. Can you explain why you choose VQ-VAE architecture or include ablation study?\n\n2. As mentioned in the paper: the manipulation concept, key state, and state are random variables depending on the trajectory. Does the initialization of these variables affect the experimental results? Or other prototype network approaches help?\n\n3. How about the generalization capability of InfoCon? In the paper, the training and testing tasks are same: P&P Cube, Stack Cube, Turn Faucet and Peg Insertion."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4476/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698746979488,
        "cdate": 1698746979488,
        "tmdate": 1699636423398,
        "mdate": 1699636423398,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "il4ah2IFyK",
        "forum": "g6eCbercEc",
        "replyto": "g6eCbercEc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4476/Reviewer_mBdA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4476/Reviewer_mBdA"
        ],
        "content": {
            "summary": {
                "value": "The authors propose using vector quantization to discretize robot manipulation trajectories into sets of discrete sub-trajectory encodings that maximize proposed metrics on discriminative and generative informativeness."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well written and the motivations and technical details are clear.  There are detailed evaluations and the proposed method is compared to multiple SOTA approaches.  The authors also include an ablation study and highlight a comparison of of human interpretability in addition to policy performance."
            },
            "weaknesses": {
                "value": "How do the authors feel about the interpretability of manipulation concepts for human robot interaction?  Learned concepts may not be as understandable in an interaction.  I am curious about an opinion on being able to map the learned concept back to a semantic concept or how that can be integrated into the objective.  I know human intuition is covered in Table 2, and the authors state there is a weak correlation with policy performance, but there may be cases where the goal is to optimize for both.\n\nIn section 2, \"partition each trajectory into semantically meaningful segments\" should this be clarified on what \"semantically meaningful\" means?  This goes with the earlier stated motivation of moving away from human semantic discretization into self-discovered discretization that optimizes discriminative and generative informativeness.\n\nFor eq 1, how does the observed state sequence factor into the generative goal?"
            },
            "questions": {
                "value": "See weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4476/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698870021540,
        "cdate": 1698870021540,
        "tmdate": 1699636423283,
        "mdate": 1699636423283,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oyX0i8YW0a",
        "forum": "g6eCbercEc",
        "replyto": "g6eCbercEc",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4476/Reviewer_1PDE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4476/Reviewer_1PDE"
        ],
        "content": {
            "summary": {
                "value": "This manuscript proposed InfoCon, a framework that can discover concepts in manipulation tasks automatically based on information reuseness. Specifically, the authors designed an analysis system that outputting discretized concepts from an offline manipulation dataset using a few different losses: generative goal loss, discriminative goal loss. Also, the side product from the architecture is the derivative of the discriminative loss, which represents the action to perform in order to complete the task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The manuscript is nicely written. I can follow most of the parts.\n2. The evaluation covers a medium size of tasks and dataset, which is not perfect (not large-scale) but I believe is enough for showcasing in robot learning area.\n3. The results look impressive that beat previous method marginally, achieving either the first or second best result in the whole table."
            },
            "weaknesses": {
                "value": "See question."
            },
            "questions": {
                "value": "1. I am a little bit confused about the motivation of discriminative goal loss. How is it trained and why it is useful for extracting information from the input states?\n2. I am not fully confident about the fairness of the comparison. It seems to me that methods including LLM+CLIP are zero-shot learning process that does not require the training data to be seen. Am I correct or it's actually not the case? If so, I would suggest to separating them in the comparison. However, I still think the proposed method has technical contributions that is worth to present.\n3. Is there any real-world example to indicate the effectiveness?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4476/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4476/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4476/Reviewer_1PDE"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4476/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698971185939,
        "cdate": 1698971185939,
        "tmdate": 1699636423210,
        "mdate": 1699636423210,
        "license": "CC BY 4.0",
        "version": 2
    }
]