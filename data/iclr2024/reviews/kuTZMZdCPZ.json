[
    {
        "id": "C8Zt8LFFVP",
        "forum": "kuTZMZdCPZ",
        "replyto": "kuTZMZdCPZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3013/Reviewer_xFQb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3013/Reviewer_xFQb"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new method to reconstruct spatiotemporal dynamics from sparse measurements by considering implicit neural networks. The spatiotemporal dynamics are separated into two independent spatial and temporal components. Superior performance has been shown in this paper compared with baseline models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- This paper proposes a new pipeline by combining implicit neural networks and functional separation of variables. In addition, Gabor filters are applied for learning high-frequency signals. \n- This paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "- The dataset is not that challenging. This paper considers monthly-averaged temperature data in **Simulation-based data** CESM2. The dynamics are relatively smoother than daily-averaged data. Please see some of my follow-up concerns regarding the dataset in **Questions**. \n\n- The sparsity setting considers some random sampling schemes. If the authors can discuss a bit on the optimal sensor placement, it would enhance the paper.\n\n- Since the authors use the Gabor filter instead of other common schemes to learn high-frequency signals, it would be good to have an ablation study on the Gabor filter part."
            },
            "questions": {
                "value": "- The 4th line of Page 6, \u201cwe uniformly distributing\u201d should be \u201cwe uniformly distribute\u201d.\n\n- How do the authors determine the sparse setting (Page 7) for those two datasets? The sparsity ratios for those two datasets are quite different. Also, can the authors provide an estimate or convergence analysis of the smallest number of sensors needed for reconstruction? \n\n- Why not consider the ERA5 dataset for climate modeling since the recent climate modeling papers [1-3] all use this benchmark dataset?\n\n- What are the spatial resolutions for the datasets used in this paper?\n\n---\n\nRefs:\n\n[1] Bi, Kaifeng, et al. \"Pangu-weather: A 3d high-resolution model for fast and accurate global weather forecast.\" arXiv preprint arXiv:2211.02556 (2022).\n\n[2] Pathak, Jaideep, et al. \"Fourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural operators.\" arXiv preprint arXiv:2202.11214 (2022).\n\n[3] Lam, Remi, et al. \"GraphCast: Learning skillful medium-range global weather forecasting.\" arXiv preprint arXiv:2212.12794 (2022)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Reviewer_xFQb"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3013/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698049011715,
        "cdate": 1698049011715,
        "tmdate": 1699636245946,
        "mdate": 1699636245946,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Dc4dDFU4xx",
        "forum": "kuTZMZdCPZ",
        "replyto": "kuTZMZdCPZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3013/Reviewer_8E6g"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3013/Reviewer_8E6g"
        ],
        "content": {
            "summary": {
                "value": "Authors consider reconstruction of continuous fields from sparse data, which has important applications in many real world problem (as authors states). They propose a new approach based on implicit neural presentations (INRs) and apply it to two climate model related datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Numerical results looks hood. Their methods seems to provide slower reconstruction accuracy (measured in terms of MSE) thank other INR approaches."
            },
            "weaknesses": {
                "value": "Presentation is quite a week and I have to say that I cannot follow it and understand what they are doing. First, mathematical notation is ambiguous and does not seem to follow standard mathematical principles, which creates confusion (Examples are in Questions section). Furthermore, background and description seems to be more like a list of different things and without clear connection. To make presentation more clear, authors could perhaps try to express their method with less mathematically rigours notations, but explaining their method with words (e.g. by providing example) \n\nAs mentioned above, numerical results looks good when compared to other INR methods. However, I would like to see also comparison to other non-INR based methods such as GP (if applicable) or methods that are currently used in meteorology and climate studies."
            },
            "questions": {
                "value": "Questions and comments:\n\n- Problem setup: They assume that the system is governed by a PDE (1). I don't see any reason why this assumption is made, or is that assumption used somewhere?\n\n- Section 2.1, \"Objective\" (and through the paper): They use notation $\\mathcal U_k=(u(t_k,x)|\\mathcal X_k)_{x\\in X_k}$ . What this \"$|\\mathcal X_k$\" stands in the set? $|$ usually is used for conditioning but I cannot see such a thing here. I would rather remove this extra part here to avoid confusion (I use '(' and ')' instead of curly brackets as this form does not seem to render those (and actually, strictly speaking, '(' and ')' would be preferred if order of measurements have meaning $\\mathcal U_k$))\n\n- The section 2.1 does not talk about noise or randomness and formulations in this section would indicate that $u(t,x)$ is deterministic. However, later sections seems to talk about noise and assume that $u$ is includes noise or is random (e.g. Eq (5) which does not have meaning if $u$ is deterministic). This is contradicting. I would suggest authors that authors would use separate notations for a noiseless quantity $u$ and the measurements, e.g., say something like $y_k$ is a vector of measurements or $u(t_k,x)$ plus noise. \n\n- Section 2.3, \"Neural pinpointing\". They mention that learning-based methods can be computationally demanding. But there are two sides in this: train time computationally complexity and run time/inference computational complexity. GANs have high training complexity but inference may not be soo much, and perhaps even less as the proposed INR depending on the architectures. \n\n- Section 2.4, \"$\\alpha=g(x)\\circ \\eta(t)$. The standard meaning for $\\circ$ is composition of functions, i.e. $(f\\circ g)(x)=f(g(x))$. Here this probable is not the case as I cannot see how you would compose $g$ and $\\eta$ in this case. Of course, authors can define their own notations, but then they should say that how they use the notation. If $\\circ$ is meant to be the multiplication, I would just remove $\\circ$. \n\n- Section 2.4, $\\eta(t_k):\\mathcal U_k=(u(t_k,x)|\\mathcal X_k)_{x\\in \\mathcal X_k}\\mapsto z_k$. Not sure what this is meant to mean. $\\eta$ is a function which maps $t$ to a function which is a mapping between the values of $u$ to $z_k$? \n\n- Section 3 seems to be a list of different things and it not clear to me that how the things are connected. For example, how you use auto-decoder? You have (auto-)decoder as encoder? How Gabor filters are used? Are these somehow connected to $g$ and $\\eta$ earlier? Multiplicative filter network is decoder?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Reviewer_8E6g"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3013/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698306822343,
        "cdate": 1698306822343,
        "tmdate": 1700660763947,
        "mdate": 1700660763947,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vanlTEvhZc",
        "forum": "kuTZMZdCPZ",
        "replyto": "kuTZMZdCPZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3013/Reviewer_A6YW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3013/Reviewer_A6YW"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an INR\u2013based method to reconstruct continuous fields from sparse sensor data for the application of climate modeling. The proposed method mainly introduces a latent variable to capture temporal information. The experiments are conducted on both simulated and real data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The paper is well written and organized, which is easy to follow.\n- The motivation and target application of the proposed method is clear and convincing.\n- The proposed method introduces a latent vector z to incorporate with INR decoder, which sounds interesting since it seems to make the INR model can be generalized across different images/samples by changing or optimizing latent vectors.\n- The experiments are conducted on both simulated data and satellite-based data with a clear comparison with baseline methods."
            },
            "weaknesses": {
                "value": "- About latent code z. The paper claims to use the trainable latent code to represent temporal information instead of using time index. What is the motivation for this? Because the recorded time index is not reliable in this application? Or the latent code can also represent other semantic information? Previous works have shown INR can represent spatial-temporal information in a good way by adding temporal index as input coordinates. \n\n- As described in the paper, during training, both latent code and INR are trained. While during training, INR model parameters are fixed and only latent code is optimized. Since the given information is quite sparse during testing, how reliable it can be to optimize latent code? How robust this method can be when generalized across different objects? By only changing the latent code in the input of INR decoder and freezing all other model weights, can this change the decoded image in an efficient way?\n\n- For the comparison with baseline methods as in Table 1, it seems all the baseline methods use a different encoding than the proposed model, which uses Gabor filters over Fourier bases to transform the coordinates as Fourier transforms emphasize a global frequency representation. Usually, the INR models are quite sensitive with different encoding methods. Can the paper also report the comparison with baseline methods using the same Gabor filters as encoding to disclose how impactful the encoding method is? Similar with the backbone model architecture, are all the comparisons based on the same backbone model? Only in this way, it may be fair to say how efficient the latent code can be in this case.\n\n- The compared methods are all the object-specific or scene-specific models, while the proposed model seems to be a generalized model across multiple images or objects. The method may also need to be compared with: (1) other generalized models based on INR such as SRN [1], etc. (2) other spatial-temporal models using time index such as D-NeRF [2].\n\n- The visualization of latent code is quite interesting but it is not clear what it means for the Figure 5. Can the author explain more about what information is learned or embedded by the latent code from these plots?\n\n[1] Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations, NeurIPS 2019.\n\n[2] \u200b\u200bD-NeRF: Neural Radiance Fields for Dynamic Scenes, CVPR 2021."
            },
            "questions": {
                "value": "Please see weakness for the details of questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3013/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698895305648,
        "cdate": 1698895305648,
        "tmdate": 1699636245781,
        "mdate": 1699636245781,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "57kduklcyi",
        "forum": "kuTZMZdCPZ",
        "replyto": "kuTZMZdCPZ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3013/Reviewer_MqB4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3013/Reviewer_MqB4"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a new implicit representation for spatio--temporal fields. The representation is based on separately processing temporal information via an encoder--decoder architecture (the decoder is an auto-decoder). This strategy, combined with other ingredients such as Fourier (here Gabor) features and multiplicative filter networks yields strong empirical performance on a synthetic climate dataset."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- the authors skillfully combine several existing techniques into a new architecture\n\n- compared with the baselines presented in the paper, the proposed method achieves remarkably strong performance\n\n- the idea to use an auto-decoder is creative and nice\n\n- the paper is well illustrated (for example, Figure 2 is very helpful in understanding the architecture)"
            },
            "weaknesses": {
                "value": "- I find the paper very hard to read. Notation and expressions in Section 3 and the last paragraph of Section 2 are confusing and it takes a long time to understand what is going on (Figure 2 helps here but the math could be clearer). Another reason is very florid prose which I'd hesitate to use in a machine learning paper. Examples: \"The endeavor to tackle the conundrum of global field reconstruction from sparse observations is currently shaping two distinct paradigms of thought\", \"raging ocean waves\", \"intricate physical fields\" (what are they?), \"we present an _innovative_ neural network approach\", \"... a singular viable option\", ...\n\n- While the narrative insists on strong novelty, all ingredients (and various combination thereof) are well known. The separation of variable idea is based on Dona et al 21, multiplicative filter networks are known, local activations (such as Gabor or wavelet) have been used in many papers, e.g. https://openaccess.thecvf.com/content/CVPR2023/html/Saragadam_WIRE_Wavelet_Implicit_Neural_Representations_CVPR_2023_paper.html. In some sense the present paper is a multiplicative filter network with a separate treatment of time through an encoder--decoder. This is perfectly fine but in my view it limits the novelty, and there is no shortage of all sorts of implicit networks.\n\n- In real fields space and time _are_ intertwined so one needs to go beyond the rank-one decomposition f(x) g(t); Dona et al mentions a low rank version \\sum_k f_k(x) g_k(t). It is not clear to me from the current description how this required expresiveness is achieved. It would be nice to explain that more clearly.\n\n- Generally, there is a lack of insight on why this strategy is supposed to perform well and why other approaches are supposed to perform poorly. This is a more general problem: there are now hundreds of implicit networks with different hyperparameters, training strategies, etc, and very little theoretical or other understanding of their mechanics. \nWhat if you compare your approach with an optimally tuned adaptive kernel estimator? How about spline interpolation? How about a simple low pass filter? It will surely not mess up as badly as ResMLP in Figure 3.\n\n- Along the same lines, in datasets description you mention that wavelets were used for initial interpolation of satellite-based data on a grid; why not compare the described method with a sparse wavelet interpolation?"
            },
            "questions": {
                "value": "- in experiments where you recover fields on the surface of a sphere, are you using Cartesian or spherical polar coordinates?\n\n- why not include (different levels of) random noise in observations? this is an important test of robustness\n\n- I am not sure that (Izacard et al., 2019) is the right reference for sparse seismic networks and small earthquakes (or even for sparse spatial coverage in scientific data; it addresses a super-resolution problem)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3013/Reviewer_MqB4"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3013/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699178446894,
        "cdate": 1699178446894,
        "tmdate": 1700683133598,
        "mdate": 1700683133598,
        "license": "CC BY 4.0",
        "version": 2
    }
]