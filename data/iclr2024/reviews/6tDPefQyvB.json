[
    {
        "id": "5z4xQRNbfr",
        "forum": "6tDPefQyvB",
        "replyto": "6tDPefQyvB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4533/Reviewer_rhbE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4533/Reviewer_rhbE"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a novel approach to extend the rotation equivariance property in local features (keypoints, desctiptors). Keypoint detection and description are essential in various downstream tasks of computer vision. The authors proposes the multi-scale rotation-equivariant feature fusion and the directional uncertainty weighted descriptor loss. The feature fusion stage isolates and concatenates the group dimension to ensure rotation equivariance. The paper also conducts a comparative analysis of classical equivariant descriptors and group-equivariant network-based descriptors on a standard image matching benchmark."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Motivation of the Problem: The paper addresses a crucial problem in computer vision, which is the extraction of rotation-equivariant local features such as keypoints and descriptors. This problem has broader applications beyond just image matching, making the research highly relevant in the computer vision.\n\nSoundness of Methodology: The utilization of multi-scale features to enhance scale robustness is well-founded. Additionally, incorporating a desctiptor loss by shifting in the direction using principal components is sound."
            },
            "weaknesses": {
                "value": "Improper citation. When citing a paper in ICLR format, citing in the middle of a sentence makes the sentence incomplete. This should be corrected to become a natural sentence.\nIt is not convinced to mention illumination invariance in the first paragraph of Section 1. This paper does not directly address illumination. (e.g., Tang et al., 2019)\nIn the first paragraph of Section 1, you give examples of image matching, 3D reconstruction, and object tracking, but the actual paper you cite is a Roxf/par paper on image retrieval. Additional citations of related papers are needed.\n\nIn section 2 related work, authors do not write a list of existing papers. Discuss the similarities and differences between them and this paper.\nIn addition, authors should discuss about a paper for Learning-based rotation-equivaraint keypoint detectior [1]. \n\n[1] Self-Supervised Equivariant Learning for Oriented Keypoint Detection (Lee et al., CVPR 2022)\n\nIn section 3, authors replace the subheadings of sections 3-1. For example, feature extraction should be discussed first, followed by feature fusion, for a more natural flow.\n\nIn section 3-3, authors should add citations to two papers that perform a principle component shift similar to the proposed directional uncertainty weighted descriptor loss function. [2], [3]\n\n[2] Self-supervised Learning of Image Scale and Orientation (Lee et al., BMVC 2021)\n[3] Learning Soft Estimator of Keypoint Scale and Orientation with Probabilistic Covariant Loss (Yan et al., CVPR 2022)\n\nInsufficient explanation of F/T captions: please add sufficient explanations to the captions of Figures 3,4,5, and Tables 1,2,3.\n\nIn section 4, authors should add a separate section for the description of the dataset. For example, in MegaDepth-series, YFCC100M, please explain what the series is separately. \n\nNeeds an ablation study: authors should add information about the performance gain of each component for the multi-scale feature fusion method proposed in the paper, the number of pyramids, and the loss function."
            },
            "questions": {
                "value": "Please see the weaknesses section to address my questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Reviewer_rhbE"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4533/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698646893670,
        "cdate": 1698646893670,
        "tmdate": 1699636430787,
        "mdate": 1699636430787,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "85K06Wol3J",
        "forum": "6tDPefQyvB",
        "replyto": "6tDPefQyvB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4533/Reviewer_FmdE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4533/Reviewer_FmdE"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new learning based local descriptors, which restorts to position ecodings and fuses multi-level rotation equivariant features.\nThe proposed method can maintain the overall performance of descriptors, while obtaining rotation-equivariance to deal with the large reotation.\nThe experiments show the proposed method improves the performance of keypoint extraction and description."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is generally well-written. The figures illustrate the framework of the proposed method clearly.\n2. The idea to fuse multi-scale feature is reasonable and the multi-head attention is also a reasonable tool to fuse features.\n3. The authors perform experiments to compare the proposed method with most of the mainstream descriptors and achieve the state-of-the-art."
            },
            "weaknesses": {
                "value": "1. The whole framework is a litte complicated. The authors do not explain the necessity of each module clearly, neither perform abation study to show each module's effect.\n2. The efficiency of descriptior extraction is also important for some application, but the authors do not show the running time of the proposed method in the experiments.\n3.In the description of figure2, all \"are fed\" is written as \"are feed\"."
            },
            "questions": {
                "value": "Could the authors compare the running time of the proposed method and other descriptors?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Reviewer_FmdE"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4533/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668075692,
        "cdate": 1698668075692,
        "tmdate": 1699636430705,
        "mdate": 1699636430705,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WOnbTvYVkq",
        "forum": "6tDPefQyvB",
        "replyto": "6tDPefQyvB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4533/Reviewer_QDcf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4533/Reviewer_QDcf"
        ],
        "content": {
            "summary": {
                "value": "This paper studies rotation equivariance for descriptor learning in image matching scenario. They proposed new model and training for learning robust descriptor following the previous work E2CNN with equivariant steerable cnns.\n\nRotation-equivariant feature pyramid (FPN) is used and local rotation-equivariant feature information is captured with a multi-head attention mechanism fusing positional information.\n\nMultiple datasets are compared to show the improvement of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The proposed direction is important in descriptor learning research. Rotation equivariance is not the main stream of the image matching at the moment, but the authors proposed a way through PCA feature direction for learning such losing property via a rotated pair images. I find the idea quite novel.\n\nThe results in Figure 5 shows improvement over some descriptors over severely rotated image pairs. Multiple datasets are studied and compared.\n\nMost real-world dataset shows improvement over the baselines."
            },
            "weaknesses": {
                "value": "Despite I understand the idea behind the rotation equivariance descriptor design, the paper hardly justifies how the performance improves the state-of-the-art.\n\nFor example, the authors claim \"If we were to combine local rotation equivariant descriptors with positional information, it wouldn\u2019t necessarily achieve complete rotational equivariance in theory\" while referring AWDesc Wang et al. (2023), SuperGlue Sarlin et al. (2020), LoFTR Sun et al. (2021) In the experimental section, only AWDesc is truly compared while SuperGlue and LoFTR and the widely accepted baselines nowadays.\n\nThere is no comparison regarding the proposed descriptor improves any classical matcher such as RANSAC variants (e.g. MAGSAC, MAGSAC++, AdaLAM, PROSAC...) or learnable matcher such as SuperGlue, ACNe, or NG-RANSAC.\n\nThere is also no clear discussion nor proof how this improves against dense matching method such as LoFTR.\n\nMany SOTA descriptors are not being directly compared such as Superpoint, D2-Net, R2D2, ...\n\nI am also very surprised to see the proposed method is losing to 2011 methods such as BRISK in Table.1.\n\nSome results are positive, but they are not enough to complete the claim of how this rotation equivariant complement the weakness of 1) SOTA descriptors, and 2) modern matcher research which is the main research domain of the community.\n\nMinor:\n\nSome pictures and descriptions are not clear enough. (e.g. Fig.1)"
            },
            "questions": {
                "value": "I do like the direction and effort, if the author can clarify how their work achieve or improve the above weakness I mentioned I would be happy to see the rating go higher.\n\n1. Why the proposed method is weaker than most of 2011-2012 methods in Table.1 if you really solve the rotation equivariance problem? I found the discussion of planar dataset is not acceptable.  \n2. How exactly does this descriptor learning being used with modern matchers (classical, deep learning)?\n3. How does this method relates to the popular dense matching and why is it better in a certain way?\n4. Show me some actual results to prove the above points rather than just arguments would be the strongest case, but that also requires the authors basically rewriting the whole experimental section. Therefore, I am leaning towards to reject this paper but encouraging the authors to complete the full thing before re-submission."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concerns"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4533/Reviewer_QDcf"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4533/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698787120112,
        "cdate": 1698787120112,
        "tmdate": 1699636430624,
        "mdate": 1699636430624,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9dApqpGAb7",
        "forum": "6tDPefQyvB",
        "replyto": "6tDPefQyvB",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4533/Reviewer_JePm"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4533/Reviewer_JePm"
        ],
        "content": {
            "summary": {
                "value": "This paper describes an improvement on typical ML descriptors by 1) replacing canonical convolution with group equivariant version in feature extraction, and 2) feeding extra positional information to local descriptor extraction. Performance improvement are presented on three common local detection/descriptor benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper combines two already explored ideas, namely rotation equivariant local descriptor and global position embedding, and fused them together into a seemingly more powerful detection and description solution. Results from 3 benchmarks are aligned and suggest that the final solution indeed captures beneficial information than baselines, that results to better matching and estimation in the end."
            },
            "weaknesses": {
                "value": "The two major comments are:\n- lack of ablation and analysis. The paper introduces two major improvements to existing local descriptor extraction algorithm, however it's surprising to not seeing a ablation on the delta introduced by each change. Especially since there are already baseline methods using group equivariance convolution as well, it could easily lead readers to think the extra improvement is coming from global positional embedding, which arguably could be injected not as part of local descriptor, but during the matching process. There's no doubt that doing a through ablation requires more work, but for this type of paper where multiple features are introduced, it will be extremely valuable to cover that.\n- presentation. Try to focus more on the main contribution of the paper (with more text / figures). The current version contains a lot of introduction level content, e.g., on what is feature pyramid network / what is multi-head attention, which is OK when publishing to general audience that are not working on Computer Vision field, but could be redundant (and diminishing YOUR contribution) as a ICLR submission. Besides, there are some typo and grammar fixes worthy of doing."
            },
            "questions": {
                "value": "As mentioned above, an ablation on the two major features introduced in this paper on some example dataset, and keep the content more focused (so you have some room for ablation as well)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4533/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698806182047,
        "cdate": 1698806182047,
        "tmdate": 1699636430507,
        "mdate": 1699636430507,
        "license": "CC BY 4.0",
        "version": 2
    }
]