[
    {
        "id": "c95U0CRyJ4",
        "forum": "BCRZq5nNZu",
        "replyto": "BCRZq5nNZu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1443/Reviewer_BU9q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1443/Reviewer_BU9q"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces and explores continual learning setting referred to as \"chunking.\" In this scenario, the learner is exposed to data segments, each derived from the same distribution. The research also imposes a constraint on these data chunks, ensuring that each class  is represented by an equal number of instances in each chunk, thereby examining the impact of restricted data availability. Experiments conducted on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate that, in the context of chunking, most methods perform comparably to standard SGD. Furthermore, the paper suggests a technique called weight averaging, which involves averaging the weights learned at the conclusion of each data chunk."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper introduces a novel continual learning (CL) scenario termed \"chunking,\" revealing that in this setting, most techniques exhibit behavior akin to standard SGD. This finding is likely to intrigue the CL community. \n- The paper suggested method of weight averaging, inspired by the linear case, is both straightforward and insightful, aiding in comprehending its practical application. \n- In terms of clarity, the paper is well-structured, and easy to read. \n- Regarding reproducibility, the supplementary materials of the paper include code developed on top of the DER++ framework, enhancing the ease with which future research can replicate these findings."
            },
            "weaknesses": {
                "value": "- **Unclear motivation and assumptions:** The central motivation surrounding the exploration of limited data availability for CL might benefit from a bit more clarification. Although the paper aims to explore the impact of limited data on CL, the assumptions introduced for 'chunking' in the continual learning framework seem to diverge significantly from practical real-world scenarios. For instance:\n   - Assuming data in each chunk are identically distributed negates the occurrence of distribution shifts. In scenarios lacking such shifts and with sufficiently large chunk sizes, performance degradation may be minimal. This could make comparing different methodologies highly sensitive to the chosen chunk size, complicating reproducibility for subsequent research.\n  - The constraint that each chunk must contain an approximately equal number of instances for each class is often unrealistic. In real-world scenarios, new categories often emerge over time, and it\u2019s impractical to anticipate equal representation of all classes. Although class imbalance is evaluated in Appendix B, the experimental settings for the imbalance settings is not well articulated.\n- **Lack of Distinction from Task-Free Continual Learning:** The paper compares its approach with online continual learning but fails to adequately differentiate it from task-free continual learning approaches [1-4], which do not assume explicit task boundaries. In many situations, identifying shifts in tasks is more critical than defining boundaries for model updating.\n- **Weight Averaging**: The method of averaging weights upon the completion of each chunk or task closely resembles existing strategies used in both offline training and online federated learning, raising questions about its innovative aspect. Additionally, this technique presupposes the availability of parameters from all chunks, a condition that might not always be feasible in practical scenarios. Despite this, the paper does not include a comparison with architectural-based continual learning methods (references [5-7]), which is essential to position the performance of this method to methods that make similar assumptions.\n- **Comparison with recent methods.** Referencing DER++ as the state-of-the-art method does not align with recent advancements. Comparisons with newer models like GMED (Jin et al., 2021), and CLS-ER (Arani et al., 2022) would be more relevant, considering their similar experimental contexts. Additionally, the paper mentions about the impossibility of resampling data or chunks, but lacks a discussion and incorporation of data-free CL methods [8-10] in the existing literature.\n- **Additional minor recommendations.**\n    - Table 1 could be improved by including data on smaller memory sizes and adding metrics on forgetting. Additionally, it is essential to have the comparison between different settings in Table 1 for multiple CL methods.\n    - Figures should have larger font sizes for enhanced readability.\n    - In Section 4.2, the symbols $m,V$ require clear definitions for better comprehension.\n\n**References.**   \n[1] Aljundi et al., Task-Free Continual Learning. CVPR 2019.  \n[2] Aljundi et al., Gradient Based Sample Selection for Online Continual Learning. NeurIPS 2019.   \n[3] Wang et al., Improving Task-free Continual Learning by Distributionally Robust Memory Evolution. ICML 2022.  \n[4] Ye et al., Task-Free Continual Learning via Online Discrepancy Distance Learning. NeurIPS 2022.  \n[5] Rusu et al., Progressive Neural Networks.   \n[6] Yoon et al., Lifelong Learning with Dynamically Expandable Networks. ICLR 2018.   \n[7] Li et al., Learn to grow: A continual structure learning framework for overcoming catastrophic forgetting. ICML 2019.  \n[8] Li et al., Learning without Forgetting. ECCV 2016.  \n[9] Zenke et al., Continual learning through synaptic intelligence. ICML 2017.  \n[10] Madaan et al., Heterogeneous Continual Learning. CVPR 2022."
            },
            "questions": {
                "value": "Kindly refer to the concerns raised in the above section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1443/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698446797454,
        "cdate": 1698446797454,
        "tmdate": 1699636072934,
        "mdate": 1699636072934,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "m7jAlaNM5d",
        "forum": "BCRZq5nNZu",
        "replyto": "BCRZq5nNZu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1443/Reviewer_4UBT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1443/Reviewer_4UBT"
        ],
        "content": {
            "summary": {
                "value": "The paper considers a setting of continual learning called \"chunking\".\n\nThe paper argues that chunking is an important setting and overlooked by prior work. \n\nThe paper presents experimental analysis and a weight-averaging method for the chunking setting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Omitted"
            },
            "weaknesses": {
                "value": "The paper has several weaknesses:\n- First, it does not seem to be a solid work. What the paper does is essentially as follows:\n   - Take the CL library *Mommoth*. \n   - Run all methods there in the specific setting of chunking. In my eyes this would require only a minor modification to load the data in a different way.\n   - Propose a method that can be implemented in a few lines.\n\n- The chunking setting is questionable:\n   - First, in Figure 1, I didn't see a difference between the so-called chunking setting and domain-incremental learning, where the change of task is only indicated by the change of data. In the language of chunking, each chunk is a task in domain-incremental learning.\n   - The paper argues that there is no task shift in chunking (while domain-incremental learning assumes a task shift like rotation or permutation of the original data). However, I didn't find this argument convincing, as task shift is hard to measure. For example, I am not sure which of the following has a larger task shift: 1. from digit 1 to digit 4 (chunking); 2. from digit 1 to a rotated digit 1 (domain-incremental learning).\n   - In summary, the notation of chunking appears to be a word game and I couldn't see the significance on its own or difference from prior works.\n\nBased on the above understanding, I don't find the experiments of interest. I consider chunking to be an instance of domain-incremental learning, and the experimental results are natural consequences of domain shift and the specific training setups. In particular:\n- In Figure 2, I am surprised to see that the chunk size is reduced from $>10^4$ to $10^2$, while the paper trains it for 50 epochs all the time. In other words, the model is given $10^2$ samples for each task, and trained for $50$ epochs. I think this would easily lead to overfitting and It would only be surprising if it does not forget the previous knowledge. Moreover, for the chunk size of $10^2$ I am not sure how large the test set is. I would guess the corresponding test set has much fewer samples, and therefore, it is easily biased rather than being representative on the performance over the entire distribution.\n- What distinguishes SGD and other (memory-based) CL methods is the memory buffer size. However, the paper does not seem to evaluate the effect of memory sizes. I would argue that for larger memory sizes, the performance difference between SGD and CL methods would appear. Therefore, in my eyes, what the paper shows is that, for small chunk sizes (or \"equivalently\" for increasingly many tasks and fewer samples per task), the current CL methods are less powerful, and would require more memory to resist forgetting. And if my reasoning is correct, this paper would be very incremental and would contribute in a very limited way.\n\nFinally, The performance on Cifar100 and Tiny ImageNet in Table 2 does not look good. For example, the table presents an accuracy of 5.48 for DER++, and the weight averaging improves this to 8.53. The accuracy is still smaller than 10%. Can we claim weight averaging gives a victory? From this table, I can only reason that none of the methods works in the proposed setting, including weight averaging."
            },
            "questions": {
                "value": "I have no questions."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1443/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698585045991,
        "cdate": 1698585045991,
        "tmdate": 1699636072849,
        "mdate": 1699636072849,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "x5qmCFNTz6",
        "forum": "BCRZq5nNZu",
        "replyto": "BCRZq5nNZu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1443/Reviewer_w2jf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1443/Reviewer_w2jf"
        ],
        "content": {
            "summary": {
                "value": "The paper presents an analysis of the 'chunking' sub-problem in continuous learning (CL), a problem that has received limited attention in the existing literature. The authors argue that chunking is responsible for a significant part of the performance drop during CL, and forgetting is responsible for the performance drop in chunking. They also demonstrate that existing CL algorithms are ineffective for the forgetting in chunking. Leveraging insights from linear models, the authors propose a per-chunk weight averaging method, which significantly improves performance in a chunking scenario and remains effective in the full CL setting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper tackles a relatively overlooked problem in the continue learning literature - the 'chunking' problem. The chunking problem is a separate problem and different from the distribution shift problem typically assumed in most continue learning literature. Furthermore, chunking exists in all continue learning and online learning settings, therefore deficiencies caused by chunking could affect all such scenarios. This means that a better understanding of the chunking problem could have wide implications for continual learning and relevant problems. \n\nThis work identifies a significant deficiency in learning caused by chunking the data alone. The authors challenge conventional wisdom that forgetting is mainly caused by distribution shifts. The analysis presented in the paper provides valuable insights into the chunking problem, and potentially draws attention to developing different kinds of effective algorithms beyond the usual distribution shift paradigm.\n\nThe proposed per-chunk weight averaging is simple and effective, well-supported with empirical evidence."
            },
            "weaknesses": {
                "value": "* One of the paper's main conclusions \"forgetting is the main reason for performance drop in chunking setting\" is not logically supported by evidence. The authors observed forgetting on the training set in Figure 5 and a performance drop on the test in Figure 2, and claim that forgetting (on the training set) leads to a performance drop (on the test set), which does not appear to have a causal relationship. \n\n  It is shown in Figure 5 that there is significant forgetting of the overfitting features on previous training chunks, but it is not clear whether the learned generalizable features are forgotten (previous chunk accuracy never dips below test accuracy). Learning overfitting features is not causal for generalization performance, as one can often train good-performing models with little overfitting by adjusting hyperparameters and/or using regularization. Therefore, forgetting of overfitting features is also not causal for losing generalization performance.\n\n  There is a simple explanation of the observed forgetting on past chunks: overfitting features are, by definition, unique to a specific combination of training examples, so overfitting features learned in one chunk are not experienced again in subsequent chunks, leading to their forgetting. Generalizing features, however, are repeatedly experienced in multiple chunks and should manifest much lower forgetting (at least in theory). Ultimately, we are concerned about the forgetting of generalizing features rather than overfitting features, as the former determines the final generalization performance.\n\n* The proposed weight averaging method already exists in the CL literature, as the Incremental Moment Matching method proposed in [1]. The Mean-IMM method in [1] is essentially weight averaging, and significant performance improvement is reported when applied to CL tasks. In light of [1], it is probably safer to say \"most popular CL algorithms ... only performing as well as SGD\" rather than \"current CL algorithms\" in the abstract of the current paper.\n\n  [1] Lee, Sang-Woo, et al. \"Overcoming catastrophic forgetting by incremental moment matching.\" *Advances in neural information processing systems* 30 (2017)."
            },
            "questions": {
                "value": "* How would the Adam optimizer perform compared to plain SGD? If the moment estimations of Adam optimizer persist across chunks, maybe it could have a similar smoothing effect similar to weight averaging.\n* Epoch numbers and learning rates are set to the same for different chunk sizes: I personally don't think that this is a very fair setting as the author believes. When training many epochs on a small chunk, the model will see the same examples more frequently and with shorter intervals, which could lead to more severe overfitting and negatively impact generalization. I would suggest finding optimal hyperparameters separately for different chunk sizes (maybe divide all chunk sizes into several ranges and find one set of hyperparameters for each range).\n* In my opinion (offering to the authors for pure discussion), the chunking problem may not be so different from a distribution shift, at least for small chunk sizes. With smaller chunks, the difference in the chunks' examples statistics will increase, even if examples are all sampled from the same distribution. For example, when the chunk size is small, some chunks will inevitably happen to have more images with indoor backgrounds, and some happen to have more outdoor backgrounds. This could be impossible to tell from true distribution change, and the model could still struggle with the changing examples statistics."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1443/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1443/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1443/Reviewer_w2jf"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1443/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698672588396,
        "cdate": 1698672588396,
        "tmdate": 1699636072774,
        "mdate": 1699636072774,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RqHV8zOmOJ",
        "forum": "BCRZq5nNZu",
        "replyto": "BCRZq5nNZu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1443/Reviewer_T7s5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1443/Reviewer_T7s5"
        ],
        "content": {
            "summary": {
                "value": "- This work investigates the process of grouping the data in chunks i.e., chunking, in online continual learning (CL) settings where data is encountered as a non-stationary stream and hence past seen data cannot be revisited anymore.\n- In doing so, the authors demonstrate that the chunking is responsible for almost half of the performance drop due to catastrophic forgetting which has mainly been associated with the drift in data distribution in recent CL literature.\n- Extensive experimental analysis of chunking in online CL settings shows that: (a) forgetting reduces as chunk size increases, (b) forgetting is the main reason for the performance drop, and (c) per-chunk weight averaging improves model performance thus leading to less forgetting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Originality\n\t- The authors have presented the analysis of online CL settings from the novel perspective of data grouping i.e., chunking. Additionally, a simple method of \"per-chunk weight averaging\" has been proposed that minimizes forgetting of the previously seen chunks by averaging the weights after training is finished for each chunk.\n- Quality\n\t- The motivation is well-founded.\n- Clarity\n\t- Paper is clearly presented.\n\t- Mathematical formulation is detailed and explanatory.\n- Significance\n\t- The proposed \"per-chunk weight averaging\" (WA) method significantly outperforms the baseline methods, which demonstrates the efficacy of this method in improving performance by retaining past knowledge and minimizing forgetting."
            },
            "weaknesses": {
                "value": "- Originality\n\t- Contributions are incremental and novelty is limited.\n- Quality\n\t- [Page-1, Section-1, Para-3] When a model sequentially learns over a sequence of datasets (in this case chunks) without having the measures of retaining the past knowledge it tends to forget the past learning as evident in the CL literature in both cases of homogeneous and heterogeneous data (chunk) distributions. Therefore, it is expected that the model performance will drop in such cases, hence the second claim is a valid expectation in such a setting and does not constitute a significant outcome of the analysis.\n\t- In practical scenarios where task boundaries are not pre-known or specified, per-chunk weight averaging could easily worsen the model performance as averaging is done without consideration of the current chunk's domain/distribution as compared to the past chunks.\n\t- Per-chunk weight averaging can be seen as the simplest form of knowledge aggregation technique in a continual learning setting. Hence, it reduces forgetting in the ideal (class-balanced) scenario which is the usual expectation from such techniques and does not constitute high significance as more sophisticated methods have already been developed in CL literature like weight regularization, data replay and incorporating additional parameters.\n\t- The chunking setting described in the papers is ideal and data for such settings is also generated under simplified and impractical assumptions which will not scale to the online settings with changing data distributions in real-world scenarios.\n\t- I am keen to hear the response of the authors on this and hope that they can change my point of view.\n- Clarity\n\t- It is difficult to keep track of the different data preparation techniques for \"offline SGD\", \"standard CL\" and \"chunking\" methods. It would be better to have clear algorithms and/or pictorial illustrations for the same.\n\t- [Page-2, Section-2, Para-2] Please elaborate on the classification problems being referred to here.\n\t- [Figure-2] The Font size is too small, please increase it and also add an explanation of the models shown in the legend (Move them from Appendix A to the Figure caption).\n\t- Inconsistent use of terminologies. Please clarify the following terminologies (maybe in a tabular format) so that the reader can refer to them whenever required:\n\t\t- \"offline learning\"\n\t\t- \"plain SGD learning\"\n\t\t- \"full CL setting\"\n\t\t- \"standard CL\"\n\t\t- \"online CL\"\n- Significance\n\t- [Table-2] As \"per-chunk weight averaging\" strategy involves updating weight parameters. It would make sense to compare it with the existing \"weight regularization\" based CL strategies like the below methods:\n\t\t- [EWC] -> Kirkpatrick, James, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan et al. \"Overcoming catastrophic forgetting in neural networks.\" Proceedings of the national academy of sciences 114, no. 13 (2017): 3521-3526.\n\t\t- [SI] -> Zenke, Friedemann, Ben Poole, and Surya Ganguli. \"Continual learning through synaptic intelligence.\" In International conference on machine learning, pp. 3987-3995. PMLR, 2017.\n- Typographical errors:\n\t- [Page-1, Section-1, Para-1] \"thwart\" -> \"thwarted\", \"focuses CL\" -> \"focuses of CL\"\n\t- [Page-2, Section-2, Para-2] \"called called\" -> \"called\""
            },
            "questions": {
                "value": "- [Page-2, Section-2, Para-2] How does one decide how many chunks (mini-batches) are there in a particular task if there is no pre-defined task boundary in online CL setting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1443/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698994578139,
        "cdate": 1698994578139,
        "tmdate": 1699636072715,
        "mdate": 1699636072715,
        "license": "CC BY 4.0",
        "version": 2
    }
]