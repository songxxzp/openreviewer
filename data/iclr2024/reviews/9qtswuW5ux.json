[
    {
        "id": "ktoxokPBRk",
        "forum": "9qtswuW5ux",
        "replyto": "9qtswuW5ux",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7813/Reviewer_vpKg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7813/Reviewer_vpKg"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses the emergence of graph neural networks (GNNs) as a solution for combinatorial optimization problems. The authors introduce a new algorithm called QRF-GNN, which employs GNNs to efficiently address problems with quadratic unconstrained binary optimization (QUBO) formulations. QRF-GNN employs unsupervised learning and minimizes a loss function derived from QUBO relaxation. Its architecture includes recurrent use of intermediate GNN predictions, parallel convolutional layers, and a combination of artificial node features as input."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well written and well presented. \n\n2. The paper also focuses on an important problem QUBO problems via unsupervised learning (which may have certain benefits)\n\n3. The paper shows experimental evidence that suggests that their method indeed works well."
            },
            "weaknesses": {
                "value": "Please refer to questions."
            },
            "questions": {
                "value": "1. I'm uncertain about the primary contributions of the paper. Are the key contributions limited to the QRF-GNN architecture and the incorporation of random node features combined with pagerank? Or do they also encompass the formulation of the problem as an unsupervised learning approach?\n\n2. If the primary contributions are solely related to the architecture and node features, it's worth noting that while the results appear promising, the method might be viewed as somewhat incremental, especially when compared to existing methods like spectral clustering, which can be considered a basic form of unsupervised learning. In such a case, could you provide insights into any theoretical guarantees, if any exist for your work?\n\n3. I have concerns about the reproducibility of this work, as it appears the authors haven't made the code base available. Additionally, they mention that the method lacks stability. How do you determine the best run under these circumstances?\n\nAs it stands, I am inclined to recommend rejecting this paper. However, since I am not an expert in this field, I am open to revising my evaluation if the authors address these questions or if other reviewers support the work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7813/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7813/Reviewer_vpKg",
                    "ICLR.cc/2024/Conference/Submission7813/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7813/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698151632214,
        "cdate": 1698151632214,
        "tmdate": 1700670954184,
        "mdate": 1700670954184,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0upWXyYbgL",
        "forum": "9qtswuW5ux",
        "replyto": "9qtswuW5ux",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7813/Reviewer_Nnir"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7813/Reviewer_Nnir"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce QRF-GNN to efficiently solve problems that have a quadratic unconstrained binary optimization (QUBO) formulation.\nThe relaxed QUBO objective can be used to perform unsupervised learning for the GNNs. \n\nFurther the GNN can be applied repeatedly by including the output probabilities from the previous round as node features in the next round."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The method is simple - relax the QUBO formulation with probability predictions and then use these to augment the node features in the next GNN step. Finally repeat until convergence.\n\nFor the loss simply minimize (or maximize) the QUBO formulation itself wrt the parameters.\n\nTo the best of my knowledge, this is the first time a QUBO probelm has been solved like this.\n\nThe results are competitive against other benchmarks algorithms to solve max cut and coloring problems."
            },
            "weaknesses": {
                "value": "Minor nit - The authors could have elaborated a little on the QUBO formulation and the training details before section 3."
            },
            "questions": {
                "value": "Did you'll try to solve QUBO problems other than max cut and coloring?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7813/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698729249346,
        "cdate": 1698729249346,
        "tmdate": 1699636956347,
        "mdate": 1699636956347,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Olm6BdndSI",
        "forum": "9qtswuW5ux",
        "replyto": "9qtswuW5ux",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7813/Reviewer_VZaD"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7813/Reviewer_VZaD"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an unsupervised QRF-GNN method for solving CO problems, characterized by two fundamental attributes: the general quadratic unconstrained binary optimization (QUBO) formulation and its recurrent design. Built upon the QUBO formulation, the proposed method compromises various CO problems including the maximum cut problem and graph coloring problem. Compared to the previous baseline PI-GNN, the main improvements lie in the refinement of the message-passing paradigm within graph neural networks, including introducing the recurrent feature, artificial input features, and parallel graph convolutional layers. Empirical results show that the proposed method outperforms existing unsupervised learning methods and is competitive with conventional heuristics."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.The empirical results show advantages over previous methods built on QUBO formulation and are competitive with conventional heuristics.\n\n2.The framework provides a general solution to a range of CO problems, though this property is derived from the existing QUBO formulation."
            },
            "weaknesses": {
                "value": "1.The novelty appears to be somewhat limited. It builds upon the foundation laid by PI-GNN [1], inheriting similarities in terms of problem formulation and experimental design. The primary enhancements are centered around the refinement of the message-passing mechanism within the graph neural networks. Moreover, the key characteristics of the proposed QRF-GNN, i.e., the unsupervised approach based on QUBO and the recurrent design, have previously been explored in methods like PI-GNN and RUN-CSP [2]. The methodological innovations do not appear compelling enough to warrant my vote for acceptance.\n\n2.The rationale behind certain design choices remains unclear. Questions arise regarding the decision to incorporate the recurrent feature, artificial input features, and parallel graph convolutional layers in lieu of the raw GNN. If the objective is to enhance representation capacity, why not consider a more advanced GNN or GraphFormer design? It is also necessary to establish the relationship between these design choices and their relevance to CO problems.\n\n3.The evaluation presented in this paper does not convincingly demonstrate QRF-GNN's superiority over heuristic methods. In PI-GNN, Fig. 4 and 5 show its advantages in scalability and computational complexity. Yet these properties are not well verified in this paper.\n\n[1] Combinatorial Optimization with Physics-Inspired Graph Neural Networks. Nature Machine Intelligence 2022.\n\n[2] Graph neural networks for maximum constraint satisfaction. Frontiers in Artificial Intelligence 2021."
            },
            "questions": {
                "value": "1.Why are recurrent features important for solving CO problems?\n\n2.Since the methodology mainly focuses on the design of the graph networks, have you tried other advanced GNNs or GraphFormers in hand for better performance of this formulation?\n\n3.In Table. 5, why is QRF-GNN more efficient than PI-GNN [1] while the main algorithm pipelines seem similar? It probably comes from the setting of PI-GNN in experiments: \"In order to obtain the results of PI-GNN, the authors applied hyperparameter optimization for each graph.\" However, in my understanding, hyperparameter optimization is not a mandatory request of PI-GNN. It is worth investigating the performance of PI-GNN under the same conditions as QRF-GNN to determine if there is still a speed advantage.\n\n4.In Section 5, the statement mentions, \"...considering that most of the mentioned methods are specialized for solving specific problems...\". In fact, many methods try to propose a general solving framework for solving broad CO problems, such as [2] [3] [4]. Additionally, solving algorithms for NP-complete (NPC) problems inherently possess the potential to solve other CO problems since any NP problem can be reduced to an NPC problem.\n\n[1] Combinatorial Optimization with Physics-Inspired Graph Neural Networks. Nature Machine Intelligence 2022.\n\n[2] Revisiting Sampling for Combinatorial Optimization. ICML 2023.\n\n[3] DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization. NeurIPS 2023.\n\n[4] From Distribution Learning in Training to Gradient Search in Testing for Combinatorial Optimization. NeurIPS 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concerns."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7813/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7813/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7813/Reviewer_VZaD"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7813/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698744670300,
        "cdate": 1698744670300,
        "tmdate": 1699636956242,
        "mdate": 1699636956242,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GMmzOpF9pp",
        "forum": "9qtswuW5ux",
        "replyto": "9qtswuW5ux",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7813/Reviewer_oXir"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7813/Reviewer_oXir"
        ],
        "content": {
            "summary": {
                "value": "This paper leverages the GNNs to solve the quadratic unconstrained binary optimization problems, especially for the maximum cut and graph coloring problems.  Experimental results demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Using Neural Networks to solve combinatorial optimization problems is an interesting topic.\n2. The proposed QRF-GNN can outperform existing GNNs in solving Max-Cut and graph coloring problems.\n3. The paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "1. The paper's novelty appears constrained, utilizing a GNN with QUBO's continuous relaxation as a loss function for combinatorial optimization. Clarification on how this differs from prior work would be beneficial.\n\n2. The motivation behind the specific design of the GNN, particularly the use of two different convolutional layers (SAGEConv Pool and SAGEConv mean) in the first layer, is not explained. A rationale for these choices should be provided.\n\n3. An ablation study is needed to substantiate the proposed GNN's superiority over existing methods. Without this, the advantage of the proposed model remains unclear."
            },
            "questions": {
                "value": "Please refer to the weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7813/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7813/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7813/Reviewer_oXir"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7813/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699474608405,
        "cdate": 1699474608405,
        "tmdate": 1699636956131,
        "mdate": 1699636956131,
        "license": "CC BY 4.0",
        "version": 2
    }
]