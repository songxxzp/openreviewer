[
    {
        "id": "NivLwTO0AD",
        "forum": "NZtF0um8S7",
        "replyto": "NZtF0um8S7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3152/Reviewer_SaZz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3152/Reviewer_SaZz"
        ],
        "content": {
            "summary": {
                "value": "This paper explores the potential of Seq2Seq models as robust few-shot learners. A few studies have demonstrated the feasibility of few-shot learning with seq2seq models; however, this has been limited to tasks that align well with the seq2seq architecture, such as summarization and translation. The paper proposes two methods to more effectively elicit in-context learning ability in seq2seq models: objective-aligned prompting and a fusion-based approach. Remarkably, the approach outperforms a decoder-only\nmodel that is six times larger and exhibits significant performance improvements compared to conventional seq2seq models across a variety of settings."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper is well-written regarding the language and organization.\n2. The experimental evaluation validates their claims.\n3.  The paper performs few-shot learning on a variety of tasks, indicating that the seq-to-seq model can have certain advantages, which is indeed a contribution.\n4. Their analysis in the experimental parts is comprehensive."
            },
            "weaknesses": {
                "value": "1. The paper might want to explain a bit more about the specific tasks of few-shot learning.\n2. The paper should explain why the seq-to-seq model is powerful in related tasks, from a machine-learning perspective.\n3. Similarity, the paper might want to analyze in-depth why early fusion sometimes yields better performance than late fusion, from a machine-learning perspective."
            },
            "questions": {
                "value": "No other question, but the model proposed seems too simple. However, the experimental analysis and finding is nontrivial."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3152/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3152/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3152/Reviewer_SaZz"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3152/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698747238125,
        "cdate": 1698747238125,
        "tmdate": 1699636262926,
        "mdate": 1699636262926,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "JHEEWptyeS",
        "forum": "NZtF0um8S7",
        "replyto": "NZtF0um8S7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3152/Reviewer_aYaC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3152/Reviewer_aYaC"
        ],
        "content": {
            "summary": {
                "value": "An extensive evaluation of zero-shot to few-shot performance of seq2seq models across a wide range of evaluation set is presented. The authors make a case for strong seq2seq model performance for generation and understanding tasks when compared to decoder only models."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The primary strength of this works seems to come from experimentally demonstrating that the seq2seq model can outperform the decoder-only model with 6 times larger parameters across diverse datasets."
            },
            "weaknesses": {
                "value": "Would've liked to see some evaluations around more varied generative tasks like Math/Coding which are more practically useful."
            },
            "questions": {
                "value": "Are there any tasks where the seq2seq few shot performance was inferior to decoder only models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3152/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3152/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3152/Reviewer_aYaC"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3152/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809003065,
        "cdate": 1698809003065,
        "tmdate": 1699636262855,
        "mdate": 1699636262855,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "CXLFBMHk1N",
        "forum": "NZtF0um8S7",
        "replyto": "NZtF0um8S7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3152/Reviewer_6VXy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3152/Reviewer_6VXy"
        ],
        "content": {
            "summary": {
                "value": "This paper pays attention to the in-context few-shot learning capabilities of seq2seq models. Specifically, this paper conducts comprehensive experiments with an in-context evaluation toolkit to investigate the performance of seq2seq models in few-shot scenarios. In addition, an objective-aligned prompting strategy and a fusion-based approach are proposed. Through extensive experiments, some interesting conclusions are also obtained."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.\tThis paper is well organized and easy to follow. \n2.\tThe motivation is reasonable and experiments are abundant.\n3.\tThe findings and conclusions about in-context few-shot learning capabilities of seq2seq models will be interesting to the community."
            },
            "weaknesses": {
                "value": "Several main concerns are as follows:\n\n1.\tThis paper claims that the objective-aligned prompting strategy is its one key contribution. However, this strategy seems to be very straightforward and some recent state-of-the-art works have already introduced such a strategy. In this sense, this contribution is somewhat limited.\n\n2.\tThe second contribution of this work is a fusion-based approach, which also comes from the existing works, such as RAG and Fid. Therefore, what\u2019s the main difference and contribution of this work? In addition, in the abstract, the sentence \u201cour approach outperforms a decoder-only model that is six times larger\u2026\u201d shows that the proposed models will be much larger than the competitors. Is it not a significant limitation? \n\n3.\tCan we consider the proposed fusion-based approach as a simple ensemble strategy? If so, the authors may need to explain more for this part.\n\n4.\tAre there any evidences to support the hypothesis in the sentence of \u201cWe hypothesize that the encoding of relations between demonstrations does not significantly impact in-context learning performance.\u201d?"
            },
            "questions": {
                "value": "Please kindly refer to the above comments."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3152/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698845173879,
        "cdate": 1698845173879,
        "tmdate": 1699636262779,
        "mdate": 1699636262779,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RfBA6Ym1Gr",
        "forum": "NZtF0um8S7",
        "replyto": "NZtF0um8S7",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3152/Reviewer_6fMx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3152/Reviewer_6fMx"
        ],
        "content": {
            "summary": {
                "value": "This paper performs a first-ever extensive experiment comparing the in-context few- shot learning capabilities of decoder-only and encoder-decoder (seq2seq) models on a broad range of tasks. The authors further propose two methods to more effectively elicit in-context learning ability in seq2seq models: objective-aligned prompting and a fusion-based approach. They show their methods significantly outperform decoder-only models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ This work develops an in-context evaluation toolkit for seq2seq models and conduct extensive experiments to investigate the performance of seq2seq models in zero-shot to few-shot scenarios.\n\n+ The author explore prompting strategies and fusion-based approaches in encoder-decoder models, which reveals their ability of zero/few-shot learning.\n\n+ The comprehensive experiments of comparison between decoder-only and encoder-decoder models could be very useful for researchers in this field."
            },
            "weaknesses": {
                "value": "- The technical novelty of this work is a bit weak. The proposed objective-aligned prompting and fusion-based approach are straightforward.\n\n- The detailed description of the objective-aligned prompting method is missing."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3152/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699068803873,
        "cdate": 1699068803873,
        "tmdate": 1699636262716,
        "mdate": 1699636262716,
        "license": "CC BY 4.0",
        "version": 2
    }
]