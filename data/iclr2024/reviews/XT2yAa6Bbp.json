[
    {
        "id": "ioeOYJt8cA",
        "forum": "XT2yAa6Bbp",
        "replyto": "XT2yAa6Bbp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7406/Reviewer_151F"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7406/Reviewer_151F"
        ],
        "content": {
            "summary": {
                "value": "This paper presents an approach for performing semi-supervised semantic image segmentation. The method utilizes Sinkhorn Output Perturbations in the prediction space to further utilize and improve the quality of pseudo labels. The author pointed out that there are few prior works that have explored perturbation strategies for the prediction space, and thus proposes a new perturbation method, dubbed Sinkhorn Output Perturbations."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper is easy to follow and well-structured, altough there are some typos. This paper proposes an interesting research topic, make a perturbed prediction based on suggested softmax-mining, beta interpolation and input patching. The results show somehow improved performance in some experiment settings."
            },
            "weaknesses": {
                "value": "-Lack of justification for the perturbation method.\n    Many perturbation methods widely used in semi-supervised learning (e.g., cut-mix) have strong motivation and have been proven for their usage; they can create powerful yet effective augmented images that can leverage unlabeled data. However, the proposed perturbation method, especially in the output space, lacks a concrete rationale for its usage. Why is this type of perturbation needed? As described in the paper, the author claims that it can guide the parameter update away from amplifying the current signal. However, as also described in the method section, the augmentation method strongly depends on the \"current status\" of the model, which leads to contradictory arguments.\n\n-Lack of performance improvement.\n    The output of unlabeled data is augmented by the proposed method and then used as pseudo-labels for self-training. However, the proposed method fails to demonstrate its effectiveness in the PASCAL-VOC setting. It cannot achieve state-of-the-art performance in at least one experimental setting (Table 2). It does achieve comparable results in the Cityscapes setting but fails to exhibit its versatility in the PASCAL-VOC setting.\n\n- Lack of additional experiments.\n    As mentioned earlier, the ultimate goal of the perturbation method is to generate another version of pseudo-labels from unlabeled data. Are the generated augmented pseudo-labels more accurate than the original ones? The author should have presented their quantitative results."
            },
            "questions": {
                "value": "Please address my concerns. And there are few typos in the paper (e.g., citation in the introduction section)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Reviewer_151F"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7406/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698585506328,
        "cdate": 1698585506328,
        "tmdate": 1699636887911,
        "mdate": 1699636887911,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QWh8hY6wym",
        "forum": "XT2yAa6Bbp",
        "replyto": "XT2yAa6Bbp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7406/Reviewer_dzt9"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7406/Reviewer_dzt9"
        ],
        "content": {
            "summary": {
                "value": "This paper targets semi-supervised semantic segmentation. It proposes Sinkhorn Output Perturbations, which adds structured pseudo label noise to the training procedure. The proposed method can be seamlessly plugged into existing methods. Experiment results prove the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method is orthogonal to existing methods. \n2. Overall the paper is well-written and easy to follow."
            },
            "weaknesses": {
                "value": "1. The related work section is a little bit concise. You can have more discussions on related works in revision. \n2. The novelty of the proposed method is a little bit limited to me, though the performance is convincing and the method is practical. Could you have more explanations on the novelty of your method?"
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Reviewer_dzt9"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7406/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698914085928,
        "cdate": 1698914085928,
        "tmdate": 1699636887812,
        "mdate": 1699636887812,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cHau8r1vg3",
        "forum": "XT2yAa6Bbp",
        "replyto": "XT2yAa6Bbp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7406/Reviewer_XPw6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7406/Reviewer_XPw6"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the teacher-student scheme in semi-supervised segmentation. It goes beyond input and feature perturbations and introduces Sinkhorn Output Perturbations to add structured pseudo-label noise to the training. Sinkhorn output perturbations can serve as a plugin to be integrated into any segmentation model. The proposed method achieves SoTA on Cityscapes and competitive performance on Pascal VOC 2012."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Most papers consider perturbations in inputs and feature levels. This paper introduces output-level perturbations which involve the structural noise of an image. From this perspective, it is novel to some extent. \n\n2. The writing is easy to follow. The motivation is clear."
            },
            "weaknesses": {
                "value": "1. The performance is less strong to prove the effectiveness of the proposed method, especially on Pascal VOC 2012. \n\n2. For the idea of introducing global class distribution to perturb local per-pixel predictions, are the local predictions really influenced by the global class (per-image level) distributions? If so, how about maintaining the class relationships based on the whole dataset (i.e., calculate P_{sm} in Eq. 5 based on the whole training set)?"
            },
            "questions": {
                "value": "Please see Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7406/Reviewer_XPw6"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7406/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698930047409,
        "cdate": 1698930047409,
        "tmdate": 1699636887694,
        "mdate": 1699636887694,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RzMcYsfyn5",
        "forum": "XT2yAa6Bbp",
        "replyto": "XT2yAa6Bbp",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7406/Reviewer_tvp8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7406/Reviewer_tvp8"
        ],
        "content": {
            "summary": {
                "value": "1. For the semi-supervised segmentation task, this paper extends the previous strong-weak augmentation methods. Instead of solely augmenting the input or features, this approach augments the output of the teacher model. \n2. The proposed method constructs plausible pseudo-labels by randomly interpolating the one-hot and softmax class distributions. This paper thinks it can soften the inherent limitations of student-teacher methodologies.\n3. The experimental results demonstrate that the proposed approach achieves state-of-the-art (SOTA) results in Cityscapes and slightly lower than SOTA results in Pascal VOC 2012. Additionally, the experiments show that this method can further enhance the performance of Uni-Match."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The authors propose perturbing output instead of input or features, which is an interesting problem. \n2. In the experimental results, their method surpasses other semi-supervised segmentation methods on the Cityscapes dataset, particularly showing significant gains with little data (76.0% vs 75.0%)."
            },
            "weaknesses": {
                "value": "1. The lack of insight and direct evidence for why perturbing the original teacher output can improve model performance, and why adding random noise can also be effective. The authors claim that it can cover possible correct predictions, but they do not provide specific numbers or charts for detailed explanation.\n\n2. Additionally, the description of the ablation experiments is not clear enough, as it does not provide a direct comparison between the results of no output perturbation, random noise, and SOP. As a result, it is hard to understand the actual impact of SOP relative to the model without output perturbation or with random noise."
            },
            "questions": {
                "value": "1. The authors could provide more explanations, either theoretically or experimentally, regarding why adding noise to the output can improve semi supervised model performance. \n2. The authors could explain the reason behind interpolating between one-hot and softmax distribution and why this approach can be effective."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7406/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698935263143,
        "cdate": 1698935263143,
        "tmdate": 1699636887566,
        "mdate": 1699636887566,
        "license": "CC BY 4.0",
        "version": 2
    }
]