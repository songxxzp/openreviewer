[
    {
        "id": "4dMIPLpu7b",
        "forum": "dHdXvu5ehy",
        "replyto": "dHdXvu5ehy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3297/Reviewer_aWFU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3297/Reviewer_aWFU"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a new technique for efficient substructure counting (ESC) for graph neural networks (GNNs), called ESC-GNN. To this end, the paper deeply explores existing subgraph GNN methods in the literature and establishes expressiveness result linked to the WL hierarchy for these. The paper then shows that using sub-graphs offers an efficiency gain, as the higher-order WL test can run on (induced) sub-graphs, shifting a high polynomial weight to sets of smaller graphs and only keeping a $k^th$ polynomial power over the input graph size related to the number of connected $k-$tuples being considered. \n\nBuilding on this result, the paper describes a structural encoding method for edges in an input graph that occurs at pre-computation: ESC-GNN considers all rooted subgraphs around connected 2-tuples, i.e., edges, and computes a structural encoding using node degree and edge distance information. The paper then shows how this approach, which is substantially more efficient than running an MPNN on each subgraph separately, allows to detect important substructures (4-cycles, 4-cycles, etc.) and how this approach is strictly more powerful than 2-WL (folklore 1-WL), while not being less powerful than 3-WL (folklore 2-WL). Finally, the paper conducts a large set of synthetic experiments to validate the strength of their model, as well as experiments on real-world benchmarks (results on QM9, efficiency on OGBG-hiv, ZINC), demonstrating the speed and good performance of their approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Presenting an efficient pre-computation to mitigate the complexity of sampling and running MPNNs over subgraphs is a well-justified and well-thought contribution. \n\n- The presentation is clear: I particularly enjoyed the running example in Figure 1, as this really helped me follow along with the structure encoding computation. The theoretical results in the background are also well-presented.\n\n- The synthetic experiments show the value of the approach, particularly in light of its efficiency.\n\n- The experimental analysis of QM9 results, particularly on tasks where ESC-GNN performs less well, is thorough."
            },
            "weaknesses": {
                "value": "- The experimental results are not very compelling. In particular, real-world experimental results for QM9 are strong in part, but performance on other tasks is substantially worse. Moreover, results on OGBG-HIV, ZINC (reported in the appendix), which ideally should also be in the main paper given that efficiency is reported on these, are not strong. Just to be clear: it is completely acceptable not to achieve SOTA results across the board, particularly against specialized approaches. However, I do expect some analysis of results (just like in QM9), leading to real-world scenarios where ESC-GNN is a clear and obvious candidate for use and would achieve the best results. This comment also applies to the synthetic experiments. I therefore ask the authors to revisit their experimental section and modify their analysis towards establishing a well-defined use case for their approach.\n\n- The paper's approach to subgraph counting is specialized towards common patterns, and only establishes relatively simple results. This is not a major weakness in itself (and is common in subgraph GNN literature), particularly given the complexity of general (induced) subgraph counting. However, the paper would be more interesting / compelling if it were to discuss more general sub-structure detection (more explicitly than via a connection to k-WL).  To this point, the authors can strengthen the work by conducting case studies on real-world datasets to establish the importance of detecting cycles/paths/cliques. This would nicely complement the existing ablation studies in the appendix, and provide a meaningful explanation of when ESC-GNN is useful. As it stands, a main concern with subgraph GNNs is their over-specialization to pre-defined graph structures, and so any results / experiments to show more general structure detection / strong performance beyond the pre-designed use case, would substantially strengthen this paper.\n\nAll in all, I think this paper has a place in the subgraph GNN literature, as it is well-written and offers an efficient solution for counting (almost) all the same small subgraphs. However, the weaknesses I raise above prevent me from more strongly supporting this work. Nonetheless, I am happy to revise my rating should the authors address my concerns."
            },
            "questions": {
                "value": "No direct questions. Please address the weaknesses / suggestions I provide in the weaknesses section above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3297/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698671263030,
        "cdate": 1698671263030,
        "tmdate": 1699636278661,
        "mdate": 1699636278661,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "IqMc29KdkM",
        "forum": "dHdXvu5ehy",
        "replyto": "dHdXvu5ehy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3297/Reviewer_p2Va"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3297/Reviewer_p2Va"
        ],
        "content": {
            "summary": {
                "value": "The authors study the counting power of those subgraph GNNs that do not exchange information between subgraphs. More precisely, they show that these are expressive in the _graph-level_ counting of connected substructures. They then propose a framework named ESC-GNN that extracts subgraphs to compute distance features within each subgraph, and use them as structural embeddings of the original graph which is then processed through a GNN. Finally, the paper shows theoretical results on the counting power of the proposed framework."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The problem is interesting and the study of the counting powers of WL tests and subgraph GNNs is valuable on its own. The proposed architecture is simple but expressive for the task of substructure counting."
            },
            "weaknesses": {
                "value": "I think the major weakness is that __it seems that the model loses permutation equivariance due to the order of the encodings__ in $s_{uv}$. Specifically, consider the node-level distance encoding: for the subgraph rooted at edge $uv$ we have a distance histogram for $v$ and a distance histogram for $u$. Those two are concatenated (along with the other encodings) in $s_{uv}$. But which of the two distance histograms should be the first in the concatenation (that for $u$ or that for $v$)? If the edge is undirected no ordering should be preferred so choosing according to the node id leads to a choice that is not permutation equivariant. \n\nThe second main weakness is that __Proposition 4.5 does not seem to follow from previous work, and it is not proven in the paper__. I think that the claim on page 5: ``Previous works (Geerts, 2020; Frasca et al., 2022) show that for m \u2265 2 .. a subgraph GNN rooted at k-tuples with backbone GNN as powerful as m-WL can be implemented by (m + k)-IGN.'' is not true. Indeed it was shown only for $k=1$ and $m=2$. Therefore Proposition 4.5 is not immediate. I think it should be related to Proposition 2 in Qian et al 2022, which proves the same for any $k$ and $m=1$."
            },
            "questions": {
                "value": "1. Please expand on the order of the two node-level distance encoding, as well as on Proposition 4.5, as explained in the Weaknesses. \n2. On page 7, the claim ``As shown in Proposition 5.1, ESC-GNN is less powerful than subgraph MPNNs rooted at 2-tuples\" does not seem correct, as according to Proposition 5.1 they can be as powerful as subgraph MPNNs. Please clarify.\n3. Does Theorem 4.4 hold for both induced and non-induced substructures?\n4. The experimental section can be improved:\n\n    a. Why do you focus on node-level tasks? I understand that node-level implies graph-level but the contrary is not true. Since you focus on graph-level tasks in the theoretical part, I don't understand why you test on node-level tasks. Furthermore, I noticed there is an additional counting experiments on ZINC in the appendix, but why is it limited to cycle counting?\n\n    b. The time comparison on ZINC and OGB is presented in the main paper without reporting the results on those datasets in the main paper. Please move the results on these datasets in the main paper. \n\n   c. Why results on ZINC do not include the std or average across seeds? And why do you use a graph transformers? What are the results with a GNN as a backbone model?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3297/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698692403013,
        "cdate": 1698692403013,
        "tmdate": 1699636278590,
        "mdate": 1699636278590,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "bGxIM5nfip",
        "forum": "dHdXvu5ehy",
        "replyto": "dHdXvu5ehy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3297/Reviewer_qaTB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3297/Reviewer_qaTB"
        ],
        "content": {
            "summary": {
                "value": "The authors seek to understand the expressive power of GNNs vis-a-vis counting substructures. Such a study has already been done using subgraph enhanced GNNs. Since existing subgraph-enhanced GNNs are inherently not scalable (they look at all subgraphs of fixed size), the authors seek to circumvent this problem by devising pre-computed structural embeddings which avoid a brute-force aggregation over all subgraphs."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The authors inject hand-crafted structural information about subgraphs (degree encoding, node-level encoding, edge-level distance encoding) into a given graph, which allows a standard GNN on the graph to count small substructures such as 4-cycles, 4-clique and 3-paths. This allows them to avoid doing subgraph enhancement, which is usually expensive because one has to brute-force iterate over all subgraphs."
            },
            "weaknesses": {
                "value": "1. It is not true that all subgraph-enhanced GNNs suffer from scalability issues. Currently, there exist subgraph-enhanced GNNs which do not brute-force search over all subgraphs, instead trying to learn which subgraphs are relevant for enhancement: see Qian (2022). \n\nOf course, sampling may not lead to \"theoretically provable\" counting power, but such theoretical results about counting power have limited relevance since the subgraphs being counted are really small and hence this is mainly a question of practical nature. \n\n2. The results in Table 1 are not strong enough even if one considers the scalability gains due to hand-crafted embeddings. \nThe drop in performance as one goes to 5-cycles and 6-cycles is quite severe, indicating poor generalization.\n\nI am not sure if the paper provides any substantial research with potential for impact, mainly because of the hand-crafted nature of the proposed models based on ad-hoc theoretical arguments which have little value in the general case and are useful only in extremely specific instances (subgraphs of size at most 3 to 4)."
            },
            "questions": {
                "value": "1. Have the authors compared their results to more efficient subgraph-enhancement algorithms such as Qian (2022)? \n\n2. (Section 4.) What are \"globally expressive models\"? \n\n3. In Table 1, the column for \"3-cycles\" has all successful entries less that 0.001. ESC-GNN shows an error of 0.0074, yet it is in the same bracket. Can you explain how the cut-off of 0.01 for MAE was chosen?  \n\n4. \"In conclusion, subgraph GNNs rooted at k-tuples with backbone GNN as powerful as m-WL can reach a similar counting power to (m + k)-WL while being much more efficient.\" What values of k and m do you use for experiments?\n\n5. Section 4.2: \"Subgraph GNNs have long been used to count substructures. Existing works mainly focus on counting certain types of substructures, e.g., walks (You et al., 2021) and cycles (Huang et al., 2023) and do not relate subgraph GNNs with substructure counting in a holistic perspective.\" Does an incremental extension to cliques/paths of size <=4 really make your framework holistic?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3297/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698820135239,
        "cdate": 1698820135239,
        "tmdate": 1699636278510,
        "mdate": 1699636278510,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "s1dSHUa7lF",
        "forum": "dHdXvu5ehy",
        "replyto": "dHdXvu5ehy",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3297/Reviewer_7TFC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3297/Reviewer_7TFC"
        ],
        "content": {
            "summary": {
                "value": "In the first part of the paper the authors generalize subgraph GNNs by allowing the use of higher-order GNNs on rooted subgraphs (so far, classical GNNs were considered on subgraphs). Corresponding theoretical results related to counting subgraphs are listed, these are easy generalizations of known results. In the second part of the paper, which is a bit orthogonal to the first part, a subgraph encoding technique is used to transform a graph into an edge weighted graph, on which a standard GNN is applied. It is shown that thanks to the preprocessing and encoding, more subgraphs can be counted than without this extra information."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The investigation of counting abilities of GNNs is important for understanding their expressive power.\n\n2. The generalisation of subgraph GNNs to those that than can leverage higher-order GNNs is a sensible\nextension from a theoretical point of view.\n\n3. The idea to augment the input graph with information about subgraphs, followed by running a GNN is\na sensible data augmentation technique.\n\n4. Theoretical results complement the proposed method."
            },
            "weaknesses": {
                "value": "1. The bulk of the paper advocates higher-order GNNs but then the proposed method is the application of a standard GNN on an augmented graph? There is a bit of a mismatch between theory and the proposed method.\n\n2. The proposed method seems very related to approach by Bouritsas et al and Barcel\u00f3 et al in which subgraph information is used (isomorphism, homomorphism) alongside classical GNNs.\n\n3. It is unclear what theoretical justifications of the proposed encoding method."
            },
            "questions": {
                "value": "**Q1** Please explain how Section 4 and Section 5 connect to each other. \n\n**Q2** What is the rationale behind the structural encoding presented in section 5. What guarantees does it give? Or other encoding methods possible? (a la molecular finger printing).\n\n**Q3** The proposed method uses handcrafted features (as part of encoding). How does it related to the work by Bouritsas et al in which edges carry counts of subgraphs?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3297/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698828744468,
        "cdate": 1698828744468,
        "tmdate": 1699636278415,
        "mdate": 1699636278415,
        "license": "CC BY 4.0",
        "version": 2
    }
]