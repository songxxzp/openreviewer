[
    {
        "id": "RYHtZ3asnL",
        "forum": "WcSofkUVge",
        "replyto": "WcSofkUVge",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_3FPZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_3FPZ"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a method for adaptive teaching based on utility theory. The authors propose a model in which the teacher's actions are determined by the expected utility of each teaching action. This utility-based framework aims to adapt teaching strategies according to students' needs and progress. The paper also details the model's implementation in a educational setting and provides empirical evidence of its effectiveness."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Integrating utility theory into adaptive teaching is a novel approach.\n2. Beyond estimating a student's skill level, the paper also aims to estimate the learner's internal goal, offering finer-grained teaching.\n3. The paper outlines the model's mathematical foundation, ensuring replicability for other researchers.\n4. The results have potential applications in personalized learning, AI-driven educational platforms, and adaptive curriculum design."
            },
            "weaknesses": {
                "value": "1. The paper's formulation is ambiguous.\n\n    1. The decision to frame the learning task as a POMDP lacks clear justification. While this relates to the proposed method, more concrete examples are needed for justification.\n\n    2. The task formulation for the ToM-teacher isn't clearly presented in the manuscript. From my perspective, the teaching task resembles a POMDP, akin to references [1, 2]. The teacher doesn't fully know the learner's internal state but tries to optimize the student's performance by providing demonstrations. Unlike earlier works, this paper also seeks to estimate the learner's transition function parameters (goals and observation function). Clarifying the task's formulation is crucial for understanding the technical value of the proposed approach, which remains unclear.\n\n2. The paper's objective is unclear. The authors claim, \"The goal of this work is to study whether learner-specific teachers who model the learner\u2019s internal state are more efficient than learner-agnostic ones.\" Given the vague problem definition, it's unclear if this captures the paper's essence. Is the primary takeaway that Bayesian ToM-teachers excel at understanding human internal state changes?\n\n3. The evaluation appears lacking. The paper notes that the teacher has a general idea of the student's policy, and during testing, the student's actions are driven by a basic decision tree. This might mean there's minimal uncertainty in the learner's behavior. It would be beneficial to incorporate human-subject experiments to see real-world impact.\n\n4. Based on points from point 1 and equation 3, the teaching policy is essentially a greedy policy. Over time, this might not be the best strategy and could lead to suboptimal results. Without a well-defined teaching task, such a policy is not well justified.\n\n[1] Srivastava et al., Assistive Teaching of Motor Control Tasks to Humans, 2022.\n\n[2] Yu et al., COACH: Cooperative Robot Teaching, 2022."
            },
            "questions": {
                "value": "see weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3350/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698297738331,
        "cdate": 1698297738331,
        "tmdate": 1699636284929,
        "mdate": 1699636284929,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ynpLfRgM7g",
        "forum": "WcSofkUVge",
        "replyto": "WcSofkUVge",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_PobE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_PobE"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a technique for teaching learners through demonstration based on Bayesian principles.\nIn particular, the teacher maintains a posterior distribution over the unknown internal state of the learner and proposes demonstrations that maximizes the utility (learner performance minus cost of demonstration) under this expectation.\n\nConcretely, we consider the task of teaching learners to navigate in a grid world.\nThe learner is specified by \n    - an unknown observation model (we consider deterministic observation function of three different sizes)\n    - a goal (I believe considered known)\n    - an initial belief (unclear over what exactly but I believe just the initial state distribution)\n    - a handcrafted policy (including A* search algorithm depending on knowledge available to the learner) *given the belief, observation model, and goal*\n\nThe teacher maintains a distribution over the unknowns, which I believe is just the observation model, but slightly different baselines are considered in the experiments too.\nThe task of the teacher is to pick a demonstration (from a set) such that it affects the initial belief of the learner in a way that the learner's reward is optimized (while keeping the demonstration short to avoid high costs)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Modeling other agents, whether biological or artificial, is an important step towards AI methods that can tackle real-world (multi-agent) scenarios and this paper should be interesting to a significant part of ICLR community.\nThe proposed approach, that of Bayesian inference over the internal state of others, is both flexible as well as suitable and seems a reasonable research direction.\n\nIn particular, I believe the core contribution is how to model giving demonstrations as a teacher in the Bayesian setting should/could be done.\nFurthermore, the proposed protocol (what is visible to whom between teacher and learner) is rather interesting and realistic.\n\nTo summarize, I find that this paper tackles a relevant problem with reasonable assumptions in an interesting way."
            },
            "weaknesses": {
                "value": "My main concerns are regarding the presentation and impact.\n\nRegarding presentation, I find the formalization unclear and sometimes misaligned with the literature.\nFor example, the environment is introduced as a POMDP but then formalized (seemingly?) as an MDP (there are no observations?).\nAdditionally, the Bayes-adaptive POMDP is mentioned but then it seems that the uncertainty is limited to the state (is the belief only over the state?), which is not a problem solved by the BA-POMDP at all.\nVarious (important) notions are not defined, including the learner's initial belief, which the teacher is trying to affect, which makes it hard to understand what exactly the demonstrations are accomplishing.\nAnother example is the data observed by the teacher (tau^obs) which does not seem to be defined anywhere.\n\nI also found the story in which the method was introduced hard to follow: it is a linear specification in which each component is discussed one at a time.\nHowever, this is difficult to understand because it is unclear which decisions are problem specific, and which are more general in nature.\nFor example, assuming I correctly understood that the belief of the learner is just the (initial?) state distribution, is this specific to the problem or more generally a property of the method?\nA general-to-concrete story would have made the contribution much clearer, in my opinion.\n\nLastly, as far as I understand, (Bayesian) ToM for teaching learners is not quite novel enough to warrant a publication on its own.\nFor example [1,2] have done similar things, although there exact setup (interaction between learners and teachers) differ.\nHence, I believe the demonstration is a key contribution here, though the lack of clarity of the proposed method makes it hard to accept the paper in its current version.\n\n[1] Celikok, M. M., Murena, P. A., & Kaski, S. (2020). Teaching to learn: sequential teaching of agents with inner states. arXiv preprint arXiv:2009.06227. \n\n[2] Peltola, T., \u00c7elikok, M. M., Daee, P., & Kaski, S. (2019). Machine teaching of active sequential learners. Advances in neural information processing systems, 32."
            },
            "questions": {
                "value": "- How exactly do the demonstrations affect the learner('s belief, as far as I understand?)?\n- What is the observation model of the teacher exactly?\n- Did you consider learning lambda?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3350/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3350/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3350/Reviewer_PobE"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3350/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698698394118,
        "cdate": 1698698394118,
        "tmdate": 1699636284846,
        "mdate": 1699636284846,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "3Dm37XFZKP",
        "forum": "WcSofkUVge",
        "replyto": "WcSofkUVge",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_sVdN"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_sVdN"
        ],
        "content": {
            "summary": {
                "value": "Based on the theory of mind (ToM), the teacher agent builds a model of the student's mental modal and then selects the best demonstration from a pool of demonstrations that maximizes the students reward minus the cost of demonstration. Authors compared two ToM based teachers against 4 baselines teachers and 1 that represents the upper bound for performance. Empirical results shows the goal and receptive field of the student can help achieving higher returns compared to 4 baselines."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The paper is very well-written and easy to follow.\n+ Experimental results are encouraging as teachers taking advantage of ToM to customize the guidance out-performed the ones that do not utilize ToM.\n+ The approach is simple and authors provided a git repository including notebooks for fast adoption."
            },
            "weaknesses": {
                "value": "- Generalizability: The proposed ToM technique assumes access to an approximate policy of the student. Also all environments discussed in the paper were deterministic. In practice, while the set of student goals are limited, the policy they follow may be far from ideal and the presence of stochasticity may confuse the teacher further to reach a reasonable belief. Would be great to discuss these limitation in the paper.\n- Computational Complexity Analysis: Given the calculation of the belief over goal x observation function, the proposed method does not scale well for more realistic scenarios. While authors left this to future works, the paper can benefit from a complexity analysis. \n- Limited novelty: the main idea of the paper is not novel and similar ideas have been explored to infer agent policies and goals as cited by the authors. The main difference is to expand the inference space to include observation model.\n\nMinor comments:\n- Spell out ISL: Implicit statistical learning\n- Typo: A set of states S^i => S^j"
            },
            "questions": {
                "value": "- \"receptive field\", does the agent see behind walls? I believe the answer is yes, but would be great to clarify in the main doc.\n- Why demonstrations are action sequence only? Why exclude observations? Is it due to deterministic assumption?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3350/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698728716972,
        "cdate": 1698728716972,
        "tmdate": 1699636284771,
        "mdate": 1699636284771,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1hqpVqdxfC",
        "forum": "WcSofkUVge",
        "replyto": "WcSofkUVge",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_C7a4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_C7a4"
        ],
        "content": {
            "summary": {
                "value": "The paper presents adaptive teaching strategies using Bayesian theory of mind.  Inspired by research in cognitive science, the paper proposes a goal-conditioned POMDP framework in which teachers choose demonstrations for learners under uncertainty about their beliefs. The paper presents an extended description of the model itself followed by experimental demonstrations in a simple gridworld environment."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- The paper tackles an interesting problem: how to formalize teaching goal-directed agents. \n- To the extent the teaching one intends is of humans, the interest in cognitive science is laudable."
            },
            "weaknesses": {
                "value": "The paper does not engage with, or obviously contribute to the large literature on models of teaching in machine learning (or cognitive science). Specifically, the introduction is entirely focused on one qualitative theoretical perspective in the cognitive science literature on teaching, without mentioning the extensive literature on formalizing teaching and cooperation. This literature has grown large and quite mature in recent years, including extensive mathematical and computational theories from a variety of perspectives. Indeed, several papers touch on topics that are quite close to the ideas here including sequential teaching under perturbations on belief and policy, teaching as a POMDP, proofs of robustness of standard ToM reasoning in cooperative settings, etc. Indeed, I would argue that the results are not surprising given what we already know. The paper does not make contact with these results, indeed doesn't even cite many of the relevant papers. \n\nDetailed comments: \n- The introduction is poorly structured to help readers understand the literature. There has been extensive work before and after the Gweon et al paper that explores this concept. \n- The introduction is almost exclusively focused on empirical research. However, there has been extensive work developing models. What is the contribution vis a vis that literature? \n- \"we explore the limitations of ToM models not being able to recover the learner actual internal state from its behaviour\" awkward sentence.\n- The contribution is rather modest. There are models for learning from observation. There are models of teaching. It appears the argument for novelty here is to do both? As noted in the literature review, this is not particularly novel either?\n- The related work section is far too broad. Theory of Mind and Bayesian inference are topics that couldn't possibly fit in a related work section. \n- There are a large number of related papers that are omitted. In recent years, there are several related NeurIPS papers, search for teacher or teaching or cooperation. There are older papers formalizing teaching as a POMDP problem. There are also newer papers on inferring beliefs of agents. \n- It is notable that neither the introduction nor the related work discuss POMDPs. \n- \"we introduce a teacher equipped with a Theory of Mind (ToM) model that we refer to as ToM-teacher\" Important to acknowledge most papers have a ToM component. \n- \"We assume that the teacher has knowledge of the learner\u2019s uniform initial belief and has access to a behavioural model of the learner \u2013 that is an approximation of its policy \u03c0\u02c6 \u2013 along with sets of possible goals GB and observation functions VB . These spaces are assumed discrete.\" These are strong assumptions that are very close to existing prior work. There are theoretical results that suggest why these assumptions are strong enough to work. \n- Given the introduction focusing on cognitive science, it is surprising to see decision trees and A* as part of the learner. Is there reason to believe that these are reasonable models of humans? \n\nI would strongly recommend that the authors review the last few years of NeurIPS (also ICML) papers for topics such as \"teacher\", \"teaching\", \"cooperation\" and \"cooperative\". Not all papers with those words will be related, but one will find quite a lot. Specifically, there are relatively theoretical papers that outline a mathematical framework and imply the results here that appeared in NeurIPS and ICML. There are also papers in NeurIPS that tested human experiments, which necessarily have errors in beliefs. Similarly, please read the literatures related to RSA (the Goodman and Frank paper cited) which have a number of interesting models and results. Please also search broadly for teaching and POMDPs as there is related work in that direction also. The current work will benefit from reconceptualization in light of these works."
            },
            "questions": {
                "value": "Please see the limitations. The big question being: what is the contribution of the current work based on prior results."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3350/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698758821803,
        "cdate": 1698758821803,
        "tmdate": 1699636284672,
        "mdate": 1699636284672,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KtYtzx7qrX",
        "forum": "WcSofkUVge",
        "replyto": "WcSofkUVge",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_dJ9E"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3350/Reviewer_dJ9E"
        ],
        "content": {
            "summary": {
                "value": "This paper studied machine teaching of reinforcement learners in the partially observable MDP (POMDP) setting. The teacher models the student learner's Theory of Mind (ToM) with Bayesian framework. In particular, there is a simple POMDP environment where teacher interacts with the student to understand the mental state of the student, and then applies the learned knowledge to teach the student in a more complex POMDP environment. The paper showed that when teacher's prior is aligned with the student's mental state, then the teacher demonstration can better help the student learn a good policy. Extensive empirical results validated the claims made in the paper."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "(1) The paper proposed to use the Bayesian framework to model student's mental state, and then utilizes the learned knowledge to help improve the learning process of the student in a complicated POMDP environment. This approach is reasonable and sound.\n\n(2) The paper performed extensive empirical explorations to demonstrate that the proposed method indeed helped speed up the learning process of the student model. The results look great and are convincing."
            },
            "weaknesses": {
                "value": "(1) It's not clear why the method requires two learning environment - a simple one for teacher to interact with the learner and gain knowledge of the student's metal state; and another more complex environment where the teacher performs real teaching. Is it possible to unify these two and let the teacher teach on the fly as it interacts with the student?\n\n(2) If there are significant distinctions between simple and complex environment. How does it affect the teaching process? Is the knowledge learned by the teacher in the simple environment going to become less effective?\n\n(3) The teacher requires full knowledge of the underlying POMDP. This is really unrealistic unless in very specific domains. This requirement limits the applicability of the proposed method.\n\n(4) The idea of the paper does not seem novel to me, and the results are not surprising at all. Of course, if the teacher learned prior for student's metal state aligns with the real mental state, then it's going to teach better. It would be much more interesting if the authors can provide theoretical justification of the proposed method through some Bayesian inference theory."
            },
            "questions": {
                "value": "Please see weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3350/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698878060642,
        "cdate": 1698878060642,
        "tmdate": 1699636284606,
        "mdate": 1699636284606,
        "license": "CC BY 4.0",
        "version": 2
    }
]