[
    {
        "id": "Mb243vfLLO",
        "forum": "Pjz3jkCAir",
        "replyto": "Pjz3jkCAir",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3505/Reviewer_EEcP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3505/Reviewer_EEcP"
        ],
        "content": {
            "summary": {
                "value": "This paper solves a family of PDEs given their general functional form. The model first derives the PDE coefficients from the encoded input data and then solves the PDE using some off-the-shelf numerical PDE solvers. This method is tested on several families of PDEs and shows some generalization ability."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) Clarity: Detailed description of the proposed method, the experiment protocols datasets involved, and the baselines.\n2) Originality: Estimate PDE coefficients by inference rather than optimization."
            },
            "weaknesses": {
                "value": "1) Novelty: Both the task definition and network architecture are not novel. The task of estimating PDE coefficients from observation data is previously known as the PDE inverse problem. And the AE architecture and finite difference scheme are not new.\n\n2) Significance: the main contribution is claimed as 'Proposing a DL encoding scheme ... enabling generalization for prediction of unseen samples based on minimal input'. However such generalization was only tested on in-distribution settings. Also, the expensive time cost of incorporating a finite-difference solver is not addressed or discussed.\n\n3) Solidness: the authors claimed in the abstract that 'We include results of extensive experimentation, comparing our method to SOTA approaches...'. however, the PDEs in experiments are relatively simple, and the baselines are not strong, compared with [1].\n\n[1]Wu, Haixu, et al. \"Solving High-Dimensional PDEs with Latent Spectral Models.\" (2023)."
            },
            "questions": {
                "value": "1) For params estimation, is the generalization or time cost of CONFINDE better than PINN and the classical adjoint method? For PDE solving, is the time cost of CONFINDE smaller than pure neural models such as FNO?\n\n2) The experiments are all about smooth solutions (Fig3 and Fig5). But in more practical settings, the PDE solution includes a discontinuity, also known as a 'shock wave' in Burgers and N-S. In such cases, the finite difference is more likely to fail or require more computations than in the smooth solution. Can you add some experiments on the shock wave data?\n\n3) Can you test the 'zero-shot' in the OOD setting, or at least in-distribution on a larger domain? For example,  change the Burgers parameter $a \\sim U[0,1]$ to $U[0,10]$.\n\n4) In the ablation study,  network size (number of learnable parameters) varies in different settings, which may affect the validity of the performance comparison."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3505/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3505/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3505/Reviewer_EEcP"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3505/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698670572179,
        "cdate": 1698670572179,
        "tmdate": 1700481971602,
        "mdate": 1700481971602,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cHEaZ0v7Jn",
        "forum": "Pjz3jkCAir",
        "replyto": "Pjz3jkCAir",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3505/Reviewer_RwBU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3505/Reviewer_RwBU"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a method to infer PDEs from data generated by unseen dynamics. The authors claim to tackle the lack of explainability of DL models for PDEs in comparison to numerical methods and their inability to extrapolate well to unseen data. To do so, the authors propose a hybrid approach CONFIDE. The method learns the unknown PDE parameters and then with the parameters solves the PDE forward in time."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Nice overview, background and motivation for PDEs in science and engineering applications.\n- Nice overview of numerical methods and mentioning RANs scheme.\n- The authors identify real limitations of current DL models for PDEs: the lack of explainability and inability to extrapolate to unseen data. Both are very serious limitations of these methods in practice for real-world science problems.\n- Nice hybrid approach and good to bring methods from numerical analysis, e.g., finite differences to black-box DL models.\n- The figures and plots are well-generated and easy to visualize.\n- It is good that the authors compare to FNO and U-Nets but I would also like to see comparisons to MeshGraphNets (Pfaff et. al, \"Learning Mesh-Based Simulation with Graph Networks\", ICLR 2021) and PINNs.\n- It is nice that the authors identified the issue common in many DL methods for PDEs that the error accumulates over time, such as in the observed results with FNO and U-Net."
            },
            "weaknesses": {
                "value": "- Abstract is a bit unclear\n- Last sentence of first paragraph in introduction is a bit vague.\n- The second paragraph in the introduction is also vague. Learning a PDE directly from data is a very different task than assuming it has a specific structure, such as the heat equation referenced here and just learning its coefficients. The description of the task is really the latter simpler task of learning the coefficients and is buried inside the introduction and is difficult to follow.\n- More examples are needed on why modeling using PDEs is limited. The (in)compressible Navier Stokes equations has been state-of-art in ocean dynamics and aerodynamics, respectively. I can see the motivation for not knowing the PDE parameter value exactly.\n- Numerical methods seem to be discounted and credited only for low-complexity problems but they are still state-of-the-art and have been made efficient with the last 40-50 years of high performance computing (HPC) research and numerical analysis. Good mention and analogy to RANs models though.\n- Too much description of the method in the introduction section that should be saved for the method section.\n- This two stage approach is reminiscent of CROM (https://arxiv.org/pdf/2206.02607.pdf), ICLR 2023, which uses neural representations to represent the spatial part of the PDE and then solves the resulting semi-discrete ODE forward in time using time stepping method.\n- The choice of finite difference methods over finite volume (suited for hyperbolic conservation laws) and finite element methods for unstructured meshes.\n- The background on current state-of-the-art SciML methods is extremely limited in the second paragraph of the related work section. In particular, Brandstetter et al., 2022 and Li et al., 2020 are very different methods, where the former is message-passing GNN based and the later is a Neural Operator approach. An advantage of Neural Operators, which is not discussed here is that they can learn the mapping from PDE parameters to solutions (Subramanian et. al, \"Towards Foundation Models for Scientific Machine Learning: Characterizing Scaling and Transfer Behavior\", NeurIPS 2023 and Negiar et. al, \"Learning differentiable solvers for systems with hard constraints\", ICLR 2023).\n- Reference to MeshGraphNets (Pfaff et. al, ICLR 2021) is missing which is another state-of-the-art class of GNN models for PDEs.\n- PINNs (Raissi et. al) can be used to solve inverse problems.\n- The authors should not be discussing details of their method in related work before describing their method in detail.\n- Assuming the form of the PDE is still a strong assumption.\n- Since the authors are comparing to a variant of NeuralODE, they should compare to DINO (\"Continuous PDE Dynamics Forecasting with Implicit Neural Representations\", ICLR 2023), which is designed for PDEs instead of ODEs for NeuralODEs and uses neural representation for the spatial discretization and then NeuralODEs to advance the continuous ODE forward in time.\n- The authors note that they cannot use PDEBench in the experiments since it is generated from the sample context. For other benchmarking examples see the GPME benchmarking framework in Hansen et. al, \"Learning Physical Models that can respect conservation laws\", ICML 2023 and various challenging PDEs including Navier-Stokes in Saad et. al, \"Guiding continuous operator learning through Physics-based boundary conditions\", ICLR 2023.\n- Large limitation to only test on (quasi)-linear and not concern challenging nonlinear hyperbolic PDEs is where numerical methods actually have challenges, e.g., hyperbolic conservation laws (nonlinear PDEs) and Stefan in Hansen et. al\n- The x vs t heat maps are more difficult to visualize in Figure 3 than the solution over space plotted at particular times as done in numerical methods. Also these plots are too qualitative to visual the performance improvement and plots of the errors would be better. Also it may be better to move these solution profiles to an appendix. Similarly for Figure 5.\n- Burgers' should be labeled properly as quasi-linear\n- The authors mention their motivation is for more explainable solution to PDEs and handle extrapolation. I don't see how either of these objectives are met by the method or shown in the experiments. The abstract should be rewritten to clarify this.\n\nMinor\n- Put RANs in parenthesis\n- Takamoto reference for PDEBench should be in parenthesis and similar for other citations"
            },
            "questions": {
                "value": "1. How does learning the PDE parameters couple with and affect the accuracy of the numerical solver?\n2. The numerical solver is a critical component and several solvers are better for different PDEs. Why was PyPDE chosen and which numerical schemes is it using?\n3. Why are finite difference methods used over finite volume and finite element methods? The choice of numerical method may vary for the different class of PDEs. Also, I don't understand why using finite differences eliminates the need to explicitly state the boundary conditions.\n4. Why is an autoencoder architecture selected? Were there ablation studies to motivate this choice?\n5. Based on the notation in Eqn. (1), does the method only work on linear PDEs? For instance, I see nonlinear Burgers $u_t + uu_x = 0 \\iff u_t + \\frac{1}{2}\\frac{\\partial u^2}{\\partial x} = 0$ in the experiments but I don't see how this equation fits in the form of Eq (1). I later found in Section 4.2 that it is only quasi-linear Burgers that is concerned so I think the p in Eqn. (1) could not be constant and need to depend on $u$ even in this case.\n6. Why is FNO and U-Net beating the proposed method CONFIDE in Figure 2a at early time steps? \n7. Why is FNO performing so poorly on the Fitz-Hugh-Nagumo equations? This seems odd.\n8. Since CONFIDE is not an operator, is it resolution invariant like Neural Operator methods are?\n9. Is the extrapolation task tested in the experiments?\n10. How is CONFIDE an \"explainable\" method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3505/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3505/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3505/Reviewer_RwBU"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3505/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777355814,
        "cdate": 1698777355814,
        "tmdate": 1699636303891,
        "mdate": 1699636303891,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cHtmkeaRl7",
        "forum": "Pjz3jkCAir",
        "replyto": "Pjz3jkCAir",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3505/Reviewer_VkbV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3505/Reviewer_VkbV"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a hybrid model for PDEs. The model combines an autoencoder with prediction of the (dynamically varying) coefficients of the underlying PDE. The method is benchmarked on signals generated with constant and non-constant coefficient PDEs. \n\nI am not fully familiar with this area, so my assessment is primarily based on reading the manuscript itself."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- this paper appears to combine the \"best of both worlds\" in PDE modelling. By combining autoencoding with coefficient prediction, it uses more PDE information than purely data-driven approaches but does not have the limitation of assuming constant PDE coefficients\n- the method is clearly explained\n- the results appear to  be competitive or better than existing methods such as U-Net"
            },
            "weaknesses": {
                "value": "- the method is limited to PDEs of the form (1)\n- no comparison with baselines such as Brandstetter et al., 2022 on prediction accuracy"
            },
            "questions": {
                "value": "-"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3505/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699032460296,
        "cdate": 1699032460296,
        "tmdate": 1699636303798,
        "mdate": 1699636303798,
        "license": "CC BY 4.0",
        "version": 2
    }
]