[
    {
        "id": "DufOw60Yqi",
        "forum": "0JTwZ30qPH",
        "replyto": "0JTwZ30qPH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9283/Reviewer_fqyn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9283/Reviewer_fqyn"
        ],
        "content": {
            "summary": {
                "value": "This paper argues that the semantic features required for different tasks may vary when using the same representation. Therefore, it proposes a task-oriented multi-view representation learning method. The paper adopts a meta-learning paradigm, defines multi-view tasks, and retains both task-specific information for each view and unified information across views. Additionally, it introduces task bias for different tasks. This method can be integrated into existing multi-view representation learning methods and has shown performance improvements."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The motivation and idea presented in this paper are reasonable. The introduction of the paper effectively highlights that multi-view representations should focus on both the unified representation and the unique information of each view, and should adapt to different representations for different tasks.\n\n2. This paper leverages a meta-learning paradigm to generate task bias and integrates it into existing multi-view representation learning methods, resulting in performance improvements."
            },
            "weaknesses": {
                "value": "1. The paper artificially defines downstream tasks for multi-view representation learning, but typically representation learning aims to acquire a general representation that can be fine-tuned for different specific tasks. Is it unfair to directly consider downstream tasks in the representation learning, and can the representations learned in this paper still perform well for new tasks that are not considered in the paper?\n\n2. The paper is not very clear in explaining how the meta-learning paradigm generates task-specific biases and whether it can explain why using task bias generated by the meta-learning paradigm can improve the model's performance.\n\n3. The experimental evaluations are not comprehensive enough in several aspects. The dataset used in this paper is not sufficiently diverse. For example, commonly used datasets in this field, such as NoisyMNIST, EdgeMNIST, Caltech20, and PatchedMNIST, were not tested. Additionally, the paper only integrates the method into three approaches, all from the same source paper. It is hoped that the authors can validate their method by integrating it into a wider range of methods to enhance its credibility."
            },
            "questions": {
                "value": "For major concerns including the problem/experimental setting, unclear description, and experimental evaluation, please see weaknesses for details.\n\nThere appears to be a minor error in the pseudocode. Should line 20 be placed after line 21?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698590980693,
        "cdate": 1698590980693,
        "tmdate": 1699637169463,
        "mdate": 1699637169463,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "EYaATRsUpm",
        "forum": "0JTwZ30qPH",
        "replyto": "0JTwZ30qPH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9283/Reviewer_d8EV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9283/Reviewer_d8EV"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a model to learn task-oriented multi-view representation. Based on the observation that almost all of current models ignore the basic fact that effective representations are different for different tasks, even for the same entity, they propose a Task-Oriented Multi-View Representation Learning (TOMRL) method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Learning task-oriented multiview representation is important."
            },
            "weaknesses": {
                "value": "1.\tThe motivation is not clear. For example, there are many methods could learn task-oriented representation and multi-view representation, however, the authors only provide some examples which are not applicable for out-of-sample data or only learning the uniform representation for entities. It is not convincible. \n\n2.\t\u201cA typical multi-view representation learning framework consists of four main components: View-specific encoding, Single-view learning (SVL), Multi-view learning (MVL), and Fusion.\u201d  It is a very strong claim or assumption. The authors should provide a comprehensive study and moreover a formulation to unify these models is necessary. \n\n3.\t\u201chow representations from multiple views can better serve the task\u201d I think this is a very natural requirement in many models. So, I do not find any necessity or novelty for this claim. \n\n4.\tThe writing and organization are not clear. It is difficult to understand the motivation and why the proposed model is good."
            },
            "questions": {
                "value": "The claim that there are four components is questionable, so the authors should provide more clear and strict evidence or analysis. \n\nThere are no theoretical results."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698763944646,
        "cdate": 1698763944646,
        "tmdate": 1699637169349,
        "mdate": 1699637169349,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "GTzf04zYx7",
        "forum": "0JTwZ30qPH",
        "replyto": "0JTwZ30qPH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9283/Reviewer_V7F6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9283/Reviewer_V7F6"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a gradient-based embedding strategy to flexibly represent multi-view tasks. The authors propose a meta-learning-based solution and learns task-oriented multi-view representations, where meta-learning and multi-view learning are ultimately formalized as a nested optimization problem and solved via a bi-level optimization paradigm."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. Results on four datasets are presented on multi-view tasks.\n2. Empirical study shows that the method consistently improves the performance of downstream tasks for both few-shot and routine tasks."
            },
            "weaknesses": {
                "value": "1. Why two modulation processes are useful in this task was unclear.  Also, the benefit of the TOMRL on different dataset domain is also not discussed or analyzed in the paper. I think the paper should at least study at least one scenario , e.g., NoisyFashion to Caltech 101-7, to verify the effectiveness of TMORL as this is considered as one of the main contribution of the paper. It shall also be helpful to analyze why TOMRL is helpful in learning a high-quality unified representation, perhaps from the perspective of gradient analysis.\n\n2. The display of experimental results in this paper is not uniform. For example, bold results in some tables indicate the best results, while others denote the results of TOMRL. Please unify the form in the full text. Alternatively, give clear comments in each table title."
            },
            "questions": {
                "value": "Regarding the cross task experiment in Table 3, the proposed TOMRL brings a decrease in NMI indicators of NoisyFashion to EdgeFashion. With the significant growth MORL has brought under other conditions, why did this particular decline occur?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission9283/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9283/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission9283/Reviewer_V7F6"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699076990221,
        "cdate": 1699076990221,
        "tmdate": 1699637169202,
        "mdate": 1699637169202,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "UkVvo5FkH0",
        "forum": "0JTwZ30qPH",
        "replyto": "0JTwZ30qPH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9283/Reviewer_caBF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9283/Reviewer_caBF"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a multi-view representation learning method, where the key idea is to modulate features in the View-specific encoding and Fusion modules according to the task guidance. The authors design a gradient-based embedding strategy to represent multi-view tasks. In addition, a meta-learner is trained to map the task embedding into a set of view-specific parameters and a view-shared parameter. This whole process is formalized as a nested optimization problem and ultimately solved by a bi-level optimization scheme."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper proposes a task-oriented multi-view representation Learning method from a meta-learning perspective. The performance of classification and clustering tasks is improved significantly.\n2. The proposed method defines an unsupervised multi-view task in an episode fashion, and designs a meta-learner for modulating the view-specific features and unified entity representations with the task guidance.\n3. The proposed method models meta-learning and multi-view learning as a nested bi-level optimization."
            },
            "weaknesses": {
                "value": "1. For \u2018representations from multiple views can better serve the task\u2019 in the contribution 1. In fact, it explores the relationship amongst various tasks, from the perspective of multi-task learning, which is not enough as an innovation point.\n2. In the section 3, the authors mentioned that the fusion process of features may also be inconsistent. The proposed method focuses on Fusion modules, how does the author align the features of similar instances in different tasks?\n3. The authors should discuss the insight of this paper with the lifelong multi-view learning or multi-view multi-task learning.\n4.  In term of the loss function, the author does not introduce the concept of weight. For multiple tasks, the data distribution and importance of different tasks are different. How does the author solve this problem?\n5. The current manuscript need to be carefully polished, such as, in the section 2, \u3016R\u3017^(d_H ) not R_(d_H ), in table 2, line 4, the font thickness should be consistent\uff1b the notations in equation (1)"
            },
            "questions": {
                "value": "Please check the comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9283/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699198525781,
        "cdate": 1699198525781,
        "tmdate": 1699637169102,
        "mdate": 1699637169102,
        "license": "CC BY 4.0",
        "version": 2
    }
]