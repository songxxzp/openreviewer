[
    {
        "id": "vgRANnq9s1",
        "forum": "5nEmi3YIz4",
        "replyto": "5nEmi3YIz4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1839/Reviewer_XoPR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1839/Reviewer_XoPR"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a post-training decomposition technique for learning prototypes for interpretable image classification. Specifically, the paper leverages Non-negative Matrix Factorization (NMF) to learn prototypes (bases) for a certain class from a batch of hidden image features from the same class. The prototypes are then used to reconstruct the learned feature classifier for this class. By visualizing the attention on the prototypes, researchers can identify interpretable regions and their importance in arriving at the final classification results. The paper demonstrated good interpretability in the experiment."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* **Simple post-training solution**: the paper proposed a simple solution to enable better interpretability for a trained model without modifying the training process. Compared to prior works, the proposed method is computationally efficient and is architecture-agnostic. \n\n* **Good interpretability and classification accuracy**: while prior works often sacrifice classification accuracy because of the modification to the training pipeline, the proposed model brings interprtablity without loosing accuracy. \n\n* **Detailed analysis**: the paper provides a detailed empirical analysis of various aspects of the model, including the discriminativeness of the extracted prototypes, which is also a limitation of the method."
            },
            "weaknesses": {
                "value": "* **Lacking an inference description**: the paper lacks a discussion on the inference procedure in the method section. While Figure 1 provides schematics, it is not clear enough. My understanding is the following: the paper uses the *original* head classifier for classification because \n$$V^c = R^c + C^c_{opt}B^c$$\nwhere $V^c$ is the original classifier vector, $R^c$ is the residual prototype and $ C^c_{opt}B^c$ is the extracted prototypes. The paper uses both the residual and the extracted prototypes, the sum of which amounts to the original classifier. This is equivalent to using the original classifiers for classification. This is the reason why the proposed method guarantees no drop in accuracy. \n\n* **Extracted prototypes not discriminative**: the paper provides a detailed analysis of the discriminativeness of the extracted prototypes $ C^c_{opt}B^c$. The conclusion is that they are not discriminative enough (if at all when the number of prototypes is small according to Table 3) .This makes one wonder if this discovery defeats the main purpose of the paper: discovering meaningful prototypes and shedding light on a transparent reasoning process, because these prototypes are neither meaningful nor explaining the model's decision for a specific class. The fact that using the extracted prototypes alone results in poor classification accuracy makes one think that the proposed NMS procedure is ineffective in extracting good prototypes for classification."
            },
            "questions": {
                "value": "* Can the authors comment on my concerns regarding the meaningfulness and usefulness of the extracted prototypes in the weakness section? \n\n* A follow-up question is how important the discriminativeness of the prototypes is in interpreting the decision-making process in classification and what information we would miss if the prototypes were not discriminative as in the proposed method.\n\nI really like the proposed method but the main concern regarding the discriminativeness of the prototypes also weighs heavily in my decision. I will be happy to raise my score if the authors can address it convincingly."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698523528703,
        "cdate": 1698523528703,
        "tmdate": 1699636113897,
        "mdate": 1699636113897,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qUCaarKceo",
        "forum": "5nEmi3YIz4",
        "replyto": "5nEmi3YIz4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1839/Reviewer_A726"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1839/Reviewer_A726"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors proposed ProtoNMF, a method to turn a black-box model into a prototype-based interpretable model using non-negative matrix factorization (NMF). The method involves constructing a feature matrix A^c for a given class c by stacking the D-dimensional feature vectors of n*H*W image features from n images as rows, and applying NMF to A^c to yield the factorization A^c = E^c B^c where B^c is the prototype matrix whose rows are D-dimensional prototype basis vectors, and E^c is the encoding matrix whose rows represent the coordinates of the image features along the prototype basis vectors. The method also involves another step to reconstruct a classification head V^c for a given class c, using a linear combination of prototype vectors (rows) of B^c, and to find a residual prototype R^c = V^c - C^c_opt B^c, where C^c_opt B^c is the best linear combination of prototype vectors (rows) of B^c that approximates the classification head V^c. The computation of the logit of class c of the original black-box model on the image features A^c can then be thought of as first computing a linear combination of prototype vectors in B^c (i.e., E^c_opt B^c), and then adding scalar multiples of the residual prototype R^c to each spatial position of each image (i.e., H^c_opt R^c). The authors conducted experiments on CUB-200-2011 and ImageNet to demonstrate the efficacy of their ProtoNMF."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed ProtoNMF can preserve the accuracy of a black-box model."
            },
            "weaknesses": {
                "value": "- The proposed ProtoNMF cannot be interpreted in the same way as the baseline ProtoPNet. Its interpretability is far from ProtoPNet. The prototypes are not constrained to be actual image features of some training images. How are they visualized?\n- The proposed ProtoNMF uses linear combinations of prototypes, rather than similarities to prototypes. This, again, reduces interpretability of ProtoNMF. What do linear combinations of (abstract) prototype vectors even mean?\n- The proposed ProtoNMF also relies on a residual prototype for each class. Again, the interpretation of a \"residual prototype\" is unclear."
            },
            "questions": {
                "value": "- As mentioned earlier, the prototypes from ProtoNMF are obtained via NMF and are not constrained to be actual image features of some training images. How are the prototypes visualized?\n- As mentioned earlier, ProtoNMF uses linear combinations of prototypes. What do linear combinations of (abstract) prototype vectors even mean?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698796313907,
        "cdate": 1698796313907,
        "tmdate": 1699636113827,
        "mdate": 1699636113827,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "7wfXMplstU",
        "forum": "5nEmi3YIz4",
        "replyto": "5nEmi3YIz4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1839/Reviewer_eeCj"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1839/Reviewer_eeCj"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a method that turns a black-box pretrained image classification network into a more interpretable prototype-based network, by performing non-negative matrix factorization to decompose the final features of the network into non-negative linear combinations of bases of classes. The authors claim that in this way, the model can achieve interpretability without sacrificing performance. Empirical evaluations are performance on two datasets and three difference model architectures."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The comprehensive evaluations of different model architectures are appreciated. \n\n2. The idea of turning a black box model into a more interpretable one is interesting."
            },
            "weaknesses": {
                "value": "1. Interpretability\n\nI believe the main contribution of this paper is to improve the interpretability of a pretrained black-box model. However, after reading the paper, I have no idea how to measure the improvements in interpretability quantitatively. The visualization of the prototypes may show how the model makes the final prediction, but I believe regular 'black-box' networks + GradCAM can do the same and there is no obvious evidence of the advantage of the proposed method. \nOne thing the author mentioned is that such prototypes can help the post-training human intervention in the model. However, the missing of this part in the experiment section makes it very hard to justify the contribution of 'interpretability.' \n\nAnd I am afraid that the 'residual prototypes,' which seem to be crucial for maintaining the recognition performance, will make it even harder to intervene manually in the model.\n\nIn summary, the authors are expected to do more than visualizations to support the interpretability. \n\n2. Writing and presentation\n\nThe overall writing of this paper is relatively casual and in many cases not precise enough for the readers to properly learn the ideas.\nAnd some examples are not solid enough. \nFor example, in Figure 2, it is true that ProtopNet is clearly converging to fewer prototypes as the training goes longer, the visualization of the learned prototypes of ProtoNMF on different images does not show the superiority in terms of diversity. How distinct are those learned prototypes?\n\n3. Evaluations\n\nPlease consider adding the performance of the standard ResNet34 to table 2.\n\nAnd I personally believe the results in Table 3 do not support the claim 'guarantee the performance on par with the black box models.' In most the cases, the performance decreases drastically. And the best performance is with the not-so-interpretable residuals."
            },
            "questions": {
                "value": "Please evaluate the interpretability of the proposed method quantitatively."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1839/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698814671678,
        "cdate": 1698814671678,
        "tmdate": 1699636113753,
        "mdate": 1699636113753,
        "license": "CC BY 4.0",
        "version": 2
    }
]