[
    {
        "id": "KLhOjUfK0x",
        "forum": "QzQSR56JZr",
        "replyto": "QzQSR56JZr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3948/Reviewer_8JQp"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3948/Reviewer_8JQp"
        ],
        "content": {
            "summary": {
                "value": "This paper 28K sentence-level natural language to First Order Logic pairs collected from GPT-4. The authors also present a LLaMA-13B model fine-tuned on this dataset which combined with GPT3.5 achieves GPT-4 level performance on the NL-FOL translation tasks.\n\nThe combination method with GPT3.5 is interesting because it relies on using RLHF method to correct synthetically perturbed NL-FOL pairs and using a first order logic verifier as a reward model."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper presents a new method for gathering RLHF feedback based on iterative correction which is a non-trivial extension of previous methods."
            },
            "weaknesses": {
                "value": "The techniques in the paper are not novel and fine-tuning LLAMA for a downstream task can be considered engineering at this point instead of active research. The novelty of the proposed approach is not totally clear."
            },
            "questions": {
                "value": "Even though the paper says that the LogicLLAMA is finetuned using RLHF there is no human feedback involved. It should probably be called something else ?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3948/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698644243412,
        "cdate": 1698644243412,
        "tmdate": 1699636355588,
        "mdate": 1699636355588,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WUEysgkO9J",
        "forum": "QzQSR56JZr",
        "replyto": "QzQSR56JZr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3948/Reviewer_6TG1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3948/Reviewer_6TG1"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to address the challenge of translating natural language sentences into first-order logic (FOL). A new dataset, MALLS, is proposed, which is generated by leveraging LLMs and applying filtering rules to eliminate bad cases. The paper proposed fine-tuning LLaMA on MALLS to enhance LLaMA's FOL generation ability. The model is tested on LogicNLI, FOLIO, and MALLS to demonstrate the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper demonstrates considerable effort in conducting numerous experiments to achieve its objective.\nThe motivation to enhance FOL generation ability is interesting."
            },
            "weaknesses": {
                "value": "1. The paper lacks novelty. Most contributions are either engineering work or published work including: prompting LLM to generate data, various prompting and dataset filtering methods, supervised fine-tuning, and RLHF. Moreover, the conclusions are predictable: fine-tuning LLM on a specific domain can improve its performance, potentially surpassing the best LLM for open domains.\n2. The proposed methods do not show significant improvement. As per Table 2, the majority of the gain comes from vanilla supervised fine-tuning on MALLS, and the newly proposed methods only bring marginal gains, especially when compared to the gain from the baseline to vanilla fine-tuning."
            },
            "questions": {
                "value": "1. The abstract should be written in a single paragraph.\n2. Consider reducing the use of markers like C1-C2, Q1-Q2, T1-T4. The frequent use of these symbols indicates a struggle to explain clearly, and it can be challenging for readers to understand by locating the definition. Short names might be more effective.\n3. Try to limit the number of your contributions and new terms. Highlight only the most significant things you want readers to remember. Currently, you have five prompting methods to create the dataset, four rules to filter the dataset, four fine-tuning methods to train LLaMA, and the experiment aims to address four research questions. This approach dilutes each contribution and makes it difficult to determine whether it works and can be generalized to new problems.\n4. Can your method generate more examples, since your generation and filtering are automatically executed?\n5. How do you assess the coverage or diversity of your dataset? LLM may only generate high-frequency knowledge.\n6. While the natural language input generated from LLM is often fluent and grammatically correct, real human inputs can be noisy. How do you address this issue?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3948/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698759193306,
        "cdate": 1698759193306,
        "tmdate": 1699636355488,
        "mdate": 1699636355488,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2R5cyDD1L4",
        "forum": "QzQSR56JZr",
        "replyto": "QzQSR56JZr",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3948/Reviewer_wVqn"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3948/Reviewer_wVqn"
        ],
        "content": {
            "summary": {
                "value": "This paper contributed the MALLS dataset and the LogicLLAMA models for natural language to first-order-logic translation tasks. The authors also describe a multi-stage training paradigm using closed-source GPT models to generate datasets for training open-source LLAM for the NL-FOL translation tasks. Experiments are conducted to demonstrate the effectiveness of the proposal."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "\u2022 Investing the possible links between large language models and logical reasoning is an important topics to advance the methodology for AI.\n\u2022 The paradigm of training open-sourced NL-FOL from open-sourced LLMs using data sourcing from close-sourced LLMs is a reasonable way to create NL-FOL models.\n\u2022 Experiments demonstrate almost start-of-the-art performance of NL-FOL tasks with the proposed LogicLLAMA model from LLAMA."
            },
            "weaknesses": {
                "value": "\u2022 The targeting FOL language lacks a formal characterization. Is it an fully expressive First-order logic language or just the logic program subset? \n\u2022  The description of iterative correction via RLHF is difficult to follow lacking a few explicit description to task T4. In particular, it took me multiple-pass to understand why T4 is different from T3. It might worth a few rewriting to make this more explicit and easy to follow regarding the format of training data and loss functions."
            },
            "questions": {
                "value": "1. Page 7, regarding logical equivalence, which exact semantic models of FOL do you refer to? It is better to explicitly name the exact semantic models, such as Herbrand structure/universe if there is any; otherwise there might be ambiguity rendering the FOL being just a subset of FOL --- even if only a subset of FOL is supported it is already meaningful but please be specific. \n2.  Please formally define the 4 training tasks T1-T4 with explicit input-output definitions and loss definitions (if not enough space, putting them into supplemental materials is acceptable)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3948/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699197661096,
        "cdate": 1699197661096,
        "tmdate": 1699636355404,
        "mdate": 1699636355404,
        "license": "CC BY 4.0",
        "version": 2
    }
]