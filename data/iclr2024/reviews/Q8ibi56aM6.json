[
    {
        "id": "OqM5L2ywGL",
        "forum": "Q8ibi56aM6",
        "replyto": "Q8ibi56aM6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5662/Reviewer_1ipB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5662/Reviewer_1ipB"
        ],
        "content": {
            "summary": {
                "value": "This paper prsents a method to reconstruct 3D shape from a single 2D RGB image without explicit 3D supervision. This research mainly focuses on the scenes where multiple human and objects appear and they have interactions including human-human and/or human-objects. In the proposed pipeline, human and objects are reconstructed separately and later their relative arrangement is controlled through the joint optimization process. Several loss functions are introduced (collision loss, interaction loss, depth-ordering loss, occlusion-silhouette loss). The results are compared with previous reearches using COCO 2017 dataset."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Well defined the loss functions essential to be considered to resonctruct 3D meshes from the single 2D image that contains interacting human and objects.\n* The explanation was enough to understand the main idea and the intention. Easy to read and well prior works are well introduced.\n* Using image inpainting algorithm to solve the problem of occluded object pose matching seems to be a clever idea and working well."
            },
            "weaknesses": {
                "value": "* Many of the building blocks of the proposed pipeline rely on the previously proposed researches. The authors claim that the novelty of collision loss, but since the collision loss is applied only after the reconstructions of each elements (human, object) are processed by the previously proposed method, the arrangement of the final scene seems to be too sparse to avoid collision between elements. The only arrangement can be optimized.\n* I may assume another reason of sparse arrangement is the collision loss exploits compact 3D bounding box to reduce computational burden.\n* One may think the quantitative evaluation metric is unfair in terms of comparison, since the metrics are designed to obtain high score according to the loss design."
            },
            "questions": {
                "value": "I think just obtimizing arrangement is not enough to get more reasonable results. Is there any method or idea to change the pose of each human considering the interaction instead of using each of 3D reconstruction meshes as pre-processed building blocks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5662/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777709674,
        "cdate": 1698777709674,
        "tmdate": 1699636590062,
        "mdate": 1699636590062,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "xBuhx35Qj8",
        "forum": "Q8ibi56aM6",
        "replyto": "Q8ibi56aM6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5662/Reviewer_NYAH"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5662/Reviewer_NYAH"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a new pipeline for human object reconstruction from single-view images. This method mainly focuses on addressing occlusions, e.g., human-human interactions and human-object interactions, to produce a reasonable spatial layout. This method does not need any 3D supervision. Occlusion issues are addressed in an interaction optimization way. Many strategies are employed to estimate a correct human and objects, e.g., depth ordering, and image impainting.\n\nFrom my side, this paper is a systematic work towards how to improve the spatial human and object layout placement with minor occlusion issues. Most technical ideas exist, which makes this paper a system and engineering work. The results look good. However, there lacks of comparisons with recent closely related works.\n\nThe paper is well writting."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "This paper focuses on addressing occlusions for better human and object pose estimation. The major strength mainly comes from the human-object and human-human occlusion losses. However, many losses are inspired by the baseline [1]. Another strength is the mask inpainting for better 6 DOF pose estimation.\n\n[1] Coherent reconstruction of multiple humans from a single image, CVPR2022"
            },
            "weaknesses": {
                "value": "Even though this paper achieves convincing visualizations, there are quite a lot of weaknesses.\n\n1. The technical contributions are not enough\nThe authors claim that they can address occlusion issues in many circumstances, e.g., human-human and human-object occlusion. However, the major methodology (loss function)  to achieve their target is heavily inspired/designed based on existing works, e.g. interaction loss and depth-ordering loss from [1].\n\n2. Overclaimed contributions\nFor the first contribution point, I do not think it is the first approach. Please check [2, 3].\nFor the second contribution point, from my view, many loss items are borrowed from [1]. I can not see novelty there.\n\n3. No discussions and comparisons with closely related papers.\nThe authors did not compare their performance with the recent works. There are quite a lot of works in human-object reconstruction. Since this is a fast-growing area, comparing it with a paper published in 2020 will not convince me. I would encourage the authors to compare with the state-of-the-art, e.g. [2,3]\n\n[1] Coherent reconstruction of multiple humans from a single image, CVPR2022\n\n[2] Human-Aware Object Placement for Visual Environment Reconstruction, CVPR2022\n\n[3] Holistic 3D Human and Scene Mesh Estimation from Single View Images, CVPR2021"
            },
            "questions": {
                "value": "Suggestions: \n1. More comparisons with the state-of-the-art.\n2. Rephrase the contribution claims."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5662/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5662/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5662/Reviewer_NYAH"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5662/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698792527862,
        "cdate": 1698792527862,
        "tmdate": 1699636589955,
        "mdate": 1699636589955,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "oaZjvqI4Z3",
        "forum": "Q8ibi56aM6",
        "replyto": "Q8ibi56aM6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5662/Reviewer_HiJk"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5662/Reviewer_HiJk"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a method for reconstructing a 3D scene containing multiple objects and humans. Compared to prior work such as [Jiang et al. 2020, Zhang et al. 2020], the main novelty is fitting a silhouette of a 3D mesh on inpainted instance segmentation, to improve accuracy on occluded objects. A holistic reconstruction through joint optimization is performed; consequently, both human-human and human-object occlusions and interactions can be considered."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "It can leverage most off-the-shelf inpainting and segmentation models and does not require extra data or 3D supervision.\n\nWell motivated. Reasoning about 3D geometry and affordances can improve most existing methods; it can also be potentially extended to generate targets for reinforcement or unsupervised learning."
            },
            "weaknesses": {
                "value": "Not enough experimental validation. It is possible I misunderstood, but there seems to be no comparison with more reasonable baselines like silhouette fitting without inpainting, or another human-human interaction method [Jiang et al. 2020].\n\nWhile the statement that the inpainting approach \"greatly boosts the precision of 6 DOF object position estimations\" may not technically be a misrepresentation, I believe it is confusing. The actual evaluations show mesh collision metrics and user preference study."
            },
            "questions": {
                "value": "How important is inpainting performance? Why did you choose EdgeConnect for inpainting?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5662/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5662/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5662/Reviewer_HiJk"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5662/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698843439302,
        "cdate": 1698843439302,
        "tmdate": 1700738865003,
        "mdate": 1700738865003,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MDzyKLjhT0",
        "forum": "Q8ibi56aM6",
        "replyto": "Q8ibi56aM6",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5662/Reviewer_6q9o"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5662/Reviewer_6q9o"
        ],
        "content": {
            "summary": {
                "value": "In this paper is proposed a novel technique to infer the 3D reconstruction of multiple objects (this is a combination of humans and additional everyday objects) from a single image. The method first exploits two approaches to infer the 3D reconstruction of humans and objects, independently. After that, the paper presents an approach to resolve the ambiguities that could arise from the previous independent composition by means of a collision loss, depth ordering and interaction information."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The method handles an important problem in computer vision.  To this end, just a single image is used and no 3D supervision is considered. In contrast, a novel collision loss is exploited. \n+ The segmentation mask is improved by a well-known inpainting-based approach. Thanks to that, the precision of 6 d.o.f object position in heavily occluded scenes is better."
            },
            "weaknesses": {
                "value": "- The full method seems to be a good combination of well-known approaches in the literature. In this line, I feel the authors should explain better their real contribution with respect to state of the art. Right now, the contribution seems to be minor, according to the information in the document. \n- Some important analysis and experiments are missing in the paper. \n- Some claims are not properly validated. The quantitative analysis shows that some of them were not solved as proposed."
            },
            "questions": {
                "value": "I think some of the claims in the paper are not properly validated. For instance, the authors comment, their method can handle strong occlusions and extreme interaction between humans and the relation human-object. Unfortunately, this interaction seems not to be correct as it can be seen in figure 2 (see hand interaction between people #1 and #2, from left to right). Maybe most important is the interaction between the first human (again from left to right) and the bicycle. In fact, no connection is inferred between human and bicycle in the provided solution. The same can be seen between the third human and the object. This analysis is very similar after observing the results in Fig. 5. On balance, the theoretical spatial coherence is only good in 2D, instead of 3D as the authors claim in the paper. In spite of improving the incoherent solutions of some competitors, I think the claims of the paper are not evaluated properly. \n \nThe authors infer a scale parameter per object (assuming, a human body is also an object), but to sort out the problem with multiple ones, I think a unique scale per scene (and camera) should be estimated. I feel it is the unique way to guarantee a coherence scale per scene. \n \nEquation (1) is optimized just with respect to translation and scale. What about rotation? In my opinion, this is a key factor in the interaction between objects.\n \nCan the authors explain their contribution in the collision loss? The final loss can be an extension of the work proposed by Jiang et al. 2020. \n \nRobustness. How can the method handle bad detections and segmentations? Note that a claim of the paper is the use of complex scenes in the wild where potentially the detection and segmentation algorithms could fail, or at least, provide non-perfect estimations. How are these artifacts considered in the optimization?  \n \nAccording to experimental results, just three external types of objects are considered in the evaluation. In my opinion, the set of interactions needs to be more extensive, by using more objects and complex interactions. \n \nSome failure cases could help readers."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5662/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699291758284,
        "cdate": 1699291758284,
        "tmdate": 1699636589747,
        "mdate": 1699636589747,
        "license": "CC BY 4.0",
        "version": 2
    }
]