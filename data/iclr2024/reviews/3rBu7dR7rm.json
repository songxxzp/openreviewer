[
    {
        "id": "SohAY6xWp9",
        "forum": "3rBu7dR7rm",
        "replyto": "3rBu7dR7rm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5498/Reviewer_ptT1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5498/Reviewer_ptT1"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a unified benchmark dataset for long-term time-series forecasting (LTSF), addressing the limitations of existing datasets. The dataset includes real-life and synthetic data from diverse domains, enabling comprehensive evaluations of LTSF methods. The datasets are split into training and testing trajectories with fixed lengths, allowing for standardized evaluations. The paper introduces two new hand-crafted models, the latent NLinear model and DeepAR enhanced with curriculum learning, which outperform existing models. The benchmark includes classical and state-of-the-art models such as LSTM, DeepAR, N-Hits, PatchTST, and LatentODE, and evaluates their performance on the dataset. The paper emphasizes the importance of dataset diversity, facilitating ML model training and testing, and introducing new models to improve LTSF accuracy. The paper concludes by providing an open-source library with implementations to promote further advancements in LTSF research."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Comprehensive dataset: The article presents a comprehensive dataset that incorporates real-life and synthetic data from diverse domains, enabling the evaluation of long-term time-series forecasting methods in a wide range of contexts. This comprehensive dataset helps in gaining a more holistic understanding of the strengths and weaknesses of different methods across various domains.\n\n2. Standardized evaluation: To ensure consistency and comparability, the authors split the dataset into training and testing trajectories with fixed lengths. This standardized evaluation approach allows for more accurate and reliable comparisons between different methods.\n\n3. Introduction of new models: The article introduces two new hand-crafted models, namely the latent NLinear model and DeepAR enhanced with curriculum learning. These new models demonstrate significant improvements across the entire dataset, showcasing their effectiveness and potential in long-term time-series forecasting.\n\n4. Extensive method comparison: The article conducts a thorough benchmarking analysis, evaluating a range of neural network-based models including classical approaches and state-of-the-art methods. By comparing the performance of these methods on the dataset, a better understanding of their strengths and limitations can be gained, fostering advancements in the field.\n\n5. Open-source code library: To facilitate further advancements in the field, the authors provide an open-source code library that includes implementations of the methods discussed. This enables other researchers to easily replicate and extend these methods, accelerating progress in the field."
            },
            "weaknesses": {
                "value": "1. Regarding innovation:\n\n   (1) The proposed methods in this article seem to have had little impact on the overall benchmark and did not address any gaps in the existing methodological framework or provide substantial insights or innovations. The article needs to clearly articulate the innovative aspects of its methods and how they improve upon existing approaches.\n\n   (2) The benchmark dataset created in the article consists of two parts: SYNTHETIC and REAL-LIFE. However, while the REAL-LIFE part mainly comprises existing time-series datasets, the contribution of the SYNTHETIC part in addressing the limitations of the existing REAL-LIFE datasets is not adequately explained. The article should analyze the potential shortcomings of the existing real-life datasets and explain how the SYNTHETIC dataset complements them.\n\n2. Regarding experiments:\n\n   (1) The description of the process for jointly evaluating models using artificial and real-life data is overly concise and fails to analyze the fundamental differences between artificial and real-life data. It is recommended to propose a systematic evaluation framework for time-series models that goes beyond presenting a series of datasets.\n\n   (2) The experimental evaluation of Transformer models only includes one model, PatchTST, thereby lacking a comprehensive exploration of other Transformer models. It is advisable to include a wider range of Transformer models in the experiments for a more comprehensive comparison and evaluation.\n\n3. Regarding presentation:\n\n   (1) The \"BENCHMARK SYNERGY\" section lacks formulas and illustrations, making it difficult for readers to understand its content. It is recommended to provide more visualizations and illustrations in this section to aid reader comprehension.\n\n   (2) The article lacks basic visual analysis and conclusions, making it challenging for readers to grasp the experimental results intuitively. Including more data visualizations and clear conclusions in the article would provide more intuitive information.\n\n   (3) The article lacks intuitive descriptions of the datasets, such as data-time graph representations, making it difficult for readers to understand the characteristics and structure of the datasets clearly.\n\n   (4) There is a lack of illustrations for different data generation methods, impeding readers' understanding of the data generation process and methods. It would be beneficial to include relevant figures to help readers comprehend the data generation process.\n\n   (5) The absence of data-time graph representations for the predictive performance of different models hinders readers' ability to visually compare the performance of various models. It is recommended to provide data-time graph representations in the results section to facilitate a better understanding of the predictive performance of the different models."
            },
            "questions": {
                "value": "1. Flaw: The author says: \"The most dominant class of LTSF benchmarks relies on datasets with rather uniform characteristics composed of nine widely-used real-world datasets: Electricity Transformer Temperature (ETT) from Zhou et al. (2021a) (split into four cases: ETTh1, ETTh2, ETTm1, ETTm2), Traffic, Electricity, Weather, ILI, ExchangeRate. All of them are univariate time series with a significant degree of non-deterministicity (these are real-life measurements).\" However, they are mostly multivariate time series.\n\n2. What I am concerned about most is listed in the weakness, I won't refuse to raise my points if the author can address my concerns."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5498/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5498/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5498/Reviewer_ptT1"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5498/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698738706204,
        "cdate": 1698738706204,
        "tmdate": 1699636562129,
        "mdate": 1699636562129,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "J1JksfdFf8",
        "forum": "3rBu7dR7rm",
        "replyto": "3rBu7dR7rm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5498/Reviewer_WuTL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5498/Reviewer_WuTL"
        ],
        "content": {
            "summary": {
                "value": "**Summary:**\n\nThis paper presents a comprehensive dataset specifically designed for long-term time-series forecasting, which includes simulated data as well as real-life data. The authors standardize each dataset into training and test trajectories with predetermined lookback lengths and conduct an extensive benchmarking analysis using both classical and state-of-the-art models, including a custom latent NLinear model and an enhanced DeepAR with a curriculum learning phase.\n\n**Strengths:**\n\n1. Several simulated datasets are proposed.\n\n2. lookback windows are standardized.\n\n\n**Weaknesses:**\n\n1. I'm not fully convinced that including various simulated datasets would be helpful. One significant feature of long-term forecasting is high volatility, such as weather and stock prices. The evolving procedure can hardly be described by several relatively simple equations. Thus even if a model works well in the simulated dataset, it still may not necessarily also work well in real-world datasets.\n\n2. No new real-world datasets are proposed.\n\n\n**Questions:**\n\n1. I'm wondering if the authors could elaborate more on the necessity of including simulated datasets and the performance correlation between simulated datasets and real-world datasets.\n\n\nAt the current stage, the paper's contributions, while noteworthy, do not seem to meet the high threshold of a top-tier machine learning conference like ICLR.  However, I'm not a expert in dataset track and I am open to reconsidering my decision after rebuttal ."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Please refer to the Strengths section in Summary."
            },
            "weaknesses": {
                "value": "Please refer to the Weaknesses section in Summary."
            },
            "questions": {
                "value": "Please refer to the Questions section in Summary."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5498/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698835300768,
        "cdate": 1698835300768,
        "tmdate": 1699636562033,
        "mdate": 1699636562033,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dV7rTxD9D9",
        "forum": "3rBu7dR7rm",
        "replyto": "3rBu7dR7rm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5498/Reviewer_av6e"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5498/Reviewer_av6e"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a standardised time series dataset for use in benchmarking long-term time series forecasting (LTSF) methods. A variety of methods are tested on the dataset, with slightly simpler methods (NLinear and DeepAR-CL) demonstrating consistently better performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Providing researchers with additional datasets for testing would help to strengthen the claims of new LSTF architectures proposed."
            },
            "weaknesses": {
                "value": "However, it is not immediately clear what novel methods the authors have created and what the value proposition of the paper is. While additional datasets can be beneficial to strengthen claims, it is not immediately unclear why the existing datasets for benchmarking (often real world diverse datasets) are insufficient, or why the synthetic datasets proposed (which can also be found in other time series papers, particularly MuJoCo) are better models the LSTF problem. In addition, details on hyperparameter tuning are sparse, with critical hyperparams such as learning rates and regularisation params (e.g. dropout) omitted from the paper. Given the diversity of time series datasets, performance of hyperparams are highly dataset specific -- and without full tuning it is difficult to disenteagle if underperformance is due to improperly selected hyperparams (e.g. with LSTM on sine waves). This is particularly the case for larger transformer models, especially when transferred onto simpler datasets."
            },
            "questions": {
                "value": "1. How would authors describe the novelty of the paper, and what new methods have been created/proposed?\n2. Why are the synthetic datasets suggested better suited for the LSTF problem?\n3. How is hyperparam tuning concretely performed, and how are learning rates/regularisation params set?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5498/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699365536426,
        "cdate": 1699365536426,
        "tmdate": 1699636561944,
        "mdate": 1699636561944,
        "license": "CC BY 4.0",
        "version": 2
    }
]