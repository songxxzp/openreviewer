[
    {
        "id": "d9YMaAYOBJ",
        "forum": "EyQO9RPhwN",
        "replyto": "EyQO9RPhwN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7355/Reviewer_SunQ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7355/Reviewer_SunQ"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes 3D-GeoCA, a method to solve PDE on arbitrary geometry. It makes use of a geometry encoder that extracts features from the point cloud, a backbone network that processes the geometry as a point cloud or graph; and an adaptor that merges these two sets of features."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The method addresses an important problem that has a potential impact on different fields. Even if it is designed for physical simulation, I understand that it can provide a better understanding of general geometries and so provide a contribution to Computer Graphics and Vision communities. The paper seems to provide a good discussion of recent literature, also considering contemporary works."
            },
            "weaknesses": {
                "value": "I am not an expert in this specific field, and hence I may overlook some important aspects. Given this, I have the following concerns:\n\n1) CLARITY: I went through the method section a couple of times, but still, I am not able to fully understand the proposed approach and the specific insight of the method. In particular, I find the paragraph about adaptors a bit cluttered with technical and implementation details, which hide the flow of the proposed approach. The output of different steps is not clear, and figure 1 lacks a proper caption. As a nonexpert, I do not feel I can make use of or re-implement the method and what are the main insights, and I think this is a significant limit in the potential impact of the work.\n\n2) COMPARISON: About the experiments, Figure 2 and the qualitative results in the appendix all provide a comparison between the result and the method, but without a baseline, it is difficult to assess the quality of the obtained results. I suggest the authors to include more visualization to help unexperienced readers to get into the topic and better understand the intuition"
            },
            "questions": {
                "value": "1) What is the computational timing of the proposed approach? How much does the complexity of the input geometry affect this?\n2) If I understand correctly, the provided ablation shows the results about dropping input data points at inference time. The method performance does not degrade much until it drops 60% of the points. Does it mean the geometry encoder suffers from partiality, e.g., missing part of the model? Does it rely on the assumption that the shape at inference time has more or less the same geometry of the training distribution, while it can be more sparse?\n3) The method uses pointnet-based feature extractors. However, why not consider more recent options that could provide more structured inductive bias (e.g., DeltaConv: Anisotropic Operators for Geometric Deep Learning on Point Clouds, Wiersma et al., 2022)?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7355/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698186140057,
        "cdate": 1698186140057,
        "tmdate": 1699636880151,
        "mdate": 1699636880151,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "4tHfHtF8z4",
        "forum": "EyQO9RPhwN",
        "replyto": "EyQO9RPhwN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7355/Reviewer_vtzc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7355/Reviewer_vtzc"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes the 3D-GeoCA method, a framework that aims to leverage learned geometry representations from existing point cloud models to solve PDEs. The approach is generic and works with different backbone neural PDE models. The authors evaluate the method on the shape-net car CFD dataset and report improvements of up to 10-30% across different backbone models. Ablations on different point cloud models and model batch sizes are included as well."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper has two main strengths, originality and promising results.\n\nFirstly, to me the proposed framework is quite original. Combining 3D shape representations with neural PDE solvers in such a generic way is an interesting direction.\n\nSecondly, the shown results indicate that there seems to be a consistent 10-30% decrease in prediction error when employing the proposed framework across different backbone models. \n\nFurthermore, source code is provided with this submission, which helps to improve reproducibility in the future. However, I did not attempt to run the code or investigate it in detail."
            },
            "weaknesses": {
                "value": "I am not an expert in the domain that this work targets, and I am unfamiliar with a range of the cited related work. As a result, I was struggling to fully understand the details of the proposed approach. Nevertheless, to me this paper appears unfinished in various aspects.\n\n### Presentation\n\n**P1:**\nThere are several references to related work in the introduction, but in my opinion this paper would benefit from a dedicated related work section. Furthermore, the paper does not address a substantially amount of related work targeting PDE solutions via graph networks. For instance, some key papers from this domain include:\n- *\u201cLearning to simulate complex physics with graph networks\u201d* by Sanchez-Gonzalez et al., ICML 2020\n- *\u201cMessage passing neural PDE solvers\u201d* by Brandstetter et al., ICLR 2022\n- *\u201cCombining differentiable PDE solvers and graph neural networks for fluid flow prediction\u201d* by de Avila Belbute-Peres et al., ICML 2020\n- *\u201cLearning mesh-based simulation with graph networks\u201d* by Pfaff et al., ICLR 2021\n\n**P2:**\nSeveral statements in this work are vague or unclear, and require additional explanation or citations. The following list is not exhaustive, but some example include:\n- \u201ccan extract the essential and robust representations of any kind of geometric shapes, which is regarded as a conditioning key to guiding the adaption of hidden features in the surrogate model.\u201d (unclear, abstract)\n- \u201cActually, various approaches have been proposed, including finite difference and finite element methods, whereas these methods usually have high computational costs, which are unendurable in many real-time settings.\u201d (lacks citation, first paragraph in section 1)\n- \u201cWhile the work above has achieved remarkable progress in solving simple 2D equations\u201d (even in 2D the investigated PDEs can create complex behavior, paragraph 4 in section 1)\n- Inefficient Representation for 3D Inputs section: Choosing non-Cartesian meshes in the context of graphnet-based PDE simulators (as mentioned above) does exactly address this problem, if I understood the argumentation here correctly?\n- \u201cCurrent work usually under-emphasizes grids in P in boundary of D and coarsely feeds all grids with simple hand-crafted features (such as SDF) into their model\u201d (lacks citation, paragraph 3 in section 3)\n\n**P3:**\nThe paper lacks overall polishing in terms of language, notation, formatting and figure design.\n\n### Evaluations\n\n**E1:**\nThe proposed method is quite generic, and as such it should also be evaluated in a generic way, however only a limited scope of experiments on a single data set are shown. Ideally, at least one more complex case from a fluid flow perspective could be considered, for example unsteady flow problems. Furthermore, generalization ability is highly desirable for ML-based PDE solvers, and thus evaluations on test sets outside of the direct training domain (for example different Reynolds numbers) should be considered, not only a random train-test split. Similarly, only a single evaluation metric via a simple L2 distance is used. Especially the domain of fluid flows offers a range of tools for more in-depth evaluations, for example spectral analyses could be considered (see e.g. *\u201cTurbulent flows\u201d*, Pope, Cambridge University Press).\n\n**E2:**\nThe proposed architecture adds a substantial amount of computational and expressive complexity to the backbone networks. This directly raises the question if additional model capacity chosen in a suitable manner (e.g. number of parameters, GPU memory, overall training time, etc.) would not increase the backbone performance just as much. Furthermore, a comparison with a model that uses the same architecture but does not pretrain the geometry encoder would be necessary, to draw conclusions regarding the usefulness of pre-training.\n\n**E3:**\nTo me it seems problematic that the pressure and velocity errors in Tab. 1 and 2 differ so much. Why would the models work so much better in predicting velocity over pressure? I assume this might be an issue with the data ranges, when looking at the colorbars in Fig. 2. If the pressure has a substantially higher magnitude, it should be normalized separately such that the network has a chance to determine both with similar accuracy. \n\n**E4:**\nDrawing conclusions on the convergence rate of different models in Fig. 3, does not seem ideal. Considering that the models are trained for 200 epochs, only looking at the first 20 epochs is a limited evaluation. This also ties into the question of larger model capacities mentioned in **E2** above.\n\n### Summary\nOverall, the results of this paper are pointing in an interesting direction and the approach is quite original. Nevertheless, the weaknesses of this work are more dominant than its strengths. The presentation appears unfinished, the scope of the experiments is limited, and there are some problems with the shown evaluations. This leads to my overall recommendation of reject for the current state of this paper."
            },
            "questions": {
                "value": "**Q1:**\nI am curios about the choice of $\\lambda=0.5$ in equation 6. This seems to arbitrarily bias the network to either focus on pressure or velocity instead of treating them in the same way (depending on the normalization of the input fields). My guess is that this also impacts the pressure vs. velocity error issue discussed in **E3** above. \n\n**Q2:**\nWhy is the evaluation in Fig. 4 meaningful? Dropping data points from the encoder is an artificial operation that should not happen in practice. And I would interpret the right half of each plot as a point against the proposed architecture: even though the model is trained to heavily rely on the geometry encoder, it only performs marginally worse when having barely any information from the encoder at all during inference."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7355/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7355/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7355/Reviewer_vtzc"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7355/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698757987043,
        "cdate": 1698757987043,
        "tmdate": 1699636880006,
        "mdate": 1699636880006,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mTl3lnaaB5",
        "forum": "EyQO9RPhwN",
        "replyto": "EyQO9RPhwN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7355/Reviewer_E9jv"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7355/Reviewer_E9jv"
        ],
        "content": {
            "summary": {
                "value": "Paper introduces a framework for predicting outputs of 3D PDEs that operates directly on geometry (point clouds).\nThe key idea is to combine a generic pre-trained geometry encoder, combine with state-of-the-art prediction backbone and train resulting model to predict the results of ground truth simulations. The method is robust to the choice of the underlying backbone (whether it's MLP or a graph CNN), and demonstrates comparable performance to some an existing baseline."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The work is well-motivated: classical CFD and similar kinds of simulations are expensive, and thus developing efficient and generalizable surrogate models has huge potential.\n- The overall approach of using a pre-trained geometry encoder features to improve generalization makes a lot of sense.\n- Proposed framework is agnostic to the choice of the backbone and seems to be producing accurate predictions (although there are questions to evaluation, see below)."
            },
            "weaknesses": {
                "value": "- (Novelty) Using a geometry encoder for predicting outputs of physical simulations, in particular with mesh-CNNs have been used before [Baque'18]. \n- (Clarity) It is a bit hard to understand what are the actual contributions of this work. The terminology provided in the into is quite confusing: is the main novelty that the method relies on pre-trained geometry decoder? Is it the fact that it directly operates on geometry rather than ad-hoc parameterizations? Is it the specific adapter architecture that is fundamental? This needs clarification.\n- (Evaluation) Since the speed is one of the core reasons for using surrogate models over classical simulation, it is surprising that no formal evaluation of speed have not been conducted.\n- (Evaluation) There are classical methods (GPs aka kriging) which are (still) standard in the engineering fields. It would probably make sense to compare against those?\n\nTypos / misc:\n- I am not a native speaker, but \"adaption\" seems like a misspelling of \"adapter\" / \"adaptation\"?"
            },
            "questions": {
                "value": "- Would be great if you could clarify the contributions and specifically technical novelties, currently all four points in the intro sound bit like the same thing rephrased multiple times. \n- The presentation of results in Section 4.3 is a bit weird: do not see why not present results in the same table? Why not compare to existing tools e.g. GPs?\n- One of the key benefits of using neural nets as surrogate models are the fact that they are differentiable [Baque'18], and are suitable e.g. for shape optimization. Did you consider using the resulting model for that purpose? Do you foresee any issues for any of the chosen backbones?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7355/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698778057486,
        "cdate": 1698778057486,
        "tmdate": 1699636879856,
        "mdate": 1699636879856,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "utQimwWfru",
        "forum": "EyQO9RPhwN",
        "replyto": "EyQO9RPhwN",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7355/Reviewer_Wkj4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7355/Reviewer_Wkj4"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes to use 3D point encoder architectures pre-trained on large-scale 3D shape datasets to extract global point cloud features and to use these features to condition the neural network models designed for solving PDEs in 3D space. The conditioning mechanism adds the extracted global point cloud features put through an MLP to per-point features computed by a separate backbone network for every input grid or surface point.\n\nIn the experiments, the authors vary several architectures for pretrained global feature extractors and backbone networks and evaluate the approach by calculating the mean absolute/relative L2 distance between the ground truth and predicted physical property values at input locations. Results suggest that global conditioning with pre-trained and possibly fine-tuned features improve the quality of the inferred PDE solutions."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "I do not possess extensive knowledge of the literature, but the authors claim that this is the first attempt at using geometric feature extractors applied to surface samples to condition the PDE solution prediction networks."
            },
            "weaknesses": {
                "value": "1. The choice of conditioning mechanism seems arbitrary. General purpose feature conditioning is an established field in deep learning, the closest to the proposed mechanism is FiLM: Visual Reasoning with a General Conditioning Layer. Since then various adaptor schemes have been applied to any imaginable learning task across numerous domains, e.g. conditioning on global features and time-positional features in diffusion models Scalable Diffusion Models with Transformers. I think the paper can benefit greatly from considering at least several options for conditioning mechanisms and comparing them.\n\n2. No intuition is provided to explain the degradation in quality when the model is trained with batch size > 1. I suspect there may be a technical error in the batched implementation of the approach causing this, rather than a consistent result, which will translate to other methods.\n\n3. I do not know if this is the norm for this task, but using mean L2 distance as the only evaluation metric is limiting. As it is an aggregate metric, it is impossible to assess the consistency/smoothness of the produced solution, and the presence of the outliers. At least adding the variance/std can show something. Also, maybe a heatmap of L2 distance instead of the heatmap of the solution can show where the model is the least accurate."
            },
            "questions": {
                "value": "I do not expect the authors to solve all this, so I put some additional comments in the questions section:\n\n1. Why no positional encoding for input locations? \n\n2. Why do you use global conditioning for all the input points? You can use local per-point features at least for points on the surface. And even for the grid points it is possible to obtain some features by discretising the point features onto the grid and applying convolutions to spread the features across the whole grid, e.g. point-cloud to 3D grid network from Neural Dual Contouring.\n\n3. I don\u2019t know if other metrics are established for the task, but L2 as a final metric is a bit misleading, in my opinion. The end goal of the considered simulations is to make a decision about the shape of the car and the materials, that will be able to deal with the pressure. Do you need as precise simulations as possible to make this decision? How much does this L2 error translate into incorrect choices for the shape and materials? I believe these things are quantifiable and I will be very interested to see metrics that can evaluate this, rather than simple final optimized loss value."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7355/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698848679024,
        "cdate": 1698848679024,
        "tmdate": 1699636879760,
        "mdate": 1699636879760,
        "license": "CC BY 4.0",
        "version": 2
    }
]