[
    {
        "id": "q6zjfwhhCV",
        "forum": "QxItoEAVMb",
        "replyto": "QxItoEAVMb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5935/Reviewer_gnLZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5935/Reviewer_gnLZ"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces an new _modular_ reinforcement learning in PyTorch named TorchRL whose goal is provide a flexible, efficient and scalable library for rapid prototyping and research.\nThe key componnet here the TensorDict data structure enablibg easy efficient communication between different components like environments, buffers, models etc.\nIt includes many reference implementations including RL algorithms as well as distributed traning and other utilities.\nExperiments are performed to validate correctness and efficiency while showing competitive performance compared to other libraries."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Modular design: seems really well designed from the perspective of allowing new implementations from existing components vs the current standard practice of trying to fork an existing implementation where which component changed and mattered can be difficult to figure out. You either have single file implementations that don't really do distributed scaling well or you have weird nested inference to figure out how/where even is the actual algorithm implemented.\n- Modularity is demonstrated with reasonable tradeoffs for a very wide variety of RL methods and applications. \n- TensorDict as a concept is very generally useful and will hopefully see wider adoption in Torch ecosystem.\n- Distributed training and scaling building on `torch.distributed` is quite nice.  \n- Example implementations are short and clear while scaling well."
            },
            "weaknesses": {
                "value": "- Likely steeper learning curve and verbosity compared to higher level libraries. However, given the focus on research over applications, should not be that bad.\n- Limited to PyTorch, although DLPack has made things easier.\n- Smaller community and ecosystem. Would have been much better if this had been ready a couple of years ago that would have helped fix some of the fragmentation issues. If I were to guess, RL _algorithm_ research is somewhat waning (and has largely been not _that_ successful as a research endeavor because a lot of things that make RL work are considered engineering details).\n- Lots of tiny details matter when it comes to RL comparisons and more tooling and integration here would be useful. Reporting 3 average seed results is likely not the best way to report results when comparing RL methods.\n- Range of \"reasonableness\" is quite wide when it comes to RL implementations. Would be great if the paper also put the current best reported results for various environments to contextualize. That is also going to be helpful in convincing new algorithm implementations to start here rather than the best performing implementation in terms of reward scores etc."
            },
            "questions": {
                "value": "- While I understand it's not the focus, would be useful to also show how heteregoenous multi-agent problems can be setup in TorchRL's API while still potentially leveraging batching/vectorization capabilities?\n- Hyperparameters in RL are a big bane. Any plans to support automatic tuning, especially population based methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5935/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698630599167,
        "cdate": 1698630599167,
        "tmdate": 1699636631822,
        "mdate": 1699636631822,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "rKSP4TO0xN",
        "forum": "QxItoEAVMb",
        "replyto": "QxItoEAVMb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5935/Reviewer_tnNy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5935/Reviewer_tnNy"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces TorchRL, a PyTorch-based reinforcement learning/sequential decision-making library. The library supports many standard algorithms in model-free deep RL including the DQN family of algorithms, SAC, and PPO. Additionally, the library offers several additional features/algorithms that have emerged only in the past 2-3 years, including RLHF and decision transformers. There is also additional support for offline RL algorithms, multi-agent algorithms, and model-based RL algorithms such as Dreamer. \n\nCore to TorchRL is another contribution of the paper: the TensorDict (released as a second library), which is a flexible data carrier for PyTorch. It is a dictionary-style object that stores tensor-like objects.\n\nThe library is well-tested with good adoption by the community. Several standard algorithms from TorchRL are benchmarked in terms of performance and speed, demonstrating that TorchRL runs much faster than other RL libraries."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Comprehensivity: The library is extremely comprehensive. It spans different algorithm classes (e.g., offline RL, model-free Deep RL, multi-agent RL, etc.) whereas most algorithms focus on a single algorithm class (typically model-free RL). This makes this library more likely to be a single place where researchers and practitioners can go for a solution to their problem.\n- Modernity: This library includes multiple powerful tools introduced only in the past 2-3 years, including RLHF and decision transformers."
            },
            "weaknesses": {
                "value": "Presentation: I did not find the explanation of TensorDict, which seems integral to the paper to be very didactic. The text delves into the various functionalities of the TensorDict at a high-level, but I did not find it clear how this abstraction or these functionalities lends itself to ease development of RL algorithms. Figure 1 did not clarify this. I realize there is more context provided in the appendix, but the explanation in the main text needs to be improved. \n\nBenchmarking: For a software library, benchmarking is extremely important. It is well known that implementation details are critical for performance, making high quality algorithm implementations a core aim of deep RL libraries. All the experiments are run with a mere 3 seeds. Moreover, the Atari results are run on 40M timesteps as opposed to the usual 50M. Moreover, for some environments/algorithms, the performance seems slightly worse than these should be. For example, if we compare the SAC results from Table 1 to PFRL (https://github.com/pfnet/pfrl/tree/master/examples/mujoco/reproduction/soft_actor_critic), we see:\n- HalfCheetah: TorchRL performs at 11419 vs. around 15000 in PFRL and other papers\n- Ant: TorchRL scores about 3692 as opposed to the 5800+ seen in PFRL and other papers.\n\nSAC also slightly underperforms in the other two environments though the differences are not profound. Is there an explanation for this and for other environments? How are the hyperparameters found for these implementations? How do these implementations differ from other libraries?\n\nOf course, the results I am linking appear to be from the v2 of the environments, whereas the results here in the paper are from v3, which may explain the results. Do you know or have a citation for good results to be expected on the v3 mujoco environments? It is also possible that these differences are due to randomness, which is all the more reason to run more random seeds for benchmarking."
            },
            "questions": {
                "value": "- The introduction has strong statements indicating that other libraries are not being actively maintained or having fallen out of favor. Active maintenance is easier to see through version control, but how have the authors concluded that other libraries have fallen out of favor? My understanding is that many of these libraries are still being used.\n- For replay buffers, the paper says: \"To overcome this, TorchRL provides a single RB implementation that offers complete composability. Users can define distinct components for data storage, batch generation, pre-storage and post-sampling transforms, allowing independent customization of each aspect.\" Is there support for prioritized experience replay which is used in several model-free RL algorithms?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5935/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5935/Reviewer_tnNy",
                    "ICLR.cc/2024/Conference/Submission5935/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5935/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698660198606,
        "cdate": 1698660198606,
        "tmdate": 1700650326514,
        "mdate": 1700650326514,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aEV2AWfMjv",
        "forum": "QxItoEAVMb",
        "replyto": "QxItoEAVMb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5935/Reviewer_77b1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5935/Reviewer_77b1"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces TorchRL, a comprehensive decision-making library in the PyTorch ecosystem, designed to address fragmentization in the decision-making field by providing efficient, scalable, and flexible primitives suitable for complex real-world data and environments. The proposed library offers a modular design, combining components that maintain standalone functionality.  TorchRL introduces several core modular classes as well as TensorDict, a standalone library that can handle multiple tensors at the same time in the form of an improved dictionary class that supports batched tensor operations. An extensive experimental section demonstrates the correct reproduction of several famous single/multi-agent and offline RL as well as the library\u2019s efficiency against strong competitors."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The proposed library tries to tackle an important problem - the fragmentization of the RL field. While many libraries have been proposed over the years (in the form of the environment \u201cGyms\u201d or full-stack RL solutions), TorchRL is, to the best of my knowledge, the most comprehensive and efficient with full support in the PyTorch ecosystem, which makes it exceptionally relevant given the prevalence of PyTorch implementations in the research community, as well as for practitioners. The experimental section touches on virtually all of the most important aspects for benchmarking, single-agent, multi-agent, and offline RL, as well as other benchmarks. The Github library has also received widespread support from several groups.\n\nFinally, I have personally used TorchRL and TensorDict in several projects and found them useful and efficient. I expect the library to have a great impact in streamlining the development of decision-making algorithms for practitioners and researchers alike."
            },
            "weaknesses": {
                "value": "The paper and its proposed library do not have any major weaknesses.\n\nThe main weakness - that does not influence my score since it is highly subjective, due to my experience while using it - is that the library\u2019s implementation is at times hard to read - meaning that the code is at times a bit convoluted and not straightforward to understand. For instance, other platforms such as CleanRL are way easier, in my opinion (also due to their single-file implementations, which are orthogonal to the proposed library), in terms of how the whole RL process works from data collection to training, and as such perhaps more suitable for new researchers.\n\n---\n\nTypos (no influence to my score)\n\n- Page 4, `, Isaac makoviychuk2021isaac, Jumanji (Bonnet et al.),` missing `\\cite` and possibly the year for Jumanji\n- Page 22 . `implementations1`"
            },
            "questions": {
                "value": "1. Tables 3-5 show a performance comparison on a machine with 8 GPUs. Do the tested gaps with other libraries hold in single-GPU machines as well? In other words, could the gaps be in part due to the fact that TorchRL is using multiple GPUs?\n2. In the Appendix, Figure 14, it looks like TorchRL can outperform RLLib in speed but cannot reach the same rewards. Does it mean there may be some incorrect implementation?\n3. In Table 4, it is mentioned: \"Those data moves are unaccounted for in this table but can double the GAE runtime\" . Does this apply only to TorchRL?\n4. Could you quantify the overhead of using TensorDict a bit more? It would be useful to see (e.g., in Appendix E) how much the difference is between using TensorDict and not using it.\n5. You mentioned that some libraries make environments vectorizable and runnable directly on GPUs (i.e., with PyTorch or JAX). In my experience, CPU-GPU overhead is one of the major challenges in terms of efficiency. Are you planning to develop a \u201cGym-like\u201d library of vectorized environments as well in the future, such as \u201cpendulum\u201d but with `_step` and `_reset` with tensors?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5935/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698798016320,
        "cdate": 1698798016320,
        "tmdate": 1699636631606,
        "mdate": 1699636631606,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1eL41d1Kbj",
        "forum": "QxItoEAVMb",
        "replyto": "QxItoEAVMb",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5935/Reviewer_C5vY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5935/Reviewer_C5vY"
        ],
        "content": {
            "summary": {
                "value": "Authors develop a new unified library for RL training that introduces the TensorDict, which enables clean modular and composable implementations of all major RL algorithms and support for vectorized GPU environments such as IsaacGym and Brax. The TensorDict enables indexing by key like a regular python dict, but also indexing by shapes like a regular pytorch tensor, which allows it to inherit tensor-based operations like reshaping, concatenating, moving between devices, gradient storing, etc. TorchRL also includes TensorDictSequential as an nn.Sequential analogue operating on TensorDicts.\n\nTorchRL has implementations of nn.Modules including MLP, LSTMs, but also RL specific things like ActorCriticOperator."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Writing contains detailed coverage of major existing RL frameworks and environments.\n- Substantial library implementation and development that is already having a large impact on the research community.\n- TorchRL includes a communication class.\n- Proposed TorchRL framework integrates well with existing pytorch code and all facets of RL are considered, including replay buffers, vectorized environments, and wall clock time."
            },
            "weaknesses": {
                "value": "### Overall\n(A1) Lacks a discussion of limitations. What are the current features that torchRL cannot handle/is bad at handling but should be improved upon in future releases?\n\n(A2) Details of TorchRL\u2019s communication class could be more clear. What defines a communication class? What part of downstream RL algorithms does it accelerate?\n\n(A3) Prior work discussion should describe data structures similar to TensorDict that have been implemented in the past on accelerated ML libraries, such as perhaps pytrees in jax, which seem to share some similarities with TensorDict.\n\n### Computational efficiency results are a bit lacking.\n\n(B1) Paper did not measure the computational overhead/efficiency gain of using TensorDicts vs. regular python data structures containing pytorch objects. For instance, what is the efficiency of standard reshaping operations on TensorDicts of some set of tensors $X$, vs. the same reshaping operation on a regular python dict containing the same set of tensors $X$?\n\n(B2) How does an optimized TorchRL implementation compare efficiency-wise to the popularly-used pytorch implementations of different RL algorithms that are publicly available? Table 4-5 mostly compares with other RL frameworks that do not use pytorch. Without these results, it is hard to determine true efficiency effects of TensorDicts.\n\n(B3) A more in-depth computational efficiency comparison between TorchRL and Jax, on the same hardware, could help practitioners decide which library to use (although ease of use is a separate issue that cannot be easily quantifiable). There is a comparison to CleanRL (Jax) in Table 4, but not in Table 5."
            },
            "questions": {
                "value": "1. Will tensor-based operations only work on TensorDicts if the leading dimensions of every single tensor in the TensorDict shares the same leading dimension? Can these operations only be done on a subset of the items in the TensorDict?\n2. What are the next major features of TorchRL under development?\n3. How much resources will be dedicated to supporting TorchRL (github issues, new features) for the foreseeable future, compared to PyTorch as a whole?\n4. Are there computational efficiency results of TorchRL on accelerator-based simulators such as IsaacGym, Brax, and MJX?\n5. Typo in 3rd paragraph under Section 2, Subsection \u201cEnvironment API, wrappers, and transformations\u201d with the \u201cIsaac\u201d citation.\n6. In Section 2, subsection \u201cEnvironment API, wrappers, and transformations,\u201d how does the data transform involving \u201cembedding through foundation models\u201d \u201ccome at no cost in terms of functionality?\u201d What does this sentence mean?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5935/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5935/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5935/Reviewer_C5vY"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5935/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698806093802,
        "cdate": 1698806093802,
        "tmdate": 1699636631509,
        "mdate": 1699636631509,
        "license": "CC BY 4.0",
        "version": 2
    }
]