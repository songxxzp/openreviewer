[
    {
        "id": "LkV4qJEbyl",
        "forum": "Zesag4jmPQ",
        "replyto": "Zesag4jmPQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2565/Reviewer_LLhf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2565/Reviewer_LLhf"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces an Explainable Active Learning framework tailored for text classification tasks in settings with limited resources. The key idea is to prompt the model to provide a natural language explanation for its prediction. This explanation is then leveraged both in active learning data selection and model fine-tuning."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The proposed method innovatively combines human-in-the-loop label annotation and LLM-in-the-loop explanation generation to optimize both the model performance and the annotation budget of active learning."
            },
            "weaknesses": {
                "value": "Section 3.1 It's inappropriate to use a development set for hyperparameter tuning, as highlighted in references [1][2]. This compromises the integrity of the experimental setup, and is the major reason for rejection. \n\nSection 4.4: The human evaluation results are perplexing. The main results in Section 4.1 show the model's accuracy on all datasets to be considerably lower than 94%. Given that the predicted labels exhibit an accuracy range of 60-80%, a 94% consistency between the predicted label and its associated explanation appears contradictory.\n\n\npaper\n1. Weaker Than You Think: A Critical Look at Weakly Supervised Learning\n2. On the Limitations of Simulating Active Learning"
            },
            "questions": {
                "value": "Suggestions:\n* In Section 2.4, change \"golden\" to \"gold.\"\n* In Figure 2, \\pi is introduced without prior definition. Its definition is provided subsequently in Section 2.3.\n* In Section 4.1, it would be beneficial to include the zero-shot ChatGPT results and the results from the model \"trained on the entire training set\" as flat lines in the figures.\n* For Figure 2, ensure consistent color coding between the caption and the figure elements (e.g., red and blue arrows).\n\nQuestions:\n* How about the performance of few-shot LLMs using a random select strategy, in addition to the zero-shot LLM?\n* For Figure 4, all other baseline models demonstrate very similar performance across all datasets when limited to 100 data points. Could there be a specific reason underlying this?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2565/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2565/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2565/Reviewer_LLhf"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2565/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698710881112,
        "cdate": 1698710881112,
        "tmdate": 1699636193540,
        "mdate": 1699636193540,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "K8RmEjewkr",
        "forum": "Zesag4jmPQ",
        "replyto": "Zesag4jmPQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2565/Reviewer_XVNV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2565/Reviewer_XVNV"
        ],
        "content": {
            "summary": {
                "value": "The manuscript proposes an Explainable Active Learning (XAL) framework for text classification with a pre-trained uni-directional decoder to generate and score the explanations. XAL proposes a ranking loss to enhance the decoder's capability in scoring explanations and combines the predictive uncertainty of the encoder and the explanation score of the decoder to select the most informative data for annotation. XAL is evaluated on 6 text classification datasets and the results show that the proposed method outperforms existing AL techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "XAL generates high-quality explanations for its classification decisions, which can better help users understand and trust the model. This combination makes Active Learning, as human-in-the-loop learning becomes more realistic."
            },
            "weaknesses": {
                "value": "- XAL only compares with typical Active Learning methods and does not compare with similar methods like [r1].\n\n- As shown in the ablation study, each component could not provide a stable performance gain on various tasks, e.g., XAL vs. w/o rank.\n\n\n[r1] Ghai B, Liao Q V, Zhang Y, et al. Explainable active learning (xal) toward ai explanations as interfaces for machine teachers[J]. Proceedings of the ACM on Human-Computer Interaction, 2021, 4(CSCW3): 1-28."
            },
            "questions": {
                "value": "- How to set the hyperparameters? Like $\\lambda$, $\\lambda_1$, $\\lambda_2$. \n\n- In experimental settings, the author only uses 500 labeled samples, as shown in Figure 4, most model performances are far from convergence.\n\n- In figure 4, why the starting point (initial model performance) of XAL are different from other baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2565/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698725260797,
        "cdate": 1698725260797,
        "tmdate": 1699636193437,
        "mdate": 1699636193437,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hu8LPRWfXq",
        "forum": "Zesag4jmPQ",
        "replyto": "Zesag4jmPQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2565/Reviewer_idfx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2565/Reviewer_idfx"
        ],
        "content": {
            "summary": {
                "value": "Active Learning represents a potent learning paradigm that seeks to minimize the labelled data necessary for training while maximizing the model's performance. Central to active learning research is the design of an effective acquisition function, aimed at selecting the most informative samples with respect to the decision boundaries, thereby enhancing the classifier's learning process. This paper suggests leveraging the predictive explanations generated by Large Language Models (LLMs) such as ChatGPT to complement the predictive uncertainty computed through entropy. The acquisition function combines the weighted sum of entropy and the likelihood of the most probable explanation. In addition to the traditional cross-entropy loss, the authors introduce two additional components: an explanation generation loss and a ranking loss. The experimental results demonstrate the effectiveness of the proposed framework, showcasing its potential to deliver promising results."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Originality:  The incorporation of explanations generated by LLMs for guiding the selection of informative samples is indeed an interesting idea, even though it is not completely new. This approach is thoughtfully motivated by the principles of explanation-based teaching and learning. Leveraging textual explanations from well-trained and established LLMs, such as ChatGPT, has the potential to provide valuable additional insights that can enhance the classifier's capability to distinguish various class patterns. The experimental results further validate its effectiveness in selecting samples for labelling.\n* Clarity: In general, the paper effectively communicates its primary idea, albeit with some minor errors and issues that I will elaborate on below.\n* Significance: The presented active learning framework yields promising results when compared to various baselines, such as BALD, CAL, LC, and others. Additionally, the ablation studies effectively demonstrate the contributions of different components within the proposed framework. The qualitative analysis employing T-SNE provides some valuable insights."
            },
            "weaknesses": {
                "value": "Despite the comprehensive demonstration of the proposed framework's performance across six different text classification tasks, it is noteworthy that the chosen baseline methods appear to be somewhat outdated. Recent developments in the field of active learning, including ALPS[2], BADGE [1], WMOCU [3], SoftMoCU [4], and BEMPS [5], could have provided more up-to-date benchmarks. Furthermore, the omission of works with similar explanation-based learning concepts mentioned in the related work section raises questions about the completeness of the experimental evaluation. Taken together, these factors lead to concerns regarding the sufficiency of the experimental work in demonstrating the advantages of the proposed framework.\n\nEq (7) has two running parameters and Eq(8) has one.The authors stated that those parameters were chosen empirically based on the preliminary experiments.  However, the reviewer thinks empirically running those running parameters has an implication in its adaptation, as how sensitive of the performance of the proposed active learning framework is unknown. Thus, it would be good to study the impact of those running parameters. \n\nFurthermore, the ablation studies show that ME-Exp and w/o rank compare favourably with each other, even with XAL in some data sets. Considering the differences among the three models/variants, the review thought the second loss term in Eq(7) associated with the explanation generation might contribute substation ally to the ultimate performance difference. Adding the ablation studies to that term becomes essential together with the running parameters above. Meanwhile, there is a lack of studies on the acquisition batch size.\n\nInterestingly, the authors have not conducted a comparative analysis of the computational costs associated with evaluating the acquisition functions of different active learning schemes. It would be of practical significance to assess the computational expenses involved in these methods.\n\n\nReferences\n* [1] J. T. Ash, C. Zhang, A. Krishnamurthy, J. Langford, and A. Agar- wal, \u201cDeep batch active learning by diverse, uncertain gradient lower bounds,\u201d in Proc. 8th Int. Conf. Learn. Representations, 2020. \n* [2] \tM. Yuan, H.-T. Lin, and J. Boyd-Graber, \u201cCold-start active learning through self-supervised language modeling,\u201d in Proc. 2020 Conf. Empirical Methods Natural Lang. Process. (EMNLP), Nov. 2020, pp. 7935\u2013 7948. \n* [3] G. Zhao, E. Dougherty, B.-J. Yoon, F. Alexander, and X. Qian, \u201cUncertainty-aware active learning for optimal Bayesian classifier,\u201d in Proc. 9th Int. Conf. Learn. Representations, 2021. \n* [4] G. Zhao, E. Dougherty, B.-J. Yoon, F. J. Alexander, and X. Qian, \u201cBayesian active learning by soft mean objective cost of uncertainty,\u201d in Proc. 24th Int. Conf. Artif. Intell. Statist., vol. 130, Apr. 2021, pp. 3970\u20133978. \n* [5] W.Tan, L.Du, and W.Buntine,\u201cDiversityenhancedactivelearningwith strictly proper scoring rules,\u201d in Advances in Neural Information Processing Systems, 2021, pp.10906\u2013 10918. \n* [6] Kuhn, L., Gal, Y. and Farquhar, S., 2022, September. Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation. In\u00a0The Eleventh International Conference on Learning Representations."
            },
            "questions": {
                "value": "* There are multiple factors that contribute to the performance of the proposed XAL method. The review wondered if the authors could show the convergence analysis of the active learner. In other words, can the learner guarantee to converge to the optimal classifier, as the number of acquired samples goes to infinity?\n* The experimental results show that using the explanation score in acquiring samples can contribute to learning. What type of uncertainty does the proposed generation score capture? Is it something to do with semantic uncertainty[6]?\n* Regarding Figure 3, Should B in the right column correspond to C in the left column?\n* In Section 3.3, Should $D_u$ be $D_l$"
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Other reasons (please specify below)"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Pushing data to service, like ChatGPT, always raises concerns about data privacy. The datasets used in the paper might all be publically available datasets. However, if one would like to use the method to privacy-sensitive domains, like medical corpora, the method proposed thus cannot be used."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2565/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699153635703,
        "cdate": 1699153635703,
        "tmdate": 1699636193364,
        "mdate": 1699636193364,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XxuaVPQeio",
        "forum": "Zesag4jmPQ",
        "replyto": "Zesag4jmPQ",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2565/Reviewer_C5EW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2565/Reviewer_C5EW"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an explanation-based active learning framework for text classification tasks. The framework selects the most informative samples for annotation, and generates and scores explanations for the classifier's predictions, then it forms a learning objective which combines the classification loss, the explanation generation loss, and the explanation ranking loss. To train the decoder for explanation generation, this paper leverages LLMs to obtain golden explanations. The proposed framework is evaluated on six text classification tasks in a low-resource setting, and the results show that it outperforms basic AL methods and coreset and contrastive AL."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. This paper injects explanations to uncertainty-based AL process to prevent overconfidence and insufficient exploration.\n\n2. The paper is presented in a coherent manner and easy to follow."
            },
            "weaknesses": {
                "value": "1. My major concern is whether generating explanation is the most efficient way to use LLMs in this paper's setting. Based on the examples in Figure 3, a budget of 500 instances corresponds to 1500 explanations. If we task LLMs to generate labels, instead of explanations, within the same API calling times, we could obtain annotated data that is N times greater, where N equals the number of labels (N=3 in this example). Such an increase in annotated data could markedly enhance model performance, particularly in low-resource Active Learning (AL) scenarios.\n\n2. The first weakness also undermines the fairness of the comparison within the given data selection budget. The XAL model uses LLMs to produce high-quality explanations, incurring additional inference costs. A more compelling comparison would involve allocating an equivalent amount of LLM resources to the baseline methods for acquiring more labeled data.\n\n3. The scope of datasets evaluated in this study is somewhat narrow. The number of classes is either 2 or 3, and the training sets do not exceed 8k instances. \n\n4. This paper does not provide an analysis of the computational complexity of the proposed framework. While the paper mentions that the proposed framework requires more time and computational resources for training than encoder-only classifiers, it does not provide a detailed analysis of the computational requirements of the proposed framework."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2565/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699328876255,
        "cdate": 1699328876255,
        "tmdate": 1699636193303,
        "mdate": 1699636193303,
        "license": "CC BY 4.0",
        "version": 2
    }
]