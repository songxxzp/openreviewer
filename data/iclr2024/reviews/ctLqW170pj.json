[
    {
        "id": "zM38B0qzhU",
        "forum": "ctLqW170pj",
        "replyto": "ctLqW170pj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5856/Reviewer_DE28"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5856/Reviewer_DE28"
        ],
        "content": {
            "summary": {
                "value": "- This paper proposes a new method for unsupervised object detector pre-training. The main pipeline is in three steps: 1) finding object proposals in an unsupervised way; 2) clustering the proposals to form pseudo class labels ; 3) training an object detector using the proposals and their labels. \n\n- On the downstream object detection task, the proposed method achieved comparable performance with previous methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper demonstrates an enhanced performance on the benchmark COCO object detection test, even if the improvement is marginal.\n2. The proposed method has a good performance in data-limited scenarios, outperforming preceding methodologies substantially.\n3. The manuscript is well-written, it is easy to follow, and the technical details are well explained. \n4. The idea of generating a detection dataset and using it to pre-train a detector in an unsupervised way is interesting."
            },
            "weaknesses": {
                "value": "1. My main concern for this paper is its significance and potential impact for future works:\n    1. While the proposed method surpasses some recent methods in terms of detection AP, the advancements are quite minimal. For instance, For example, on Mask R-CNN it only outperform CutLER by 0.3 AP. (Table 1)\n    2. One anticipated advantage of unsupervised pre-training would be the ability to exponentially scale the training dataset, subsequently enhancing the model's efficacy. This paper seems to miss out on this potential. The proposed clustering of object proposals becomes increasingly complex with dataset expansion, which may not even tractable when the dataset becomes very large, i.g., web scale. \n    3. Even if the clustering challenges are addressed, the method doesn't appear to capitalize on a larger dataset. For example, when switching the training set from COCO to OpenImage, which is much larger, the model performance keeps the same. (Table 6)\n    4. he proposed multi-stage training only bring marginal improvement: increasing an extra stage of training brings less than 1.0 AP improvment. (Table 13)\n2. The novelty of this work is also limited. The shift to generating object proposals from generating from low-level features is a simple extension of previous works. Additionally, the object detector's training mechanism seems heavily reliant on pre-existing methodologies.\n3. I think the one of the intersting point of this method is its supervority on data-scarce settings (Table 4 and Table 5). However, the paper lacks in depth study about this superiority."
            },
            "questions": {
                "value": "I am wondering if the *Clustering and Classifying* paradigm can be replaced by some other methods, like contrastive learning. If this can work, it will greatly improve this work's impact."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5856/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5856/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5856/Reviewer_DE28"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5856/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698710709369,
        "cdate": 1698710709369,
        "tmdate": 1699636619692,
        "mdate": 1699636619692,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Mf9ybeVl1l",
        "forum": "ctLqW170pj",
        "replyto": "ctLqW170pj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5856/Reviewer_Yy8P"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5856/Reviewer_Yy8P"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses the challenges in object detection training, where conventional methods involve a two-phase approach: self-supervised training of the backbone followed by supervised fine-tuning using annotated data. Many existing unsupervised pretraining techniques tend to depend on low-level data, neglecting high-level class semantics, resulting in a gap between the pretraining and actual detection tasks. To tackle this issue, the authors introduce a novel framework that emphasizes semantics-based initial proposals, employs discriminative training with object pseudo-labels, and utilizes self-training. This innovative approach not only surpasses preceding techniques but also facilitates the pretraining of detectors from scratch on complex datasets, such as COCO."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. This paper includes the experiments that pre-train on COCO, which is a good exploration. When pre-trained on COCO, the proposed method outperforms the previous methods on the linear evaluation on ImagNet.\n2. The method is validated on both transformer and cnn based detectors."
            },
            "weaknesses": {
                "value": "1.\tFrom tab 7, we can see that the models pre-trained on COCO still can not outperform the models pre-trained on ImageNet, which has been shown in the previous papers. From this point, the exploration of pre-training on COCO did not bring novelty.\n2.\t\u201cUtilizing semantic information from self-supervised image encoders to produce rich object proposals and coherent pseudo-class labels\u201d has been explored in the previous papers such as [1].\n3.\tIn the abstract, the authors claimed that \u201cHowever, existing unsupervised pretraining methods typically rely on low-level information to create pseudo-proposals that the model is then trained to localize, and ignore high-level class membership.\u201dI do not agree with it. In fact, the Moco and Mocov2 address on the high-level semantic information, while the later works[2,3] focus low-level information and localization. So you can not say that the existing pretraining methods typically rely on low-level information. The challenge is to create a pre-training method that can balance both localization and classification.\n4. I am also curious about the comparison with MAE pre-training methods.\n[1] Deep Spectral Methods: A Surprisingly Strong Baseline for Unsupervised Semantic Segmentation and Localization, L. Melas-Kyriazi, C. Rupprecht, I. Laina and A. Vedaldi, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022\n[2] Fangyun Wei, Yue Gao, Zhirong Wu, Han Hu, and Stephen Lin. Aligning pretraining for detection via object-level contrastive learning. Advances in neural information processing systems.\n[3] Zhenda Xie, Yutong Lin, Zhuliang Yao, Zheng Zhang, Qi Dai, Yue Cao, and Han Hu. Selfsupervised learning with swin transformers. arXiv preprint arXiv:2105.04553, 2021c."
            },
            "questions": {
                "value": "See the weakness.\nI fail to discern how this work differs from prior efforts."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5856/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698735427436,
        "cdate": 1698735427436,
        "tmdate": 1699636619560,
        "mdate": 1699636619560,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "X2E4YKmtnk",
        "forum": "ctLqW170pj",
        "replyto": "ctLqW170pj",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5856/Reviewer_xbku"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5856/Reviewer_xbku"
        ],
        "content": {
            "summary": {
                "value": "This study proposes a new self-supervised pretraining method called SEER for object detection. SEER first generates pseudo proposals using spectral clustering of the feature map generated by a pretrained feature extractor. The generated pseudo proposals are then fed to the detector to yield an end-to-end self-supervised an object detector. The pretrained network is validated on the MS-COCO and PASCAL VOC datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The proposed framework is simple and effective. By utilizing a pretrained feature extractor to generate proposals in an unsupervised manner, this method can obtain proposals of higher quality and better semantic meaning. The proposal filtering and pseudo-class label generation also require strong engineering insights to make the pipeline work for end-to-end self-supervised object detector pretraining.\n\n- The presentation is easy to follow, and the contribution of the paper has been made clear after comparing it with existing object detector pretraining methods in its related works section.\n\n- The obtained results are competitive, as the method is able to achieve 46.7 AP using the Deformable DETR detector and 49.6 AP using the ViDT+ detector.\n\n- The evaluation on different tasks, including few-shot and semi-supervised learning, and the study of different pretraining datasets are appreciated. This helps demonstrate broader significance by investigating common interesting questions."
            },
            "weaknesses": {
                "value": "- The contributions of this work may be overstated. This paper presents SEER as a unique end-to-end object detection pretraining method that can train the backbone from scratch without freezing backbone parameters. However, previous works like JoinDet and [1] have also shown the potential ability to train the backbone without freezing, so unfreezing the backbone is not an entirely new contribution.\n    \n\n- Moreover, the ability to train the backbone of an object detector is an overstatement to some extent. As the method still requires a pretrained backbone model to generate pseudo proposals, it then leverages the generated pseudo proposals to train its backbone feature. Given that a pretrained backbone is already provided, forcing the network to retrain a backbone from scratch is not viewed as a fully end-to-end self-pretraining method.\n    \n\n- Additionally, [1] has already explored the possibility of pretraining an object detector in a fully self-supervised manner without requiring an extra pretrained backbone. When comparing [1] to this study, the pipeline of [1] seems simpler and is able to train the whole model from scratch.\n    \n\n- The pipeline relies on clustering over a pretrained network for its pseudo proposals, which inevitably introduces many hyperparameters. For example, the number of clusters for both local and global clustering is critical to the method's performance.\n    \n\nReferences:\n\n[1] G Jin, et al., Self-Supervised Pre-training with Transformers for Object Detection, Neurips workshop 2022. ([https://sslneurips22.github.io/paper_pdfs/paper_4.pdf](https://sslneurips22.github.io/paper_pdfs/paper_4.pdf))."
            },
            "questions": {
                "value": "- This study highlights its ability to train the backbone from scratch. I would like to raise the reverse question: How does model performance compare when using a frozen pretrained backbone versus training the backbone from scratch?\n    \n- The performance on semi-supervised results lags far behind recent studies in semi-supervised object detection [2]. What if SEER adopts the same architecture and compares results with traditional semi-supervised object detection using self-training?\n    \n\nReferences:\n\n[2] J. Zhang, et al. Semi-DETR: Semi-Supervised Object Detection with Detection Transformers. CVPR 2023."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5856/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5856/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5856/Reviewer_xbku"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5856/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807483237,
        "cdate": 1698807483237,
        "tmdate": 1699657791706,
        "mdate": 1699657791706,
        "license": "CC BY 4.0",
        "version": 2
    }
]