[
    {
        "id": "PSCa3Y0DlY",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2628/Reviewer_JsWa"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2628/Reviewer_JsWa"
        ],
        "forum": "dbcWzalk6G",
        "replyto": "dbcWzalk6G",
        "content": {
            "summary": {
                "value": "This paper introduces an innovative method for translating graph-structured data into a natural language that Large Language Models  (LLMs) can understand. The authors demonstrate that their proposed approach facilitates training-free graph reasoning and enables interactive graph-based reasoning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- **Innovative Graph-Syntax Tree Design**: One of the notable strengths of this paper is the introduction of the graph-syntax tree. Particularly impressive is the discretization of continuous node features. This novel approach is significant as it strikes a balance between providing informative features to LLMs while avoiding the issue of massive input tokens. Besides, this creative design facilitates feature propagation and thus significantly enhances LLMs' graph reasoning capabilities.\n\n- **Comprehensive Experimental Evaluation:** The authors demonstrated the effectiveness and flexibility of the proposed method by testing it in different scenarios. These include training-free settings with closed-source LLMs, fine-tuning with open-source LLMs, interactive graph reasoning, etc. This comprehensive evaluation underscores the practical utility and versatility of the proposed approach, making it a valuable contribution to the field."
            },
            "weaknesses": {
                "value": "- **Heavy Parameter Tuning**: The paper's heavy reliance on dataset-specific parameter tuning, as demonstrated in Table 6, raises concerns about the generalizability and effectiveness of the proposed method. Conducting ablation studies on the selection of these hyperparameters would be beneficial to determine whether the performance boost is primarily a result of heavy parameter search or the inherent design of the method itself. This clarification would help assess the true impact of the proposed method.\n\n\n- **Reliance on Domain Knowledge for Interactive Graph Reasoning**: While the paper successfully highlights the adaptability of LLMs to human feedback for interactive graph reasoning, it is important to recognize that this approach heavily depends on the quality and relevance of the human feedback. Not all tasks can be addressed using a single inductive bias, such as the PPR label. This necessitates tailoring human feedback for specific graph tasks."
            },
            "questions": {
                "value": "- Q1: Could you provide information on the number of prompts/training samples used in the experiment presented in Table 1? \n\n- Q2: When transforming the continuous features into a discrete space using K-means, it would be valuable to know the specific value of K that was used in your experiments. Additionally, could you explain the heuristic or rationale behind selecting this particular value for K?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697358985881,
        "cdate": 1697358985881,
        "tmdate": 1699636202462,
        "mdate": 1699636202462,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "zMsJRcjF1X",
        "forum": "dbcWzalk6G",
        "replyto": "dbcWzalk6G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2628/Reviewer_LfFz"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2628/Reviewer_LfFz"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the authors introduce GRAPHTEXT, a novel framework designed to bridge the gap between Large Language Models (LLMs) and graph machine learning. While LLMs have excelled in natural language understanding and reasoning, they have faced challenges in applying their capabilities to graph-structured data. GRAPHTEXT addresses this issue by translating graphs into natural language, enabling LLMs to perform graph reasoning tasks. GRAPHTEXT presents a promising approach to extend the capabilities of LLMs into the realm of graph machine learning, offering potential benefits for various applications that involve graph-structured data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper presents an elegant solution to a fundamental problem: How to derive a language for relational data. The proposed tree-based solution provides a principled way to bridge relational data and one-dimensional sequential language. This innovation has the potential to catalyze significant future research.\n\n2. GraphText equips LLMs with the ability to reason over graphs using natural language, thereby enabling interactive graph reasoning. The distinct aspects of interpretability and interactiveness of GraphText differentiate it from traditional GNNs.\n\n3. Another outstanding feature of GraphText is its training-free reasoning ability, which not only reduces the computational overhead but also delivers impressive performance, even surpassing some supervised GNNs. Such capabilities indicate great potential for real-world applications."
            },
            "weaknesses": {
                "value": "1. A comparative analysis with existing baselines is required. It would be especially beneficial to compare GraphText against other methods like GraphML and GML, which explore a similar problem\n\n2. How to construct discrete text from continuous features is not comprehensively studied. According to the hyper-parameters, the best settings are mostly based on label propagation.\n\n3. The algorithm is overall good. Nonetheless, there is a lack of time complexity analysis. I think it should be added then."
            },
            "questions": {
                "value": "See in weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2628/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2628/Reviewer_LfFz",
                    "ICLR.cc/2024/Conference/Submission2628/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697759628618,
        "cdate": 1697759628618,
        "tmdate": 1700492568679,
        "mdate": 1700492568679,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FnxHW7ViKx",
        "forum": "dbcWzalk6G",
        "replyto": "dbcWzalk6G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2628/Reviewer_ekj8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2628/Reviewer_ekj8"
        ],
        "content": {
            "summary": {
                "value": "The paper addresses an important problem of bridging the gap between LLM and GNN. A GRAPHTEXT method is introduced to construct a graph-syntax tree by incorporating node features and structural information in a graph. The graph-syntax tree is then converted to a graph text sequence, which is then processed by an LLM to treat graph-related tasks as text generation tasks. However, the experiments seem insufficient in some aspects."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Paper Strength:\n\n1. Exploring the gap between LLM and GNN is highly meaningful, as it effectively utilizes the potential of LLMs.\n\n2. The proposed graph-syntax tree is novel and conceptually sound."
            },
            "weaknesses": {
                "value": "Paper Weakness:\n\n1. The article lacks a comparison with large text-attributed graph datasets such as OGB-Arxiv, which is a commonly-used dataset extensively discussed in numerous papers regarding text-attributed graphs [1-4]. \n\n2. Regarding the experiments, I have several questions. (1) Since Wisconsin, Texas, and Cornell datasets are relatively small datasets, it would be beneficial if the authors could provide variance analysis of the results. The results on these datasets may exhibit considerable variance. (2) Moreover, Wisconsin, Texas, and Cornell datasets exhibit high heterophily. Therefore, when evaluating performance on these datasets, it is crucial to include comparisons with MLP. Based on the results from prior studies [5], it appears that GraphText may not show a significant advantage over MLP. (3) There appears to be an inconsistency in the accuracy of GraphText on Cora between Table 3 and Table 1. Could you provide an explanation for this inconsistency? (4) Providing the results under different hyper-parameters regarding the selection of text attributes and relations in Appendix A.3 would be valuable. (5) The comparison with directly utilizing LLMs to handle text attributes while ignoring the graph structure is essential.\n\n3. It would be helpful if the authors can provide a time complexity analysis for constructing the graph-syntax tree and run-time requirements. It seems that it would be costly to construct a graph-syntax tree on large-scale graphs.\n\n4. Can the proposed framework help other graph-related tasks, like link prediction, community detection?\n\n[1] Chen, Zhikai, et al. Exploring the potential of large language models (llms) in learning on graphs.\n\n[2] Duan, Keyu, et al. Simteg: A frustratingly simple approach improves textual graph learning.\n\n[3] Zhao, Jianan, et al. Learning on large-scale text-attributed graphs via variational inference.\n\n[4] He et al. Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning.\n\n[5] Zhu, Jiong, et al. Beyond homophily in graph neural networks: Current limitations and effective designs."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2628/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2628/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2628/Reviewer_ekj8"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698635442932,
        "cdate": 1698635442932,
        "tmdate": 1699636202128,
        "mdate": 1699636202128,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kJydYyCLEy",
        "forum": "dbcWzalk6G",
        "replyto": "dbcWzalk6G",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission2628/Reviewer_2ufP"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission2628/Reviewer_2ufP"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method GRAPHTEXT to solve graph tasks by LLMs. The method constructs a syntax tree to describe necessary information about the graph. Then the syntax tree is traversed to the prompt. LLMs can use the prompt to get information about the graph. The paper also proposes to use discretization methods like clustering to transform continuous feature into discrete space. Experiment results show that the method can achieve good performance in some datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Bridging the gap between graphs and LLMs is an interesting and important problem."
            },
            "weaknesses": {
                "value": "1. The performance on Cora/CiteSeer is very low, According to [1], GPT3.5 can achieve 67% accuracy on Cora with target text features, but ChatGPT performance shown in Table is much worse than it (label+feat, original). I guess it is because of the prompt used. I suggest to use a better prompt for the baseline. Besides, comparing 67% with the highest 68.3% performance in Cora, the proposed method does not provide good benefit to the task.\n2. Some datasets used (Texas, Wisconsin, Cornell) are heterophily graphs where many GNNs cannot outperform MLP. You should compare with MLP and heterophily graph methods as baselines.\n3. Some essential parts are missing in the paper. See questions.\n4. in Section 4.2, the observation 2 is confusing. Why in-context learning being good indicate that GPT-4 outperforms ChatGPT?\n\n[1] Chen, Z., Mao, H., Li, H., Jin, W., Wen, H., Wei, X., ... & Tang, J. (2023). Exploring the potential of large language models (llms) in learning on graphs. arXiv preprint arXiv:2307.03393."
            },
            "questions": {
                "value": "1. How to generate the pseudo labels in Figure 2a?  \n1. Section 4.2 uses human feedback to improve LLM prediction, can you provide the details about human feedback?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission2628/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698852460807,
        "cdate": 1698852460807,
        "tmdate": 1699636202033,
        "mdate": 1699636202033,
        "license": "CC BY 4.0",
        "version": 2
    }
]