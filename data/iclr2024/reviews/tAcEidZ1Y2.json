[
    {
        "id": "yeAwAL4jaO",
        "forum": "tAcEidZ1Y2",
        "replyto": "tAcEidZ1Y2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7561/Reviewer_FBWg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7561/Reviewer_FBWg"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a novel self-supervised MRI reconstruction paradigm in which the reconstruction process is modeled as parameter estimation, leveraging the idea of bootstrapping. To mitigate the high variance incurred by randomly generating a sample set, this paper proposes to get the distribution of the observations by mapping the observation to a virtual sample set. The authors conduct both theoretical and empirical analyses for the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea is novel and interesting. \n2. The demonstrated equivalence between the sample set bootstrapping and the re-undersampling is inspiring. \n3. The results are promising to an extent. \n4. The paper is well written."
            },
            "weaknesses": {
                "value": "1. It is highly expected that the paper includes a comparison with other typical methods for MRI reconstruction, such as [1] and [2]. Although the authors argue that deep learning models may suffer from unreliability, as the fast growing of vision transformers, their appealing performance should not be ignored. Thus, a comparison with such methods will make the results more convincing. Although these methods may not focus on zero-shot, the testing performance can still be compared. \n\n2. I think the paper lacks a discussion of the differentiability of the aggregation function h. Although the classical MSE loss is differentiable, due to the use of the aggregation function in the MSE which is adopted to train a model, the authors are highly encouraged to discuss the differentiability of the aggregation function. \n\nReference\n\n[1] https://proceedings.mlr.press/v172/lin22a/lin22a.pdf\n[2] http://proceedings.mlr.press/v139/fabian21a/fabian21a.pdf"
            },
            "questions": {
                "value": "1. Is the uncertainty in this paper partially from the resampling operation due to the use of bootstrap? More insights will be helpful. \n\n2. Although reconstruction is an important topic in MRI, are there any other reasons that make the proposed method tie to MRI reconstruction? In other words, whether the proposed method is suitable for potential reconstruction tasks in natural image domains?\n\n3. Is that possible to use the Monte Carlo method in this work?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_FBWg"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7561/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698338177834,
        "cdate": 1698338177834,
        "tmdate": 1700508260657,
        "mdate": 1700508260657,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "03dJNYZMSQ",
        "forum": "tAcEidZ1Y2",
        "replyto": "tAcEidZ1Y2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7561/Reviewer_n9iq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7561/Reviewer_n9iq"
        ],
        "content": {
            "summary": {
                "value": "This paper interprets a popular self-supervised MRI reconstruction approach: self-training with secondary undersampling [1,2], as bootstrapping. The repeated secondary undersamplings are modeled as a virtual sample set, and the secondary sampling masks are aggregated as a sampling distribution for bootstrapping. The authors then propose to use the bootstrapped error to estimate the true underlying reconstruction error. Qualitative results are shown on public MRI datasets and some correlations between estimated errors and the true underlying errors can be observed."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The problem of estimating the error in MRI reconstruction is of practical value. It links to the trustworthiness of deep learning based image reconstruction. \n \nThe authors link the secondary undersampling technique [1,2] to bootstrapping. This is a very interesting interpretation. \n\nCorrelations between estimated reconstruction errors and the true underlying reconstruction errors can be observed."
            },
            "weaknesses": {
                "value": "An important prior work [3] for modeling aleatoric and epidemic uncertainties for deep learning MRI reconstruction is missing. \n \nThe detailed approach and its mathematical framework of the prior works: self-supervised MRI reconstruction using self-training on secondary undersampling [1,2], need to be introduced in Sec. 2, as they are the basis for the entire manuscript. \n \nThe manuscript in general lacks clarity: it is difficult to find the key arguments and the core take-home information from the abstract and the introduction. \n \nThe writing style is also sloppy with key concepts arbitrarily named, used, but left unexplained. E.g., the first paragraph of Sec. 3.2: the narration is quite casual. Also, what does the paragraph under Eq. 8 mean? What does the starting paragraph in Sec. 4.3 mean? This sloppy writing may make readers who are not familiar with secondary undersampling based MRI reconstruction, extremely difficult to follow. The writing does not meet the high standards of ICLR. \n \nDespite the interesting interpretation of bootstrapping, the manuscript does not make significant theoretical/methodological breakthroughs beyond the existing secondary undersampling based MRI reconstruction approaches [1,2], not to mention that secondary undersampling is not the only approach for unsupervised/zero-shot MRI reconstruction and/or error estimation. \n \nSec. 5.2: There is a lack of quantitative evaluation of the quality of error estimations. The authors also fail to compare with the well-established Bayesian deep learning based image reconstruction [3]. Notebly, unlike the proposed approach, Bayesian deep learning allows to explicitly separate aleatoric uncertainty and epistemic uncertainty. \n \n[1] https://arxiv.org/abs/2102.07737 \n \n[2] https://www.sciencedirect.com/science/article/abs/pii/S1361841522001852 \n \n[3] https://link.springer.com/chapter/10.1007/978-3-030-00129-2_8"
            },
            "questions": {
                "value": "Is the most fundamental assumption mentioned at the starting of the manuscript: modeling U as independent Bernoulli\u2019s, unrealistic? In practice sampling patterns are subjects to the physical constraints of the gradient system of the scanners, and the resultant sampling patterns (both original and secondary) are by no means independent.  \n\nThe authors are suggested to improve the clarity of writings and illustrations."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "This study is mostly based on public datasets and the authors need to check the terms and conditions by the owners of the datasets."
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_n9iq",
                    "ICLR.cc/2024/Conference/Submission7561/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7561/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698444997016,
        "cdate": 1698444997016,
        "tmdate": 1700600818091,
        "mdate": 1700600818091,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "qPNfVKkSWQ",
        "forum": "tAcEidZ1Y2",
        "replyto": "tAcEidZ1Y2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7561/Reviewer_4bq6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7561/Reviewer_4bq6"
        ],
        "content": {
            "summary": {
                "value": "The paper titled: Self-supervision Meets BOOTSTRAP Estimation: New Paradigm for Unsupervised Reconstruction with Uncertainty quantification proposes a novel SSR methods with BootStraping for MRI reconstruction, with the ability of uncertainty estimation and quantification."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Uncertainty quantification for MRI reconstruction is an open problem, based on my knowledge, I think this paper is the first one to quantify MRI uncertainty in an unsupervised or self-supervised manner from under-sampled MRI.\n\n2. I like the idea of using BootStrap to resample the undersampling pattern, and from the Figure 7 plots, the results outperform SSDU and other SOTAs in terms of quantitative metrics.\n\n3. The algorithm is well-written and delivered."
            },
            "weaknesses": {
                "value": "1. I think one of my biggest concerns is how the proposed method compared with other existing approaches for uncertainty quantification, there have been a wide range of works on this topic, they are either sampling based [Uncertainty Quantification in Deep MRI Reconstruction] or directly estimation the absolute residual error [Rigorous Uncertainty Estimation for MRI Reconstruction], this paper lack the comparisons with other approaches, please discuss/cite them. \n\n2. For the reconstruction results, the authors only showed an PSNR and SSIM plot (Figure 7) without any visual results to inspect on the details, the only visual results is Figure 5, which also doesn't deliver much information. I think this paper demonstrates a proof-of-concept, but lack evaluations.\n\n3. What is the purpose of estimating MSE, this can be generalized to an open question, how to use the uncertainty estimation results for diagnosis, I can imagine it would be useful if we compute uncertainty in latent space, but could you elaborate on how to use uncertainty estimation for down-stream task?\n\nOne inspiring paper of quantifying theoretical results of uncertainty estimation is: [https://arxiv.org/abs/2202.05265 Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging], you maybe able to get some insights from."
            },
            "questions": {
                "value": "1. How to quantitatively evaluate the quality of your uncertainty estimation results."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_4bq6"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7561/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698704342303,
        "cdate": 1698704342303,
        "tmdate": 1699636914900,
        "mdate": 1699636914900,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "9ypWbewnFJ",
        "forum": "tAcEidZ1Y2",
        "replyto": "tAcEidZ1Y2",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7561/Reviewer_tf3c"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7561/Reviewer_tf3c"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel self-supervised approach for MRI reconstruction using bootstrap sampling. The method involves re-subsampling the undersampled k-space, reconstructing each resampled measurement, and formulating a loss function based on the reconstruction of the original measurement and the mean squared error of the resampled reconstruction."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The approach presents an innovative concept and demonstrates commendable performance. Notably, the training loss trajectory aligns consistently with that of training on self-supervised MSE, as shown in Figure 6."
            },
            "weaknesses": {
                "value": "The primary challenge with this paper lies in its presentation, making it difficult for readers to follow. Some issues include:\n- Excessive Equations and Notations: The paper is overwhelmed with equations and notations, overshadowing the fundamental concept. The core idea appears to be sampling, but the multitude of equations adds unnecessary complexity without aiding comprehension.\n- Confusing Notations: Notations like the two 'U's in Equation (6) are ambiguous and visually similar, leading to confusion and hindering understanding.\n- Unexplained Figures: Figures, such as Figure 4, lack detailed explanations, leaving readers without essential context to interpret the visual data.\n- Lack of Explaining Prior Works: Assumptions about the reader's familiarity with existing work, especially (Yaman, 2022)'s zero-slot learning, create gaps in understanding. The absence of pertinent details hampers comprehension.\n\nI suggest the authors clean up the notation, reformat this paper, add more details, and make resubmission to another conference.\n\nAnother concerns the authors might take into consider for improving this paper:\n- Unclear Significance of Variance: The paper lacks clarification on why the variance (uncertainty) of bootstrap resampled reconstruction is important. Address the relevance of this aspect, especially in comparison to uncertainty quantification for raw measurement reconstruction.\n- Theoretical Foundation: While the paper claims to provide a \"theoretical foundation,\" it predominantly relies on equations without substantive theoretical analysis. A more comprehensive exploration of the theoretical underpinnings is essential to substantiate this claim."
            },
            "questions": {
                "value": "See the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7561/Reviewer_tf3c",
                    "ICLR.cc/2024/Conference/Submission7561/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7561/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698714379543,
        "cdate": 1698714379543,
        "tmdate": 1700697074913,
        "mdate": 1700697074913,
        "license": "CC BY 4.0",
        "version": 2
    }
]