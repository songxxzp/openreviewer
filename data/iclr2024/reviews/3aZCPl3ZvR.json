[
    {
        "id": "x7rYxIHpMd",
        "forum": "3aZCPl3ZvR",
        "replyto": "3aZCPl3ZvR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8452/Reviewer_Cbxh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8452/Reviewer_Cbxh"
        ],
        "content": {
            "summary": {
                "value": "This paper analyzes the label noise robustness of the SAM (Sharpness-Aware Minimization) optimizer. SAM is known to achieve large gains in test accuracy over SGD when there is label noise, but the reasons are not well understood. The authors decompose SAM's sample-wise gradient into a logit term and Jacobian term. In linear models, they show SAM's logit term acts like an explicit reweighting that upweights low-loss (likely clean) examples. However, in neural networks, SAM's gains come primarily from regularization effects induced by the Jacobian term rather than explicit reweighting. The authors analyze the Jacobian term in a 2-layer linear network, showing it induces feature norm regularization. Adding just these implicit regularization terms recovers much of SAM's performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Provides theoretical analysis and experiments investigating an important practical phenomenon - SAM's label noise robustness.\n\n2. Careful decomposition and ablation studies (logit vs Jacobian SAM) elucidate the source of gains.\n\n3. Analysis of the Jacobian term shows it induces implicit regularization that aids robustness.\n\n4. Proposes a simplified method motivated by analysis that recovers much of SAM's gains."
            },
            "weaknesses": {
                "value": "1. Analysis limited to 2-layer linear networks, unclear if insights extend to deep nonlinear networks.\n\n2. Lacks comparison to other label noise robust methods."
            },
            "questions": {
                "value": "Does the analysis for 2-layer linear networks provide insights into deep nonlinear networks? What are the limitations?\n\nCould you compare the proposed simplified method to existing techniques like MentorNet?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8452/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698374088367,
        "cdate": 1698374088367,
        "tmdate": 1699637054440,
        "mdate": 1699637054440,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jZYU4pZxBB",
        "forum": "3aZCPl3ZvR",
        "replyto": "3aZCPl3ZvR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8452/Reviewer_WpDM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8452/Reviewer_WpDM"
        ],
        "content": {
            "summary": {
                "value": "This paper examines why SAM has better generalization performance than SGD in the presence of label noise. This phenomenon can't be explained by flatness minimization because the best performance is usually reached before the loss converges. The author decomposed SAM's robustness into two effects, one induced by the logit term and the other induced by changing network Jacobian. In the linear setting, the Jacobian is independent of weight, and the logit effect upweights the gradient of clean examples. In a neural network setting, however, the logit effect is neither necessary nor sufficient for performance improvement. The authors conclude by deriving a regularization method that is cheaper than SAM and can almost recover the benefit of SAM for experiments on CIFAR10."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* **Originality.** Although the robustness of SAM towards label noise has been discussed, this paper shows surprisingly logit effect is in fact not important for this robustness.\n\n* **Clarity.** The paper is well-written and easy to read.\n\n* **Significance.** The paper examines an interesting and important question in understanding SAM."
            },
            "weaknesses": {
                "value": "* Equation 4.5 includes a stop gradient operator in a minimization target, which, to the reviewer's knowledge, is a non-standard way of writing. The reviewer would recommend to rephrase into an update rule."
            },
            "questions": {
                "value": "* How would the regularization method perform when there is no label noise present?\n\n* Is the performance gain bring by SAM additive to current robust training algorithm or will this performance gain diminishes when more sophisticated training algorithm than SGD is used?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8452/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698498415192,
        "cdate": 1698498415192,
        "tmdate": 1699637054316,
        "mdate": 1699637054316,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "C0tntVLy4Y",
        "forum": "3aZCPl3ZvR",
        "replyto": "3aZCPl3ZvR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8452/Reviewer_M3rX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8452/Reviewer_M3rX"
        ],
        "content": {
            "summary": {
                "value": "This paper provides analysis to understand robustness of SAM to label noise through the lens of implicit regularization. The key idea is that the benefits of SAM can be primarily attributed to the network Jacobian part appearing in the sample-wise gradient. Analysis of the Jacobian term is then provided in simplified settings and empirical experiments are also provided to illustrate the general applicability of the idea (in CIFAR-10 classification)."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Provide refreshing insights on robustness of SAM to input labels through the lens of implicit regularization\n- Overall the paper is well written and is easy to follow"
            },
            "weaknesses": {
                "value": "- No analysis/empirical demonstrations on tasks other than classification are provided (e.g., regression tasks)\n- Missing discussions/analysis on how the robustness benefits depend on parameters such as number of parameters, number of training samples, learning rate , etc. (see also Questions below)\n- Missing some references in Related Work, e.g.: https://arxiv.org/abs/1609.04836, https://arxiv.org/abs/1705.10694"
            },
            "questions": {
                "value": "- How does robustness of SAM depend on the network width/number of parameters (d) and number of training samples (n)? Are there additional benefits (or otherwise) that SAM provide in the overparametrized regime (or some non-trivial regimes in terms of n and d)?\n- How does robustness of SAM in the stage of SGD training depends on the learning rate? Does the learning rate need to be small enough  to better isolate the benefits of SAM? \n- Perhaps one could investigate the above  questions in the setting of Section 3.1 and also perform empirical studies on benchmark tasks like CIFAR-10 classification?\n\n\nMinor comments:\n- typos in the formula for $\\epsilon_i$ in Eq. (2.6): $y_i \\mapsto t_i$"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8452/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698855779734,
        "cdate": 1698855779734,
        "tmdate": 1699637054208,
        "mdate": 1699637054208,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DZpPC17VYe",
        "forum": "3aZCPl3ZvR",
        "replyto": "3aZCPl3ZvR",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8452/Reviewer_ATLV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8452/Reviewer_ATLV"
        ],
        "content": {
            "summary": {
                "value": "The submission studies early stopping performance of Sharpness-Aware Minimization (SAM) under label noise. The effect of SAM on optimization is first decomposed into a logit term and a Jacobian term. In logistic regression, the Jacobian term is ineffectual and the effect is totally explained by the logit term which upweights the gradients of clean labels and delays fitting the noise. In neural networks, the logit term plays a similar role of reweighting gradients. However, here this term has little effect on the overall performance and the beneficial effects are due to the Jacobian term. A simple theoretical analysis on a two-layer linear network shows that the Jacobian term regularizes the representation and the last layer weights."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Understanding the effect of SAM is of paramount interest due to the popularity of this technique. The baselines and the experiments are designed to directly answer the questions. The theory, although rather simple, is not known nor trivial. The related work is adequately covered."
            },
            "weaknesses": {
                "value": "The following concerns are the reasons for the low score and I can raise the score if all three are addressed.\n\n**1. Little evidence on the role of early stopping.** Most of the narrative highlights that SAM is especially effective when combined with early stopping. The importance of early stopping in the analysis is emphasized throughout the paper. However, when I look at the ResNet experiments in Fig 1 and 3, early stopping seems to have little to no effect, and the difference in performance is already largely present in the final stage of training. I ask the authors to either provide more evidence on the special role of early stopping or edit the text in the abstract, introduction, and sections 5 and 6 to deemphasize the importance of early stopping. In addition, the presentation of the middle plot in Figure 1 is problematic: The caption says \"SAM fits much more clean data however before beginning to overfit to mislabeled data\" but the evidence is hard to infer from the plot. The revision should present this result more clearly.\n\n**2. Little insight on the effects of the regularization.** Section 4.2 shows that the role of the Jacobian term is similar to a certain regularization on the representation and the final layer weights. The discussion does not properly connect this regularization effect to the overall narrative about robustness to label noise and the role of early stopping. The text below the theory only briefly says \"In linear models, weight decay has somewhat equivalent effects to SAM\u2019s logit scaling in the sense that it balances the contribution of the sample-wise gradients and thus, prevents overfitting to outliers,\" but I did not find any basis for this claim, nor any discussion on the effect of regularizing the representation. \n\n**3. Inadequate empirical support.** The large-scale experiments in the submission are only on Cifar-10. This is not nearly enough for an ICLR publication and hardly supports the claims in the paper. There are many other medium- to large-scale datasets (Tiny ImageNet, ImageNet, MS-COCO, flowers102, places365, food101, etc.) and the revision should include at least one of these datasets (the new dataset should not be too similar to Cifar-10 like Cifar-100 or too small like MNIST). \n\nOther comments:\n- In regression there is a rigorous theoretical framework for studying the role of early stopping on performance under label noise [1,2]. The type of task and label noise in this framework is different from the submission and discussing these tools is outside the scope of this paper but the authors may find them interesting for future work.\n\n[1] Advani, Madhu S., Andrew M. Saxe, and Haim Sompolinsky. \"High-dimensional dynamics of generalization error in neural networks.\" Neural Networks 2020.\n\n[2] Ali, Alnur, J. Zico Kolter, and Ryan J. Tibshirani. \"A continuous-time view of early stopping for least squares regression.\" AISTATS 2019."
            },
            "questions": {
                "value": "See Weaknesses 1, 2, and 3."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8452/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699387524357,
        "cdate": 1699387524357,
        "tmdate": 1699637054086,
        "mdate": 1699637054086,
        "license": "CC BY 4.0",
        "version": 2
    }
]