[
    {
        "id": "phhgdHrdT1",
        "forum": "XHPjs3ivdV",
        "replyto": "XHPjs3ivdV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1471/Reviewer_rdp2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1471/Reviewer_rdp2"
        ],
        "content": {
            "summary": {
                "value": "This paper conducts an empirical study on various active learning algorithms on deep neural networks trained on 69 tabular classification datasets. The results show that the margin-based sampling techniques can achieve good performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper conducts extensive experiments on tabular data, the results show that the margin-based sampling techniques can achieve comparable performance. This can inspire researchers to consider this problem."
            },
            "weaknesses": {
                "value": "1. There lack of analysis about the experimental results.\n2. Actually, deep neural networks can not achieve good performance on tabular data. This may influence the fairness of the experiments."
            },
            "questions": {
                "value": "Deep neural networks can not achieve good performance on tabular data. Will this influence the fairness of the experiments? How about the performance of different sampling techniques on other data types, such as image?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1471/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698754340823,
        "cdate": 1698754340823,
        "tmdate": 1699636076279,
        "mdate": 1699636076279,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mmlSRFmuaY",
        "forum": "XHPjs3ivdV",
        "replyto": "XHPjs3ivdV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1471/Reviewer_uF25"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1471/Reviewer_uF25"
        ],
        "content": {
            "summary": {
                "value": "This paper conducts a comprehensive benchmark of many active learning techniques on tabular data. The experiments are tested on basic learners both with and without pretraining on the data. The study encompasses a substantial array of datasets sourced from OpenML. The key observations are that the classic margin-based method frequently demonstrates competitive performance, often not significantly worse than state-of-the-art approaches. Surprisingly, some methods like BALD exhibit significantly worse performance than random selection in this context."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- This paper is well-written and easy to follow.\n\n- This paper is skillfully composed and presents an extensive comparative survey that encompasses a wide range of 69 tabular datasets."
            },
            "weaknesses": {
                "value": "- The conclusion section states that margin sampling outperformed other strategies in deep neural network models. However, it is important to note that the experiment solely relied on a specific model architecture (SCARF) as the backbone. Consequently, it is recommended to diversify the model architectures used in the experiments to ensure the generalizability of the findings.\n\n- It is advisable to incorporate an ablation study and detailed analysis to assess the potential influence of pre-training backbones on the performance of various active learning strategies, including margin sampling.  This additional analysis would provide valuable insights into the influence of pre-training on the efficacy of different AL methods.\n\n- To enhance the persuasiveness of the conclusions, it is crucial to conduct more experiments encompassing a broader range of active learning settings. The current results are derived from a limited set of active learning settings, and expanding this scope would enhance the overall validity and generalizability of the study's findings.\n\n- For the results to be truly groundbreaking and instructive, the paper should strive for innovation and provide additional theoretical analysis and in-depth discussions. While the current implication is that margin sampling excels as a general active learning strategy, it would be significantly enhanced by offering a deeper understanding of why margin sampling outperforms other methods. Moreover, practical suggestions should be included to guide future research in selecting the most appropriate active learning techniques for specific scenarios."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1471/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698792687347,
        "cdate": 1698792687347,
        "tmdate": 1699636076199,
        "mdate": 1699636076199,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mdqrXurpDY",
        "forum": "XHPjs3ivdV",
        "replyto": "XHPjs3ivdV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1471/Reviewer_eSnA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1471/Reviewer_eSnA"
        ],
        "content": {
            "summary": {
                "value": "This comprehensive study analyzes the performance of a variety of AL algorithms on deep neural networks trained on 69 real-world tabular classification datasets from the OpenML-CC18 benchmark. This study finds that the classical margin sampling technique matches or outperforms all others, including current state-of-art, in a wide range of experimental settings."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Novelty: This work analyzed a diverse set of methods on 69 real-world datasets with and without pre-training under different seed set and batch sizes, which is not conducted by previous work.\nQuality: Through the experiment, this paper proposes that no method is able to outperform margin sampling in any statistically remarkable way.\nClarity: This paper describes the experiment in detail, which makes it easy to follow.\nSignificance: This work gives the conclusion that margin has no hyper-parameters and is consistently strong across all settings explored, which proves it safe to commit to margin sampling for practitioners."
            },
            "weaknesses": {
                "value": "1. The figures in this paper cannot prove the conclusion strongly, which is unclear.\n2. BADGE outperforms all methods when existing statistically remarkable difference between them, while this paper do not analyze the reason, which makes the conclusion lacking of convince."
            },
            "questions": {
                "value": "1. What is the criteria for choosing comparison methods? Margin, Entropy and Least Confidence are all based on uncertainty, which are somewhat repeatedly. As far as I know, there are other kinds of deep active learning methods. Adding them in it will improve the convince of this work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1471/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1471/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1471/Reviewer_eSnA"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1471/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698831808787,
        "cdate": 1698831808787,
        "tmdate": 1699636076131,
        "mdate": 1699636076131,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "1xuZI0G6uF",
        "forum": "XHPjs3ivdV",
        "replyto": "XHPjs3ivdV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1471/Reviewer_vfAb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1471/Reviewer_vfAb"
        ],
        "content": {
            "summary": {
                "value": "-This paper examines active learning (AL) methodologies within the context of training deep neural network on tabular datasets. It evaluates various AL algorithms on 69 real-world tabular classification datasets from the OpenML-CC18 benchmark. This evaluation encompasses considerations of varying data conditions and the implications of self-supervised model pre-training. The results of the study reveal that the conventional margin sampling technique consistently demonstrates comparable or superior performance in comparison to alternative AL methods, including the most current state-of-the-art methodologies, across a spectrum of experimental configurations. It is worth noting that margin sampling is a hyperparameter-free approach, making it a robust and advantageous choice for practitioners dealing with data labeling constraints, especially for tabular data. This paper suggests that margin sampling should be recognized as both a benchmark for research investigations and a practical strategy for practitioners."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "-The paper conducts a thorough and comprehensive study of AL algorithms using real-world tabular classification datasets. It rigorously compares various AL algorithms, encompassing both traditional and state-of-the-art approaches, against the classical margin sampling technique. This comparative analysis effectively highlights the relative strengths and weaknesses of these methods. The results contribute to a comprehensive understanding of AL method performance in various settings and may help offer valuable insights to assist researchers and practitioners in selecting the most suitable AL algorithms for their specific problems. \n\n-The finding that margin sampling consistently matches or outperforms other AL strategies across a wide range of experimental settings is also an advantage, underscoring the robust and dependable nature of the simple margin sampling method for practitioners."
            },
            "weaknesses": {
                "value": "-The paper assesses various AL algorithms within the framework of tabular datasets. It's important to note that the outcomes may not be universally applicable, as the study does not investigate their potential implications in other contexts or domains, such as image data and others, potentially limiting its broader relevance. \n\n-While the paper underscores the effectiveness of margin sampling, it falls short in offering comprehensive practical guidelines and actionable recommendations for practitioners seeking to make informed choices regarding AL algorithms in real-world applications."
            },
            "questions": {
                "value": "-How might the paper be enhanced to investigate the transferability of the studied AL algorithms to diverse domains, beyond tabular datasets, to provide a more comprehensive understanding of their applicability across different contexts? Also, it may be very helpful if the paper can provide more comprehensive and practical guidance to assist practitioners in effectively selecting and implementing AL algorithms in real-world applications."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1471/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699216006329,
        "cdate": 1699216006329,
        "tmdate": 1699636076070,
        "mdate": 1699636076070,
        "license": "CC BY 4.0",
        "version": 2
    }
]