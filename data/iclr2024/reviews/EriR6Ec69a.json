[
    {
        "id": "5YmuNuS51r",
        "forum": "EriR6Ec69a",
        "replyto": "EriR6Ec69a",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5484/Reviewer_R5dM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5484/Reviewer_R5dM"
        ],
        "content": {
            "summary": {
                "value": "Low-rank and sparse initial recurrent connectivity have been found to be two powerful priors when training RNNs to imitate an expert and later deploy them (in control tasks). This work aims to better understand the reasons behind this behavior. From a theoretical point of view, it links sparsity levels and rank at initialization with properties of the recurrent connectivity matrix. Empirically, it studies in depth how those two properties affect the dynamics of the different networks and analyzes how they affect generalization to distribution shifts."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is very well written. Theoretical results are simple and insightful for the result of the result. The empirical analysis is thoroughly done. It nicely combines analysis tools developed in dynamical systems, computational neuroscience, and deep learning to better understand the observed behavior."
            },
            "weaknesses": {
                "value": "The analysis focuses on the spectral properties of the connectivity matrix. While I can understand why this is a reasonable choice for understanding the impact on low-rank and sparsity for a single architecture, it seems limited when it comes to comparing different architectures. Ideally, one would need to study the spectral properties of the recurrent Jacobian. The recurrent Jacobian would heavily depend on the recurrence connectivity matrix for all architectures, but important differences might still remain. The paper is currently missing a discussion of this point.\n\nMinor: \n\n- It would be great to know which kind of distribution shift you are using in your experiments. I could not find this information.\n- the work of Herbert Jaeger or Wolfgang Maass is probably a better reference for echo state networks than the Deep Learning Book of Goodfellow et al."
            },
            "questions": {
                "value": "c.f. Weaknesses"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Reviewer_R5dM"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5484/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697626276833,
        "cdate": 1697626276833,
        "tmdate": 1699636560212,
        "mdate": 1699636560212,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XzuPh9Apma",
        "forum": "EriR6Ec69a",
        "replyto": "EriR6Ec69a",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5484/Reviewer_XFJy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5484/Reviewer_XFJy"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates the robustness of recurrent-based agents on non-stationary environments. In particular, the paper focuses on how sparsity and rank of different recurrent neural networks (RNNs) impact network dynamics. The paper provide theoretical insight on the property of the weight matrices in RNNs with respect to the rank and sparsity, which is used to support their empirical findings. Specifically, by considering the spectral radius and the spectral norm of the weight matrices, the paper suggests that smaller spectral radius and norm can yield better generalization under distribution shift under their experiments."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper does a thorough investigation on how the sparsity and rank of the weight matrices impact the generalization of an agent under distribution shift.\n\t- The paper focuses on many axes in the experimentation."
            },
            "weaknesses": {
                "value": "**Comments**\nAddressing the following comments will increase my score:\n- The paper is very difficult to read---while the paper provides some high-level intuition for particular quantities (e.g. low sparsity corresponding to the rate of vanishing gradient), I feel there is a big gap between every subsection. In other words, I often have trouble making the connections between the results. Furthermore, even with the large text of paragraphs, often the most important information is ambiguous, and I list them in the following:\n\t- I don't think I completely understand this experiment. What is $W_{full}$? I expected the full state-space trajectories mean running PCA on the states gathered over time, and the two former corresponding to $W_{rec}h_t, W_{inp}x_t$.\n\t- Theorem 4.1 seems to relate the weight matrices based on particular initialization schemes. I understand that in figure 4 the paper appears to agree with theorem 4.1, but I fail to understand why this theorem needs to be in the main paper as it does not explain any insight on the generalization/robustness directly.\n\t- The scale of the subplots should be consistent for easier comparison (e.g. figures 4, 5, and 6.)\n- The proof of theorem 4.1 is unclear to me. While I see that the paper uses random matrix theory to obtain result on the spectral radius and spectral norm based on the sparsity, I don't completely understand how we obtain the statements for rank $r$ for both initializations.\n- Regarding the reward ranking metric: Why not normalized return? Ranking is not too meaningful regarding how generalized the agent is---it is only relative performance. An alternative is to provide the expert performance as a baseline.\n- On figure 5, the paper only indicates the variance of the data captured by the top 5 principal components (PCs), we lose the information on the remaining variance captured by the proceeding PCs. As a result, using only the top 5 PCs to claim higher/lower effective dimensionality seems incorrect. For example, comparing two methods $M_1$ and $M_2$, if we assume that $M_1$'s top 5 PCs capture 0.7 explained variance while $M_2$'s capture 0.5, we cannot guarantee that $M_1$ is always capturing more variance as we increase the number of PCs."
            },
            "questions": {
                "value": "See comments above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Reviewer_XFJy",
                    "ICLR.cc/2024/Conference/Submission5484/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5484/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698640123784,
        "cdate": 1698640123784,
        "tmdate": 1700670559755,
        "mdate": 1700670559755,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Zli5u4SPDB",
        "forum": "EriR6Ec69a",
        "replyto": "EriR6Ec69a",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5484/Reviewer_59d7"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5484/Reviewer_59d7"
        ],
        "content": {
            "summary": {
                "value": "This paper show how the spectral radius and norm depend on sparsity and the rank of the recurrent weights, using these as a proxy to robustness and to introduce an inductive bias towards better performance for networks trained in a causality gap setting.\nBetter performance under distribution shifts is demonstrated for low-rank and sparse recurrent neural networks for networks trained on various environments under an imitation learning framework.\nFinally, it is shown that closed-form continuous-time neural networks are more amenable to a low-rank and sparse connectivity prior than the canonical recurrent architectures (vanilla RNNs and LSTMs)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Application of existing analyses to understand robustness and generalization performance to a new connectivity framework is novel. Furthermore, the analysis of  decomposing the activity into recurrent and input driven components seems novel.  The proof of the theorems are sound. All methods are well described in a way that allows for reproducible, especially if code will be made available. The main aim, to better understand why why sparse connectivity is useful in closed-loop systems is a very important problem to tackle.\nThe theoretical contributions are significant to an even broader setting than is considered in the paper."
            },
            "weaknesses": {
                "value": "Already existing analysis and tasks.\nA more comprehensive comparison to other networks trained on the tasks is missing.\n\nSome existing analyses to measure robustness, for example as the loss in performance as a function of noise level is missing.\nOverall, it is not entirely clear why some of the proxies used in the paper are sufficient to be used to asses robustness.\nThe proxies are only partially justified to be good measures of robustness. Further analyses of the dynamics, in greater detail than dimensionality, would be important to have certainty about the robustness properties of the trained networks.\nThere are many other measures for assessing the effect of perturbations on dynamics, for example Lyapunov exponents and these should be calculated for a more complete analysis.\n\nBecause there is no assessment of the learning dynamics itself or the process of learning itself the vanishing gradient analysis is a misnomer. I understand the main point of these analyses to be some memory component or transient (convergent/divergent) dynamics itself instead of it being related to the question whether the network architecture can support vanishing gradients. That said, also for vanishing gradients Lyapunov exponents are a good method for analysis.\n\nIt is unclear why a particular number of samples were considered to be sufficient. For example, why are 3 randoms sufficient to rule out that a favorable random sparse mask is not influencing the results? \nFurthermore, for such high spaces for the task, averaging over 5 perturbations seems insufficient.\n\nTheorem 1 lacks the case where the recurrent matrix does not have full connectivity to begin with and the influence of the sparsity parameter $s$ on the spectrum in that case.\n\n\\paragraph{Reward}\nIt is difficult to asses to what (good) performance the reward range in Figure 3 corresponds to. Would it be possible to show what kind of actions the highest and lowest performing networks correspond to at least? The performance of the agents is a very relative concept for which a number is not sufficient to understand what the networks actually are doing when they perform the task (supposedly well). What is the maximum number of rewards?\n\n\\paragraph{Reward ranking}\nIt seems that the reward ranking is a difficult to asses proxy for performance on the perturbed environments. For a full picture it would be better to show what amount of reward decrease the different shift cause. How do the distribution shift change the reward range for example? If all networks perform badly, but the Cfc slightly better, can we still claim that they are robust?  \nThe best performing networks on the online performance measure seem not to be performing particularly well on distribution shifted versions of the task. How does the ranking look like if the performance of the in-distribution reward is also taken into account?\nFinally, to see what kind of perturbation is most damaging for the different networks would be very insightful. Performance per perturbation type could also show what kind of robustness the different networks display.\n\nFor showing these ranking, it would be perhaps better to show the actual (average) rank as a number instead of a color coded version."
            },
            "questions": {
                "value": "About the eigenspectrum analysis.\nWhy is it the case that the closer the distribution of eigenvalues is to uniform, the more balanced the attention profile of the recurrent weights is across dimensions of the eigen-transformed?\nAnd why does this have implications for the dimensionality of recurrent state-space dynamics?\n\n\nIn Figure 5, 6, 7 etc, what does the colored region mean? Is it the variance? Is it a confidence interval? If there are only three networks per parameter setting shouldn't they all be shown?\n\nIs it really counterintuitive that with increasing sparsity, the dimensionality of the recurrent trajectories increases? Isn't sparsity just functioning as effectively increasing the rank?\n\nIt is not clear why higher dimensional dynamics would lead to more robust networks, as claimed in Figure 16. This seems to be in disagreement with the claims about constraining the network to be low-rank improved robustness in Section 4.3.\n\nHow is $\\Delta W$ calculated in Figure 7? If it is just the change of the parameter across training, the caption should mention that instead of saying that the change in weights \\emph{during} training is shown.\n\nWhat number of parameters do the different networks have? In particular, how many more parameters do Cfcs have as a result of having two vanilla RNNs in them and another gating mechanism? Be more clear about how $F$ is parameterized. How could the increase in the number of parameters explain the increase in performance?\n\n\nShouldn't a higher spectral norm contribute to higher dimensional dynamics? For a low spectral norm the network would quickly collapse onto a low-dimensional manifold. How do you explain then the RNNs have higher spectral norm and lower dimensionality in their dynamics?\n\nThe last claim of Theorem 1 is only proved for orthogonal initialization?\n\nWhat are the parameters used for the Adam optimizer? The default ones? Mention."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Reviewer_59d7"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5484/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698775909946,
        "cdate": 1698775909946,
        "tmdate": 1699636560022,
        "mdate": 1699636560022,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YnKEHSBPh4",
        "forum": "EriR6Ec69a",
        "replyto": "EriR6Ec69a",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5484/Reviewer_p6DM"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5484/Reviewer_p6DM"
        ],
        "content": {
            "summary": {
                "value": "Paper analyzes how the sparsity and rank of recurrent connectivities effects the robustness of using these models for closed-loop control."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Originality\n- The setting that this paper analyzes appears to be novel\n\nQuality\n- Paper presents a variety of in-depth analysis experiments, which seek to understand the effect of rank and sparsity on different aspects of the model"
            },
            "weaknesses": {
                "value": "- In its current form, I found it a bit challenging to parse the main contributions of the paper. I think the reason might be that Section 3 (Parameterization of Connectivity) only details the form of the proposed connectivity and the theoretical ramifications on spectral radius and norm, without any mention of the main empirical findings in the paper. It is not until section 4 (Experiments), where the paper mentions the specific findings within each subsection. Even there, I found it difficult to get concrete takeaways from the experiments, because the results are usually describe in great detail without a high-level point. For example, in Sec 4.1, it seems like low-sparsity, high-rank CfCs and LSTMs are good in online settings, and LSTMs tend to be better than CfCs and RNNs at high sparsities, and low-rank, sparsity CfCs tend to be good under distribution shift. From reading this section, it was not clear to me which configuration of sparsity, rank, and architecture was most effective? In general, I think it would be helpful to distill the main takeaways from the experiments and incorporate them into Section 3, before explaining the details of the experimental setup and results.\n- Right now, all of the neural network models used in the experiments use some kind of temporal connection. However, I believe this is not the standard architecture used when solving the tasks used in the experiments (Seaquest, halfcheetah, etc.). It would be helpful to to include an additional baseline using standard architectures (conv net, fully connect, etc) to get a sense for the return that a \"vanilla\" approach can get, and to better appreciate the significance of the robustness gains made by the additional sparsity and low rank formulations."
            },
            "questions": {
                "value": "See weaknesses section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5484/Reviewer_p6DM",
                    "ICLR.cc/2024/Conference/Submission5484/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5484/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698864509239,
        "cdate": 1698864509239,
        "tmdate": 1701040544936,
        "mdate": 1701040544936,
        "license": "CC BY 4.0",
        "version": 2
    }
]