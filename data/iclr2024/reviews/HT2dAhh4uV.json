[
    {
        "id": "eMmXvOukWV",
        "forum": "HT2dAhh4uV",
        "replyto": "HT2dAhh4uV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5301/Reviewer_H2Bo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5301/Reviewer_H2Bo"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the compositional ability in object-centric learning. Existing works mostly rely on auto-encoding training paradigm and may sacrifice the object disentanglement. While this work explicitly introduces an object composition path in addition to the original reconstruction objective, and employs generative prior to validate the rendered object compositions. The experiments show that the proposed method achieves better resutls in object disentanglement and enhances the robustness to hyper-parameters."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is well motivated. Compositionality is a vital property in object-centric perception and generation. The authors conclude the potential weakness in existing auto-encoding based object-centric learning methods and introduce an object composition path for explicit optimization on composition.\n2. The method is simple and intuitive. It uses generative prior to help validate the rendered object composition from mixed slot representations and guides the object disentanglement and composition learning.\n3. The experiments show the improvement on object-centric benchmarks. And the proposed method is robust to the number of slots, which is a significant hyper-parameter in object-centric learning and difficult to determine."
            },
            "weaknesses": {
                "value": "1. Most experiments are conducted on the synthetic objects, more experiments on realistic complex scenes, e.g., COCO, are desired.\n2. More compared methods should be included, e.g., DINOSAURE [1].\n3. There are some recent works focusing on the binding ability of the slots to specific object types or properties, e.g., [2]. Is it possible to employ the binding ability to enhance the interpretablity of slot mixing and further enahnce the composition ability?\n\n[1] Seitzer et al. Bridging the gap to real-world object-centric learning. ICLR 2023.\n[2] Jia et al. Improving Object-centric Learning with Query Optimization. ICLR 2023."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5301/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698719587456,
        "cdate": 1698719587456,
        "tmdate": 1699636530917,
        "mdate": 1699636530917,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aB1fyYZ9bM",
        "forum": "HT2dAhh4uV",
        "replyto": "HT2dAhh4uV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5301/Reviewer_f9fX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5301/Reviewer_f9fX"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a generative objective to regularize the learned representation of a Slot Attention model. In particular, the generative objective ensures that decoding a composition of slots from different images results in a realistic image. The additional regularizer trades off reconstruction quality for better compositionality of the learned representation."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The authors identify a weakness in the standard reconstruction objective of Slot Attention and similar papers: the reconstruction objective does not explicitly encourage compositionality of the learned representation. This observation calls for a generative objective that ensures that composition of slots can be decoded into realistic images. Instead of implementing this with a GAN discriminator, which would require an additional component, the authors follow the approach of Poole et al. (2022) where the diffusion model is reused as a generative prior.\n\nThe idea of using a cheap surrogate one-shot decoder to approximate an expensive denoising process is quite clever and surely helps speeding up training.\n\nThe qualitative results on compositional generation are convincing. I would like to see if the method would work on real-world images like the ones in COCO."
            },
            "weaknesses": {
                "value": "In the proposed method, the number of losses, regularizers, and training tricks to balance is high. I would appreciate a more thorough ablation study where each component is isolated and tested. The combinations in table 2 are valid but do not cover all possibilities.\n\nI would appreciate additional evaluation metrics that are not based on segmentation. Learning a good object-centric representation means much more than achieving good segmentation. It is important to show that the learned slots are useful for downstream tasks such as counting, tracking, property prediction, etc. This way the claim made in the introduction that \"[the method] significantly boosts the overall quality of object-centric representations\" can be supported. My rating on \"soundness\" would be higher if the authors had included such experiments."
            },
            "questions": {
                "value": "May I recommend a bar plot for Figure 3? The current plot based on colored Xs is quite hard to read. Moreover, a bar plot would allow to show the standard deviation of the results over multiple independent runs, which is important to strengthen the claims made in the text.\n\nCan you provide non-segmentation based evaluation metrics? They can be the same as in Jiang et al. (2023) for example.\n\nIn Jiang et al. (2023) the compositional generation appear to be much stronger that what is shown in Figure 4. It seems to me that for the proposed method the authors chose a source image where all objects are well separated and therefore the composition looks good. Whereas the segmentation in LSD and SLATE+ on the same image is poor and therefore the composed image looks bad. Can you clarify in the caption if the examples were cherry-picked? Can you find another image where all 3 methods segment correctly the objects that you want to compose? This way the comparison would be fairer.\n\nTypo: \"is not contrained to\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5301/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698790982302,
        "cdate": 1698790982302,
        "tmdate": 1699636530810,
        "mdate": 1699636530810,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ThN0XYiQqO",
        "forum": "HT2dAhh4uV",
        "replyto": "HT2dAhh4uV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5301/Reviewer_6966"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5301/Reviewer_6966"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a scheme for encouraging compositionality in slot-based Object-Centric Learning (OCL) models by introducing a compositional objective alongside the standard auto-encoding reconstruction loss. In particular, they enforce that mixing subsets of slots from two separate scenes should result in a \"valid\" image, as determined by a generative prior which is trained through the auto-encoding process - this is accomplished by using a diffusion model as the decoder. To enable fast-decoding and cheaper evaluation of gradients for the encoder through the compositional path, they also train a transformer-decoder on the autoencoding tasks.\n\nThey perform extensive experiments and ablations, demonstrating the efficacy of their method against other state-of-the art methods, both in terms of performance and robustness to hyperparameters such as slot-count and decoder size (which are sensitive in many OCL methods). To the best of my knowledge, the idea of encouraging compositionality of slots through a valid-mixing objective is novel and forms a valuable contribution to the OCL community."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper's methodology is well described with helpful figures, and the experiments are comprehensive. Notably, the experiments on parameter robustness in sec 5.2, as well as the qualitative results shown alongside experiments with slot mixing strategy in the appendices, provide a compelling case for the benefits of this method against other SoTA methods, beyond the mere improvement of performance."
            },
            "weaknesses": {
                "value": "There are no major weaknesses with the methodology or evaluations. The presentation is clear in most places, but there are many grammatical mistakes. It is recommended that these be fixed through the use of automated grammar checkers or proof-reading by a native speaker.\n\nSome minor notes on clarification:\n* On the first reading, it was not entirely clear how the one-shot decoder and diffusion decoders were being trained (i.e. whether one, or both, were being used in the auto-encoding path) - this is made clear at the start of sec 3.3 \"in auto-encoding path [...] two different decoders [...] are trained\", but it would be good to make it more explicit in prior paragraphs when the relevant decoders are introduced and their training is discussed.\n* Related to the above, it would be good to make it clear in the figure that *both* decoders are trained/used on the auto-encoding branches, for example by putting \"(both) Decoder\" on the branches"
            },
            "questions": {
                "value": "Overall the work is very interesting and comprehensively explained, and I was left only with minor questions:\n1) *Why background slots do not conflict*: Could the authors explain whether / why, if not, background slots conflict when sampling slots with the random mixing strategy? In this case 1) is there any reason to expect canonical slot ordering, such that two background slots are unlikely to be sampled or 2) any reason why if two background slots are sampled, this does not lead to invalid scenes?\n2) *On the relative contributions of Regularization+Shared Slot Initializations (Row 2) and the compositional prior (Row 1) in Table 2*: It is Interesting that Row 2, is roughly as effective as Row 1. Was there a significant difference in the qualitative behaviour of the models in these two settings; i.e. did Row 1 yield \"better\" slots, but lead to worse metrics for some other reason - or can we conclude that the bias towards compositional slot representations in both of these settings was comparably strong? (which would be somewhat surprising!). Perhaps the decoder receives a stronger learning signal in Row 2, and in Row 1 the generative prior acting by itself is constrained because the decoders don't learn as well, and so provide a weaker compositional signal?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5301/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5301/Reviewer_6966",
                    "ICLR.cc/2024/Conference/Submission5301/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5301/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698826288322,
        "cdate": 1698826288322,
        "tmdate": 1700099237401,
        "mdate": 1700099237401,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gOoTO8qUec",
        "forum": "HT2dAhh4uV",
        "replyto": "HT2dAhh4uV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5301/Reviewer_Cp4U"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5301/Reviewer_Cp4U"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new training objective that encourages learning object-centric representation by considering mixtures over objects across images, and empirically explores it in conjunction with a slot attention architecture over CLEVR-like data."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- **Evaluation**: Multiple types of experiments are conducted, including quantitative/qualitative unsupervised segmentation, ablation studies, and analysis of robustness. The approach is shown to be robust to factors such as number of slots, as well as settings of the encoder and decoder, aspects which slot attention methods are usually sensitive to.\n- **Research Context**: The authors do a good job in providing the relevant research context as well as model\u2019s preliminaries, pointing to the limitations of some of the prior works.\n- **Presentation**: The writing quality is good and the paper is clear, well-organized and easy to follow. The first parts of the model section are particularly clear, and both the diagrams and visualizations help understanding the approach and its behavior. The supplementary is also good, providing implementation details and additional quantitative and qualitative results."
            },
            "weaknesses": {
                "value": "- **Synthetic Data & Scalability**: The experiments are performed over synthetic data only. I recommend exploring scalability to real-world data too. This is especially important since it is unclear to me whether such an approach would scale well to more diverse real-world data, where there are correlations between object occurrence as well as appearance. I don\u2019t know for sure but it might be the case that for realistic data the loss could damage the model\u2019s learning compared to standard auto-encoding, by encouraging it to unlearn important object correlations. For instance, even for the images at figure 1, the lighting of the mixed objects does not fit the context, potentially making the model less aware of the impact of lighting conditions on the object\u2019s appearance. For this reason I believe it is really critical to study this objective in the context of realistic data too.\n- **Compositional Synthesis**: The results about compositional synthesis aren't the most compelling. I would like to see object mixing in cases that involve more interesting interactions among the objects (like reflection, more substantial occlusions, and matching of the appearance between the object and its environment). It does perform better than the baselines so that\u2019s still an improvment.\n- **Novelty & Related Works**: The specific proposed idea is novel, but object mixing as a form of regularization isn\u2019t. For instance,  it would be good to cite and discuss the \u201cObject Discovery with a Copy-Pasting GAN\u201d paper as a related prior work that also uses mixes over image to encourage object discovery."
            },
            "questions": {
                "value": "- **Baselines**: It would be good to also compare to a vanilla slot attention as a baseline.\n- **Slot Initialization* I didn\u2019t fully understand the intuition why a shared slot initialization should help avoiding bad mixes of objects. It seems to me that learning good combinations of objects could be achieved instead by not sharing the initialization scheme between them and letting them interact across the two images to coordinate valid object compositions. If possible please explain the initialization point further.\n- **Diffusion**: It would be helpful to make it clearer how the denoising diffusion and auto-encoding fit together in the proposed framework. \n- **Super-CLEVR**: The ARI performance drop on super-clevr is particularly large, even though multiShapenet and PTR also include objects with subparts, and the latter even includes more complicated backgrounds. Do you have an intuition of why is that the case? \n- \u201cit decompose\u201d -> \u201cit decomposes\u201d\n- \u201cemployed auto-encoding framework\u201d -> \u201cemploy an auto-encoding framework\u201d\n- \u201cas architectural/algorithmic bias\u201d -> \u201cas an architectural/algorithmic bias\u201d\n- \u201catttention\u201d -> \u201cattention\u201d\n\nOverall, while the paper is well-made, I'm in between 5 and 6 due to mentioned weaknesses above. But I'll be glad to raise my score if results will be presented over realistic data."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5301/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699483189592,
        "cdate": 1699483189592,
        "tmdate": 1699636530604,
        "mdate": 1699636530604,
        "license": "CC BY 4.0",
        "version": 2
    }
]