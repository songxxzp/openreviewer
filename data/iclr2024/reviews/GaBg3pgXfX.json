[
    {
        "id": "cHAHMrGZLQ",
        "forum": "GaBg3pgXfX",
        "replyto": "GaBg3pgXfX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5274/Reviewer_T1Mh"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5274/Reviewer_T1Mh"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a formalization of music using probabilistic And-or Grammar. Compared to former music analysis model (e.g., GTTM), the proposed method considers more general music data types and formalizes both lower and higher music concepts. The probabilistic model can be learned from data and music is generated via Metropolis-Hastings algorithm."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "Originality: There is only a few formal methods for music and even fewer that are ready to be applied for automatic music generation. With this regard, the paper makes an attempt propose a solution to this problem. The music grammar has enough complexity to handle some non-trivial music concepts including both local music relations and long-term music structure."
            },
            "weaknesses": {
                "value": "It is a challenging task to put everything in one research paper including introduction of a formal approach, learning method, inference method and experiments. The approach introduced in this paper is intriguing, but still lacks some crucial material for readers to capture the main idea and the details.\n\n1. The workflow of this study could be clearer? Is the goal of this study music analysis or music generation? Is the generation conditioned on the learned analysis? What music knowledge is assumed and what is not in analysis and generation? What are the major differences compared to existing generation methods, PCFG approach and GTTM?\n2. The images in this paper could be clearer. Figure 1 is crucial for readers to understand the defined grammar. However, the defined edge types are not easily recognizable and lacks sufficient explanation about how is the graph achieved. It is even necessary to try to show the graph at multiple levels separately using multiple figures. Figure 2 is not readable. \n3. Section 1 and 2 points the drawbacks of existing works. However, the highlight of this work and the workflow of the proposed method is missing. \n4. From section 3 to 6, what are the intuition of the proposed method? Try to use intuitive ways to briefly introduce your results and shows the methods at certain level of abstraction. All details can be systematically summarized in the appendix.\n5. For section 7, it is not effective to directly compare the methods with deep generative models. The proposed method is almost rule-based (with learnable parameter) and other methods are data-driven. With only three music samples, it is not convincing to say if the model can be generalized to the scenario where there are more data samples and by various composers in different styles. The attributes in Table 1 are not well-introduced and the scores might not be significant. It would be better if the study first present some generation result for analysis and show the learned concept or pattern. Then, evaluate the generative results objectively or subjectively on different learning settings to show generation quality and generalizability on different datasets."
            },
            "questions": {
                "value": "The questions are related to the weakness section and summarized as follows:\n\nQ1: Could you introduce the workflow of the study in a clearer way?\n\nQ2:  Could you show examples of defined music AOG (e.g., like Figure 1) in a clearer way? What are defined and what are learned?\n\nQ3: Could you provide an example of the learning and generation process of the model if possible?\n\nQ4: Could you explain more on the generalizability of the method on different music corpus?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5274/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698163938915,
        "cdate": 1698163938915,
        "tmdate": 1699636527287,
        "mdate": 1699636527287,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ADKomLYQbY",
        "forum": "GaBg3pgXfX",
        "replyto": "GaBg3pgXfX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5274/Reviewer_kK8y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5274/Reviewer_kK8y"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes MusicAOG, a novel graph-based representation of symbolic music together with a probabilistic model for sampling a musical piece over the graph. The graph representation copes with hierarchical natures of music and leverages structural nodes, textural nodes, and various types of relations (edges) to represent music in a structured manner. The probabilistic model leverages a set of statistical observational constraints and is optimized via the minimax entropy principle. The subjective evaluation demonstrates a superior musicality compared to baseline models with deeper architectures. A sampled sheet music in Bach style also showcases a decent quality."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The hierarchical graph representation of musicAOG is intuitive and gives much insight from a musicology point of view. Specifically, the division of structural and textural functions reflects human perception of music at different cognitive scales. The application of and-or graph also seems a good fit to describe the diverse possibilities of development of a piece of music.\n\n* The energy-based model is lightweight and flexible for few-shot learning. In this paper, a decent sample result is showcased with a training set of 3 annotated Bach chorales."
            },
            "weaknesses": {
                "value": "* The paper highlights adopting Metropolis-Hastings sampling to enhance fine-grained control of music generation. However, the reviewer questions the extent of this control. The only controllable parameter, $T$, which encourages more varying and creative results, seems insufficient for fine-grained control, and the concrete way of variation seems not controllable.\n\n* MusicAOG is a probabilistic graph model that can learn from a few annotated pieces and then leverage the learned probabilities to sample a new piece. Considering that different styles/genres of music may underlie varied probability distributions, it makes sense to train the MusicAOG model on a very specific style (like Bach chorales in this paper) and fit that style only. Yet, this may also imply a limited potential for a diverse generative capacity. Considering that Bach chorale is a relatively straightforward form of music, it is not surprising that MusicAOG outperforms those baselines with deeper architectures. On the other hand, Music AOG cannot be trained over large and diverse music corpus in a self- or unsupervised manner as those baselines can do. Hence it is questionable if it can cater to more diversified genres and more complex music forms."
            },
            "questions": {
                "value": "* The metrical tree in Figure 1 is somewhat hard to parse. How do the synchronization nodes relate to the event tree? And what do the colours in the metrical nodes refer to?\n\n* In page 2 Line 2 \"$X$ represents the set of vertices\", should this be \"set of attributes\"?\n\n* It is not particularly clear with what the rules $\\mathcal{R}=\\\\{ \\gamma\\_1, \\cdots, \\gamma\\_k \\\\}$ refer to and how they function. Are $\\gamma_i$ associated with parameters of the multinomial distribution in the probability model? Are their values learned by inferring from the Lagrange multipliers $\\lambda\\_\\alpha$?\n\n* In Section 6.1 \"Once all children of a particular node are sampled, a random selection of two distinct child nodes is made, establishing a variation relation $E_{\\mathrm{var}}$ between them.\" What is the purpose of this operation? The reviewer was considering that the model should be able to learn to sample a variation of a previous period/section node by itself."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Reviewer_kK8y"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5274/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698490786518,
        "cdate": 1698490786518,
        "tmdate": 1699636527198,
        "mdate": 1699636527198,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RQBaR4VWW7",
        "forum": "GaBg3pgXfX",
        "replyto": "GaBg3pgXfX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5274/Reviewer_swR4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5274/Reviewer_swR4"
        ],
        "content": {
            "summary": {
                "value": "This paper presents MusicAOG, a hierarchical graph representation for modeling symbolic music. The authors extensively detail how the MusicAOG and parse graphs are constructed, and demonstrate their method against state of the art generative models for the music generation task."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- The authors present an extensive discussion of the proposed method, going in considerable depth as to how the MusicAOG and parse graphs are constructed.\n- The relative efficiency of their method (in terms of number of parameters) against current deep learning-based methods is a clear strength of the model."
            },
            "weaknesses": {
                "value": "- My biggest concern is the lack of generalizability of the present method. As the authors note that extensive human labeling is needed to create the MusicAOG for even one score, it is hard to imagine how usable the present method would be in large scale deployable settings.\n- The evaluation section is relatively weak, as the focus on only a handful of example pieces calls into question how extrapolatable the authors' claims are. I think an overabundance of the paper is dedicated to explaining the framework for MusicAOG, which while is useful, could be traded for a more thorough and extensive evaluation.\n- The clarity of the overall paper could be improved, as it is relatively hard to follow along the overall flow during the methods section."
            },
            "questions": {
                "value": "Most concerns were addressed above. While the proposed framework is novel, it is hard to assess its performance or its generalizability from the present work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Reviewer_swR4"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5274/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698729421625,
        "cdate": 1698729421625,
        "tmdate": 1699636527016,
        "mdate": 1699636527016,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "AeMHR8PEiI",
        "forum": "GaBg3pgXfX",
        "replyto": "GaBg3pgXfX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5274/Reviewer_296y"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5274/Reviewer_296y"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a generative of model of symbolic music based on many cost (energy) functions. The proposed method is based on the framework of And-Or Graph (AOG), adn the authors extended the AOG to be suitable for symbolic music data.\nAlthough the size of experiment is not large enough, the evaluation results shows that the proposed method outperforms existing methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The method proposed seems moderately original.\nThe experiment, albeit the size is limited, shows that the performance is better than existing methods.\nThe description of this methodology appears to be generally well structured and clear. (However, there are so many elements involved that it does not seem easy to comprehensively and correctly understand the specifics regarding all of these numerous elements. There are too many symbols defined to follow the discussion quickly.)\nThe authors claim that their proposed method is so comprehensive that it can represent most music in existence, and indeed, the model appears to be that general. It is important to note that the model is not dependent on Western tonal music models, which is an important aspect of symbolic music models."
            },
            "weaknesses": {
                "value": "- It appears to have fewer references than a typical ICLR empirical paper. For example, I think that there are various studies that should be included as references for GTTM, such as some of parsers (e.g. by Hamanaka) and some of applications, not only the original book. It may not be directly related to the discussion in this paper, but it would be easier to understand the research background if attention is paid to such peripheral discussions.\n- The size of experiment is limited. Only three pieces by Bach were examined. I think the number could be increased more. The use of works by more diverse composers other than Bach and Schumann would also make this paper more compelling. Other polyphonic works including some of major composers like Mozart, Beethoven, Bruckner, Schoenberg, etc. and, many polyphonic choral works from the Renaissance periods, and some of academic composers in modern era. There are probably many composers worth considering. \n- Although they say it can be used for music from other cultures, the only specific music shown is classical Chinese music, which is still unsatisfactory in quantity.\n- It is not clear enough what is essentially different from the existing symbolic music models."
            },
            "questions": {
                "value": "- The title of this paper calls it an energy-based model, and it is indeed an energy-based model since it uses the Boltzmann/Gibbs distribution. However, calling it \"energy-based\" simply because various cost functions are placed in the upper right corner of the exponential seems a bit misleading. Of course, logically, it is not wrong, but if I were the author I would not particularly mention such models energy-based, because it is just a common sense.\n- The part where the theory of the maximum entropy method is written is just a decorative description of the known theory, and does not seem to be a particularly new discussion. I feel that a more substantive description could be made without being too formal.\n- When I encountered the terms \"and-node\" and \"or-node\" in the text, I often feel a little confused because they often look like ordinary conjunction words. I think it would be easier to read if they were italicized like *and*-node, *or*-node, or replaced with symbols like $\\wedge$-node, $\\vee$-node.\n- The figures are too small and I have to enlarge them every time to see what is written. I think it would be better to make figures larger."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5274/Reviewer_296y"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5274/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698912972654,
        "cdate": 1698912972654,
        "tmdate": 1699636526936,
        "mdate": 1699636526936,
        "license": "CC BY 4.0",
        "version": 2
    }
]