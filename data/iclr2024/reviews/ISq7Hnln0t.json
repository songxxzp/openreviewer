[
    {
        "id": "7XSpKqYBCN",
        "forum": "ISq7Hnln0t",
        "replyto": "ISq7Hnln0t",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9403/Reviewer_K3ep"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9403/Reviewer_K3ep"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on the adversarial robustness of the Segment Anything Model (SAM) in the context of computer vision. The authors investigate the possibility of attacking SAM using a single image-agnostic Universal Adversarial Perturbation (UAP), which can mislead SAM into predicting invalid masks for most, if not all, images. They propose a novel perturbation-centric framework that leverages self-supervised contrastive learning (CL) to generate UAPs effectively."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The authors are working on a very cutting-edge problem, exploring whether generalized adversarial attacks can be made against segmented large model SAMs."
            },
            "weaknesses": {
                "value": "1. The authors' approach is not general enough for SAM only in my opinion, especially nowadays there are a lot of variants of SAM and similar generalized segmentation large models like HQ-SAM [1], Semantic-SAM [2], and SEEM [3]. The authors should study attacking segmentation large models, not only SAM.\n2. The author didn't quote the reference correctly, all of them are \\citet, while some places should be \\citep. \n3. Multi-modal prompts are not only point and bbox but also text. Both SAM and SEEM [3] can accept text prompts and the author did not address this aspect of the attack.\n\nReferences\n\n[1] Ke, L., Ye, M., Danelljan, M., Liu, Y., Tai, Y. W., Tang, C. K., & Yu, F. (2023). Segment Anything in High Quality. NeurIPS 2023.\n\n[2] Li, Feng and Zhang, Hao and Sun, Peize and Zou, Xueyan and Liu, Shilong and Yang, Jianwei and Li, Chunyuan and Zhang, Lei and Gao, Jianfeng. Semantic-SAM: Segment and Recognize Anything at Any Granularity. arXiv preprint arXiv:2307.04767.\n\n[3] Xueyan Zou*, Jianwei Yang*, Hao Zhang*, Feng Li*, Linjie Li, Jianfeng Wang, Lijuan Wang, Jianfeng Gao^, Yong Jae Lee. SEEM: Segment Everything Everywhere All at Once. NeurIPS 2023."
            },
            "questions": {
                "value": "The author's experimental section is very inadequate. Why are there no comparisons with other attack methods and against previous classical segmentation models\uff1f"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "None"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9403/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762315726,
        "cdate": 1698762315726,
        "tmdate": 1699637185267,
        "mdate": 1699637185267,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "t4wDP5YqX3",
        "forum": "ISq7Hnln0t",
        "replyto": "ISq7Hnln0t",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9403/Reviewer_HSyT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9403/Reviewer_HSyT"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a universal adversarial attack against the SAM model. The underlying motivation of this paper is straightforward. However, by simply extending the image-dependent attacks for universal adversarial perturbation, the results are not as good as reported. Instead, this paper presents a new method for the UAP problem against SAM using the contrastive learning perspective. The proposed method is more effective than the baseline method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.Fortunately, this paper is not simply extending traditional UAP methods to SAM. The newly proposed method based on contrastive learning is more effective than a direct extension of existing methods. This helps a lot in assessing the novelty of the paper."
            },
            "weaknesses": {
                "value": "1.[minor] There are some typesetting issues in the \\cite formats. Please carefully read the template instructions and use \\citep or \\citet instead. The formatting issue makes the paper difficult to read when printed, especially the paragraphs with dense citations.\n\n2.[minor, defense, ethics] Discussion on how to improve SAM robustness is missing. Although not required, I still want to see some discussions on how we can improve the adversarial robustness of SAM, especially from the unique experience of the proposed UAP. I think there are a couple of references when discussing this. For reference, \"On the Robustness of Segment Anything\" (https://arxiv.org/pdf/2305.16220.pdf) analyzes the adversarial robustness of SAM. \"Enhancing Adversarial Robustness for Deep Metric Learning\" (https://openaccess.thecvf.com/content/CVPR2022/html/Zhou_Enhancing_Adversarial_Robustness_for_Deep_Metric_Learning_CVPR_2022_paper.html) presents defense methods for deep metric learning, which is the supervised version of contrastive learning and also involve anchor, positive, negative samples. Moreover, the proposed method resembles \"finding a universal visual prompt (perturbation) that can reduce the mIoU\". Is it possible to find a \"universal visual prompt (perturbation)\" that makes SAM more adversarially robust? Those discussions are suggested because, after all, attacks will become robustness evaluation metrics eventually.\n\n3.[important, transferability across prompt type] According to last paragraph in section 3, during evaluation, point prompts are used by default for quantitative evaluations. Is the UAP created under point prompts still effective under other types of SAM prompts? We can never assume the user to stick at one single prompt type. Visualizations for box prompts in section 5.2 without quantitative results are insufficient and not convincing enough at this point. A true \"universal\" perturbation should not build any correlation with a prompt type. Namely, in the context of SAM, image-agnostic is no longer sufficient for being \"universal\". It has to be prompt-agnostic as well.\n\n4.[evaluation dataset size] According to the last paragraph in section 3, only 100 images are used for evaluating the proposed method, which does not seem sufficient. UAP evaluation should not be slow as it is merely applying UAP to the image and doing the forward pass. It is suggested to increase the number of test images and additionally report the error bar to make sure the performance is less affected by the bias of the sampled dataset. SA-1B consists of 11M dimages and 1.1B high-quality segmentation masks. The 100 subset is really too small.\n\n5.[clarify, figure] The core formulation of this paper is Eq. 3. To ease reading and understanding, please consider adding the mathematical notations in Figure 1.\n\n6.[important, cost] It would be good to know how much the computational cost is for the proposed method, compared to image-dependent ones. This is because, the higher the attack cost is, the less likely an attacker in practice will adopt it. Hence, attacks with higher costs imply lower practical security risk. This is one of the reasons why I said attacks will eventually serve as robustness metrics. If the authors tend to write the paper from the attack side, then attack cost is important information. If the authors tend to write the paper from the defense side, the robustness discussion should not be absent. The current draft contains neither of them."
            },
            "questions": {
                "value": "See weaknesses. I'll consider changing my rating based on the author's response on weaknesses marked as \"important\"."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9403/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698769160492,
        "cdate": 1698769160492,
        "tmdate": 1699637185156,
        "mdate": 1699637185156,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "8VC4gv1kJh",
        "forum": "ISq7Hnln0t",
        "replyto": "ISq7Hnln0t",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission9403/Reviewer_8LBE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission9403/Reviewer_8LBE"
        ],
        "content": {
            "summary": {
                "value": "This paper explores the problem of creating Universal Adversarial Perturbation (UAPs) for SAM in-order to disrupt its mask prediction ability."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea of creating UAPs for SAM is interesting."
            },
            "weaknesses": {
                "value": "- Table 1 is a known phenomenon (Moosavi-Dezfooli et al. (2017a)). I do not see the relevance of this in the paper.\n\n- The idea to increase the strength of the perturbations using contrastive loss has also been explored in works like [A, B]. The only difference I observe is the positive pair chosen in the proposed method. \n\n- With the above point, this also explains the phenomenon of using unrelated natural images yield better results, also observed in [B] (where unrelated natural image patches are compared in the CL).\n\n- The proposed method is severely lacking in terms of comparisons to prior works that attack dense predictions tasks.\n\n[A] GAMA: Generative Adversarial Multi-Object Scene Attacks, NeurIPS 2022\n\n[B] Leveraging Local Patch Differences in Multi-Object Scenes for Generative Adversarial Attacks, WACV 2023"
            },
            "questions": {
                "value": "None."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission9403/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698954885628,
        "cdate": 1698954885628,
        "tmdate": 1699637185062,
        "mdate": 1699637185062,
        "license": "CC BY 4.0",
        "version": 2
    }
]