[
    {
        "id": "2sYgABzjXe",
        "forum": "WrBxRtGNLH",
        "replyto": "WrBxRtGNLH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1703/Reviewer_Wbn8"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1703/Reviewer_Wbn8"
        ],
        "content": {
            "summary": {
                "value": "The paper proposed an adjusted nonparametric estimator that handles the problem of covariate shift. The new estimator is shown to outperform the estimator without adjustment. Specifically, this paper presents theoretical upper bound for the adjusted estimator, which differ from the bound of the un-adjusted estimator by a factor that is generally less than one, whose magnitude depends on the smoothness of the function to be estimated and the dimension of the covariate."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ Careful mathematical analysis\n+ The estimator looks novel"
            },
            "weaknesses": {
                "value": "- No empirical analysis. Although this paper is highly mathematical, it could have showcased the proposed estimator\u2019s performance with some empirical experiments. A paper without any empirical analysis is probably uncommon for a conference like ICLR"
            },
            "questions": {
                "value": "1. The main estimator (2.10) is under the assumption that the data used to estimate the density ratio are independent from the data used to estimator the regression function $f$. Another estimator, perhaps more natural, is to estimate the density ratio and the regression function $f$ using \u201cthe same\u201d $X$. That is, $\\{X_i^\\mu\\}_i = \\{X_i^P\\}_i$. Could the current theory be modified to analyze the estimator under this setting?\n\n2. [Minor] Some notations are not defined: Notations like dimensionality $d$, functional class $\\mathcal H$ should have been defined where they first appear rather.\n\n(1) What is the function class $\\mathcal L$ for $u$ in Eq. (2.6).\n\n(2) Lemma 2.1 and Remark 2.2 should be existing results? Please include reference for them.\n\n3. The rate in Theorem 3.4 v.s. Theorem 3.8: from a bias variance decomposition perspective, is the convergence rate difference in the two theorems main due to the variance part? I would guess the mean of the estimators, reweighted or not, are the same."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1703/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698615636413,
        "cdate": 1698615636413,
        "tmdate": 1699636098784,
        "mdate": 1699636098784,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "fWQQsAEXQ2",
        "forum": "WrBxRtGNLH",
        "replyto": "WrBxRtGNLH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1703/Reviewer_GV9c"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1703/Reviewer_GV9c"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to tackle the challenges arising from distribution mismatches in deep nonparametric regression. To address this, the authors introduce a two-stage pre-training reweighted framework that utilizes deep ReLU neural networks. They conduct a rigorous analysis of the convergence rates for three estimators: unweighted, reweighted, and pre-training reweighted. The analysis emphasizes the importance of the density ratio reweighting strategy in mitigating the impact of covariate shift."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. By incorporating deep ReLU neural networks, the authors provide a novel methodology that can effectively handle covariate shift scenarios.\n\n2. The study establishes fast convergence rates, indicating efficient learning and improved estimation performance.\n\n3. The paper sheds light on the significance of the density-ratio reweighting strategy."
            },
            "weaknesses": {
                "value": "The paper is technically sound, but the limitations and drawback of the proposed methods are not clearly stated. A more comprehensive and detailed comparison between the proposed method and alternative approaches is necessary to provide a thorough evaluation."
            },
            "questions": {
                "value": "1. Assumption 2 seems to be a little bit strong. Is it possible to weaken it to make it more applicable? When considering $\\Lambda$ as a finite constant, it can be observed that the convergence rates for the three different algorithms are equivalent.\n\n2. Do the convergence rates achieve minimax optimality with respect to the parameter $\\Lambda$?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1703/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698831253433,
        "cdate": 1698831253433,
        "tmdate": 1699636098694,
        "mdate": 1699636098694,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "XhnGWEAPxk",
        "forum": "WrBxRtGNLH",
        "replyto": "WrBxRtGNLH",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1703/Reviewer_FH47"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1703/Reviewer_FH47"
        ],
        "content": {
            "summary": {
                "value": "This paper proposed some training schemes to deal with the covariate shift problem in deep learning, including re-weighted training and pre-training. Theoretically, convergence rates were derived."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "Provided detailed mathematical derivations, and showed seemingly correct convergence rates. The analysis is based on ReLU neural networks."
            },
            "weaknesses": {
                "value": "1. The settings are restrictive, such as the accessibility to testing data (even without labels), and the bounded density ratio. Some papers reviewed did consider unknown testing distributions (no accessibility to testing data), such as Duchi & Namkoong (2021), Krueger et al. (2021), and Xu et al. (2022). Some others did consider unbounded density ratio, such as Ma et al. (2023).\n\n2. There are no experimental studies. I know that some statistical papers have no experimental studies, but as a machine learning researcher, I think it is important to show that the methodology really works and to show the issues one may encounter in practice. The paper stated that it can offer guidance for practitioners."
            },
            "questions": {
                "value": "1. Because the paper assumed the accessibility to testing data without labels, the problem now becomes one type of domain adaptation. What is the advantage of such a methodology over popular domain adaptation methodologies?\n\n2. Sun et al. (2011) was a much earlier work that adopted re-weighting samples. What is the difference from their method? Can the performance be compared?\n\n3. I appreciate that the theoretical results with heavy mathematics are derived, but the paper can benefit from both simulation and empirical studies."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1703/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699244314061,
        "cdate": 1699244314061,
        "tmdate": 1699636098629,
        "mdate": 1699636098629,
        "license": "CC BY 4.0",
        "version": 2
    }
]