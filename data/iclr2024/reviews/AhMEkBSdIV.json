[
    {
        "id": "3XPvPdZSY3",
        "forum": "AhMEkBSdIV",
        "replyto": "AhMEkBSdIV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4697/Reviewer_CuPJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4697/Reviewer_CuPJ"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on addressing the challenge of assessing model generalization under out-of-distribution conditions. They reintroduce the Least Common Ancestor (LCA) distance. Particularly, they utilize the LCA to measure the taxonomic distance between labels and predictions, presenting it as a benchmark for model generalization. In the experiments, the proposed method is evaluated on multiple datasets."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "It is interesting to address the challenge of assessing model generalization under out-of-distribution conditions."
            },
            "weaknesses": {
                "value": "1. The Introduction Section is not clear. The authors indicate that most methods involve modeling correlations with in-domain accuracy or agreement. And many studies evaluate generalization on OOD datasets that feature limited visual shifts. These interpretations are very unclear. I am not clear the concrete meaning. I recommend the authors modify their paper carefully.\n\n2. The authors indicate that to address the analyzed issues, they introduce a method to benchmark model generalization, i.e., using the taxonomy loss. Firstly, the authors do not interpret whether the research is meaningful clearly. Secondly, the authors do not sufficiently introduce the advantages of the taxonomy loss. I recommend the authors draw a figure to clearly describe the motivation.\n\n3. In Table 1, the evaluated methods are somewhat old. The authors should verify the effectiveness of the proposed method on more state-of-the-art methods, e.g., the works from CVPR 2023, ICLR 2023. Meanwhile, the experiments are somewhat unclear. The authors only evaluate the classification performance. I recommend the authors evaluate the proposed method on other tasks, e.g., object detection and semantic segmentation. Finally, for Fig. 1, the authors should give more interpretations."
            },
            "questions": {
                "value": "See Weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4697/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697530643166,
        "cdate": 1697530643166,
        "tmdate": 1699636451281,
        "mdate": 1699636451281,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HGpIOapkaD",
        "forum": "AhMEkBSdIV",
        "replyto": "AhMEkBSdIV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4697/Reviewer_r8af"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4697/Reviewer_r8af"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the Least Common Ancestor (LCA) distance via the WordNet hierarchy is employed to measure the taxonomic distance between labels and predictions, utilizing it as a benchmark for model generalization. Extensive experiments are performed on model evaluation, including vision-only and vision-language models on natural distribution shift datasets. A strong linear correlation is observed between in-domain ImageNet LCA scores and out-of-domain (OOD) Top1 performance across many variants of ImageNet."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "A thorough experimental analysis of the relationship between Out-of-Distribution (OOD) detection performance and Least Common Ancestor (LCA) distance for image classifiers is provided in this paper. The following are key strengths of the work:\n\n(1) Experiments are conducted on a diverse set of neural network architectures, including ResNet, VGG, EfficientNet, Vision Transformer (ViT), and Vision-Language Models (VLMs), enabling conclusions that potentially generalize across problem domains. The rigor and comprehensiveness of the methodology are underscored by the scale of experiments, involving up to 75 network variants.\n\n(2) A major point about this submission is the analysis that demonstrates a correlation between OOD detection performance and LCA distances in the classifier. For instance, it is quantitatively shown how images from OOD datasets with more distant LCA relationships to the training data tend to be easier to detect as anomalies. The intuitive justification provided is that greater separation between the semantics of the origin dataset and OOD dataset in the hierarchical LCA structure leads to more separable distributions."
            },
            "weaknesses": {
                "value": "Major:\n\n(1) The paper does not evaluate multiple OOD scoring methods like energy scores[1], ODIN[2], Mahalanobis distance[3], and ReAct[4], which would have provided insights into the validity of the key conclusions across different anomaly scoring approaches. The interaction between the choice of scoring method and LCA distance remains unclear. Understanding how these scoring methods affect OOD performance from the perspective of the LCA distance is important. It should be noted that the calculation of this LCA distance is limited to variants of ImageNet considering the WordNet hierarchy used.\n\n(2) The claim is made that the findings offer \"invaluable insights and actionable techniques\" to enhance robustness and generalization. However, no concrete solutions leveraging the LCA distance are proposed or analyzed. Further theoretical or empirical analysis that establishes a connection between these insights and improved generalization would be beneficial.\n\n\nMinor:\n\n\u201cGiven two classes, y (the ground truth class) and y\u2032, we define the LCA distance according to (Bertinetto et al., 2020) as lcad(y\u2032, y) := f(y) \u2212 f(lca(y, y\u2032), where f(y) \u2265 f(lca(y, y\u2032) and\nlca((y\u2032, y) denotes\u2026\u201d All formulations lose the right brackets.\n\n\u201cAs highlighted in Fig 1 (indicated in red), when adhering to \u2019accuracy on the line\u2019,\u201d Wrong quotes.\n\nIn summary, the rigorous experiments and novel analysis of OOD detection vs. LCA distance are valuable contributions, but additional evaluation of alternative scoring methods and practical applications of the findings could further strengthen the work.\n\n\n[1] Liu, Weitang, et al. \"Energy-based out-of-distribution detection.\" Advances in neural information processing systems 33 (2020): 21464-21475.\n\n[2] Liang, Shiyu, Yixuan Li, and Rayadurgam Srikant. \"Enhancing the reliability of out-of-distribution image detection in neural networks.\" ICLR 2018.\n\n[3] Ren, Jie, et al. \"A simple fix to mahalanobis distance for improving near-ood detection.\" arXiv preprint arXiv:2106.09022 (2021).\n\n[4] Sun, Yiyou, Chuan Guo, and Yixuan Li. \"React: Out-of-distribution detection with rectified activations.\" Advances in Neural Information Processing Systems 34 (2021): 144-157."
            },
            "questions": {
                "value": "Please see the weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4697/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698770337719,
        "cdate": 1698770337719,
        "tmdate": 1699636451208,
        "mdate": 1699636451208,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RCxriyCuW5",
        "forum": "AhMEkBSdIV",
        "replyto": "AhMEkBSdIV",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4697/Reviewer_5fCB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4697/Reviewer_5fCB"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on evaluating the Out-of-Distribution (OOD) generalization by using Least Common Ancestor (LCA) distance based on the WordNet hierarchy. LCA measures the taxonomic distance between labels and predictions, and the paper shows that LCA is a better measure of OOD generalization than top-1 accuracy (when both LCA and top-1 accuracy are computed on in-domain data). Intuitively, LCA is able to better evaluate how well a model has learned semantic knowledge of the classes (since lower LCA indicates that the model\u2019s wrong predictions are semantically closer to the true class). This enables LCA to be a better measure of OOD performance compared to top-1 accuracy which only considers whether the prediction is correct or not. Specifically, they test 75 different models (including both vision models and vision-language models) and find a linear correlation between ImageNet LCA and OOD accuracy across 4 standard ImageNet-OOD datasets. They also use the pairwise LCA between classes as soft labels for linear probing over pretrained models, and find that OOD performance can be improved at the cost of in-domain performance."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "* The idea of using LCA for evaluating OOD generalization is simple, intuitive, well-motivated, and effective.\n\n* The paper is fairly well-written (except some typos which can be fixed).\n\n* The experimental analyses are quite extensive. The contributions of this work will likely be quite significant for industry applications where predicting OOD performance ahead of deployment tends to be important."
            },
            "weaknesses": {
                "value": "* Explanation of LCA is complicated\n    * A visual illustration of LCA computation with a small part of the WordNet hierarchy and 2-3 example pairs of classes would help readers to quickly and better understand the LCA distance measure.\n    * Maybe a figure in the main paper like Fig. 3 (in Suppl.) but with some actual classes and example LCA values for a few pairs of classes.\n\n* Fig. 1 is very difficult to read and understand\n    * The legend is too small. It would be better to show only top-1 here (first row) with larger font sizes (match caption size, roughly) and show the full figure in supplementary.\n\n* Implementation of inferred class taxonomy is difficult to understand\n    * It is unclear what \"establishing the cluster level where both classes share the same cluster as the height of LCA\" means. Please clarify and try to simplify it.\n    * A figure illustrating the method would be ideal to help readers understand it better."
            },
            "questions": {
                "value": "* Please see the weaknesses section.\n\n* Minor comments\n    * Abstract (second paragraph) has a typo: \u201cBeside\u201d \u2192 \u201cBesides\u201d.\n    * Introduction (second paragraph): \u201ceffective robustness(Taori et al., 2020)\u201d space needed between robustness and the citation.\n    * Above the contributions list, typo: \u201cin measure model\u2019s semantic awareness\u201d \u2192 \u201cin measuring a model\u2019s semantic awareness\u201d.\n    * Sec. 2 (second paragraph): extra or less brackets in three equations in this paragraph.\n    * In many places in the paper, quotes are used incorrectly in LaTeX. Please use ` ' in LaTeX (i.e. backtick and quote instead of both quotes).\n    * Paragraph below Table 3 has a typo: \u201cAs illustrated in Table3\u201d \u2192 \u201cAs illustrated in Table 3\u201d, i.e. add space.\n    * Sec. 3.3 (last paragraph) has a typo: \u201cnatural image(ImageNet)\u201d \u2192 \u201cnatural image (ImageNet)\u201d, i.e. add space."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4697/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4697/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4697/Reviewer_5fCB"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4697/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698977555937,
        "cdate": 1698977555937,
        "tmdate": 1699636451139,
        "mdate": 1699636451139,
        "license": "CC BY 4.0",
        "version": 2
    }
]