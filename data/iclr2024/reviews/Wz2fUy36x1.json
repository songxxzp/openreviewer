[
    {
        "id": "Ow1KwpuBhp",
        "forum": "Wz2fUy36x1",
        "replyto": "Wz2fUy36x1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission941/Reviewer_GDLV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission941/Reviewer_GDLV"
        ],
        "content": {
            "summary": {
                "value": "This study shows that masked autoencoders (MAEs) can be used to compute weight importance in structured pruning. Based on the \u2018harder-reconstructed-more-important\u2019 assumption, the convolutional filters in CNNs (or the linear projection matrices in ViTs) work as the training data of MAEs. The weights that are challenging for the MAE to reconstruct are deemed vital and remain unpruned."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The idea of reconstructing weights parameters under the MAE framework seems new.\n- The applicability is shown not only for CNNs but also for ViTs, and the transferability of trained MAEs is demonstrated."
            },
            "weaknesses": {
                "value": "- It's unclear why MAE was chosen as the primary method for determining importance. I think the core of this framework is capturing inter-weight relationships/correlations via a reconstruction task, which implies that other networks can be also workable. What distinct benefits do MAEs offer? Is it possible to design other baselines (e.g., vanilla AE without masking) and conduct the comparison?\n- Considering the added complexity of the proposed method, such as the requirement for individual MAE training, the performance shown in Tables 1 and 2 hardly seems worthwhile. Additionally, the ResNet baselines for ImageNet experiments look outdated (works in 2020, 2021) or hard to understand (works in 2022 with different Base Top-1).\n- It is difficult to understand where the performance gains come from, compared to the baseline methods. In particular, in Figure 4(d) and (e), better post-training accuracies (without finetuning) did not guarantee better final accuracies (with finetuning). \n- Please report the actual throughput and/or latency, which is the main advantage of structured pruning.\n- Analyzing which parts were pruned would be interesting to understand the network behavior.\n- Is it possible to show the transferability of trained MAEs for the ViT experiments? I think it would be beneficial to claim \u201ca well-trained MAE can be regarded as a universal pruning criterion.\u201d"
            },
            "questions": {
                "value": "Described in the above Weaknesses section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698576854929,
        "cdate": 1698576854929,
        "tmdate": 1699636020875,
        "mdate": 1699636020875,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "hXHg5M4psi",
        "forum": "Wz2fUy36x1",
        "replyto": "Wz2fUy36x1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission941/Reviewer_XNx5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission941/Reviewer_XNx5"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a masked autoencoder (MAE) for structured pruning. MAE conducts pruning based on reconstruction criteria and self-learning schema. Numerical experiments validate the efficacy of the proposed method."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is written well in general and easy to follow. \n- The reconstruction and self-learning for pruning criteria make senses, that should lead to better performance."
            },
            "weaknesses": {
                "value": "- **Some statements are not correct.**  For example, in introduction **existing pruning criteria are\n predominantly based on handcrafted heuristics or calculated statistics, hindering\n their generality and effectiveness.** In fact, many pruning methods design the pruning criteria based on numerical optimization, which are generic for general applications. \n- **The pruning method is not that appealing.**  The current trend of structured pruning is automated and ease-to-use, such as Torch-Pruning (DepGraph) and OTOv2. The proposed MAE seems computational expensive, hard to use, and a case-by-case approach, which is opposite to the main trend. Meanwhile the paper does not discuss and compare with these automated pruning approaches. \n\n- **The novelty is limited.** Reconstruction for pruning has been proposed. The combination with self-learning seems not that dedicately designed and not well presented."
            },
            "questions": {
                "value": "See the weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698639453854,
        "cdate": 1698639453854,
        "tmdate": 1699636020783,
        "mdate": 1699636020783,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "E8UF56FtF7",
        "forum": "Wz2fUy36x1",
        "replyto": "Wz2fUy36x1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission941/Reviewer_Q6JX"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission941/Reviewer_Q6JX"
        ],
        "content": {
            "summary": {
                "value": "This paper seeks to construct a feasible criterion that can provide importance evaluation on network pruning without explicit reliance on quantitative data. To this end, the authors propose a well-trained pruning criterion based on the masked autoencoder, to fully exploit the intrinsic correlations among learned parameters."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The idea of constructing a universal and learnable pruning criterion to access the pruned accuracy is reasonable.\n2. This paper brings new insights into the field by building the bridge between pruning and self-supervised learning."
            },
            "weaknesses": {
                "value": "1. The minor difference between reconstructed and original filters in Figure 2 is insufficient to demonstrate that MAE can learn the semantic information hidden in the filters.\n2. Observations through ResNet-56 experiments on the CIFAR-10 dataset is insufficient to establish a clear relationship between the performance of MAE and the pruned accuracy. The authors should validate the assumption of \"harder-reconstructed-more-important\" on more models and datasets.\n3. Could you analyze the cases in Table 1 where the proposed MAEP is inferior to the baselines? Please provide more \"inference speedup\" results in Tables 1 and 2.\n4. Section 4.3 states that \"a well-trained MAE can be regarded as a universal pruning criterion\". However, the conclusion lacks credibility as Table 3 does not show a universal MAE that performs the best on all target models.\n5. The ablation experiment of Figure 4(d) only relies on pruning ResNet-56 on CIFAR-10, which is insufficient to prove that MAE is insensitive to mask ratios. More experimental results should be provided.\n6. The fonts in all figures and tables in the paper are too small to read, especially in Figure 1. There are also grammar and punctuation errors in the paper. Please correct them carefully."
            },
            "questions": {
                "value": "Please refer to the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698807587921,
        "cdate": 1698807587921,
        "tmdate": 1699636020702,
        "mdate": 1699636020702,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NowJdQ9ECV",
        "forum": "Wz2fUy36x1",
        "replyto": "Wz2fUy36x1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission941/Reviewer_WXme"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission941/Reviewer_WXme"
        ],
        "content": {
            "summary": {
                "value": "In this work, the authors propose a new structured pruning method (MAEP) by using masked autoencoders as indicators of weight importance. The proposed MAEP mainly includes two steps. In the first step, the authors reconstruct the weight of the networks by using masked autoencoders. To make the training efficient, the authors fix the length of the weight matrix and balance the reconstruction loss for different layers.  In the second step, the authors prune the network with the assumption of \"harder-reconstructed-more-important\" by using the proposed Sampe-Without-Replacement strategy for the reconstructed parameters.  In the experiments, the authors conduct experiments with prior pruning works and show better performance on multiple benchmarks with varied network structures."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed MAEP is interesting and novel which prunes the weights according to their reconstruction difficulty by using masked autoencoders.  \n\n2. The writing is well and easy to follow.\n\n3. Obtain better accuracy compared to the pruning methods."
            },
            "weaknesses": {
                "value": "1. The training cost of the proposed method is unknown compared to the conventional pruning method.\n\n2. It's unclear how to obtain the reported accuracy after pruning.\n\n3. Regarding MAE, the authors propose two techniques: 1) fix the row in the weight matrix as the maximum length in a network; 2)  adjust the reconstruction loss for different layers. Both methods are not related to \"efficiency\" which involves extra computation cost, but serve to enable parameter modeling by using MAE"
            },
            "questions": {
                "value": "The detailed questions regarding Weaknesses.\n\n1. The training cost of the proposed method is unknown compared to the conventional pruning method.\n\n    1.1 What is the training cost of MAE compared to conventional supervised pruning methods? This comparison helps to justify the efficiency of the proposed method. \n\n2.  It's unclear how to obtain the reported accuracy after pruning. \n    \n     2.1 What is the initial network? Is it a well-trained network or a random initialized model?\n \n     2.2 The proposed pruning strategy directly removes unimportant weights without any supervision or weight update. Does the pruned model need to be further fine-tuned by using supervised learning to obtain the reported accuracy? \n\n3.  It's better to provide more intuition to justify the \"harder-reconstructed-more-important\" assumption for purning"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698817302732,
        "cdate": 1698817302732,
        "tmdate": 1699636020631,
        "mdate": 1699636020631,
        "license": "CC BY 4.0",
        "version": 2
    }
]