[
    {
        "id": "DGEeOArCFP",
        "forum": "Cx6Jn6gKHz",
        "replyto": "Cx6Jn6gKHz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8574/Reviewer_ZZdy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8574/Reviewer_ZZdy"
        ],
        "content": {
            "summary": {
                "value": "This work addresses the problem of learning to recover SDFs from point clouds, which may be sparse or dense, without ground truth supervision. A method for mining adversarial samples around a shape\u2019s surface is proposed, which aids in learning better neural SDFs and leads to improved robustness towards overfitting."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1) The paper is well organized and easy to follow.\n\n2) An extensive set of experiments are conducted in which previous methods are outperformed in the sparse input case and SOTA is matched in the dense input case.\n\n3) Qualitatively the proposed method seems to perform better than previous methods on reconstructing thin structures and fine details in the presence of low point density inputs."
            },
            "weaknesses": {
                "value": "1) Considering that the main contribution of the paper revolves around Eq. 6-8, there should be a formal derivation for $\\hat{\\delta}$ when using the first order Taylor expansion of loss $\\mathcal{L}$. I would expect to see this in the supplemental for completeness, but couldn\u2019t find any such derivation.\n\n2) For sparse inputs on ShapeNet and Faust, it seems like NTPS (Chen 2023) evaluate on 300 points while here sparse inputs are being considered as 1024 points. Since NTPS is the other main work that does unsupervised SDF learning from sparse point clouds, it would be nice to see results on 300 points which are significantly sparser inputs then what has been presented.\n\n3) Best values in Table 3 should be bolded to make it easier to read. \n\n4) Figure 5 should include a comparison to NTPS as it performs the closest to the proposed method according to Table 3.\n\n5) In Tables 4 and 5, metric $d_{C}$ is never defined. I assume this is chamfer distance.\n\n6) DiGS seems to perform slightly better in the dense point cloud case (Table 4), but it wasn\u2019t compared against in the sparse input case (Table 5). I would expect to see a comparison to this method for the sparse input to see if it performs worse. Additionally, NTPS should be included in both Table 4 and 5.\n\n7) Please add the point cloud inputs to Figure 6 to have an understanding of the difference in inputs."
            },
            "questions": {
                "value": "1) Considering that extra query samples are generated with the proposed method, did you train the Neural Pull baseline with the same total number of samples as the proposed method or with just the same initial number of samples? It would be good to know how much more effective the approach is to just increasing the number of samples initially generated.\n\n2) I'm a little confused on what \"global radii\" is in the ablation. In Table 6, it has the same definition as one of the local radii (i.e. $\\rho_{q} = \\sigma_{p}/100$). \n\n3) Instead of using a hybrid loss with learnable weights, did you try just training with the adversarial loss or with a fixed weighting between the original objective and adversarial one?\n\n4) Why is the term \u201cfew shot\u201d used in this work? Few shot seems like it would imply this work is learning a network that generalizes to a large set of SDFs from only training with a few shapes; however, in this work a single SDF is being fit separately for each sparse point cloud. This is really unsupervised SDF learning from sparse point clouds."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Reviewer_ZZdy",
                    "ICLR.cc/2024/Conference/Submission8574/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8574/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698117856486,
        "cdate": 1698117856486,
        "tmdate": 1700723093091,
        "mdate": 1700723093091,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "cqsi2lPSMe",
        "forum": "Cx6Jn6gKHz",
        "replyto": "Cx6Jn6gKHz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8574/Reviewer_iVm1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8574/Reviewer_iVm1"
        ],
        "content": {
            "summary": {
                "value": "Neural Signed Distance Functions (SDF) is a power implicit representation of 3D shapes. However, to robustly learn such a representation from sparse point cloud is a challenging problem. The paper introduces leverages adversarial samples around the shape to improve the learned SDFs. Specifically, it first compute the loss per sampled query point (Eq.4) and then augment the sampled query point set by selecting additional query points which maximize the computed loss (Eq.6). The radii of the range in which the adversarial query points are sampled is adaptively changed based on statistics per local region. \n\nThe 3D reconstruction experiments are conducted on four datasets covering 3D objects, 3D human bodies, and 3D scenes. For each dataset, the proposed method is compared against at least three recent approaches, and achieves the best performance in most cases under different evaluation metrics (except for Normal Consistency (NC) for 3D scene). Qualitative results of each dataset are also shown for comparison. The ablation study compares the effect of different values of adversarial sample are radii."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. $\\textbf{Problem formulation}$: neural signed distance function (sdf) is indeed an important representation of 3D shapes, and how to learn such a representation robustly without over-fitting is an interesting and useful topic, especially under sparse point cloud cases. This paper tried to tackle an important research problem.\n\n2. $\\textbf{Method soundness}$. The proposed adversarial sampling strategy is sound and the math formulas are valid.\n\n3. $\\textbf{Experimental results}$. The performance is superior than the compared approaches in most cases, especially for $L_1$ Chamfer Distance (CD1) and $L_2$ Chamfer Distance (CD2)."
            },
            "weaknesses": {
                "value": "1. $\\textbf{Method}$ \n\n1.1 The proposed strategy to find adversarial query points is an extension of Fast Gradient Sign Method Adversarial Training (FGSM-AT) [1] and Projected Gradient Descent (PGD) [2] from 2D image classification to 3D point cloud sample, with the former trying to find adversarial images and this paper trying to find adversarial points.\n\n1.2 Using Taylor expansion to estimate the loss value at a certain point has also been proposed in previous literatures [3], [4].\n\nThough applying adversarial training to SDF learning is interesting and somewhat novel, an in-depth analysis of relating SDF fields to 3D shape geometry is welcome to strength the paper.\n\n2. $\\textbf{Experiments}$\n\n2.1 It is confusing in Table 3 that CD1 and CD2 outperforms all the compared methods, but NC is inferior to other methods. If a justification could be provided or the performance in NC metric could be improved, the paper will be more strengthened.  \n\n2.2 The proposed method is used to sample additional adversarial points to augment the queried points, what if I uniformly (or randomly) sample more points (or use Gaussian distribution to sample more points), instead of adversarially sampling as augmentation? If such an experiments can be presented, it will lend strong support to the effectiveness of the adversarial sampling.\n\n2.3 Another suggestive ablation experiment to strengthen the paper is to compare the proposed approach on point clouds with 1024 points with a baseline approach (i.e., without adversarial sampling) on point clouds with more than 1024 points (like 2048 points).\n\n3. $\\textbf{Writting}$\n\n3.1 This paper needs a more careful proof-reading and grammar checking. For example, \"using this approximation\" (above Eq.8) should be \"Using this approximation\".\n\n3.2 The legend text in Figure 1 is too small to be seen clearly. \n\n3.3 It is preferable to add citations in Tables to make it easier to check the reference papers.\n\n3.4 Figure 3 and Figure 4 should be combined as a single big figure to avoid large empty space.\n\n$\\newline$\n\n[1]. Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. ICLR, 2015.\n\n[2]. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. ICLR, 2018.\n\n[3]. Jin G, Yi X, Wu D, Mu R, Huang X. Randomized adversarial training via taylor expansion. CVPR, 2023.\n\n[4]. Qian YG, Zhang XM, Swaileh W, Wei L, Wang B, Chen JH, Zhou WJ, Lei JS. TEAM: An Taylor Expansion-Based Method for Generating Adversarial Examples. arXiv preprint arXiv:2001.08389. 2020."
            },
            "questions": {
                "value": "Please refer to the weakness part. If the weaknesses can be resolved, I will raise my rating."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Reviewer_iVm1"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8574/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698572531302,
        "cdate": 1698572531302,
        "tmdate": 1699637072849,
        "mdate": 1699637072849,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sU6O81jKek",
        "forum": "Cx6Jn6gKHz",
        "replyto": "Cx6Jn6gKHz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8574/Reviewer_akZJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8574/Reviewer_akZJ"
        ],
        "content": {
            "summary": {
                "value": "This paper attempts to enhance the generalization of reconstructing meshes from sparse point clouds by employing an optimization strategy similar to adversarial training. The authors observed that as the input point cloud becomes sparser, the phenomenon of network overfitting becomes more severe during the experiments with the NeuralPull method. Therefore, they propose the need to mitigate this overfitting phenomenon using some strategy. The authors suggest not directly optimizing randomly sampled points in space, but instead identifying the worst-performing points in space (defined as points with the highest loss value) and then aligning the implicit function with the given point cloud as closely as possible at these identified points. Technically, the authors employ a method similar to the PGD attack to train these worst-performing points. Finally, the authors conduct experiments on both object and scene point cloud data, and in comparison, achieve favorable results in terms of experimental outcomes."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The article attempts to address an important problem and introduces relevant concepts from other fields to solve it (such as defining overfitting as a flaw in the sampling strategy, leading to the introduction of a strategy similar to adversarial training). Additionally, the paper compares different methods and experimentally demonstrates the effectiveness of the proposed approach. Overall, this is not an incremental work, as it introduces novel ideas and approaches to tackle the problem."
            },
            "weaknesses": {
                "value": "However, I do have some concerns regarding the proposed method in this paper. \n\nFirstly, from my perspective, using a PGD-like optimization method imposes a smooth constraint on the implicit function (considering that the Lipschitz constant of the model generally decreases after adversarial training). While this approach is indeed an effective regularization for noisy point clouds, it may not be as effective for sparse point clouds. We cannot deny the existence of sparse surfaces with high curvature, and further experiments may be needed to address this issue. \n\nSecondly, I am unsure how the authors obtained the normals of the point cloud. Screened Poisson Surface Reconstruction (SPSR) requires this parameter, and it heavily relies on the consistency of normal directions. If the normals are estimated incorrectly, it could introduce unfairness in the comparison with SPSR. More experimental details need to be provided, and at least the optimization of results using normal flipping strategies should be considered. \n\nFurthermore, there is a significant amount of related work in this field that has not been compared. I suggest the authors refer to [1] and provide further and more comprehensive comparisons. \n\nLastly, it is generally believed that the performance on the original samples tends to decrease after adversarial training. It would be helpful to provide additional explanations as to why this performance decrease is reasonable. \n\n[1] Huang Z, Wen Y, Wang Z, et al. Surface reconstruction from point clouds: A survey and a benchmark. arXiv preprint arXiv:2205.02413, 2022."
            },
            "questions": {
                "value": "As mentioned above, I see the potential in this paper, but the current version still has some way to go before it can be accepted by a top conference. At the very least, the following issues need to be addressed:\n\n1. Carefully examine the scope of the method to ensure there is no overclaiming.\n\n2. Provide additional experimental details to enable fairer comparisons between the proposed method and others, and include more relevant experiments.\n\n3. If possible, provide further theoretical derivations to explain what adversarial training specifically improves in the implicit function.\n\nIf my concerns mentioned above are addressed, I would consider raising the score."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Reviewer_akZJ",
                    "ICLR.cc/2024/Conference/Submission8574/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8574/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698586814843,
        "cdate": 1698586814843,
        "tmdate": 1700706344459,
        "mdate": 1700706344459,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MmvrTiaVvw",
        "forum": "Cx6Jn6gKHz",
        "replyto": "Cx6Jn6gKHz",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8574/Reviewer_PU6C"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8574/Reviewer_PU6C"
        ],
        "content": {
            "summary": {
                "value": "The paper considers the task of learning neural SDFs from sparse point cloud data. The typical approach for learning such SDFs without external supervision is to sample  **query** points around each point in the pointcloud, and optimizing a loss that pulls the query points toward the closest point on the neural surface (Neural-Pull, Ma et al 2021). The authors observe that such methods are prone to overfitting (the training loss continues to drop when the validation chamfer error grows). The authors propose a simple solution to this problem. After sampling query points near the input point clouds, one can find additional **adversarial** points near the query points that maximize the SDF loss. The authors demonstrate empirically that training with these additional adversarial points improves the quality of SDFs recovered from point clouds on a range of 3D datasets."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* The paper is clear to read and the content is easy to follow.\n* The related work is thorough and clearly positions prior work.\n* The proposed method is simple and effective.\n* The results demonstrate state-of-the-art performance compared to existing methods.\n* The approach is well-motivated from the perspective of robustness and hard sample mining for improved generalization"
            },
            "weaknesses": {
                "value": "* Insufficient analysis of how overfitting is manifested and how it is addressed: The central motivation for the approach is that NeuralPull and related works experience overfitting, but it\u2019s not clear what it looks like to experience overfitting. For instance, maybe the surface starts smooth and then becomes bumpy around the input points? It would be illuminating to see some actual NeuralPull reconstructions at different levels of overfitting to be clear about what problem the proposed work is addressing.\n* The task is unrealistic: For this method (and related approaches) to work, the point clouds must be roughly uniform in coverage over the object. At a minimum, there must be good coverage of points across most of the object (and this is why the method struggles on thin structures as shown in Figure 3). This is reflected in the evaluation setup, where all datasets start with a high-quality mesh which is then subsampled with uniform density into a point cloud, which is then used to reconstruct a surface.  However, in real-world point clouds, the sampling will never be uniform in density or coverage. For instance, in point clouds captured via depth cameras (one of the most common ways to acquire a point cloud), most of the points will be biased toward regions of high-frequency texture with very few points on textureless surfaces.\n* (minor) The differences in Figure 5 are difficult to observe even with the red box. Figure 1 text is too small."
            },
            "questions": {
                "value": "* Why is the reconstruction quality better than NeuralPull? From Figure 1, it seems that the primary benefit of the red line over the baseline is that there is less overfitting. However, the red line does not seem to go significantly lower than the green line for the Chamfer validation. In other words, I would think that the primary benefit of the proposed work is in robustness/less hyperparameter tuning and not outright reconstruction quality.\n* Related to the above, how were hyperparameters for prior works chosen, namely for which epoch to stop at? As the paper notes, which epoch to stop at has an immense effect for NeuralPull. Perhaps the fairest comparison would be to consider 3 setups for each baseline: stop at the optimum iteration based on test error, at a fixed early-ish iteration, and at a fixed very late iteration. For the proposed approach, I would expect all 3 to give similar performance whereas the gap would be large for the baselines. This would also help demonstrate the robustness of the proposed work."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8574/Reviewer_PU6C",
                    "ICLR.cc/2024/Conference/Submission8574/Senior_Area_Chairs"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8574/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699481328186,
        "cdate": 1699481328186,
        "tmdate": 1700613257618,
        "mdate": 1700613257618,
        "license": "CC BY 4.0",
        "version": 2
    }
]