[
    {
        "id": "WyB0vjpqB0",
        "forum": "PXNrncg2DF",
        "replyto": "PXNrncg2DF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3941/Reviewer_Rono"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3941/Reviewer_Rono"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces SOHES, a method designed to eliminate the need for manual annotation and facilitate the learning of hierarchical associations for open-world entity segmentation. Specifically, the authors have devised a novel approach for generating initial pseudo-labels and subsequently enhancing the segmentation model through their utilization. When compared to previous research on open-world entity segmentation, SOHES demonstrates a significant reduction in the gap between self-supervised methods and the supervised SAM."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed method is highly motivated, and the results of SOHES demonstrate tremendous potential in open-world entity segmentation, even surpassing SAM's performance on certain datasets. \n2. The paper is excellently structured and provides a clear and easy-to-follow presentation."
            },
            "weaknesses": {
                "value": "1. The analysis of the hierarchical architecture is inadequate.\n2. Certain details in the method lack clarity, and there is a noticeable absence of some ablation experiments."
            },
            "questions": {
                "value": "1. Regarding the generation of pseudo-labels, I am inquisitive about why the visual feature of merged patches is computed as the sum of original features rather than an average or any other operation?\n2. Concerning the second local re-clustering step, I'm curious about whether it has an impact on the results for large entities and how the threshold for small regions affects the final results. \n4. In the ablation study, there is no information regarding how the ancestor prediction head contributes to the final results. Further analysis of the hierarchical architecture is needed for clarification."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3941/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3941/Reviewer_Rono",
                    "ICLR.cc/2024/Conference/Submission3941/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698548901680,
        "cdate": 1698548901680,
        "tmdate": 1700575710615,
        "mdate": 1700575710615,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "kw8jtsEZCj",
        "forum": "PXNrncg2DF",
        "replyto": "PXNrncg2DF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3941/Reviewer_vWUT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3941/Reviewer_vWUT"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces the Self-supervised Open-world Hierarchical Entity Segmentation (SOHES) approach for computer vision, which can segment entities in images beyond pre-defined classes without human annotations. SOHES uses three stages: self-exploration, self-instruction, and self-correction, generating high-quality pseudo-labels from visual feature clustering and refining them through mutual-learning. This method achieves a new standard in self-supervised open-world segmentation, eliminating the need for human-annotated masks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1.\tThe task SOHES is seldom investigated.\n2.\tThis paper proposed a new method to generate hierarchical proposals.\n3.\tThis paper proposed an ancestor prediction head, which is novel.\n4.\tThe proposed method significantly outperformed the previous methods."
            },
            "weaknesses": {
                "value": "1.\tAlthough this paper divide the stages into self-exploration, self-instruction, and self-correction. But it looks like previous papers[1] that generate pseudo-labels, then training from pseudo-labels, and apply self-training to improve the model. The framework is actually quite common. So what is the core difference from the previous works in the framework?\n2.     The authors claimed that \u201cExisting segmentation models cannot predict the hierarchical relations among masks. \u201d However, methods like Groupvit[2] already can predict the hierarchical relations among masks.\n3.\tThe proposed method introduced too many hyperparameters such as Theta_{merge}, Theta_{small}, Theta_{cover}. There is not explanation for the selection of some hyperparameters, such as Theta_{cover}. \n4.\tAlthough the authors proposed the ancestor prediction head for the hierarchical segmentation. However, the mask prediction of masks at each hierarchy is independent.  I am curious if the relation modeling of hierarchy can contribute to better mask predictions. I am also curious about the effect of just predicting the hierarchical relationships. It seems that there is no ablation to verify if the ancestor prediction head can bring the performance improvements.\n\n[1] Wang, Xinlong, et al. \"Freesolo: Learning to segment objects without annotations.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n[2] Xu, Jiarui, et al. \"Groupvit: Semantic segmentation emerges from text supervision.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022."
            },
            "questions": {
                "value": "See weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698739244730,
        "cdate": 1698739244730,
        "tmdate": 1699636354709,
        "mdate": 1699636354709,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "p86IwNLQeH",
        "forum": "PXNrncg2DF",
        "replyto": "PXNrncg2DF",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3941/Reviewer_PuvF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3941/Reviewer_PuvF"
        ],
        "content": {
            "summary": {
                "value": "The authors introduced the Self-supervised Open-world Hierarchical Entity Segmentation (SOHES) method, a three-phase approach for entity segmentation. The first phase, Self-exploration, uses a pre-trained DINO model to produce initial pseudo-labels. By clustering visual features, it identifies regions representing meaningful entities. In the Self-instruction phase, a Mask2Former segmentation model refines the segmentation by training on these initial labels. Even with some label noise, the model effectively averages out inconsistencies, resulting in better mask predictions. The final Self-correction phase uses a teacher-student mutual-learning framework to further refine the model's predictions and adapt to open-world segmentation. This approach only uses raw images without human annotations. A standout feature of SOHES is its ability to segment not just whole entities but also their parts and sub-parts."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "[Task] Unsupervised image segmentation holds significant importance, and this study successfully performs segmentation without human supervision, offering segmentation masks at multiple levels of granularity.\n\n[The generation of hierarchical masks] The approach to generate unsupervised hierarchical masks is pretty interesting. And surprisingly, this method surpassed SAM in recall on some evaluation benchmarks. \n\n[Paper writing] The paper is well-articulated, effectively communicating the central ideas."
            },
            "weaknesses": {
                "value": "[Technical Contributions] The three phases proposed in this work are very similar to the Cut-and-Learn pipeline proposed by CutLER [1]. Self-exploration is pretty similar to the MaskCut stage in CutLER, which also leverages DINO feature for pseudo-label generation. Self-instruction is the same as the LEARN process of CutLER, which trains a model on pseudo-labels. And, the Self-correction stage can be viewed as a variant of CutLER's multi-round self-training, but with a teacher-student framework. I agree that while there are some implementation differences between the stages in SOHES and CutLER, their core concepts are largely analogous.\n\n[Model performance] SOHES performs much worse than CutLER (9.8 vs. 2.1 on COCO and 3.6 vs. 1.9 on LVIS) in terms of the mask AP. This works show stronger performance than the previous SOTA CutLER and SAM on some benchmarks, however, the main results are AR (averaged recall). Recall is important, however, for many downstream tasks, the AP is still the most valuable evaluation metric. \n\n[Unfair comparison] The main baseline CutLER used Cascade Mask RCNN as the segmentation model, while this work used Mask2Former, a stronger segmentation model, as the base model. This makes the performance comparison unfair. \n\n[1] Wang, Xudong, Rohit Girdhar, Stella X. Yu, and Ishan Misra. \"Cut and learn for unsupervised object detection and instance segmentation.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3124-3134. 2023."
            },
            "questions": {
                "value": "My main questions are listed in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3941/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698908394511,
        "cdate": 1698908394511,
        "tmdate": 1699636354644,
        "mdate": 1699636354644,
        "license": "CC BY 4.0",
        "version": 2
    }
]