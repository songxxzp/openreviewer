[
    {
        "id": "kTIkIlq5M7",
        "forum": "3edHHvu5GX",
        "replyto": "3edHHvu5GX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_SDSd"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_SDSd"
        ],
        "content": {
            "summary": {
                "value": "The paper investigates different approaches towards continual learning of image scene graphs, where the continual learning of object vocabulary, predicate vocabulary and the combination can increase over time. The authors have experimented with several baselines, proposed several metrics ranging from Recall to mRecall; forgetfulness to generalizability with increasing task numbers."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The problem of image scene graph generation is inherently long-tailed. On top of that, the continuous learning on objects and predicates and their combination makes the problem even more challenging. Their experiments are methodical. The overall idea of the continual learning of them are based on the observation that these are long-tailed distributions and the task definition, dataset creation are all motivated by standard long-tailed learning paradigms which long-tailed class-incremental learning."
            },
            "weaknesses": {
                "value": "The writing is convoluted in some places. Specially the scene graph generation backbone 3.2 wasn't clear after the first read. The references to CNN-SGG and SGTR aren't separated, and caused a bit of confusion."
            },
            "questions": {
                "value": "As evident by several studies, the mean recall usually improves at the cost of recall in SGG literature. What is the impact of the long-tailed incremental learning in the forgetfulness of Recall? A recent paper proposed a one-stage method [1] which provided a good balance between Recall and mean Recall. Is it possible to utilize similar backbone so we know the effect of incremental learning on both Recall and mean Recall in a balanced way. Table 2 in [1] shows that mean recall of [1] is more than twice than that of training baseline of Fig S.8 in the current paper.  \n\n\n[1] Desai et al, \"Single-Stage Visual Relationship Learning using Conditional Queries\", NeurIPS 2022."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3278/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698482808361,
        "cdate": 1698482808361,
        "tmdate": 1699636276504,
        "mdate": 1699636276504,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "0VBdMbQG3r",
        "forum": "3edHHvu5GX",
        "replyto": "3edHHvu5GX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_FdjE"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_FdjE"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the continual learning problem in SGG, and conducts experiments to show the performance of existing methods in the proposed continual learning scenarios."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The proposed scenario is realistic and is worth to investigate.\n2. The paper is easy to follow."
            },
            "weaknesses": {
                "value": "1. Clarity on Relationship with SGG Tasks: The paper lacks clarity in establishing the direct correlation between its observations and the Scene Graph Generation (SGG) tasks. While the identified issues like catastrophic forgetting, the efficacy of replay methods, and addressing long-tail problems are extensively explored in existing research, the unique challenges in integrating continual learning, long-tail problems, and SGG remain unclear. The paper falls short in delineating the specific challenges arising from the amalgamation of these factors.\n\n2. Inadequate Support for Conclusions: The paper argues that replay-based methods underperform on S3 due to models focusing on detecting more in-domain object boxes. However, this conclusion lacks direct substantiation. The mixed nature of the test datasets across all tasks in S3 complicates such straightforward assertions. Further information and experimental evidence are necessary to strengthen and clarify this particular assertion.\n\n3. Limited Contribution to Method Design: The primary contribution of this paper lies in evaluating continual learning algorithms within the proposed scenarios. Nevertheless, this contribution, while valuable, may not meet the rigorous criteria for publication in esteemed venues such as ICLR. This is primarily because it lacks the introduction of novel methods or groundbreaking observations that can serve as a source of inspiration and guidance for future method development."
            },
            "questions": {
                "value": "1. Could the authors delve further into elucidating the unique challenges that arise in SGG tasks due to continual learning scenarios? Clarifying these challenges could significantly strengthen the paper's contribution.\n\n2. It would be beneficial if the paper explored how the insights garnered from this paper could inspire or guide the design of enhanced methodologies for continual SGG scenarios."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3278/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698675707651,
        "cdate": 1698675707651,
        "tmdate": 1699636276409,
        "mdate": 1699636276409,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "2C8N9GCBQh",
        "forum": "3edHHvu5GX",
        "replyto": "3edHHvu5GX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_pXA5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_pXA5"
        ],
        "content": {
            "summary": {
                "value": "This work proposes comprehensive studies on several new settings of the scene graph generation task, in which the relationships, scene, and object incremental scenarios are considered. It conducts experiments that combine continuous learning with current two-stage and transformer-based SGG methods and analyzes their performance."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "I think continual scene graph generation is quite practical. \n\nThe authors provide some introduction and analyses about the learning scenarios, evaluation methods and metrics, and results using current SGG algorithms combined with continuous learning. These analyses are quite essential."
            },
            "weaknesses": {
                "value": "It seems the organization and writing are quite disordered and difficult to follow. For example, the authors claim scenario 1 has 5 tasks. However, detailed definitions of these tasks are missing. Similar problems exist for the other two scenarios.\n\nThe first contribution seems to over-claim. It seems the images, object classes and relationships inherit from the visual genome dataset. I do not know what is new."
            },
            "questions": {
                "value": "see weakness"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3278/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698763923399,
        "cdate": 1698763923399,
        "tmdate": 1699636276342,
        "mdate": 1699636276342,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "M1M31j4apV",
        "forum": "3edHHvu5GX",
        "replyto": "3edHHvu5GX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_LwTF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_LwTF"
        ],
        "content": {
            "summary": {
                "value": "This work divides up the Visual Genome dataset into three scene graph-based continual learning scenarios. It then evaluates some baseline approaches on the benchmarks: two scene generation backbone architectures (SGTR and CNN-SGG), three sampling strategies for learning (LVIS, BLS, and EFL), as well as five continual learning approaches (naive, EWC, PackNet, Replay, and joint training)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* Scene graphs present an interesting (novel to my knowledge) domain for continual learning.\n* The learning scenarios make sense and are well motivated with comparison to (somewhat distant) real-world scenarios.\n* The work pays attention to the distribution of attributes/data for each task per learning scenario (e.g., relationships within a task are long-tailed).\n* The choice of baselines and evaluation metrics seems sound to me.\n* I particularly liked Figure 4 showing an overview of SGTR and the continual learning baseline algorithms.\n* The authors have made their code available."
            },
            "weaknesses": {
                "value": "* The authors missed connections to the meta-learning and curriculum design literature. From that lens, claims such as \"CSEGG methods improve generalization abilities\" seem a bit unsurprising.\n* The dataset is somewhat small in scale. 150 objects and 50 relationships might not be enough to pose a sufficient continual learning channel. The benchmark also reuses images between tasks in a learning scenario, which is not ideal.\n* Though there is some interpretation of the baselines, I struggled to see what the community should take away about them. \n* I'm also uncertain how the benchmark might encourage future algorithm or model developments.\n* The writing introduces a lot of terms (in bold text). Some of this could be done better, for instance:\n  * Please enumerate the continual learning algorithms in Section 3.3.\n  * Some terms that are introduced are never referenced again in the main text (e.g., Forward and Backward Transfer).\n* It is confusing when \"long-tailed\" in mentioned in the context of dataset creation as well as learning (e.g. the title of Section 4.2 is ambiguous. In Section 3.2, perhaps it would be clearer to say \"Techniques for sampling to deal with long-tailed data\"?)."
            },
            "questions": {
                "value": "* There are other datasets which come with scene graphs as you laid out on your Related Work section. Why not use those?\n* The caption for Fig 1 suggests objects are nodes and relations are edges. But Fig 1a shows them as nodes of different color. Could you please ensure consistency? Figure 1b intends to show that new objects and relations emerge over time, but some of the uncolored objects (e.g. man, tree) have not appeared previously. So which objects/relations are colored seems arbitrary?\n* Could you please walk us through the immediate implications of your work for the community, rather than distant possibilities?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3278/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3278/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3278/Reviewer_LwTF"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3278/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698962021213,
        "cdate": 1698962021213,
        "tmdate": 1700844402618,
        "mdate": 1700844402618,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ZXmoIdyxn8",
        "forum": "3edHHvu5GX",
        "replyto": "3edHHvu5GX",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_TSA3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission3278/Reviewer_TSA3"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a scene graph generation dataset for continual learning based on already existing dataset of visual genome. They \nproposed three learning scenarios such as incrementing relationships classes, incrementing objects and relationship classes and generalization on relationship between unseen objects over some tasks. They implemented continual learning for scene graph generation over this dataset using a transformer-based approach and a classic two-stage approach and reported their results on 8 evaluation metric including R@K and mR@K."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. Applying continual learning setting on scene graph generation tasks seems to have great potentials for tasks such as robotic navigation etc.\n2. Curated a dataset for continual learning setting from an existing benchmark SGG dataset (VG)\n3.The codes and dataset will be publicly available"
            },
            "weaknesses": {
                "value": "1. The overall presenation of the paper is difficult to follow and not organized well. (Also too many bold letters for section and figure names)\n2. The authors has proposed three learning scenarios and 8 evaluation metrics. All the learning scenarios has multiple tasks (data separations). However, given that there is a lot to report and include, the results are not summarized well in a tabular form. And it is very difficult to follow how each component is contributing in different metrics and leanring scenrios over the tasks.\n3. Most of the results are written in textual description. Summarizing them in a tabular form and discussing the interesting finding might help the readers to understand the numbers better."
            },
            "questions": {
                "value": "The concerns in the weakness section"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission3278/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3278/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission3278/Reviewer_TSA3"
                ]
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission3278/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699756258415,
        "cdate": 1699756258415,
        "tmdate": 1699756258415,
        "mdate": 1699756258415,
        "license": "CC BY 4.0",
        "version": 2
    }
]