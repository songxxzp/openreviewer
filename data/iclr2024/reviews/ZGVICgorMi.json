[
    {
        "id": "2C8CG4iuaO",
        "forum": "ZGVICgorMi",
        "replyto": "ZGVICgorMi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5718/Reviewer_bZ3G"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5718/Reviewer_bZ3G"
        ],
        "content": {
            "summary": {
                "value": "This paper studies communications between agents in multi-Agent reinforcement learning. Specifically, it focuses on team-level communications instead of commonly used peer-to-peer communications. By doing so, the communication bandwidth is reduced. The proposed algorithm is tested on Traffic Junction Environment (TJ) with different levels of difficulties and Multi-agent Particle Environment (MPE)."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper is well-motivated, since reaching team consensus is an efficient strategy for human cooperation.\n- The team communication channel in section 3.3 is permutation-invariant, which is reasonable for homogenous settings and can potentially reduce the search space.\n- There are ablation studies over the design choices of different components of the proposed algorithm (DC2Net)."
            },
            "weaknesses": {
                "value": "- DC2Net needs the access to a centralizer, which may not be available in practice.\n- The paper claims \"peer-to-peer communication may not provide sufficient IG for effective agent decision-making\". However, peer-to-peer communication is not taken as a baseline in the experiments.\n- The empirical study is focusing on limited scenarios. There are many other challenging tasks, such as Cooperative Navigation and Cooperative Push in MPE, SMAC[1] and GRF[2]. The benefit of DC2Net is more convincing by additional experiments on these tasks.\n\n[1] The StarCraft Multi-Agent Challenge\n\n[2] Google Research Football: A Novel Reinforcement Learning Environment"
            },
            "questions": {
                "value": "- What's the difference between all-to-all communication, where each agent receive all other agents' information, and DC2Net? It seems that team consensus can be reached by all-to-all communication, and if so DC2Net is just a special case of peer-to-peer communication. \n- Does DC2Net still outperform the baselines in the heterogeneous setting where permutation invariance does not hold?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5718/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5718/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5718/Reviewer_bZ3G"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5718/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697927496511,
        "cdate": 1697927496511,
        "tmdate": 1699636598489,
        "mdate": 1699636598489,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "F3PxqRw4LM",
        "forum": "ZGVICgorMi",
        "replyto": "ZGVICgorMi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5718/Reviewer_GjzF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5718/Reviewer_GjzF"
        ],
        "content": {
            "summary": {
                "value": "This authors in this paper propose to enhance MARL by allowing both individual and team information to be used.  Specifically, they propose the DC2Net as depicted in Figure 1.  They show that for Traffic Junction and Predator-Prey problems, the newly proposed model outperforms IQL, CommNet and DGN."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The authors propose a new Model that outperforms a number of model proposed in the past a few years for Traffic Junction and Predator-Prey problems."
            },
            "weaknesses": {
                "value": "I think the main weakness of the paper is the lack of significance.  The authors criticise that previous work only use team information as a kind of supplementary information, but I do not think that the new Model is not among them.  Worse, there is no direct comparison of performance/ communication cost between the new model and these previous works.\n\nIn fact, personally I do not feel comfortable to consider models such as that depicted in Figure 1 should be used for MARL.  This is because the whole model has to be trained centrally--which defeat the purpose of MARL in some scenarios.\n\nFinally, the authors seem to have incorrectly used the citation style."
            },
            "questions": {
                "value": "The authors are expected to elaborate and justify the significances of the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5718/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5718/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5718/Reviewer_GjzF"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5718/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698738477540,
        "cdate": 1698738477540,
        "tmdate": 1699636598357,
        "mdate": 1699636598357,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HLLJS48amD",
        "forum": "ZGVICgorMi",
        "replyto": "ZGVICgorMi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5718/Reviewer_rpxc"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5718/Reviewer_rpxc"
        ],
        "content": {
            "summary": {
                "value": "The paper presents Double Channel Communication Network (DC2Net), a multi-agent reinforcement learning communication model that addresses the limitations of individual-level communication by integrating team-level information. DC2Net separates individual and team feature learning into two independent channels, allowing for collaborative decision-making while reducing communication costs and enabling adaptive balancing between individual and team learning based on task requirements.\n\nI have several major concerns, comments, and questions:\n\n- The method proposes team-level communication channel in order to avoid individual inter-agent communications, supposedly due to low bandwidth constraints. Nevertheless, my biggest concern is that, this approach imposes centralization which is a major limiting factor in multi-agent systems and introduces scalability problems. This also contradicts the Dec-POMDP formulation adopted by the paper, since a centralized team-level communication channel is required.\n\n- limited bandwidth can be resolved by learning efficient communication. For instance, see [1]. This related work, which to my surprise was not even mentioned in the paper, learns an efficient binarized communication policy which works well in low bandwidth scenarios AND it can be executed distributed. They also consider scenarios where some agents have extremely low visibility and team-level coordination is a requirement for accomplishing the multi-agent task. This is only one example of such approaches and you can find more of such works in the recent emergent multi-agent communication literature.\n\n[1] Seraj, Esmaeil, et al. \"Learning efficient diverse communication for cooperative heterogeneous teaming.\" Proceedings of the 21st international conference on autonomous agents and multiagent systems. 2022.\n\n- The employed benchmarks are said to be \u201cstate-of-the-art\u201d. However, this is not true. The employed baselines, IQL, CommNet, and DGN at best, are some standard baselines and not the SOTA, as they are relatively old and have been repeatedly outperformed by recent methods such as MAGIC, HetNet [1], MAPPO, TarMAC, and many others (see the list of benchmarks in mentioned papers). This weakens the evaluation process and the presented results. The method needs to be experimented and evaluated against more recent SOTA methods for the employed domains.\n\n- The employed particle domains, i.e., Traffic Junction and Predator Pray are very simplistic. To draw firm conclusions on the usability and efficacy of the proposed method, more advanced domains are needed to be tested, especially in scenarios where the centralization process (as required in the proposed method) may pose a challenge.\n\n- What are the limitations of this approach? For instance, the centralization required by the team-level communication channel must be discussed as a potential limitation.\n\nAt current states I vote weak rejection mostly due to the centralization issue, missing important related prior work, and weak benchmarks and domains, although the algorithm seems to be sound and working. I\u2019d be happy to increase my score when authors satisfactorily addressed my comments and questios."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "See above."
            },
            "weaknesses": {
                "value": "See above."
            },
            "questions": {
                "value": "See above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5718/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698751035874,
        "cdate": 1698751035874,
        "tmdate": 1699636598238,
        "mdate": 1699636598238,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MRlE3uHcxl",
        "forum": "ZGVICgorMi",
        "replyto": "ZGVICgorMi",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission5718/Reviewer_fZN2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission5718/Reviewer_fZN2"
        ],
        "content": {
            "summary": {
                "value": "This paper seeks to address the problem of communication-based multi-agent reinforcement learning. The new idea is in the proposed Double Channel Communication Network (DC2Net) that utilizes two separate channels for individual and team-level learning to achieve the mixed learning process. Compared to most existing work, the proposed DC2Net eliminates the peer-to-peer communication setting, and leaves all the communication for the team-level channel to achieve centralized joint learning. Experimental results against multiple baseline algorithms are provided to demonstrate the effectiveness of the proposed framework."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "+ The idea of separating individual learning and team-level communication is interesting.\n\n+ The summary of representative literature in learning-enabled multi-agent RL with communication is adequate."
            },
            "weaknesses": {
                "value": "- While the idea of separating individual and team-level communication is quite interesting, the proposed DC2Net lacks key insights to properly justify the current design. For example, it seems DC2Net needs to assume centralized training and execution with strong assumptions on the underlying communication topology, i.e. every agent should be able to communicate to a centralized team-level channel at all times. Besides, the communication process simply aggregates all the agent\u2019s team-level information with gradient truncation, thus making it more like a decentralized implementation of a centralized MARL without special treatment of communication component, which is less comparative to peer-to-peer communication where a centralized agent or node may not exist. \n\n- Although it\u2019s claimed in the paper that the existing work with mixed learning of individual and team-level information does not perform well, there is no evidence to support that. For example, more insights could be provided to highlight what information should be considered as an individual learning-related component and what should be considered as a team-level component, and how they would interact with each other so that it will indeed outperform the existing mixed learning process.\n\n- There is no direct comparison against the MARL framework that uses peer-to-peer communication or centralized computation. In the Ablation Study, it would be more helpful to provide results from DC2Net with mixed learning to justify the influence of the team-level communication component, rather than the provided DC2Net-T that boils down to a MARL without joint learning among agents."
            },
            "questions": {
                "value": "1. Can authors provide more insights on the particular examples where it\u2019s better to use the DC2Net instead of the existing mixed communication learning process of MARL? What would be the individual feature and team-level features, and how that could be properly observed from the given simulation results?\n\n2. What is the assumption on the communication topology in DC2Net? Does it require a centralized communication channel where the team-level features have to be aggregated for centralized training?\n\n3. Is there any theoretical analysis in terms of policy convergence of the proposed DC2Net?\n\n4. Could authors give a fair experiment comparison against peer-to-peer communication-based MARL?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission5718/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699500667191,
        "cdate": 1699500667191,
        "tmdate": 1699636598145,
        "mdate": 1699636598145,
        "license": "CC BY 4.0",
        "version": 2
    }
]