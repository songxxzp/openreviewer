[
    {
        "id": "MT5u40fhdF",
        "forum": "JEYWfmz2TU",
        "replyto": "JEYWfmz2TU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7916/Reviewer_z6Zs"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7916/Reviewer_z6Zs"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses concerns related to action failure during the learning-from-demonstrations process. To address this challenge, the authors design an action model to categorize actions and introduce an action-level failure detector model that employs meta-learning for failure detection. Experiments are conducted in both stationary and variable settings, potentially showcasing the efficacy of the proposed action failure models in the simulator environment."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "* Detecting action failures is an interesting and crucial aspect of robot learning from demonstrations, which can enhance the stability and reliability of the learned policy."
            },
            "weaknesses": {
                "value": "* The chosen tasks are too simple to illustrate the effectiveness of the action failure model. In the meanwhile, it\u2019s unclear if the user demonstrations are collected through teleoperation or just some rule-based demonstrations.\n* There is lack of comparison and connection to the related Behaviour Cloning work (e.g. explicit imitation learning (ACT), implicit imitation learning (iBC) and some recent popular Diffusion Policy). Without a proper connection to the popular algorithms on learning from demonstration, it\u2019s hard to evaluate the effectiveness of the proposed action failure detection model.\n* For the categorization of the action, it may not be realistic for more complicated tasks. \n* There is limited discussion on how to leverage the action failure model to further boost the success rate of the learned policy. Some inituitive way may be redo the action when it fails. And the evaluation metric should be the final success rate."
            },
            "questions": {
                "value": "* Is there some idea on how the approach can be used with some matured imitation learning algorithms or some other matured algorithms on learning from demonstrations?\n* For the random exploration stage, is it pure-random or with some rule-based heuristic for each action type?\n* For table 1, why your methods with no-ft or ft failure detector have different number on the final success? The final success should be related to the learned policy, why related to the action failure? After you detect the action failure, the process will just be terminated, right? Is this also counted as #ES?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7916/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7916/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7916/Reviewer_z6Zs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7916/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698686526315,
        "cdate": 1698686526315,
        "tmdate": 1699636971782,
        "mdate": 1699636971782,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "663CycYDVl",
        "forum": "JEYWfmz2TU",
        "replyto": "JEYWfmz2TU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7916/Reviewer_kyzR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7916/Reviewer_kyzR"
        ],
        "content": {
            "summary": {
                "value": "This submission focuses on robot learning by demonstration and aims to introduce a failure detection model that holistically oversees the execution of the overall plan, rather than using individual failure detection models focusing on individual actions. The proposed solution consumes a small set of human-provided demonstrations and process them in 3 stages. Initially, a sequence of actions comprising a plan is derived from the demonstrations employing a bi-directional LSTM model and a time-windowed voting method. Subsequently, action controllers are learned based on the segmented demonstrated action data, using DMPs. Upon deployment, a Detection model is employed to oversea the execution of each action by the respective controller. Interestingly, this detection model is meta-learned in view of the provided demonstrations, before being fine-tuned to each respective task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-The submission studies the interesting problem of robot learning by demonstration, under the supervision of a failure detection model. In contrast to the plethora of \"open loop\" approaches in the literature, closing the loop of action execution with additional supervision for failure detection is a potentially very impactful problem setting. \n\n-The control and supervision model are jointly trained, and the design choice of plan-level supervision can develop towards a foundational model for failure detection under a wide variety of tasks and environments, given the timely release of large scale task datasets in real-world environments: https://arxiv.org/abs/2310.08864"
            },
            "weaknesses": {
                "value": "-Although the problem setup is well-formulated (Sec. 3.1), some aspects of the proposed methodology are not clearly explained in the manuscript. Most prominent example is the adoption of a meta-learning training framework in Sec. 3.4, which although appears to be one of the key contributions of the paper, is not adequately discussed (formulation of adopted loss and training pipeline details are missing). \n\n-The experimental evaluation of the proposed approach is severely limited. Comparisons are conducted solely in simulation, with a single baseline that lacks any mechanism for failure identification. A comparison with approaches that apply failure detection to individual actions (some cited in the related work section) would be more appropriate to demonstrate the capabilities and limitations of the proposed approach. \n\n-The manuscript claims that an extension to real-world is possible due to the high-fidelity of the Gazebo simulator. This is a very bold statement that is not backed by any experimental data.\n\n-Some sections of the paper, (primarily the introduction and parts of the evaluation) are not well written and feature a large number of syntax and grammar errors and typos"
            },
            "questions": {
                "value": "1. Please provide a more formal and detailed description of the meta-learning pipeline used to train the Detect model. \n\n2. How does the proposed approach compare to other frameworks that adopt action-level failure detection on the tasks examined in the experimental evaluation?\n\n3. Have the authors experimented with the application of the proposed methodology in real-world data/settings?\n\nPresentation/Typos:\n\nAbstract: \n-cooking coffee -> making coffee\n-robot randomness execution -> robot random trajectory execution (?)\n\nIntro:\n-While research (...). They (..). -> .While research (...), they (...)\n-Action Model.T This (,,,)\n-The fine-tuned model are able -> is\n- for failure detection for the corresponding -> (...) of the corresponding\n-an baseline -> a baseline"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7916/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698774568484,
        "cdate": 1698774568484,
        "tmdate": 1699636971675,
        "mdate": 1699636971675,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "DvysvJSbIE",
        "forum": "JEYWfmz2TU",
        "replyto": "JEYWfmz2TU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7916/Reviewer_YtSr"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7916/Reviewer_YtSr"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a methodology for action-failure detection in a robotics setting. Prior work largely focuses on predicting the best action given an observation, but ignores action-failure detection which may be used to inform recovery. The authors conduct experiments in the Gazebo environment to evaluate their proposed meta-learning based framework. Experimental results show that the proposed method is able to detect action-failures better than the baselines."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- Sound motivation. The motivation behind this work is interesting and sound. \n- Good presentation. The text, along with the figures, does a good job of communicating ideas and results."
            },
            "weaknesses": {
                "value": "- Limited Evaluation. The proposed methodology is only evaluated in one very simple pick-and-place task in simulation. It is very difficult to believe that the results on this one simplistic environment will transfer to a variety of tasks, let alone to the real world.\n  - Furthermore, the authors claim that the \"high-fidelity nature of the simulator\" suggests their results will transfer to the real world. This is very difficult to believe, and completely dismisses the entirety of the sim2real literature, which attempts to address the well-known simulation-to-real gap. \n- Missing baselines. The proposed methodology is not compared to any baselines from prior work. \n  - Existing policies which learn from demonstrations for long-horizon tasks may implicitly learn to do failure detection -- these should be compared against as well.\n  - \"A solely learned action failure detector may not achieve successful generalization to the plan.\" Empirically demonstrating this by comparing against such a baseline would be more convincing.\n- Missing ablations. A number of design choices are made in the proposed intricate method, but very limited ablations are performed to evaluate these design choices."
            },
            "questions": {
                "value": "- The plots in Figure 3 seem to be over 10 random seeds, but there don't seem to be any error bars in the plots. Why is this the case?\n- The motivation behind the proposed work is that most prior work ignores failure detection, and that this can be problematic in long-horizon tasks. While the experiments design a methodology to detect failures, it is not shown how such a module can be used to improve the downstream policy. What use is a failure detection module if its result is not utilized to improve execution?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission7916/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7916/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission7916/Reviewer_YtSr"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7916/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698787777692,
        "cdate": 1698787777692,
        "tmdate": 1699636971546,
        "mdate": 1699636971546,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "6fp5RZa3C5",
        "forum": "JEYWfmz2TU",
        "replyto": "JEYWfmz2TU",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7916/Reviewer_3kJ5"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7916/Reviewer_3kJ5"
        ],
        "content": {
            "summary": {
                "value": "This papers proposes a framework that predicts action plans and detects failed execution of the plan.  The policy module is trained with imitation learning from human demonstrations, where trajectories are partitioned into segments.  The policy learns to predict discrete action labels, followed by a DMP controller to generate exact robot action.  The detection model is a transformer that predicts if the current observed states resulted from successful execution of a given action (stage).  The paper conducts experiments in a simulation environment."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The idea of prediction successful/failed action execution is indeed important.  Being able to detect failures enable the robot to replan / correct the original action plans."
            },
            "weaknesses": {
                "value": "1. Missing details:\n    a. How the action are discretized into labels is unclear\n    b. How to partition trajectories into action segment is unclear.\n    c. No details about meta learning.\n    d. How the DMP equation related to action label $z$ is unclear.\n    e. Details of Detection Model are unclear.  I'm not sure if the authors train separate model per action stage, or share the same model conditioned on different action stage label.\n    f. How to categorize each action into three stages is unclear.\n\n2. I'm not sure if using other action (stages) as negative samples make sense.  Because in the practice, the failed action execution usually results in environment states different from successful execution of other actions (e.g. dropping the mug on the floor does not belong to any other successful action).  I doubt that the Detection Model works in practice."
            },
            "questions": {
                "value": "1. How are actions discretized into labels? Also, what are the representations of robot actions?\n\n2. How to partition trajectories into action segments? Do you apply some hand-crafted heuristics, or learn a action segmentation model?\n\n3. What's the formulation of meta learning? What are the inputs, loss functions, and optimization procedure?\n\n4. How is the DMP equation related to action label $z$? There's no $z$ in the equation\n\n5. Do you train separate Detection Model for each action stage, or share the same model conditioned on different action stage label?\n\n6. How to categorize each action into grhee stages?\n\n7. Confusing denotation\n    * what does $M$ mean in the 1st paragraph of Setion 3.1: $D_M=\\{X_{m, t}, z_{m, t}\\}_{m=1:M, t=1:T}\n    * what do $y$ and $x$ mean in the DMP equation? (Section 3.3)"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7916/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698856584882,
        "cdate": 1698856584882,
        "tmdate": 1699636971426,
        "mdate": 1699636971426,
        "license": "CC BY 4.0",
        "version": 2
    }
]