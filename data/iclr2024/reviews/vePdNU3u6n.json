[
    {
        "id": "fdNTImeHja",
        "forum": "vePdNU3u6n",
        "replyto": "vePdNU3u6n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1736/Reviewer_Q1Z2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1736/Reviewer_Q1Z2"
        ],
        "content": {
            "summary": {
                "value": "This paper focuses on adapting deep learning models for edge devices with limited resources in dynamic environments. Traditional approaches involve deploying fixed models, which can result in reduced performance as scenarios change. This paper devises the Cloud-Edge Model Adaptation (CEMA) paradigm, in which the edge models only need to perform forward propagation and the edge models can be adapted online, by performing a data filtering strategy to allow high-quality data to be uploaded to the cloud and a replay-based entropy distillation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper is well-written, easy to follow.\n2. Manage what data to train is a sound approach to reduce training efficiency.\n3. Experiments are comprehensive."
            },
            "weaknesses": {
                "value": "From algorithmic perspective (low-informative data identification), the novelty is limited. There should be existing papers studied how to filter out low-informative data. These can be added into the paper related works and experiments to compare."
            },
            "questions": {
                "value": "1. In equation 6, is f\u03b8(x) and the pseudo labels y\u02c6  the same thing or different?\n2. To use KL divergence loss and CE loss together is interesting. I wonder how the hyperparameter alpha and beta change in different dynamic scenarios."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1736/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698701214436,
        "cdate": 1698701214436,
        "tmdate": 1699636102361,
        "mdate": 1699636102361,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "o3UzfJXHXk",
        "forum": "vePdNU3u6n",
        "replyto": "vePdNU3u6n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1736/Reviewer_5VG6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1736/Reviewer_5VG6"
        ],
        "content": {
            "summary": {
                "value": "The authors present a Cloud-Edge Model Adaptation (CEMA) paradigm that executes dynamic model adaptation, which puts all adaptation workloads to the cloud and only requires vanilla inference in edges. A replay-based entropy distillation method is also proposed to improve the adaptation performance of the edge model. Extensive experiments show that CEMA achieve SOTA performance with lower communication cost."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The proposed cloud-edge model adaptation (CEMA) framework seems novel to me.\n\n2. The CEMA paradigm only requires the edges to perform forward computation, which is important considering that backpropagation on edge is difficult.\n\n3. The proposed dynamic unreliable and low-informative sample exclusion are simple but effective.\n\n4. Extensive experiments and ablation studies are provided. There are large performance improvements over previous methods."
            },
            "weaknesses": {
                "value": "1. The proposed method is only evaluated on classification tasks. Could the proposed method be extended to other tasks such as object detection?"
            },
            "questions": {
                "value": "1. From table 15, it seems that the performance improves as the replay buffer increase. Why not use all the uploaded samples for adaptation?\n\n2. What's the performance if no teacher model is used?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1736/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698743692771,
        "cdate": 1698743692771,
        "tmdate": 1699636102278,
        "mdate": 1699636102278,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BYSYGO3wmE",
        "forum": "vePdNU3u6n",
        "replyto": "vePdNU3u6n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1736/Reviewer_iQ7Q"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1736/Reviewer_iQ7Q"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces a Cloud-Edge Model Adaptation (CEMA) paradigm for dynamic model adaptation. This approach delegates adaptation workloads to the cloud, thereby reducing the burden on edge devices. To minimize communication overhead, CEMA excludes unreliable high-entropy and low-informative low-entropy samples from uploading to the cloud. The model leverages knowledge distillation from the foundation model to guide the edge model, and a replay buffer is employed to enhance data utilization efficiency. Experimental results demonstrate a 60% reduction in communication costs compared to state-of-the-art methods on ImageNet-C."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "* This paper introduces the Cloud-Edge Model Adaptation (CEMA) paradigm, which addresses the dynamic model adaptation problem in a novel way.\n\n* The paper is of high quality, the language is clear, the structure is clean, the related work review in the appendix is adequate (including a valuable comparative analysis with various methods), and the figures are clear and easy to follow.\n\n* The manuscript is very clear in the explanations and the methodology. \n\n* As a practical method for model adaptation, I think this paper is of great chance to benefit the community, especially in real-world scenarios."
            },
            "weaknesses": {
                "value": "The overall framework appears to be somewhat straightforward as it contains multiple steps. The selection scheme used in the paper is relatively simple, as mentioned in Q1.  Additionally, the selection scheme is designed to exclude data that is either entirely out-of-distribution or absolutely in-distribution. There could be alternative methods to identify these two types of data beyond logits."
            },
            "questions": {
                "value": "Q1. The authors employ the entropy of the logits to assess uncertainty and selectively upload test samples, excluding both unreliable and low-informative ones. However, recent research has pointed out that neural networks can exhibit overconfidence. In such cases, can the uncertainty of a sample still be accurately evaluated based on the logits?\n\nQ2. The sample selection process involves dynamically adjusting the threshold and incorporating more samples into training. This idea seems to be similar to self-paced learning. Can the authors elaborate on the relationship between self-paced learning and their sample-selection scheme?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1736/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698934789968,
        "cdate": 1698934789968,
        "tmdate": 1699636102213,
        "mdate": 1699636102213,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "HwltmqWiA9",
        "forum": "vePdNU3u6n",
        "replyto": "vePdNU3u6n",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1736/Reviewer_xxok"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1736/Reviewer_xxok"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel learning paradigm aimed at enhancing the adaptability of cloud-edge models to address challenges posed by out-of-distribution test samples in real-world scenarios. The proposed approach is both practical and holds substantial significance. Specifically, to reduce communication overhead, the authors have incorporated a dynamic sample filtering strategy, allowing for the identification and exclusion of unreliable and low-informative samples. Furthermore, to further augment the edge model's capabilities and fully capitalize on the abundant cloud resources, the authors have integrated a substantial foundational model to serve as a guiding teacher for the edge model. Extensive experimental results on ImageNet-C and ImageNet-R datasets serves to underscore the efficacy of the presented method."
            },
            "soundness": {
                "value": "4 excellent"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "1.\tThe proposed collaborative cloud-edge model adaptation (CEMA) paradigm addresses a highly practical problem in the realm of cloud-edge model deployment, emphasizing the challenges of distribution shifts and the limited resources of the edge devices.\n2.\tThe proposed CEMA paradigm is a pioneering achievement in the field. It effectively divides adaptation tasks and distributes them between the cloud and edge devices, resulting in optimized resource utilization and the assurance of robust performance. \n3.\tThe experimental results demonstrate that the proposed method not only achieves the highest level of out-of-distribution performance but also reduces communication costs by an impressive 60% when compared to SOTAs on the ImageNet-C and ImageNet-R benchmarks.\n4.\tThe paper is well-written and easy to follow. Furthermore, it is accompanied by illustrative figures that enhance its overall readability."
            },
            "weaknesses": {
                "value": "1.\tIn Section Identification on low-informative samples, the author claims that \u2018We emphasize that uploading samples does not block the edge from inferring on next incoming samples. In other words, the processes of inference and uploading can be executed simultaneously.\u2019. How do the authors decide which test samples use which updated model to make a prediction? More explanations are required. \n2.\tIn Equation (6), the foundation model assigns pseudo labels to the uploaded samples. Simultaneously, the authors employ entropy to update the model, introducing another pseudo label (the maximum value). Is there a potential conflict between these approaches? What consequences might arise if the entropy loss is eliminated?\n3.\tIn Algorithm 1, line 3, \u2018Calculate S(X) via Eqn. (x)\u2019, It is confused what is Eqn.(x)."
            },
            "questions": {
                "value": "See weakness."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1736/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698978254880,
        "cdate": 1698978254880,
        "tmdate": 1699636102149,
        "mdate": 1699636102149,
        "license": "CC BY 4.0",
        "version": 2
    }
]