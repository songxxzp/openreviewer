[
    {
        "id": "IdSCes9QZS",
        "forum": "qT1I15Zodx",
        "replyto": "qT1I15Zodx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1691/Reviewer_gnhU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1691/Reviewer_gnhU"
        ],
        "content": {
            "summary": {
                "value": "The manuscript \"The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive Field\"\nintroduces an innovative approach, termed the Snowflake Hypothesis (SnoH), for training deep Graph\nNeural Networks. This hypothesis advocates for the uniqueness of the receptive field for each node in the\ngraph. The authors propose a method that utilizes gradient and node-level cosine distance as metrics to\nregulate the aggregation depth for each node. This approach, which can be likened to an \"early stopping\"\nmechanism at the node level through edge pruning, has shown effectiveness across a variety of backbone\nnetworks, offering enhanced generalizability and interpretability."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper is well-writtened, ensuring ease of comprehension. It offers a fresh perspective on tackling\nthe over-smoothing issue in GNN training through the early stopping method under the proposed\nSnowflake Hypothesis.\n2. The proposed method is not only simple and effective but also exhibits compatibility with diverse\nbackbone networks and training strategies. This adaptability encourages broader adoption and\npotential future extensions.\n3. The authors have conducted extensive experiments, encompassing different training schemes, a\nvariety of GNN backbones on diverse scale benchmarks. The results demonstrate that the framework\ncan serve as a universal operator for a range of tasks"
            },
            "weaknesses": {
                "value": "1. The methodology is heavily reliant on the adjacency matrix, which confines its applicability to\nmessage-passing based backbone networks, whose discriminative ability is limited by the 1-Weisfeiler-\nLehman Isomorphism Test. The manuscript does not offer a viable method for extending its\napplication to subgraph-based and multihop networks.\n2. Despite claims of broad applicability, the results presented in Table 1 primarily focus on deep GNN\nmodels, while regular network like GCN sexhibiting notable performance decline as the number of\nlayers increases. This observation brings into question the framework's generalizability across\ndifferent backbone networks.\n3. The manuscript lacks an in-depth analysis of the impact of the parameter on the training process of\nvarious models. Furthermore, it does not provide guidelines for setting in accordance with the\nspecific characteristics like the of the model and dataset."
            },
            "questions": {
                "value": "1. The paper choose cosine distance as a metric to determine when the node updation should stop. Why\nwas this method chosen, given its potential introduction of homogeneity assumptions, and could this\nlead to a decline in performance in heterophily networks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1691/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698794625987,
        "cdate": 1698794625987,
        "tmdate": 1699636097488,
        "mdate": 1699636097488,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "NUr65vCRiG",
        "forum": "qT1I15Zodx",
        "replyto": "qT1I15Zodx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1691/Reviewer_yhNV"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1691/Reviewer_yhNV"
        ],
        "content": {
            "summary": {
                "value": "This paper propose SnoH, which use different receptive fields for node aggregation operation in GNN.\n\nHowever, I am unconvinced that the proposed method offers significant advantages for graph learning tasks. While this method aims to boost deepGNN's performance, the enhancement seems marignal and is considerably distant from the state of the art. Additionally, the SnoH's performance on Ogbn-Arxiv appears random, which contradicts the assertion in the abstract that it \"serves as a universal operator for a range of tasks and shows considerable potential with deep GNNs.\""
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. marginally improve deepGNN's performance.\n2. evaluate the model on a range of dataset."
            },
            "weaknesses": {
                "value": "1. The motivation is unclear.\n2. overclaim, SnoH does not always improve deepGNN's performance.\n3. The GNN backbone is far from STOA, both on Ogbn-Proteins and Ogbn-arxiv dataset."
            },
            "questions": {
                "value": "1. The motivation is unclear, why enhance deepGNN? many GNN use 2 or 3 layers but still achieve good performance. For example, [1] use 3 layers and achieve 73\\% on ogbn-arxiv, higher than the model's performance.\n\n2. In Table 4, performance drops after using SnoHv1, so SnoHv1 is not always helpful for deepGNN.\n\n3. Is SnoH only limited to the GNN proposed here or it also enhance other models' performance,  I would suggest evaluating SnoH on GNN  models that have demonstrated strong performance on Ogbn-Proteins and Ogbn-arxiv.\n\n\n[1] Huang, Qian, et al. \"Combining label propagation and simple models out-performs graph neural networks.\" arXiv preprint arXiv:2010.13993 (2020)."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1691/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698820412015,
        "cdate": 1698820412015,
        "tmdate": 1699636097409,
        "mdate": 1699636097409,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QCc3SMsG4Y",
        "forum": "qT1I15Zodx",
        "replyto": "qT1I15Zodx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1691/Reviewer_8f4f"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1691/Reviewer_8f4f"
        ],
        "content": {
            "summary": {
                "value": "The authors propose a new training paradigm for Graph Neural Networks (GNNs): they use a masked adjacency matrix to prune the graph structure.\nThey evaluate on several models and datasets"
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Originality: as far as I can judge, this is a novel application.\nQuality: empirical validation is thorough, and the results appear convincing.\nClarity: while there were some stilistic issue (see Weaknesses), the underlying thoughts were mostly clear. I was able to follow the exposition without much trouble.\nSignificance: given the solid results, I think this paper is relevant for the GNN community"
            },
            "weaknesses": {
                "value": "The paper is solid, but currently has a lot of stylistic issues. For example, the text contains many filler-sentences (\"We have another interesting observation\") and hyperlatives (\"These astonishing results clearly verify the effectiveness of our algorithm.\").  Please go over the text, and keep in mind that good writing should have active voice, be **clear** and **concise**. There is no need to write \"we meticulously conduct a multitude of experiments to validate our hypothesis...\"  when one could just write \"we validate our hypothesis...\". This will make the text easier to read. The goal should be to convey your findings, not to convince the reviewers how awesome you are. \n\nI'd also suggest going over the abstract: it's the most important piece of the text, and it's probably the *only* piece of your work most people will read. The current abstract contains many awkward sentences (what does \"Given that the potency of numerous CV and language models is attributable to that support reliably training very deep architectures\" even mean?). If available, try to work with someone who has experience in editing text and making it more readable. I think your work is overall interesting, it deserves a good, clean packaging.\n\nI would also strongly suggest to remove the \"red numbers\" in Table 1, and instead add variances: The relevant part is what the average performance over 5 runs is, plus how much variance there will be between runs. The \"best result out of N runs\" is not valuable information, it's random-seed-lottery."
            },
            "questions": {
                "value": "What is the running time (wall clock, FLOPS) of your method vs the baselines?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1691/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699022457036,
        "cdate": 1699022457036,
        "tmdate": 1699636097347,
        "mdate": 1699636097347,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "wamIMU4tc1",
        "forum": "qT1I15Zodx",
        "replyto": "qT1I15Zodx",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1691/Reviewer_ngCy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1691/Reviewer_ngCy"
        ],
        "content": {
            "summary": {
                "value": "The paper presents the \"Snowflake Hypothesis\" for Graph Neural Networks (GNNs) to address overfitting and oversmoothing by assigning unique receptive fields to nodes. This hypothesis is operationalized using edge pruning (via gradient and node-level distance metrics) in order to modify the receptive field / aggregation strategy for each node. The experiments show that this can be flexibly applied with different training schemes and deep GNN backbones on large-scale benchmarks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "- Tackles important problem (mitigates oversmoothing in GNNs)\n- The second version of the proposed method (SnoHv2) is scale to large-scale graphs\n- Extensive empirical analysis: different training schemes, datasets, GNN backbones. Results suggest that SnoHv{1,2} improve performance. This supports the hypothesis that for a subset of nodes, early stopping is necessary to mitigate oversmoothing, especially as depth increases."
            },
            "weaknesses": {
                "value": "- Paper is not well-written, would benefit from a reorganization with a shorter and more to-the-point introduction,  preliminaries and problem setup, and the algorithm describe more formally + clearly.\n- Unclear if the performance improvements in general are statistically significant, an easy way to fix this is via multiple runs\n- \u201cAlthough DropEdge can improve performance through implicit data augmentation, it lacks interpretability in its aggregation strategy.\u201d I am not sure how this improves interpretability over DropEdge or pruning.\n- The high-level approach in SnoHv{1,2} is largely heuristic-driven and lacks grounding"
            },
            "questions": {
                "value": "None, please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1691/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699038706935,
        "cdate": 1699038706935,
        "tmdate": 1699636097279,
        "mdate": 1699636097279,
        "license": "CC BY 4.0",
        "version": 2
    }
]