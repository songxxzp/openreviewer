[
    {
        "id": "tH6SfUDtf4",
        "forum": "Xz13DtbOVW",
        "replyto": "Xz13DtbOVW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1562/Reviewer_qBid"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1562/Reviewer_qBid"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method for mitigating disparate effect on model accuracy by formulating the task as a constrained optimization problem and solving it via alternative gradient descent. The introduced approach manages to decrease the gap between average model performance and worst performance on a subgroup of data while preserving the mean accuracy on the target task."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The problem being addressed is quite novel in sparsification community and is of significant interest to practitioners, especially in safety-critical applications. The approach looks very reasonable and directly optimizes the imposed constraints via solving a min-max problem. The method is quite non-trivial and comprises several interesting ideas - alternating between non-differentiable accuracy constrain term and excess loss term, as well as use of replay buffers for stabilization of optimization. \n\nCEAG outperforms existing alternatives on a couple of benchmarks - UTKFace and CIFAR100. The method doesn\u2019t add significant computation overhead compared to the standard training procedure."
            },
            "weaknesses": {
                "value": "While the proposed method manages to keep train accuracy on subgroups within desired tolerance bounds, seems it has hard to achieve on the test data, especially in the setting with many classes and subgroups (for example in the provided CIFAR-100 experiment). \n\nThe difference between $\\mathrm{max}_g \\psi_g $ on the hold-out-data between NFT and CEAG doesn\u2019t seem to be very significant in many cases - 2.0 vs 2.1 on 99% sparsity UTKFace *(Table1)*, 3.3 vs 3.6 for 92.5% *(Table2)*, 13.8 vs 14.3 on CIFAR-100 *(Table3)*. Given the standard deviation of the runs, improvement of CEAG appears to be statistically insignificant. \n\nExperimental validation is not exhaustive enough. To demonstrate the efficiency in a more large scale and practically relevant scenario one could consider more diverse and large-scale dataset, such as ImageNet (or ImageNet-LT version), or one of the iNaturalist versions, considering only large hierarchy groups to make the task computationally tangible. \n\n*Minor*. The pruning strategy called in the paper is customary named **Gradual Magnitude Pruning** (GMP) [2], where after each pruning step one continues training the model from the current state. **Iterative Magnitude Pruning** (IMP) [3] adopted in discovery of Lottery Tickets rewinds the weights to initialization after pruning step. I would suggest calling the method GMP to avoid confusion. \n\n---\n[1] Liu, Ziwei, et al. \"Large-scale long-tailed recognition in an open world.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.\n\n[2] Zhu, Michael, and Suyog Gupta. \"To prune, or not to prune: exploring the efficacy of pruning for model compression.\" arXiv preprint arXiv:1710.01878 (2017).\n\n[3] Frankle, Jonathan, and Michael Carbin. \"The lottery ticket hypothesis: Finding sparse, trainable neural networks.\" arXiv preprint arXiv:1803.03635 (2018)."
            },
            "questions": {
                "value": "How sensitive is the algorithm to the initialization of dual parameters $\\lambda_g$ and the corresponding update rule?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_qBid",
                    "ICLR.cc/2024/Conference/Submission1562/Senior_Area_Chairs"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1562/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698344111769,
        "cdate": 1698344111769,
        "tmdate": 1700244174464,
        "mdate": 1700244174464,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "BB6Dm9qkz2",
        "forum": "Xz13DtbOVW",
        "replyto": "Xz13DtbOVW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1562/Reviewer_KSs2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1562/Reviewer_KSs2"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a new approach for fine-tuning sparse models after pruning. The proposed approach involves formulating a constrained problem, where loss function is optimized subject to a group-wise accuracy constraint (that is, the accuracy drop for each group should be bounded by a tolerance $\\varepsilon$). This Lagrangian of this constrained problem is then optimized with standard gradient-based methods. This approach is empirically shown to reliably generate models where the differences in the group-wise impact of sparsity on accuracy is minimized."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper has several strengths:\n\n* The proposed approach is interesting, novel, and flexible, and reliably reduces group wise disparities in accuracy after pruning.\n* The empirical evaluation is very thorough.\n* Limitations of the proposed methods and ethical considerations are discussed thoroughly as well.\n* In the appendix, variations of the main results are discussed as well.;/\n* The writing and presentation is clear."
            },
            "weaknesses": {
                "value": "The paper has a few weaknesses. \n\n* This method is independent of the choice of pruning strategy. However, it would have been nice to see the experiments replicated for other pruning strategies, including structured pruning methods. \n* A more detailed discussion on the feasibility of the constrained problem given in equation (4) would have been useful for readers."
            },
            "questions": {
                "value": "* Have the authors tried applying this technique to other pruning methods? For instance, how well would this fine-tuning method work if structured pruning was used instead of unstructured pruning? How well would the method work if other unstructured pruning methods were used instead of IMP (i.e. SynFlow [1] or SNIP [2])?\n* Is there a sparsity level at which the method fails to achieve models with the desired worst-case groupwise accuracy loss? Put another way, is there a sparsity level at which the constrained optimization problem described in eq. (5) become infeasible? Can the authors comment on how this might play out in the case of structured pruning?\n* Are there any formal results that can be provided for solving the CEAG (eq (5))? For instance, is Algorithm 1 guaranteed to find a solution provided the feasible set is nonempty?\n* Have the authors considered ways by which the test-case performance can be improved, say by dataset splits?\n* Is the CEAG method affected by dataset imbalance? Suppose certain groups have comparatively fewer samples in the dataset. How, if at all, would this affect the efficacy of the method?\n\n[1] \"Pruning neural networks without any data by iteratively conserving synaptic flow\", Tanaka et al, 2020.\n\n[2] \"SNIP: Single-shot Network Pruning based on Connection Sensitivity\" Lee et al, 2019."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_KSs2"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1562/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698833862775,
        "cdate": 1698833862775,
        "tmdate": 1699636084489,
        "mdate": 1699636084489,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "uEJt2M5oZm",
        "forum": "Xz13DtbOVW",
        "replyto": "Xz13DtbOVW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1562/Reviewer_Haeo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1562/Reviewer_Haeo"
        ],
        "content": {
            "summary": {
                "value": "This paper provides a new training protocol to manage pruning induced bias. The main aim is to create algorithms in which the difference in accuracy between any two groups is minimised. The authors highlight that their main focus is lessen the effects of compression and thus they treat dense models as baseline."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This is a useful research area. With concerns of AI inclusion and climate change, sparse models are very appealing. The authors provide a method to ameliorate some of the effects of compression by limiting the disparity between group performance.\nThis is a well written paper and the methodology is clear. Implementation and results are well described and the examples in the appendix provide further grounding on their work."
            },
            "weaknesses": {
                "value": "It is not clear from the analysis provided that solutions always exist given the constraints. Perhaps the authors could more light on this. Is there a relationship between the starting point and how tight the constraints can be?"
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_Haeo"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1562/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699020655232,
        "cdate": 1699020655232,
        "tmdate": 1699636084408,
        "mdate": 1699636084408,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SBnrfujZCB",
        "forum": "Xz13DtbOVW",
        "replyto": "Xz13DtbOVW",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1562/Reviewer_cVd6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1562/Reviewer_cVd6"
        ],
        "content": {
            "summary": {
                "value": "This paper deals with the problem of pruning models with desire of not decreasing performance on subsets via constraints."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The technique is solid and the experiments are sound."
            },
            "weaknesses": {
                "value": "Can the paper deals with other pruning techniques to demonstrate the effectiveness of constraint to subsets?"
            },
            "questions": {
                "value": "Can we give some formal results with Equation(6) like the analytical solution or convergenece guarantee?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1562/Reviewer_cVd6"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1562/-/Official_Review"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699685275548,
        "cdate": 1699685275548,
        "tmdate": 1699685275548,
        "mdate": 1699685275548,
        "license": "CC BY 4.0",
        "version": 2
    }
]