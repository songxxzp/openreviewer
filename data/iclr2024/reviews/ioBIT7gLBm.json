[
    {
        "id": "MjGrQUbLL5",
        "forum": "ioBIT7gLBm",
        "replyto": "ioBIT7gLBm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission294/Reviewer_zn9X"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission294/Reviewer_zn9X"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces Hard View Selection (HVS), aiming to improve the effectiveness of pretraining in contrastive learning scenarios. By selecting the \"hardest\" views during training, HVS pushes the model to learn more robust features. The authors claim compatibility with several popular contrastive learning methods, like SimSiam, DINO, and SimCLR, and demonstrate its effectiveness using ImageNet for pretraining."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Novel Approach: The paper introduces a novel concept of \"Hard View Selection (HVS),\" which aims to improve the efficacy of pretraining in contrastive learning settings.\n- Compatibility: One of the significant advantages of HVS is its compatibility with a variety of existing contrastive learning methods like SimSiam, DINO, and SimCLR. This makes it easily adaptable in various existing pipelines.\n- Simplicity: The method is described as being simple to integrate, requiring only the ability to compute sample-wise losses. This lowers the bar for adoption and experimentation.\n- Focus on Challenging Samples: By focusing on the \"hardest\" views during training, the paper takes an interesting approach to make the model focus on challenging aspects of the data, potentially leading to more robust feature learning."
            },
            "weaknesses": {
                "value": "- Computational Cost: The method involves selecting the \"hardest\" views by running forward passes for multiple view pairs, which could increase the computational cost of training, especially for large-scale datasets or complex models.\n- Lack of Theoretical Analysis: The paper seems to focus on empirical validation but doesn't provide a theoretical foundation for why the \"hard view selection\" approach should work, which could limit its scientific rigor.\n- Unclear Impact on Convergence: Introducing harder samples could potentially slow down the convergence of the training process"
            },
            "questions": {
                "value": "Could you elaborate on the computational overhead introduced by the Hard View Selection (HVS) method, especially when dealing with large-scale datasets or complex models?\n\nCould you provide more details on the complexities involved in computing sample-wise losses, particularly in the context of different neural network architectures?\n\nDoes the introduction of \"harder\" samples through HVS have any noticeable impact on the convergence speed or stability of the training process?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission294/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission294/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission294/Reviewer_zn9X"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission294/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698781027176,
        "cdate": 1698781027176,
        "tmdate": 1699635955621,
        "mdate": 1699635955621,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Vzvr3UhyZG",
        "forum": "ioBIT7gLBm",
        "replyto": "ioBIT7gLBm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission294/Reviewer_PWAF"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission294/Reviewer_PWAF"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes an approach to improve self-supervised contrastive learning methods (computer vision) that aim to learn features invariant to different views (i.e. augmentation) of an input image. The paper introduces a simple (and easy to implement) algorithm \u201cHard View Selection (HSV)\u201d for selecting the view pair used in SSL contrastive training. The goal of HSV algorithm is to select relatively hard views that improve the model's performance. HSV comprises of making forward calls with a set of randomly selected views, then making forward calls to pick out the view pair with highest loss for backpropagation step. The paper hypothesizes that selecting the view pair that are dependent on the current state of the model parameters yields the most benefits rather than using a fixed/random/learned adversary policy. The benefit of the proposed method is to empirically improve the SSL feature representation so that it could be show improvement for other downstream tasks (classification, detection, etc.). The paper shows that HSV is compatible with other contrastive methods like DINO, SimSiam and SimCLR."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The paper explores a strategy (HSV) for selecting the views (image augmentation pairs in contrastive learning) that leads to performance improvement on downstream tasks.\u2028HSV is a simple and easy to implement view-selection strategy that achieves improvement on ImageNet linear classification accuracy (order of 0.55% - 1.93%). The paper provides detailed ablation experiments to find an alternative view-sampling strategy (both learning-based eg. STN and statistics-based approach). Ablation experiments regarding the initial number of view pairs that determine the hardness of the selected view pair is also provided.(higher initial pool of view pairs would lead to more adversarial view selection for CL training). The paper is well-written and easy to follow. The paper provides code for reproducibility."
            },
            "weaknesses": {
                "value": "It would be helpful for the reader to get a better understanding of the following questions/suggestions:\n\n1. A detailed analysis of the HVS overhead in terms of running time/ wall clock/ FLOPs/ throughput along with memory requirement for each the baselines DINO (2x overhead), SimSiam(1.55x overhead), SimCLR.  Preferably in a format of a table.\n\n2. Extending on the above point, it seems since the overhead is added due to HSV, a more fair choice of x-axis in table 1 (and other tables) should be training time instead of epochs, as we see in table 1, that algorithm's performance increases with longer epoch training. For example assuming DINO + HSV is twice slower than DINO, it would be great to see a performance comparison between DINO+HSV at epoch 100 with DINO at epoch 200 (similarity with other baselines).\n \n3. It might be good to see some qualitative results on how good the learned features are with HSV strategy. For example, adding some attention maps as done in DINO paper, to get an idea if the attention maps also improves using HVS.\n\n4. As HSV is proposed as a general view sampling strategy it might be helpful to see some results on other relevant baselines like SimCLR_v2, DINO_v2, Swav. If some of the recent methods require huge amounts of compute or dataset, showing some results on ImageNet with lower training epochs would give the reader a better idea about the efficacy of the hard view selection strategy.\n\n5. It could be a good idea to relate and mention in the sub-section of \u201cTaking a Closer Look at the Intersection over Union\u201d with the idea of \u201clocal-to-global\u201d correspondences (as introduced in SimCLR :  Global and local views/Adjacent views and DINO : global and student view). Qualitatively, looking at Fig2, it does look like a HSV selected view pair comprises of global view (larger area crop) and student view (small area crop)."
            },
            "questions": {
                "value": "Some questions/suggestions: \n\n1. How many seeds are used for Table 1 average computation. \u201cRef: averaged over multiple seeds unless otherwise mentioned\u201d\n\n2. It is stated in the paper that SimSiam+HSV has 1.55x overhead and DINO+HSV has 2x overhead. Since DINO uses much more views (10 views leading to 128 max view pairs for forward call) than SimSiam (2 views that leads to 4 view pairs for forward call). What is the time taken for doing 1 DINO forward call and 1 backward call as the reviewer was expecting the DINO+HSV to be slower than 2x.\n\n3. The reviewer was wondering about the combination of HSV with random view pair selection in order to reduce the computational  overhead. Maybe having 50% random and 50% HSV samples for training would be nice ablation experiment to shed light on the requirement of HSV adversarial pair selection. If this works without decreasing the performance with a large margin, then it would be interesting to see some ablation on tuning this percentage of HSV samples in training."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission294/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission294/Reviewer_PWAF",
                    "ICLR.cc/2024/Conference/Submission294/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission294/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698824546316,
        "cdate": 1698824546316,
        "tmdate": 1700640800400,
        "mdate": 1700640800400,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "INQ8xtWEfP",
        "forum": "ioBIT7gLBm",
        "replyto": "ioBIT7gLBm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission294/Reviewer_seyJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission294/Reviewer_seyJ"
        ],
        "content": {
            "summary": {
                "value": "In pair-based self-supervised representation learning methods (e.g. SimCLR), positive pairs are constructed using data augmentation. \nThis paper proposes to produce many random positive pairs (e.g. 4) for any query image and compute loss over the \"hardest\" one.\nIn a way, it is a hard positive (or view) selection method.\nIt is shown that this technique can be utilized for various methods such as DINO, SimSiam and SimCLR, yielding consistent improvements on ImageNet classification and several transfer learning scenarios."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The main idea behind the paper is to make the training of pair-based self-supervised methods harder. \nThis is done by producing several random positive pairs and backpropagating gradients through the hardest one.\nIt is shown that this strategy picks pairs that overlap less, hence models learn better representations on ImageNet-1K after being trained the same amount of \"epochs\".\nBetter representations mean consistent improvements on ImageNet-1K classification and various transfer learning experiments including classifcation, detection and segmentation.\n\nOverall, the paper is easy to read."
            },
            "weaknesses": {
                "value": "I have two main concerns, listed below.\n\n1) As shown in Figure-3, positive pairs used for computing loss overlap less thanks to the proposed method, and this facilitates better representations. Tian 2020b already shows this phenomenon, i.e. there is a sweat spot in the IoU ratio which leads to the \"optimal\" performance. It is not clear what more this paper offers. One distinct angle in this paper is the fact that multiple positive pairs are utilized during training (although loss is computed over only 1 pair in the end). I wonder what would happen if loss was computed over all crops, by simple averaging or weighted averaging (depending on the difficulty of a pair).\n\n2) The computational overhead introduced by the proposed method (\"about a factor of 1.55\u00d7 for SimSiam\") is a bit unfair for the baselines. I wonder if this extra compute time can be used in favor of other models too, e.g. by training models longer. Cause longer training schedules often bring substantial gains for self-supervised methods. Also, it should be noted that the proposed method has seen more samples (due to encoding multiple pairs) which already impacted for instance batch-norm statistics (although loss is not backpropagated over unused pairs). Then it would be nice to see baselines processed 4x more samples."
            },
            "questions": {
                "value": "I would like the authors to address the concerns I raised in the weaknesses part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission294/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698872496817,
        "cdate": 1698872496817,
        "tmdate": 1699635955458,
        "mdate": 1699635955458,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "jesK5ZY9IU",
        "forum": "ioBIT7gLBm",
        "replyto": "ioBIT7gLBm",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission294/Reviewer_a1az"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission294/Reviewer_a1az"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel approach called Hard View Selection (HVS) to enhance self-supervised methods by improving the selection of image views during training. HVS effectively increases the task difficulty during pretraining and achieves competitive or better results compared to the conventional baseline, improving accuracy on ImageNet and transfer tasks across various methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The method is simple to understand and sound\n- Augmentations are crucial in self-supervised learning. However, they are either hardcoded or grid-searched. It is good to see that there is research in the direction of picking augmentations automatically\n- The authors try many methods and validate with many downstream tasks"
            },
            "weaknesses": {
                "value": "- The title says \u201ccontrastive\u201d but most of the experiments use non-contrastive methods like simsiam and dino. This is confusing.\n- In addition to the point above, it actually seems that the proposed method is better defined for non-contrastive losses. In fact, for contrastive losses (which contrast the attraction of the positives with the repulsion of the negatives) the method is not guaranteed to find the hardest possible set of positives and negatives. This would require exploring all the possible combinations of negatives, which is intractable. A better idea would be to use all the negatives from all the views at the denominator. In that case, since the denominator works as a max at low temperatures, you would be \u201cguaranteed\u201d to have the hardest negative. This is not described and discussed in the paper except one sentence at the end of 3.3.\n- In algorithm 1, the authors report that they first organize the views into pairs and then forward each pair. This entails forwarding every view multiple times (one view can be in more than one pair). This is confusing and does not make sense at all. It would be better to first forward the views separately and then compare them 2 by 2. Can the authors please explain why they first create the pairs and then forward?\n- Why not just make all comparisons and backprop all of them? Why is this not ablated?\n- Figure 4 shows that the manual min IoU policy works for SimSiam but not for DINO. Maybe it\u2019s just that multi-crop does not play well with min IoU. I am not fully convinced by this ablation.\n- Figure 5 shows that performance decreases over time, which might be due to overfitting (or might not). In any case, cifar100 is not a good benchmark to make a point about longer training.\n- Throughout all the tables the performance improvements are small. Once factored in the ~2x slowdown, there seems to be almost no difference. This is not great, also considering that the proposed method probably uses a lot more memory than the vanilla method, and it is also more complex to implement. In practice, I would rather train longer with a well-known vanilla method than using the proposed method.\n- In addition, there exist more efficient ways to learn representations nowadays (e.g. CLIP). There are many papers that use multiple views for CLIP as well. Why not testing them?\n- There are many other papers that treat this topic. They were not discussed. A few examples:\nThere are many other papers that treat this topic. They were not compared with. A few examples: \"On the Importance of Asymmetry for Siamese Representation Learning\", \"What Makes for Good Views for Contrastive Learning?\"."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission294/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699303874504,
        "cdate": 1699303874504,
        "tmdate": 1699635955349,
        "mdate": 1699635955349,
        "license": "CC BY 4.0",
        "version": 2
    }
]