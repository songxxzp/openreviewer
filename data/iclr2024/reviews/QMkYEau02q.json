[
    {
        "id": "4QaTHvLxB8",
        "forum": "QMkYEau02q",
        "replyto": "QMkYEau02q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1523/Reviewer_hFQ3"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1523/Reviewer_hFQ3"
        ],
        "content": {
            "summary": {
                "value": "In this paper, the author proposes a new physics-informed framework to solve PDEs, with the aim to achieve enhanced downscaling reconstruction and temporal forecasting in weather forecasting problems. This is an important and challenging problem. The author conducts a series of experiments to justify the effectiveness of the proposed model in both downscaling and forecasting cases. Additionally, it is demonstrated that the proposed model can be easily incorporated with other deep learning models as a plug-in module."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The paper provides a clear and effective explanation of the background and justifies the proposed method through a comprehensive series of experiments.\n2. The paper studies an important and challenging problem. \n3. It demonstrates how the proposed method can be seamlessly integrated as a plug-in module into additional deep learning models."
            },
            "weaknesses": {
                "value": "1.\tThe presentation in the method section remains unclear in some parts, particularly in explaining the model's approach to downscaling. A detailed explanation of the model's design rationale for addressing the downscaling problem, including its advantages over existing methods, would be beneficial.\n2.\tThe authors may want to discuss the difference/superiority between the proposed method with existing works on similar topics (e.g., decomposing PDEs into components using neural networks and capturing temporal dynamics). The paper needs to more clearly articulate the unique advantages or improvements of the proposed method over these existing approaches."
            },
            "questions": {
                "value": "See weakness points above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1523/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698695824103,
        "cdate": 1698695824103,
        "tmdate": 1699636080850,
        "mdate": 1699636080850,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Kp1nkQzccL",
        "forum": "QMkYEau02q",
        "replyto": "QMkYEau02q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1523/Reviewer_W7oo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1523/Reviewer_W7oo"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes a new method that blends deep learning and traditional numerical methods for weather downscaling and forecasting. The main idea is to train neural networks to represent different components in a partial differential equation (PDE). These networks can then either be used independently to perform weather downscaling or used to guide the training of a weather forecasting model. The experiments on different datasets show that the proposed method outperforms other baselines on weather downscaling, and boosts the performance of existing weather forecasting models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- Relevance: The paper aims to combine the strengths of deep learning and numerical methods for weather prediction tasks, which I think is a very important and interesting direction to pursue. \n- Originality: To the best of my knowledge, the idea of the paper is original. \n- The authors conduct a large number of experiments, and the empirical results support their claim."
            },
            "weaknesses": {
                "value": "### Paper presentation\n- Overall, I think the paper writing and presentation can be improved a lot. I had to spend quite a long time reading Section 3, as different sections were not connected very well. It would be much easier for readers if the authors first presented an overview of the method, i.e., learn a PDE using neural networks that can later be used for weather downscaling or guiding weather forecasting models. While the authors did mention this in the introduction, I think it's good to also repeat this at the beginning of Section 3 as it's important to understand the method.\n- Many details of the method and experiments are missing: what partial derivative candidate terms are used and why, the weights of different loss terms, the network architectures, training details (e.g., learning rate, scheduling, etc.), and implementation of the finite difference method, etc. These details are needed to understand how to train the model in practice, and to improve the reproducibility of the paper.\n\n### Soundness\n- The main claim of the paper is the physical mechanism in Equation (1) provides guidance to optimizing neural networks that better obey physics. However, I wonder if this is true, because all components of the PDE are parameterized as a neural network and are learned from data. Therefore, all the Equation (1), or correspondingly, the L_physics loss does is to make sure these different networks \"agree\" in a certain way, and it's not guaranteed that they'll agree with physics laws after training.\n\n###  Significance\n- My biggest concern I have about the paper is its significance. While the experiments support the authors' claim, they are quite small-scale compared to existing works, and seem to use non-sota baselines for comparison.\n- The paper uses 3 regional datasets that specifically target China. These datasets are not standard and I've not seen them used in previous works in deep learning for the weather domain. Can the authors justify their choice of data? What stops the authors from using more standard datasets such as ERA5 for weather forecasting, which have been a standard in the literature, and have also been used in different benchmarks [1, 2, 3]?\n- The baselines used for comparison are not strong enough. For downscaling, why don't the authors compare with models that were specifically proposed for downscaling such as YNet [4] and DeepSD [5], or more recent super-resolution models? For weather forecasting, there have been significant advancements in recent years, including FourCastNet [6], ClimaX [7], GNN [8], PanguWeather [9], Graphcast [10], etc. The paper only compares with FourCastNet, which is the least-performing method among these baselines. Can the authors include more recent baselines for weather forecasting? It would be more convincing if the proposed framework also improves sota methods.\n- Scalability: I suspect the proposed method will scale well to more data and bigger/better base models. As the training loss is computed for each grid point (x, y, t), the number of training samples will increase significantly with higher spatial and temporal resolutions. Is this the reason why the experiments are limited to small-sized datasets?\n- Ablation studies are lacking. It's important to understand the importance of different components in the framework, such as the physics loss, regularization loss, etc. \n\n### Minor comments\n- Equation (7) is strange because the PDE parameters are already learned and fixed. They should not appear here.\n- The papers I cited here are relevant and should be discussed in the paper.\n\n[1] Rasp, Stephan, et al. \"WeatherBench: a benchmark data set for data\u2010driven weather forecasting.\" Journal of Advances in Modeling Earth Systems 12.11 (2020): e2020MS002203.\n\n[2] Rasp, Stephan, et al. \"WeatherBench 2: A benchmark for the next generation of data-driven global weather models.\" arXiv preprint arXiv:2308.15560 (2023).\n\n[3] Nguyen, Tung, et al. \"ClimateLearn: Benchmarking Machine Learning for Weather and Climate Modeling.\" arXiv preprint arXiv:2307.01909 (2023).\n\n[4] Liu, Yumin, Auroop R. Ganguly, and Jennifer Dy. \"Climate downscaling using YNet: A deep convolutional network with skip connections and fusion.\" Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2020.\n\n[5] Vandal, Thomas, et al. \"Deepsd: Generating high resolution climate change projections through single image super-resolution.\" Proceedings of the 23rd acm sigkdd international conference on knowledge discovery and data mining. 2017.\n\n[6] Pathak, Jaideep, et al. \"Fourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural operators.\" arXiv preprint arXiv:2202.11214 (2022).\n\n[7] Nguyen, Tung, et al. \"ClimaX: A foundation model for weather and climate.\" arXiv preprint arXiv:2301.10343 (2023).\n\n[8] Keisler, Ryan. \"Forecasting global weather with graph neural networks.\" arXiv preprint arXiv:2202.07575 (2022).\n\n[9] Bi, Kaifeng, et al. \"Pangu-weather: A 3d high-resolution model for fast and accurate global weather forecast.\" arXiv preprint arXiv:2211.02556 (2022).\n\n[10] Lam, Remi, et al. \"GraphCast: Learning skillful medium-range global weather forecasting.\" arXiv preprint arXiv:2212.12794 (2022)."
            },
            "questions": {
                "value": "- In Equation (4), can we use n' and m' (coordinates of the high-resolution data) too?\n- For the downscaling task, how do you make predictions after training given the coarse resolution data?\n- The PDE is learned but only used to provide guidance to training other neural networks. Can we solve this learned PDE to solve weather tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1523/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698732388481,
        "cdate": 1698732388481,
        "tmdate": 1699636080749,
        "mdate": 1699636080749,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Va6VOJwYRS",
        "forum": "QMkYEau02q",
        "replyto": "QMkYEau02q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1523/Reviewer_MMEb"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1523/Reviewer_MMEb"
        ],
        "content": {
            "summary": {
                "value": "This paper addresses two common challenges in weather and climate modeling (downscaling and forecasting). There are currently two separate ways of modeling these problems: numerical physics based models and statistical machine learning models. The paper attempts to get the best of both worlds, by proposes a machine learning approach that incorporates physics domain knowledge.\n\nFor downscaling, the method starts from a physics-informed neural network (PINN) that takes as input spatiotemporal coordinates and outputs weather variables (e.g. temperature). PINN models use a set of known physical constraints (in the form of PDEs) to penalize models for violating physical laws. However, this model does not assume that physical constraints are given --- instead, they must be discovered from the data. The method entails fitting a PINN neural network in a supervised manner without physics constraints, then identifying relationships in the form of a sparse set of PDEs that relate the variables of interest. These physical relationships contain parameters learned from the data, so they are able to capture subgrid effects that are not captured by traditional physics constraints. Since these relationships are assumed to remain constant throughout space and time, it is reasonable to assume that they can be learned efficiently.\n\nFor forecasting, the method starts from a typical machine learning forecasting model and then uses the same strategy to learn physical relationships and penalize the forecasts for violating them.\n\nThe method is tested on three different weather datasets and compared to other deep learning methods."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The paper addresses an interesting problem, provides a reasonable solution, and demonstrates its value through experiments. \n- Figures 1 and 2 are helpful in explaining and comparing the steps of the methods. \n- It was exciting to see the section discussing the physical relationships that were discovered by the model. The discovery of sparse, interpretable models like this is of high interest."
            },
            "weaknesses": {
                "value": "- Overall, I found the writing to be unclear and difficult to follow. This includes details of the method and its relationship to previous work.\n- The experiments comparing on multiple datasets and multiple benchmark architectures are nice, but there is no discussion of hyperparameter optimization, early stopping, and how the competitor models were implemented. A few details were in the appendix but not enough details are provided to be confident in these results.\n- While I agree that this is an interesting method, I disagreed with many of the ways the authors motivated the work.\n- In section 1, I don't agree with the motivations. (1) \"While deep learning models can excel at fitting complex patterns in training data, they lack the ability to generalize well to unseen scenarios by capturing noise or specificities of the training data. Moreover, the models often do not consider the physical mechanisms that govern weather systems, leading to predictions that may be statistically accurate for the training dataset but physically inconsistent.\" Yes, overfitting is a problem in ML, but models can still generalize. In the second sentence, it's unclear what \"physically inconsistent\" means in this context. I believe the authors are referring to the idea that incorporating physics knowledge is a useful source of inductive bias that will help the model generalize better.\n- In section 3.3 the authors say PINNs won't work for forecasting because a dense neural network lacks the advantages of more complicated \"state-of-the-art\" architectures. It's not the architecture that is important here, it is how the problem is being modeled, i.e. the inputs and outputs.\n- In section 4.1, \"Unlike computer vision, the weather data has multiple variables and the spatio-temporal dependencies are not completely local\". I disagree. Natural images have RGB channels (plus the time dimension). I would argue that they have more non-local spatio temporal dependencies."
            },
            "questions": {
                "value": "- I would like to see a more clear description of how this relates to previous work.\n- I would like to see a better description of how the hyperparameters were tuned."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1523/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698825929226,
        "cdate": 1698825929226,
        "tmdate": 1699636080680,
        "mdate": 1699636080680,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "W1vZ5Cq2iS",
        "forum": "QMkYEau02q",
        "replyto": "QMkYEau02q",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1523/Reviewer_HSXq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1523/Reviewer_HSXq"
        ],
        "content": {
            "summary": {
                "value": "The paper attempts to model the meteorological dynamics with physics guided deep leaning method.  Authors propose a physics guided deep learning framework, which can be combined with existing deep learning networks. Experiments are conducted on real world datasets to validate the model."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. First of all, weather forecasting is a very important problem and should get more attention from the ai community to defending the climate change.\n2. Generally, I like the idea of combining physics mechanism with deep learning to improve the performance and generalization ability of ai methods. The proposed method seems reasonable. \n3. Experiments are conducted on the ERA5 dataset, which is one of the most high-quality weather data. The results show that the proposed method can obtain performance gain for both downscaling and forecasting tasks."
            },
            "weaknesses": {
                "value": "1. The writing of the paper could be further improved, especially the use of symbols. For example, what is (u, v, w) in figure 1, is Q the same as Q_pi? What is epsilon?\n2. One the mentioned advantage of physics guide is physical consistent. However, it is not clear how to measure physical consistent, do you mean the analysis in sec 4.3?\n3. There are some important recent works and background information missed in the related work part. Section 2.1 missed some recent progress in weather forecasting such as GraphCast, ClimaX, and FengWu. The relate work part also lacks discussions about PINNs.\n4. It is also not clear to me what is the core technique contribution of this paper when aligning it to the broad PINN family. \n5. Regarding the experiments, it is hard to compare this work with existing deep learning works since it is conducted in the special region. It would be good to present the results in the full ERA5 dataset or a smaller resolution (e.g., weatherbench) if the resource is limited. \n6. The assumption that deep learning model is accurate enough does not hold in this paper.\n7. It is not clear about the detailed train, validation, and test settings. There is also no code shared for reproduce ability checking."
            },
            "questions": {
                "value": "please check the weakness part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1523/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699086564586,
        "cdate": 1699086564586,
        "tmdate": 1699636080624,
        "mdate": 1699636080624,
        "license": "CC BY 4.0",
        "version": 2
    }
]