[
    {
        "id": "KeNZGsb1nJ",
        "forum": "aG3EARrrd1",
        "replyto": "aG3EARrrd1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4600/Reviewer_TLX1"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4600/Reviewer_TLX1"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method, Online Sparse Residual Tree (OSRT) for\nhandling streaming multivariate scattered data. The proposed\nmethod is built on the sparse residual tree (SRT) method proposed in [Xu & Luo, 2022] and extended to deal with\nevolving data efficiently in an online fashion.\n\nThe proposed OSRT model dynamically updates the tree structure by adding or deleting neurons and by splitting nodes as a new training sample arrives.\nExperiments demonstrate that the ORST method has superior performance to other online algorithms."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- With the proposed online extension, the SRT framework can now learn streaming data in an online fashion to predict future data.\n- The experiments demonstrate the proposed method outperforms the state-of-the-art base-line methods in the literature."
            },
            "weaknesses": {
                "value": "- There are some imprecise parts which make it difficult to evaluate the feasibility of the proposed method. For example, in Section 2.2, on page 5, the sentence \"then we set the.\" is incomplete. Algorithm 1 is not fully explained in the text. For example, FindLeaf() in step 3 is not defined in the text. The step 9 seems to contradict what they say in the text. I supporse if the condition is NOT satisfied then it should do splitting. On page 5, the authors state that \"We have mentioned ... as $N_{max} = 1.2 N_{\\chi}$,\" but they never mentioned it earlier.\n- The SRT, which is the previous work, is treated as if originally proposed in this paper. The authors should clearly split Section 2 into two separate sections, one for explaining the previous SRT as background and the other for the proposed online extensions. \n- The details of the hyperparameter settings used in the experiments are missing completely. The hyperparameters include the maximum tree depth $d_{max}$, the factor $\\theta_s$, the stack size $N_l$ and the error threshod $\\Delta_1$. Changing their values may influence their performance and setting them to appropriate values may be non-trivial. However, none of their concrete values nor\ntheir robustness to the performance in the experiments is reported."
            },
            "questions": {
                "value": "Because OSRT is an extension of SRT, I would like to know the performance difference\nbetween the original SRT and its online version OSRT. The ORST is an online algorithm and evaluates each\nsample only once according to Algorithm 1 on page 7. Therefore \nsome performance degradation is expected against SRT, while OSRT is more\ncomputationally efficient. The extent of the performance degradation is important\ninformation to understand the potential of the proposed method and should be reported.\n\nMinor comments:\n\nIn Section 2 on page 2, the Gaussian kernel is defined as $\\theta_j(x)$ that includes $c_j$ as its center vector but a different\nsymbol $\\phi_j(x)$ is used in the following equation. \nOn page 4, $\\phi_{\\delta_l}(X_{li} -\\chi_j)$ is used, where the definition of $\\phi_{\\delta_l}(x)$ does not include $c_j$ and the suffix of $\\phi_{\\delta_l}$ is the shape parameter, while the suffix of $\\phi_j$ is the node index.\n\nOn page 4, $\\sum_{i=1}^{t_q}$ should be $\\sum_{i=1}^{q}$.\n\nIn Section 2.1, $\\prec t_q$ is defined but $t_q$ is not defined at all and is still used in a couple of places.\n\nIn Equation (8), the notation $r_l(x)$ is misleading. It should be $r_l(X_l)$ as  used\nlater in $Q^T_{q+1}r_l(X_l)$.\n\nIn Section 2.3 on page 6, the definition of $S_m$ is unclear. $S_m$ is supposed to be a vertex of Voronoi diagram.\n\nThe right hand side of Equiation (1) : $\\sum_{i=1}^{N_{\\chi}} \\alpha_i \\phi_{\\delta_l}(x)$ is confusing because \n$\\sum_{i=1}^{N_{\\chi}} \\alpha_i \\phi_{\\delta_l}(x) = \\phi_{\\delta_l}(x)\\sum_{i=1}^{N_{\\chi}} \\alpha_i $"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "I have no concerns."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4600/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4600/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4600/Reviewer_TLX1"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4600/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698652658124,
        "cdate": 1698652658124,
        "tmdate": 1699636438568,
        "mdate": 1699636438568,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FKjBwDyzPD",
        "forum": "aG3EARrrd1",
        "replyto": "aG3EARrrd1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4600/Reviewer_4t5w"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4600/Reviewer_4t5w"
        ],
        "content": {
            "summary": {
                "value": "The paper extends methods for radial basis function (RBF) neural networks to predict time-series to online models---named an \"online sparse residual tree\" (OSRT) model. OSRT involves building a sparse tree in which the RBF networks reside.  To address streaming time-series, the model's online adaptation is done by thresholding the current mean squared residual error as new data arrives."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The paper presents several novel ideas, by combining RBF networks, sparse regressison trees, and online updating for time series prediction."
            },
            "weaknesses": {
                "value": "The paper lacks a principled approach to model design and evaluation, appearing to have little rationale in the combination of methods used beyond their adaptation from the recent literature, and their apparent heuristic value.  Typically one would expect a cross validation step as part of the algorithm when complexity parameters or thresholds are called for in a model.  \n\nThe exposition is hard to follow at best, and at times incomplete, or the symbols are incorrect. \nFor instance, in Section 2: \n\n- Gaussian kernel is designated \\theta, but in the approximation the character \\phi is used -- are these the same thing? Note that \\theta is reused with a different meaning in Equation (17).\n\n- After equation (2) the phase \"Where N\u03c7 is the number of neurons in this node, \u03b4l is the shape parameter.\" makes no sense since neither variables appear in the previous formula.  The rest of that paragraph has similar problems with reference to variables not introduced in the equations that it attempts to explain. \n\nIn general, one needs a principled method for determining the complexity of the model, e.g. the number of nodes, such as cross validation, or use of complexity penalty terms, e.g. in BIC. Is the maximum tree depth (Section 2.2) something one calculates, or is it a parameter one setd? Simply considering when \"the increase in the number of nodes no longer yields significant improvements in approximation quality\" will lead to overfitting. \"Significant improvement\" is not a principled method."
            },
            "questions": {
                "value": "There are many terms introduced in the explanation of the model that are introduced but not explained:  Could you describe the tree in terms of its layers?  What is the \"split rule\" and what is the stopping condition referred in the paragraph following Equation (2)?  In what sense is it sparse? Is there a sparsification step?  What do you mean in Section 2.1 by \"quasi-uniform\"?  Are your \"mean points\" C the same as your centers? Honestly this as far as I got in the text."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4600/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698780617480,
        "cdate": 1698780617480,
        "tmdate": 1699636438489,
        "mdate": 1699636438489,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "O48bNGifwf",
        "forum": "aG3EARrrd1",
        "replyto": "aG3EARrrd1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission4600/Reviewer_nWJS"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission4600/Reviewer_nWJS"
        ],
        "content": {
            "summary": {
                "value": "This paper presents a predictive statistical model OSRT for handling streaming multivariate scattered data. The OSRT model can dynamically expand its network depth with the arrival of data. A RBS refinement is also incorporated into the OSRT model to minimize its residual error. Moreover, the paper proposes an incremental method to explore the central node of the RBF function, ensuring the sparsity and accuracy of the model. Theoretical analysis and Empirical results are provided to demonstrate the effectiveness of the proposed OSRT mode."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. The paper focuses on online regression analysis, which is an important problem especially considering the growing necessity to process large-scale data in the era of Big Data.\n\nS2. The paper proposes several approaches to minimize the residual error. The effectiveness of the proposed method is theoretically proved and empirically demonstrated."
            },
            "weaknesses": {
                "value": "My main concern is the presentation of the paper. \n\n1. There is no formal problem definition in the introduction, which makes it almost impossible for non-experts to understand the paper. \n\n2. The introduction part is too short and not very informative. The authors should at least illustrate some of the backgrounds of online regression analysis and highlight existing challenges. \n\n3. The authors did not clearly state the technical contributions of the work. The related work part is also messy, which makes it very hard for me to identify the contributions of the paper. \n\n4. the author did not present any intuition for the proofs, which makes it hard to verify the correctness. \n\n5. the current manuscript contains numerous typos, unclear sentences, and undefined notations. For instance: \n\n- Page 1: For example, The partition\n\n- Page 1: with more and more data is generated\n\n- Page 1: have deriving\n\n- Page 1: too large a network may bring in ...\n\n- Page 1: takes the growing strategy first, it adds\n\n- Page 2: It separate\n\n- Page 2: represented blow\n\n- Page 2: Where\n\n- Page 3: Where\n\n- Page 3: Most regression trees grown by \n\n- Page 3: $r_{l+1, j}$ combined into\n\n- Page 3: the notation $\\varphi$ requires clarifications\n\n- Page 3: $i \\neq j$ Then -> $i \\neq j$. Then\n\n- Equation (4): $\\mathbb{I}$ and $1_{\\Omega_{L_i}}$\n\n- Page 4: then the problem (??)\n\n\nIn general, I think the paper is promising. However, the presentation of the paper does not meet the high standards of ICLR."
            },
            "questions": {
                "value": "Please refer to the Weaknesses part for details."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission4600/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4600/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission4600/Reviewer_nWJS"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission4600/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698996106179,
        "cdate": 1698996106179,
        "tmdate": 1699636438384,
        "mdate": 1699636438384,
        "license": "CC BY 4.0",
        "version": 2
    }
]