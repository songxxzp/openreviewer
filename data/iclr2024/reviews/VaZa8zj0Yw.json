[
    {
        "id": "xjW141wtk0",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_XnQy"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_XnQy"
        ],
        "forum": "VaZa8zj0Yw",
        "replyto": "VaZa8zj0Yw",
        "content": {
            "summary": {
                "value": "The paper introduces a generative agents architecture called lyfe agents. The claim is that it is more economically than baselines by using hierarchical action selection scheme. Furthermore, the architecture introduced a self-monitoring module to facilitate more coherent behavior of agents. Finally, a summary-then-forget mechanism is introduced to reduce redundant information and keep what is salient. Overall, the paper is able to produce coherent, objective driven agents, simulated in their own environment called LyfeGame."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "- Tackles the problem of cost efficient generative agents and effective memory systems. The topic is very relavant to the conference and as a field. The paper is presented in a simpe manner, and the presented material is easy to understand.\n- The economic value seems like a valuable topic to explore, since agents should not need a heavy LLM to perform low level actions, which is very expensive\n- provided clear advantage over generative agents: cost, which is also significant reduction"
            },
            "weaknesses": {
                "value": "- The paper uses mainly people in the field already practice, e.g., reflecting on top of reflections in generative agents is similar to the self-monitoring in lyfe agents, and time as a inverse importance metric in generative agents is similar to summary-then-forget\n- paper is missing alot of key implementation details in order to reproduce, see questions section for a list of them\n- the environment seem like a navigatable chatroom (only walk/talk actions), seems a bit simplified to incentivize more complex social behaviors"
            },
            "questions": {
                "value": "- Could you provide more details of the\n    - memory system, how was it implemented, what retrieval/embedding mechanisms were employed\n    - hierarchical actions were implemented in code? or pretrained policy?\n    - clustered using what technique? what was the embedding employed?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8143/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697379888599,
        "cdate": 1697379888599,
        "tmdate": 1699637009340,
        "mdate": 1699637009340,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "FUZ77x6kwl",
        "forum": "VaZa8zj0Yw",
        "replyto": "VaZa8zj0Yw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_tWHo"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_tWHo"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces a novel generative agent architecture for real-time social interactions. \n\nAchieving real-time responses necessitates high throughput but also incurs significant computational costs. The proposed work aims to develop a cost-effective agent with key features such as: 1) an option-action selection strategy that generates social actions hierarchically, similar to an option framework, 2) a self-monitoring module that continuously updates an activity summary for streamed observations, and 3) a summarize-and-forget memory that discards redundant previous memories based on their similarity with newer ones. By operating multiple agents with these features, social interactions can emerge. \n\nExperimental results on two social interaction tasks (murder mystery and activity fair) validate the effectiveness of the proposed agents."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "**Novelty**: The specific architecture of the generative agents developed in this work appears novel, although I am not an expert in this particular field.\n\n**Quality**: The development of a comprehensive framework for social interactions by multi-generative agents likely required a significant engineering effort. From an engineering perspective, the quality of the proposed work is high. Each technical component of the proposed agent is thoroughly evaluated in the ablation study.\n\n**Clarity**: The paper is mostly well-written and easy to understand. Although many technical implementation details are omitted from the main sections, this is acceptable for a conference paper submission with a page limit.\n\n**Significance**: The demonstrated results appear significant (although I'm not certain if they truly outperform other work, as discussed in the next section.)"
            },
            "weaknesses": {
                "value": "While the proposed work seems to be of high quality from an engineering perspective, its significance as a conference paper is somewhat limited in its current form, due to what I perceive as insufficient experimental evaluation.\n\nHere are my concerns:\n- Although I understand that all the components of the proposed agent contribute to task success rates, it's unclear how crucial they are for the agent to be \"cost-effective\", which was the original motivation of this work as stated in the introduction.\n- While the proposed agent is performant, it's unclear if this performance is consistent across various base LLMs. The experiment appears to use GPT-3.5. What would happen if we use different LLMs such as Alpaca and GPT4ALL, or LLMs with various model capacities? Without this information, it remains unclear whether using GPT-3.5 is a crucial requirement or not. Also, from the perspectives of reproducibility and transparency, using open-sourced LLMs would be more desirable.\n- The cost analysis was not very convincing. Currently, \"cost per agent per human hour\" is reported. However, for tasks with specific goals such as murder mystery, isn't it more essential to show the cost required until the task is successfully completed? Otherwise, agents with very low throughput (due to, say, insufficient compute resources) will be evaluated as low cost, which I don't believe this paper intends to argue. Furthermore, reporting costs in USD seems unhelpful. This would result in running open-sourced models in a region with cheap electricity as an optimal choice. What happens if the service provider changes API usage prices in the future? Why not just report the number of interactions or number of tokens consumed until task completions?"
            },
            "questions": {
                "value": "Though I'm not an expert in this field, I found this work overall interesting. My main concerns are about whether the arguments \"low-cost\", \"cost-effective\", etc. are sufficiently supported, which I don't believe they are in the current submission.\n\n- Can the contribution of each technical component be evaluated in terms of cost-effectiveness, such as the number of interactions or the number of tokens consumed?\n- Can the base LLM be replaced from GPT-3.5 to other open-sourced LLMs such as Alpaca https://github.com/tatsu-lab/stanford_alpaca and evaluated with several model capacities?\n- Can the cost analysis be performed not based on USD/agent/hour but something else that does not depend on some API's price setting? For example, could we use the number of interactions or tokens required until task completion?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "details_of_ethics_concerns": {
                "value": "n/a"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8143/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698018034479,
        "cdate": 1698018034479,
        "tmdate": 1699637009153,
        "mdate": 1699637009153,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "mIER9ZndTm",
        "forum": "VaZa8zj0Yw",
        "replyto": "VaZa8zj0Yw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_4MNZ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_4MNZ"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes an LLM-based agent named Lyfe Agents, which is claimed to enable real-time interactions with low computational cost. The authors propose an option-action framework and a new memory mechanism for the Lyfe Agents. Lyfe Agents are claimed to reduce the number of queries by 95% compared to Generative Agents.\n\nHowever, this paper lacks novelty and contributes marginally to the field of LLM-based agents. The claims of 'low-cost,' 'real-time,' and 'generative' are not sufficiently substantiated for a scientific research paper. It appears more akin to an application of existing LLM-based agents with a designed script."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. The pipeline in Figure 2 is clear and interesting.\n2. The paper is well-written and presents its ideas in a clear, concise manner."
            },
            "weaknesses": {
                "value": "This paper is difficult to regard as a research paper, or even as a technical report. It more closely resembles a manual for implementing an LLM-based agent framework in two scenarios designed by the authors.\n\nThe logic of this paper is not rigorous. \n\n1. The authors claim that existing LLM-based agents are redundant in leveraging fewer queries to empower the agents. However, the problem they address is not convincing. The authors treat the redundancy issue as common knowledge within the community, which lacks objectivity.\n\n2. The overall logic of this paper is unclear. What motivates the proposal of the three modules for Lyfe Agents, and how do these modules differ from those in other LLM-based agents? The improvements offered by these modules are difficult to discern.\n\n3. The authors do not fairly compare Lyfe Agents with existing LLM-based agents. The paper's most significant claim pertains to the 'low-cost' agents depicted in Figure 6. However, the authors should attempt to keep all variables consistent when comparing the queries of LLMs. Comparing generative agents with Lyfe Agents in different scenarios is unjust! Also, the lyfe agents should compare with other general social simulation agents such as [1,2].\n\n4. There are no objective evaluation metrics for Lyfe Agents other than cost per hour (which, as stated in point 3, is an unfair comparison). The police success rate shown in Figure 3b is absurd. It is based on a self-designed script with predetermined and clear answers, which is not convincing and should not serve as an evaluation metric in a scientific paper. \n\n5. The proposed framework in figure 2 should be a general LLM-based agents framwork. The lyfe agent should be evaluated in other well-know scenarios such as games and generative agents [3,4].\n\n6. Generative agents [3] propose reflection to summarize the high-level memory. What is the difference between the proposed memory mechanism and the one in generative agents [3]? \n\n\n[1] Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue Ping, and Qin Chen. Agentsims: An open-source sandbox for large language model evaluation. arXiv preprint arXiv:2308.04026, 2023.\n\n[2] Lei Wang, Jingsen Zhang, Xu Chen, Yankai Lin, Ruihua Song, Wayne Xin Zhao, and Ji-Rong Wen. Recagent: A novel simulation paradigm for recommender systems. arXiv preprint arXiv:2306.02552, 2023.\n\n[3] Joon Sung Park, Joseph C. O\u2019Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. Generative agents: Interactive simulacra of human behavior. In In the 36th Annual ACM Symposium on User Interface Software and Technology (UIST \u201923), UIST \u201923, New York, NY, USA, 2023. Association for Computing Machinery.\n\n[4] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint arXiv:2305.16291, 2023."
            },
            "questions": {
                "value": "1. What is the problem (motivation) addressed in this paper? llm-based agents with too many queries? What is the factor leading to the \"extensive queries\" of existing LLM-based agents? Are the queries really extensive? Is the memory mechanism resulting in the \"extensive queries\"?\n\n2. How do the proposed Lyfe agents solve the problems addressed by the existing LLM-based agents? Which module contributes the most to efficiency?\n\n3. How are the scripts (scenario 1 & 2) driven? \n\n4. What is the LLM used in the experiments?\n\n5. Could existing LLM-based agents be real-time agents if the LLM is running locally?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8143/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698654854916,
        "cdate": 1698654854916,
        "tmdate": 1699637009024,
        "mdate": 1699637009024,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "d3q8pxHDxw",
        "forum": "VaZa8zj0Yw",
        "replyto": "VaZa8zj0Yw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_yeom"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_yeom"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces Lyfe Agents, an LLM framework for simulating social behaviour in virtual societies. In terms of the LLM framework, the paper proposes 3 new architecture components: a module for high-level decision-making, a module for helping agents maintain contextual awareness, and an improved memory module. In addition, the paper introduces a new environment, LyfeGame, for studying social interactions amongst LLMs."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- I like how the authors have grounded their three new modules in brain-inspired research. All three of the modules appear to be valid and useful in terms of improving performance of the agents, and I appreciate that they are also designed in order to be cost effective. \n- I think the scenarios that the authors have developed in order to evaluate their agents are smart and well-designed, and useful for picking out interesting emergent behaviours amongst LLM agents. In particular the murder mystery scenario, and the corresponding ablation that demonstrates the importance of all of the proposed modules."
            },
            "weaknesses": {
                "value": "I have two main problems with the paper that, in my opinion, need to be addressed.\n\n1) Whilst the intentions and role of all of the modules are well explained, the details of their implementations are not particularly well explained within the main body of the text. For example, take the option-action selection module: what are the implementation details for the LLM call that is used to output an options along with a subgoal? What are the available options, is this defined by the LLM or a discrete list provided beforehand? What are the details of the exit conditions that lead to the option-action selection module being called? Whilst there are some more details included in the appendix, I believe some more important implementation points should be included in the main body of the text.\n\n2) I am not currently convinced by the cost analysis that is provided by the authors. This is particularly important as one of the key-selling points of the framework, according to the authors, is the cost effectiveness of the framework. I am not disputing the project cost of the Stanford GenAgent work. However, I just have a few queries about the cost provided for the Lyfe Agent. Firstly, is the difference in cost primarily coming from the fact that GPT3.5 is used for LyfeAgent vs. GPT-4 for Stanford GenAgent? In my opinion, this isn't necessarily a fair comparison - instead would it not be fairer to evaluate more in terms of tokens inputted / outputted when solving the scenarios? For example, how many tokens need to be inputted / outputted by LyfeAgent vs. Stanford GenAgent in order to arrive at a Murder mystery solution? In my opinion this is a fairer comparison."
            },
            "questions": {
                "value": "I would be grateful if the authors could address my points brought up in the weaknesses. Primarily:\n\n1) Please provide more implementation details for the modules, especially in the main body of the paper. Currently, for example, I would not personally be able to reproduce this framework based on all the information provided in the paper and appendix.\n\n2) Please discuss my thoughts on the cost-analysis. Is my point fair? If the point relates to GPT3.5 vs. GPT4, please discuss why it is fair to compare the two.\n\nI would be happy to update my score based on the authors responses to these points."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8143/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8143/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8143/Reviewer_yeom"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8143/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698678293746,
        "cdate": 1698678293746,
        "tmdate": 1699637008918,
        "mdate": 1699637008918,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QuCG0BSAP0",
        "forum": "VaZa8zj0Yw",
        "replyto": "VaZa8zj0Yw",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_Qy47"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8143/Reviewer_Qy47"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce generative agents based on ChatGPT, combining a modular internal architecture inspired by neurobiology. As a core concept, they employ a self-monitoring mechanism to align the agent's behavior with their internal goals. It combines a textual representation of recent events and the internal motivation to plan the next steps. In addition, each agent has a dynamic memory that changes based on perceived inputs and events. This module is divided into short and long-term containers. While inputs are first stored in the short-term memory, they can be clustered and summarized into the long-term. The work overserves and evaluates the agent\u2019s behavior in a custom 3D virtual environment in three simulated scenarios: solving an (easy, hard) murder mystery, discussing joining social clubs, and finding a suitable treatment for a medical issue. In addition, the authors perform different ablation scenarios to evaluate the performance of the subparts."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "\u2022\tAgent \u201cBrain\u201d: The authors combine and enhance different modeling techniques that are motivated by the human brain. This approach shows promising results in the simulation of emergent social behavior. I want to highlight the combination of the self-observation and the dynamic memory system. In combination with the retrieval process based on vector similarity, I find this a fair contribution to the conference.\n\u2022\tMultiple Experiments + Ablation: The work contains three experiments covering different domains of collaboration and conversation. The results show that the agents successfully manage all scenarios. In addition, the ablation setup provides insights into the importance of each submodule in the larger context. Thus, I find the results sound in terms of technical claims and experimentation setup."
            },
            "weaknesses": {
                "value": "\u2022\tImplementation of the virtual world: I see no benefit in highlighting the 3D environment work this work contribution. The interaction is purely text-based, and the agents do not perceive their visuals as image inputs. Thus, the work could be reduced to a text-based role-play scenario.\n\u2022\tAppendix Structure: I found relevant information about the agent architecture missing in the content but given inside the appendix. Thus, moving relevant information into the body of the paper would emphasize the main contribution. \n\u2022\tReliance on GPT3.5: Like previous agent-based work (Park et al.), the observations and consequences are limited to a singular foundation model. As this work employs complex memory and decision mechanisms, the behavior of competitive models like Llama-2 70B or Falcon 180B, when prompted with this approach, may strengthen impact."
            },
            "questions": {
                "value": "I would like to see examples of the prompt templates used to interact with ChatGPT. Further, I suggest focusing on the agent\u2019s architecture in the main content instead of utilizing the space for a half-page screenshot of the environment. The quality and relevance of the paper would improve with more focus on the contribution regarding the learning representation itself: memory architecture, discerning storage, and retrieval."
            },
            "flag_for_ethics_review": {
                "value": [
                    "Yes, Discrimination / bias / fairness concerns"
                ]
            },
            "details_of_ethics_concerns": {
                "value": "While the names of the individual agents seem to present people from various heritages (Western and Eastern), the provided long-term memories focus on Japanese stereotypes: Dream of moving from the countryside to Tokyo, Loving Mangas, Bonsais, Kendo, or Cherry Blossoms. We see this only as a minor issue, as the authors also focus on an anime-like 3D environment, which seems sound. However, this might restrict the impact of the work."
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 5,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8143/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698744623403,
        "cdate": 1698744623403,
        "tmdate": 1699637008786,
        "mdate": 1699637008786,
        "license": "CC BY 4.0",
        "version": 2
    }
]