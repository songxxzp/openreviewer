[
    {
        "id": "10WNWRouUe",
        "forum": "hqUznsPMLn",
        "replyto": "hqUznsPMLn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7893/Reviewer_XBPq"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7893/Reviewer_XBPq"
        ],
        "content": {
            "summary": {
                "value": "The paper presented their approaches to generate diverse and solvable programming questions leveraging LLMs."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "The writing is easy to follow and the entire generation and evaluation process are presented with adequate details."
            },
            "weaknesses": {
                "value": "The contribution of this paper is pretty poor. There are several severe problems: \n\n1. The observation that LLMs can generate tasks outside the P3 dataset (the training set that is used for prompting), is basically because the LLM has been pre-trained on many larger scale coding question datasets. For example, the combination of string and grid question on page 21 is a canonical programming task. Even if it's not in P3 dataset, it's highly likely that LLM has seen this during pretraining. \n\n2. The semantic descriptor is sort of defined arbitrarily. It's fine if only used to prompt the LLM, but not quite reasonable in measuring interesting-ness and diversity. For example, solely from the human labeled P3 dataset, what's the correlation coefficients between each pairs of labels? As far as the reviewer can see, many labels are highly related, e.g. sorting and searching -> stacks and queues or tree or recursion. Using Hamming distance over those highly correlated field is problematic. Similarly, in the diversity measurement, the grid of labels is reasonable only if categories are almost independent and orthogonal to each other.\n\n3. The process relies on LLM to label the generated tasks and add them into the prompt example pool. View from the Figure 3, this labelling accuracy is far from satisfactory, especially the generation process is iterative and accumulates the errors."
            },
            "questions": {
                "value": "1. What does the first contribution bullet in the introduction section mean? **We define the notion of semantic descriptors to leverage LLMs for the encoding of high-dimensional textual data into hard-to-compute, abstract and interpretable features of interest**\n\n2. What does the first sentence in Figure 1 caption mean?\n\n3. The page limit of 9 suggests that the reproducibility and ethics should be put after the references. \n\n4. The reviewer agrees that interesting-ness and diversity measurement itself could be a good contribution if they had been well developed."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7893/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1697873740423,
        "cdate": 1697873740423,
        "tmdate": 1699636968349,
        "mdate": 1699636968349,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ibDxbe8JY5",
        "forum": "hqUznsPMLn",
        "replyto": "hqUznsPMLn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7893/Reviewer_ufAe"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7893/Reviewer_ufAe"
        ],
        "content": {
            "summary": {
                "value": "This paper studies the task of automatically generating python programming puzzles.\n\nFirst, it proposes to use high-dimensional 0-1 vectors (referred to as \u201csemantic descriptors\u201d) to describe different semantic features of programming puzzles, measure the distance between puzzles and diversity of puzzle sets.\n\nSecond, it introduces an algorithm ACES that uses these semantic descriptors to generate diverse programming puzzles. Specifically, this algorithm\n\n- randomly samples a descriptor as the goal for generation,\n- retrieves similar puzzles according to the hamming distance between the goal descriptor and the descriptor of the known puzzles,\n- prompts a language model with the goal descriptor and the retrieved puzzles to generate new puzzles.\n\nThe authors evaluate the validity of LLM-labeling for the descriptors and the diversity of ACES-generated puzzles measured by semantic descriptors and other representations. They also examine whether a diversity of generated puzzles can train better code models."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "1. Automatic generation of programming puzzles (and more broadly, other tasks) is an interesting problem and could be very useful for the purposes the paper mentions.\n2. The paper\u2019s evaluation of diversity is multidimensional and extensive. I am convinced that the proposed algorithm does improve the diversity of generated puzzles.\n3. The qualitative analysis and the examples in the appendix show that ACES was able to generate some very non-trivial puzzles."
            },
            "weaknesses": {
                "value": "### 1. There is a lack of discussion on literature related to diverse data generation.\n\nIn my opinion, there are important previous studies that are not cited and discussed in your paper. Therefore, I am not sure about the novelty of your algorithm.\n\nAs I understand, the proposed ACES algorithm achieves diversity with two approaches:\n\n- Specifying diverse goals with random \u201csemantic descriptors\u201d. In other words, you randomly sample a set of features (like \u201cgraph theory\u201d, \u201coptimization algorithm\u201d) and ask the model to make sure the generated puzzles include these features.\n- Mutating randomly sampled puzzles from the archive to generate new samples. Since the randomly sampled puzzles are diverse, their mutations will be diverse.\n\nThe same two approaches have been extensively used in recent studies on diverse data generation and curation that try to create more data to train and fine-tune language models. Here are some examples.\n\n**Mutation for diversity.** Unnatural Instructions [1] starts with 15 seed examples of (instruction, input, constraints) tuples and mutates a 3-example demonstration to generate new examples. Self-Instruct [2] also does similar things with (instruction, input, output) tuples and it randomly samples instructions from both the initial pool (like your P3 train set) and the generated pool (like your generated puzzle-solution pairs) to start their mutation. Evol-Instruct [3] uses an even more complicated evolutionary algorithm to mutate and generate complex instruction samples.\n\n********************************************************************Goal specification for diversity.******************************************************************** The authors claim that the semantic descriptor (binary vector that indicates which features to include) of ACES is novel and easy to interpret. I agree with the interpretability argument but not the novelty argument. TinyStories [4] also tries to create diverse stories to train language models by creating a list of story features and asking language models to include randomly sampled features from the list each time. Evol-Instruct [3] also involves rewriting and evolving the prompts towards different goals.\n\nMore importantly, even in the domain of generating coding tasks, these two approaches (mutation and goal specification) have been used to generate diverse coding tasks (though not programming puzzles). Gunasekar, Suriya, et al. [5], Code Llama [6], and WizardCoder [7] all use these approaches to instruction-tune language models.\n\nI would love to see more discussions on these related works and how ACES is different from (and better than) them.\n\n### 2. ChatGPT labeled semantic descriptor isn\u2019t good enough for measuring semantic diversity.\n\nFirst, I\u2019m not sure the confusion matrices in Figure 3 support the claim that \u201cpuzzle labeler demonstrates high true positive rates\u201d because only 3 among the 10 dimensions have true positive rates over 0.6. Could you be saying it demonstrates high true negative rates? Even so, I\u2019m a bit concerned about the accuracy of the labeler.\n\nSecond, I agree with you that \u201cthe classification does not need to be perfect to drive diversity.\u201d However, I do think it needs to be more accurate to *******measure******* diversity.\n\nYour entire claim about \u201cdiversity in semantic space\u201d is supported by a not-so-accurate labeler of semantic descriptors. Although I think it might be true, the supporting evidence you gave isn\u2019t strong.\n\n### 3. There is a lack of evaluation beyond diversity.\n\nI appreciate your efforts in evaluating diversity with multiple different metrics. However, I think there\u2019s more to data quality than diversity. While the validity check of puzzles `f(g())==True` does say something about the generated puzzles, they could still be meaningless. Therefore, I would love to see more evaluations or arguments about the quality of the generated data.\n\nSpecifically, in your qualitative analysis, you mentioned that the generation processes \u201cshift the algorithmic load from g to f, in which case g only provides arguments for f.\u201d I wonder if there were other shifts in the generation processes and if these shifts could lead to degraded puzzles. For example, could f ignore what g is doing or what the algorithmic part in itself is doing and just return True?\n\nAnother worry I have is that your goal specification could lead to an infeasible combination of features. Randomly sampled semantic descriptors could involve semantic labels that hardly appear together and create absurd problems.\n\nAs demonstrated by your section 4.4, diversity does not entail performance gain. Even though that is the case, I would love to see more evaluation and discussion about the quality of the generated puzzles beyond diversity because quality is important for education, data augmentation, and scientific discovery.\n\n### Reference\n\n[1] Honovich, Or, et al. \"Unnatural instructions: Tuning language models with (almost) no human labor.\"\u00a0*arXiv preprint arXiv:2212.09689*\u00a0(2022).\n\n[2] Wang, Yizhong, et al. \"Self-instruct: Aligning language model with self generated instructions.\"\u00a0*arXiv preprint arXiv:2212.10560*\u00a0(2022).\n\n[3] Xu, Can, et al. \"Wizardlm: Empowering large language models to follow complex instructions.\"\u00a0*arXiv preprint arXiv:2304.12244*\u00a0(2023).\n\n[4] Eldan, Ronen, and Yuanzhi Li. \"TinyStories: How Small Can Language Models Be and Still Speak Coherent English?.\"\u00a0*arXiv preprint arXiv:2305.07759*\u00a0(2023).\n\n[5] Gunasekar, Suriya, et al. \"Textbooks Are All You Need.\"\u00a0*arXiv preprint arXiv:2306.11644*\u00a0(2023).\n\n[6] Roziere, Baptiste, et al. \"Code llama: Open foundation models for code.\"\u00a0*arXiv preprint arXiv:2308.12950*\u00a0(2023).\n\n[7] Luo, Ziyang, et al. \"WizardCoder: Empowering Code Large Language Models with Evol-Instruct.\"\u00a0*arXiv preprint arXiv:2306.08568*\u00a0(2023)."
            },
            "questions": {
                "value": "I would appreciate your answers to the questions raised in the weakness section."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7893/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698335735526,
        "cdate": 1698335735526,
        "tmdate": 1699636968224,
        "mdate": 1699636968224,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YlaeRaQ0rg",
        "forum": "hqUznsPMLn",
        "replyto": "hqUznsPMLn",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission7893/Reviewer_AUHG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission7893/Reviewer_AUHG"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces ACES (autotelic code exploration with semantic descriptors), a prompting-based algorithm that uses an LLM (ChatGPT) to produce a diverse set of programming puzzles. The algorithm first uses the LLM to label an existing base set of puzzles (P3, the Python Programming Puzzles dataset) as to which of ten skills (aka semantic descriptors) they require. It then proceeds iteratively to generate new puzzles. To generate each new puzzle it uses a nearest neighbor approach to construct a few-shot prompt using existing puzzles, aimed at generating a puzzle requiring a particular subset of the ten skills. It uses this prompt with an LLM to generate a puzzle-solution pair, which it keeps if the puzzle-solution pair passes. The resulting set of puzzles exhibits high diversity both according to the semantic descriptors and according to an embedding based measure of diversity. Despite the diversity of the puzzles produced, fine-tuning using the produced puzzle set does not help on the test puzzle set compared with fine-tuning on a less diverse set of puzzles produced by a baseline approach."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The approach is quite simple, and given access to an instruction-following LLM like ChatGPT, it would be straightforward to reproduce a comparable approach to ACES. The prompts included in the Appendix and the algorithm provided in the text aid in this reproducibility meaningfully. (The reliance on gpt-3.5-turbo-0613 unfortunately time-limit precise reproducibility, but other models will slot into the algorithm without issue even once gpt-3.5-turbo-0613 is no longer available.)\n* The approach leads to greater diversity in programming puzzles compared to the static gen, ELM semantic, and ELM baselines. The diversity is evident both in the number of cells covered (the objective the algorithm is designed for) and through an embedding based similarity metric.\n* The qualitative inspection of the samples generated by the ACES approach is welcome and informative. Thank you for including this.\n* The approach seems readily generalizable from the 10 selected semantic descriptors for programming puzzles to other domains where characteristics of examples can be represented as a set of features or properties present/not-present."
            },
            "weaknesses": {
                "value": "* ACES relies on a manually crafted set of semantic descriptors that is specific to the task of generating programming puzzles. The paper does not explore the role that the selection of these semantic descriptors plays on the resulting set of programming puzzles, and does not provide insight into how the approach works in non-programming puzzle domains where these pre-selected semantic descriptors would not be appropriate.\n  * The semantic descriptor based metric is tailored specifically for the semantic descriptors selected for the approach. If the set of semantic descriptors used in the approach were to change, it's not clear the current semantic descriptor approach (holding the set of semantic descriptors fixed to allow comparing across the change) to measuring diversity would remain meaningful.\n* One weakness of this manually crafted set of semantic descriptors is that it places a kind of constraint on the diversity that the approach can produce, and it shifts the burden of identifying this diversity from the ACES algorithm itself to the human seeding the algorithm with semantic descriptors.\n* The 2**10 size grid of sets of semantic descriptors is (a) in my opinion quite small. P3 has 636 train puzzles spanning ~60-80 cells, but there are only 1024 cells in total to try to cover (using 45000 generated programs to do so). (b) I expect that many of these cells aren't meaningful, e.g. it doesn't seem that important to identify a programming puzzle that is simultaneously a Sorting and Searching, Counting and Combinators, Tree and Graph, Bit manipulation, string manipulation, recursion, and dynamic programming problem (7 semantic descriptors), and a full 38% of the cells represent the goal of having 6 or more semantic descriptors. Indeed Figure 7 confirms generating programming puzzles with 6+ semantic descriptors is quite rare, yet the algorithm spends significant time trying to do so.\n* The primary measure of diversity (number of cells covered in the archive) is both an imperfect measure (the labels used to determine which cell is covered are determined by ChatGPT) and also the same model producing the puzzles (where generation is conditioned on the desired label) is the one predicting the label. Since puzzle generation is conditioned on the goal label and the same model then predicts those labels, there is real risk of the model overestimating the amount of diversity produced. As a toy example of how this overestimation could occur, we could imagine the model adds a comment to each generated puzzle saying what labels that puzzle should have. Then during labeling, the model ignores the code and simply reports the labels indicated by the comment. If this were to occur, the semantic descriptor metric would report all cells get covered (despite not actually achieving the desired diversity). I trust that this precise mechanism is not taking place here, but something directionally similar could easily evade notice and I don't think is being checked or controlled for.\n\n* And of course there is the significant weakness, readily acknowledged and discussed by the paper, that the diversity of puzzles identified by ACES did not help in fine-tuning for the downstream task of puzzle solving on the test set compared with the static gen baseline. I applaud the frank discussion of this weakness in Section 4.4 and the discussion of the paper."
            },
            "questions": {
                "value": "# Questions and Suggestions\n\nYou present two key use cases for generating diverse programs: education and LLM training. You evaluate the latter and find that the diversity provided by ACES is not helpful for the downstream puzzles test task you evaluate on. I am curious to get your thoughts on the former, which you do not evaluate. What properties of diversity do you think are important for the education use case, and how do you think these would be the same/different from the properties of diversity that would lead to positive effects of fine-tuning on a downstream task (like the puzzle test set you work with)?\n\nWhy do you select the grid of 2^10 sets of semantic descriptors as your set of possible goals to induce diversity? I ask this question with the following thoughts in mind. First, it seems like many of the cells in this grid don't actually represent diversity of interest (e.g. 38% of cells have 6 or more semantic descriptors which seems an unwieldy amount). Second, it seems like there are more dimensions of diversity not being considered. I brainstorm a few here to make the point: complexity/difficulty, domain, number of inputs, reliance on data dependencies, libraries used, and wall clock runtime.\n\nI am curious to hear any observations you may have made about the embedding based similarity measure. Does its measure correspond to your intuitive sense of similarity? Did you notice any qualitative differences across the three embedding models that you used?\n\nIn Section 3.2 you introduce a notion of interestingness, saying that functions R will map all uninteresting samples to the same point. This R notation is then never used, and the notion of interestingness is not further explored. What is meant by interesting, and how do the two representation functions (cosine distance and semantic descriptors) send uninteresting examples to the same point?\n\nIn \"What's new?\" you claim ACES is the first algorithm to use an autotelic LLM to generate diverse artifacts via in-context learning. In seeking to evaluate this claim, I am reminded first of EvoPrompting: Language Models for Code-Level Neural Architecture Search\n (https://arxiv.org/abs/2302.14838) (which is not autotelic, instead optimizing an objective) and I subsequently find concurrent work LLMatic: Neural Architecture Search via Large Language Models and Quality-Diversity Optimization (https://arxiv.org/abs/2306.01102). This concurrent work is also not autotelic. Another such concurrent work is Quality-Diversity through AI Feedback (https://arxiv.org/abs/2310.13032). Finally, does not Colas 2023 Augmenting Autotelic Agents with Large Language Models (https://arxiv.org/abs/2305.12487) also have all of these properties?\n\nI have collected some typographic suggestions for you below. These issues did not meaningfully harm the readability of the paper.\n\nTypo: Figure 1 caption \"an archive of dcreate figure from tcolorboxiscovered\" is a typo.\nTypo: Section 3.2 \"the example of 2\" -> \"the example in Figure 2\"\nTypo: Section 3.2 \"Counting and Combinatoris\" -> \"Counting and Combinatorics\"\nNotation: Section 3.2 \"k \\in [1 : 10]\" -> \"k \\in [1..10]\" or \"k \\in [1, 10]\"\nFormatting: In Algorithm 1, consider consistent formatting for \"LLM\" across lines 5 and 8\nTypo: Section 3.3 Puzzle labeler. \"the generate puzzle\" -> \"the generated puzzle\"\nTypo: Section 4.2 Figure -> Figures\nTypo: Section 4.2 \"more cell\" -> \"more cells\""
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission7893/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698792396278,
        "cdate": 1698792396278,
        "tmdate": 1699636968111,
        "mdate": 1699636968111,
        "license": "CC BY 4.0",
        "version": 2
    }
]