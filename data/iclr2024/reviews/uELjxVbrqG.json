[
    {
        "id": "oYddvH78Lj",
        "forum": "uELjxVbrqG",
        "replyto": "uELjxVbrqG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1105/Reviewer_UpYx"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1105/Reviewer_UpYx"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a method to learn a new, better representation space for facial features, from two existing, already optimal representation spaces. The analysis is based on some geometrical consideration regarding the possibility to improve a representation feature space, by interpolating other representation spaces.\nThe feature augmentation approach demonstrates very limited improvements on some identification tests. However, the proposed idea has some merits and it is worth further considerations and discussion towards the direction of adaptive techniques for feature space augmentation."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "Attempting to design a general feature space augmentation techniques interpolating already sub-optimal baseline spaces."
            },
            "weaknesses": {
                "value": "The reported results demonstrate a very limited improvement, maybe not justifying the efforts.\nThe designed feature augmentation model may be dependent on the training and produce different results on  different pre-trained models.\nLanguage mistakes"
            },
            "questions": {
                "value": "How would you expect to enlarge the scope of the proposed techniques?\nHow could you disentangle the proposed augmentation method from the training data, and consequently the learned features?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1105/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698749948805,
        "cdate": 1698749948805,
        "tmdate": 1699636036700,
        "mdate": 1699636036700,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "WyXi7bnFRs",
        "forum": "uELjxVbrqG",
        "replyto": "uELjxVbrqG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1105/Reviewer_GUup"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1105/Reviewer_GUup"
        ],
        "content": {
            "summary": {
                "value": "This paper proposes a face representation learning method considering the intra-class dissimilarity. Experimental results on multiple datasets and baselines show the effectiveness of the proposed method."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "This paper is well-written and easy to follow, the findings about pro-features and innovation features are interesting."
            },
            "weaknesses": {
                "value": "Here are some questions about this paper:\n1) The loss L_{dissim} should be described more detailedly, especially the relationship between the motivation describe in introduction and minimizing the cosine similary of teacher and student feature.\n2) The student network and teacher network are in the same sturcture. Will it be better if using the trained student network to be the teacher network since the goal of the method is a student network with higher performance? More analysis should be given.\n3) Sicne this method mainly focuses on feature distillation and representation learning, more comparision with the SOTA distillation methods should be given."
            },
            "questions": {
                "value": "See weaknesses above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Reviewer_GUup"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1105/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698760476238,
        "cdate": 1698760476238,
        "tmdate": 1700446009152,
        "mdate": 1700446009152,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "dNUb27Yvsb",
        "forum": "uELjxVbrqG",
        "replyto": "uELjxVbrqG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1105/Reviewer_JUcW"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1105/Reviewer_JUcW"
        ],
        "content": {
            "summary": {
                "value": "This paper starts with the hypothesis that when considering two face recognition (FR) models, the better-performing model can be further improved by combining features orthogonal to the worse-performing model. Authors propose the use of intra-class incoherence constraint (IIC) as a way of accomplishing this when a single FR model is available. Accuracy results on multiple face image datasets indicate that the proposed approach shows slightly better performance over other relevant approaches."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "One strength of the paper is the observation that incorporating the features orthogonal to the inferior model can improve the performance of a superior model. I am still not convinced of this as there is no theoretical proof of this, but numerical results are reasonably convincing.\n\nAnother strength of the paper is the collection of experimental results. Authors show accuracy results on multiple face image datasets and show comparisons with the state of the art FR methods. Also, ablation studies included seem to support authors' hypothesis."
            },
            "weaknesses": {
                "value": "One major weakness of the paper is the most of the concepts and associated discussion seem to be based on the 2-D spaces in Figs. 1 and 2 whereas the feature vectors are in a much higher dimensional space. One problem with over-relying on the figures is that authors speak as if there is one perpendicular component to the inferior model in Fig. 1. For a given model in n-dimensional space, there is a (n-1)-dimensional space orthogonal to it. How do we choose the innovation feature from this space?\n\nAnother major weakness is that there are no theoretical proofs or justifications for the suggested improvements.  If a superior model can be further improved by combining it with something orthogonal to an inferior model, doesn't that imply that the \"superior\" model may not have been trained sufficiently? Also, why should we stop with combining the innovation from just one inferior model? Why not consider multiple inferior models and extract and use features orthogonal to these multiple models?"
            },
            "questions": {
                "value": "1. Please clarify in the paper how the feature vector diagrams in Figs. 1 and 2 generalize to higher dimensions?\n\n2. On Page 2, it is stated that \"...innovation is always independent of features from CosFace\". Independence and orthogonality are different concepts. Do you mean orthogonality or independence here? If later, please provide a justification for why orthogonality implies independence.\n\n3. Manuscript suffers from language deficiencies. For example, \"orthogonal\" is a better choice for \"perpendicular\". Please revise the manuscript carefully to improve the language quality.\n\n4. In Section 3.1, it is stated that \"In the first case, as shown in Fig. 2(a), a and b are on different sides of d.\" In 2-D, it is clear what we mean by different sides. How are different sides defined in higher dimensional spaces?\n\n5. In Eq. (3), should there be a summation over i on the RHS? If not, how come there is no dependence on i on the LHS?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "No ethics concerns."
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Reviewer_JUcW"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1105/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698762404681,
        "cdate": 1698762404681,
        "tmdate": 1700402784932,
        "mdate": 1700402784932,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "sAemMgWWIg",
        "forum": "uELjxVbrqG",
        "replyto": "uELjxVbrqG",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission1105/Reviewer_V2zT"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission1105/Reviewer_V2zT"
        ],
        "content": {
            "summary": {
                "value": "In this paper, authors present a novel method that can improve existing face recognition (FR) methods by imposing a constraint of dissimilarity with learned embeddings.  \n\nThe paper starts with a framework that decomposes the feature space of a superior model into two sub features, with one along that of a inferior model (pro-feature) and the other being orthogonal (innovation feature). Experiments show that the innovation part (orthogonal features)  has a high level of face distinguishability, which can be useful to learn from. Thus authors propose to use the dissimilarity with learning embedding as an auxiliary task in addition to the main face recognition tasks, under the knowledge distillation framework. \n\nExperiments showed that this method can consistently improve existing methods (ArcFace, CosFace, MagFace, AdaFace) across 6 FR benchmarks. It's observed that the proposed method has a larger benefit on smaller datasets. Author hypothesized that the proposed method works as an feature augmentation mechanism."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper is well written and easy to follow.  The paper uses multiple sections to explain the main idea step by step. It starts with the introduction of feature decomposition and uses experiments to demonstrate the usefulness of the orthogonal subfeature; Then experiments show that moving the feature along the direction of the orthogonal subfeature can improve model performance; finally, authors  propose the idea to encourage the model to move towards the direction that dissimilar to learned embeddings.  The idea is implemented within the knowledge distillation framework.   \n\nThe proposed method is novel and effective. Existing knowledge distillation methods generally impose a similarity objective to help the student model better mimic the teacher model. The proposed method is on the opposite direction - it leans dissimilarity.  Authors has provided a detailed analysis to justify this novel learning objective.\n\nThe experiments are extensive and the results are solid. Multiple classic face recognization models are used as baselines and studied on several common benchmarks. The improvements look consistent. Ablation studies provides good insights for understanding the proposed method."
            },
            "weaknesses": {
                "value": "The ablation of the proposed method can be further enhanced.  Authors has hypothesized the proposed method works as a feature augmentation mechanism. It will be insightful if other feature augmentation or regularization methods can be compared, for example, injecting noise to the activations. \n\nThe method is only studied on face recognition. In theory, this method can be applied to other classification tasks (especially fine-grained classification). Existing face recognition benchmarks already have high accuracy, so the improvement doesn't look too significant."
            },
            "questions": {
                "value": "It would be interesting if authors can conduct experiments on some more challenging classification tasks."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission1105/Reviewer_V2zT"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission1105/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698822365490,
        "cdate": 1698822365490,
        "tmdate": 1699636036466,
        "mdate": 1699636036466,
        "license": "CC BY 4.0",
        "version": 2
    }
]