[
    {
        "id": "VRwBGl3rHY",
        "forum": "xVlcbh0poD",
        "replyto": "xVlcbh0poD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6606/Reviewer_mKqw"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6606/Reviewer_mKqw"
        ],
        "content": {
            "summary": {
                "value": "This paper introduces AutoRT which is a system designed to address the challenge of training autonomous robots in real-world environments with minimal human supervision. The main components consist of two parts: 1) VLMs discover environmental affordances from visual observations. 2) LLM proposes the tasks to try based on prompts and the affordances from VLMs. Basically, AutoRT leverages LLMs and VLMs to enhance the autonomy and data collection capabilities of a fleet of robots. The system employs multiple \"collect policies\" to ensure diverse data collection and adaptability, and tasks are filtered based on the capabilities of the selected policy. Finally, the authors extensively evaluate AutoRT in various real-world scenarios resulting in the collection of 77,000 trajectories."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The idea of autonomous embodied agents with foundation models from collecting data to exploring the world is interesting and the proposed system is quite well-organized for that.\n- This paper is well-written and easy to follow. And the method is clearly presented with descriptive figures.\n- This paper shows extensive real-world experiment evaluations in diverse tasks and  environments. And the results demonstrate that the data collected by AutoRT improves RT-1\u2019s performance, which shows that autonomous embodied system can collect useful data for action learning and this line of work is the promising way to go in the future."
            },
            "weaknesses": {
                "value": "- This paper lacks of technical novelty. This is a simple extension of [1, 2] to real-world robotic scenarios. I wonder if there is unique technical contribution over these existing works to deal with real-world robotic scenarios.\n- In table 1, the collect policies other than teleoperation have very low success rate which means the collected data might not be useful for action learning. Basically, this method sounds like it is scalable but in a low quality. Can we learn meaningful actions from these data other than visual generalization ability?\n- In Figure 3, it seems that teleoperated data has diverse action policies. However, when looking at the other data, excluding teleoperated data, they do not seem to have diverse action policies, especially considering that there are over 20 times more episodes with scripted policies. It seems that AutoRT does not explore sufficiently. Is there a way to encourage more action diversity?\n\n\n[1] Yuqing Du et al., Guiding Pretraining in Reinforcement Learning with Large Language Models. ICML, 2023.\\\n[2] Guanzhi Wang et al., VOYAGER: An Open-Ended Embodied Agent with Large Language Models. arXiv, 2023."
            },
            "questions": {
                "value": "- Does LLM ever propose tasks that require skills not within the robot's scripted policy or teleoperation policy? If so, how does the robot behave in such cases? If such cases do not exist, how does the LLM restrict task proposals to the skills the robot possesses?\n- I'm curious about how robots automatically perform a reset after completing a task. Is there a predefined reset policy, or is the reset also part of the task itself? I'm curious because there seems to be not much information on the reset process in the paper."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Reviewer_mKqw"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6606/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698666571387,
        "cdate": 1698666571387,
        "tmdate": 1699636752958,
        "mdate": 1699636752958,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "aywBwDh5s6",
        "forum": "xVlcbh0poD",
        "replyto": "xVlcbh0poD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6606/Reviewer_jtyJ"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6606/Reviewer_jtyJ"
        ],
        "content": {
            "summary": {
                "value": "This work proposes AutoRT, a system that uses VLM and LLM to guide diverse real-world manipulation data collection with a fleet of robots. The system proposes tasks given the scene at hand, and resort to either existing policy or human teleoperators to collect  manipulation data.\nThe collected data is shown to be more diverse than prior works, and lead to policy performance improvement."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "* The whole system requires a lot of effort to get running\n* the process of using LLM to generate diverse human-teleoperated task is interesting\n* many components are interesting, presenting value to the community: robot constitution, task generation, self-reflection\n* the collected data seems diverse and would be useful"
            },
            "weaknesses": {
                "value": "I like the general direction, and this paper makes a first important step towards more scalable real-world data collection. I do have a somewhat philosophical question: the introduction aims to solve the problem of \"lacking understanding of physical world\", but at the end it primarily resort to human teleoprators to collect policies. Indeed, using LLMs to generate more diverse tasks certainly eases the cost of collecting real-world data, compared to alternatives that solely rely on human, but the stage requiring the most human effort - actual teleoperation - still remains.\n\nAlso, the idea of using llm to generate diverse tasks is not a completely new thing. I believe it was firstly proposed in [1], which talks about very similar idea of generating diverse tasks (in simulation though), and is not cited.\n\n[1] Towards A Foundation Model for Generalist Robots: Diverse Skill Learning at Scale via Automated Task and Scene Generation (arXiv preprint arXiv:2305.10455)"
            },
            "questions": {
                "value": "In the paper it says \"For each environment, this map is generated once, then copied to all robots collecting in the space and loaded from cache to save time in future episodes.\" However, during the course of data collection, the objects and componenets in the scene will inevitably be changed. Does the map gets updated?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Reviewer_jtyJ"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6606/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698702341032,
        "cdate": 1698702341032,
        "tmdate": 1699636752846,
        "mdate": 1699636752846,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Xz8Y8feUUY",
        "forum": "xVlcbh0poD",
        "replyto": "xVlcbh0poD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6606/Reviewer_F9Mu"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6606/Reviewer_F9Mu"
        ],
        "content": {
            "summary": {
                "value": "This paper is about using a combination of LLMs and human teleoperators to collect a large amount of diverse training data where the number of operators is less than the number of robots. The system first builds a semantic map of the environment using an open vocabulary detector + slam. It then uses the map and the list of visible objects to prompt a LLM to come up with a series of tasks. It then uses another LLM to triage the tasks between human operator, scripted pick and place, deploying rt2, or rejecting the tasks because they are too dangerous or kinematically infeasible (requiring 2-hands). The high level story of the paper makes sense but there are some questions on the experiment's side that need to be answered."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "4 excellent"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The idea of scaling up data collection from limited human bandwidth is really good.\n- Leveraging LLMs for filtering, guardrailing, and proposing tasks is also another great plus.\n- Large scale data collection with  multiple robot is also commendable."
            },
            "weaknesses": {
                "value": "- The success rates are surprisingly low for both RT-1 and the one co-trained with Auto-RT. The gains are not that impressive to justify the pipeline.\n- What would happen if a task is deemed solvable by RT-2 and then RT-2 cannot actually solve it?\n- Does Auto-RT leverage the failure data as well?\n- According to Table 1, the majority of non-teleoperated data is not successful. I would like to see a comparison with AutoRT data but only using the teleoperated portion.\n- There is a confusion in the paper. Earlier RT2 is mentioned everywhere but all the tables use RT-1 for quantitative numbers. I thought RT-1 is inferior to RT-2. Why not provide quantitative numbers for RT-2 to see the gains of training on Auto-RT data are also observed there as well? I would like to see an experiment on that.\n- More details are needed for the scripted policy. It seems to be dependent on object pose which is possible to extract from the cached map in the beginning but it does not say anything about the orientation of the object. Any object where the orientation of the object is important would cause failure with this policy. The only exception that I can think of where the orientation does not really matter is to pick up a deformable object such as stuffed toy, sponge, etc or symmetric objects such as bowl/plate."
            },
            "questions": {
                "value": "See weaknesses above."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6606/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698803631110,
        "cdate": 1698803631110,
        "tmdate": 1699636752695,
        "mdate": 1699636752695,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vatNasJjqP",
        "forum": "xVlcbh0poD",
        "replyto": "xVlcbh0poD",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6606/Reviewer_P3WR"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6606/Reviewer_P3WR"
        ],
        "content": {
            "summary": {
                "value": "The paper discusses the challenges of training foundation models for robots due to a lack of real-world data. It introduces AutoRT, a system that uses existing foundation models to enable operational robots to work in new environments with minimal human intervention. AutoRT relies on vision-language models for scene understanding and large language models to generate diverse and innovative instructions for robots. By leveraging foundation model knowledge, AutoRT enhances data collection for robot learning while considering autonomy and safety. The system successfully deploys instructions to over 20 robots in various locations, resulting in 77k real robot episodes. Experimental results indicate that AutoRT's use of large language models leads to diverse data and robot behaviors that align with human preferences."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "-The paper was well written and flows smoothly.\n-The idea of a robot orchestrator is interesting, I like the idea of selecting an optimal collect policy from a suite of policies based on the generated task.\n-Experiments were run to assess language and visual diversity of the dataset, and results show that the dataset has higher diversity compared to existing approaches."
            },
            "weaknesses": {
                "value": "1.The collect policies used are limited, consisting of only teleoperation, a scripted pick policy and RT2. The authors mentioned that RT2 had frequent failures, and hence decided to run RT-2 less frequently. This means that the two dominant policies were teleoperation, and scripted pick policy, both of which requires manual labor / lacks action diversity. Because of this, the execution component is not truly automated.\n\n2.The paper emphasized the scale of the collected data, in that 53 robots were used to collect 77000 new episodes. However, while the scale of the data is big, the authors did not mention the possibility of open-sourcing the data. Further, the physical embodiment of the robot is not available to the research community.\nIn AutoRT Operational Details, the authors mentioned that AutoRT was run using stationary robots that skipped navigation and only conducted manipulation. In these scenarios, would the tasks which robots generate be dependent on the objects which are exposed to the robot? Can the authors provide some explanation on how the scenes for such robots were set up to ensure practicality while reducing the inherent bias that could be introduced into tasks generated by humans manually selecting the objects to set up the environment?\n\n3.I would also suggest the author look into if there is a need for a real-robot for the data collection process as there are a few works that look into self-generating tasks or ever collecting demonstrations for a real robot without the need for a flight of robot. Examples:\n-Huang, Wenlong, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, and Li Fei-Fei. \"Voxposer: Composable 3d value maps for robotic manipulation with language models.\" arXiv preprint arXiv:2307.05973 (2023).\n-Wang, Lirui, Yiyang Ling, Zhecheng Yuan, Mohit Shridhar, Chen Bao, Yuzhe Qin, Bailin Wang, Huazhe Xu, and Xiaolong Wang. \"GenSim: Generating Robotic Simulation Tasks via Large Language Models.\" arXiv preprint arXiv:2310.01361 (2023).\n-Duan, Jiafei, Yi Ru Wang, Mohit Shridhar, Dieter Fox, and Ranjay Krishna. \"AR2-D2: Training a Robot Without a Robot.\" arXiv preprint arXiv:2306.13818 (2023).\n\n4. The authors specify a robot constitution for filtering tasks, where the embodiment rules involve an understanding of the physical attributes of objects (i.e. heaviness). However, it is uncertain whether the language models are suitable for embodiment style questions (i.e. weight, composition reasoning). Perhaps the authors should look into literature which studies the capability of language models and vision language models in doing physical reasoning such as:\n1.Wang, Yi Ru, Jiafei Duan, Dieter Fox, and Siddhartha Srinivasa. \"NEWTON: Are Large Language Models Capable of Physical Reasoning?.\" arXiv preprint arXiv:2310.07018 (2023).\n2.Gao, Jensen, Bidipta Sarkar, Fei Xia, Ted Xiao, Jiajun Wu, Brian Ichter, Anirudha Majumdar, and Dorsa Sadigh. \"Physically Grounded Vision-Language Models for Robotic Manipulation.\" arXiv preprint arXiv:2309.02561 (2023)."
            },
            "questions": {
                "value": "All my question is listed in the weakness, I hope the authors can address my concerns in the weakness section and make the necessary changes."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "Nill"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6606/Reviewer_P3WR"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6606/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698821086159,
        "cdate": 1698821086159,
        "tmdate": 1699636752549,
        "mdate": 1699636752549,
        "license": "CC BY 4.0",
        "version": 2
    }
]