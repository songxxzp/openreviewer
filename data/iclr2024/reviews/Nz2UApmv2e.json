[
    {
        "id": "rC9Tk7tuBv",
        "forum": "Nz2UApmv2e",
        "replyto": "Nz2UApmv2e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission930/Reviewer_teCi"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission930/Reviewer_teCi"
        ],
        "content": {
            "summary": {
                "value": "The authors propose SpikSLC-Net, a novel SNN based architecture dealing with sound event localization and classification tasks simultaneously. To effectively integrate acoustic features extracted jointly from both GCC-PHAT and Log-mel Spectrogram,  they combine SSA module together with its extended SCA module and propose a novel SHAF block involving the aforementioned two attention modules, which is declared as fundamental to utilize synchronization information between multiple feature modalities. Experiments also manifest a state-of-the-art performance of the proposed architecture."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. To the best of my knowledge, it is the first work for a SNN based model manifesting its strong effectiveness in multitasking like SELC task, even exceeds the performance of ANN model.\n2. The paper is well written and clearly presented. The motivation is meaningful and interesting.\n3. Employing GCC-PHAT feature and Log-mel Spectrogram altogether to fully explore the characteristic of sound sources is advisable, which naturally fit for the design of multi-head attention mechanism."
            },
            "weaknesses": {
                "value": "1. Though achieving state-of-the-art performance on SLoClas dataset, the proposed architecture still lacks novelty. According to my understanding, the core part of the architecture is the SHAF block, however its components are just copies or slight modifications/extensions of spiking self attention mechanism proposed in [zhou et al., 2022]. The extension seems straight forward and may not be regarded as a genuine technical contribution.\n2. Some of the notations are not align with the others. For example, sometimes the embedding feature dimension is denoted as $D$, but sometimes not (fig 2).\n3. Though performing best on SLoClas dataset, it is hard to conclude that the current work is better than previous works in terms of sound localization and classification. More experiments on various datasets is recommended.\n4. Comprehensive analysis of the robustness to noisy environment is insufficient.\n5. As in [zhou et al., 2022], comparison of computation complexity and estimated power consumption are highly recommended to be embraced in the experiments."
            },
            "questions": {
                "value": "The above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission930/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698575933669,
        "cdate": 1698575933669,
        "tmdate": 1699636019807,
        "mdate": 1699636019807,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MygKwhetzQ",
        "forum": "Nz2UApmv2e",
        "replyto": "Nz2UApmv2e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission930/Reviewer_zvoL"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission930/Reviewer_zvoL"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a spiking neural network model (SpikSLC-Net) for joint sound localization and classification. Extending earlier work on attention in spiking neural networks, the authors propose a cross-attention mechanism. In addition, the propose a form of layer normalization which they claim to be more suitable for spiking neural nets than the vanilla version. They show that their approach outperforms a few earlier spiking neural network approaches on the SLoClas dataset."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "+ Spiking neural networks are an interesting and important research direction\n + Sound localization and classification are relevant perception problems\n + Models able to solve multiple tasks are a relevant research direction also in the auditory domain"
            },
            "weaknesses": {
                "value": "1. Unclear why this particular combination of problems and approaches\n 1. Claims not supported well by experiments and evidence\n 1. Lack of strong baselines\n 1. Very narrow evaluation on only a single, quite specific dataset\n 1. Method is not really understandable from the paper, lots of details missing\n\n\nOverall, I think this paper needs a major overhaul in terms of motivation, presentation and (most likely) additional experiments. I don't see how it could be accepted even if many of the questions could be answered in a discussion. I think it should be thoroughly revised and resubmitted, so reviewers can assess the revised version. To be honest, it should not have left the PIs desk like this. In an effort to be constructive, I will detail my concerns below, but I don't see much potential for a change in score."
            },
            "questions": {
                "value": "### 1. Why this combination of problems and approaches\n\nIt is not clear to me what the goal of the paper is. If it's about sound localization and classification, why do we need spiking neural nets? If it's about spiking neural nets, why such a narrow focus on this particular (combination of tasks)? What motivates the development of the LN layer for spiking nets? The paper reads like a very specific approach to a very specific problem, where the approach is not motivated by the requirements of the problem. Thus, it remains unclear to me what we can learn from this paper.  \n  \n  \n### 2. Claims not supported well by experiments and evidence\n\nThe paper makes four main claims at the end of the introduction. The first three of them are not supported by evidence in my opinion.\n\n 1. The authors claim their paper is the first to use multi-task learning in SNNs and audio-related tasks. That may well be the case, by why is this a contribution? There is little evidence presented that multi-task learning is necessary to achieve the goal (sound localization and classification) or that it improved performance on either of the tasks. Table 3 shows that training each task individually works almost as well on localization and equally well on classification. As there are no error bars given, it remains difficult to judge whether there is an effect at all.\n\n 1. The Spiking Hybrid Attention Fusion (SHAF) mechanism is presented as a contribution of the paper. However, I could not follow its description in the paper because too many symbols were not defined. Moreover, it is not clear to me whether this mechanism could actually be implemented with spiking neurons on neuromorphic hardware, since Q,K,V are claimed to be real-valued.\n\n 1. The training-inference-decoupled LN method (DSLN) is presented as a contribution of the paper. Again, I could not follow what is happening since too many symbols were undefined. Generally, it is not clear to me what's the goal here. Since the whole point of layer norm is to normalize by activation statistics of other units in the same layer, I don't understand how the authors want to absorb it into the weights of the previous layer (seems to be the goal of Eq. 15) and why they drop the variance normalization (if getting rid of the sqrt is the goal, they could, e.g., use mean absolute deviation instead).\n\n\n\n### 3. Lack of strong baselines\n\nThe authors claim to outperform earlier methods. That might be the case for the two spiking neural nets in Table 1, but how strong are these baselines? The ANN baseline casts some doubt: Why would the spiking version outperform an ANN baseline? What's the mechanism that makes a spiking net perform better than one that doesn't restrict itself to spiking? This seems to be an implausible claim or a very weak baseline.\n\n\n\n### 4. Narrow evaluation\n\nIn case the goal is not to solve these two particular tasks (sound localization and classification) but to make a contribution to spiking neural nets in general, the paper would need a more thorough evaluation of a broader set of problems/datasets to demonstrate the usefulness of the method. If, however, the goal is to solve these particular two tasks, then I think there are better approaches than SNNs and it is not clear why the authors focus on SNNs.\n\n\n### 5. Lack of clarity in methods\n\nI found the description of the methods extremely hard to follow and could not resolve a number of questions. Part of the reason is that in many cases the motivation for doing something is not spelled out clearly at the outset, another part is that many symbols are simply not defined, not explained or their dimensions remain unclear. A few examples:\n\n 1. Fig. 2: Meaning of N, F, B_g and B_m are unclear. They are not defined in the figure caption. N seems to be used at multiple places for multiple different things. In this Fig. it might refer to the number of microphone pairs, but later (Eq. 8) it shows up again with a different meaning. It looks like T x F x E from Fig. 2 might correspond to T x N x D in Eq. 8, but since neither are defined, I can only guess.\n\n 1. The meaning of the symbols in Eq. 8 is unclear. First, the dimensions T x N x D: What does each mean? If T refers to time, does this mean attention extends over time? What are the dimensions of W_Q, W_K and W_V? and what does the product X_alpha W_Q mean? Why is there a batch norm around this product? That's not usually the case in Transformer attention. What is the meaning of SN(.)? The action potential symbols in Fig. 3 do not really help. What are the dimensions of SN(.), both input and output?\n\n 1. Section 4.3, in particular Eq. 15 remains unclear to me. W, W'_*,* are only defined in terms of dimensions, but it's neither clear what they are, how they come about nor what m and n in their dimensions mean. Also, A_i has not been introduced."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "1: strong reject"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission930/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698694797177,
        "cdate": 1698694797177,
        "tmdate": 1699636019723,
        "mdate": 1699636019723,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "QgO21U9Wor",
        "forum": "Nz2UApmv2e",
        "replyto": "Nz2UApmv2e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission930/Reviewer_zsh4"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission930/Reviewer_zsh4"
        ],
        "content": {
            "summary": {
                "value": "The paper presents a Spiking Neural Network based framework for sound source localization and classification. The framework incorporates a novel Spiking Hybrid Attention Fusion (SHAF) mechanism and a unique training-inference-decoupled Layer Normalization method (DSLN), and achieves state-of-the-art performance on the SLoClas dataset with minimal computational steps.\n\nOverall, within the spike neural network framework, this is a useful contribution. Although I have doubts about it's performance relative to traditional ANNs and CNNs, it is nice to see SNNs applied to a wider array of complex audio tasks."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "4 excellent"
            },
            "strengths": {
                "value": "The paper introduces a novel approach to simultaneous sound source localization and classification using SNNs. I haven't seen such use of SNNs for audio-related multi-task learning\n\nThe introduction of the Spiking Hybrid Attention Fusion mechanism, is interesting. This mechanism seems to capture temporal dependencies and aligns relationships among diverse features.\n\nLayer Normalization: The DSLN method proposed for SNNs addresses the challenges associated with dynamic calculation during runtime in vanilla layer normalization. This method reduces the floating-point operations required, making it more suitable for SNNs.\n\nEnergy Efficiency: The framework\u2019s design is motivated by energy efficiency, which is a significant consideration for deploying models in real-world applications, especially on edge devices.\n\nThe paper shows strong  performance on the SLoClas dataset\n\nThe ablation studies are good and show that the proposed layer norm maintains strong performance while reducing the overall computation"
            },
            "weaknesses": {
                "value": "Baselines - The method compares with other SNN baselines and one ANN baseline. However I would like to see comparisons with other recent ANN methods. For example the method in (https://arxiv.org/pdf/2010.06007.pdf) is able to localize and separate speech to 2.1 degrees, although it uses 8 microphones to do so.\n\nAchieving 99% accuracy with only 2 timesteps during inference is impressive, but it does raise questions about overfitting. It would strengthen the paper to have some real world examples or examples on a different dataset besides the Sloc dataset."
            },
            "questions": {
                "value": "Do you have any other results to compare against traditional ANN methods?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "8: accept, good paper"
            },
            "confidence": {
                "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission930/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698793743536,
        "cdate": 1698793743536,
        "tmdate": 1699636019624,
        "mdate": 1699636019624,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "Cgf2RLtoRj",
        "forum": "Nz2UApmv2e",
        "replyto": "Nz2UApmv2e",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission930/Reviewer_VDuB"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission930/Reviewer_VDuB"
        ],
        "content": {
            "summary": {
                "value": "This paper designed a multi-task spiking neural network (SNN), by incorporating spiking self-attention modules and cross-attention modules that can capture temporal dependencies, to solve both sound source localization and classification tasks. The authors further introduced training-inference-decoupled layer normalization (DSLN), and demonstrated similar performance in benchmarking on SEC tasks with fewer time steps."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. This paper showed novelty as a first implementation in multi-task learning with full SNNs in audio domain, while previous papers on SNNs have focused more on single classification task. \n2. Strong benchmarking performance in showing superior accuracy in both SEC and localization tasks, lower MAE for localization task, at fewer time steps. , which further brought possibility on short latency given few time steps required by SNN."
            },
            "weaknesses": {
                "value": "1. Most previous SEC task reported F1 score to account for potential bias in sound classes. Would it be possible to show F1 score benchmarking with previous SEC task (potentially could leverage some DCASE datasets) instead? Such high accuracy was unclear to me if there were any biases, and unclear whether your algorithm has specific bias on precision vs. recall. \n2. Ablation studies of DSLN do not suggest the difference is statistically significant, suggesting a relatively small or even no impact on the strong performance in SEC and localization tasks. \n3. Additionally, ablation studies did not show how self-attention and cross-attention modules could play an essential role in decoding these tasks. The non-significant differences in numbers of SHAF blocks and embedding dimensions (Table 2) posed a confusing and open question on where the major performance benefits from. It would be more persuading by providing a stronger ablation study, showing how SHAF blocks contribute to the essential performance boosting here, while the rest of modules (multi-task) remained in the model."
            },
            "questions": {
                "value": "1. Following above in weaknesses, I think it would be helpful to perform ablation studies, showing the role of the proposed SHAF blocks and DSLN specifically in the superior performance. The fact that ablation studies did not show strong impact wrt different hyperparameters in SHAF and LN modules, pose a question on whether the major benefit comes from the multi-task heads, or different algorithmic complexity of this SNN vs. previous SNN.  \n2. Can authors provide benchmarking with F1 score, precision, recall? \n3. Can authors provide an algorithmic complexity analysis of this SNN vs. previous SNN?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission930/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699232105339,
        "cdate": 1699232105339,
        "tmdate": 1699636019541,
        "mdate": 1699636019541,
        "license": "CC BY 4.0",
        "version": 2
    }
]