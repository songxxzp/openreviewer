[
    {
        "id": "52MRZ3iv1b",
        "forum": "GfXF04YYvu",
        "replyto": "GfXF04YYvu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8065/Reviewer_gUoU"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8065/Reviewer_gUoU"
        ],
        "content": {
            "summary": {
                "value": "This paper investigates the impact of personalization techniques in the FL paradigm on local (group) fairness of the learned models, and show that personalization techniques can also lead to improved fairness. In addition, \nWe establish this effect through numerical experiments comparing two types of personalized FL algorithms against the baselines and elaborate on the reasons behind improved fairness using personalized FL methods. What\u2019s more, they further provide analytical support under certain conditions."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "1 poor"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. The paper through the introduction of personalization techniques alone can improve local fairness and has a potentially more desirable fairness-accuracy tradeoff, which is important.\nS2. They have provided theory analytics."
            },
            "weaknesses": {
                "value": "W1. The motivation for Formula 1 is expected with clear explanation.\nW2. It is rather abrupt to say \u201cConsequently, clients with heterogeneous datasets may encounter local accuracy degradation\u201d. Please elaborate on it, preferably with an example.\nW3. There is no relevant pseudocode in this article.\nW4. The icon of figure1(c) is inconsistent."
            },
            "questions": {
                "value": "Q1. This sentence \u201cIt effectively treats information originating from other clusters as noise, which, if left unaddressed, would have led to model divergence, potentially compromising both cluster-specific performance and fairness.\u201d What does this mean?\nQ2. Is the algorithm in this article only for binary classification? Can it be adapted to more complex tasks?\nQ3. Please provide a detailed explanation of all formulas in the \"Fairness metric\" chapter."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8065/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8065/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8065/Reviewer_gUoU"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698636514477,
        "cdate": 1698636514477,
        "tmdate": 1699636997446,
        "mdate": 1699636997446,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RwGt12nwmt",
        "forum": "GfXF04YYvu",
        "replyto": "GfXF04YYvu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8065/Reviewer_9xvK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8065/Reviewer_9xvK"
        ],
        "content": {
            "summary": {
                "value": "The paper proposes to explore the intersection of personalization techniques in federated learning (FL) with the goal of improving fairness."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "It argues that the collaboration inherent in FL can enhance both local accuracy and fairness, especially when dealing with imbalanced samples and offers an empirical and theoretical foundation to support its claims. The authors also provide detailed theoretical proposition and analytical results to support the idea."
            },
            "weaknesses": {
                "value": "However,  while the work touches on an interesting aspect of federated learning, there are critical shortcomings and limitations.\n\n1.\tLack of Novelty and Significance: The paper attempts to align personalization techniques with fairness benefits in FL. While the authors have shown that is it a valid and relevant research direction, the authors do not present a novel or significant contribution to the field. The concepts of clustered FL and personalized FL used in this paper is proposed by prior research works such as Ghosh et al. (2020) and Nardi et al. (2022). As a result, this work appears to be a reiteration or extension of established ideas, but it does not come across as a breakthrough or innovative approach.\n\n2.\tLimitation of Assumptions: The theoretical propositions make several assumptions, such as equalized label participation rates and balanced label distribution. While these assumptions are necessary for the theoretical analysis, they might not fully represent real-world scenarios, limiting the generalizability of the findings."
            },
            "questions": {
                "value": "See above"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission8065/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8065/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission8065/Reviewer_9xvK"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698740681612,
        "cdate": 1698740681612,
        "tmdate": 1699636997321,
        "mdate": 1699636997321,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "f4VsatWJe4",
        "forum": "GfXF04YYvu",
        "replyto": "GfXF04YYvu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8065/Reviewer_4EZY"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8065/Reviewer_4EZY"
        ],
        "content": {
            "summary": {
                "value": "This paper investigate the impact of personalization in federated learning for fairness. The analysis show that under certain constraints, introducing personalization techniques could achieve a better accuracy-fairness tradeoff. Empirical and theoretical analyses on real-world adult dataset and synthetic dataset supports the authors' claims."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. Interesting study to show the relationship between fairness, accuracy, and personalization.\n\nS2. Both empirical and theoretical analyses are provided."
            },
            "weaknesses": {
                "value": "W1. When motivating fairness in federated learning, the authors use 2 examples, and I am concerned about both examples. For the 1st example, I doubt federated learning is a commonly used learning paradigm for LLMs. And for the 2nd example, it seems the mentioned paper is not related to federated learning either. Is it possible to offer stronger evidence to motivate fair federated learning?\n\nW2. The assumption that clients within the same cluster are identical is too strong. This might be a too simple case for data heterogeneity and can be seen as FL with only 2 clients in my opinion (is it better to describe the scenario in this way?). What is the rationale for this assumption? And what is the main theoretical difficulty of assuming a more complex case? \n\nW3. What are the x-axis and y-axis in Figures 1, 2, and 3? Is each bar a bin w.r.t. fractions? Is y-axis the normalized count of states within that bin?\n\nW4. Why can we assume that $\\mu_b^0 \\leq \\mu_a^0 \\leq \\mu_b^1 \\leq \\mu_a^1$?\n\nW5. While I appreciate the interesting analysis in this paper, it would be better to have a way to summarize the key findings, e.g., a table or itemized list to show under which condition personalization is recommended to obtain fairness for free.\n\nW6. Showing such analyses for statistical parity is great. Is there any technical limitation for analyzing equal opportunity? How about Rawls' fairness that maximize the worst-off group accuracy?"
            },
            "questions": {
                "value": "Please see weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699250587528,
        "cdate": 1699250587528,
        "tmdate": 1699636997194,
        "mdate": 1699636997194,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "SaPTEPlRtM",
        "forum": "GfXF04YYvu",
        "replyto": "GfXF04YYvu",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission8065/Reviewer_eX39"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission8065/Reviewer_eX39"
        ],
        "content": {
            "summary": {
                "value": "This paper studied the cost-free fairness brought by personalized federated learning. With clustering clients into groups, the authors showed that personalization in FL could lead to fairness in the FL paradigm. Finally, experiments were conducted on several datasets to investigate the impact of personalization techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1. This study demonstrated that personalization in FL can promote fairness, even without the use of dedicated fair FL algorithms. This represents a novel and intriguing discovery.\n\nS2. This study employed numerical experiments to support its findings and conclusions.\n\nS3. The figures included in this study served as illustrative representations of the findings."
            },
            "weaknesses": {
                "value": "W1. The paper considered only one effectiveness metric for fairness, ASPD, and hence it may not be entirely convincing, as it provides a limited scope for evaluating fairness. In particular, the fairness in FL is not a new problem.\n\nW2. It is worth noting that while the study claims that the samples are drawn independently and identically distributed (IID) in the conclusion section, this is not explicitly stated in the experiment section. Moreover, an IID setting is less practical than real-world FL application.\n\nW3. In the third experiment, only one normalized sample frequency is considered, i.e., Fig.3 (b) may not describe the situation well. For the fraction is comparable for label 0, but differs for label 1.\n\nW4. The comparison with fair FL may not be entirely convincing due to the inadequate experiment results and the inclusion of only one baseline and its variant. Further experiments and additional baselines could strengthen the credibility of the comparison.\n\nW5. The introduction in Section 3 regarding FL algorithms may contain some inaccuracies. For instance, the clustered FL algorithm (Ghosh et al.) is described as clustering based on model similarity, whereas in reality, it clusters based on model performance."
            },
            "questions": {
                "value": "Beyond the above weak points, there are also additional questions:\n\nQ1. This paper does not conduct experiments under a non-iid setting, which may affect the overall persuasiveness of the results. What about experimental evaluation under Non-IID setting? Does your solution still work well?\n\nQ2. Following the question above, do we really need personalization under iid setting? Please provide more justifications, references, and real-world applications to demonstrate the motivation.\n\nQ3. In the experiment, each client is provided with 1000 training samples and 2000 testing samples, why is the size of testing samples twice of training samples?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "NA"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission8065/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699341694459,
        "cdate": 1699341694459,
        "tmdate": 1699636997073,
        "mdate": 1699636997073,
        "license": "CC BY 4.0",
        "version": 2
    }
]