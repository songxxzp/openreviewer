[
    {
        "id": "6S5WWRRCvO",
        "forum": "hRbLHpLAy4",
        "replyto": "hRbLHpLAy4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6968/Reviewer_vSmf"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6968/Reviewer_vSmf"
        ],
        "content": {
            "summary": {
                "value": "The authors introduce a purification model named \"RetPur\" designed to purify adversarial test datasets. This helps mitigate targeted attacks in both uni-modal and cross-modal retrieval systems.\nThe \"RetPur\" model uses a pre-trained diffusion model, which provides plug-and-play convenience. It also utilizes adversarial samples as conditioning factors to guide image generation, enhancing task accuracy.\nThe study pioneers the incorporation of adversarial purification tasks into uni-modal (Image-to-Image) and cross-modal (Image-to-Image, Image-to-Text) hash retrieval systems, especially tailored for image retrieval scenarios.\nThe authors explore the application of adversarial purification tasks against a variety of attacks, including both generative and iterative approaches."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "The paper showcases originality by addressing a novel problem in the domain of image retrieval, maintains a high standard of quality in its methodology and comparative analysis, is presented with clarity, and holds significant implications for the broader field of deep learning and image retrieval.\u200b"
            },
            "weaknesses": {
                "value": "Potential Overhead and Scalability: The paper introduces a plug-and-play feature without addressing the potential computational overhead or scalability when integrating \"RetPur\" into existing retrieval systems.\nActionable Insight: An evaluation of the computational cost, in terms of time and resources, when deploying \"RetPur\" would be valuable. The authors should discuss the feasibility of using their model in real-world, large-scale applications and any potential bottlenecks."
            },
            "questions": {
                "value": "Are there specific types of adversarial attacks or scenarios where \"RetPur\" might not be as effective?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "none"
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6968/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698304615182,
        "cdate": 1698304615182,
        "tmdate": 1699636813993,
        "mdate": 1699636813993,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "RDkQSVOMGS",
        "forum": "hRbLHpLAy4",
        "replyto": "hRbLHpLAy4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6968/Reviewer_6D5x"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6968/Reviewer_6D5x"
        ],
        "content": {
            "summary": {
                "value": "This paper purifies datasets to defend the attacks in image retrieval models. Following the previous methods, based on a pre-trained diffusion model, the authors utilize adversarial examples as the conditioning factor to guide image generation. They attack both uni-modal and cross-modal retrieval tasks. The results demonstrate that the proposed method could improve the retrieval performance."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "This paper is well-written and easy to understand.  \nThe proposed method is effective in improving the defense performance in their experiments."
            },
            "weaknesses": {
                "value": "Considering the existing works [1][2], I think that the contribution of this paper is limited. The authors also utilize the adversarial examples as guidance [1] and leverage the forward and reverse diffusion process to remove the perturbations [2]. This paper transfers this protection paradigm from image classification to image retrieval tasks. Therefore, I think the novelty of this paper is below the acceptance threshold.\n\n[1] Jinyi Wang, Zhaoyang Lyu, Dahua Lin, Bo Dai, and Hongfei Fu. Guided diffusion model for adversarial purification. arXiv preprint arXiv:2205.14969, 2022.\n[2] Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, and Anima Anandkumar. Diffusion models for adversarial purification. arXiv preprint arXiv:2205.07460, 2022."
            },
            "questions": {
                "value": "The proposed method is not specific to image retrieval tasks or cross-modal relationships. Why not conduct experiments on other tasks?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6968/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6968/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6968/Reviewer_6D5x"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6968/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698657251499,
        "cdate": 1698657251499,
        "tmdate": 1699636813873,
        "mdate": 1699636813873,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "YW1K1SPihp",
        "forum": "hRbLHpLAy4",
        "replyto": "hRbLHpLAy4",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6968/Reviewer_o7o6"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6968/Reviewer_o7o6"
        ],
        "content": {
            "summary": {
                "value": "The paper introduces RetPur, a novel purification model designed to enhance the robustness of hash retrieval systems against targeted attacks by purifying adversarial test datasets. RetPur employs a pre-trained diffusion model and uses adversarial samples as conditioning factors to guide image generation, thereby improving task accuracy. The contributions of this model lie in its effectiveness in mitigating the impact of adversarial attacks and its applicability to both uni-modal (image-to-image) and cross-modal (image-to-image, image-to-text) hash retrieval systems."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1.The authors introduce adversarial purification into hash retrieval systems, mitigating the issue of targeted attacks within both uni-modal and cross-modal retrieval systems by purifying adversarial test datasets.\n\n2.The authors have validated the effectiveness of the proposed RetPur purification model through extensive experiments and have explored the application of adversarial purification tasks in a wider range of attack scenarios."
            },
            "weaknesses": {
                "value": "1.The authors did not provide a specific explanation of the differences between the proposed RetPur and the 'Guided Diffusion Model for Adversarial Purification' article's purification methods.\n\n2.The novelty of the method may be somewhat lacking; in my opinion, the purification method is akin to preprocessing the data, and the preprocessed clean data can evidently be used for various downstream tasks.\n\n3.In the paper, there are several typo errors , for instance, in Figure 1, 'RetPur' is incorrectly written as 'RerPur,' and in the 'CONCLUSION' section, the model name 'RetPur' is mistakenly written as 'RerPur' and 'PerPur.'"
            },
            "questions": {
                "value": "1.Could the authors provide a detailed explanation of the differences between their RetPur method and the purification method in the 'Guided Diffusion Model for Adversarial Purification' article?\n\n2.Could the authors provide more ablation experiments using different datasets, attack methods, and retrieval models?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6968/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6968/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6968/Reviewer_o7o6"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6968/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698715083617,
        "cdate": 1698715083617,
        "tmdate": 1699636813723,
        "mdate": 1699636813723,
        "license": "CC BY 4.0",
        "version": 2
    }
]