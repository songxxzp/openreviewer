[
    {
        "id": "IfdQxg1b4m",
        "forum": "fe8CzLTMG1",
        "replyto": "fe8CzLTMG1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6535/Reviewer_wB3J"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6535/Reviewer_wB3J"
        ],
        "content": {
            "summary": {
                "value": "Paper presents a new benchmark to evaluate the capacity of spatial-temporal reasoning of LLMs. The format is path planning, where given a 2D grid map with obstacles and targets (given as text), the LLM is required to produce a path plan that connects all the targets (optionally in a given order) and avoids all the obstacles. The LLM is also asked to predict whether the current path planning problem is unsolvable. The experiments cover an extensive range of topics including different LLMs, prompting methods, using in-context learning (zero-shot) vs, fine-tuning, IID vs. OOD tasks, etc."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "1 poor"
            },
            "strengths": {
                "value": "+The topic studied here is important, spatial-temporal reasoning is critical to more general intelligence, and as far as I know, there is not much evaluation on LLMs with a focus on this. I believe the research presented in this manuscript should be of interest to audiences not just from the LLM community, but reasoning and GOFAI as well.\n\n+The benchmark is well designed. It is simple and straightforward but gets right to the point of spatial-temporal reasoning(maybe a bit short on the temporal part, more on that lately).\n\n+The experiments are quite thorough, with rich numbers and details. From the LLM evaluation perspective, it covers most of the angles. I personally like the IID vs OOD part as it is less discussed before in the literature of LLM + reasoning and the results look quite promising as well."
            },
            "weaknesses": {
                "value": "I have some concerns regarding the motivation, the results, and some technical details (which will be listed in the question section):\n\n-Can the author elaborate more on why the path planning task in this benchmark can be used to measure temporal reasoning? I understand there is a variant that requires reaching the goals in a pre-specified order, but this seems more of a spatial reasoning problem as the planned path ultimately unfolds into a 2D grid. How is this spatial-temporal? I need to admit I am not an expert it this but more of a curious reader and I am happy to learn more if there are kinds of literature/references about this.\n\n-As the results show, most of the models (both in-context learning and fine-tuned) are able to attain 75+ accuracy some many critical metrics, ex. success rate, optimality, feasibility, etc. If this is the case, it seems that LLMs have almost nailed this task, why is this benchmark still useful for building better LLMs? Maybe the unreachable accuracy is still quite challenging, but this is only a small portion of the proposed benchmark.\n\n-some references on LLM + planning are missing: [1-3]\n\n[1] DEPS: https://arxiv.org/abs/2302.01560\n\n[2] Plan4MC: https://arxiv.org/abs/2303.16563\n\n[3] GITM: https://arxiv.org/abs/2305.17144"
            },
            "questions": {
                "value": "-In table 2, there are some results on OOD evaluation with in-context learning. Can the authors clarify the exact settings of this? What are the data used to fine-tune the models, and what are the in-context examples when performing the OOD evaluations?\n\n-What are the exact prompts used in the task? Specifically, what is the prompt for predicting whether the goal is reachable?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "details_of_ethics_concerns": {
                "value": "N/A"
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6535/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698592381100,
        "cdate": 1698592381100,
        "tmdate": 1699636735897,
        "mdate": 1699636735897,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "gNcPKsg56q",
        "forum": "fe8CzLTMG1",
        "replyto": "fe8CzLTMG1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6535/Reviewer_yt2L"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6535/Reviewer_yt2L"
        ],
        "content": {
            "summary": {
                "value": "This paper aims to investigate spatial-temporal reasoning and planning capabilities of SOTA LLMs. It proposed PPNL, a benchmark contains a set of 2D grid path planning problems, and conducted various experiments examining several LLMs's capabilities in path planning in a number of settings: in-distribution, out-of-distribution with varying grid size and number of obstacles, and multi-goal long-term planning settings. The results show that with appropriate prompting technique, LLMs can reason well in relatively simple settings, but struggles when it comes to long-term temporal reasoning."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "- The direction of the paper is important: temporal and spatial reasoning capabilties are indeed crucial for LLMs and ultimately AGI systems\n- The experiments are well designed and conducted thoroughly\n- Writing and paper presentation are polished"
            },
            "weaknesses": {
                "value": "- My biggest concern is that the experiment setting is a bit too simple: it's just a set of discrete 2D grid, which is far from ideal and realistic path planning setting: high DoF, 3D space, continuous action. I understand 2D grid is a good starting point, but still, it doesn't provide sufficient value for revealing deep enough insight into LLM's limits. for example, such experiments don't shed light on how current LLMs can reason in 3D space\n- This is a bit philosophical: spatial reasoning in a blind (pure language) space is, at least to me, not a well grounded request. I understand at the time of submitting, GPT-4v is not available yet, but there are also other large multimodal available, such as Bard. Maybe such experiments would be more justified if the reasoning is grounded with a vision input? After all, spatial path planning with only access to language description, even for humans, is not a very common task. I would like to see more insights on this from the authors."
            },
            "questions": {
                "value": "NA"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6535/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6535/Reviewer_yt2L",
                    "ICLR.cc/2024/Conference/Submission6535/Senior_Area_Chairs"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6535/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698777324071,
        "cdate": 1698777324071,
        "tmdate": 1700689880062,
        "mdate": 1700689880062,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "g6FcWnwnJD",
        "forum": "fe8CzLTMG1",
        "replyto": "fe8CzLTMG1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6535/Reviewer_w1hA"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6535/Reviewer_w1hA"
        ],
        "content": {
            "summary": {
                "value": "The paper examines the ability of Large Language Models (LLMs) to perform spatial-temporal reasoning with a focus on path planning. It presents findings on LLMs\u2019 proficiency in spatial reasoning when provided with spatial information and feedback from the environment. The paper highlights challenges LLMs face in scenarios requiring long-term planning and complex environments. The research introduces ReAct prompting and fine-tuned models' performances on newly proposed datasets, emphasizing their limitations and potentials in robotic applications."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The strengths of the paper include a thorough analysis of LLMs' capabilities in spatial-temporal reasoning and path planning. The originality of the work is evident in the creation of a new dataset and the formulation of specific benchmarks for path planning. The quality of research seems robust, with significant clarity in presenting the challenges and potential of LLMs in complex tasks. The significance of the study is clear, as it informs the limitations of current models and outlines potential future work to improve LLMs' application in real-world tasks."
            },
            "weaknesses": {
                "value": "One primary concern is what this paper brings to the community. The conclusion is stated at the end of the introduction, which basically matches what we would expect from other recent papers, especially considering the toy nature of the tasks. Additionally, the prompting itself, as the \"method\" section, is also using existing stand \"techniques\" and will not fundamentally solve the spatiotemporal reasoning + generalization problem.\n\nAnother one of the concerns about the paper is that the domain studied, such as 7x7 path planning, could be considered somewhat simplistic or \"toy-like.\" This raises questions about the extent to which the findings can be generalized to more complex, real-world scenarios. The use of small-scale environments may not adequately capture the challenges and nuances that would be present in larger, more intricate settings that LLMs might encounter in practical applications. If the benchmarking tasks do not accurately reflect the complexity of real-world tasks, it may limit the utility of the findings. To advance the field, it would be beneficial for future work to address scaling issues and test LLMs in more diverse and complex environments that better approximate actual use cases."
            },
            "questions": {
                "value": "1. How do the authors justify the use of the 7x7 path planning environment as a valid proxy for evaluating LLMs' true planning performance?\n2. What are the authors' plans for testing LLMs in more complex and realistic environments to ensure the findings are scalable and applicable to real-world tasks?\n3. Could the authors comment on any additional metrics or methods that might be used to evaluate planning performance in more complex scenarios?\n4. How might advancements in LLMs impact the spatiotemporal reasoning capability?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "3: reject, not good enough"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6535/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699084282899,
        "cdate": 1699084282899,
        "tmdate": 1699636735648,
        "mdate": 1699636735648,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "MlE9QuSJKh",
        "forum": "fe8CzLTMG1",
        "replyto": "fe8CzLTMG1",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6535/Reviewer_T3Yg"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6535/Reviewer_T3Yg"
        ],
        "content": {
            "summary": {
                "value": "This work proposes a benchmark on the ability of LLMs to perform path planning (PPNL - Path Planning from Natural Language) and analyzes several language models on the benchmark including fine tuned models. The authors claim that results on this benchmark demonstrate that LLMs perform spatial reasoning which can be systematically measured and improved upon via evaluation on the benchmark. They find that LLMs do not succeed in path planning on out-of-distribution data and long horizon examples."
            },
            "soundness": {
                "value": "1 poor"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "The systematic construction of examples on which to test path planning is nicely presented. The writing in the paper is clear, and the evaluation on the proposed benchmark is thorough. The formulation of this paper as an investigation into the true characteristics of a property which people are actively trying to leverage in their model development is a strong direction. If the claim of demonstrating spatial temporal reasoning in LLMs was established in this work (see weaknesses), it would be an interesting and novel result."
            },
            "weaknesses": {
                "value": "It seems to me that the results here could be explained in an entirely different way.\n\nEven though there are systematically constructed evaluations of increasing complex path planning problems across different dimensions (length, number of obstacles, etc.), I do not see how the fact that LLMs fail on the more complex tasks does not just imply that the pattern based instruction imitation of LLMs (the alternative interpretation of LLM instruction success) does not just fall apart more quickly on more difficult tasks. Imitating textual examples of instructions that these LLMs have been trained on in a pattern based way would yield significant success in providing directional information, particularly over short horizons.  Difficult tasks (long horizon, etc.) which require spatial reasoning have a lower probability of accidentally being successful with imitation-based responses.\n\nIn fact, the fine-tuning results where improvement is found in distribution and fail on out of distribution examples seems to support this alternate interpretation - not the authors\u2019 interpretation.\n\nThis imitation based mimicry of problem solving in relation to the ability of LLMs to perform mathematical computations have been widely discussed in the past (Bubeck et al. 2023). Also, the referenced papers on spatio-temporal reasoning used on PPNL (CoT and ReAct) provide approaches to use LLMs for spatio-temporal reasoning which is fundamentally different from implying LLMs actually perform spatio-temporal reasoning. \n\nIn fact even in the spatial reasoning section of the related work, it does not appear that any prior work supports the idea that spatial reasoning can be performed by LLMs. There are 3 types of work cited by the authors which also represent my understanding of the community's view of this problem: \n\n1. LLMs can be used via methodological automated prompting to develop spatial plans (the prompting method + LLM executes planning which has varying success in accomplishing the task), \n2. LLMs have some level of spatial understanding (textual request for code to make images has significant success, etc.), \n3. LLMs do not perform reasoning for math / planning / etc. problems - just quite good mimicry.\n\nIf the authors can explain and convince me that these results show LLMs actually perform reasoning over spatial information during the rebuttal, I would be willing to significantly increase my score."
            },
            "questions": {
                "value": "See weaknesses."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6535/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6535/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6535/Reviewer_T3Yg"
                ]
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6535/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1699100506399,
        "cdate": 1699100506399,
        "tmdate": 1700742860763,
        "mdate": 1700742860763,
        "license": "CC BY 4.0",
        "version": 2
    }
]