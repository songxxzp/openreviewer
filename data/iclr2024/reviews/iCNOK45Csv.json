[
    {
        "id": "rVS5Wz86er",
        "forum": "iCNOK45Csv",
        "replyto": "iCNOK45Csv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6151/Reviewer_bXcG"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6151/Reviewer_bXcG"
        ],
        "content": {
            "summary": {
                "value": "This paper study the backdoor attack for the Kernel Inducing Points (KIP) based dataset distillation. Specifically, the paper introduces two theory-driven trigger patterns and provides empirical evidence that they can increase ASR of models (with the same architecture as the proxies for dataset distillation) trained on the distilled datasets without sacrificing CTA remarkably. Additionally, experimental results also indicate that the evaluated backdoor defense methods may not be fully effective against the proposed relax-trigger."
            },
            "soundness": {
                "value": "2 fair"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "S1: This paper proposes to investigate a theoretical framework for the KIP-based dataset distillation method about why certain backdoors can survive in distilled datasets. Then, two theory-driven backdoor trigger patterns are consequently introduced.\n\nS2: In the evaluated scenarios, the proposed triggers present adequate ability to raise ASR without sacrificing CTA remarkably. Moreover, experimental results also indicate that the 8 evaluated backdoor defence methods may not be fully effective against the proposed relax-trigger."
            },
            "weaknesses": {
                "value": "W1: Certain key aspects of the presented theory appear ambiguous from my vantage point. I will delve deeper into these ambiguities in the Questions section.\n\nW2: The established theoretical framework predominantly caters to kernel-based dataset distillation methods, and its application seems restricted primarily to the initially proposed KIP method. Given the complexities associated with computing the NTK, KIP's practicality has been empirically questioned. While subsequent kernel-based dataset distillation methods capable of distilling comprehensive datasets have emerged (e.g., [1]), this paper falls short of validating their compatibility with the introduced framework. This oversight not only raises concerns about the paper's soundness but also limits the practicability of the introduced attack method.\n\nW3: The experimental design in the paper appears insufficient, raising questions about the broader applicability of the proposed attack. First, it relies on a mere two benchmark datasets. Second, the distilled dataset's size variation is limited to IPC (abbreviation of Image Per Class) scenarios of 10 and 50. Third, while cross-architecture generalization is pivotal in dataset distillation, the paper's evaluations seem to be confined to a 3-layer ConvNet, which is consistent with the architecture of the proxy model designated for distillation.\n\n[1] Yongchao Zhou, Ehsan Nezhadarya, Jimmy Ba: Dataset Distillation using Neural Feature Regression. NeurIPS 2022"
            },
            "questions": {
                "value": "Q1: Regarding Equation 9, why is the objective of the KIP-based backdoor attack to minimize the empirical loss of $f_{\\mathcal{S}^*}$ on either $\\mathcal{D}_A$ or $\\mathcal{D}_B$, rather than simultaneously reducing the empirical loss on both $\\mathcal{D}_A$ and $\\mathcal{D}_B\\$ as your statement about \"Backdoor Attack\" (The next to the last paragraph above Equation 7)?\n\nWhile you attempt to address this in Equation 10 by introducing $\\tilde{D}=D_A \\cup D_B$ to establish an upper bound on the loss of $f_{\\mathcal{S}^*}$ with respect to $D$, this formulation seems somewhat unreasonable to me.\n\nQ2: It appears that the introduced projection loss can be directly optimized with respect to the trigger $T$. What's the rationale behind setting an upper bound and optimizing the projection loss through this bound? Does this approach offer computational benefits?\n\nQ3: Based on my W3, could you share additional experimental evidence to validate the efficacy of your proposed triggers when applied to models with alternative architectures trained on the synthesized datasets?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "5: marginally below the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6151/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6151/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6151/Reviewer_bXcG"
                ]
            }
        },
        "number": 1,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6151/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698309518866,
        "cdate": 1698309518866,
        "tmdate": 1699636667060,
        "mdate": 1699636667060,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "vfXbULL3o8",
        "forum": "iCNOK45Csv",
        "replyto": "iCNOK45Csv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6151/Reviewer_Z9NC"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6151/Reviewer_Z9NC"
        ],
        "content": {
            "summary": {
                "value": "The research provides a comprehensive exploration of the theoretical underpinnings of backdoor attacks and their interplay with dataset distillation, employing kernel methods as the foundational framework. This investigation leads to the introduction of two innovative trigger pattern generation techniques, intricately crafted to suit the specific requirements of dataset distillation. These methodologies are meticulously derived from a foundation of theoretical insights."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. The research significantly contributes to the theoretical understanding of backdoor attacks and their interaction with dataset distillation. By using kernel methods as the foundational framework, it provides a rigorous theoretical foundation for subsequent developments.\n\n2. The introduction of two novel trigger pattern generation methods tailored for dataset distillation is a notable contribution. These methods are based on theoretical insights and offer new avenues for designing backdoor attacks in this context.\n\n3.The study backs its theoretical findings with comprehensive empirical experiments. The results demonstrate the resilience of datasets poisoned by the designed triggers against conventional backdoor attack detection and mitigation methods, adding practical significance to the research."
            },
            "weaknesses": {
                "value": "The experimental results presented in the study may benefit from further substantiation to conclusively support the stated claims. A notable observation in Table 2 is that the performance of the 'simple-trigger' method is notably outperformed by 'DoorPing,' which prompts questions regarding the efficacy of the former.\n\nMoreover, enhancing the organization and writing style of the manuscript could enhance its overall readability and comprehension for a wider readership."
            },
            "questions": {
                "value": "Please refer to \"Weaknesses\" part."
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6151/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6151/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6151/Reviewer_Z9NC"
                ]
            }
        },
        "number": 2,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6151/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698668982645,
        "cdate": 1698668982645,
        "tmdate": 1700874747189,
        "mdate": 1700874747189,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "KDcmtjMcrP",
        "forum": "iCNOK45Csv",
        "replyto": "iCNOK45Csv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6151/Reviewer_npoK"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6151/Reviewer_npoK"
        ],
        "content": {
            "summary": {
                "value": "The paper aims to bridge a gap in the literature by providing a theoretical framework for understanding backdoor attacks on dataset distillation. It introduces two new theory-driven trigger pattern generation methods: simple trigger and relax trigger, specialized for dataset distillation. The paper presents analyses and experiments on two datasets, showing that these triggers are effective at launching resilient backdoor attacks that can significantly weaken conventional detection and mitigation methods."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "2 fair"
            },
            "contribution": {
                "value": "2 fair"
            },
            "strengths": {
                "value": "1. The paper is among the first to provide a theoretical framework for understanding backdoor effects on dataset distillation, thus filling a significant gap in the field.\n2. The introduction of simple-trigger and relax-trigger is interesting. These triggers are also shown to be effective through empirical testing."
            },
            "weaknesses": {
                "value": "1. Some sections could benefit from more straightforward explanations to make the paper more accessible to readers not deeply familiar with the subject matter.\n2. The datasets evaluated in the paper appear to be limited in scope. Typically, researchers conduct experiments on more comprehensive datasets like ImageNet, or other comparable datasets, to convincingly demonstrate the effectiveness of a proposed attack method."
            },
            "questions": {
                "value": "1. Are there some potential defense methods during the dataset distillation process to mitigate backdoor attacks?\n2. Given the variety of dataset distillation methods available, could the choice of distillation method potentially impact the conclusions drawn about the efficacy of the proposed attack method?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            },
            "first_time_reviewer": {
                "value": "Yes",
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission6151/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission6151/Reviewer_npoK",
                    "ICLR.cc/2024/Conference/Submission6151/Senior_Area_Chairs"
                ]
            }
        },
        "number": 3,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6151/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698723143035,
        "cdate": 1698723143035,
        "tmdate": 1700658189737,
        "mdate": 1700658189737,
        "license": "CC BY 4.0",
        "version": 2
    },
    {
        "id": "ExOJlKXGa0",
        "forum": "iCNOK45Csv",
        "replyto": "iCNOK45Csv",
        "signatures": [
            "ICLR.cc/2024/Conference/Submission6151/Reviewer_hKa2"
        ],
        "nonreaders": [],
        "readers": [
            "everyone"
        ],
        "writers": [
            "ICLR.cc/2024/Conference",
            "ICLR.cc/2024/Conference/Submission6151/Reviewer_hKa2"
        ],
        "content": {
            "summary": {
                "value": "The paper studies the problem of backdoor attacks to evade data distillation, which introduces subtle changes or \"triggers\" to data to manipulate machine learning models.  It focuses on the theoretical underpinnings of dataset distillation and its implications on backdoor attacks. Based on the theoretical understandings, the authors propose two new theory-induced trigger generation methods: simple-trigger and relax-trigger. Experimental results demonstrate that these triggers, when used in an attack, can successfully evade common backdoor detection techniques."
            },
            "soundness": {
                "value": "3 good"
            },
            "presentation": {
                "value": "3 good"
            },
            "contribution": {
                "value": "3 good"
            },
            "strengths": {
                "value": "1. One of the primary strengths of this work is the establishment of the first theoretical framework to understand backdoor effects on dataset distillation. This fills a significant gap in the literature, especially when considering the practical implications of such attacks.\n2. The paper introduces two new backdoors - simple-trigger and relax-trigger - which are computationally efficient. The relax-trigger, in particular, is more efficient than DoorPing as it doesn't rely on bi-level optimization.\n3. Both the simple-trigger and relax-trigger have been demonstrated to challenge or evade eight existing defense mechanisms."
            },
            "weaknesses": {
                "value": "1. If we utilize the original dataset instead of the distilled data for model training, would the trigger remain effective? It would be better to include such experiments.\n2. Can the proposed attacks evade other data distillation techniques (e.g., gradient matching based methods and distribution matching based methods)? It would further strengthen the experimental evaluation by examining the transferability of the proposed attacks.\n3. In my understanding, individuals would majorly employ distilled data for training new models in scenarios such as neural architecture search and continual learning. Expanding on the implications of backdoor attacks in these applications would provide greater clarity."
            },
            "questions": {
                "value": "1. In Equation (9), why the second term is called the generalization gap?"
            },
            "flag_for_ethics_review": {
                "value": [
                    "No ethics review needed."
                ]
            },
            "rating": {
                "value": "6: marginally above the acceptance threshold"
            },
            "confidence": {
                "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
            },
            "code_of_conduct": {
                "value": "Yes"
            }
        },
        "number": 4,
        "invitations": [
            "ICLR.cc/2024/Conference/Submission6151/-/Official_Review",
            "ICLR.cc/2024/Conference/-/Edit"
        ],
        "domain": "ICLR.cc/2024/Conference",
        "tcdate": 1698809964829,
        "cdate": 1698809964829,
        "tmdate": 1699636666690,
        "mdate": 1699636666690,
        "license": "CC BY 4.0",
        "version": 2
    }
]