[
    {
        "title": "Input-gradient space particle inference for neural network ensembles"
    },
    {
        "review": {
            "id": "b1eQn1voxm",
            "forum": "nLWiR5P3wr",
            "replyto": "nLWiR5P3wr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2353/Reviewer_aXJD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2353/Reviewer_aXJD"
            ],
            "content": {
                "summary": {
                    "value": "Most prior research employing particle-based variational inference (ParVI) has proven to be inefficient and has not significantly improved performance. To tackle these issues, this study presents a new ParVI approach known as the First-order Repulsive Deep Ensemble (FoRDE), which integrates repulsion principles into the realm of first-order input gradients."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The idea of incorporating repulsion into first-order input gradients(not a function space or a weight space repulsion which are quite common in Bayesian Neural Network literature) to enhance functional diversity is new to the community and intriguing.\n- The paper is well-written, ensuring it is easy to read and understand."
                },
                "weaknesses": {
                    "value": "- The scale of experiments are quite small to show the effectiveness of FoRDE.\n- The overall performance gain compared to other baselines looks quite marginal for the out-of-distribution datasets, especially for the TinyImageNet which is the largest dataset. And shows lower performance compared to the other baselines for the in-distribution datasets.\n- Having empirical or theoretical evidence to demonstrate the effectiveness of FoRDE in enhancing input gradient diversity would be beneficial.\n- Providing empirical results that illustrate how the improved input gradient diversity effectively changes into enhanced functional diversity in deep neural network scenarios would be valuable. \n- Additional hyperparameters for the kernel would be another burden for this method."
                },
                "questions": {
                    "value": "See the weakness section\n\nRecommend\n- It is recommended to include an ethics statement and a reproducibility statement right after the main paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2353/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2353/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2353/Reviewer_aXJD"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2353/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698559956650,
            "cdate": 1698559956650,
            "tmdate": 1700267330052,
            "mdate": 1700267330052,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "m6h2T7NAL6",
                "forum": "nLWiR5P3wr",
                "replyto": "b1eQn1voxm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your review. We have updated our manuscript according to your comments and uploaded the new version to the system. Below we address the specific concerns.\n\n> The scale of experiments are quite small to show the effectiveness of FoRDE.\n\nIn our paper, we performed experiments using ResNet18 and PreActResNet18 architectures with CIFAR-10/100 and TinyImageNet datasets. These experiments have been designed to show effectiveness of FoRDE on scales comparable to earlier works on particle inference for neural networks [1, 2, 3] and neural network ensembles [4, 5].\n\n> The overall performance gain compared to other baselines looks quite marginal for the out-of-distribution datasets, especially for the TinyImageNet which is the largest dataset. And shows lower performance compared to the other baselines for the in-distribution datasets.\n\nWhile our method achieve slightly lower performance on clean data compared to the baselines, we argue that the performance gain on corrupted data is much more substantial and is not trivial to achieve since we need not assume any prior knowledge of these corruptions, and FoRDE consistently outperforms the baselines on corruptions across different datasets. For instance, Table 1 and 2 in the manuscript shows that  FoRDE-PCA achieves a +1.3% gain on CIFAR-100-C and +2.4% gain on CIFAR-10-C in accuracy compared to the second-best results.\n\n> Having empirical or theoretical evidence to demonstrate the effectiveness of FoRDE in enhancing input gradient diversity would be beneficial.\n\n> Providing empirical results that illustrate how the improved input gradient diversity effectively changes into enhanced functional diversity in deep neural network scenarios would be valuable.\n\nTo show that FoRDE indeed produces ensembles with higher input gradient diversity among member models, which in turn leads to higher functional diversity than DE, we visualize the input gradient distance and epistemic uncertainty of FoRDE and DE in Fig. 7 of Section D.1 in the Appendix of the revised manuscript. To measure the differences between input gradients, we use *cosine distance*, defined as $1-\\cos(\\mathbf{u}, \\mathbf{v})$ where $\\cos(\\mathbf{u}, \\mathbf{v})$ is the cosine similarity between two vectors $\\mathbf{u}$ and $\\mathbf{v}$. To quantify functional diversity, we calculate the epistemic uncertainty using the formula in [6], similarly to the transfer learning experiments. Fig. 7 shows that FoRDE has higher gradient distances among members compared to DE, while also having higher epistemic uncertainty across all levels of corruption severity. Intuitively, as the test inputs become more corrupted, epistemic uncertainty of both FoRDE and DE increases, and the input gradients between member models become more dissimilar for both methods. These results suggest that there could be a connection between input gradient diversity and functional diversity in neural network ensembles.\n\n> Additional hyperparameters for the kernel would be another burden for this method.\n\nWe did acknowledge this difficulty in our manuscript, and proposed setting the lengthscales based on the PCA of the training data which makes the model more robust against natural corruptions. For the revised version of the manuscript, we also included Section D.4 in the Appendix which shows that by choosing a lengthscale setting which is a linear combination of the identity lengthscales and the PCA lengthscales, FoRDE can achieve good performance on both clean and corrupted data. This can serve as a guideline for choosing the lengthscales when applying FoRDE on new datasets.\n\n> It is recommended to include an ethics statement and a reproducibility statement right after the main paper.\n\nThank you for your recommendation. We have included the ethics statement and reproducibility statement at the end of the revised manuscript, noting that these sections do not count towards the page limit according to the ICLR author guidelines.\n\n[1] Z. Wang, T. Ren, J. Zhu, and B. Zhang, \u201cFunction Space Particle Optimization for Bayesian Neural Networks,\u201d in ICLR 2019.\n\n[2] F. D\u2019Angelo and V. Fortuin, \u201cRepulsive deep ensembles are Bayesian,\u201d In NeuRIPS, 2021.\n\n[3] S. Yashima, T. Suzuki, K. Ishikawa, I. Sato, and R. Kawakami, \u201cFeature Space Particle Inference for Neural Network Ensembles,\u201d in ICML 2022.\n\n[4] A. Rame and M. Cord, \u201cDICE: Diversity in Deep Ensembles via Conditional Redundancy Adversarial Estimation,\u201d in ICLR 2021.\n\n[5] T. Pang, K. Xu, C. Du, N. Chen, and J. Zhu, \u201cImproving adversarial robustness via promoting ensemble diversity,\u201d in ICLR 2019.\n\n[6] S. Depeweg, J.-M. Hernandez-Lobato, F. Doshi-Velez, and S. Udluft, \u201cDecomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning,\u201d in ICML 2018."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700055383518,
                "cdate": 1700055383518,
                "tmdate": 1700055383518,
                "mdate": 1700055383518,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "00YrtGJbJ0",
                "forum": "nLWiR5P3wr",
                "replyto": "m6h2T7NAL6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_aXJD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_aXJD"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "I appreciate the authors' comprehensive explanation. While I still have some queries regarding FoRDE's performance, I've adjusted my evaluation positively and now lean towards accepting it."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700267317998,
                "cdate": 1700267317998,
                "tmdate": 1700267317998,
                "mdate": 1700267317998,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QfcL7C3tIC",
            "forum": "nLWiR5P3wr",
            "replyto": "nLWiR5P3wr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2353/Reviewer_XVK8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2353/Reviewer_XVK8"
            ],
            "content": {
                "summary": {
                    "value": "This paper is concerned with adapting particle based variational inference for improved training of neural network ensembles.  The authors attempt to circumvent problems that have affected previous attempts to use particle based variational inference for ensembles, with a lack of effective repulsion in weight space (intended to promote functional diversity) chief among them.  This paper proposes instead to enforce diversity in the input gradients rather than in weight space, by using Wasserstein gradient descent along with an RBF kernel defined over the input gradients to guide the particles during training.  They compare against deep ensembles and other BNNs on accuracy, calibration, and robustness to covariate shift."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is very well written.  The potential advantages of moving to input gradient based diversity management are well introduced & well motivated, and the explanations are largely self-contained, which is no small feat considering page restrictions for conferences.\n- In particular, the main contribution section (section 3) is *so* well written.  It takes time to lead the reader from the wider view of Wasserstein gradient descent, to input space gradients, and the more narrow questions of choice of kernels, and their tradeoffs.  Of all the papers I reviewed, this was by far the most enjoyable and informative to read.  Bravo for taking the time to write so clearly."
                },
                "weaknesses": {
                    "value": "- One thing I often worry about is that the experiments are performed only in the vision domain, on over-hygenic datasets.  While I don't want to discount the amount of work needed to extend to other domains, projects like [WILDS](https://wilds.stanford.edu/) make this easier, and build confidence that demonstrated success isn't due to some quirk of CIFAR datasets.\n- One other complaint that to the authors' credit they highlight in section 3.5 is the cost of computing FoRDEs.  At a 3x computational premium to DEs, the penalty paid in compute seems to be the largest drawback of FoRDE with respect to DEs.  Do the authors have any ideas for reducing this burden? DEs themselves are expensive in both space and time to compute."
                },
                "questions": {
                    "value": "- Regarding the motivation of the RBF kernel in the \\textbf{Choosing the base kernel} paragraph of section 3.2, they are good arguments for using the RBF kernel, but are there others that were considered? As the authors suggest in section 3.3 and 3.4, choosing the length scales for RBF presents its own problem.  Could this be circumvented by employing a simpler base kernel? \n- Again in section 3.3, is the median heuristic required? I\u2019m a little unsure at the outset why this is the solution chosen over any others that would reduce the effect of the dominant eigenvalues."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2353/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698684653746,
            "cdate": 1698684653746,
            "tmdate": 1699636167485,
            "mdate": 1699636167485,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XAgpdMA4V4",
                "forum": "nLWiR5P3wr",
                "replyto": "QfcL7C3tIC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the positive review. \n\n> One thing I often worry about is that the experiments are performed only in the vision domain, on over-hygenic datasets. While I don't want to discount the amount of work needed to extend to other domains, projects like WILDS make this easier, and build confidence that demonstrated success isn't due to some quirk of CIFAR datasets.\n\nThank you for your suggestion. We were not aware of the WILDS project. We will certainly start using this project in our future works for more robust evaluations. Here, we followed previous works on Repulsive deep ensembles [1, 2] which focused mainly on benchmarking on vision datasets. We also provided experiment results on TinyImageNet, which is a bigger dataset with a higher number of classes (200 classes) compared to CIFAR.\n\n> One other complaint that to the authors' credit they highlight in section 3.5 is the cost of computing FoRDEs. At a 3x computational premium to DEs, the penalty paid in compute seems to be the largest drawback of FoRDE with respect to DEs. Do the authors have any ideas for reducing this burden? DEs themselves are expensive in both space and time to compute.\n\nWe are currently investigating methods to circumvent this computational drawback of FoRDE. One approach that we are studying is to replace the input-output Jacobian with the Jacobian-vector product. This approach can be implemented in Jax using the `jax.jvp` function, which efficiently calculates the Jacobian-vector product during the forward pass using the dual number approach [3]. In our preliminary experiments, we found that this new approach is almost as fast as plain DEs. We have added this discussion in Section 6 of the revised manuscript.\n\n> Regarding the motivation of the RBF kernel in the \\textbf{Choosing the base kernel} paragraph of section 3.2, they are good arguments for using the RBF kernel, but are there others that were considered? As the authors suggest in section 3.3 and 3.4, choosing the length scales for RBF presents its own problem. Could this be circumvented by employing a simpler base kernel?\n\nHere, we employed the RBF kernel following prior works on particle inference for neural networks [1, 2] and we did not consider other kernels for this task. While it is difficult to set the length scales for the RBF kernels, we also demonstrated that these length scales allow us to control the biases of the resulting ensemble, since we can improve the ensemble\u2019s robustness against natural corruptions using the PCA length scale setting. For alternative kernels, we can explore the family of kernels on the unit sphere introduced in [4] since we compare input gradients on a unit sphere, which is an interesting future research direction. Another solution is to study dimensionality reduction techniques for input gradients before calculating the kernel, which also reduces the number of length scales to be set. We have added this discussion in Section 6 of the revised manuscript.\n\n> Again in section 3.3, is the median heuristic required? I\u2019m a little unsure at the outset why this is the solution chosen over any others that would reduce the effect of the dominant eigenvalues.\n\nSince we calculate the kernelized repulsion term using the RBF kernel, we need to use the median heuristic so that the RBF kernel does not vanish during optimization. To understand this, we can look at Eq. (14) in the manuscript. If the eigenvalues are large, then the square distance inside the exponential function of the RBF kernel can reach a large value during optimization, and thus the RBF kernel will quickly converge to 0 and the repulsion term will also reach 0. Therefore, we divide the square distance inside the exponential with a scalar estimated via the median heuristic so that the repulsion term does not vanish during optimization. Prior works [5, 6] also employ the median heuristic to avoid this vanishing problem when using the RBF kernel in particle variational inference.\n\n[1] F. D\u2019Angelo and V. Fortuin, \u201cRepulsive deep ensembles are Bayesian,\u201d In NeuRIPS, 2021.\n\n[2] S. Yashima, T. Suzuki, K. Ishikawa, I. Sato, and R. Kawakami, \u201cFeature Space Particle Inference for Neural Network Ensembles,\u201d in ICML 2022.\n\n[3] J. Bradbury et al., \u201cJAX: composable transformations of Python+NumPy programs.\u201d 2018.\n\n[4] S. Jayasumana, R. Hartley, M. Salzmann, H. Li, and M. Harandi, \u201cOptimizing over radial kernels on compact manifolds,\u201d in CVPR 2014.\n\n[5] Q. Liu and D. Wang, \u201cStein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm,\u201d in NeuRIPS, 2016.\n\n[6] C. Liu, J. Zhuo, P. Cheng, R. Zhang, and J. Zhu, \u201cUnderstanding and Accelerating Particle-Based Variational Inference,\u201d in ICML, 2019."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700055094572,
                "cdate": 1700055094572,
                "tmdate": 1700055094572,
                "mdate": 1700055094572,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ryj9SX2xfa",
                "forum": "nLWiR5P3wr",
                "replyto": "XAgpdMA4V4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_XVK8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_XVK8"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "> Here, we employed the RBF kernel following prior works on particle inference for neural networks [1, 2] and we did not consider other kernels for this task. While it is difficult to set the length scales for the RBF kernels, we also demonstrated that these length scales allow us to control the biases of the resulting ensemble, since we can improve the ensemble\u2019s robustness against natural corruptions using the PCA length scale setting. For alternative kernels, we can explore the family of kernels on the unit sphere introduced in [4] since we compare input gradients on a unit sphere, which is an interesting future research direction. \n\nI'm glad to see the authors have already considered how to move from RBF kernels (whose suitability they have established in my mind) to other families with an established way of optimizing the parameters.  I look forward to seeing if they'll make a difference.\n\n> Another solution is to study dimensionality reduction techniques for input gradients before calculating the kernel, which also reduces the number of length scales to be set. We have added this discussion in Section 6 of the revised manuscript.\n\nI applaud this idea, but am somewhat skeptical that reducing the information in the input gradients by dimensionality reduction will lead to a benefit.  It's worth investigating though.\n\n> Since we calculate the kernelized repulsion term using the RBF kernel, we need to use the median heuristic so that the RBF kernel does not vanish during optimization. To understand this, we can look at Eq. (14) in the manuscript. If the eigenvalues are large, then the square distance inside the exponential function of the RBF kernel can reach a large value during optimization, and thus the RBF kernel will quickly converge to 0 and the repulsion term will also reach 0. Therefore, we divide the square distance inside the exponential with a scalar estimated via the median heuristic so that the repulsion term does not vanish during optimization. Prior works [5, 6] also employ the median heuristic to avoid this vanishing problem when using the RBF kernel in particle variational inference\n\nThanks for pointing out the necessity of the median heuristic.  So if I understand your explanation correctly, this is a necessary measure to guard against undesired behaviour in optimization, something akin to why (e.g) gradient clipping is employed?  That makes more sense now."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700065552187,
                "cdate": 1700065552187,
                "tmdate": 1700065552187,
                "mdate": 1700065552187,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HVMMI5Uc1E",
            "forum": "nLWiR5P3wr",
            "replyto": "nLWiR5P3wr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2353/Reviewer_eVm5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2353/Reviewer_eVm5"
            ],
            "content": {
                "summary": {
                    "value": "This paper points out that while the repulsion in the existing weight-space or function-space repulsive deep ensembles has been theoretically well-motivated, it does not lead to a practical performance improvement compared to vanilla deep ensembles. Rather than relying on repulsion in weight or function space, the authors employ a kernel comparing input gradients of particles and propose First-order Repulsive Deep Ensembles (FoRDE). Experimental results clearly indicate that FoRDE outperforms baseline methods, particularly when dealing with corrupted data."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. I have experienced that although repulsive deep ensembles are theoretically well-grounded, they do not result in performance enhancements in practice. In this regard, this paper is well-motivated, as it states, \"Neither weight nor function space repulsion has led to significant improvements over vanilla DEs.\"\n2. The paper provides a comprehensive overview of the literature concerning repulsive deep ensembles. Also, the proposed approach is meticulously detailed in a step-by-step manner, as well as its practical considerations.\n3. The connection to the EmpCov prior (Izmailov et al., 2021) further clarifies why the proposed FoRDE-PCA algorithm performs well for data under common corruptions.\n\n---\nIzmailov et al., 2021,  Dangers of Bayesian model averaging under covariate shift."
                },
                "weaknesses": {
                    "value": "Despite the critique that neither weight nor function space repulsion yielded significant improvements compared to vanilla DEs, the FoRDE algorithm introduced in this context still did not result in a substantial performance enhancement over vanilla DEs. In particular, FoRDE-Identity demonstrates a performance similar to that of vanilla DE, while FoRDE-PCA excels in performance under corruption but significantly diminishes its in-distribution performance.\n\nThe authors seem to have recognized this aspect; \"Hence, we believe that the optimal lengthscales for good performance on both clean and corrupted data lie somewhere between unit lengthscales (the identity) and using the inverse square root eigenvalues as lengthscales.\" For this paper to be considered complete, it should not just acknowledge such ideal lengthscales but also offer experimental evidence of their practical identification."
                },
                "questions": {
                    "value": "1. The paper mentions the reasons for the ineffectiveness of weight-space repulsion: (1) \"Typically repulsion is done in the weight space to capture different regions in the weight posterior. However, due to the over-parameterization of neural networks, weight-space repulsion suffers from redundancy.\" (2) \"Weight-space repulsion is ineffective due to difficulties in comparing extremely high-dimensional weight vectors and the existence of weight symmetries (Fort et al., 2019; Entezari et al., 2022).\" Could you provide a more detailed explanation of this?\n\n2. The paper outlines the advantages of ensemble methods in four specific areas: (1) predictive performance, (2) uncertainty estimation, (3) robustness to adversarial attacks, and (4) corruptions. In the experimental results, it delves into (1) using ACC, (2) using NLL and ECE, and (4) using cA, cNLL, and cECE. Did you carry out any experiments regarding (3) by any chance? Considering that the current experimental results are somewhat lacking in (1) and (2), it might be worthwhile to focus more on (3) and (4).\n\n3. FoRDE-PCA exhibits robust performance in addressing common corruptions (although it shows a minor decrease in its in-distribution performance). Hence, I would like to suggest providing more detailed experimental results concerning common corruptions, e.g., if it operates similarly to EmpCov (Izmailov et al., 2021), it is worth exploring whether the most beneficial corruption type aligns as well.\n\n---\nFort et al., 2019, Deep ensembles: A loss landscape perspective.  \nEntezari et al., 2022, The role of permutation invariance in linear mode connectivity of neural networks.  \nIzmailov et al., 2021,  Dangers of Bayesian model averaging under covariate shift."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2353/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2353/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2353/Reviewer_eVm5"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2353/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839037001,
            "cdate": 1698839037001,
            "tmdate": 1700327763688,
            "mdate": 1700327763688,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tPUMQjwpkM",
                "forum": "nLWiR5P3wr",
                "replyto": "HVMMI5Uc1E",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for the reviews. We have made changes to our manuscript based on your suggestions and uploaded the new version to the system. Below we address the specific concerns.\n\n>  For this paper to be considered complete, it should not just acknowledge such ideal lengthscales but also offer experimental evidence of their practical identification.\n\nWe have included in Section D.4 in the Appendix of the revised manuscript anecdotal evidence that the ideal lengthscale setting lies somewhere between the identity lengthscales and the PCA lengthscales for the ResNet18 / CIFAR-100 experiments. Particularly, we train FoRDE under the lengthscale settings $\\alpha * \\mathrm{pca\\\\_lengthscales} + (1-\\alpha) * \\mathrm{identity\\\\_lengthscale}$, where we increase $\\alpha$ from $0$ to $1$, and visualize the accuracy on both clean and corrupted data as a function of $\\alpha$ in Fig. 11 in the Appendix.\nFig. 11 shows that as $\\alpha$ increases, FoRDE becomes more robust against corruptions, while exhibiting small degradation in performance on clean data. With $\\alpha \\in [0.1, 0.4]$, FoRDE achieves higher accuracy than DE on both clean and corrupted data, with $\\alpha=0.4$ produces the best result.\n\n> The paper mentions the reasons for the ineffectiveness of weight-space repulsion: (1) \"Typically repulsion is done in the weight space to capture different regions in the weight posterior. However, due to the over-parameterization of neural networks, weight-space repulsion suffers from **redundancy**.\" (2) \"Weight-space repulsion is ineffective due to difficulties in comparing extremely high-dimensional weight vectors and the existence of **weight symmetries** (Fort et al., 2019; Entezari et al., 2022).\" Could you provide a more detailed explanation of this?\n\nPerformance of an ensemble partly relies on the functional diversity of its members. The purpose of weight-space repulsion in ensemble learning is to find weight particles that are different from each other in the hope that they represent different functions in the function space. However, the weight posterior of a neural network contains weight symmetries, meaning that two different weight vectors can represent the same function [1]. If we average the predictions from these two weight vectors, it would be equivalent to using the prediction from one of those weight vectors, and we refer to this problem as **redundancy**. Additionally, modern neural networks contains large amounts of parameters (more than tens of millions of parameters) arranged into hierarchical structures with various components (such as non-linear activations, convolution, normalization and pooling layers), making the geometry of the weight posterior highly complex [2]. This complexity makes it difficult to define a meaningful kernel to measure the similarity between two weight vectors, which is needed to calculate the kernelized repulsion term. Previous works [3, 4] used the RBF kernel for weight-space repulsion and observed no improvement in performance compared to plain Deep ensembles.\n\n\n[1] C. M. Bishop, Pattern recognition and machine learning. Chapter 5.1. 2006\n\n[2] R. Entezari, H. Sedghi, O. Saukh, and B. Neyshabur, \u201cThe Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks,\u201d in ICLR, 2022.\n\n[3] F. D\u2019Angelo and V. Fortuin, \u201cRepulsive deep ensembles are Bayesian,\u201d In NeuRIPS, 2021.\n\n[4] S. Yashima, T. Suzuki, K. Ishikawa, I. Sato, and R. Kawakami, \u201cFeature Space Particle Inference for Neural Network Ensembles,\u201d in ICML 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700054493195,
                "cdate": 1700054493195,
                "tmdate": 1700054493195,
                "mdate": 1700054493195,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QYBvihGKqO",
                "forum": "nLWiR5P3wr",
                "replyto": "BiXq5ORgtv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_eVm5"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_eVm5"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "I appreciate the authors' efforts in addressing my concerns. I anticipate the revised paper will comprehensively address the mentioned issues in the main text (e.g., it would be nice to see FoRDE with tuned alpha values in the main tables). I am increasing the score since the additional results have resolved my primary concerns.\n\nMoreover, I would like to make some remarks on the transfer learning experiments outlined in Section 5.4, employing a 3-hidden layer MLP after the fixed pre-trained feature extractor. Considering the relatively small size of this model, it would be feasible to conduct posterior sampling using the gold standard sampling method, Hamiltonian Monte Carlo (HMC). Introducing an HMC baseline, in my opinion, would offer readers additional valuable insights."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700327752518,
                "cdate": 1700327752518,
                "tmdate": 1700327752518,
                "mdate": 1700327752518,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oCEMJWyNqy",
            "forum": "nLWiR5P3wr",
            "replyto": "nLWiR5P3wr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2353/Reviewer_VQHQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2353/Reviewer_VQHQ"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel method for ensembling deep models that ensures diversity of the ensemble members. The paper continues the line of work in particle-based variational inference transforming the repulsion step of this approach into an input gradient space. This is different from the existing works that have done this step in weight and function spaces."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "* A novel method for an important problem of ensembling\n* Thorough empirical evaluation and comparison to the existing methods\n* Drawing connections with the existing methods\n* The paper is mostly well written and easy to follow\n* Runtime analysis presented"
                },
                "weaknesses": {
                    "value": "* Some presentation unclearness (see details below)\n* Some transformations between theory in Section 3 and steps in Algorithm (in Appendix) are not obvious\n\n\n1. What corruption is considered? CIFAR-10/100-C datasets have several types of corruptions each of which has several level of severity of corruptions. No confidence intervals (+-) for corruption results. \n2. Section 3.1 doesn't address that the target distribution \\pi is not available, or am I missing something? \n3. It would help to clear some confusion of how Algorithm comes in place if steps in Algorithm would be linked to equations in Section 3. \n4. Section 3.4. \"However, in practice we found no performance degradation nor convergence issues in our experiments\" - though the convergence issues can easily be observed, in order to see no performance degradation one would need to compare the performance with and without mini-batches. This experiment is not presented in the paper (including Appendix). \n5. Though the code is provided, some implementation details in text are missing. For example, ECE computation details such as a number of bins. Or details of OOD experiments: what portion of OOD data (CIFAR-100 for CIFAR-100 and vice versa) was used. \n6. No reference for CINIC10 dataset"
                },
                "questions": {
                    "value": "What exact corruption has been used in reported corruption experiments?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2353/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698972820134,
            "cdate": 1698972820134,
            "tmdate": 1699636167307,
            "mdate": 1699636167307,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kOKrCmqwUH",
                "forum": "nLWiR5P3wr",
                "replyto": "oCEMJWyNqy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the suggestions which helped us further improve the manuscript, and we have uploaded the new version to the system. Below we address the specific concerns.\n\n> What corruption is considered? CIFAR-10/100-C datasets have several types of corruptions each of which has several level of severity of corruptions. No confidence intervals (+-) for corruption results.\n\nWe used all the available types of corruptions and all 5 levels of severity in CIFAR-10/100 and TinyImageNet datasets for evaluation. We have added these details in Section C.2 and C.3 in the Appendix of the updated manuscript. We also added figures containing the corruption results with confidence intervals for each level of severity in Section D.2 in the updated manuscript.\n\n> Section 3.1 doesn't address that the target distribution \\pi is not available, or am I missing something?\n\nYou are correct. We have clarified that the target distribution $\\pi$ is intractable (and hence approximated with the particle distribution in Eq. 6)  in Section 3.1 of the revised manuscript.\n\n> It would help to clear some confusion of how Algorithm comes in place if steps in Algorithm would be linked to equations in Section 3.\nWe have added clarifications in Section C.1 in the Appendix of the revised manuscript.\n> Section 3.4. \"However, in practice we found no performance degradation nor convergence issues in our experiments\" - though the convergence issues can easily be observed, in order to see no performance degradation one would need to compare the performance with and without mini-batches. This experiment is not presented in the paper (including Appendix).\n\nWe wholeheartedly agree with this assessment. We however cannot perform the full-batch experiments due to resource limitations, since performing forward-backward passes on the entire 50000 training samples of CIFAR requires a large amount of GPU memory. One could compromise by varying the minibatch size, however it has been observed that large-batch training produces models with lower generalization performance than small-batch training [1], meaning that we would likely observe lower performance on large batch sizes compared to small batch sizes due to this phenomenon. Therefore, we have changed this statement to \u201cHowever, in practice we found no convergence issues in our experiments'' in Section 3.4 of the revised manuscript.\n\n> Though the code is provided, some implementation details in text are missing. For example, ECE computation details such as a number of bins. Or details of OOD experiments: what portion of OOD data (CIFAR-100 for CIFAR-100 and vice versa) was used.\n\nFor all experiments, we used 15 bins to calculate ECE. For the OOD experiments, we calculated the epistemic uncertainty on the test sets of CIFAR-10/100 and CINIC10. We have added these details in Section C.2 and C.3 in the Appendix of the updated manuscript.\n\n> No reference for CINIC10 dataset.\n\nWe have added the reference in our updated manuscript.\n\n[1] N. S. Keskar, D. Mudigere, J. Nocedal, M. Smelyanskiy, and P. T. P. Tang, \u201cOn Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima,\u201d in ICLR 2017."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700053955893,
                "cdate": 1700053955893,
                "tmdate": 1700053955893,
                "mdate": 1700053955893,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CtU01dxp4o",
                "forum": "nLWiR5P3wr",
                "replyto": "kOKrCmqwUH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_VQHQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_VQHQ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you so much for addressing all my comments/questions. \n\nCould you please elaborate about corruptions more please? How do you compute 1 number for each of the metrics (cA, cNLL, cECE) based on all corruptions and all severity types? Do you just consider all corruptions and all severity types as one big dataset? \n\nThank you again, I enjoyed your paper (as it seems other reviewers as well), hopefully it will be accepted."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700320487135,
                "cdate": 1700320487135,
                "tmdate": 1700320487135,
                "mdate": 1700320487135,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ep6QzsiaNR",
                "forum": "nLWiR5P3wr",
                "replyto": "pjR3NJMZfT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_VQHQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Reviewer_VQHQ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you so much for clarification. It is just different from, e.g., Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon, J., Lakshminarayanan, B. and Snoek, J., 2019. Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift. Advances in neural information processing systems, 32., that is why I was confused. Could you please add this clarification to the manuscript?"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700473544950,
                "cdate": 1700473544950,
                "tmdate": 1700473544950,
                "mdate": 1700473544950,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "N4lOcYh8rH",
                "forum": "nLWiR5P3wr",
                "replyto": "oCEMJWyNqy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2353/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We have added clarification in the current version of the manuscript available on the system. Specifically, we added the following sentence in the first paragraph of Section 5.2 in the main text:\n\n> For evaluations on input perturbations, we use CIFAR-10/100-C and TINYIMAGENET-C provided by Hendrycks & Gimpel (2017), which are datasets of corrupted test images containing 19 image corruption types across 5 levels of severity, and we report the accuracy, NLL and ECE averaged over all corruption types and severity levels (denoted cA, cNLL and cECE in Tables 1\u20134)."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2353/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700476673765,
                "cdate": 1700476673765,
                "tmdate": 1700493596889,
                "mdate": 1700493596889,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]