[
    {
        "title": "Sparse Mask Representation for Human-Scene Interaction"
    },
    {
        "review": {
            "id": "pDfRQefCEN",
            "forum": "WXXuORQwbQ",
            "replyto": "WXXuORQwbQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1581/Reviewer_BCwn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1581/Reviewer_BCwn"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes the use of sparse tensors to represent human-scene interaction data. Given a dense tensor input the authors proposed to learn multiple sparse masks. Sparse tensors are created by multiplying the learned masks and the dense input tensor. The sparse masks have a pre-defined fixed sparsity. The authors reused existing dense architecture but converted its dense operations into sparse ones.\nThe paper shows two applications: contact prediction and scene generation"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The input dimensionality in human-scene interaction is rightfully large. Using sparse input for this task is novel and technically sound.\n- The paper is easy to read.\n- Human-scene interaction is an interesting and important problem."
                },
                "weaknesses": {
                    "value": "- The novelty is limited to sparsifying the input for the human-scene interaction. Using sparse inputs by itself is not new, but it has not been studied for this task before.\n- In Figure 6 and Table 4. It seems the model gets worse when using 50 or 10 masks which is strange.Why would using 3 masks be better than 10 or 50 masks? Why would it be even better than using the full dense tensor?\n- The paper attributes the COO representation to \"Choy 2020\". The COO format is much older than that. \n- Figure 4 is hard to see. Human bodies are too small."
                },
                "questions": {
                    "value": "- The method is basically learning mesh subsampling. I wonder about how the method compares to classic subsampling methods.\n- Did the masking learn any interesting patterns? like which vertices are more relevant for which pose?\n- I understand that the method can be faster than POSA, but why would it be more accurate?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1581/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1581/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1581/Reviewer_BCwn"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1581/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697659961359,
            "cdate": 1697659961359,
            "tmdate": 1699636086907,
            "mdate": 1699636086907,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "euZdqvBIm7",
                "forum": "WXXuORQwbQ",
                "replyto": "pDfRQefCEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response for Reviewer BCwn (Part 1/2)"
                    },
                    "comment": {
                        "value": "**Q1: The novelty is limited to sparsifying the input for the human-scene interaction. Using sparse inputs by itself is not new, but it has not been studied for this task before.**\n\n> The use of sparse masks to enhance model speed has been investigated and established as a path within Sparse Coding solutions, as outlined in our Related Work. However, as you mentioned, its effectiveness on the human-scene interaction task has not been studied before. Unlike other methods that mostly apply the sparsity for improving inference speed, our method can increase both accuracy and speed. Despite the simplicity, our method outperforms recent work by a significant margin, for example, we outperform MIME [1] with 2.72% higher accuracy and 60 times faster. \n\n**Q2: In Figure 6 and Table 4. It seems the model gets worse when using 50 or 10 masks which is strange. Why would using 3 masks be better than 10 or 50 masks? Why would it be even better than using the full dense tensor?**\n\n>We value the feedback provided by the reviewer. The POSA backbone operates on dense tensor inputs. However, ***not all vertices contribute meaningfully*** to predicting human-scene contacts, leading to redundant information that can induce overfitting during the learning process. Sparse masks aim to mitigate this issue by increasing sparsity and selecting useful information. Nonetheless, an excessively large set of sparse masks can introduce a similar problem of redundant information, which adversely affects results when employing 50 or 10 masks.\n\n>Among these, the kept 3-mask setup refined by our introduced Sparse Mask Refinement technique yields the best results. This refinement process helps eliminate redundant sparse masks, enabling even better performance than the baseline which still suffers from redundant information issues. For further detailed insights, please refer to Section 4.4 'How do sparse masks help reduce input information?'\n\n**Q3: The paper attributes the COO representation to \"Choy 2020\". The COO format is much older than that.** \n\n>We appreciate the reviewer for pointing this out and concur that the original COO format has been appropriately cited. To the best of our knowledge, the initial representation of a sparse tensor using the COO format is documented by [2] (Chou et al., 2018), and subsequent extensions to operations on sparse tensors are detailed in [3] (Choy et al., 2020). Please do let us know if we missed any citations.\n\n**Q4: Figure 4 is hard to see. Human bodies are too small.**\n\n>We appreciate your feedback. We have enhanced the size of Figure 4.\n\n**Q5: The method is basically learning mesh subsampling. I wonder about how the method compares to classic subsampling methods.**\n\n>We appreciate the reviewer for mentioning the comparison with mesh subsampling methods. We agree that these methods also enhance the inference speed, with much of the mesh subsampling process occurring at runtime.\n    \n>The table below illustrates the comparison between our proposed SMR and other Mesh Subsampling methods, including typical algorithm-based methods and deep-based ones. Across all cases, our method significantly outperforms other approaches in terms of both speed and accuracy. This result is easily explainable, as most mesh subsampling methods do not adhere to any specific algorithms during the subsampling process to preserve model performance. Additionally, their primary objectives revolve around finding a better discrete representation of a mesh with triangles of equal edge length, rather than catering to human-scene interaction tasks. Besides, some deep-based mesh simplifier methods also take time to finish their sampling process.\n\n>|Methods|Mesh Subsampling|Reconstruction Accuracy(%)|Speed (s/sample)|\n|:-|:-:|:-:|:-:|\n|Baseline (POSA)|Algorithm-based|91.12|0.28|\n|Isotropic Remeshing [4]|Algorithm-based |82.18(-8.94)|0.18($\\downarrow$ 1.56)|\n|Vertex Clustering [5]|Algorithm-based | 78.67 (-12.45)|0.13($\\downarrow$ 2.15)|\n|Incremental Decimation [6]|Algorithm-based | 79.45 (-11.67) | 0.09 ($\\downarrow$ 3.11)|\n|Neural Mesh Simplification [7]|Deep-based|85.56(-5.56)|0.47($\\uparrow$ 1.68)|\n|CoMA [8]|Deep-based|89.22(-1.90) |0.23($\\downarrow$ 1.22)|\n|**Ours**|-|**93.69**(+2.57)|**0.01**($\\downarrow$ 28)|\n>\n>*Result comparison between SMR and other mesh subsampling methods. Results are benchmarked on the PROXD dataset.*"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1581/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700416685835,
                "cdate": 1700416685835,
                "tmdate": 1700416746851,
                "mdate": 1700416746851,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NX2BbAYXrz",
                "forum": "WXXuORQwbQ",
                "replyto": "pDfRQefCEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A friendly reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer **BCwn**,\n\nWe appreciate your time and feedback on our paper. We have responded to all the concerns you raised. Please let us know if you have any further questions.\n\nBest regards,\nAuthors."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1581/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581996867,
                "cdate": 1700581996867,
                "tmdate": 1700581996867,
                "mdate": 1700581996867,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8uSmj6JFrT",
            "forum": "WXXuORQwbQ",
            "replyto": "WXXuORQwbQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1581/Reviewer_gK1o"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1581/Reviewer_gK1o"
            ],
            "content": {
                "summary": {
                    "value": "Instead of focusing on optimizing the model architecture, the authors proposed a novel way to enhance the human-scene interaction research from the view of representation. \nIt is revealed that the input for human-scene interaction is usually of high dimension, which limits the inference speed and effectiveness of the models.\nSparse Mask Representation is thus proposed, exploring the sparsity of the inputs.\nRigorous experiments are conducted on tasks related to contact prediction and scene synthesis.\nResults show the effectiveness of the proposed sparse encoding."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors show that introducing sparse encoding is an effective technique for the improvement of Human-Scene Interaction tasks.\nImpressive inference acceleration and model compression are achieved with the proposed method.\nCompetitive results are shown compared to previous efforts."
                },
                "weaknesses": {
                    "value": "The current version appears to be an application of the Choy, 2020 citation. Clarification on the contribution beyond this should be provided.\n\nAs mentioned, the acceleration could be attributed to two factors. First, a sparse body mesh with 90% fewer vertices is used. Second, the sparse network works. Ablation should be conducted on the sparse mesh only and the sparse network only."
                },
                "questions": {
                    "value": "Please refer to the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1581/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1581/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1581/Reviewer_gK1o"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1581/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698575931631,
            "cdate": 1698575931631,
            "tmdate": 1699636086840,
            "mdate": 1699636086840,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NHclDNFrso",
                "forum": "WXXuORQwbQ",
                "replyto": "8uSmj6JFrT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response for Reviewer gK1o"
                    },
                    "comment": {
                        "value": "**Q1: The current version appears to be an application of the Choy, 2020 citation. Clarification on the contribution beyond this should be provided.**\n\n>- Our method is an input representation technique that centers on a learned set of sparse masks to generate zero-filtered data points.\n>- COO is a matrix reformatting technique used to restructure the inputs. The indexing characteristic of the COO enables us to safely eliminate the mentioned zero points while guaranteeing the incorporation of the remaining data into the network. \n>- Simply speaking, our method learns and ranks the sparse masks, while the COO ensures sparsity implementation. Our experiment shows that we need both the sparse masks and the COO to obtain the best results.\n\n **Q2: As mentioned, the acceleration could be attributed to two factors. First, a sparse body mesh with 90% fewer vertices is used. Second, the sparse network works. Ablation should be conducted on the sparse mesh only and the sparse network only.**\n\n>We appreciate the reviewer's question. The table below shows some results regarding the contribution of sparse masks and a sparse network. POSA serves as our baseline, and if setups involve masks, three masks are used. It is evident that when we use sparse masks without the COO format, the learning is not effective since there are too many zero points from the input without being removed, leading to no improvement in speed and, in fact, a decrease in accuracy. Applying a sparse network to original inputs improves speed, but the trade-off for accuracy is noticeable, as discussed in many previous papers. When we apply the COO format to the original inputs, the differences in speed and accuracy are not significant compared to the original baseline. If sparse masks and the COO format are both used without the sparse network, we must retain all zero points, even in the COO format, to match the input shape for the network. Consequently, no improvement in speed is observed, and the model's effectiveness is limited. With our introduced Sparse Mask Refinement that works on COO format, we can preserve the performance of the model but the speed improvement is not guaranteed. Ultimately, when we use COO inputs obtained from sparse masks and a sparse network together, with the stored indexes in COO format, the input shape problem can be addressed, achieving optimization in both speed and accuracy.\n\n\n>|Network|COO Format|Sparse Masks|Sparse Mask Refinement|Reconstruction Accuracy (%)|Inference Speed (s/sample)|\n|:-:|:-:|:-:|:-:|:-:|:-:|\n|Dense||||91.12|0.28|\n|Dense||x||85.72(-5.4)|0.28($\\downarrow$ 1.0)|\n|Sparse||||83.41(-7.71)|0.09($\\downarrow$ 3.11)|\n|Dense|x|||91.02(-0.1)|0.27($\\downarrow$ 1.04)|\n|Dense|x|x||85.46(-5.66)|0.28($\\downarrow$ 1.0)|\n|Dense|x|x|x|93.27(+2.15)| 0.28($\\downarrow$ 1.0)|\n|Sparse|x|x|x|**93.69**(+2.57)|**0.01**($\\downarrow$ 28)|\n>\n>*SMR Component Analysis. Results are benchmarked on the PROXD dataset. POSA is used as a backbone. The kept 3-mask setup is used when Sparse Masks are available.*"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1581/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700416498017,
                "cdate": 1700416498017,
                "tmdate": 1700416498017,
                "mdate": 1700416498017,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VuKGHAFzgr",
                "forum": "WXXuORQwbQ",
                "replyto": "8uSmj6JFrT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking foward to your feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer **gK1o**,\n\nMany thanks for your time and feedback on our paper. As the authors-reviewers discussion will end soon, please let us know if you have any further questions or comments.\n\nBest regards,"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1581/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700609613430,
                "cdate": 1700609613430,
                "tmdate": 1700609613430,
                "mdate": 1700609613430,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WFieMtEyUy",
                "forum": "WXXuORQwbQ",
                "replyto": "VuKGHAFzgr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1581/Reviewer_gK1o"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1581/Reviewer_gK1o"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your detailed responses. The added SMR Component Analysis is helpful in fully understanding the source of the improvements in accuracy and acceleration. However, I'm still not convinced that the contribution reaches the bar of acceptance with major concerns lying in novelty and contribution\n\n1. First, the major novelty lies in the sparse mask selection for HSI, which is incremental upon the Choy 2020 citation, instead of sparse mask representation, which has been covered in Choy 2020, making the title a little over-selling. \n\n2. Even though, it would have convinced me more if it could be formulated as a low-cost plug-in for existing methods. However, as discussed in Sec. 5, the compatibility and cost are limited. \n\n3. As for contribution, the improvement in accuracy is promising and inspiring for HSI, while acceleration appears to be a less crucial characteristic for HSI as I understand. I would expect more positive characteristics that sparsity could bring specifically to HSI understanding. A missing opportunity would be the sparse mask distribution with respect to the human body structure. Similar knowledge would be more helpful to the community than the new method.\n\nDue to the above concerns, I tend to keep my rating."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1581/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662262994,
                "cdate": 1700662262994,
                "tmdate": 1700662262994,
                "mdate": 1700662262994,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fic0uhiR8c",
            "forum": "WXXuORQwbQ",
            "replyto": "WXXuORQwbQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1581/Reviewer_t62A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1581/Reviewer_t62A"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel approach called Sparse Mask Representation (SMR) to effectively handle the complex and sparse input data in human-scene interaction. Unlike previous methods that focused on lightweight models or quantization, SMR uses sparse masks to select important information from the input, reducing computational cost. Experimental results demonstrate its superior performance in contact prediction and scene synthesis tasks, with significantly faster inference speed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is skillfully written, ensuring ease of comprehension for the reader. It introduces a seemingly straightforward yet remarkably effective solution to the complex issue of human contact prediction in 3D environments. The authors have undertaken a thorough set of experiments, clearly demonstrating the superior performance of their approach. Furthermore, they have meticulously examined the related work, providing a comprehensive comparison with existing literature across multiple datasets."
                },
                "weaknesses": {
                    "value": "I find the paper to be well-written, and the authors have conducted thorough experiments to demonstrate the effectiveness of their approach. The only potential area for improvement lies in providing more detailed explanations on how the sparse masks are defined, especially in the context of task dependency. This would further enhance the clarity and depth of the paper."
                },
                "questions": {
                    "value": "Are the sparse masks randomly generated, meaning do the 0 and 1 values occur at random locations? Or are the masks specifically tailored to the task at hand?\n\nHow does your approach handle fine-grained contacts, such as situations where the tips of the fingers come into contact with other objects?\n\nAdditionally, could you elaborate on how your approach addresses videos?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1581/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1581/Reviewer_t62A",
                        "ICLR.cc/2024/Conference/Submission1581/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1581/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698793054127,
            "cdate": 1698793054127,
            "tmdate": 1700995787974,
            "mdate": 1700995787974,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3ZIttij0Qr",
                "forum": "WXXuORQwbQ",
                "replyto": "fic0uhiR8c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response for Reviewer t62A"
                    },
                    "comment": {
                        "value": "**Q1: How the sparse masks are defined, especially in the context of task dependency?**\n\n>The sparse masks are randomly generated based on the input format used for human-scene contact prediction. Each mask is a tensor whose shape is similar to the shape of the input. In the contact prediction task, each input is represented by using a tensor with shape $N_v \\times N_S$, where $N_v$ is the number of vertices to represent the human mesh, and $N_S$ is the number of features (coordinate and contact label) of each vertex. \n\n**Q2: Are the sparse masks randomly generated, meaning do the 0 and 1 values occur at random locations? Or are the masks specifically tailored to the task at hand?**\n\n>Yes, sparse masks are randomly generated. During the learning process, the model relies on the mask score $\\alpha$ to identify the contribution of masks. Only masks that show a high enough contribution are kept.\n\n**Q3: How does your approach handle fine-grained contacts, such as situations where the tips of the fingers come into contact with other objects?**\n\n>The datasets used in our task (PROXD, GIMO, BEHAVE) do not consider fine-grained contacts. For instance, a part of the human body, such as a hand or foot, is assumed to make contact with at most one object. We believe our method will work effortlessly with fine-grained contacts, however, the current limitation in datasets does not allow us to verify the results of this case.\n\n**Q4: Could you elaborate on how your approach addresses videos?**\n\n>Our contribution is the sparse mask representation, and it works both with frames or video-based backbone. For example, to manage consecutive frames in the Scene Synthesis task, we simply employ the algorithm-based ContactFormer backbone. In a standard configuration, ContactFormer typically receives only one input from the contact predictor to compute contextual dependencies and the dynamic evolution of interactions. However, in our proposed SMR, ContactFormer can consider multiple contacts with associated weights. This capability enables it to establish more robust contextual dependencies, leading to improved reconstruction results. A recap of our approach and other methods in the mentioned task can be found in Section A.2 of our Appendix."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1581/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700416483731,
                "cdate": 1700416483731,
                "tmdate": 1700416483731,
                "mdate": 1700416483731,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hNoJ9XArEe",
            "forum": "WXXuORQwbQ",
            "replyto": "WXXuORQwbQ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1581/Reviewer_fpDr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1581/Reviewer_fpDr"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new representation for human-scene interaction task. The authors suggest to inject sparsity in the input space rather than designing lightweight model, model pruning or quantization which were used by previous methods. By enforcing input sparsity, the method is simple and effective in benefitting both the accuracy and inference time."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* Proposed approach is very simple but effective. The design choices made by the authors are intuitive and make sense. \n* The experiments and analysis are quite comprehensive and provides insights for the method. \n* Discussion is fairly done and includes a number of limitations and future directions. Overall it is a well written research paper."
                },
                "weaknesses": {
                    "value": "* Methodology is incremental and not much novelty by itself."
                },
                "questions": {
                    "value": "I can see that from Figure 6. it shows optimal performance for k = 3 mask with 90% sparsity, but there is no clear pattern or correlation between sparsity ratio vs accuracy. Could authors give an explanation on this trend?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1581/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698818244487,
            "cdate": 1698818244487,
            "tmdate": 1699636086700,
            "mdate": 1699636086700,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QMot5d7ppX",
                "forum": "WXXuORQwbQ",
                "replyto": "hNoJ9XArEe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respone for Reviewer fpDr"
                    },
                    "comment": {
                        "value": "**Q1: About the methodology contribution.**\n\nWe thank the reviewer for the comment, we verify our contribution as below:\n> - We propose a simple yet effective method that focuses on ***the representation of inputs used for human-scene interaction***. Our method reduces processing time while enhancing model effectiveness by eliminating redundant information. Existing works on human-scene interaction have not yet investigated this problem.\n> - We not only utilize sparse masks as in previous work but also propose a refinement strategy to create zero-filtered inputs.\n> - Despite simplicity, our method outperforms other state-of-the-art methods significantly. For example, our method outperforms MIME [1] with ***2.72% higher accuracy and 60 times faster***. \n\n\n**Q2: I can see that from Figure 6. it shows optimal performance for k = 3 mask with 90% sparsity, but there is no clear pattern or correlation between sparsity ratio vs accuracy. Could authors give an explanation on this trend?**\n\n> We appreciate the reviewer's feedback. In the original submission, we have shown the correlation between the sparsity ratio, number of masks, accuracy, and running time in Figure 6. That figure shows that using only one mask results in a significant drop in performance due to missing information. Increasing the number of masks helps retain essential information and enhances the overall model performance. However, an excessive number of sparse masks (50 masks) can introduce redundant and inconsistent information, potentially lowering the overall accuracy. By maintaining the sparse masks at appropriate values (which can be easily achieved using Sparse Mask Refinement), we can optimize performance while significantly speeding up the evaluation process.\n   \n    \n>As per your suggestion, we have further added a comprehensive discussion about the mentioned information in Section E.1 of our Appendix, providing a more comprehensive exploration. This includes an in-depth analysis of the correlation between the number of sparse masks and sparsity concerning accuracy. Additionally, another experiment examining inference speed is also conducted within this section."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1581/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700416462765,
                "cdate": 1700416462765,
                "tmdate": 1700416462765,
                "mdate": 1700416462765,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "p37jb8fhjN",
                "forum": "WXXuORQwbQ",
                "replyto": "hNoJ9XArEe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1581/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Please let us know if you have futher questions"
                    },
                    "comment": {
                        "value": "Dear Reviewer **fpDr**,\n\nPlease do let us know if you have any further questions before the authors-reviewers discussion period.\n\nBest regards,\nAuthors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1581/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588526764,
                "cdate": 1700588526764,
                "tmdate": 1700588526764,
                "mdate": 1700588526764,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]