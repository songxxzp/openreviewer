[
    {
        "title": "Deep Backtracking Counterfactuals for Causally Compliant Explanations"
    },
    {
        "review": {
            "id": "9z5hAiI9y6",
            "forum": "JshLcbPI9J",
            "replyto": "JshLcbPI9J",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_6DZ1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_6DZ1"
            ],
            "content": {
                "summary": {
                    "value": "This work focuses on *backtracking* counterfactuals as opposed to *interventional* counterfactuals that are most frequently considered. It formulates backtracking counterfactuals as constrained optimization using bijective deep structural causal models. Furthermore, it highlights connections to causally compliant counterfactual explanations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The writing is super clear. I want to thank the authors for such clarity.\nI also liked the connection made between backtracking counterfactuals and causally compliant counterfactual explanations."
                },
                "weaknesses": {
                    "value": "The authors make a very big assumption that they only gently brush in section 2.2: \n> We assume that all f_i are given as deep generative models.\n\nThis assumption is central, and key to feasibility of their formulation. However, structural causal equations are unknown, and often impossible to figure out solely based on data [1].\nMy question to authors regarding this: `How can we get access to structural causal equations underlying our data? How do we ensure identifiability of such equations given observed data?` I will reconsider my score if authors provide a convincing answer.\n\nSome thoughts regarding this matter: Although authors assume access to underlying generation mechanisms, my guess is that this assumption might not be necessary. identifiability of backtracking counterfactuals seems easier than identifiability of interventional counterfactuals, and we might not need access to generation mechanisms for them. This is just my intuition, and not rigorous.\n\n[1] [Counterfactual Non-identifiability of Learned Structural Causal Models](https://arxiv.org/abs/2301.09031)"
                },
                "questions": {
                    "value": "1. How is  *Deep Invertible Structural Causal Models* defined in section 2.2 or structural causal models with invertible reduced form mentioned in the last sentence of Appendix. D different from BGMs [2]? If they are similar, perhaps you can use some of their identifiability results?\n2. In the third line of section 2.3., It took me a while to understand the quoted question. I enclosing $x^*$ with parentheses will help the reader.\n3. Why does the title of section 3 contain the word `Deep`? I think your formulation as a constrained optimization is not limited to deep neural networks.\n4. In the first line of section 3, why do you use the word `example`? I thought counterfactual explanations explained in the former section are just an application of backtracking counterfactuals. If that is the case, I don't think you should use them when explaining your general formulation.\n5. I beleive F should be changed to $F^{-1}$ in the end of equation (4).\n6. What is $Y$ in the footnote of page 4? I don't think it's mentioned anywhere else in the text.\n7. How computationally expensive is calculating the Jacobian esp. for high-dimensional generation mechanisms such as those of images? Can you provide some numbers? I think this is important esp. for practitioners as you may need many Jacobian calculations for your method to converge.\n8. How many iterations does it take for Algorithm 1 to converge? Can you provide some ballparks?\n9. How did you choose $\\lambda=10^4$? How should we choose it for a new domain? What are the implications of large or small $\\lambda$s?\n\n\n[2] [Counterfactual Identifiability of Bijective Causal Models](https://arxiv.org/abs/2302.02228)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Reviewer_6DZ1"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7148/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697988537028,
            "cdate": 1697988537028,
            "tmdate": 1700605777556,
            "mdate": 1700605777556,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oIGpK5odPC",
                "forum": "JshLcbPI9J",
                "replyto": "9z5hAiI9y6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6DZ1"
                    },
                    "comment": {
                        "value": "We are delighted to hear that you appreciated the clarity and presentation of the paper and the connection made to the counterfactual explanations literature. We incorporated your valuable comments and suggestions in our revised version.\n\n> The authors make a very big assumption that they only gently brush in section 2.2: We assume that all $f_i$ are given as deep generative models. This assumption is central, and key to feasibility of their formulation. However, structural causal equations are unknown, and often impossible to figure out solely based on data [1]. My question to authors regarding this: How can we get access to structural causal equations underlying our data? How do we ensure identifiability of such equations given observed data? I will reconsider my score if authors provide a convincing answer.\n\nThank you for pointing this out! We agree that the structural equations are, in general, not identifiable from observational data---even without confounding and with a known causal graph, as assumed in our case. However, recent work [3] has shown that, under the additional assumption of univariate real-valued exogenous variables and diffeomorphic mechanisms $f_i$---both common assumptions in the context of deep generative modelling---the true structural equations can be identified up to an invertible component-wise transformation of the exogenous variables. We included this fact as a footnote into our paper in Section 2.2.\n\nWe hope that you find our answer convincing. Please let us know should this not be the case.\n\n[3] Adrian Javaloy, Pablo Sanchez-Mart\u0131n, and Isabel Valera. Causal normalizing flows: from theory to\npractice. Advances in Neural Information Processing Systems, 2023.\n\n> identifiability of backtracking counterfactuals seems easier than identifiability of interventional counterfactuals, and we might not need access to generation mechanisms for them.\n\nThis is an interesting thought. In our setting, we do know the causal graph and the structural equations are identifiable for univariate exogenous variables, as responded above. However, in settings where the causal graph is not known, identifiability does not hold in general [4]. We thank you for pointing this out, and we touch upon this point in the additional paragraph we included in the revised discussion section (Sec. 6).\n\n[4] Amir-Hossein Karimi, Julius Von K\u00fcgelgen, Bernhard Sch\u00f6lkopf, and Isabel Valera. Algorithmic recourse under imperfect causal knowledge: a probabilistic approach. Advances in Neural Information Processing Systems, 2020.\n\nBelow, we address your remaining questions (where appropriate, we incorporated your suggestions into the revised manuscript).\n\n1. Indeed, our models fit into the definition of BGMs and we included this fact into our revised manuscript for clarity. It could be the case that backtracking counterfactuals are identifiable for this class as well. We leave this question open for future work.\n\n2. Incorporated into the revised manuscript.\n\n3. We would like to stress that this is the formulation that we employ for our approach. It is true, however, that this formulation can also work for shallow methods. In order to stress that the considered formulation is a design choice and not inherent to backtracking in general, we would leave it as it is.\n\n4. Incorporated into the revised manuscript.\n\n5. You are correct. Thanks for catching this.\n\n6. Incorporated into the revised manuscript.\n\nIn response to your questions 7. - 8., we included an additional section in Appendix B.1 to elaborate more on these aspects and run additional numerical experiments."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700427710606,
                "cdate": 1700427710606,
                "tmdate": 1700427710606,
                "mdate": 1700427710606,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "elfnJlBTZD",
                "forum": "JshLcbPI9J",
                "replyto": "oIGpK5odPC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_6DZ1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_6DZ1"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Response"
                    },
                    "comment": {
                        "value": "Thanks for your detailed answers.\nRegarding the identifiability discussion, how do the assumptions in [3] apply to the tasks considered in this work which are mostly focused on images? For example, if my understanding is correct, assumptions in [3] imply that all variables are continuous which doesn't hold for age or gender."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588309983,
                "cdate": 1700588309983,
                "tmdate": 1700588309983,
                "mdate": 1700588309983,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KHl9Q7MNxh",
                "forum": "JshLcbPI9J",
                "replyto": "1Iblvsa7KH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_6DZ1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_6DZ1"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Response"
                    },
                    "comment": {
                        "value": "Thanks for your answer. I increased my score.\n\nI think it's helpful if you include a discussion about the implications of non-identifiability for your work; i.e., what happens if a practitioner uses this methodology in non-identifiable cases."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605754063,
                "cdate": 1700605754063,
                "tmdate": 1700605754063,
                "mdate": 1700605754063,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Q1hJhgceju",
            "forum": "JshLcbPI9J",
            "replyto": "JshLcbPI9J",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_8kK7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_8kK7"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the author proposed a scheme for computing backtracking counterfactuals in SCM."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-written and is easy to follow.\n\n2. The backtracking counterfactual is an interesting concept to explore."
                },
                "weaknesses": {
                    "value": "1. First of all, there should be a related work section in the main paper.  I checked the one in the appendix, and it is still not sufficient. If the contribution of this paper is to introduce a new computation scheme for backtracking counterfactuals, you should at least include how existing work computes it. Also, there is a lack of proper citation in the introduction when you compare your work to the existing methods. \n\n2. My main concern is how significant the proposed method is. It seems like the author optimizes it in the latent space rather than the feature space. Basically, all deep models are learning representations in the latent space, it looks like the proposed algorithm is just an implementation. \n\n3. In the experiment section, the author compares backtracking intervention and conventional intervention, it is more like an introductory article that introduces backtracking intervention."
                },
                "questions": {
                    "value": "See weakness, and also\n\nHow does deepBC perform against other algorithms that also conduct backtracking counterfactual reasoning?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Reviewer_8kK7"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7148/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698152995769,
            "cdate": 1698152995769,
            "tmdate": 1700661419906,
            "mdate": 1700661419906,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vvwFjXXxE6",
                "forum": "JshLcbPI9J",
                "replyto": "Q1hJhgceju",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8kK7"
                    },
                    "comment": {
                        "value": "We are happy to hear that you find our paper easy to follow and are interested in the backtracking concept. We incorporated your comments and suggestions in our revised version of the manuscript. \n\nWe would like to address your points:\n\n> First of all, there should be a related work section in the main paper. I checked the one in the appendix, and it is still not sufficient. If the contribution of this paper is to introduce a new computation scheme for backtracking counterfactuals, you should at least include how existing work computes it. Also, there is a lack of proper citation in the introduction when you compare your work to the existing methods.\n\nThank you for the suggestion. In response to your point, we decided to move other aspects of our method to the appendix in favor of a compressed related work section (Sec. 5) in the main article. We do keep a more comprehensive related work section in the appendix (App. E), which we also extended. We agree that a comprehensive review of the literature is crucial.\n\n> My main concern is how significant the proposed method is. It seems like the author optimizes it in the latent space rather than the feature space. Basically, all deep models are learning representations in the latent space, it looks like the proposed algorithm is just an implementation.\n\nWe believe that you missunderstood the main contribution of our work and are sorry that we did not formulate this more clearly. Our optimization is not just about the latent space of a deep model. The relevant aspect is that this latent space is **embedded into a causal model**, which makes the key difference to these many existing works that you have in mind. This causal model cannot be learned from data without any assumptions, which is why models without the causal models do not achieve the same amount of causal faithfulness as ours. We introduced three metrics in our revised manuscript, one of which measure causal compliance (see Sec. 4.2). Our model performs best here (see Tab. 1), especially in comparison to models **without a causal model**. Please let us know if this is still not clear.\n\n> In the experiment section, the author compares backtracking intervention and conventional intervention, it is more like an introductory article that introduces backtracking intervention.\n\nWe agree that this section is also meant to introduce these concepts to readers who are not familiar with causality. To the best of our knowledge, *backtracking interventions* do not exist. However, the experiments also demonstrate several other properties. For example, we show that counterfactuals can be identical for interventional counterfactuals and backtracking counterfactuals, in some settings. In our revised manuscript, the Morpho-MNIST furthermore serves to show the weighting feature of DeepBC (see Sec. 3.3 and App. D.1 in the revised version).\n\nWe would furthermore like to address your question:\n\n> How does deepBC perform against other algorithms that also conduct backtracking counterfactual reasoning?\n\nWe are not aware of any other method that implements backtracking counterfactuals. As mentioned above, DeepBC is not simply about optimizing in an arbitrary learned latent space. The **causal model** is the essential part. In our revised manuscript, we compare our method to a method without a causal model and quantitatively show that it does not achieve the same degree of causal faithfulness as DeepBC. In our revised manuscript, we introduced three metrics to compare our method against others and found that our method outperforms others in the metric relevant for backtracking (see Tab. 1)."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700424645140,
                "cdate": 1700424645140,
                "tmdate": 1700424645140,
                "mdate": 1700424645140,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "n1Pbw20hOm",
                "forum": "JshLcbPI9J",
                "replyto": "vvwFjXXxE6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_8kK7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_8kK7"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarification and much of my questions have been resolved. Thus I'll increase my score."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661401785,
                "cdate": 1700661401785,
                "tmdate": 1700661401785,
                "mdate": 1700661401785,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BDJzGMThXc",
            "forum": "JshLcbPI9J",
            "replyto": "JshLcbPI9J",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_5aYw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_5aYw"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new method to compute the backtracking counterfactuals in structural causal models with deep generative components. The problem is transformed into a tractable optimization in the structured latent space. Through experiments on the data sets MINST and CelebA, the paper also demonstrates that the proposed method has good properties such as being versatile and modular."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "A good addition to the existing literature."
                },
                "weaknesses": {
                    "value": "1. The importance of the problem under consideration is not well-articulated.\n2. The performance evaluations lack a quantitative measure to demonstrate the validity of the method. In other words, how do we know if the generated counterfactuals are good or bad?"
                },
                "questions": {
                    "value": "1. Why is it important to generate backtracking counterfactuals?\n\n2. Can the authors provide an important application of their proposed method and demonstrate that the proposed deep backtracking counterfactuals approach provide great solutions for this application?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Reviewer_5aYw"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7148/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698562711505,
            "cdate": 1698562711505,
            "tmdate": 1699636846473,
            "mdate": 1699636846473,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l4ORFmyomq",
                "forum": "JshLcbPI9J",
                "replyto": "BDJzGMThXc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5aYw"
                    },
                    "comment": {
                        "value": "We are delighted to hear that you consider our work a good addition to the existing literature. We would like to incorporate your valuable comments and suggestions for our revised version. We hope that we will be able to convince you to re-assess the current score.\n\n> The importance of the problem under consideration is not well-articulated.\n\nThank you for your feedback. Due to the preservation of causal mechanisms, backtracking counterfactuals allow for gaining faithful insights into the structural relationships of the data generating process, which render them a promising opportunity in practical domains such as medical imaging [1], biology [2], and robotics [3]. We incorporated additional text in the introduction (Sec. 1) as a response to your comment.\n\n> The performance evaluations lack a quantitative measure to demonstrate the validity of the method. In other words, how do we know if the generated counterfactuals are good or bad?\n\nThis is a relevant point. The short answer is that a general score does not exist. Whether a counterfactual is good or bad highly depends on the application at hand. If we wish to gain faithful insights into **how different variables interact with each other** through the construction of counterfactuals, backtracking presents a favorable alternative over other approaches such as interventional counterfactuals or methods that do not employ a causal model. This is because backtracking is guaranteed to always preserve all causal relationships between variables. To highlight this better, we revised the visualization in the CelebA section (Section 4.2, Fig. 5). \n\nFurthermore, we included a metric to quantitatively assess this property (among two other metrics) and show that our method outperforms the others (Tab. 1).\n\n> Can the authors provide an important application of their proposed method and demonstrate that the proposed deep backtracking counterfactuals approach provide great solutions for this application?\n\nOur method has great potential for applications such as medical imaging, biology and robotics, where domain experts can use our approach to develop and verify insights into their data. For instance, our method could be applied to understand how variables such as age, sex and brain volume interact with a brain MRI image. Rather than creating counterfactuals by breaking links between variables, our method can change the value of brain volume and faithfully take into account how the upstream variable sex changes (which in turn has other downstream effects that are respected) as to preserve the causal mechanism as good as possible. We agree that a real-world application of our method, e.g. in medical imaging, is a very interesting and relevant direction for future work, but beyond the scope of the current work. In our manuscript we use CelebA and Morpho-MNIST as our benchmarks, which makes our work accessible to a broad audience that does not require a biological/medicine background. Our benchmarks are therefore intuitive and interpretable by a broad audience and illustrate the beneficial properties of backtracking counterfactuals.\n\nWe would be happy to hear from you whether you are convinced by our reply and the changes to the manuscript. We are happy to make further adjustments.\n\n[1] Cathie Sudlow, John Gallacher, Naomi Allen, Valerie Beral, Paul Burton, John Danesh, Paul\nDowney, Paul Elliott, Jane Green, Martin Landray, et al. Uk biobank: An open access resource for\nidentifying the causes of a wide range of complex diseases of middle and old age. PLoS medicine,\n12(3):e1001779, 2015.\n\n[2] Karren Dai Yang, Anastasiya Belyaeva, Saradha Venkatachalapathy, Karthik Damodaran, Abigail\nKatcoff, Adityanarayanan Radhakrishnan, G. V. Shivashankar, and Caroline Uhler. Multi-domain\ntranslation between single-cell imaging and sequencing data using autoencoders. Nature Communications, 12(1):31, 2021.\n\n[3] Ossama Ahmed, Frederik Tr\u00e4uble, Anirudh Goyal, Alexander Neitz, Yoshua Bengio, Bernhard\nSch\u00f6lkopf, Manuel W\u00fcthrich, and Stefan Bauer. Causalworld: A robotic manipulation benchmark for causal structure and transfer learning. International Conference on Learning Representations, 2021."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700423332105,
                "cdate": 1700423332105,
                "tmdate": 1700423332105,
                "mdate": 1700423332105,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DG4ZnkKNtq",
                "forum": "JshLcbPI9J",
                "replyto": "l4ORFmyomq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_5aYw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_5aYw"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks the authors for the detailed response. As the authors commented in the response \"Whether a counterfactual is good or bad highly depends on the application at hand\", I wonder, given a specific application problem at hand, how could one judge whether we should adopt the method?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700556105944,
                "cdate": 1700556105944,
                "tmdate": 1700556105944,
                "mdate": 1700556105944,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KuzTkqJNUp",
                "forum": "JshLcbPI9J",
                "replyto": "xnlC2LGhdz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_5aYw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_5aYw"
                ],
                "content": {
                    "comment": {
                        "value": "But how do we know the counterfactuals created by your method could reliably \"retain the causal relationships between all variables\"?"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722135013,
                "cdate": 1700722135013,
                "tmdate": 1700722135013,
                "mdate": 1700722135013,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0Q6Fdz3N7X",
            "forum": "JshLcbPI9J",
            "replyto": "JshLcbPI9J",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_xQRn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_xQRn"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a particular instantiation of backtracking counterfactuals introduced by von Kugelgen et al. by formalising the counterfactual generation as a tractable constrained optimisation problem in the latent space of a causal model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method draws interesting connections between counterfactuals in explainability literature and causal literature and shows how backtracking counterfactuals can be seen as a generalised form of other.\n- The paper is very well written easy to follow the framework introduced \n- Nice illustrative examples on the Morpho-MNIST dataset"
                },
                "weaknesses": {
                    "value": "- The proposed approach solves an optimisation problem for every counterfactual query, very similar to [1, 2]. Unlike referred papers, the authors here aim to generate faithful counterfactuals respecting the given causal graph; it is unclear how the faithfulness of generated counterfactuals is maintained. (based on results, in the case of celebA it seems like the causal graph is not respected).\n- Is identity preservation enforced in the inference optimisation iteration? (as observed in celebA dataset, changing baldness is also affecting gender, facial hair, and age)\n- The main difference between the counterfactual explanations and deepBC is that explainability approaches do not use the auxiliary causal variables to generate counterfactual images (at least to the best of my knowledge, I haven't seen any papers using them); using deepBC for generating explanations will severally limit the applicability on datasets with meta information on auxiliary variables and the data generating graph. \n- From an explainability point of view, the metrics like faithfulness, reliability, and robustness of the generated counterfactuals would be interesting to discuss, celebA results suggest that these metrics would be affected \n- It would be useful to have auxiliary models evaluating the identity preservation and faithfulness of the generated counterfactuals and have a comparison against interventional counterfactuals.\n\n\n[1] Olah, C., Satyanarayan, A., Johnson, I., Carter, S., Schubert, L., Ye, K. and Mordvintsev, A., 2018. The building blocks of interpretability.\u00a0_Distill_,\u00a0_3_(3), p.e10.\n\n[2] Bau, D., Liu, S., Wang, T., Zhu, J.Y. and Torralba, A., 2020. Rewriting a deep generative model. In\u00a0_Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part I 16_\u00a0(pp. 351-369). Springer International Publishing."
                },
                "questions": {
                    "value": "Please refer to weakness section"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7148/Reviewer_xQRn"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7148/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698771121881,
            "cdate": 1698771121881,
            "tmdate": 1699636846351,
            "mdate": 1699636846351,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jYKzeX0Z1M",
                "forum": "JshLcbPI9J",
                "replyto": "0Q6Fdz3N7X",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xQRn"
                    },
                    "comment": {
                        "value": "We are happy to hear that you appreciate the connection we draw between our method and other methods in the counterfactual explanation literature. We considered your comments and suggestions for our revised version and hope that we will be able to convince you of the relevance of our work.\n\n> The proposed approach solves an optimisation problem for every counterfactual query, very similar to [1, 2]. Unlike referred papers, the authors here aim to generate faithful counterfactuals respecting the given causal graph; it is unclear how the faithfulness of generated counterfactuals is maintained. (based on results, in the case of celebA it seems like the causal graph is not respected).\n\nWe regret that the experiments on CelebA do not convey the preservation of the causal laws. In response, we updated Section 4.2 (CelebA experiments). Specifically, the new visualization (Fig. 5) highlights how exactly causal relationships are violated/preserved for the different approaches. In addition, we introduced and evaluated three metrics to compare the methods quantitatively. Our methods performs best on the metric relevant for backtracking counterfactuals. We would be happy to hear from you whether it is clearer now.\n\n> Is identity preservation enforced in the inference optimisation iteration? (as observed in celebA dataset, changing baldness is also affecting gender, facial hair, and age)\n\nIdentity preservation is encouraged through the distance function $d(u_i, u_i^*)$. In response to your point, we introduced and assessed the metric \"obs\" that assesses how much the observed attributes change for the different approaches. Interestingly, our method actually does allow for adjusting the level of preserving the different attributes manually. We did not touch upon this in the current version, but implemented this features in the revised version (see Sec. 3.3 and App. D.1). We hope you will find this an interesting new aspect of our approach.\n\n> The main difference between the counterfactual explanations and deepBC is that explainability approaches do not use the auxiliary causal variables to generate counterfactual images (at least to the best of my knowledge, I haven't seen any papers using them); using deepBC for generating explanations will severally limit the applicability on datasets with meta information on auxiliary variables and the data generating graph.\n\nThis is a relevant point that we do not touch upon enough in the current version. There exists a highly active area of research known as *causal representation learning* that is concerned with extracting this meta data from the observed data set. Many conditions for the identifiability of these variables (and causal relationship) have already been established in recent years and we hope that further developments in this field will broaden the applicability of our methods further. To address this point, we decided to include an additional paragraph into our discussion section (Sec. 6).\n\n> From an explainability point of view, the metrics like faithfulness, reliability, and robustness of the generated counterfactuals would be interesting to discuss, celebA results suggest that these metrics would be affected. It would be useful to have auxiliary models evaluating the identity preservation and faithfulness of the generated counterfactuals and have a comparison against interventional counterfactuals.\n\nWe agree that we did not discuss the properties of our methods enough in the original manuscript. In response to your comment, we decided to introduce three metrics that measure 1) observable attribute preservation (as mentioned above) and 2) faithfulness with respect to the causal mechanisms and 3) plausibility of the generated counterfactuals. These are the metrics that we are most concerned about in this work and indeed, our approach performs best on 2) (see Tab. 1 in our revised manuscript)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700422764568,
                "cdate": 1700422764568,
                "tmdate": 1700422764568,
                "mdate": 1700422764568,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qMZtLIzrpc",
                "forum": "JshLcbPI9J",
                "replyto": "0Q6Fdz3N7X",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_xQRn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Reviewer_xQRn"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your thoughtful rebuttal.\n\nThanks for highlighting the violated relations; I feel discussing these relations are violated would be really helpful.\nI'm unsure how the introduced metrics will play a role in downstream explanation tasks. Thus, I'll be maintaining my score."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722885906,
                "cdate": 1700722885906,
                "tmdate": 1700722979702,
                "mdate": 1700722979702,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vkbzfjpVGv",
            "forum": "JshLcbPI9J",
            "replyto": "JshLcbPI9J",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_GJzV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7148/Reviewer_GJzV"
            ],
            "content": {
                "summary": {
                    "value": "The paper implements backtracking counterfactuals [1] in the framework of deep SCMs [2] and points to connections with counterfactual explanations for deep learning models. The paper performs experiments similar to the MorphoMNIST experiments in [2] as well as showing the differences of interventional and backtracking counterfactuals on CelebA.\n\n[1] Von K\u00fcgelgen, Julius, Abdirisak Mohamed, and Sander Beckers. \"Backtracking counterfactuals.\" Conference on Causal Learning and Reasoning. PMLR, 2023.\n[2 ]Pawlowski, Nick, Daniel Coelho de Castro, and Ben Glocker. \"Deep structural causal models for tractable counterfactual inference.\" Advances in Neural Information Processing Systems 33 (2020): 857-869."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well written and easy to follow. It combines the idea of backtracking counterfactuals with the deep SCM framework to tackle the problem of counterfactual estimation. The paper is sound and shows convincing results of the differences between interventional and backtracking counterfactuals in high-dimensional settings."
                },
                "weaknesses": {
                    "value": "The paper is a relatively simple combination of [1] and [2] and it is unclear how important the linearisation of the optimisation procedure is for the performance of the counterfactuals: How well would simple SGD perform? Is the optimisation over u* converging or simply stopped after 30 iterations?\nFrom my understanding, the DeepBC algorithm is limited to handle continuous variables and it is unclear how the choice of distance metric would influence the resulting counterfactuals in case of u's with different dimensionalities along the backtracking trace. Additional ablations comparing the different design choices would strengthen the paper.\nAdditionally, I would encourage the authors to consider adding quantitative evaluations such as proposed by [3].\n\nGenerally, it feels like this paper tries to introduce DeepBC as a combination of [1] and [2], while being a counterfactual explanation paper. I am not sure which of the two it really ends up being. Furthermore, the use of the DSCM framework could be highlighted more.\n\n[3] Monteiro, Miguel, et al. \"Measuring axiomatic soundness of counterfactual image models.\" The Eleventh International Conference on Learning Representations. 2022."
                },
                "questions": {
                    "value": "- I saw in the code that the autoencoders use a simple MSE loss without properly modelling the observational noise. Why is this choice made?\n- In eq 7 you use an L2 penalty for the distance in latent space. This is very restrictive and would only sensibly work for continuous noise variables.:\n  - What's the impact on that if the variables have different noise dimensions?\n  - How would this generalise to discrete variables?\n  - This does not use any scaling between the variables. In footnote 2, it is mentioned that this isn't necessary because they all assume the same base distribution. I believe this point should be elevated beyond a footnote as it might be lost to readers otherwise.\n- You mention that you approximate $F_s$ at $\\bar{u}$. Is this correct? What is $\\bar{u}$ in this case?\n- Why do you use the linearisation? Is this faster than SGD? Did you compare the two?\n- Why do we want to enforce sparse changes in $u$? Is this sparse in the dimensions of all u or sparse in the different variables?\n- You mention that interventional CF can generate samples in low-density regions and mention it as a weakness. Why is that? Isn't that actually one of the strengths in terms of disentanglement and generalisation?\n- You mention that you're using standardized logits for modelling. How do you compute them? What's the impact of using this over discrete variables?\n- You mention the composability / modularity as a strength of your work. However, this is generally possible within any causal generative framework, particularly the DSCM framework. What's special about this work in this regard?\n- You mention you're using \"an image regressor, together with an unconditional AE ...\". Can you elaborate how this baseline works?\n- You mention that DeepBC does not properly sample from the counterfactual distribution and it didn't yield satisfactory results. Why is that? What were the results?\n- As for CF explanations, how does this compare to explaining anti-causal predictions by using causal generative models (e.g. see [4]).\n\n[4] Zhang, Cheng, Kun Zhang, and Yingzhen Li. \"A causal view on robustness of neural networks.\" Advances in Neural Information Processing Systems 33 (2020): 289-301."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7148/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699349804691,
            "cdate": 1699349804691,
            "tmdate": 1699636846233,
            "mdate": 1699636846233,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KsHiRH77pO",
                "forum": "JshLcbPI9J",
                "replyto": "vkbzfjpVGv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer GJzV - Part I"
                    },
                    "comment": {
                        "value": "We are delighted to hear that you found our work to be well-written and easy to follow. Furthermore, we appreciate the effort you undertook in rigorously assessing our manuscript. We would like to consider your valuable comments and suggestions for our revised version and hope that we will be able to convince you of the relevance of our work.\n\n> The paper is a relatively simple combination of [1] and [2]\n\nThe main contribution of our work is to provide a practical and computationally efficient way of generating backtracking counterfactuals. It is important to note that the formulation presented in [2] cannot be readily implemented \u201cout-of-the box\u201d, since it requires computing the posterior $p(\\mathbf{u}^* | \\mathbf{u}, \\mathbf{x}^*_S)$ (see App. A.2), which involves several steps that are computationally intractable. Our approach computes the mode of the posterior $p(\\mathbf{u}^* | \\mathbf{u}, \\mathbf{x}^*_S)$, and shows that this can, in fact, be done by solving a constrained optimization problem that is tractable (under the assumption of (approximate) bijectivity of the generative models). Our research goes therefore well beyond the results of [2] due to its focus on numerical evaluation, computation, and practical evaluation on Morpho-MNIST and CelebA. \n\nOur approach indeed relies on incorporating deep neural networks into structural causal models, but only as a starting point (this is not the contribution of the paper). The work therefore builds on new advances, such as [1], which makes our work timely and relevant to the community.\n\n> it is unclear how important the linearisation of the optimisation procedure is for the performance of the counterfactuals: How well would simple SGD perform? Is the optimisation over u* converging or simply stopped after 30 iterations? From my understanding, the DeepBC algorithm is limited to handle continuous variables and it is unclear how the choice of distance metric would influence the resulting counterfactuals in case of u's with different dimensionalities along the backtracking trace. Additional ablations comparing the different design choices would strengthen the paper.\n\nThank you for this remark. We agree that we only swiftly touched upon this part in the old manuscript. We confirm that the optimization indeed converges after 30 iterations with respect to the penalty loss (equation (7)). Empirically, we observe that our method converges much quicker, compared to gradient-based optimization algorithms. Note that, strictly speaking, SGD is not applicable, because the optimization is not over a data set, but only a single example. To address your point, we included an additional section to our appendix (App. B.1) where we describe the choice of algorithm and parameters in detail. We also provide numerical experiments that contrast constraint linearization to the Adam optimizer. These experiments highlight the fact that the convergence of Adam is very sensitive to the step-size, whereas our method works out-of-the-box.\n\n> it is unclear how the choice of distance metric would influence the resulting counterfactuals in case of u's with different dimensionalities along the backtracking trace.\n\nWhile we agree that choosing the distance metric might be non-trivial in more complex examples such as multi-modal single cell data [4], we in fact, provide an intuitive interpretation of the distance metric as the log of the backtracking conditional density $p(\\mathbf{u}^*|\\mathbf{u})$ (see App. A2). As a result, the distance metric arises indirectly from the definition of the backtracking counterfactuals.\n\n[4] Karren Dai Yang, Anastasiya Belyaeva, Saradha Venkatachalapathy, Karthik Damodaran, Abigail\nKatcoff, Adityanarayanan Radhakrishnan, G. V. Shivashankar, and Caroline Uhler. Multi-domain\ntranslation between single-cell imaging and sequencing data using autoencoders. Nature Com-\nmunications, 12(1):31, 2021"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700420567795,
                "cdate": 1700420567795,
                "tmdate": 1700420567795,
                "mdate": 1700420567795,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "S273f61ze2",
                "forum": "JshLcbPI9J",
                "replyto": "vkbzfjpVGv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7148/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer GJzV - Part II"
                    },
                    "comment": {
                        "value": "> Additionally, I would encourage the authors to consider adding quantitative evaluations such as proposed by [3]\n\nWe agree that quantitative evaluations are of great interest to the reader. However, the work you mention is based on an axiomatic characterization of interventional counterfactuals (section 7.3.1 in [5]) and it is not obvious to us whether and how it can be applied/adapted to the backtracking philosophy, which is inherently different. Specifically, the reversibility axiom is not obvious to apply to backtracking, because backtracking does not employ functional re-assignmnents, which this axiom is based on (instead, all causal mechanisms are kept in place). In order to address your point, we introduced three metrics (Section 4.2) that measure how well the original example is preserved in terms of observable attributes (obs), plausibility, and causal compliance (causal). We indeed find that our method outperforms other approaches in the causal compliance metric, which is the relevant metric for backtracking counterfactuals (see Tab. 1).\n\n> Generally, it feels like this paper tries to introduce DeepBC as a combination of [1] and [2], while being a counterfactual explanation paper. I am not sure which of the two it really ends up being.\n\nThe main part of this point has already been addressed above. We note that the relation of our work to multiple other lines of work is actually a strength, since it is relevant for the causal community, by focusing a high-dimensional data (images) and computational tractability, and it is relevant to the high-dimensional explanations community by providing a solid theoretical foundation rooted in causality (see App. A2). These fields have thus far evolved separately (for the most part), and our work bridges the gap.\n\n> Furthermore, the use of the DSCM framework could be highlighted more.\n\nWe modified the first mentioning of deep learning for modelling structural equations to highlight this more. Thank you for the suggestion.\n\nWe would furthermore like to address your questions:\n\n>1. I saw in the code that the autoencoders use a simple MSE loss without properly modelling the observational noise. Why is this choice made?\n\nDuring training, there is no difference compared to the standard variational autoencoder [6] (the fixed observational noise leads to the MSE loss of the decoder.). For computing counterfactuals, we only keep the encoder and decoder of the trained models and do not consider observational noise. This is justified to some extent by [7], as written in the paper. Please let us know if we did not understand your question correctly.\n\n> In eq 7 you use an L2 penalty for the distance in latent space. This is very restrictive and would only sensibly work for continuous noise variables.: What's the impact on that if the variables have different noise dimensions? How would this generalise to discrete variables? This does not use any scaling between the variables. In footnote 2, it is mentioned that this isn't necessary because they all assume the same base distribution. I believe this point should be elevated beyond a footnote as it might be lost to readers otherwise.\n\nIn our method, we employ generative models only, which all operate on a standard Gaussian as base distribution. In response to your comment, we decided to include this into the main text (see Sec. 3.3). It is true that the method does not readily support discrete variables. We note, however, that discrete variables can often be replaced by logits , as we do in the experiments for CelebA (see Sec. 4.2.: Experimental Setup). In this case, our method can be applied. \n\nOur framework also allows for scaling the distances for variables differently. We find this an excellent point and therefore included this idea in the revised version of the manuscript (see equ. (8) and experiments in App. D1).\n\n[5] Judea Pearl. Causality. Cambridge University Press, 2009.\n\n[6] Diederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. International Conference on Learning Representations, 2014.\n\n[7] Patrik Reizinger, Luigi Gresele, Jack Brady, Julius von K\u00fcgelgen, Dominik Zietlow, Bernhard Sch\u00f6lkopf, Georg Martius, Wieland Brendel, and Michel Besserve. Embrace the Gap: VAEs\nPerform Independent Mechanism Analysis. Advances in Neural Information Processing Systems,\n35:12040\u201312057, 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7148/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700421556064,
                "cdate": 1700421556064,
                "tmdate": 1700646313744,
                "mdate": 1700646313744,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]