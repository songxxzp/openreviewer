[
    {
        "title": "FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler"
    },
    {
        "review": {
            "id": "D7gbYHNwr9",
            "forum": "msXxrttLOi",
            "replyto": "msXxrttLOi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1972/Reviewer_vABe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1972/Reviewer_vABe"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a semi-asynchronous federated learning framework named FedCompass, which adjusts the local training steps of each client according to their computing power and groups clients with similar training times in asynchronous federated learning. The proposed framework effectively alleviates the staleness issue in asynchronous federated learning while avoiding prolonged waiting time in synchronous federated learning."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "FedCompass is a semi-asynchronous federated learning framework that benefits from both asynchronous and synchronous federated learning while avoiding the drawbacks of these two frameworks. More specifically,\n\n1.\tFedCompass effectively addresses the staleness issue in asynchronous federated learning by grouping clients and thereby reducing the frequency of model aggregation on the server. By adaptively setting numbers of local epochs for each client, FedCompass ensures that the clients in each group can complete the training in a similar time, which avoids prolonged waiting time in synchronous federated learning.\n\n2.\tA theoretical analysis of the convergence of FedCompass is provided to support the effectiveness of FedCompass.\n\n3.\tExperimental results on four datasets with different statistical and systematic heterogeneity are conducted, and the results show that FedCompass outperforms previous asynchronous and synchronous methods."
                },
                "weaknesses": {
                    "value": "FedCompass seems to be an incremental improvement based on Tiered Federated Learning by complementing adaptive numbers of local epochs. The differences between FedCompass and Tired Federated Learning are not clear and not significant. Though the authors claim that Tired Federated Learning cannot deal with time-varying computing power, it is not a serious issue in cross-silo federated learning where the local devices usually have sufficient computing power for running multiple tasks at the same time. In addition, experiments do not provide any comparison between FedCompass and Tired Federated Learning. To highlight the contribution of this work, the authors need to give more elaborations and empirical evidence for the significance of FedCompass compared with Tired Federated Learning.\n\nIn addition, the explanation of Algorithm 1 in Section 3.2 is more difficult to follow than the explanation in Figure 1. The authors may need to improve the clarity of this part since it is the core of the proposed method."
                },
                "questions": {
                    "value": "See the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Reviewer_vABe",
                        "ICLR.cc/2024/Conference/Submission1972/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698267374224,
            "cdate": 1698267374224,
            "tmdate": 1700494438816,
            "mdate": 1700494438816,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iDPjFSTc2S",
                "forum": "msXxrttLOi",
                "replyto": "D7gbYHNwr9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vABe"
                    },
                    "comment": {
                        "value": "Dear Reviewer vABe,\n\nFirst and foremost, we would like to express our sincere gratitude for taking the time to review our paper and providing insightful comments. Our responses to your comments are as follows.\n\n**Comparison with Tiered FL algorithms**\n\nThe primary distinction between tiered FL algorithms and FedCompass lies in their targeted FL settings and client scale. Tiered FL algorithms are specifically designed for cross-device FL settings, where the client count can range from hundreds to thousands and even more. In contrast, FedCompass is designed for cross-silo FL scenarios and focuses on optimizing the use of dedicated computing resources at each silo, typically involving client numbers on the order of ten.\n\nThe FedAT algorithm aims to develop a communication-efficient asynchronous FL method  (Chat et al., 2021). It features synchronous updates within tiers and asynchronous updates among them. The method employs random client sampling within tiers and rough tier assignment broadly based on client response latency. However, such design choices are not well-suited for cross-silo FL, where all clients are expected to participate in each round of training. This fundamental difference in settings makes it difficult to directly compare FedCompass with tiered FL methods. Moreover, the granularity of tiers in tiered FL algorithms is generally coarse. In scenarios with a small number of clients, it's likely that only one tier is formed, effectively making the algorithm the same as the FedAvg algorithm (McMahan et al., 2017).\n\nIn terms of the resilience to client speed changes, we would like to first elaborate on what this means in the context of cross-silo FL. Unlike cross-device FL where a client experiences frequent changes due to the unreliability and intermittent computing of the devices, for cross-silo FL, each client usually has dedicated and reliable computing resources on HPC or cloud. It is possible that the clients have significant yet occasional speed changes due to some auto-scaling behaviors. FedCompass is designed to be responsive and resilient for those significant speed changes as showcased by the ablation study results in Appendix G.2. However, tier FL methods usually lack response to sudden speed changes and may experience performance degradation.\n\n**Unclarity in Section 3.2**\n\nThanks a lot for pointing this out and we agree that the previous presentation lacks clarity. Now we have rewrote the paragraph for describing the server side algorithm of FedCompass by focusing on the higher-level idea instead of the low-level details (last two paragraphs at the end of page 5). We believe that now it is a more clear presentation of the algorithm.\n\n**Summary of changes in the paper in response to Reviewer vABe**\n\n(1) Rewrite Section 3.2 for better presentation clarity, and have the descriptions focus more on higher-level design ideas.\n\n(2) Add few sentences at the first and last paragraphs of Appendix G.2 to further explain the resilience of FedCompass to client speed changes in practical cross-silo FL settings.\n\nChai, Z., Chen, Y., Anwar, A., Zhao, L., Cheng, Y., & Rangwala, H. (2021, November). FedAT: A high-performance and communication-efficient federated learning system with asynchronous tiers. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (pp. 1-16).\n\nMcMahan, B., Moore, E., Ramage, D., Hampson, S., & y Arcas, B. A. (2017, April). Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics (pp. 1273-1282). PMLR."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699940692936,
                "cdate": 1699940692936,
                "tmdate": 1699940692936,
                "mdate": 1699940692936,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zuWe867le9",
                "forum": "msXxrttLOi",
                "replyto": "iDPjFSTc2S",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_vABe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_vABe"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your reply. The clarity issue has been addressed in the revised version, but I am still not convinced by your claim that Tired FL is not comparable with FedCompass in cross-silo settings. You can replace the client sampling in Tired FL with full participation for the cross-silo setting, and you can also use more fine-grained tires in Tired FL such that you can have multiple tires in cross-silo settings. These are not technical difficulties of applying Tired FL in cross-silo settings. Meanwhile, an empirical comparison between FedCompass and Tired FL in your cross-silo settings can also provide support for your claim that Tired FL cannot deal with sudden speed changes. Accordingly, I will maintain my score at 6 unless more experimental comparisons between FedCompass and Tired FL are provided."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700336823947,
                "cdate": 1700336823947,
                "tmdate": 1700336823947,
                "mdate": 1700336823947,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FxRsQlUfKI",
                "forum": "msXxrttLOi",
                "replyto": "DSQLJD5Sk3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_vABe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_vABe"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response and the new experimental results. All of my concerns have been addressed in the current version and I would like to increase my score to 8."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700494420797,
                "cdate": 1700494420797,
                "tmdate": 1700494420797,
                "mdate": 1700494420797,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SXOQvrowRD",
            "forum": "msXxrttLOi",
            "replyto": "msXxrttLOi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF"
            ],
            "content": {
                "summary": {
                    "value": "- This work proposes a new semi-asynchronous FL for cross-silo FL. Specifically, FedCompass is designed to track the computing time of each client and adaptively adjust the local epoch, which enables the server to simultaneously receive local models from clients. The proposed method not only mitigates the straggler issue but also provides a great platform for global aggregation. The authors established a theoretical convergence bound and experimentally confirmed that the proposed method converges faster and higher than other baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The approach of adjusting local updates differently for each client to reduce the staleness gap between models is interesting.\n- Compared to existing asynchronous methods, the proposed method enables global aggregation, which is an important advantage since various existing aggregation-based methods (e.g., robust aggregation methods in FL) can be combined.\n- The proposed method is well supported by theoretical analysis."
                },
                "weaknesses": {
                    "value": "- The motivation is a bit unconvincing. The straggler issue is considered important primarily in cross-device FL since the organizations are expected to have sufficient computational/communication resources in cross-silo FL [arXiv\u201922].\n- Most experiments were conducted on datasets with a small number of classes. To confirm the scalability of the proposed method, could the authors conduct experiments on datasets with more classes like CIFAR-100?\n- The idea of adjusting local epochs for each client is straightforward and the technical novelty of the proposed method seems somewhat limited."
                },
                "questions": {
                    "value": "See Weaknesses and,\n\n- In Line 21-23 of Algorithm 1, it seems that each client\u2019s update is accumulated one-by-one into group specific buffer. How can existing aggregation strategies (e.g., [ICLR\u201921]) be performed in the global aggregation step of the proposed algorithm?\n- Could the authors conduct ablation study on Q_min/Q_max using CIFAR-10 dataset and compare the results with other baselines?\n- There are some typos in Appendix that should be corrected (e.g., in equation (6) of the proof for Lemma 2, the gradient symbol is missing)\n\n[arXiv\u201922] Chao et al., Cross-silo federated learning: Challenges and opportunities \n\n[ICLR\u201921] Reddi et al., Adaptive Federated Optimization"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF",
                        "ICLR.cc/2024/Conference/Submission1972/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698759953611,
            "cdate": 1698759953611,
            "tmdate": 1700651833952,
            "mdate": 1700651833952,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "I05sADoy4b",
                "forum": "msXxrttLOi",
                "replyto": "SXOQvrowRD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DhHF (Part 1 of 2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer DhHF,\n\nFirst and foremost, we would like to express our sincere gratitude for taking the time to review our paper and providing insightful questions and comments. Our responses to your comments and questions are as follows.\n\n**Unconvincing motivations**\n\nThe straggler issues in cross-device FL are mainly caused by the unreliability of the clients due to intermittent compute availability and connectivity. On the other hand, in cross-silo FL, though each client is assumed to have reliable and dedicated resources, the straggler issues come from the disparity/difference of the computing power among clients. In practical settings, there usually exists a substantial gap in computing capability between cross-silo FL clients.\n\nFirstly, the increasing adoption of specialized ASICs like those from Cerebras, SambaNova, and Graphcore, particularly by large institutions engaged in FL projects such as national laboratories, is noteworthy. At the other end of the spectrum, institutions like hospitals, also interested in utilizing federated learning, may only have access to standard consumer GPUs or solely CPU-based computing resources. This diversity in the types of accelerators and computing machines used by cross-silo FL clients inevitably leads to substantial disparities in computational capabilities.\n\nSecondly, disparities in computing power are also evident even among clients using the same type of accelerator, such as GPUs. For instance, HPC clusters built with different generations of GPUs and associated support hardware, like networking components, can exhibit significant differences in training capabilities. This is further elaborated in the following NVIDIA post (https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/).\n\nConsidering these disparities among cross-silo clients' computing resources, it becomes crucial to address resource utilization efficiently. The aim is to prevent resource wastage, which can occur by having faster clients idly wait for slower ones and underutilizing the available resources. A typical scenario in HPC clusters illustrates this: when a user requests a node with 8 GPUs through a job scheduler like Slurm, they are billed for a fixed number of compute hours, regardless of whether all 8 GPUs are fully utilized throughout the job duration.\n\n**Using CIFAR-100 as datasets**\n\nIn our experiments, we selected the MNIST and CIFAR-10 datasets to evaluate the performance of FedCompass. These two datasets are widely recognized and frequently utilized in FL research, as evidenced by Ma et al. (2022), who noted their prevalent use in the field. According to a survey presented in their study (Figure 9), MNIST is used in 32% of FL experiments, while CIFAR-10 is used in 28%. CIFAR-100, in contrast, is seldom chosen for such experiments. Beyond these traditional datasets, we also assessed FedCompass using two datasets from FLamby (Terrail et al., 2022), a recently introduced benchmark specifically designed for cross-silo FL. These datasets are significantly larger, at 444MB and 9GB, respectively. We believe this diverse range of datasets, both in terms of size and complexity, adequately demonstrates the versatility and efficacy of FedCompass in various scenarios.\n\n**Limited technical novelty**\n\nAt first glance, the concept of assigning varying local steps to clients based on clients' computing speeds might seem straightforward. However, in practice, this approach encounters several challenges and edge cases. For example, these include synchronizing clients when there is no prior knowledge of their computing speeds, addressing minor and significant fluctuations in client speeds, and handling scenarios where there is a substantial disparity in client computing power (e.g., exponential client computing speed distributions).\n\nFedCompass not only addresses these practical challenges effectively but also provides theoretical proof of convergence and demonstrates robust performance through an extensive series of experiments. Therefore, we believe that this paper possesses sufficient novelty, underscoring its contribution to advancing FL methodologies.\n\nMa, X., Zhu, J., Lin, Z., Chen, S., & Qin, Y. (2022). A state-of-the-art survey on solving non-IID data in Federated Learning. Future Generation Computer Systems, 135, 244-258.\n\nTerrail, J. O. D., Ayed, S. S., Cyffers, E., Grimberg, F., He, C., Loeb, R., ... & Andreux, M. (2022). Flamby: Datasets and benchmarks for cross-silo federated learning in realistic healthcare settings. arXiv preprint arXiv:2210.04620."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699938538270,
                "cdate": 1699938538270,
                "tmdate": 1699938538270,
                "mdate": 1699938538270,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1GeHbI8jVw",
                "forum": "msXxrttLOi",
                "replyto": "SXOQvrowRD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DhHF (Part 2 of 2)"
                    },
                    "comment": {
                        "value": "**Integrating other server optimization strategies**\n\nAlgorithm 1 only presents a simple demonstration of the FedCompass algorithm without combining it with other server-side optimization strategies. If the individual client update is needed to combine FedCompass with other strategies such as FedAdam, FedAdagrad, and FedYogi (Reddi et al., 2020), the server can simply buffer each client\u2019s update instead of adding them up. Therefore, it only requires some minor changes in the implementation.\n\n**Adding ablation study on CIFAR-10**\n\nSure! We have now added ablation study results for $Q_{\\min}/Q_{\\max}$ on the class partitioned CIFAR-10 datasets in Table 3 as well. The results are consistent with those on the MNIST dataset, namely, FedCompass can outperform FedBuff (Nguyen et al., 2022) with a large range of $Q_{\\min}/Q_{\\max}$ values.\n\n**Typos**\n\nThanks for the reminder! We have fixed it in the revised paper.\n\n**Summary of changes in the paper in response to Reviewer DhHF**\n\n(1) Cite the survey paper to further explain our choice of experiment datasets in the first paragraph of Section 5.1\n\n(2) Add results for ablation study on CIFAR-10 in Table 3.\n\n(3) Fix typos in equation 6.\n\nReddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K., Kone\u010dn\u00fd, J., ... & McMahan, H. B. (2020). Adaptive federated optimization. arXiv preprint arXiv:2003.00295.\n\nNguyen, J., Malik, K., Zhan, H., Yousefpour, A., Rabbat, M., Malek, M., & Huba, D. (2022, May). Federated learning with buffered asynchronous aggregation. In International Conference on Artificial Intelligence and Statistics (pp. 3581-3607). PMLR."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699939132421,
                "cdate": 1699939132421,
                "tmdate": 1699939132421,
                "mdate": 1699939132421,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1nA9cgQEtt",
                "forum": "msXxrttLOi",
                "replyto": "SXOQvrowRD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF"
                ],
                "content": {
                    "comment": {
                        "value": "I really appreciate the authors for their efforts to address the concerns and clarify the unclear aspects. But I have the remaining concerns below. \n\n1)  Unconvincing motivation: Now, I understood there might be a significant gap in computing time between cross-silo FL clients, even if they have sufficient computing resources. However, I think the gap is more meaningful in large models/datasets, and it is unlikely to be a critical issue in small models/datasets such as MNIST and CIFAR-10, which are the main experimental results of this paper.\n\n2) CIFAR-100 dataset: As the number of classes is large, more diverse heterogeneous scenarios can be simulated in FL. Therefore, I was just curious about the scalability of the proposed method with respect to the number of classes. Since this work addresses cross-silo FL where each client has sufficient computing power, I think this analysis would be valuable. I also found that the CIFAR-100 dataset has been adopted in many well-known studies such as FedDC, FedDyn, FedMD.\n\n3) Limited technical novelty: I admit this work tackles a practically important problem in cross-silo FL. However, I found that the authors mentioned the convergence analysis is not a core contribution (in the response to Reviewer UVPW). Considering this, the main contributions of this work seem not to lie in machine learning algorithms but rather in the simple assistance for implementation. Therefore, I am not sure if this is above the acceptance threshold bar of ICLR.\n\nTherefore, for now, I will keep my original score."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700374318712,
                "cdate": 1700374318712,
                "tmdate": 1700610875656,
                "mdate": 1700610875656,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "deQNrms7Jb",
                "forum": "msXxrttLOi",
                "replyto": "SXOQvrowRD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer DhHF"
                    },
                    "comment": {
                        "value": "Dear Reviewer DhHF,\n\nThanks for your reply and we would like to further clarify your concerns more specifically.\n\n**Unconvincing Motivation**\n\nWhile MNIST and CIFAR-10 are relatively small datasets, our experimental design is still challenging. We use two partition strategies, resulting in each client holding only a few classes. Further, this differs from cross-device FL scenarios where there are thousands of clients and each client may hold data of 3 to 4 classes. In cross-silo FL, there are only around 10 clients and each client only holds 3 to 4 classes, and this makes the problem much more challenging. As illustrated in the x-axis of Figures 12 to 17, experiments on the CIFAR-10 dataset usually take 1 (asynchronous algorithms) to 6 hours (asynchronous algorithms) to finish, indicating a significant saving of more than 5 GPU hours per client compared to synchronous methods like FedAvg. This translates to a total of **100 GPU hours** saved if there are 20 clients. Additionally, we incorporate two datasets (444MB and 9GB, both are larger than CIFAR100 - 161MB) from the FLamby cross-silo benchmark (Terrail et al., 2022) to further demonstrate FedCompass\u2019s effectiveness. Therefore, we believe that our experiment design is still well-aligned with our motivation.\n\n**CIFAR-100 Datasets**\n\nIn the experiment setting of this paper, each speedup/accuracy number is obtained from the average of 10 independent runs, taking 10 to 60 hours **per client** on CIFAR10 or CIFAR100 in total. Consequently, obtaining all accuracy/speedup numbers on CIFAR100 could exceed 10,000 GPU hours. Due to the limited time available for discussion, acquiring comprehensive CIFAR100 results is currently unfeasible, and we request your understanding in this matter.  Nonetheless, we still believe that our findings on the heterogeneous CIFAR10 dataset and the two FLamby datasets could highlight FedCompass\u2019s efficiency and accuracy advantages over synchronous and other asynchronous methods, especially given the fact that CIFAR10 and CIFAR100 actually have the same dataset size (~161 MB) and the used two FLamby datasets have even larger sizes. \n\n**Limited Technical Novelty**\n\nWe think there may exist some miscommunication or misunderstanding in terms of the theoretical contribution of this paper. Here is what we really want to express in terms of our convergence analysis part, and we also updated the responses the reviewer UVPW as well to further clarify things.\n\n(1) The main focus/contribution of our convergence analysis section is deriving the convergence behavior of our newly proposed semi-asynchronous algorithm FedCompass using the commonly-used assumptions and obtaining further insights, instead of trying to get rid of any commonly-used assumptions such as bounded staleness.\n\n(2) Though we are not the first ones to study the convergence behavior of the general asynchronous FL algorithms or FL algorithms with different client local steps, this paper actually first studies the convergence behavior of a semi-asynchronous FL algorithm with a scheduler assigning different numbers of local steps to clients, and we really believe this is still a good contribution to the FL community.\n\nWe apologize for any previous confusion and look forward to further discussions.\n\nTerrail, J. O. D., Ayed, S. S., Cyffers, E., Grimberg, F., He, C., Loeb, R., ... & Andreux, M. (2022). Flamby: Datasets and benchmarks for cross-silo federated learning in realistic healthcare settings. arXiv preprint arXiv:2210.04620."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700381834876,
                "cdate": 1700381834876,
                "tmdate": 1700464021573,
                "mdate": 1700464021573,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KiGoXghGWi",
                "forum": "msXxrttLOi",
                "replyto": "deQNrms7Jb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your additional responses to my questions. I have further comments as follows:\n\nIt is not clear that the current experimental setting (through gaussian assumption) regarding client heterogeneity could reflect practical scenarios. For example, if each client has sufficient resources (high quality CPU or GPU) above a certain level, it is unlikely that there will be a significant difference in computing time when performing small MNIST or CIFAR-10 tasks.\n\nMeanwhile, one additional question is, why does the proposed FedCompass converge faster than FedAvg in the homogeneous client setting where each client has the same computing time?"
                    }
                },
                "number": 30,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700617365175,
                "cdate": 1700617365175,
                "tmdate": 1700617365175,
                "mdate": 1700617365175,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pB7BEMyyxu",
                "forum": "msXxrttLOi",
                "replyto": "VLOCtw6tAQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_DhHF"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate your detailed responses to my further questions about \"unconvincing motivation\". Now, I feel this concern is well addressed, and therefore I have increased my score. However, since I still have concerns regarding the technical novelty in terms of machine learning literature, my confidence remains somewhat weak."
                    }
                },
                "number": 32,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651815574,
                "cdate": 1700651815574,
                "tmdate": 1700651815574,
                "mdate": 1700651815574,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "y37aJbvU5C",
            "forum": "msXxrttLOi",
            "replyto": "msXxrttLOi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1972/Reviewer_7w8f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1972/Reviewer_7w8f"
            ],
            "content": {
                "summary": {
                    "value": "This paper takes aim at tackling the combined problems of system and data heterogeneity in the context of cross-silo Federated Learning. The authors propose FedCompass a semi-asynchronous federated algorithm that assigns adaptively different amounts of training task to clients with different computational capabilities. Additionally, FedCompass ensures that received models are received in groups almost simultaneously reducing the staleness of local models while the overall process remains asynchronous eliminating long waiting periods for fast nodes. Theoretical results on the convergence of the proposed method are presented and experiments on both academic and real-world datasets support the theoretical findings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-The paper tackles an interesting problem in the literature of FL, namely the problem of system and data heterogeneity. Improving on prior works this paper attempts to circumvent the weaknesses observed in synchronous and asynchronous federated methods (which boil down to long delays due to stragglers and stale models respectively).\n\n-Theoretical results that prove the convergence of the proposed FedCompass are presented providing useful insights.\n\n-Substantial experimental evidence has been provided showcasing the superiority of the proposed method compared to established synchronous and asynchronous baselines."
                },
                "weaknesses": {
                    "value": "-The description of the algorithm in section 3.2 is unclear and further discussion is required. Specifically, the assignment of groups and the group aggregation are major components of the proposed method and they are not presented or discussed sufficiently in the main body of the paper (I strongly believe that including these components or at least an extensive discussion about them in the main body of the paper would significantly improve the presentation of this work). It is unclear how the implementation of these components alleviate the bias introduced by faster nodes performing more updates than slower nodes (a common issue met in previously proposed asynchronous methods). It is also unclear how the overall method  reaches an equilibrium (as discussed in section 3.1) and what properties it has. I would appreciate it if the authors could elaborate on the above. \n\n-In the description in section 3.2 it seems that when a client arrives later than $G[g].T_{max}$ it is immediately assigned a new training task whereas the clients that arrive earlier than $G[g].T_{max}$ are assigned training tasks when the next aggregation takes place. What is the justification for this differentiation? \n\n-Some of the assumptions required for the theoretical results are very restrictive. Specifically, the bounded gradient assumption rules out simple function such as the quadratic. Further, the bounded heterogeneity  and staleness assumption is rather strong and the derived results in Theorem 1 and Corollary 1 have a heavy dependence on  quantity $\\mu$. As a result the impact of those results is diminished.\n\n-The related work section could be extended with works on device heterogeneity (Reisizadeh et al., 2022; Horvath et al., 2022) and on asynchronous FL (So et al., 2021)\n\nReisizadeh, A., Tziotis, I., Hassani, H., Mokhtari, A., and Pedarsani, R. (2022). Straggler-resilient federated\nlearning: Leveraging the interplay between statistical accuracy and system heterogeneity. \n\nHorv\u00e1th, S., Sanjabi, M., Xiao, L., Richt\u00e1rik, P., and Rabbat, M. (2022). Fedshuffle: Recipes for better use\nof local work in federated learning.\n\nSo, J., Ali, R. E., G\u00fcler, B., and Avestimehr, A. S. (2021). Secure aggregation for buffered asynchronous\nfederated learning."
                },
                "questions": {
                    "value": "See the weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Reviewer_7w8f"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699261288644,
            "cdate": 1699261288644,
            "tmdate": 1700710498627,
            "mdate": 1700710498627,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oZOj8dOAy2",
                "forum": "msXxrttLOi",
                "replyto": "y37aJbvU5C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7w8f (Part 1 of 2)"
                    },
                    "comment": {
                        "value": "Dear Reviewer 7w8f,\n\nFirst and foremost, we would like to express our sincere gratitude for taking the time to review our paper and providing insightful questions and comments. Our responses to your comments are as follows.\n\n**Unclear description in Section 3.2**\n\nFor Section 3.2, we now rewrote the paragraph for describing the server-side algorithm of FedCompass by focusing on the higher-level idea instead of the low-level details (last two paragraphs at the end of page 5). We believe that now it is a more clear presentation of the algorithm.\n\n**How FedCompass alleviates the bias towards faster clients**\n\nCompared with other asynchronous FL algorithms such as FedAsync (Xie et al., 2019) and FedBuff (Nguyen et al., 2022), FedCompass alleviates the bias towards faster clients by using group aggregation to reduce global aggregation frequency and avoids the frequent application of staleness factors. We would like to further elaborate this via a simple example:\n\nSuppose that client A is 4 times faster than client B. In FedAsync, if A and B perform the same number of local steps in each local training round, then client A will perform 4 times more local training rounds than client B. When client B\u2019s model arrives, the global model has already been updated four times using A\u2019s model, so B\u2019s local model will become very stale/outdated, and another penalty staleness factor (e.g., say 0.25) will be applied to B\u2019s model during the aggregation. In such a case, B not only performs fewer updates, but its model also experiences an additional penalty factor to further cause the global model to drift away from it. For FedBuff, although it has a buffer to reduce the global update frequency, it is very possible that the buffer contains several local models from the same fast clients and slower clients may also experience some staleness factor. However, for FedCompass, we are grouping the arrival of clients, so in this example, A will perform 4 times more local steps than B and they will arrive almost simultaneously at the server for a group aggregation. In this case, no staleness factor (i.e., that 0.25) is applied to B, so the drift towards A is mitigated compared to other methods.\n\nOf course, from the above description, it is clear that FedCompass only mitigates the drift caused by the stateless factor but does not eliminate it, as client A still performs 4 times more steps than B. The drift can be further mitigated by combining FedCompass with other strategies such as normalized averaging (Nova) proposed in FedNova (Wang et al., 2020). Nova basically normalizes the client\u2019s local gradient according to the number of local steps to mitigate objective bias towards faster clients. Now we also include the experiment results for this combination (FedCompss+N) in the last row of Tables 1 and 2 of the revised paper (which is also the response to another review\u2019s comments). However, it is noteworthy that there is still a tradeoff here: though Nova can mitigate the objective bias, it also diminishes the updates from the faster nodes and may sometimes even lead to slower convergence of the global model.\n\n**Questions about equilibrium**\n\nEquilibrium means that the number of existing groups and the group assignments do not change. Take the scenario in Figure 1 as an example. Initially, there are two groups {1,2,3} and {4,5}. At 12:00, when clients {1,2,3} finish local training together, the Compass scheduler assigns them to the group of clients 4 and 5 and now all clients are within the same group. Then, we can see that all the clients will continue the training following the same grouping (assuming no drastic changes in the computing speed of clients during training), and the number of local steps performed by each client is proportional to the computing speed of each client.\n\nXie, C., Koyejo, S., & Gupta, I. (2019). Asynchronous federated optimization. arXiv preprint arXiv:1903.03934.\n\nNguyen, J., Malik, K., Zhan, H., Yousefpour, A., Rabbat, M., Malek, M., & Huba, D. (2022, May). Federated learning with buffered asynchronous aggregation. In International Conference on Artificial Intelligence and Statistics (pp. 3581-3607). PMLR.\n\nWang, J., Liu, Q., Liang, H., Joshi, G., & Poor, H. V. (2020). Tackling the objective inconsistency problem in heterogeneous federated optimization. Advances in neural information processing systems, 33, 7611-7623."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699936070271,
                "cdate": 1699936070271,
                "tmdate": 1699936153478,
                "mdate": 1699936153478,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NCgKJGN2bY",
                "forum": "msXxrttLOi",
                "replyto": "y37aJbvU5C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7w8f (Part 2 of 2)"
                    },
                    "comment": {
                        "value": "**Different behaviors for clients arriving before and after $T_{\\max}$**\n\nAll clients within the same group are expected to arrive at almost the same time for a group aggregation. Therefore, if a client arrives earlier than the latest arrival time $T_{\\max}$, then the server will wait for other pending clients (or $T_{\\max}$, whichever is earlier) for a group aggregation. Then the clients can obtain new training tasks with the **most updated global model**. However, if a client arrives later than $T_{\\max}$, it means that all other clients within the same group have already finished the group aggregation after waiting until $T_{\\max}$. Therefore, there is no point in waiting and the server will immediately assign new training tasks to the client. We think the confusion is mainly caused by the unclarity in the original draft and we hope the revised version conveys the idea more clearly.\n\n**Restrictive assumptions for convergence analysis**\n\nThe first three assumptions are commonly used in convergence analysis of non-convex functions in federated learning and distributed learning literature (Stich, 2019; Li et al., 2019, Yu et al., 2019, Nguyen et al., 2022). In terms of the bounded heterogeneity and staleness assumption, it is valid and reasonable in cross-silo FL, as each client is considered to be reliable. We would also like to clarify that the main focus/contribution of our convergence analysis section is deriving the convergence behavior of our newly proposed semi-asynchronous algorithm FedCompass using the commonly-used assumptions and obtaining further insights (such as the impacts of different hyperparameters/setting on convergence), instead of trying to get rid of any commonly-used assumption such as bounded staleness. Additionally, this paper actually first studies convergence behavior of a semi-asynchronous FL algorithm with a scheduler, and we really believe this is still a good contribution to the FL community.\n\n**Citations to other related works**\n\nThanks a lot for providing those additional papers. We find them relevant and useful and have cited them in suitable places in the revised paper.\n\n**Summary of changes in the paper in response to Reviewer 7w8f**\n\n(1) Rewrite Section 3.2 for better presentation clarity, and have the descriptions focus more on higher-level design ideas.\n\n(2) Add one sentence at the end of Section 3.1 to explain the property of equilibrium - fixed number of existing groups and group assignments.\n\n(3) Cite additional papers at suitable places.\n\n\nStich, S. U. (2018). Local SGD converges fast and communicates little. arXiv preprint arXiv:1805.09767.\n\nLi, X., Huang, K., Yang, W., Wang, S., & Zhang, Z. (2019). On the convergence of fedavg on non-iid data. arXiv preprint arXiv:1907.02189.\n\nYu, H., Yang, S., & Zhu, S. (2019, July). Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 33, No. 01, pp. 5693-5700).\n\nNguyen, J., Malik, K., Zhan, H., Yousefpour, A., Rabbat, M., Malek, M., & Huba, D. (2022, May). Federated learning with buffered asynchronous aggregation. In International Conference on Artificial Intelligence and Statistics (pp. 3581-3607). PMLR."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699936693876,
                "cdate": 1699936693876,
                "tmdate": 1700382673448,
                "mdate": 1700382673448,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o1PEzdcYAp",
                "forum": "msXxrttLOi",
                "replyto": "NCgKJGN2bY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_7w8f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_7w8f"
                ],
                "content": {
                    "title": {
                        "value": "Post Rebuttal"
                    },
                    "comment": {
                        "value": "I would like to thank the reviewers for addressing my concerns. After reading carefully the updated version of their manuscript and the comments from the other reviewers I find that the revision of section 3.2 has significantly improved the presentation of their work and the additional experiments that have been included exhibit the strengths of the proposed method and increase the impact of this paper. As a result I have decided to increase my score to 6. Having said that I still believe that the theoretical contribution of this work is to some extent limited."
                    }
                },
                "number": 34,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700710466260,
                "cdate": 1700710466260,
                "tmdate": 1700710466260,
                "mdate": 1700710466260,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9ttqNAiggT",
            "forum": "msXxrttLOi",
            "replyto": "msXxrttLOi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1972/Reviewer_UVPW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1972/Reviewer_UVPW"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a way of tracking the computation speed of different clients in federated learning (FL), based on which a time threshold is determined to collect the clients' updates with possibly different numbers of local updates. Compared to fully asynchronous FL and some semi-asynchronous FL baselines, the experimental results show that the proposed FedCompass algorithm gives better performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This work tackles the important problem of system heterogeneity in FL, focusing on the cross-silo FL setup."
                },
                "weaknesses": {
                    "value": "- The adaptation of the number of local updates based on clients' computation speed is not new. An important and well-known baseline is FedNova (Wang et al., 2020), which has been cited in the paper but not compared against. Compared with the proposed FedCompass method, FedNova is much easier to implement and supports both cross-silo FL and cross-device FL with partial client participation. The advantage of FedCompass over FedNova is not clear.  \n\n- The proposed FedCompass approach is heuristic and a lot of its description is based on simplified examples. The paper argues that FedBuffer includes the buffer size $K$ as a hyper parameter that needs to be tuned. However, FedCompass also includes hyper parameters $Q_\\mathrm{min}$, $Q_\\mathrm{max}$, and parameters in sub-procedures, such as $\\lambda$ in Algorithm 2, that need to be tuned heuristically. It is worth noting that the experiments in this paper use FedBuffer with small values of $K$ up to 5 (as listed in Appendix E) while the original FedBuffer paper (Nguyen et al., 2022) uses $K=10$ in the majority of experiments. It is not clear how the authors selected $K$ in the experiments presented in this paper, but I would expect that FedBuffer with a properly tuned $K$ would give a similar performance as FedCompass with properly tuned hyper parameters.\n\n    Side note: The algorithm is called FedBuff in the original paper (Nguyen et al., 2022), not sure why the authors call it FedBuffer in this paper.\n\n- In practice, the clients' computation speeds can vary over time due to the varying amount of concurrent tasks running in the system. The paper has a mentioning of this but only studies the behavior of the algorithm in some oversimplified cases of computation speed variation. It is unclear whether the scheduling procedure in Section 3.1 is robust to all types of speed variation, or does there exist a worst case scenario where the scheduler completely loses track in its estimation of clients' computation speeds. This needs a separate theoretical analysis IMHO, which is different from the convergence bound. \n\n- The convergence result appears fairly straightforward, since results with bounded staleness and different numbers of local updates both exist in the literature. It is not quite clear what is the challenge and novelty in the convergence analysis."
                },
                "questions": {
                    "value": "Basically all the things mentioned under weaknesses. Some specific questions include:\n- How does FedCompass compare with FedNova?\n- How is $K$ chosen for FedBuffer in the experiments? Was any hyper parameter optimization or grid search implemented?\n- Is it possible to theoretically show the robustness of the scheduler when the clients' computation speeds can vary arbitrarily?\n- What is the challenge and novelty in the convergence analysis?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1972/Reviewer_UVPW"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1972/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699328979860,
            "cdate": 1699328979860,
            "tmdate": 1700284781327,
            "mdate": 1700284781327,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SxUxpjdsDB",
                "forum": "msXxrttLOi",
                "replyto": "9ttqNAiggT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UVPW (Part 1 of 3)"
                    },
                    "comment": {
                        "value": "Dear Reviewer UVPW,\n\nFirst and foremost, we would like to express our sincere gratitude for taking the time to review our paper and providing insightful questions and comments. Our responses to your questions are as follows.\n\n**Comparison between FedCompass and FedNova**\n\nThe main focus of FedNova (Wang et al., 2020) is how to eliminate objective inconsistencies when the number of local steps for clients is different (via adjusting weighting factors). In practice, FedNova is typically implemented in the following two **synchronous** manners:\n(1) Each client performs the same number of local epochs, thus different number of local steps due to different data sizes. In this case, the algorithm suffers a lot from client computing speed variations like the FedAvg algorithm. In the worst case, the slowest client may have the largest dataset, and the whole training process can be extremely slow.\n(2) Setting a universal completion time in each round and letting each client perform local updates until the completion time is reached. This approach eliminates the long waiting time and also has a simple implementation process, but it requires the universal completion time to be manually selected for different training tasks, model sizes, and average client computing capabilities.\n\nOn the other hand, FedCompass is designed to be an **asynchronous** federated learning algorithm, and focuses on how to employ a scheduler to have asynchronous clients arrive almost simultaneously. This is achieved by assigning different numbers of steps dynamically using real-time performance metrics. This design choice, while marginally complicating the implementation, significantly streamlines the experimental setup, as users only need to provide a range of desired local update steps in each round (which is more intuitive to users) and do not need to empirically estimate a suitable universal completion time. There is a tradeoff between ease of implementation and usage convenience.\n\nFurthermore, we would like to clarify that FedNova and FedCompass are not analogous but actually \u201corthogonal\u201d to each other. As FedCompass involves different client local steps in each round, it can be combined with FedNova\u2019s normalized averaging strategy as a manner to further mitigate the drifting to faster clients. To further emphasize the FedNova paper and explain the orthogonal relationship between FedCompass and FedNova, we now provide a new set of experiment results for their combination in the last rows of Tables 1 and 2 (FedCompass+N) of the revised paper (as well as all result tables and figures in the Appendix).\n\nWang, J., Liu, Q., Liang, H., Joshi, G., & Poor, H. V. (2020). Tackling the objective inconsistency problem in heterogeneous federated optimization. Advances in neural information processing systems, 33, 7611-7623."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699934238049,
                "cdate": 1699934238049,
                "tmdate": 1699934238049,
                "mdate": 1699934238049,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eBmSjwG8Gn",
                "forum": "msXxrttLOi",
                "replyto": "9ttqNAiggT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UVPW (Part 2 of 3)"
                    },
                    "comment": {
                        "value": "**Hyperparameter problems for FedBuff and FedCompass**\n\nFirst, thanks for the reminder to adopt FedBuff instead of FedBuffer for consistency with the original paper (Nguyen et al., 2022). We have changed all FedBuffer to FedBuff in the revised paper now.\n\nSecond, we would like to answer why we do not simply use $K=10$ as the original FedBuff paper does, especially given that their paper mentions that \u201cOur extensive empirical evaluation finds that $K=10$ is a good setting across benchmarks and does not require tuning\u201d. This is because all the experiments in FedBuff are in cross-device FL settings, and have **at least thousands of clients in all experiment settings** (CelebA dataset: 9343 clients, Sent140: 660120 clients, and CIFAR-10: 5000 clients). However, that statement does not hold for cross-silo cases, as we have less than or equal to 10 clients in most experiments. When the number of clients becomes small, the users have to decide the buffer size themselves instead of directly using $K=10$.\n\nThen, we would like to describe how we decide the value of $K$ for different numbers of clients. We use the *class partitioned* MNIST dataset with {5, 10, 20} clients and normal distribution as the client heterogeneity setting. For 5 clients, we search $K$ among values {2,3}, for 10 clients, we search $K$ among {2, 3, 5}, and for 20 clients, we search $K$ among {3, 5, 10}. We select $K$ with the highest average accuracy of three independent runs. According to the table below, we finally select $K=3/3/5$ for 5/10/20 clients. For Fed-IXI, we choose $K=2$ as there are only three clients. For Fed-ISIC2019 with 6 clients, we choose $K=3$ as we use this buffer size for both 5 and 10 clients. Additionally, we would like to mention that from the training process visualization figures (Figure 2 and more in Appendix F), we can clearly see that there is a non-marginal gap between the FedCompass curve and the FedBuff curve in many cases, especially for the relatively complicated datasets, CIFAR10 and Fed-ISIC2019.\n\n| Number of Clients | K=2     | K=3     | K=5     | K=10    |\n|-------------------|---------|---------|---------|---------|\n| 5 clients         | 94.13   | 94.77   |    -     |    -     |\n| 10 clients        | 93.88   | 94.60   | 94.54   |    -    |\n| 20 clients        |    -     | 97.65   | 98.21   | 98.16   |\n\nFinally, regarding the hyperparameter tuning, we would like to elaborate on the reason why we state that FedCompass requires easier tuning. For FedCompass, it has three algorithm-specific hyperparameters: $Q_{\\min}$, $Q_{\\max}$, and $\\lambda$, or equivalently, $Q_{\\max}$, $Q_{\\min}/Q_{\\max}$, and $\\lambda$. For FedBuff, it requires $Q$ and $K$. $Q_{\\max}$ in FedCompass and $Q$ in FedBuff are both used to define the amount of computational work we want each client to do in each round, so they cancel each other out. The ratio $Q_{\\min}/Q_{\\max}$ is irrelevant to the number of clients, and we empirically show in the ablation study that a large range of values can lead to faster convergence than FedBuff (we now also added new ablation study results on the CIFAR-10 datasets to address another reviewer\u2019s request, and the observation remains on the more difficult CIFAR-10 dataset). Similarly, for $\\lambda$, its impact on the convergence is also minor and a number slightly above 1 is fine. On the other hand, for $K$ in FedBuff, though their paper mentions $K=10$ is a good choice when the client numbers are large, there does not exist any rule of thumb for selecting $K$ when the number of clients is small in cross-silo settings, so we had to do some small preliminary experiments to choose $K$ for different numbers of clients. For FedCompass, we simply choose $Q_{\\min}/Q_{\\max}=0.2$ and $\\lambda=1.2$ for all experiments (which are not even optimal in some cases), and FedCompass still outperforms FedBuff all the time with a non-marginal gap.\n\nNguyen, J., Malik, K., Zhan, H., Yousefpour, A., Rabbat, M., Malek, M., & Huba, D. (2022, May). Federated learning with buffered asynchronous aggregation. In International Conference on Artificial Intelligence and Statistics (pp. 3581-3607). PMLR."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699935093675,
                "cdate": 1699935093675,
                "tmdate": 1699935118240,
                "mdate": 1699935118240,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BNhOhvWi58",
                "forum": "msXxrttLOi",
                "replyto": "9ttqNAiggT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UVPW (Part 3 of 3)"
                    },
                    "comment": {
                        "value": "**FedCompass\u2019s behavior with speed changes**\n\nDifferent from cross-device FL where each client may experience frequent speed changes due to power constraints, the operation of other concurrent applications, or network connectivity issues. In practice, a cross-silo FL client usually has dedicated computing resources such as HPC with a job scheduler or some cloud computing facilities\u2014where significant changes in computing speed are less frequent, generally arising from events like auto-scaling. Our experiment design in Appendix G.2 is an overestimate of the practical cases, where each client has a 10% probability in each round to resample a \u201cspeed\u201d from the client speed distribution (a simulation for auto-scaling behaviors), and we think that this setup could be a reasonable simulation for speed variations in practical cross-silo FL settings. Of course, in the worst-case scenario where all client speeds change dramatically all the time, then the scheduling algorithm of FedCompass will fail to synchronize the client arrival as desired, since the previous speed information becomes obsolete. In such a scenario, the training will go completely asynchronously and FedCompass will downgrade to the FedAsync algorithm (Xie et al., 2019). \n\n**Convergence analysis [updated]**\n\n(1) The main focus/contribution of our convergence analysis section is deriving the convergence behavior of our newly proposed semi-asynchronous algorithm FedCompass using the commonly-used assumptions and obtaining further insights (such as the impacts of different hyperparameters/settings on the convergence), instead of trying to get rid of any commonly-used assumptions such as bounded staleness.\n\n(2) Though we are not the first ones to study the convergence behavior of the general asynchronous FL algorithms or FL algorithms with different client local steps, this paper actually first studies convergence behavior of a semi-asynchronous FL algorithm with a scheduler, and we believe this is still a good contribution to the FL community.\n\n**Summary of changes in the paper in response to Reviewer UVPW**\n\n(1) Add experiment results for combining FedCompass and normalized averaging (Nova) to further clarify the \u201corthogonal\u201d relationship between FedCompass and FedNova in Tables 1 and 2.\n\n(2) Add a few sentences at the end of the first paragraph in Appendix E.2 to explain the choice of buffer size K and the reason why we do not simply choose $K=10$.\n\n(3) Add sentences at the end of Appendix G.2 to explain that our experiment design is aimed to mimic the occasional yet substantial changes in speed that may arise in real-world cross-silo federated learning environments as a result of auto-scaling. We also point out the limitations of FedCompass if all clients experience dramatic and very frequent speed changes.\n\n\n\nXie, C., Koyejo, S., & Gupta, I. (2019). Asynchronous federated optimization. arXiv preprint arXiv:1903.03934."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699935480654,
                "cdate": 1699935480654,
                "tmdate": 1700382215928,
                "mdate": 1700382215928,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6C916JvjGE",
                "forum": "msXxrttLOi",
                "replyto": "BNhOhvWi58",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_UVPW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_UVPW"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the additional explanation and experiments. I will update my score to 5.\n\nSome further concerns remain:\n- \"FedCompass is designed to be an asynchronous federated learning algorithm, and focuses on how to employ a scheduler to have asynchronous clients arrive almost simultaneously.\" This sentence is somewhat self-contradictory. When all the clients arrive simultaneously, it becomes a synchronous algorithm, although the specific parameter that is being synchronized here may be different from other synchronous algorithms. \n- Since the scheduling mechanism is essentially heuristic, I would expect it to be evaluated in more realistic settings. Currently, the system is simulated with parameters derived from some simple models. It is hard to tell whether the performance will be similar in real systems or not. There are other open questions, such as whether the algorithm will be robust to drastic changes in the system, which are also unclear from the current evaluation. \n- Algorithm 1 is quite complicated. It seems to be a carefully engineered approach probably designed by someone with strong hands-on experience. However, it is generally difficult for most people in the research community to understand the rationale and key insights behind such a design. Since the scheduling algorithm is not backed by theory, we do not know whether it is optimal or not, we do not even know what is the concrete objective that the scheduling algorithm is trying to optimize.\n\nSince most of my research papers have a theoretical emphasis, I feel it a bit difficult for me to evaluate a paper like this, so I will reduce my confidence to 3."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700284742368,
                "cdate": 1700284742368,
                "tmdate": 1700284742368,
                "mdate": 1700284742368,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4SRzsbEnsX",
                "forum": "msXxrttLOi",
                "replyto": "apjk6yFZ2d",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_UVPW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1972/Reviewer_UVPW"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for these additional answers. A few more comments are as follows:\n- Evaluation in realistic setting: I agree that simulations are helpful for controllable experiments, but it can be made more realistic by simulating the processing speed etc. using real-world data traces collected from data centers. Some public datasets of this kind exist, such as https://research.google/resources/datasets/google-cluster-workload-traces-2019/. As of now, it is not clear how well the random distributions match with real system behavior. The related works mentioned in the response have strong theoretical contributions, which this paper lacks. This is why I would emphasize on experiments especially for this paper.\n- Theoretical foundation: It should be possible to at least formulate an objective that the proposed algorithm tries to optimize, although it may not be possible to optimize the objective exactly, which is why the heuristic is needed. This would greatly improve the readability of the paper."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1972/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583311986,
                "cdate": 1700583311986,
                "tmdate": 1700583311986,
                "mdate": 1700583311986,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]