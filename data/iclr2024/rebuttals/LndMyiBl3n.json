[
    {
        "title": "SheAttack: A Silhouette Score Motivated Restricted Black-Box Attack on Graphs"
    },
    {
        "review": {
            "id": "rA6XBjndzp",
            "forum": "LndMyiBl3n",
            "replyto": "LndMyiBl3n",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission128/Reviewer_1uf8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission128/Reviewer_1uf8"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new method, SheAttack, for attacking Graph Neural Networks (GNNs) in the Restrict Black-box attack setting. This method aims to diminish the quality of graph data by manipulating node distinguishability. The approach utilizes a Modified Silhouette Score (MSS) to assess graph quality across various homophily levels. Experiments show that SheAttack performs effectively on both homophilic and heterophilic graphs and offers comparable results to more knowledge-intensive white-box attacks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "**Clarity**: The paper is well written and clear to understand.\n\n**Quality**: The assumptions made about real-world scenarios and RBA are well-considered.\n\n**Significance**: The problem addressed is significant due to the growing need to detect vulnerabilities in graph neural network models. The problem setting in this paper (RBA) seems more aligned with real-world scenarios compared to white-box and grey-box attacks."
                },
                "weaknesses": {
                    "value": "* The attack proposed relies heavily on node features to achieve a quality cluster to replace ground-truth labels when calculating the Silhouette score. This dependence is a significant vulnerability. If one adds noise to features and incorporates a de-noising mechanism within the base model, the attack's efficacy could be undermined since the attacker wouldn't know about the noise or how to de-noise the features.\n\n* Given that the attacker has access to node features, it might be more impactful to target both the structure and features. Not leveraging this information seems like a missed opportunity.\n\n* The attack lacks a theoretical foundation; it's mainly empirical. There are no guarantees about the efficacy of the attack.\n\n* The paper seems to have limited novelty. The idea of using clustering due to the absence of label information in RBA and the shift loss has been previously explored. The primary innovation appears to be the modification of the Silhouette score, which has its challenges.\n\n* In Section 3.2, the authors propose modifications in $a$ and $b$ to accommodate the absence of ground-truth labels. However, the later modifications in $b$ do not address the issue of pushing nodes of different classes further apart.\n\n* The parameter $\\Delta$ plays a significant role in the problem definition (Section 2), yet it isn't discussed in the methodology or experiment sections. It's unclear how much perturbation is excessive or how this was determined and verified.\n\n* Please ensure notation consistency. In Section 2, both notations $f_\\theta(X;A)$ and $f_\\theta(X,A)$ are used.\n\n* The related work section mentions interesting algorithms not used as benchmarks. Specifically, the absence of some RL-based methods was noticeable. Why were they excluded? Modifications to the benchmark could also be applied to other methods."
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission128/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698708417071,
            "cdate": 1698708417071,
            "tmdate": 1699635938252,
            "mdate": 1699635938252,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uhqZMiDywy",
                "forum": "LndMyiBl3n",
                "replyto": "rA6XBjndzp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission128/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission128/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 1uf8"
                    },
                    "comment": {
                        "value": "Thanks for your time and efforts!\n\n**Reply to the Weaknesses**\n1. The quality of clusters would be a concern in practice. However, stand at the attacker side, the quality of features would lead to a somewhat chicken and egg paradox. \nIf the cluster performance is extremely undesirable, or there exists huge feature noise, the defenders will not be able to achieve desirable classification performance, and therefore no need for attacks.\nNote that the defender have no access to inject controllable noise in most cases. If so, the results of all current attack methods would be unreliable.   \nIn our empirical results, Kmeans achieves acceptable clustering and lead to successful attacks in most graphs.\nAs we discussed in Section 7, improving the quality of clusters is feasible.\nOne could adopt Graph Constrative Learning, advanced or dataset-tailored clustering methods to achieve better cluster performance.  And as we discussed in Appendix F.2, such modifications would lead to even better performance for SheAttack.\n2. Attacking node features would be an opportunity for further improvement. \nIt can be easily incorporated into our framework by updating $X$ and $A$ simultaneously through the gradients. \nWe do not focus on feature attacks for more fair evaluation as most RBAs only focus on structural attacks.\n3. It is hard to derive general theoretical results for an RBA to surpass the others in all aspects. \nIn our paper, we pay attention to heterophily, which has been ignored in previous RBA design.\nWe theoretically verify that SheAttack is suitable for both homophilic and heterophilic settings, which is in accordance with the empirical results in synthetic datasets.\n4. The novelty of our methods is that we get rid of the homophily assumption and costly spectral techniques. \nWe try to induce the graph into a more general dilemma, where nodes are of less distinguishablility from the perspective of the class-wise distance.\nThe class-wise distance is more fundamental, yet rarely explored in graph adversarial attacks.\nWe provide theoretical interpretation for previous losses, and propose a more general attack framework. \n5. The modification in $b$ is to enlarge the scope of the attacker to fit in practical attack scenario. \nWhen considering just clustering, Silhouette Score is good enough. \nBut during attacks, the Silhouette Score without modifications tend to ignore opportunities.\nThe modifications do not aim to push intra-class nodes further apart, but enlarge the feasible sets during edge flipping.\nThe benefits are verified empirically in Table 5 in Section 6.\n6. We include experiments with different $\\Delta$ in Appendix F.5, with the perturb ratio being 10%, 15% and 20%. \nSheAttack constantly hold promising performance.\n7. Thanks for pointing the typos out. We will ensure the consistency of notations in the revised version.\n8. The RL-based models mentioned in the related works are RL-S2V and ReWatt. \nRL-S2V consider target-attacks, and is of extremely high time costs compared to loss-based methods.\nReWatt explores graph-level attacks, and only focus on rewiring attacks which are different to most RBA settings.  \nSo we decide to not include them for the setting differences and efficiency issues following previous loss-based RBAs."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission128/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699797875224,
                "cdate": 1699797875224,
                "tmdate": 1699797875224,
                "mdate": 1699797875224,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nJ1t57jNdq",
                "forum": "LndMyiBl3n",
                "replyto": "uhqZMiDywy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission128/Reviewer_1uf8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission128/Reviewer_1uf8"
                ],
                "content": {
                    "comment": {
                        "value": "I thank authors for their comprehensive reply, it resolved a number of my question. I still have two main concerns regarding the paper:\n1. The defender has both structure and features for performing classification task. Indeed in the circumstances when there is extreme heterophily and large feature noise, it is both infeasible for defender and attacker to deal with such data. However, as we lower the degree to which the network shows heterophily, it becomes easier for the defender to perform classification even in the presence of large feature noise (i.e., the classifier learns to ignore the features). But this is not the case with the attacker here as it solely relies on features to perform clustering. Regarding the last part, I don't understand why would we need the assumption that defender cannot perform a protection scheme based on introducing calculated noise to the data and de-noising within the model (which is not accessible to the attacker). \n2. If it could be easily incorporated, wouldn't it make sense to include it to have the strongest attacker possible, and then in the experiment section choose whether or not use that feature?"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission128/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689172105,
                "cdate": 1700689172105,
                "tmdate": 1700689172105,
                "mdate": 1700689172105,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "M0nRCJ8U4W",
            "forum": "LndMyiBl3n",
            "replyto": "LndMyiBl3n",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission128/Reviewer_8KRc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission128/Reviewer_8KRc"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a new black box attack on the graph structure that uses a variant of the silhouette score as one component of the attacker's loss. This captures distances between intra-class/cluster and inter-class/cluster instances and reflects the difficulty of the classification problem. The authors argue that this loss is agnostic to whether the graph is homophilic or heterophilic. Their attack does not require knowledge of the node labels."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The theoretical insights are interesting even though they rely on several simplifying assumptions.\n\nThe attack can scale to larger graphs such as ogbn-arxiv and ogbn-products.\n\nThe black box threat model is relevant and interesting to study but has received relatively less attention in the past."
                },
                "weaknesses": {
                    "value": "The threat model only enforces a global budget, and completely ignores any local constraints e.g. w.r.t. the degree of the nodes. This is likely to lead to unrealistic and noticeable attacks. While the authors perform an empirical analysis in section G and conclude that \"unnoticability of SheAttack is in an acceptable range.\" I do not necessarily agree. First, the averaged results in Table 22 can be misleading since there is likely a big skew in the distribution of changes, and second the mean values are already large.\n\nThe experimental evaluation focuses on a fixed perturbation ratio (mostly 0.2 and sometimes 0.1) which can be considered unrealistically large. An in-depth ablation study w.r.t. different perturbation budgets is missing.\n\nThe paper would benefit from formalizing and describing the threat model in much more detail. For example, the authors state \"only training inputs excluding node labels, are known to attackers.\" Does this mean that the attacker also does not have access to the training node labels. I assume that this is the case. If yes, a reasonable baseline would be to compare previous (adaptive) attacks [1] using clusters as a surrogate for labels.\n\nIf I am wrong and the attacker does have access to training node labels, then they can train a surrogate and use the predictions for the test labels (instead of true labels) which is likely to work much better than using the unsupervised clusters, and likely also better than using \"node embeddings generated by supervised GCN as input to generate clusters\".\n\nReferences:\n1. Mujkanovic et al. \"Are Defenses for Graph Neural Networks Robust?\""
                },
                "questions": {
                    "value": "1. How does the attack peform when introducing local budget constraints (e.g. relative to the node degree)?\n2. How does the attack compare to an attack where instead of the true labels we use the predictions from the victim model?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission128/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837938554,
            "cdate": 1698837938554,
            "tmdate": 1699635938183,
            "mdate": 1699635938183,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "khTgW9D9ol",
                "forum": "LndMyiBl3n",
                "replyto": "M0nRCJ8U4W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission128/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission128/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 8KRc"
                    },
                    "comment": {
                        "value": "Thanks for your insightful feedbacks!\n\n**Reply to the Weaknesses**\n1. While perturb ratio above 0.10 might seem unrealistic, a sad fact about RBAs is that it could be extremely hard to find a powerful attack if the perturb ratio is low.\nTake Cora_ml with perturb ratio 0.05 for example, the results against a two-layer GCN are summarized below.\n| Attack  | Evasion | Poison |\n|----------|----------|----------|\n| Clean    | 85.94  | 85.94   |\n| Random | 84.79 | 84.72 |\n| DICE | 84.09 | 83.82 |\n| SPAC-A |84.97 | 84.69 |\n| GFAttack| 84.83 | 83.92 |\n| PEEGA | 82.49 | 81.56 |\n| She | **81.95** | **80.77** |\n| She-A | 82.07 | 80.92 | \n\nWhile the results of SheAttack is promising, the performance drop is marginal for all RBAs. \nBased on our discussion in Section 7, we highly suspect that the attack performance of white-box attacks would be similarly marginal without utilizing  split information.\nSo following the settings of previous RBAs, we set the perturb ratio in most experiments equal of higher than 10%.\nWe include experiments with perturb ratio 0.15 in Appendix F.5. \n\n2. Unnoticability. In our paper, we do not focus on addressing unnoticability for the following reasons.\n* The requirements of unnoticability is varied. \nBesides of the degree shift mentioned, there are homophily shift [1] and spectral shift [2] that might also be noticeable for the defender. \nIt is hard for an RBA to tackle unnoticability from all perspective while staying effective.\n*  Difficulties for evaluation. For example, baselines like DICE and PEEGA are based on utilizing homophily shift for performance improvement. \nSo it could be meaningless to impose unnoticability constraints about homophily for them. \nBased on our knowledge, it is still hard to ensure a fair evaluation setting with reasonable unnoticability constraint.\n\nDespite the above difficulties, SheAttack could incorporate plug-in unnoticability designs if necessary.\nIn the cases where a large degree shift is not allowed, we could include a degree-shift loss into the loss term as a penalty:\n$L_{atk} = L_{she} + \\lambda L_{shift} - \\gamma L_{deg-shift}$\nWe test the performance of She-Comb and She-Comb with degree constraints in Cora-ML with 20% perturb ratio. \nThe result is:  \n| Attack  | Evasion | Poison | Deg shift |\n|----------|----------|----------|-----------|\n| She-Comb | 74.44\u00b11.95 | 72.06\u00b11.46  | 0.59 | \n| She-Comb (deg-cons) |76.82\u00b11.26 | 75.11\u00b11.07 | 0.01 |\n\nWhile the attack performance slightly drops, the degree shift is almost eliminated. \n\n3. Yes, RBAs do not allow the attacker to have access to any node labels. \nFor example,  in a social network, the attacker could hack the member accounts, but do not know the downstream tasks of defenders (e.g., whether they predict the genders or regions of members).\nIn the experiments, we have include a self-atk attack, which can be seen as GRBCD trained on surrogate labels. \nThe attack aims to make the output of the attacked graph different to clusters as labels, but the performance is not satisfactory. \nWe will include a more detailed illustration of the RBA setting in the Appendix in the revised version.\n\n**Reply to the Questions**\n\nWe have included the reply to questions in the **Reply to the Weaknesses**. \nIf you have any further questions, we are willing for more discussion.\n\n[1] Chen, Yongqiang, et al. \"Understanding and improving graph injection attack by promoting unnoticeability.\"  In ICLR 2022.\n\n[2] Lin, Lu, Ethan Blaser, and Hongning Wang. \"Graph structural attack by perturbing spectral distance.\" Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission128/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699797770540,
                "cdate": 1699797770540,
                "tmdate": 1699797770540,
                "mdate": 1699797770540,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iZ3f8HKNCG",
            "forum": "LndMyiBl3n",
            "replyto": "LndMyiBl3n",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission128/Reviewer_e7Jw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission128/Reviewer_e7Jw"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors study the problem of restrict black-box attacks (RBA) on GNNs. It first introduces the Silhouette Scores, which is used for quantifying the difficulty of a clustering problem, to the RBA attacks on GNNs. Then it introduces a RBA attack named SheAttack by minimizing the silhouette score of the graph. And a scalable version of SheAttack is also proposed for the large-scale graphs. The experimental results on homophily and heterophily graph benchmarks demonstrate its effectiveness compared to other RBA baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper study the problem of restricted black-box attacks, which is both practical and noteworthy.\n2. This proposed method is effective in both homophily and heterophily settings. And the scalable version of SheAttack can also work on the large-scale graphs.\n3. The experimental results on both homophily and heterophily graphs show that SheAttack can outperform other RBA baselines."
                },
                "weaknesses": {
                    "value": "1. Although the authors include the experimental results on large-scale graphs, the comparison between SheAttack and some existing powerful baselines, such as PRBCD, on the large-scale graphs is missing.\n2. In this paper, the authors highlight that SheAttack is applicable to the heterophilic settings while existing RBA methods cannot. However, I think it would be better if some robust GNNs for heterophily graphs can be included during the comparison, such as [1]. \n3. I recommend the authors can include the comparison of the running time among different methods to verify the efficiency of SheAttack.\n\n[1] Robust Heterogeneous Graph Neural Networks against Adversarial Attacks. AAAI 2022"
                },
                "questions": {
                    "value": "1.\tCould you please provide some comparisons between PRBCD/PRBCD-shuffle with SheAttack on large-scale graphs? \n2.\tPlease add the experimental results of SheAttack against RobustGNN for heterophily graphs.\n3.\tPlease include the comparison of running time among different methods."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission128/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698908093494,
            "cdate": 1698908093494,
            "tmdate": 1699635938062,
            "mdate": 1699635938062,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "E5NNQiH6hj",
                "forum": "LndMyiBl3n",
                "replyto": "iZ3f8HKNCG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission128/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission128/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer e7Jw"
                    },
                    "comment": {
                        "value": "Thanks for your detailed feedback!\n\n**Reply to the Weakness**:\n1. PRBCD / GRBCD are white-box attacks that utilize training-test spilts, architecture of victim models, and node labels. \nThe results of PRBCD and GRBCD would be extremely strong with these extra information.\nTherefore,  we do not compare our attack with these white-box attacks following previous literature addressing RBAs.\nWe include the shuffled version of them that dismiss the splits information in Table 6.\nWithout the splits information, PRBCD/GRBCD suffers from severe performance drop even with the knowledge of ground-truth node labels.\n\nWe further test PRBCD and PRBCD-shuffle on ogbn-arxiv. \nWe see that if the split is shuffled, PRBCD as white-box attacks is just slightly better than SheAttack although it utilizes node labels. \n\n| Attack  | Evasion | Poison |\n|----------|----------|----------|\n| Clean    | 69.60   | 69.60   |\n| PRBCD  | 37.01  | 38.52   |\n| PRBCD-shuffle | 59.06 | 61.61| \n\n2. We carefully go through the baseline the reviewer mentioned, but it seems that the paper is about heterogenous graphs, which are graphs of multiple edge types. \nThe heterophily concept we adopt in the paper is about the preference of connections in edges.  \nNevertheless, we test the performance of SheAttack against a robust heterophilic baseline EvenNet [1] on the synthetic datasets with perturb ratio being 20%.\nThe results are summarized below. SheAttack still perform well against the robust defense model.\n\n| Attack      | cSBM+25 Evasion | cSBM+25 Poisoning | cSBM-25 Evasion | cSBM-25 Poisoning | \n|-------------|-----------------|-------------------|-----------------|-------------------|\n| Clean       | 81.95\u00b10.36      | 81.95\u00b10.36        | 80.34\u00b11.15      | 80.34\u00b11.15      |       \n| Random    | 81.55\u00b10.61   | 81.26\u00b10.61     | 79.47\u00b10.84   | 79.14\u00b10.93     |     \n| DICE         | **79.58\u00b10.64**      | 78.86\u00b11.10       | 83.07\u00b11.08      | 86.78\u00b10.33        | \n| SPEC        | 82.22\u00b10.35      | 81.74\u00b10.33        | 80.00\u00b10.81     | 80.72\u00b10.46        | \n| GFAttack    | 81.68\u00b10.54     | 80.82\u00b11.23        | 79.12\u00b10.41      | 79.41\u00b10.43        | \n| Self-atk       | 81.04\u00b10.28      | 81.01\u00b10.61        | 79.84\u00b11.13      | 79.98\u00b10.58        |    \n| PEEGA      | 81.63\u00b10.27      | 81.28\u00b10.63        | 79.74\u00b10.71      | 79.49\u00b10.42      |    \n| She            | 79.94\u00b10.33      | **78.69\u00b11.11**   | **78.03\u00b11.07**      | **78.21\u00b10.83**       |    \n| She-A        | 79.60\u00b10.38     | 78.72\u00b11.13        | 78.27\u00b10.85      | 77.60\u00b10.99      |        \n\n| Attack      | cSBM+50 Evasion | cSBM+50 Poisoning | cSBM-50 Evasion | cSBM-50 Poisoning | \n|-------------|-----------------|-------------------|-----------------|-------------------|\n| Clean       | 91.10\u00b10.37     | 91.10\u00b10.37        | 91.34\u00b10.22      | 91.34\u00b10.22     |       \n| Random    | 89.76\u00b10.48   | 89.33\u00b10.54     | 89.02\u00b10.36  | 88.32\u00b10.65     |     \n| DICE         | **85.84\u00b10.74**      | **83.66\u00b11.11**       | 95.81\u00b10.39      | 95.78\u00b10.34        | \n| SPEC        | 91.50\u00b10.36      | 91.34\u00b10.45        | 91.65\u00b10.21     | 91.68\u00b10.21        | \n| GFAttack    | 89.90\u00b10.36     | 90.22\u00b10.57       | 89.73\u00b10.56      | 89.18\u00b10.88        | \n| Self-atk       | 90.11\u00b10.27      | 90.13\u00b10.16        | 89.65\u00b10.45      | 89.26\u00b10.56     |    \n| PEEGA      |89.26\u00b10.22      | 88.02\u00b10.66        | 89.63\u00b10.52    |88.85\u00b10.68      |    \n| She            | 88.58\u00b10.51      | 87.52\u00b11.01       | **86.35\u00b10.63**      | **84.03\u00b10.95**       |    \n| She-A        | 89.41\u00b11.01    | 88.67\u00b11.04    | 87.09\u00b11.03      | 85.62\u00b10.88      |  \n\n3. We have included the time efficiency on cSBM datasets and ogbn-products in Appendix F.6. \nIf you are interested in the time efficiency of other datasets, we are willing for more discussion.\n\n[1] Lei, Runlin, et al. \"Evennet: Ignoring odd-hop neighbors improves robustness of graph neural networks.\" Advances in Neural Information Processing Systems 35 (2022): 4694-4706."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission128/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699797734062,
                "cdate": 1699797734062,
                "tmdate": 1699797734062,
                "mdate": 1699797734062,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DScQe7JVwb",
            "forum": "LndMyiBl3n",
            "replyto": "LndMyiBl3n",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission128/Reviewer_oiQU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission128/Reviewer_oiQU"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the restricted black-box attack scenario where attackers only have access to node features and the graph structure. To solve this problem, the authors introduce the Modified Silhouette Score (MMS) to measure a graph\u2019s quality and propose a Silhouette score-based attack. Extensive experiments are conducted."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The studied restricted black-box attack is a practical scenario and an important problem.\n2. The motivation of this paper is clear and the idea of introducing the Silhouette Score to measure the quality of a graph is interesting.\n3. Extensive experiments are conducted."
                },
                "weaknesses": {
                    "value": "1. The proposed SheAttack depends on various hyper-parameters, which may significantly affect the performance of the proposed method and lack detailed theoretical support or empirical analysis. For example, the number of clusters $k$, the propagation layer/time on the adjacency matrix, and the $\\lambda$ that balance the Shift Loss and Silhouette Score-based Loss. \n2. The proposed method does not seem to be consistently effective in all scenarios in Tables 1&3.\n3. The writing of this paper needs to be further improved. For example, the citation format of references in Introduction and Preliminaries seems strange. 'Aggreation function' should be 'Aggregation function\u2019. The definition of poison attacks and evasion attacks on page 3 is confusing."
                },
                "questions": {
                    "value": "1. In Figure 3, why do GRBCD and RandAttack show different Modified Silhouette Score at epoch 0?\n2. How would the proposed method perform when the victim model is not a two-layer GNN? In other words, when the propagation layers/times in the proposed method and victim model are not the same, would the proposed method still be effective?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission128/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission128/Reviewer_oiQU",
                        "ICLR.cc/2024/Conference/Submission128/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission128/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699264203706,
            "cdate": 1699264203706,
            "tmdate": 1700663602218,
            "mdate": 1700663602218,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kfc2W4fEkJ",
                "forum": "LndMyiBl3n",
                "replyto": "DScQe7JVwb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission128/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission128/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to reviewer oiQU"
                    },
                    "comment": {
                        "value": "Thank you for your time and efforts!\n\n**Reply to the Weakness**:\n1. For the hyperparameter $k$, we have included a sensitivity analysis in Appendix F.3. Our results show that our method is not sensitive to it, and we provide suggestions for choosing a proper $k$ in practice.\nFor the hyperparameter $\\lambda$, we only tune it in within a small range, which is [0, 1.0, 5.0]. the result turned out to be desired enough.\nTo sum up, SheAttack is not dependent on well-chosen hyperparameters. \n2. On synthetic datasets and homophilic datasets, SheAttack is only inferior to DICE in the homophilic setting, which utilizes ground-truth labels and is not strictly an RBA. \nOn real-world datasets, SheAttack is inferior to baselines in the poison setting in Chameleon and Squirrel. \nIn [1], the authors questioned that the two datasets may face data leakage problems.  \nIn the filtered Chameleon and Squirrel, the results with 20% the perturb ratio is: \n| Attack      | Chameleon_filtered (Evasion)| Chameleon_filtered (Poison) | Squirrel_filtered (Evasion) | Squirrel_filtered (Poison) | \n|-------------|-----------------|-------------------|-----------------|-------------------|\n| Clean       | 40.36\u00b12.36     | 40.36\u00b12.36 | 35.47\u00b11.00 |  35.47\u00b11.00 |   \n| Random    | 35.52\u00b13.44  | 36.50\u00b11.72     | 32.70\u00b12.39 |   35.36\u00b11.55|     \n| DICE         | **33.00\u00b12.43**      | **32.91\u00b12.08**     | 28.78\u00b11.38 | 38.81\u00b11.82   | \n| SPEC        | 38.30\u00b12.02      | 37.85\u00b12.43        | 31.22\u00b12.81     | 35.72\u00b10.80      | \n| GFAttack    | 34.44\u00b12.51     | 35.34\u00b14.51       | 32.01\u00b13.10      | 33.88\u00b11.98     | \n| Self-atk       | 39.82\u00b12.48      | 37.13\u00b12.67        | 33.13\u00b13.60    | 35.36\u00b11.64     |    \n| PEEGA      | *33.00\u00b12.68*      | 35.96\u00b12.48        | 29.46\u00b12.02    | 33.53\u00b10.50      |    \n| She            | 35.78\u00b13.15      | *33.72\u00b12.43*       | **28.38\u00b12.55**      | *33.24\u00b10.93*     |    \n| She-A        | 36.23\u00b11.64    | 36.68\u00b11.80    | *28.67\u00b11.39*      | **32.91\u00b12.33**      |  \n\nWe see that SheAttack holds best performance in the three of four new heterophilic settings.\nA recent study [1] points out that these two datasets also exhibit a mixing pattern of homophily and heterophily, which would be complex for both attackers and defenders.\nAs a result, no methods show general superiority in these two datasets. \n\n3. Thanks you for your advice in the writings. For the citations and writing, we will adopt a unify format and carefully revise the spellings. For the definition about poison attacks and evasion attacks, we only include a brief introduction due to space limitations. \nWe adopt the most common definition for them as previous graph adversarial literature, and we will include a detailed explanation to it in the Appendix for the readers' convenience in the revised version.\n\n**Reply to the Questions**:\n1. In Figure 3, GRBCD and RandAttack exhibits almost the same Modified Silhouette Score at epoch 0 when evaluated given the labels (warm-colored) and clusters (cold-colored). \nThe slight difference could be due to visualization issues.\nWe would appreciate that if more details about the question could be provided. \n2. In the experiments against ogbn-arxiv and ogbn-products, we set the number of GNN as 3 following [ogb-example](https://github.com/snap-stanford/ogb/tree/master/examples/nodeproppred/arxiv). \nBased on the result in our paper, the performance of SheAttack is still promising. \n\n[1] Platonov, Oleg, et al. \"A critical look at the evaluation of GNNs under heterophily: are we really making progress?.\" In ICLR 2023.\n\n[2] Mao, Haitao, et al. \"Demystifying Structural Disparity in Graph Neural Networks: Can One Size Fit All?.\" In NIPS 2023."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission128/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699797650083,
                "cdate": 1699797650083,
                "tmdate": 1699797650083,
                "mdate": 1699797650083,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2gj5dNtJUo",
                "forum": "LndMyiBl3n",
                "replyto": "kfc2W4fEkJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission128/Reviewer_oiQU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission128/Reviewer_oiQU"
                ],
                "content": {
                    "title": {
                        "value": "Replys"
                    },
                    "comment": {
                        "value": "Thank the authors for addressing some of my concerns. Based on this, I would like to adjust my score accordingly."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission128/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663575183,
                "cdate": 1700663575183,
                "tmdate": 1700663575183,
                "mdate": 1700663575183,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]