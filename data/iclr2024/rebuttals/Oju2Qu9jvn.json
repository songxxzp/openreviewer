[
    {
        "title": "Estimating Conditional Mutual Information for Dynamic Feature Selection"
    },
    {
        "review": {
            "id": "zMCg8Yk6OH",
            "forum": "Oju2Qu9jvn",
            "replyto": "Oju2Qu9jvn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6140/Reviewer_s6Fj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6140/Reviewer_s6Fj"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose DIME a dynamic feature selection (DFS) method that is based on two neural networks, aiming to maximize prediction accuracy while balancing the cost of acquiring features. Specifically, a value network is designed to estimate the conditional mutual information (CMI), $I(y;x_i\u2223x_S)$, and a prediction network is used to make predictions based on the currently selected features. Both networks are jointly trained. If the acquisition costs for features are known, the objective aims to select the feature that maximizes $I(y;x_i\u2223x_S)/c_i$, where $c_i$ is the acquisition cost of $i$'th feature. In the experiments, DIME is compared against both static and dynamic feature selection methods on various (tabular and image) datasets. The results show that DIME outperforms the competitors in terms of predictive performance and effectiveness (i.e., number of selected features)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.) The research investigates various policies for feature selection, such as RL, imitation learning, and a greedy policy based on CMI.\n\n2.) The introduction of the Predictor Network and Value Network, which jointly work to estimate Conditional Mutual Information (CMI) is interesting and represents a novel approach.\n\n3.) The theoretical parts of the paper provide a solid foundation for the approach.\n\n4.) The experimental evaluation is quite comprehensive."
                },
                "weaknesses": {
                    "value": "1.) While the incorporation of acquisition costs with CMI estimates is straight-forward, the acquisition costs appear to be an artificial supplementary add-on to the methodology.\n\n2.) Some related approaches should be mentioned in the related work section and could have been considered as competitors\n\nIncremental permutation feature importance (iPFI): towards online explanations on data streams (Machine Learning 2023) \nF Fumagalli, M Muschalik, E H\u00fcllermeier, B Hammer\n\nLeveraging model inherent variable importance for stable online feature selection (KDD 2020)\nJ Haug, M Pawelczyk, K Broelemann, G Kasneci \n\n3.) It is not quite clear how prior information is factored into and affects the feature selection policy; this part should be better explained.\n\n4.) An exact algorithmic representation should be used to provide clarity on the interplay between the networks, the CMI estimation, the use of prior information, and how the features are finally selected in various scenarios."
                },
                "questions": {
                    "value": "See weaknesses 3.) and 4.) from above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6140/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6140/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6140/Reviewer_s6Fj"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6140/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697913473064,
            "cdate": 1697913473064,
            "tmdate": 1700082344574,
            "mdate": 1700082344574,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "l3nLTjJhfV",
                "forum": "Oju2Qu9jvn",
                "replyto": "zMCg8Yk6OH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer s6Fj"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for closely examining our work and providing their feedback. We have used the space below to respond to the questions raised in the review.  Updates to the manuscript are highlighted in red to make them easily identifiable.\n\n> \u201cWhile the incorporation of acquisition costs with CMI estimates is straight-forward, the acquisition costs appear to be an artificial supplementary add-on to the methodology.\u201d\n\nOnce we are able to accurately predict the CMI with DIME, extending the method to incorporate non-uniform feature costs may seem like a small add-on, but it makes DIME more useful in real-world settings where features have diverse acquisition costs. Taking the emergency medicine setting as a motivating example, there are many features that can be acquired with significant variation in the temporal and monetary cost. Demographic features like age, sex, and patient history would be cheap and only take only minutes to obtain, whereas lab test features might take days and would be more expensive, and genetic tests could take weeks to conduct. Incorporating non-uniform feature costs allows us to take these differences into consideration, and DIME can use multiple low-cost features in lieu of one high cost feature to get the same diagnostic performance.\n\n> \u201cSome related approaches should be mentioned in the related work section and could have been considered as competitors\u201d\n\nThank you for pointing us to these very interesting works! We carefully read them both, and after studying their proposed methods, we do not think they are closely related to our problem setting. Fumagalli et al. (2023) study global feature importance in the context of streaming data, where new data points come in and the distribution may change over time; in contrast, we focus on feature selection with selections that can differ between data points, and there is no analogous notion of distribution shift. Haug et al. (2020) focus on online feature selection, which is also related to data streams where the distribution can shift over time; our work considers the iterative acquisition of features for each prediction, but this is very different from the notion of incoming data streams with changing distributions. As such, we do not think there is any room to compare DIME with these methods.\n\n> \u201cIt is not quite clear how prior information is factored into and affects the feature selection policy; this part should be better explained\u201d\n\nSection 4.2 describes how our approach can be modified to include prior information: essentially, $z$ becomes an input to both the predictor and value networks, and they are optimized in the same way as before using the same loss functions. The predictor network is trained with the loss $\\ell(f(x_S, z; \\theta), y)$ (e.g., cross entropy loss) and the value network is trained with $(v_i(x_S, z; \\phi) - \\Delta(x_S, x_i, z, y))^2$. Theorem 2 describes how this should theoretically affect the dynamic feature selection procedure.\n\nWe demonstrate this approach with the histopathology dataset, using a Canny edge image as prior information. During training, we use separate ViT backbones for the original and the edge images, and we pass these images as inputs to both the value network and the predictor. Specifically, we concatenate the resulting embeddings of the original and edge images from the backbones before either getting the CMI estimates from $v$ or the predictions from $f$, which are implemented as small networks that take concatenated embeddings as their input. We can update this section in the manuscript to better explain how the prior information is passed to the networks.\n\n> \u201cAn exact algorithmic representation should be used to provide clarity on the interplay between the networks, the CMI estimation, the use of prior information, and how the features are finally selected in various scenarios.\u201d\n\nFor more information about how the networks are trained, please see Algorithm 1 in Appendix C, which shows how the value network and predictor network are jointly optimized. We are happy to specify how the algorithm incorporates prior information, as well as add another one describing how features are selected at inference time. We will also add a reference to these algorithms in the main text, which we forgot to include in the original submission."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700023699414,
                "cdate": 1700023699414,
                "tmdate": 1700026983040,
                "mdate": 1700026983040,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0acNZMhbg8",
                "forum": "Oju2Qu9jvn",
                "replyto": "l3nLTjJhfV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_s6Fj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_s6Fj"
                ],
                "content": {
                    "title": {
                        "value": "\"... and there is no analogous notion of distribution shift.\""
                    },
                    "comment": {
                        "value": "Could you please specify/formalize your notion of differences (or assumptions) with respect to the conditional (i.e., concept) distribution P(y|x)? Because if you assume that certain features that are important for one prediction may not be important for another prediction, then you are assuming some kind of differences w.r.t P(y|x) for different data points (e.g., similar to the differences between the distributions in the leaf nodes of a decision tree). If so, then many works concerning feature selection under the assumption of differences w.r.t. the concept distribution become relevant (feature selection under concept drifts would actually be only a small fraction of relevant related works)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700040992946,
                "cdate": 1700040992946,
                "tmdate": 1700040992946,
                "mdate": 1700040992946,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qh4bbsm75J",
                "forum": "Oju2Qu9jvn",
                "replyto": "bVRJl1yR4m",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_s6Fj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_s6Fj"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the clarification!"
                    },
                    "comment": {
                        "value": "Thank you for clarifying your assumptions. I think the work would benefit from highlighting this difference between your approach and feature selection strategies in dynamic data scenarios. Overall, you have addressed my concerns well, and I will raise my score accordingly."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700082179085,
                "cdate": 1700082179085,
                "tmdate": 1700082179085,
                "mdate": 1700082179085,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2udhyuqQG4",
                "forum": "Oju2Qu9jvn",
                "replyto": "zMCg8Yk6OH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to read our response and adjust your score, we appreciate it! We will consider the differences between our method and data streams."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700101408192,
                "cdate": 1700101408192,
                "tmdate": 1700101434758,
                "mdate": 1700101434758,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HWk317YILR",
            "forum": "Oju2Qu9jvn",
            "replyto": "Oju2Qu9jvn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6140/Reviewer_j5dM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6140/Reviewer_j5dM"
            ],
            "content": {
                "summary": {
                    "value": "The work is devoted to the problem of dynamic feature selection. The authors propose to estimate \u2013 learn \u2013 Conditional Mutual Information (CMI) of the next feature given the past selected ones. The learning is based on the incremental loss improvements of a given predictor (simultaneously learned with the CMI). It is proven that, for cross entropy loss, the optimal learning point will be CMI. The paper also contains experiments on several datasets that demonstrate better performance of the proposed method in comparison to several baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-\tClear problem setup\n-\tLarge volume of experiments"
                },
                "weaknesses": {
                    "value": "-\tComparison with baselines (see questions)\n-\tIt looks like incorporating prior information and variable feature selection constitute 2/3 of the overall work contribution, but they seem more-or-less incremental things (i.e., given such a task a practitioner would easily reproduce Sections 4.2 and 4.3 having Section 4.1). More non-trivial insights would be nice to see in the main contribution."
                },
                "questions": {
                    "value": "1.\tAs far as I understand, the authors propose a method to learn CMI improvement. It would be nice to compare this method to the ones, where CMI is approximated in the direct statistical way. For instance, there is a lot of approaches like MIM, MIFS, mRMR, JMI, CMICOT, etc. See for a brief overview of them in [Shishkin, A., et al. \u201cEfficient high-order interaction-aware feature selection based on conditional mutual information\u201d, NeurIPS 2016]. Could you please compare your approach with such statistical methods? Including, in experiments. Is it true that the gain we obtain from learning CMI improvement over statistical methods is cost effective? (learning consumes more computation => on the same level of computation costs, we can get more from statistical methods, right?)\n\n\n2.\tReturning back to [Shishkin, A., et al. \u201cEfficient high-order interaction-aware feature selection based on conditional mutual information\u201d, NeurIPS 2016], we can see that greedy approach of selecting features one by one is not the best way. The ideal approach is to select the best subset of features (which is computationally and dimensionally infeasible). But we at least can select features not one-by-one, but taking into account interactions between selecting features (like in CMICOT). Is there any way to incorporate that approach into the work of the authors?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6140/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698403318530,
            "cdate": 1698403318530,
            "tmdate": 1699636665404,
            "mdate": 1699636665404,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uVmwJhhv8n",
                "forum": "Oju2Qu9jvn",
                "replyto": "HWk317YILR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer j5dM"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for closely examining our work and providing their feedback. We have used the space below to respond to the questions raised in the review.  Updates to the manuscript are highlighted in red to make them easily identifiable.\n\n> \u201cAs far as I understand, the authors propose a method to learn CMI improvement. It would be nice to compare this method to the ones, where CMI is approximated in the direct statistical way. For instance, there is a lot of approaches like MIM, MIFS, mRMR, JMI, CMICOT, etc. See for a brief overview of them in [Shishkin, A., et al. \u201cEfficient high-order interaction-aware feature selection based on conditional mutual information\u201d, NeurIPS 2016]. Could you please compare your approach with such statistical methods? Including, in experiments. Is it true that the gain we obtain from learning CMI improvement over statistical methods is cost effective? (learning consumes more computation => on the same level of computation costs, we can get more from statistical methods, right?)\u201d\n\nThe reviewer is correct that DIME estimates each feature\u2019s CMI with the response variable given a set of observed features. However, our problem formulation is different from all the methods that the reviewer points to: these methods perform *static feature selection*, which means that the features are selected just once and used for all predictions, whereas DIME performs *dynamic feature selection*, which means that we select features separately for each prediction. To be precise, these static methods are concerned with the quantity $I(\\mathbf{y}; \\mathbf{x}_i \\mid \\mathbf{x}_S)$, while DIME aims to estimate $I(\\mathbf{y}; \\mathbf{x}_i \\mid x_S)$ with $x_S$ being a set of observed features for the current prediction. Estimating these two quantities requires very different methodologies, and it is not clear if the procedures used by the suggested methods are applicable here or if they are computationally feasible to be run repeatedly for each selection performed for each prediction.\n\nAs for the static feature selection methods mentioned by the reviewer, we did not include these initially because we instead use a more recent state-of-the-art static baseline: the Concrete Autoencoder (Balin et al., 2019). For completeness, we tried comparing DIME with mRMR and CMICOT, and the results are now shown in Figure 2. We can confirm that these methods both underperform DIME. CMICOT does better than mRMR, but both methods underperform the Concrete Autoencoder, our original static baseline. Note that we chose mRMR and CMICOT among the suggested methods because CMICOT has been shown to outperform the others and both of them had public implementations that were easy to incorporate into our problem.\n\n> \u201cReturning back to [Shishkin, A., et al. \u201cEfficient high-order interaction-aware feature selection based on conditional mutual information\u201d, NeurIPS 2016], we can see that greedy approach of selecting features one by one is not the best way. The ideal approach is to select the best subset of features (which is computationally and dimensionally infeasible). But we at least can select features not one-by-one, but taking into account interactions between selecting features (like in CMICOT). Is there any way to incorporate that approach into the work of the authors?\u201d\n\nAs described in the previous response, a key difference between CMICOT and DIME is whether features are selected just once (static) or separately for each prediction (dynamic). In our case, DIME can only observe features once they are acquired, so features must be selected one at a time. However, in a sense DIME\u2019s training procedure does consider feature interactions, because the CMI conditions on the subset of features that are already observed. For example, if two features are perfectly correlated, after observing one of them, the other\u2019s CMI would drop to zero because acquiring it will provide no additional information about the response variable."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700023515324,
                "cdate": 1700023515324,
                "tmdate": 1700161340011,
                "mdate": 1700161340011,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iPrbTdvOLV",
            "forum": "Oju2Qu9jvn",
            "replyto": "Oju2Qu9jvn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the problem of dynamic feature selection (i.e., adaptively acquire features based on previously acquired ones), where the ultimate goal is to classify each data instance using a small subset of the available features. A greedy approach, termed DIME, is proposed, where feature selection is based on the conditional mutual information (CMI) with the response variable. The paper focuses on estimating CMI in a discriminative fashion, and then trains two networks to implement the feature selection policy. Furthermore, the paper discusses how to handle non-uniform costs across features, prior information and variable feature budgets. A number of experiments on tabular and image datasets are provided that showcase the performance of DIME in contrast to prior work on the area of dynamic feature selection."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The paper studies a very important and timely problem, i.e., dynamic feature selection with a minimal budget.\n+ A new greedy algorithm is proposed that estimates CMI in a discriminative fashion.\n+ The paper discusses how to handle common issues happening in practice, e.g., non-uniform costs, variable feature budgets, etc.\n+ Theoretical results are provided that lead to an unbiased estimator of CMI.\n+ The paper is well-written and effort has been put to clarify its contributions.\n+ The performance of the proposed algorithm is illustrated on a number of datasets and compared with existing methods."
                },
                "weaknesses": {
                    "value": "- I believe that some relevant wont on dynamic feature selection that is neither RL-based nor greedy-based is missing (see references below)\n- The performance improvement of DIME wrt to one of the baselines (i.e., Argmax Direct) is small (especially for the tabular datasets). \n- The paper claims that DIME only accounts for non-uniform costs and variable feature budgets, but I am pretty sure that some of the RL-based methods handle such settings too.\n- The really bad performance of the RL-based methods compared to the greedy methods, including DIME, is quite surprising to me and I am wondering if this is some kind of typo."
                },
                "questions": {
                    "value": "(1) I believe that the following set of references also study dynamic feature selection, but from a different perspective than the references presented in the paper. Specifically, they formulate the problem as POMDP and study the theoretical properties of the optimum solution, which enables them to design fast algorithms for dynamic feature selection. They also give bounds on the expected number of features needed to achieve a specific accuracy level. Finally, the latter paper uses mutual information to also drive dynamic feature selection. I think that after reviewing these papers, the authors would agree with me that this is relevant work and they should consider citing them for completeness.\n \n- Liyanage, Y.W., Zois, D.S. and Chelmis, C., 2021. Dynamic instance-wise joint feature selection and classification. IEEE Transactions on Artificial Intelligence, 2(2), pp.169-184. \n\n- Liyanage, Y.W., Zois, D.S. and Chelmis, C., 2021. Dynamic Instance-Wise Classification in Correlated Feature Spaces. IEEE Transactions on Artificial Intelligence, 2(6), pp.537-548. \n\n(2) I also believe that the algorithms proposed in the previous references as well as (Janisch et al; 2019) are designed to handle non-uniform costs and variable feature budgets. I think this need to be clearly stated in the paper, since at the moment, it is suggested that only DIME can accommodate such settings.\n\n(3) The performance of DIME is very close to Argmax Direct. What is the benefit of using DIME instead of Argmax Direct in that sense?\n\n(4) My major concern is the really surprisingly bad performance of RL-based methods compared to the greedy methods, including DIME. The reason is that I see the RL-based methods as a way of implementing dynamic programming, which is the optimal thing to do, and should be better than greedy methods. Of course, RL has its own issues, but I am still wondering if the performance improvement observed in the experiments is due to using more powerful neural networks to approximate the selection process and not the greedy nature of the method. In addition, it may be because the RL-based methods that DIME is compared with use different criteria than mutual information (excluding the missing references above). Finally, I believe that the RL-based methods consider the cost of features during their decision making process. Is it possible that the results presented in the paper have misspecified this parameter? May be an ablation study  would help me better justify the above surprising behavior of RL-based methods compared to DIME\n\n(5) I noticed in the Appendix that features are in groups. Does DIME use the group structure somehow?\n\n(6) It is unclear to me from the description in the paper if DIME uses a hard feature budget constraint for each data instance or an average constraint or something else. May be you can clarify this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6140/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6140/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6140/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698784046277,
            "cdate": 1698784046277,
            "tmdate": 1700541710237,
            "mdate": 1700541710237,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yKwMrpCAoG",
                "forum": "Oju2Qu9jvn",
                "replyto": "iPrbTdvOLV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iU6i"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for closely examining our work and providing their feedback. We have used the space below to respond to the questions raised in the review. Updates to the manuscript are highlighted in red to make them easily identifiable.\n\n> \u201cI believe that some relevant work on dynamic feature selection that is neither RL-based nor greedy-based is missing\u201d\n\nWe agree that formulating the problem as a POMDP and using a Bayesian network to capture feature dependencies are valid approaches, and we are happy to include other references in the related work. The suggested works are now included in the updated manuscript, with descriptions based on our best understanding of those works.\n\n> \u201cI also believe that the algorithms proposed in the previous references as well as (Janisch et al; 2019) are designed to handle non-uniform costs and variable feature budgets. I think this need to be clearly stated in the paper, since at the moment, it is suggested that only DIME can accommodate such settings\u201d\n\nWe don\u2019t wish to suggest that DIME is the only method that allows non-uniform costs and variable feature budgets. In the original submission, we cite Janisch et al. (2019) and Kachuee et al. (2018) as examples of methods that consider these, see for example the following quote: \u201cFor example, Janisch et al. (2019) formulate DFS as a MDP where the reward is the 0-1 loss minus the feature cost, while considering both variable budgets and non-uniform feature costs.\u201d Notice that we also compare DIME to EDDI and CwCF in Figure 3 where we consider non-uniform costs.\n\nHowever, in the context of greedy approaches for dynamic feature selection, it\u2019s worth noting that most previous works focus on the fixed-budget setting with uniform costs. DIME is therefore unique in enabling these additions to the greedy approach, and this is possible only because it more accurately estimates the CMI in a discriminative fashion. If it is helpful, we can update the manuscript to make this point clearer.\n\n> \u201cThe performance of DIME is very close to Argmax Direct. What is the benefit of using DIME instead of Argmax Direct in that sense?\u201d\n\nThe performance of Argmax Direct approaches that of DIME for two tabular datasets (Intubation and ROSMAP), but for the other 4/6 datasets we tested, DIME substantially outperforms Argmax Direct for almost all feature budgets. Furthermore, DIME addresses real-world challenges that Argmax-Direct cannot address: first, feature acquisition costs are not always identical for all features (e.g., a genetic test takes longer than obtaining demographic features), and second, allowing variable per-sample feature budgets enables quicker diagnosis for certain samples (e.g., it may become immediately clear that a patient with a neck injury needs intubation). Argmax Direct does not estimate the CMI, which means that it cannot be adjusted when using non-uniform feature costs, and the CMI values cannot be incorporated into a stopping criterion (Section 4.3). By estimating the CMI with DIME, we are able to do both of these; the former is crucial to support for some applications, and the latter leads to clear performance improvements under a given average budget. To help readers appreciate these points, we will emphasize them in our revised conclusion."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700023162156,
                "cdate": 1700023162156,
                "tmdate": 1700026956451,
                "mdate": 1700026956451,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5p3XyRQJoH",
                "forum": "Oju2Qu9jvn",
                "replyto": "yKwMrpCAoG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response and the clarifications. I believe it will be beneficial to also include in the revised paper the discussion about handling non-uniform costs and variable feature budgets."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700540115971,
                "cdate": 1700540115971,
                "tmdate": 1700540115971,
                "mdate": 1700540115971,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "V34PvCj0a9",
                "forum": "Oju2Qu9jvn",
                "replyto": "16eIEX6LgJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the clarifications. They have clarified many of the concerns that I had. Regarding the RL vs greedy question, you mentioned about the use of AUROC vs accuracy. I am still wondering if this is not the only reason. As I mentioned earlier, RL-based methods such as CwCF (Janisch et al; 2019) make decisions based on expected misclassification cost and the feature acquisition cost, but DIME uses mutual information to guide feature acquisition. This should play some role, right? In any case, I feel that the Introduction of the paper strongly suggests that RL-based methods are not good alternatives for the problem studied in the paper. However, it seems that there is limited work to suggest that in addition to the fact that it is not for sure that RL is worse, since there are many factors that can influence the final result (e.g., the objective a method optimizes or even the datasets selected for the experiments). I suggest that the Introduction be modified to clarify this point."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700541428496,
                "cdate": 1700541428496,
                "tmdate": 1700541428496,
                "mdate": 1700541428496,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "g7gmZUQTb7",
                "forum": "Oju2Qu9jvn",
                "replyto": "z5C5rpGbQz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                ],
                "content": {
                    "comment": {
                        "value": "The response has addressed most of my comments and I will be raising my score. Nonetheless, I have left a few more comments to be addressed."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700541513622,
                "cdate": 1700541513622,
                "tmdate": 1700541513622,
                "mdate": 1700541513622,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gprrlpS3ut",
                "forum": "Oju2Qu9jvn",
                "replyto": "iPrbTdvOLV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for response"
                    },
                    "comment": {
                        "value": "Thank you for your response and for engaging in the discussion period! We appreciate your comments and have made a couple additional changes to the introduction.\n\n1. We now specify that greedy methods have been found to outperform RL methods in several specific works, rather than making a more general claim. We also mention what we believe is the main reason RL methods currently don't work as well: policy optimization is a much more difficult learning problem. In the DFS context, RL incurs sparse rewards and must explore an exponential state space, so even with an appropriate reward like classification accuracy it's understandably difficult to train. With DIME, learning the greedy CMI policy involves fitting one classifier model (the predictor network) and one regression model (the value network), and training these is nearly as simple as standard supervised learning.\n\n2. We added further clarification that some existing RL methods consider non-uniform costs and variable feature budgets (Janisch et al, Kachuee et al). We added this in the discussion of our contributions, and we clarified that these capabilities are new for greedy CMI-based methods.\n\nThanks again for engaging in the discussion, and we appreciate you adjusting your score!"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700597111984,
                "cdate": 1700597111984,
                "tmdate": 1700616955632,
                "mdate": 1700616955632,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kZ237LkxiT",
                "forum": "Oju2Qu9jvn",
                "replyto": "gprrlpS3ut",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6140/Reviewer_iU6i"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6140/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706203998,
                "cdate": 1700706203998,
                "tmdate": 1700706203998,
                "mdate": 1700706203998,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]