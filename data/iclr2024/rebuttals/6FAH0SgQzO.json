[
    {
        "title": "FedRC: Tackling Diverse Distribution Shifts Challenge in Federated Learning by Robust Clustering"
    },
    {
        "review": {
            "id": "3UoO8ZnqmI",
            "forum": "6FAH0SgQzO",
            "replyto": "6FAH0SgQzO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4308/Reviewer_gsbU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4308/Reviewer_gsbU"
            ],
            "content": {
                "summary": {
                    "value": "This paper studied the federated learning problem with heterogeneous data induced by multiple types of distribution shifts, e.g., feature shift, label shift, and concept shift. To solve this problem, this paper introduced a principle of robust clustering where clients with concept shifts should be clustered together. Then, it proposed a novel FedRC approach (as well as its centralized version RobustCluster) to find the clusters based on the types of distribution shifts. The convergence of RobustCluster was also theoretically analyzed."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**Originality:** This paper studied a more challenging clustered FL setting where multiple types of distribution shifts existed in local clients. It pointed out that the clusters with concept shifts might not learn a common decision boundary, and existing clustered FL approaches failed in handling the concept shifts. This paper then proposed a novel FedRC with concept shift aware objective function. Experiments demonstrated that FedRC achieved better performance than clustered FL baselines in various data sets.\n\n**Quality:** The motivating example in Figures 3&4 clearly illustrated the principles of robust clustering in handling concept shifts. Then the principles of robust clustering also guided the design of the objective function in Eq. (1). The clients with concept shifts were expected to clustered in different groups. The experiments verified the effectiveness of FedRC with respect to local and global generalization performance.\n\n**Clarity:** The motivation of this paper is clear. Different from feature or label shift, concept shift essentially affects the clustering structure. The objective function in Eq. (1) aims to avoid generating clusters with concept shifts. Experiments show that the proposed FedRC significantly outperforms existing clustered FL methods.\n\n**Significance:** The problem studied in this paper is practical but challenging. In real scenarios, different types of distribution shifts occur simultaneously among clients. As a result, adaptively generating clusters based on the types of distribution shifts can be applied to solve real-world federated learning problems."
                },
                "weaknesses": {
                    "value": "**W1:** The impact of feature and label shifts on clustering can be further explained. The goal of the proposed clustered method is to separate clients with concept shifts into different clusters. It might consider clients with feature and label shifts into a single cluster. Thus, the clustering quality can also be affected by the feature and label shifts. For example, a single model might fail to hand clients with large label shifts.\n\n**W2:** The optimization of Eq. (2) is unclear. \n- Firstly, the definition of $\\tilde{\\mathcal{I}}(\\mathbf{x}, y; \\theta_k)$ is confusing. It is defined over the weights $\\gamma_{i,j; k}$, but $\\gamma_{i,j; k}$ is also defined over $\\tilde{\\mathcal{I}}(\\mathbf{x}, y; \\theta_k)$ in Eq. (4). \n- Secondly, the updating in Eqs. (4)(5) are not associated with $\\lambda_i$ in Eq. (2). Then how would the second term of Eq. (2) affect the optimization?\n\n**W3:** The convergence of FedRC is not provided. Theorem 4.3 shows the convergence of the centralized version of FedRC. Can it also hold for federated learning scenarios?\n\n**W4:** Step 2 in Algorithm 1 is not explained. It is unclear why checking and removing models are necessary for FedRC during training."
                },
                "questions": {
                    "value": "**Q1:** Figure 1 is hard to follow. It is confusing how label shift and concept shift are involved in Figure 1.\n\n**Q2:** Section 3 compares different clustered FL algorithms in Figure 3. It shows that existing approaches, e.g., FeSEM, IFCA, are not robust to feature and label shifts. But it is confusing how these observations are indicated in Figure 3.\n\n**Q3:** Does FedRC in Algorithm 1 update $\\gamma_{i,j; k}, w_{i; k}$ once and $\\theta_{i; k}$ for $\\Gamma$ local steps?\n\n**Q4:** How are the models of nonparticipating clients generated during testing in the experiments?\n\n**Q5:** Figure 6(d) shows that FedRC outperforms FedAvg and retains robustness when there is only one concept. When there is only one concept, would FedRC exactly recover FedAvg?\n\n**Q6:** Figure 6(c) shows that FedRC with hard clustering consistently outperforms that with soft clustering. Besides, hard clustering can better satisfy the principles of robust clustering by separating clients with concept shifts into different clusters. In this case, It is confusing why not simply apply hard clustering when optimizing FedRC."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4308/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698111448089,
            "cdate": 1698111448089,
            "tmdate": 1699636399242,
            "mdate": 1699636399242,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GR7ObXy5xc",
                "forum": "6FAH0SgQzO",
                "replyto": "3UoO8ZnqmI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gsbU (1/3)"
                    },
                    "comment": {
                        "value": "Thank you for dedicating your time to review our work. We appreciate your thoughtful feedback and insightful comments, which have undoubtedly enriched the quality of our submission. Below, we address the major concerns you raised:\n\n### W1. The impact of feature and label shifts on clustering can be further explained. The goal of the proposed clustered method is to separate clients with concept shifts into different clusters. It might consider clients with feature and label shifts into a single cluster. Thus, the clustering quality can also be affected by the feature and label shifts. For example, a single model might fail to hand clients with large label shifts.\n\nThank you for your valuable suggestion. We concur with the reviewer's observation that a single model may encounter challenges in handling clients with substantial label shifts. To tackle this issue, we recommend incorporating FedRC with other methods:\n\n- **Integration with algorithms tailored for label shifts:** As depicted in Figure 2 (c), amalgamating FedRC with techniques specifically designed to handle label shifts, such as FedProx and FedDecorr, significantly amplifies performance.\n- **Integration with PFL methods:** As evidenced in Table 4, FedRC can serve as a robust initialization for PFL methods, achieving performance comparable to other PFL methods through fine-tuning with just one local epoch.\n\nFurthermore, we believe that retaining models trained with FedRC, showcasing commendable generalization performance, remains invaluable. For instance, these models can be utilized by non-participating clients without the necessity for further training on model parameters.\n\n### W2 (1). The definition of\u00a0$\\tilde{\\mathcal{I}}(x,y;\\theta_k)$\u00a0is confusing. It is defined over the weights $\\gamma_{i,j;k}$\u00a0, but\u00a0$\\gamma_{i,j;k}$\u00a0is also defined over\u00a0$\\tilde{\\mathcal{I}}(x,y;\\theta_k)$\u00a0in Eq. (4).\n\nWe apologize for any confusion, and we have made enhancements to the revised paper to ensure greater clarity:\n\n- Equation (3) *defines* $\\tilde{\\mathcal{I}}(x,y;\\theta_k)$  by incorporating the sample-level clustering weights $\\gamma_{i, j; k}$.\n- Equation (4) illustrates the *updating process* of $\\gamma_{i, j; k}^{t}$ using information from previous rounds, such as $\\tilde{\\mathcal{I}}(x, y; \\theta_k^{t-1})$.\n\n### W2 (2). The updating in Eqs. (4)(5) are not associated with\u00a0$\\lambda_{i}$\u00a0in Eq. (2). Then how would the second term of Eq. (2) affect the optimization?\n\nThank you for your insightful comment. We have set $\\lambda = \\frac{-N_i}{N}$ to ensure that $\\sum_{k=1}^{K} \\omega_{i;k} = 1$, where $N_i$ represents the number of samples from client $i$, and $N = \\sum_{i=1}^{M} N_i$.\n\nWe have improved the proof in Appendix A in the revised paper by adding the following clarification, emphasizing that the condition $\\sum_{k=1}^{K} \\omega_{i;k} = 1$ is guaranteed only when $\\lambda = \\frac{-N_i}{N}$.  We also list the key steps below.\n\nStarting from Equation (12) in Appendix A, we derive the following expression: $ \\frac{1}{N} \\sum_{j=1}^{N_i} \\frac{\\gamma_{i,j;k}}{\\omega_{i;k}} = -\\lambda_i$.\n\nConsequently, we obtain: $\\omega_{i;k} = -\\frac{1}{N \\lambda_i} \\sum_{j=1}^{N_i} \\gamma_{i,j;k}$.\n\nBy setting $\\sum_{k=1}^{K} \\omega_{i;k} = 1$ and considering that $\\sum_{k=1}^{K} \\gamma_{i,j;k} = 1$, we directly derive the result $\\lambda = \\frac{-N_i}{N}$.\n\n### W3:\u00a0The convergence of FedRC is not provided. Theorem 4.3 shows the convergence of the centralized version of FedRC. Can it also hold for federated learning scenarios?\n\nThank you for your detailed comment. In response to the reviewer's comment, we would like to highlight that we have included a detailed discussion on the convergence of FedRC in Appendix C of our original submission. Our analysis demonstrates that FedRC can achieve a convergence rate of $O(1/\\sqrt{T})$ in federated learning scenarios.\n\n### W4:\u00a0Step 2 in Algorithm 1 is not explained. It is unclear why checking and removing models are necessary for FedRC during training.\n\nWe sincerely apologize for the oversight and appreciate your valuable feedback. We would like to provide clarification regarding the concerns raised:\n\n1. **Explanation of Step 2 in Algorithm 1:**\n    - In our initial submission, Step 2 of Algorithm 1 uses adaptive FedRC to autonomously determine the number of clusters. The detailed explanation is available in Appendix F.\n2. **Addressing Feedback:**\n    - In response to your feedback, we have removed Step 2 from Algorithm 1 on the main pages to streamline the presentation.\n3. **Comprehensive Presentation in Appendix F:**\n    - To maintain the logical consistency of our paper while ensuring the completeness of the algorithmic details, we have incorporated the comprehensive version of Algorithm 1 in its entirety, including the previously omitted Step 2, in Appendix F."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699968923496,
                "cdate": 1699968923496,
                "tmdate": 1699977032252,
                "mdate": 1699977032252,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LGk4nUpmIz",
                "forum": "6FAH0SgQzO",
                "replyto": "3UoO8ZnqmI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gsbU (2/3)"
                    },
                    "comment": {
                        "value": "### Q1:\u00a0Figure 1 is hard to follow. It is confusing how label shift and concept shift are involved in Figure 1.\n\nWe apologize for the oversight regarding missing details. In response to your feedback, we have revised the paragraph as follows:\n\n> Label shifts are represented by clients exhibiting data points of varying colors, as seen in clients 1 and 2. Feature shifts are exemplified by clients maintaining data points with the same color but having substantial distances between them, as observed in clients 2 and 3. Concept shifts occur when data points at the same position have different labels, as evident in clients 2 and 5.\n\nFurthermore, Figure 1 has been revised to illustrate that clients 1, 2, and 3 coexist within the same coordinate space as clients 3, 4, and 5. This modification aims to enhance the clarity of the concept shifts for a more comprehensive understanding.\n\n### Q2:\u00a0Section 3 compares different clustered FL algorithms in Figure 3. It shows that existing approaches, e.g., FeSEM, IFCA, are not robust to feature and label shifts. But it is confusing how these observations are indicated in Figure 3.\n\nThank you for your insightful comment. The depicted observations are elucidated in the 'Class Labels' and 'Feature Styles' rows of Figure 3, where circle sizes are employed to denote sample quantities. \n\nIn the 'Class Labels' row, the x-axis represents 'labels', and the y-axis represents 'clusters'. The circle size at coordinates (y, k) indicates the number of samples with class label $y$ that choose cluster $k$. The findings suggest that in FeSEM, IFCA, and FedEM, samples with shared class labels tend to choose the same cluster. Consequently, when faced with data containing out-cluster labels, cluster models may demonstrate suboptimal performance. \n\nSimilar patterns are evident in the 'Feature Styles' row concerning feature shifts.\n\n### Q3:\u00a0Does FedRC in Algorithm 1 update\u00a0$\\gamma, \\omega$\u00a0once and\u00a0$\\theta$\u00a0for\u00a0$\\mathcal{T}$\u00a0local steps?\n\nIn FedRC, we update the parameters $\\gamma$ and $\\omega$ once during each communication round, while $\\theta$ undergoes an update for $\\mathcal{T}$ local steps. To improve clarity, we have made revisions to the paper, indicating the changes with red lines in Algorithm 1.\n\n### Q4:\u00a0How are the models of nonparticipating clients generated during testing in the experiments?\n\nWe apologize for the confusion. As illustrated in Appendix H.2, when performing tests on non-participating clients, we will utilize the global models stored by the servers directly. Non-participating clients are required to initially update $\\gamma_{i,j;k}$ and $\\omega_{i;k}$ using their corresponding local validation/training datasets before proceeding to the testing phase.\n\nFurthermore, as shown in Appendix H.2, the prediction results are generated by $y_{\\text{pred}} = \\sum_{k=1}^{K} \\omega_{i;k} \\sigma(m_{i,k}(x, \\theta_k))$, where $y_{\\text{pred}}$ is the predicted output, $m_{i,k}(x, \\theta_k)$ is the output of model $\\theta_k$ given data $x$, and $\\sigma$ is the softmax function.\n\n### Q5:\u00a0Figure 6(d) shows that FedRC outperforms FedAvg and retains robustness when there is only one concept. When there is only one concept, would FedRC exactly recover FedAvg?\n\nWe apologize for any confusion and appreciate the opportunity to address the concerns raised by the reviewer. We would like to provide clarification on the following points:\n\n- *In FedRC, the number of concepts may not necessarily align with the number of clusters.* It is important to note that we can set the cluster number $K > 1$ even in scenarios with only one concept. FedRC recovers FedAvg when $K = 1$, but by choosing $K = 3$ in Figure 6 (d), we aim to showcase the performance gain in terms of global test accuracy under non-concept shift conditions.\n- Through our careful observations, we have noted that in scenarios without concept shifts, FedRC tends to concentrate the majority of samples within the same cluster, while also exhibiting outliers in other clusters. Our hypothesis suggests that the observed performance enhancement may be attributed to the effective elimination of outliers within the datasets."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699969132014,
                "cdate": 1699969132014,
                "tmdate": 1699976994191,
                "mdate": 1699976994191,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QsDwSfw0Fe",
                "forum": "6FAH0SgQzO",
                "replyto": "3UoO8ZnqmI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer gsbU (3/3)"
                    },
                    "comment": {
                        "value": "### Q6:\u00a0Figure 6(c) shows that FedRC with hard clustering consistently outperforms that with soft clustering. Besides, hard clustering can better satisfy the principles of robust clustering by separating clients with concept shifts into different clusters. In this case, It is confusing why not simply apply hard clustering when optimizing FedRC.\n\nWe apologize for any confusion and appreciate the opportunity to provide clarification:\n\n- *FedRC with hard clustering in Figure 6 (c) employs hard clustering exclusively during testing while maintaining soft clustering during training.* The revised paper has been updated with red lines to address any ambiguities.\n- *The feasibility of test-time hard clustering arises from the gradual convergence of clustering weights $\\gamma_{i,j;k}$ to $1$ during the training process.* The values of $\\gamma_{i,j;k}$ at the final training epoch are accessible in the **`division-results/`** folder within the updated Supplementary Material.\n- *Optimizing FedRC with hard clustering introduces discrepancies between theory and practice, resulting in a decline in performance.* Theoretically, as outlined in Equations (4), (5), and Theorem 1 of Appendix A, to maximize the objective function defined in Equation (2), optimization of all $K$ models is necessary.\n    \n    Furthermore, we conducted experiments below to demonstrate the performance degradation of FedRC when optimized with hard clustering. The experimental settings are consistent with those depicted in Figure 6 (c). Note that\n    \n    - The (original) FedRC is trained using soft clustering, and the predictions of all models are also ensembled to derive the final prediction results (for further details, refer to Q4).\n    - FedRC + TeHC is trained using soft clustering but only employs the models with the highest clustering weights for prediction.\n    - FedRC + TrHC is both trained and tested using a hard clustering method. This approach optimizes only the models with the highest clustering weights in local optimization steps and also uses a single model for prediction.\n|  | FedRC | FedRC + TeHC | FedRC + TrHC |\n| --- | --- | --- | --- |\n| CIFAR10 | 44.37 | 48.03 | 20.5 |\n| Tiny-ImageNet | 27.79 | 29.23 | 11.47 |"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699969198983,
                "cdate": 1699969198983,
                "tmdate": 1699970624462,
                "mdate": 1699970624462,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tZY0TpWrx2",
                "forum": "6FAH0SgQzO",
                "replyto": "3UoO8ZnqmI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your reply"
                    },
                    "comment": {
                        "value": "Dear Reviewer gsbU\n\nWe sincerely value your insightful review, as it plays a pivotal role in enhancing the quality of our manuscript. Moreover, we have carefully considered your feedback to further refine our paper. To review a summary of these revisions, please visit the [Summary of Revision](https://openreview.net/forum?id=6FAH0SgQzO&noteId=NN4i1FyAoB).\n\nAs the discussion phase comes to a close, we kindly request that you reconsider the score if we have effectively addressed your concerns. Furthermore, we are more than willing to address any additional questions or concerns you may have. \n\nWarmest regards,\n\nAuthors"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700467409561,
                "cdate": 1700467409561,
                "tmdate": 1700467409561,
                "mdate": 1700467409561,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LSgxrLcC5G",
                "forum": "6FAH0SgQzO",
                "replyto": "tZY0TpWrx2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Reviewer_gsbU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Reviewer_gsbU"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up questions"
                    },
                    "comment": {
                        "value": "Thanks for your response. I have some follow-up questions after reviewing the rebuttals.\n\n(1) The explanation on W1 is unclear to me. It mentioned that FedRC could be incorporated with other methods to handle feature and label shifts in each cluster. Does it mean that FedRC is designed for concept shift only? If not, how FedRC can handle concept/label/feature shifts in a unified framework?\n\n(2) Eq. (3) defines $\\tilde{I}$ over $\\gamma_{i,j;k}$ which represents the weight of data assigned to $\\theta_k$. It might be more convincing to explain the definition of $\\gamma_{i,j;k}$ in Eq. (4), e.g., how Eq. (4) is correlated with the weight of data assigned to $\\theta_k$. As shown in the appendix, in Eqs. (4)(5), $w^t_{i,k}$ and $\\theta_k^t$ are derived by optimizing Eq. (2). But $\\gamma_{i,j;k}$ in Eq. (4) is a new definition without much explanation.\n\n(3) If $\\lambda_i = -N_i / N$, the derivation step from Eq. (15) to Eq. (16) in the appendix is confusing. Should $w_{i;k}$ involve the negative term in Eq. (16)?\n\n(4) Why is the checking and removing step necessary for the proposed FedRC method? Does the convergence of FedRC in \nTheorem C consider the impact of the proposed FedRC method? For example, would $\\mathbf{\\Theta}$ include the removed model parameters during training?\n\n(5) Since $\\gamma$ and $w$ are only updated once for each communication, the number of local epochs might balance the training efficiency and the optimality (e.g., Eqs (4)(5)) for maximizing Eq. (2). Though some empirical results are provided in Table 5, it is unclear whether the sensitivity of FedRC w.r.t. the number of local epochs is induced by the sub-optimal $\\gamma$ and $w$."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700507544532,
                "cdate": 1700507544532,
                "tmdate": 1700507544532,
                "mdate": 1700507544532,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6HhghPchf8",
                "forum": "6FAH0SgQzO",
                "replyto": "3UoO8ZnqmI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Follow-up Questions (2/2)"
                    },
                    "comment": {
                        "value": "### 4. Why is the checking and removing step necessary for the proposed FedRC method? Does the convergence of FedRC in Theorem C consider the impact of the proposed FedRC method? For example, would $\\Theta$ include the removed model parameters during training?\n\nThank you for bringing this to our attention. We appreciate the opportunity to clarify a few key points:\n\n- **Checking and removing steps are optional:** It's important to note that the checking and removing steps are not necessary. We have explicitly removed these steps in Algorithm 1 in the main paper. In Appendix I and F, we delve into practical enhancements for FedRC, exploring techniques such as the checking and removing step, privacy-preserving methods, and Adam-like clustering weights updating. However, we want to emphasize that these techniques are not obligatory for FedRC.\n- **The theory part considers the original FedRC:** The convergence analysis provided in the theory section addresses the original FedRC, specifically referring to Algorithm 1. The techniques explored in Appendix I and F, including the aforementioned checking and removing step, are not considered in the theory part. We agree with the reviewer that it would be an interesting future direction to give a more comprehensive theoretical understanding when adding all the practical techniques together.\n\n### 5. Since $\\gamma$ and $\\omega$ are only updated once for each communication, the number of local epochs might balance the training efficiency and the optimality (e.g., Eqs (4)(5)) for maximizing Eq. (2). Though some empirical results are provided in Table 5, it is unclear whether the sensitivity of FedRC w.r.t. the number of local epochs is induced by the sub-optimal $\\gamma$ and $\\omega$\n\nThank you for your insightful comments and suggestions. In response to your query about the sensitivity of FedRC to suboptimal values of $\\gamma$ and $\\omega$, we would like to demonstrate that the experiments in Table 5 show that FedRC performs relatively robustly under variations in the number of local epochs. Furthermore, we would like to provide some theoretical insights here. \n\nTheoretically, the sub-optimal $\\gamma$ and $\\omega$ may hinder the convergence at the initial stages of the training: \n\n- **Preliminaries on the impact of the number of local epochs and the update of clustering weights on the convergence of FedRC.** In Appendix C, we demonstrated the construction of the surrogate function $g_i$ satisfying all the requirements outlined in [1]. Utilizing this surrogate optimization framework, we can directly derive the convergence analysis.\n    \n    By extending Lemma G.1 from [1], the single-round convergence $\\mathbb{E} [\\mathcal{L}(\\Theta^{t+1},\\Omega^{t+1}) - \\mathcal{L}(\\Theta^{t},\\Omega^{t})]$ can be lower-bounded by the sum of \n    \n    1. the KL divergence between clustering weights $\\frac{1}{N} \\sum_{i=1}^{M} \\sum_{j=1}^{N_i} KL (\\gamma_{i,j;k}^{t+1} \\|\\| \\gamma_{i,j;k}^{t})$, \n    2. the gradient norms of $\\Theta^{t}$, denoted by $\\frac{\\mathcal{T}}{4} \\mathbb{E} [ \\|\\| \\nabla_{\\Theta} L(\\Theta^{t}, \\Omega^{t}) \\|\\|^2]$,\n    3. certain negative constants measuring client drifts and related to $\\mathcal{T}$. \n- **The local epochs hinder the convergence of FedRC due to client drifts.** To expedite convergence, we aim to maximize the single-round convergence $\\mathbb{E} [\\mathcal{L}(\\Theta^{t+1},\\Omega^{t+1}) - \\mathcal{L}(\\Theta^{t},\\Omega^{t})]$. Consequently, we observe that the terms related to $\\mathcal{T}$ that *slow down convergence are the constant terms measuring client drifts, not related to $\\gamma$*.\n- **Negative impacts of sub-optimal $\\gamma$ and $\\omega$ reduce after the initial stages of training.** According to Theorem C.1, the clustering weights $\\omega_{i;k} = \\frac{1}{N_i} \\sum_{j=1}^{N_i} \\gamma_{i,j;k}$ converge faster than the parameters $\\theta_k$. Thus, during the initial stages of training, when $\\gamma_{i,j;k}^{t+1}$ and $\\gamma_{i,j;k}^{t}$ vary significantly, the induced error will be large. However, beyond the initial stages of training, the clustering weights tend to converge, mitigating the induced error attributable to sub-optimal $\\gamma$ and $\\omega$.\n\n[1] Marfoq, Othmane, et al. \"Federated multi-task learning under a mixture of distributions.\"\u00a0*Advances in Neural Information Processing Systems*\u00a034 (2021): 15434-15447."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700553851630,
                "cdate": 1700553851630,
                "tmdate": 1700554165123,
                "mdate": 1700554165123,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8tOaUfOQaS",
                "forum": "6FAH0SgQzO",
                "replyto": "6HhghPchf8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Reviewer_gsbU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Reviewer_gsbU"
                ],
                "content": {
                    "title": {
                        "value": "Comments"
                    },
                    "comment": {
                        "value": "(1) If I understand correctly, the proposed FedRC method can perform clustering based on concept shift, no matter whether other types (feature/label) of distribution shifts exist or not. It is a generic strategy to handle concept shifts, and it can identify concept shifts even when other distribution shifts exist among clients. But FedRC cannot directly handle the feature/label shifts in each cluster. Please correct me if there is any misunderstanding.\n\n(2) Did all the experiments in the paper use Algorithm 1 without the checking and removing step? Is there any result to show the impact of this step on the proposed algorithm? In addition, it seems that in the submitted code, lines 285-288 in \"run_experiments.py\" involve a \"remove_learner\" step. Does this correspond to the checking and removing step?"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700601938607,
                "cdate": 1700601938607,
                "tmdate": 1700601938607,
                "mdate": 1700601938607,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jR9nO2FTfo",
            "forum": "6FAH0SgQzO",
            "replyto": "6FAH0SgQzO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4308/Reviewer_kcSi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4308/Reviewer_kcSi"
            ],
            "content": {
                "summary": {
                    "value": "This paper identifies the learning challenges posed by the simultaneous occurrence of diverse distribution shifts and propose a clustering principle to overcome these challenges, i.e., separating clients with concept shifts into different clusters, while keeping clients without concept shifts in the same cluster.\nThe principle is further translated into a bi-level optimization problem which are provided with an efficient and convergent optimizer. \nExtensive experiments demonstrate that FedRC significantly outperforms other SOTA."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper identifies an important problem 'ensuring global performance when multiple types of distribution shifts occur simultaneously among clients'. The illustration of Figure 1 clearly shows the motivation.\n2. The algorithm comes with theoretic analysis including convergence proof for FedRC as well as RobustCluster.\n3. The experiments are presented with sufficient details, such as ablations and experiments on real-world concept shift data. Great effort."
                },
                "weaknesses": {
                    "value": "1. Section 6, it seems 'future work' has already been done by the appendix. Better find 'real' future work or change the title of the last section.\nThe same goes for 'Limitations'.\n2. It seems that FedRC outperforms previous SOTA by a large margin. The success of FedRC seems lie in the objective funtion eq. (8). However, there is a lack of theoretic comparison between eq. (8) and the obj. func of existing methods."
                },
                "questions": {
                    "value": "no"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4308/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4308/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4308/Reviewer_kcSi"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4308/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698584500427,
            "cdate": 1698584500427,
            "tmdate": 1699636399175,
            "mdate": 1699636399175,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "B4Jf6ZiuCS",
                "forum": "6FAH0SgQzO",
                "replyto": "jR9nO2FTfo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer kcSi"
                    },
                    "comment": {
                        "value": "Thank you sincerely for your positive review of our work. We also greatly appreciate your constructive comments. We have carefully considered the main concerns you raised and address them below.\n\n### 1. Section 6, it seems 'future work' has already been done by the appendix. Better find 'real' future work or change the title of the last section. The same goes for 'Limitations'.\n\nThank you for your valuable suggestion. We have revised Section 6 to the following paragraph:\n\n> This paper addresses the diverse distribution shift challenge in FL and proposes using clustered FL methods to tackle it. However, we found that none of the existing clustered FL methods effectively address the diverse distribution shift challenge, leading us to introduce FedRC as a solution. Furthermore, we have explored extensions in Appendix I and Appendix F, including improvements in communication and computation efficiency, automatic determination of the number of clusters, and mitigation of the personalization-generalization trade-offs. For future research, delving deeper into providing a more comprehensive theoretical understanding of the distinctions in clustering results between FedRC and other methods would be intriguing.\n> \n\nIn summary, we simplified the discussion of the techniques in the Appendix and introduced a 'real' future work based on the reviewer's suggestion.\n\n### 2. It seems that FedRC outperforms previous SOTA by a large margin. The success of FedRC seems lie in the objective function eq. (8). However, there is a lack of theoretic comparison between eq. (8) and the obj. func of existing methods.\n\nThank you for your insightful comment. We appreciate your feedback. We would like to clarify that while Equation (8) updates clustering weights $\\omega$, it does not explicitly define our objective functions. We presume that you are referring to Equation (1), which indeed defines the objective function of FedRC.\n\nWe acknowledge that providing an in-depth theoretical analysis of the distinctions between the clustering results obtained from Equation (1) and existing methods is challenging. However, we can delve into a discussion on the design of the objective function.\n\nOur paper includes an illustrative example to highlight the advantages of Eq (1). In Figure 9 of Appendix G, we compare RobustClustering with the traditional EM algorithm that maximizes the log-likelihood functions. The results in Figure 9 indicates:\n\n1. **Limitation of the EM Algorithm:**\n    - Confronted with inputs featuring concept shifts and a poor initialization of $p(x, y; \\theta_k)$, the EM algorithm tends to converge to suboptimal local optima. In these cases, the samples with concept shifts often get erroneously assigned to the same cluster, resulting in subpar classification outcomes.\n2. **Advantages of RobustClustering:**\n    - In contrast, the RobustClustering algorithm showcases its ability to automatically adjust cluster assignments. This adaptive nature allows it to navigate away from unfavorable local optimums, leading to superior classification results for all samples, even in the presence of concept shifts.\n\nThese observations underscore the robustness and effectiveness of our proposed RobustClustering method, especially in scenarios where traditional EM algorithms may struggle due to poor initialization and concept shifts, as illustrated in Figure 9 and experiment results in Tables 1 and 2."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699967950018,
                "cdate": 1699967950018,
                "tmdate": 1699970564614,
                "mdate": 1699970564614,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sKCcKHvNmc",
            "forum": "6FAH0SgQzO",
            "replyto": "6FAH0SgQzO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4308/Reviewer_xiXR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4308/Reviewer_xiXR"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes FedRC, a novel algorithm framework based on soft clustering, to ensure global model performance when multiple types of distribution shifts occur in clients' data, including feature shift, label shift, and concept shift. Specifically, FedRC addresses the challenges posed by distribution drift by combining the proposed clustering principles with a dual level optimization problem and a new objective function. The main contributions of this paper are: \n1) This paper proposes the principle of robust clustering to address the challenges posed by multiple data distribution drift.\n2) This paper proposes that FedRC implement robust clustering principles and provides theoretical analysis.\n3) This paper conducts experiments on multiple datasets to demonstrate the effectiveness of the proposed method and FedRC can be integrated with existing methods."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1)\tThe paper is technically well presented.\n2)\tThe proposed method is well-motivated and novelty, the analysis of the related work is clear and convincing.\n3)\tThe paper provides rigorous theoretical analysis of the proposed method. \n4)\tThe authors do a lot of experiments to prove that their method is good and compare it with many existing methods, the results seem convincing."
                },
                "weaknesses": {
                    "value": "1) It will be clearer if there is a workflow diagram to explain the working principle of the proposed method. \n2) According to the robust clustering principle proposed by the author, clients with concept drift are classified into different categories. It will be more convincing if the division results are presented. \n3) In Tables 1, 2, and 4, some methods have very low accuracy on CIFAR100 or Tiny-ImageNet datasets. Authors should provide reasons for the very low accuracy in experimental analysis. \n4) The writing of some symbols should be unified. In Eq. (1), $x_{ij}$ and $y_{ij}$ should be $x_{I,j}$, and $y_{I,j}$."
                },
                "questions": {
                    "value": "1) Concept shift has two cases: \u201csame label different features\u201d and \u201csame feature different labels\u201d, Can the FedRC ignore the difference between the two concept shifts in this paper? \n2) Figure 2 (a) is not mentioned in the main text. And according to the results in Figure 2 (a), there is concept drift in scenarios with significant improvement in FedRC. Is FedRC only more effective for concept drift? \n3) In section 4.1, the authors claim that If (x, y) exhibits the concept shift with respect to the distribution of cluster k, P (y | x; \u03b8_k) will be small. Please give a detailed explanation.\n4) In Algorithm 1, does each client need to calculate local update for each clustering model? If so, should loops be added to k models in local update? \n5) The title of Figure 5 mentions' Both groups have IID training and test datasets'. Does 'IID' here refer to the overall data distribution of all clients or the data distribution of each client? If the data distribution of the clients is IID, does it conflict with the settings of the participating clients?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4308/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4308/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4308/Reviewer_xiXR"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4308/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698713760190,
            "cdate": 1698713760190,
            "tmdate": 1699636399086,
            "mdate": 1699636399086,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "S13gsbaBZy",
                "forum": "6FAH0SgQzO",
                "replyto": "sKCcKHvNmc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xiXR (1/3)"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your positive review and are grateful for the time and effort you dedicated to providing valuable feedback. Please find our responses to the major concerns below.\n\n### 1. It will be clearer if there is a workflow diagram to explain the working principle of the proposed method.\n\nThank you for your suggestion! As per your recommendation, we have incorporated Figure 10 into the revised version of the paper to provide the workflow diagram illustrating the whole optimization process of FedRC.\n\n### 2. According to the robust clustering principle proposed by the author, clients with concept drift are classified into different categories. It will be more convincing if the division results are presented.\n\nThank you for your valuable suggestion. In response, we have incorporated the division results of FedRC in various formats in our revised submission.\n\n1. **Visualization about the division results in Appendix I.2:** We have introduced a visual representation in Appendix I.2 using circles of varying sizes to depict the number of samples belonging to each cluster. The division results of FedRC on CIFAR10, CIFAR100, and Tiny-Imagenet datasets are presented in this format. Our results consistently demonstrate the successful achievement of FedRC in assigning data samples with concept shifts to different clusters.\n2. **Raw Files on Division Results:** Additionally, we have incorporated raw files that contain the distribution of clustering weights for each sample at the end of training in the updated Supplementary Material. These files are now organized within the **`division-results/`** folder. Each file follows a structure with $N$ rows, where $N$ denotes the count of training samples. Within each row, the values represent (concept_id, label_id, feature_style_id, clustering weights). It is important to note that rows with concept_id pairs (1 and 2), (3 and 5), and (4 and 6) correspond to identical concepts.\n\nWe hope these additional information provide a clearer understanding of the division results of FedRC in our paper.\n\n### 3. In Tables 1, 2, and 4, some methods have very low accuracy on CIFAR100 or Tiny-ImageNet datasets. Authors should provide reasons for the very low accuracy in experimental analysis.\n\nThank you for your comprehensive feedback. The notably low accuracies can be attributed primarily to the following factors:\n\n- *Clustered FL methods, with the exception of FedRC, struggle to handle concept shifts.* The presence of concept shifts within a single classifier significantly impacts the model's performance, as empirically investigated in existing literature [1].\n- *The PFL methods exhibit notably low global accuracy, primarily attributable to the simultaneous presence of concept shifts and overfitting to local distribution.*\n    - As elucidated in [2], PFL methods have a tendency to overfit local distributions, resulting in elevated local performance but diminished global performance, as demonstrated in Table 4 of our paper.\n    - In our study, global accuracy is computed by averaging across all test clients for each concept. The challenge arises from the difficulty of generalizing personalized models trained on individual concepts to other concepts, leading to a further reduction in the reported global accuracy of PFL methods.\n\n### 4. The writing of some symbols should be unified. In Eq. (1),\u00a0$x_{i,j}$\u00a0and\u00a0$y_{i,j}$\u00a0should be\u00a0$x_{I,j}$ and\u00a0$y_{I,j}$.\n\nThank you for your insightful suggestions! Following your guidance, we carefully reviewed the notations in Equation (1), focusing on $x_{i,j}$ and $y_{i,j}$. We observed that the current version might be correct regarding its contexts.\n\nTo avoid overlooking any details, we kindly request the reviewer to provide additional information, enabling us to pinpoint and address any potential problems that may have eluded us. Your further guidance will be invaluable in refining our work."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699967627679,
                "cdate": 1699967627679,
                "tmdate": 1699970516015,
                "mdate": 1699970516015,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mPHIZvpWTF",
                "forum": "6FAH0SgQzO",
                "replyto": "sKCcKHvNmc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xiXR (2/3)"
                    },
                    "comment": {
                        "value": "### 5. Concept shift has two cases: \u201csame label different features\u201d and \u201csame feature different labels\u201d, Can the FedRC ignore the difference between the two concept shifts in this paper?\n\nWe apologize for any confusion and appreciate the opportunity to provide further clarification regarding the definition of concept shifts in our paper. Additionally, we have added Appendix J to incorporate the discussions below into our revised paper.\n\nFollowing the definitions outlined in the dataset shift literature, specifically Definition 4 in [3] and Source 2 in [4], we categorize concept shifts into the following classifications:\n\n1. Instances where $p_{i}(y|x) \\neq p_{j}(y|x)$ and $p_{i}(x) = p_{j}(x)$ in $X \\to Y$ problems, indicating \"same feature different labels.\"\n2. Instances where $p_{i}(x|y) \\neq p_{j}(x|y)$ and $p_{i}(y) = p_{j}(y)$ in $Y \\to X$ problems, signifying \"same label different features.\"\n\nHere, $X \\to Y$ denotes the utilization of $X$ as inputs to predict $Y$. Following most studies in FL [5, 6, 7], this paper focuses on the $X \\to Y$ problems, thereby investigating \"same feature different labels\" problems.\n\nMoreover, within the context of $X \\to Y$ problems, we contend that \"same label different features\" aligns more closely with the definition of \"feature shift\" rather than concept shift, as depicted in Clients 2 and 3 of Figure 1. Notably:\n\n1. Feature shift scenarios, such as those involving augmentation methods (CIFAR10-C, CIFAR100-C) employed in our paper or natural shifts in domain generalization, often give rise to \"same label different features\" issues.\n2. In \"same label different features\" scenarios, where the same $x$ is not mapped to different $y$ values, shared decision boundaries persist, obviating the need for assignment into distinct clusters.\n\nConsequently, we treat the challenge of \"same feature different labels\" as a manifestation of \"feature shift\" in this paper. We hope that this clarification enhances the understanding of definitions.\n\n### 6. Figure 2 (a) is not mentioned in the main text. And according to the results in Figure 2 (a), there is concept drift in scenarios with significant improvement in FedRC. Is FedRC only more effective for concept drift?\n\nThank you for your feedback; we have added the reference to Figure 2 (a) in the Introduction section.\n\nThe FedRC exhibits superior global accuracy, even in the absence of concept shifts. For instance, as illustrated in Table 7, FedRC showcases a notable improvement of 2.3% in global accuracy compared to alternative methods. Furthermore, the performance advantage of FedRC becomes even more pronounced in scenarios involving concept shifts."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699967703027,
                "cdate": 1699967703027,
                "tmdate": 1699970531194,
                "mdate": 1699970531194,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OGvc6KVQAi",
                "forum": "6FAH0SgQzO",
                "replyto": "sKCcKHvNmc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4308/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xiXR (3/3)"
                    },
                    "comment": {
                        "value": "### 7. In section 4.1, the authors claim that If (x, y) exhibits the concept shift with respect to the distribution of cluster k, P (y | x; \u03b8_k) will be small. Please give a detailed explanation.\n\nThank you for your detailed suggestion! The assertion is grounded in the definition of concept shifts:\n\n- Concept shifts (please refer to Question 5 for the formal definition) are defined by the inequality $p_{j}(y|x) \\neq p_{i}(y|x)$ for distributions $i$ and $j$. If we consider $\\theta_i$ as the parameters trained on distribution $i$, the probability density of in-distribution samples $(x, y_{i})$ will inherently surpass that of out-distribution samples $(x, y_{j})$. This phenomenon is widely leveraged in research domains such as concept drift detection [4].\n- To illustrate this phenomenon, let's examine a simple example. Assume the distribution parametrized by $\\theta_k$ includes data points $(x, y) = (1, 1)$ and $(x, y) = (2, 2)$. Consequently, we have $p(1|1;\\theta_k) = 1.0$ and $p(2|2;\\theta_k) = 1.0$. In the occurrence of concept shifts, where the same $x$ is associated with different $y$ values, as in the cases of $(1, 2)$ and $(2, 1)$, we observe that $p(2|1;\\theta_k) = 0.0$ and $p(1|2;\\theta_k) = 0.0$.\n\n### 8. In Algorithm 1, does each client need to calculate local update for each clustering model? If so, should loops be added to k models in local update?\n\nThank you for your valuable suggestion, and we apologize for the oversight in missing details. In response to your comments, we have included '$\\forall k$' in line 7 of the revised manuscript.\n\n### 9. The title of Figure 5 mentions' Both groups have IID training and test datasets'. Does 'IID' here refer to the overall data distribution of all clients or the data distribution of each client? If the data distribution of the clients is IID, does it conflict with the settings of the participating clients?\n\nWe apologize for any confusion regarding the experiment settings. In the original statement, 'IID' denoted that the training and test distributions of each client are identical, but it may not have been clear that individual clients have distinct local distributions. To provide clarity, we have revised the sentence in the paper to state: 'The training and test distributions of each client are identical.\n\n[1] Shuqi Ke, Chao Huang, and Xin Liu. Quantifying the impact of label noise on federated learning. Arxiv 2022.\n\n[2] Shanshan Wu, Tian Li, Zachary Charles, Yu Xiao, Ziyu Liu, Zheng Xu, and Virginia Smith. Motley: Benchmarking heterogeneity and personalization in federated learning. Arxiv 2022.\n\n[3] Moreno-Torres J G, Raeder T, Alaiz-Rodr\u00edguez R, et al. A unifying view on dataset shift in classification. PR 2012.\n\n[4] Lu J, Liu A, Dong F, et al. Learning under concept drift: A review. IEEE TKDE 2018.\n\n[5] McMahan B, Moore E, Ramage D, et al. Communication-efficient learning of deep networks from decentralized data. AISTATS 2017.\n\n[6] Li T, Sahu A K, Zaheer M, et al. Federated optimization in heterogeneous networks. MLSys 2020.\n\n[7] Karimireddy S P, Kale S, Mohri M, et al. Scaffold: Stochastic controlled averaging for federated learning. ICML 2020."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4308/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699967779620,
                "cdate": 1699967779620,
                "tmdate": 1699970550910,
                "mdate": 1699970550910,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]