[
    {
        "title": "On the Joint Interaction of Models, Data, and Features"
    },
    {
        "review": {
            "id": "qWHw7eZQQW",
            "forum": "ze7DOLi394",
            "replyto": "ze7DOLi394",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6358/Reviewer_PinD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6358/Reviewer_PinD"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a novel framework for analyzing feature learning in deep NNs, from the perspective of observed phenomena occurring in trained networks. The learnt features in a trained model are defined as the principal components of the last layer's activations, and the proposed interaction tensor examines these feature representations of a dataset for a set of models. The interaction tensor is used to empirically validate several common-sense intuitions, such as feature distribution being long-tailed, which then leads to a further abstracted framework for combinatorial-style analysis. This framework is able to theoretically demonstrate empirical phenomena from the observations as well as prior works such as GDE."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- Due to the increasingly complex nature of deep networks, the concept of studying feature learning's observed phenomena like a natural science is a useful supplement to more derivation-based frameworks such as NTK\n- The combinatoric analysis is a creative and original perspective for studying feature learning. While the simplifications might seem a little overly-simplistic at first, the experiments in section 6 and observations in section 4 serve as adequate motivation\n- The resulting findings of the framework not only validate but add nuance to understanding of prior phenomena such as GDE"
                },
                "weaknesses": {
                    "value": "- Like any theoretical framework, many assumptions went into the combinatorial analysis. In particular, this framework assumes features and datapoints are each either dominant *or* rare, a dominant/rare datapoint always has the same number of dominant/rare features, etc\n- The framework is less useful for understanding the learning process of networks, such as why some runs might collapse while others successfully learn the desired features\n- Some minor typos: section 5, data generating process paragraph's second-to-last sentence samples $n_r$ rare, not dominant, features. Appendix C, equation line 34 the two $\\not = \\emptyset $ could maybe instead be $= \\emptyset$"
                },
                "questions": {
                    "value": "- While simplifying features and datapoints to be either dominant *or* rare is good enough for the section 6 experiments, have you considered modeling the rare-dominant variation as a spectrum instead of a binary? For instance, looking at figure 2b, I'm not sure where I would want to draw a line to separate the rare from the dominant features. Even putting the line somewhere around x=6.5, there is still a relatively large deal of variation of frequency of occurrence in both the rare and the dominant feature types"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6358/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6358/Reviewer_PinD",
                        "ICLR.cc/2024/Conference/Submission6358/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6358/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698264625909,
            "cdate": 1698264625909,
            "tmdate": 1700418200862,
            "mdate": 1700418200862,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zWmXlbhOHL",
                "forum": "ze7DOLi394",
                "replyto": "qWHw7eZQQW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PinD"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful feedback! We are glad that you still find our work original and creative.\n\n> many assumptions went into the combinatorial analysis.\n\nWe fully agree that many assumptions were made. The way we see it is that deep learning's complexity necessitates some level of simplification for tractable analysis. In this case, since the resulting framework is still useful for understanding empirical phenomena, we feel the assumptions are justified. \n\n> The framework is less useful for understanding the learning process of networks\u2026\n\nThis is correct. The framework as it stands does not describe the learning process, which is an extremely complicated subject itself. However, we postulate that techniques similar to [1] could be used to study the optimization of a feature model like ours in the future.\n\n> typos\n\nThank you for the close reading and for catching these typos! We have fixed them in the revision.\n\n> have you considered modeling the rare-dominant variation as a spectrum instead of a binary?\n\nThis is an excellent question! We have indeed considered the possibility of modeling it as a spectrum, which we discussed in Appendix D.1 and D.4. In our preliminary investigation, we found that modeling the feature spectrum may require introducing more free parameters (e.g., Zipf\u2019s distribution), and can drastically increase the complexity of analysis. Given that this is our first foray into the topic, we opted for the simpler binary model. This is an important problem and we plan to explore it in more detail in future works.\n\nWe hope these responses have addressed some of the questions and we are open to further discussion. Thank you again for your constructive feedback!\n\n**Reference**\n\n[1] Towards understanding ensemble, knowledge distillation and self-distillation in deep learning. Allen-Zhu et al."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110721284,
                "cdate": 1700110721284,
                "tmdate": 1700111677813,
                "mdate": 1700111677813,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2sMTpi9NQA",
                "forum": "ze7DOLi394",
                "replyto": "zWmXlbhOHL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_PinD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_PinD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed response; I agree with the justifications provided and also appreciate your efforts with the other reviewer to improve the notation. I think the work presents a very novel analysis perspective and will raise my review to an 8."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700418182814,
                "cdate": 1700418182814,
                "tmdate": 1700418182814,
                "mdate": 1700418182814,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RUsLYJEhvF",
            "forum": "ze7DOLi394",
            "replyto": "ze7DOLi394",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6358/Reviewer_MLur"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6358/Reviewer_MLur"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the interaction tensor, for empirically analyzing the interaction between data and model through features. Based on some observations using this tensor, they propose a very simple toy model (a combinatorial model) for feature learning. They show that this model also exhibits Generalization Disagreement Equality (GDE). Finally, the authors use their model to provide data distributions that break GDE in real world experiments."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The problem of feature learning is quite important and there has been a lot of attempts for gaining a better theoretical understanding of it in recent years.\n\n- The authors are able to come up with a toy model that shows GDE which is a very important phenomenon (and it does need the explicit assumption of calibration).\n\n- The model that the authors propose is simple and it can be analyzed fully.\n\n- The paper is very well-written."
                },
                "weaknesses": {
                    "value": "- I definitely agree with \"the empirical phenomena of deep learning can be understood at many different layers of\nabstraction\". However, I think the model proposed in this paper is too simplistic. The implicit biases of deep learning are core to some of the merging phenomenon that we see these days and the models that the authors propose fails to capture that. I also think that a good toy model should leave the door open to generalizations and getting closer to real world practice (for example, for the random features model of deep learning, there is a very obvious way to move towards making it more realistic). But the models that the authors propose is too abstract and it is not clear what simplifications are made to the real problem to arrive at the proposed model.\n\n- Although the model is based on some observations using the interaction tensor, I still find the model to be not very well motivated. Any insights on how this can relate to the training of deep nets?\n\n- It is not very clear how the authors set the hyperparameters in their model (e.g., the thresholds).\n\n- The notations are a bit confusing (i, j, k, etc.). I suggest authors avoid using these generic letters. Also, the paper will benefit greatly from a figure that summarizes all the notations (p_d, p_r, etc.). It will also help explain the method.\n\n- The authors \"prove\" GDE in their model without the explicit assumption of calibration. But the model is very abstract/high-level and I'm not sure if the assumptions that they make are stronger or weaker than calibration.\n\n- The theoretical understanding of feature learning is not as rudimentary as the authors claim. For example,\n\n[1] Alex Damian, Jason Lee, and Mahdi Soltanolkotabi. Neural networks can learn representations with gradient descent, 2022.\n\n[2] Zhichao Wang, Andrew Engel, Anand Sarwate, Ioana Dumitriu, and Tony Chiang. Spectral evolution and invariance in linear-width neural networks, 2022.\n\n[3] Eshaan Nichani, Alex Damian, and Jason D Lee. Provable guarantees for nonlinear feature learning in three-layer neural networks, 2023.\n\n\n[4] Yatin Dandi, Florent Krzakala, Bruno Loureiro, Luca Pesce, and Ludovic Stephan. Learning two-layer neural networks, one (giant) step at a time, 2023.\n\n[5] Behrad Moniri, Donghwan Lee, Hamed Hassani, and Edgar Dobriban, A theory of non-linear feature learning with one gradient step in two-layer neural networks, 2023.\n\nand many more."
                },
                "questions": {
                    "value": "- Looking at figure 3 (a) and 3 (c), it seems that the observations made from them are not that significant. Am I missing something? How does the choice of the thresholds affect your observations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6358/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6358/Reviewer_MLur",
                        "ICLR.cc/2024/Conference/Submission6358/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6358/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698679964676,
            "cdate": 1698679964676,
            "tmdate": 1700352059176,
            "mdate": 1700352059176,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WOHn3t1SAU",
                "forum": "ze7DOLi394",
                "replyto": "RUsLYJEhvF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer MLur (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your detailed review and thoughtful feedback. We are glad that you find the problem we study timely and important. Below are our responses to your concerns:\n\n> I definitely agree with \"the empirical phenomena of deep learning can be understood at many different layers of abstraction\". However, I think the model proposed in this paper is too simplistic\u2026\n\nWe definitely agree that our model is unconventional and more abstract than most existing works but similar assumptions have been made in prior work [6]. As is the case for all theoretical models, simplifications are required to keep analysis tractable. Despite the simplification, our model already exhibits some interesting behaviors and offers insight into empirical phenomena so we believe that it adds value to the current discussion on feature learning. \n\nIn the case of random feature models, we feel that it is a little unfair to say in hindsight that there was a very obvious way to move towards making it more realistic. When NTK first came out in 2018, it was thought to be very promising. Indeed, despite its simplification, it offers clear value in the analysis of some phenomena in deep networks. However, it only later became clear that there was a big gap between NTK and real deep learning (despite many efforts to close this gap). More recent works (many of which you already brought up) rely on quite distinct analysis tools than those used in NTK and, still, it\u2019s not clear if any of them is close to real-world practice.  As such, while we agree (and have acknowledged in Section 5, Appendix D.1 and D.4) that there is a gap between our proposed framework and practice, we feel it\u2019s a tall order for the current state of deep learning theory to have no strong assumptions.  Just like NTK analysis, we hope that our approach will ultimately prove valuable (albeit along different dimensions), despite its simplicity.\n\n> Although the model is based on some observations using the interaction tensor, I still find the model to be not very well motivated. Any insights on how this can relate to the training of deep nets?\n\nThe primary goal of our work is to investigate the effect of different features being learned by different models on GDE and the calibration of deep ensembles, both of which are robust empirical observations. While our model does not directly provide insights into training, understanding these feature interactions may indirectly inform training strategies in the future. For example, [6] shows potential avenues for how observations like ours may transfer to training.\n\n> It is not very clear how the authors set the hyperparameters in their model (e.g., the thresholds).\n\nAs detailed in Appendix F.10 (referred to at the end of Section 4), our conclusions are robust across a range of parameter settings so we believe that the settings used in our paper should be appropriate for most situations.\n\n> The notations are a bit confusing ($i, j, k$, etc.). I suggest authors avoid using these generic letters. Also, the paper will benefit greatly from a figure that summarizes all the notations ($p_d, p_r$, etc.). It will also help explain the method.\n\nWe apologize for the confusion. There is already a centralized list of notations in Appendix A which we could not include in the main text due to space constraints (this is referred to in the second paragraph of section 5). Beyond this, could you be more specific about where the $i,j,k$ are causing confusion so we could better address the confusion? $i,j,k$ are used to denote an arbitrary member of the ordered collection so we feel this is in accordance with the standard usage.\n\n> But the model is very abstract/high-level and I'm not sure if the assumptions that they make are stronger or weaker than calibration.\n\nWe want to clarify that we *do not* claim that the assumptions we make are weaker than calibration (since neither is a clear superset of the other), but we do believe that it sheds more light on the underlying reasons behind GDE. Only stating the model is calibrated does not tell us much about the model or the data, but our assumptions do. In fact, our framework tells us how one can break our assumption (and calibration) through data distribution interventions. Of course, it is an important open question why so many natural distributions seem to satisfy these assumptions."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110446527,
                "cdate": 1700110446527,
                "tmdate": 1700190200046,
                "mdate": 1700190200046,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1ebf5x8nMf",
                "forum": "ze7DOLi394",
                "replyto": "RUsLYJEhvF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer MLur (2/2)"
                    },
                    "comment": {
                        "value": "> The theoretical understanding of feature learning is not as rudimentary as the authors claim\n\nWe sincerely apologize for the characterization. Perhaps \u201crudimentary\u201d is not the best description. We have revised the phrase to be \u201cstill in early development\u201d to better convey the sentiment. However, we do feel that it is reasonable to say that we still have much to understand about feature learning. \n\nTo briefly address the specific works you mentioned: these models generally assume the input data are isotropic Gaussian and the function class is a 2 layer MLP. The feature is usually a linear function of the input and often special training algorithms are needed (e.g., layer-wise training). A notable exception is [3] which learns non-linear features but still requires layer-wise training. \nMost of these works are quite recent (and all came out after we started this project): [3,4,5] showed up in October 2023 and [2] was updated in November 2023. In general, it is hard to say how well they encapsulate the full complexity of deep learning, or how feasible it is to apply them to modern architectures and datasets. Nonetheless, the goal of this work is not to compare existing theoretical works on the topic or discuss their merits and shortcomings, but rather to identify what realistic (perhaps strong) modeling assumptions to make when studying feature learning. Given the recently increasing interest in the subject, we view these works and our approach as complementary components of a broader exploration into feature learning. We have added a discussion of these works to Appendix D.1, but would be happy to revise them if you have further suggestions.\n\nWe hope these responses address your concerns and we are open to further discussion. Thank you again for your constructive feedback!\n\n**Reference**\n\n[6] Towards understanding ensemble, knowledge distillation and self-distillation in deep learning. Allen-Zhu et al."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110510248,
                "cdate": 1700110510248,
                "tmdate": 1700192529145,
                "mdate": 1700192529145,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Akfegu8h4J",
                "forum": "ze7DOLi394",
                "replyto": "RUsLYJEhvF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_MLur"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_MLur"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for writing a detailed response to my comments and updating the manuscript. I have read all the reviews, comments, and the revised manuscript. I agree with the authors that this submission does indeed shed some light on the reasons behind GDE.\n\nHowever, I still have the following comments regarding the submission:\n\n0- I think the authors forgot to address this point: \"Looking at figure 3 (a) and 3 (c), it seems that the observations made from them are not that significant. Am I missing something? How does the choice of the thresholds affect your observations?\". Can the authors please clarify on this?\n\n1- When NTK was first introduced, it was obvious that it is a first order Taylor series expansion around initialization (that is accurate in the infinite width regime) and it was obvious that adding more terms will make it more realistic (but maybe harder -- or much harder -- to analyze).\n\nAlso, when people study shallow neural networks (or infinitely deep neural networks), the assumptions that they make is explainable. We know what aspects they are missing out on. We know that they need to add more layers, we know the training procedure is very specialized, etc. However, this is not the case for your model. I am not sure what your assumptions/simplifications are to the real problem. \n\nThis is a limitation of the current work. I think a \"limitations\" section discussing these issues might benefit the paper. \n\n2- The notation of this paper is not well optimized, and it is making the paper very hard to read at some points. I know the authors are also aware of this (e.g., the footnotes in page 4). Adding a table discussing notations in main text (I know there is a page about this in appendix) will greatly benefit the paper -- at least if (when) the authors plan to publish an extended manuscript on a preprint server later."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700229539237,
                "cdate": 1700229539237,
                "tmdate": 1700229624010,
                "mdate": 1700229624010,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hjX6JdKe9X",
                "forum": "ze7DOLi394",
                "replyto": "QHiowPpmt2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_MLur"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_MLur"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the author for their response. \n\nI am satisfied with the answer to point 0. \n\nI still think point 1 is a limitation of the current study, but the \"limitations\" section is now making everything much more transparent. I thank the authors for expanding it.\n\nI also thank the authors for the effort to make the notation better. I think the revision made the paper much more readable.\n\n\nI will raise my score from 5 to 6."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700351842330,
                "cdate": 1700351842330,
                "tmdate": 1700351842330,
                "mdate": 1700351842330,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aJUc38hbU2",
            "forum": "ze7DOLi394",
            "replyto": "ze7DOLi394",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6358/Reviewer_PxMC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6358/Reviewer_PxMC"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the interaction between data and model through feature to understand deep learning from the feature learning perspective. Based on their observations, they propose a framework to characterize the quality and process of feature learning, with theoretical support. Some empirical results are provided to validate their approach.\n."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1) To catch on feature learning process during deep learning is a key problem in community.\n2) Paper provides a practical framework with solid theoretical analysis. \n3) Empirical results on different datasets are provided. And clear experimental details are listed."
                },
                "weaknesses": {
                    "value": "Figure 1 is a bit vague. It is recommended to replace it with a clearer version."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "nan"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6358/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6358/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6358/Reviewer_PxMC"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6358/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721773591,
            "cdate": 1698721773591,
            "tmdate": 1699636701555,
            "mdate": 1699636701555,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yHSBwD1HB0",
                "forum": "ze7DOLi394",
                "replyto": "aJUc38hbU2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer PxMC"
                    },
                    "comment": {
                        "value": "Thank you for the support of our paper! We are glad that you find our work valuable.\n\nRegarding Figure 1, to better address your concerns, could you elaborate on which aspects of the figure you found unclear? This will help us make more targeted improvements. \n\nThe goal of Figure 1 is to demonstrate that our definition of features can capture images with redundant information and images that contain uncommon instances of a given class. To make this clearer, we have updated the figure in the paper with texts to better reflect the core idea. Does this resolve your concerns? If not, we\u2019d be happy to make more adjustments."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110179718,
                "cdate": 1700110179718,
                "tmdate": 1700110179718,
                "mdate": 1700110179718,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "eFVHB9wonL",
                "forum": "ze7DOLi394",
                "replyto": "yHSBwD1HB0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_PxMC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_PxMC"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the clarifications. I will maintain my initial score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661246828,
                "cdate": 1700661246828,
                "tmdate": 1700661246828,
                "mdate": 1700661246828,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CmYGaqyrCP",
            "forum": "ze7DOLi394",
            "replyto": "ze7DOLi394",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6358/Reviewer_AyvM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6358/Reviewer_AyvM"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes the interaction tensor which is a binary 3-dimensional tensor T describing the presence of certain features in both model and data point, i.e., if $T_{tmn} = 1$ implies that $t_{th}$ feature is present in both $m_{th}$ model and $n_{th}$ data point. The construction of the interaction tensor is based on the correlation analysis between PCA-reduced features of penultimate layers of the collection of models on the given dataset. Authors utilize this interaction tensor to empirically analyze properties of feature learning and propose a feature learning model based on their observations. Using this feature learning model they focus on analysing recently proposed Generalization Disagreement Equality and given which conditions GDE can arise."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Understanding how models learn is an important topic in modern deep learning. Authors build the new framework to describe feature learning from the different perspective which allows to describe recently observed phenomenas. I think that this new perspective provides a valuable contribution to the community and can facilitate further developments in this area. In addition, I personally liked the construction of a natural dataset on which deep ensemble is not well-calibrated in-distribution and where GDE fails."
                },
                "weaknesses": {
                    "value": "Honestly, I don't see obvious weaknesses of the proposed framework and study."
                },
                "questions": {
                    "value": "1. Given that construction of interaction tensor depends on thresholding ($\\gamma_{corr}$ and $\\gamma_{data}$), how important are these hyperparameters? How to properly set them?\n2. Currently theoretical framework analyzes binary classification, does the analysis extend to multi-class classification?\n3. Does the framework allow for introducing distribution shifts and etc?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6358/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698746159950,
            "cdate": 1698746159950,
            "tmdate": 1699636701422,
            "mdate": 1699636701422,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "subhwl2MLA",
                "forum": "ze7DOLi394",
                "replyto": "CmYGaqyrCP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer AyvM"
                    },
                    "comment": {
                        "value": "Thank you for your supportive feedback on our work. We are glad that you find our new perspective on feature learning interesting. Below are our responses to your questions:\n\n> how important are these hyperparameters? How to properly set them?\n\nIn Appendix F.10, we conducted an ablation study and found that our qualitative conclusions are robust to variations in these hyperparameters. Therefore, we believe the values used in our paper should be appropriate for most applications.\n\n> Currently theoretical framework analyzes binary classification, does the analysis extend to multi-class classification?\n\nWe discuss the necessary steps for the extension to multi-class classification in Appendix D.3. \n\n>Does the framework allow for introducing distribution shifts and etc?\n\nThis is a great question. We believe our framework can accommodate distribution shifts. For instance, the simplest form of covariate shift one could introduce is to add a new set of features that are not present in the training data with some probability at test time. Since the model has not seen these new features during training, we may assume that individual members of the ensemble will make random predictions (but the prediction of different models will be correlated) if the data points only contain the new features (the same assumption for features that the models did not learn). One can also introduce a covariate shift on existing features but that would require imposing a non-uniform distribution over the existing features. We leave the exploration of these directions to future works.\n\nWe hope these answers clarify your question, and we are open to further discussion. Thank you again for your constructive feedback."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700110107056,
                "cdate": 1700110107056,
                "tmdate": 1700110107056,
                "mdate": 1700110107056,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JaMHEETawg",
                "forum": "ze7DOLi394",
                "replyto": "subhwl2MLA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_AyvM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6358/Reviewer_AyvM"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for the clarifications and will maintain my initial assessment of the paper."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6358/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700128312419,
                "cdate": 1700128312419,
                "tmdate": 1700128312419,
                "mdate": 1700128312419,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]