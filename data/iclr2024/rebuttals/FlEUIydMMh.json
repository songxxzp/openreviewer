[
    {
        "title": "Neuro-Causal Factor Analysis"
    },
    {
        "review": {
            "id": "f16SlHPf96",
            "forum": "FlEUIydMMh",
            "replyto": "FlEUIydMMh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_VCXV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_VCXV"
            ],
            "content": {
                "summary": {
                    "value": "The authors proposed Neuro-Causal Factor Analysis (NCFA) method, which is a nonparametric approach for modeling latent causal factors in deep generative models. They have proved theoretical results for the proposed method. They proposed an algorithm and applied it to simulated and real datasets. They compared their method with standard VAEs and showed that their method performs comparably and is more causally interpretable."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is clearly written and theoretically solid."
                },
                "weaknesses": {
                    "value": "The experiment section is a bit weak, and it lacks comparisons with other causal inference methods for deep generative models."
                },
                "questions": {
                    "value": "- how sensitive the results are to the hyperparameters? and in practice, how should users choose them?\n\n- is NCFA scalable for larger datasets and denser casual connections? what's the running speed of this method?\n\n- how does NCFA compare to other causal inference methods for deep generative models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698526899599,
            "cdate": 1698526899599,
            "tmdate": 1699636218522,
            "mdate": 1699636218522,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AyMnwOV3sw",
                "forum": "FlEUIydMMh",
                "replyto": "f16SlHPf96",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> how sensitive the results are to the hyperparameters? and in practice, how should users choose them?\n\nThe main hyperparameter, lambda, is similar to the choice of latent dimension in any generative model: If lambda is too small, then we would run into the same kinds of problems training any generative model with insufficient capacity. It does not have to be tuned carefully in practice.\n\nMore precisely, lambda should be greater than the number of causal latents, but how much greater is not as important. In practice (and our experiments on real data), VAEs are likely to have high enough latent DoF that experimentally exploring this further is beyond the scope of our presentation of the NCFA framework. Also see our response to the third question of Reviewer WRCe for discussion of how this parameter should be chosen by users.\n\n> is NCFA scalable for larger datasets and denser casual connections? what's the running speed of this method?\n\nOur real data application in Section 5 (especially Table 1, and further discussion in appendices F and C) demonstrates that NCFA scales to large data sets like MNIST, even with dense (fully connected) structures and up to a 1/4 of a million latent degrees of freedom in the VAE. The computational bottleneck is the NP-hard problem of finding an exact minimum edge clique cover, however our applications in Section 5 demonstrate that using polynomial-time ECC heuristics (based on the 1-pure-child assumption) bring the runtime to the order of standard VAE methods without sacrificing much of the accuracy of the exact method.\n\n> how does NCFA compare to other causal inference methods for deep generative models?\n\nThis is discussed in Section 2.3. Our results are complementary to existing results, and make different, sometimes weaker, assumptions. We are happy to clarify any more specific questions you have on this."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586921985,
                "cdate": 1700586921985,
                "tmdate": 1700586921985,
                "mdate": 1700586921985,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6o4P0YjKOm",
                "forum": "FlEUIydMMh",
                "replyto": "AyMnwOV3sw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2755/Reviewer_VCXV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2755/Reviewer_VCXV"
                ],
                "content": {
                    "title": {
                        "value": "Responses to authors' rebuttal"
                    },
                    "comment": {
                        "value": "Thank the authors for their responses. I keep my current score."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739266834,
                "cdate": 1700739266834,
                "tmdate": 1700739266834,
                "mdate": 1700739266834,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AUtoL9XzVm",
            "forum": "FlEUIydMMh",
            "replyto": "FlEUIydMMh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_eQDF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_eQDF"
            ],
            "content": {
                "summary": {
                    "value": "Neural Causal Factor Analysis (NCFA) was proposed in this submission to understand source-measurement causal relations in a factor analysis framework. By utilizing clique cover based latent structure constraints and variational autoencoder source-measurement mapping, the authors claimed that NCFA has the identifiability guarantee and also achieves nonlinear factor analysis with interpretable and flexible causal understanding. Experiments using simulated and real data (MNIST and TCGA) shows effective reconstruction of NCFA under certain settings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "NCFA emphasizes the identifiability guarantee with the focus on source-measurement two-level dependence structures. \n\nWith identified unconditional dependence graph (UDG), the authors reasoned that the corresponding minimum MCM graphs with minimum edge clique cover are identifiable under certain conditions, for example, 1-pure-child assumption. \n\nNCFA leverages existing causal structure discovery and deep generative models to achieve computationally feasible source-measurement factor analysis. \n\nThe experiments showed that incorporating causal constraints, VAE has reasonable reconstruction performance."
                },
                "weaknesses": {
                    "value": "The positioning of NCFA for causal structure discovery may be problematic as both causal understanding and interpretability are quite constrained. \n\nIt is not really clear how the identifiability guarantee may be beneficial for causal understanding under the constrained settings of NCFA. \n\nThe presented experimental results appear to be preliminary, without much explanations on causal relationships, interpretability, benefits from identifiability and flexibility by having nonlinear mapping using VAE. \n\nThe first part of NCFA depends on the quality of UDG and minimum MCM graphs. UDG appears to be a Markov Network for statistical independence representation. By the nature of Markov Networks, UDG can be guaranteed to be an I-map but not be a perfect map for the data generation distribution. The UDG and induced minimum MCM graphs therefore may not always capture the underlying causal structure faithfully. For example, when we have a M_1 to M_5 forming a Markov chain. Based on the described algorithm, the UDG may just have a complete graph with 5-node clique, which does not really provide any additional causal understanding or constraints in NCFA. \n\nThe authors may want to clearly define what they meant by NCFA being 'non-parametric' and 'identifiable'. For example, the overall FA framework is a parametric setting and VAEs also typically are considered parametric for the source-measurement mapping. If the authors meant that there is no need to specify mapping functional families as being 'non-parametric', it may need to explained clearly. It may also not be fair to claim the advantages on identifiability of minimum MCM graphs in NCFA over the existing other causal structure discovery methods due to the assumed specific settings. \n\nMath notations may need careful proofread. For example, in Section 4, $\\hat{U}$ was referred as 'estimated UDG' in the second and third paragraphs but then as the MCM graph at the beginning of the fourth graph. It is quite confusing. There are in fact many of these examples in the submission."
                },
                "questions": {
                    "value": "1. What does MCM stand for? Medil Causal Models? If so, please provide the full name in the main text too. \n\n2. What are the details of model structure and training, especially the VAE model constructed following the induced minimum MCM graphs? These do not appear to be included either in the main text or appendix."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2755/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2755/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2755/Reviewer_eQDF"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698611032853,
            "cdate": 1698611032853,
            "tmdate": 1699636218446,
            "mdate": 1699636218446,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bquTsM7IIn",
                "forum": "FlEUIydMMh",
                "replyto": "AUtoL9XzVm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> What does MCM stand for? Medil Causal Models? If so, please provide the full name in the main text too.\n\nYes, MCM stands for MeDIL causal model. We have added this to the main text.\n\n> What are the details of model structure and training, especially the VAE model constructed following the induced minimum MCM graphs? These do not appear to be included either in the main text or appendix.\n\nThese details are given in Appendix C.\n\n> For example, when we have a M_1 to M_5 forming a Markov chain. Based on the described algorithm, the UDG may just have a complete graph with 5-node clique, which does not really provide any additional causal understanding or constraints in NCFA.\n\nSuch graphs are not within the model class we are concerned with. Namely, your example is Markov to a DAG over the measurement variables, while we are explicitly concerned with causal factor models, which we motivate beginning in the second paragraph of Section 1.\n\n> The authors may want to clearly define what they meant by NCFA being 'non-parametric' and 'identifiable'.\n\nOur _statistical model_ is nonparametric (infinite-dimensional without functional restrictions), whereas the _estimator_ is parametric (finite-dimensional). The latter is of course always necessary if it is to be implemented on a computer, e.g. as with a neural network.  A similar phenomenon arises in density estimation: The model (usually H\"older, Sobolev, etc.) is infinite-dimensional, but the estimator is finite-dimensional (e.g. kernel estimates). In other words, VAEs are parametric estimators of nonparametric models.\n\n>  It may also not be fair to claim the advantages on identifiability of minimum MCM graphs in NCFA over the existing other causal structure discovery methods due to the assumed specific settings.\n\nTo the best of our knowledge, our identifiability results are the first of their kind for nonparametric causal factor models. Other methods make parametric assumptions and use this added power to relax their model class at the expense of stronger assumptions. Our approach has the advantage of not needing the stronger parametric assumptions, but of course if one is willing to make such assumptions for a given application, other methods are more appropriate."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586876184,
                "cdate": 1700586876184,
                "tmdate": 1700586876184,
                "mdate": 1700586876184,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "C7YafmNqDV",
                "forum": "FlEUIydMMh",
                "replyto": "AUtoL9XzVm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2755/Reviewer_eQDF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2755/Reviewer_eQDF"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for providing clarifications. However, I still have concerns on limited experimental results and the positioning of the paper on the claim of causal structure discovery. I will have to keep the current score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660109525,
                "cdate": 1700660109525,
                "tmdate": 1700660109525,
                "mdate": 1700660109525,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "25YXurBUEa",
            "forum": "FlEUIydMMh",
            "replyto": "FlEUIydMMh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_XmbE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_XmbE"
            ],
            "content": {
                "summary": {
                    "value": "The paper combines advancements in causal discovery and deep learning, to propose a new nonparametric framework called Neuro-Causal Factor Analysis (NCFA). It uses variational autoencoder (VAE) with Markov factorization constraints of the distribution with respect to the learned graph for learning causal factors in a neuro mode."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The presentation is clear.\n2. The experiements concerning the validation delta of the learning process is enough."
                },
                "weaknesses": {
                    "value": "1. Some aspects concerning the theoretical soundness should be improved.\n2. The efficiency should be further analyzed."
                },
                "questions": {
                    "value": "1. Fig 2: it seems that all graphs can be aligned as the hierarchical structure. Is this an assumption or based on some theoretical results?\n2. Definition 3.5: why this is called \"observationally equivalent\"? How about calling \u201cequivalent wrt d-separation\u201d?\n3. Algorithm 1: it is clear that the partition of variables into \"two groups\" are critical to the performance of the algorithm. Is there any analysis about the efficiency, and the error cascade if an inaccuracy partition appears?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698634538087,
            "cdate": 1698634538087,
            "tmdate": 1699636218357,
            "mdate": 1699636218357,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FrJWoj9Jdt",
                "forum": "FlEUIydMMh",
                "replyto": "25YXurBUEa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Fig 2: it seems that all graphs can be aligned as the hierarchical structure. Is this an assumption or based on some theoretical results?\n\nIt is a well-known fact (due to Pearl) that any latent variable model can be represented minimally in this way. So this is not an assumption, and follows from known theoretical results.\n\n> Definition 3.5: why this is called \"observationally equivalent\"? How about calling \u201cequivalent wrt d-separation\u201d?\n\nThe phrase \"observationally equivalent\" is standard in the causal graphical models literature. For example, see Judea Pearl's seminal book \"Causality\", which uses the phrase in Theorem 1.2.8 (on page 19, in the printing from 2000). \n\n> Algorithm 1: it is clear that the partition of variables into \"two groups\" are critical to the performance of the algorithm. Is there any analysis about the efficiency, and the error cascade if an inaccuracy partition appears?\n\nThe algorithm does not partition variables. Line 2 of the algorithm along with Definition 3.2 rigorously describes how the latent variables are learned from the measurement variables. We do provide analysis about efficiency and robustness in the face of error\u2014we describe this at the end of the \"Synthetic data\" analysis in Section 5, with the help of Figure 3, as well as in more detail and with more plots in Appendix E."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586820774,
                "cdate": 1700586820774,
                "tmdate": 1700586820774,
                "mdate": 1700586820774,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YRv2MDy52h",
                "forum": "FlEUIydMMh",
                "replyto": "FrJWoj9Jdt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2755/Reviewer_XmbE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2755/Reviewer_XmbE"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thank you for the rebuttal. I still think that hierarchical structure is an assumption (for example, contains acyclicity, no confounders etc), and some expressions like \"observationally equivalent\" should be rephrased more mathematically rigorous, like being \"equal\" with respect to Markov condition (or state this in terms of conditional probability given observational set S), and I remain unchanged of my score."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656611709,
                "cdate": 1700656611709,
                "tmdate": 1700656611709,
                "mdate": 1700656611709,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "A82FmDC9dQ",
            "forum": "FlEUIydMMh",
            "replyto": "FlEUIydMMh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_hmd4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_hmd4"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes to use the VAE for modeling the factor analysis and aim to identify the factor via latent causal discovery."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This work Neuro-Causal factor analysis using a VAE framework."
                },
                "weaknesses": {
                    "value": "- Clarity is one of the main issues of this work. Many terminology descriptions are missing or without explanation. For example, what is the full name of MCM graph and ECC model? \n- Moreover, the contribution of this work is rather limited and it seems to a simple incremental of the work Markham & Grosse-Wentrup, 2020.\n- The notations are confusing and the theoretical results in this paper are problematic. Theorem 3.6 states that the DAG G is identifiable with the conditions that $M_{i}\\perp M_{j}\\iff i-j\\notin E^{\\mathcal{U}}$, which is problematic. Since a DAG identifiable means that every direction for every edge in the DAG will be identified, which is impossible without any assumptions under the existence of a latent variable. In fact, this theorem relies on the theory of Markham & Grosse-Wentrup, 2020 which has several underlying assumptions and constrained which is missing in the statement of the theorem."
                },
                "questions": {
                    "value": "See the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766589018,
            "cdate": 1698766589018,
            "tmdate": 1699636218280,
            "mdate": 1699636218280,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "M7phL1sYTr",
                "forum": "FlEUIydMMh",
                "replyto": "A82FmDC9dQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Clarity is one of the main issues of this work. Many terminology descriptions are missing or without explanation. For example, what is the full name of MCM graph and ECC model?\n\nMCM abbreviates \"MeDIL causal model\", and ECC abbreviates \"edge clique cover\". The MCM graph is rigorously defined in Definition 3.2 and ECC-observational equivalence is rigorously defined in Definition 3.5.\n\n> The notations are confusing and the theoretical results in this paper are problematic. Theorem 3.6 states that the DAG G is identifiable with the conditions that, which is problematic. Since a DAG identifiable means that every direction for every edge in the DAG will be identified, which is impossible without any assumptions under the existence of a latent variable. In fact, this theorem relies on the theory of Markham & Grosse-Wentrup, 2020 which has several underlying assumptions and constrained which is missing in the statement of the theorem.\n\nThe underlying assumptions and theory required for Theorem 3.6 are clearly stated in the first sentence of the theorem, in the phrase \"the data-generating distribution is Markov to a minimum MCM graph\". Being Markov to a minimum MCM graph means that each clique in the ECC of U implies the existence of a latent variable in G (and this is clearly stated in the proof, which explicitly references all necessary supporting theory). This latent variable (by the assumption that the MCM graph is minimum), necessarily has exactly the edges directed to the measurement variables in its corresponding clique. Hence, the clearly stated assumption renders the latent DAG (and every direction of every edge in it) identifiable."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586742551,
                "cdate": 1700586742551,
                "tmdate": 1700586742551,
                "mdate": 1700586742551,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1Wavs2fbiI",
            "forum": "FlEUIydMMh",
            "replyto": "FlEUIydMMh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_WRCe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2755/Reviewer_WRCe"
            ],
            "content": {
                "summary": {
                    "value": "This work considers the classic factor analysis model from a causal perspective. The authors introduce a new method known as Neuro-Causal Factor Analysis. Unlike traditional factor analysis, the authors integrate a causal discovery approach and a variational autoencoder tool to uncover the latent causal graph and its corresponding parameters. They show the minimum  \ufeffMeDIL Causal Model is identifiable under some conditions.\nFurthermore, they validate the effectiveness of the proposed method through experiments conducted on both synthetic and real-world datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper addresses a non-trivial task and introduces a new method to tackle this challenge. In contrast to most traditional factor analysis (FA) methods, the approach proposed in this paper can handle nonlinear FA models.\n\n2. The identification results of this paper are novel and significant for the causal discovery and generative models community.\n\n3. The experimental results are presented in a logical way."
                },
                "weaknesses": {
                    "value": "1. I have some confusion regarding the conclusion in Theorem 3.6. This conclusion states that if there exist UDGs with a unique minimum edge clique cover, then we can uniquely identify that graph G. I attempted to read the proof; however, the author references the conclusions of two other articles to establish this point. Without any specific constraints on the generating function, the validity of this conclusion requires further elucidation. I hope the author can provide an intuitive proof framework to demonstrate the correctness of this conclusion.\n\n2. The algorithm's results depend on the latent degree of freedom lambda."
                },
                "questions": {
                    "value": "1. How can we ensure the identifiability of loading functions (f) and residual measurement errors?\n\n2. Could you provide an intuitive proof framework to demonstrate the correctness of Theorem 3.6? Are there any graphical conditions when UDGs have a unique minimum edge clique cover?\n\n3. In practice, how do we set the latent degree of freedom lambda?\n\nminor typos:\n\n Section 2.2 on Page 4: which relax the Causal Markov Assumption? It should be the Causal Sufficiency Assumption, right?\n\nFigure 2: double l_2,2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2755/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698823583567,
            "cdate": 1698823583567,
            "tmdate": 1699636218073,
            "mdate": 1699636218073,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wokKIa5k8U",
                "forum": "FlEUIydMMh",
                "replyto": "1Wavs2fbiI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2755/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> How can we ensure the identifiability of loading functions (f) and residual measurement errors?\n\nOur focus is on identifying the causal structure. We have left identifiability of the parameters to future work (and would note that there is already extensive work on this problem). Our approach is to emphasize causal interpretability and accurate generative modeling as opposed to factor loading identification. \n\n> Could you provide an intuitive proof framework to demonstrate the correctness of Theorem 3.6? Are there any graphical conditions when UDGs have a unique minimum edge clique cover?\n\nIn Corollary 3.7 (and its proof in Appendix B), we prove that a UDG has a unique minimum ECC when it has equal intersection and independence numbers. We also show that this condition on UDGs is equivalent to the 1-pure-child condition on latent DAG models known in the literature.\n\n> In practice, how do we set the latent degree of freedom lambda?\n\nThe experiments show that this parameter does _not_ need to be carefully tuned, and indeed this is a key contribution. Simply put, we need lambda to be larger than the true number of causal latents, and small enough to train in practice. In other words, lambda could be in the thousands and it does not matter very much. (If lambda is too small, then we would run into the same kinds of problems training any generative model with insufficient capacity.)\n\n> Section 2.2 on Page 4: which relax the Causal Markov Assumption? It should be the Causal Sufficiency Assumption, right?\n\nThe causal Markov assumption (CMA) is basically (as mentioned in the second sentence of Section 2.2) Reichenbach's common cause principle plus the causal sufficiency assumption (CSA), so relaxing the CSA is one (but not the only) way of relaxing the CMA.\n\n>   * Figure 2: double l_2,2?\n\nYes, thanks for pointing out the typo! It should be l_2,1 and l_2,2."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2755/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586670634,
                "cdate": 1700586670634,
                "tmdate": 1700586670634,
                "mdate": 1700586670634,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]