[
    {
        "title": "How connectivity structure shapes rich and lazy learning in neural circuits"
    },
    {
        "review": {
            "id": "e6LkQIH361",
            "forum": "slSmYGc8ee",
            "replyto": "slSmYGc8ee",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission542/Reviewer_rK41"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission542/Reviewer_rK41"
            ],
            "content": {
                "summary": {
                    "value": "This paper probes the effect of weight initialization rank on feature learning in recurrent neural networks. The authors study in particular how the alignment between a particular low-rank initialization and the task affect how much the kernel moves during training."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "In the large, I think this paper is timely, and the core idea is (to the best of my knowledge) novel and interesting."
                },
                "weaknesses": {
                    "value": "1. Upon reaching the conclusion of the paper, I found myself confused as to why the authors did not perform any experiments with feedforward networks. Though I appreciate the neuroscience-inspired focus on recurrent networks, including some tests in the feedforward setting would be valuable. In particular, this would show more directly how departures from the idealized setting of their theoretical results (linear networks with whitened data) affect the phenomenology. Demonstrating that these ideas are applicable to deep feedforward networks  and more standard machine learning tasks would in my view substantially improve the impact of the paper by tying it more closely to the main body of theoretical work on feature learning. \n\n2. The metrics introduced in Section 2.2 are restricted to measuring changes in weights or kernels over the course of training. Particularly given the fact that the stated goal is to investigate how task structure affects feature learning, it would be useful to also track a measure of task-kernel alignment, for instance the kernel-target alignment $y^{\\top} K y / |y|^2 tr K$ or the task norm $y^{\\top} K^{-1} y$ throughout training. \n\n3. The criteria used for task selection are unclear. The authors choose three of the original tasks from the neurogym environment (I note that this task suite has been critiqued by Khona et al., \"Winning the Lottery With Neural Connectivity Constraints: Faster Learning Across Cognitive Tasks With Spatially Constrained Sparse RNNs\") along with sequential MNIST. Why are these four tasks relevant? The paper could be made more compelling either by using a more diverse suite of tasks or by justifying why these four are appropriate. \n\n4. On the whole, I found the Discussion to be a weak point of the manuscript. Section 4.1 does not answer the vital question of precisely what experimentally-measurable biological phenomena the present work can explain, contextualize, or predict. As it stands, this section is in some sense a restatement of Zador's ideas around the importance of task-aligned initialization in the language of lazy learning. Moreover, the discussion of implications for deep learning promised by the section title seems to be missing. Section 4.2 contains far too many ideas to be jammed into its single paragraph; for clarity the authors should split it into at least two paragraphs. Finally, the relevance to neuroscience of neural collapse and of Tishby's proposals regarding the information bottleneck needs to be justified. The sentence where they are mentioned is much too long as it is, and these are both somewhat subtle and controversial topics."
                },
                "questions": {
                    "value": "1. In the block of citations in the second sentence of the introduction, the work of Canatar, Bordelon, and Pehlevan (2021) should be cited before Xie et al 2022, as the latter is based on the results developed in the former work. \n\n2. Is \"tabula rasa\" the appropriate way to describe Gaussian or Uniform random initialization with non-vanishing variance? \n\n3. In-text citations to the work of the Allen Institute and the MICrONS Consortium are not formatted correctly. \n\n4. Why do the eigenvalues in Figure 2 appear not to be sorted by magnitude? Also, why is $\\frac{\\sum\\_{i} |\\lambda|\\_{i}}{|\\lambda\\_{1} N}$ the relevant notion of effective rank in this setting?\n\n5. Figures 2 and 3 each occupy more than half of a page, but both contain a significant amount of whitespace. Is it possible to combine them side-by-side into a single figure?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Reviewer_rK41",
                        "ICLR.cc/2024/Conference/Submission542/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission542/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698087233918,
            "cdate": 1698087233918,
            "tmdate": 1700165552068,
            "mdate": 1700165552068,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TufwvR1ROm",
                "forum": "slSmYGc8ee",
                "replyto": "e6LkQIH361",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rK41 (1/3)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the accurate summary of our work and recognizing its timeliness and novelty. Moreover, we thank the reviewer for their concrete and executable suggestions to sharpen our claims and improve the presentation. We are confident that by incorporating the reviewer\u2019s insightful feedback, our updated manuscript has been significantly improved along all axes of soundness, presentation and contribution. \n\n**Experimentation with feedforward networks in a non-idealized setting**: as the reviewer pointed out, we studied RNNs due to our neuroscience focus, and we completely agree with the reviewer that adding results on feedforward settings would be important. We agree with the reviewer that this would help out with tying to the existing literature on feature learning predominantly in feedforward settings. Following the reviewer\u2019s suggestion to showcase this in non-idealized feedforward settings, we have now appended a panel to a figure in Appendix (see Appendix Figure 9B), showing our main claim (higher rank initialize lead to effectively lazier learning) also apply to to nonlinear feedforward networks trained on a real-world dataset. Although we trained the network on MNIST (instead of something like CIFAR), it is sufficient for the purpose of departing from the idealized setting. As originally mentioned in Limitations & Future Work, more comprehensive examination across wider range of architecture, including feedforward settings, is left for future work. We have also added a sentence in Simulation Results alerting interested readers to this appendix figure. \n\n**Tracking task-kernel alignment during training**: We thank the reviewer for the insightful comment. In line with the reviewer\u2019s suggestion of tracking impact on not just the final trained network but also during the learning process (and related comments by other reviewers), we have now added Appendix Figure 14 tracking the tangent kernel alignment as well as the alignment of the kernel and task throughout training. Figure 14A examines the kernel alignment (alignment of the current kernel to the initial one) in the idealized linear setting with 2D input in Fig. 2 in Atanasov et al. across different initialization schemes: random rank-1 initialization, random full-rank initialization and initially aligned low-rank initialization. We see that low-rank random initialization lead to greater movements, i.e. growing to be more dissimilar to the initial kernel (lower alignment value). Figure 14B looks at the task kernel alignment, $y^T K y / |y|^2 TrK$. Regardless of the initializations, the network kernel moves to be more aligned to the task over training. Low-rank initialization, without being specifically tuned to the task, is the latest to achieve alignment. \n\nFigure 14C examines the kernel alignment (alignment of the current kernel to the initial one) in a non-idealized setting: sMNIST task. Again, random low-rank initialization leads to more movement over training, i.e. more dissimilar to the initial kernel. For Figure 14D, with multiple (10) output targets, we track the centered kernel alignment (CKA) of the NTK and class label, e.g. used in Baratin et al. (2021). We again saw that all initializations grow to be more aligned with the class label through training, but higher rank initialization gets to a higher alignment value faster and with less kernel rotation. We have already trained for nearly 20000 SGD iterations and we are not sure if training longer would eventually lead to similar final alignment values across initializations. We note that although achieving higher CKA over training can indicate greater degree of feature learning, a hallmark of the standard rich regime, this does not contradict our findings centered on effective learning regime that is defined based on the amount of change post-training (see Introduction). To incorporate these new findings in the main text, we have added sentences in Simulation Results to bring these Appendix Figures to the attention of an interested reader. \n\n**Please continue to the comment below**"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700135701140,
                "cdate": 1700135701140,
                "tmdate": 1700135701140,
                "mdate": 1700135701140,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jxjWbFyuCs",
                "forum": "slSmYGc8ee",
                "replyto": "e6LkQIH361",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Improving Discussion Section**: In response to the reviewer\u2019s crucial comment regarding more concrete experimental explanation or prediction, we have now updated the manuscript, and the paragraph reads as: \u201c*We study the impact of effective weight rank on learning regime due to its potential implications in neuroscience. In particular, learning regimes are indicative of the amount of change undergone through learning, which bear consequences for metabolic costs and catastrophic forgetting (McCloskey & Cohen, 1989; Pla\u00e7ais & Preat, 2013; Mery & Kawecki, 2005). These considerations are especially pertinent when we examine the various learning regimes evident in neural systems. For instance, during developmental phases, neural systems undergo resource-intensive, plasticity-driven transformations characterized by significant synaptic changes. These transformations are in contrast to the more subdued adjustments observed in mature neural circuits (Lohmann & Kessels, 2014). Based on this understanding, we predict that a circuit's alignment with specific tasks is likely established either through evolutionary processes or during these early developmental phases. As such, the specialization of a neural circuit (e.g., ventral vs dorsal (Bakhtiari et al., 2021)) likely stems from its engagement with tasks that share overlapping computational requirements, ensuring that each circuit is optimally configured for the tasks it is predisposed to perform. Conversely, circuits with high-rank structures, due to their inherent flexibility, are expected to be less specialized, potentially engaging in the learning of a broader range of tasks. With this in mind, our framework could be used as a tool to compare the connectivities across brain regions (and species) to predict their function and flexibility\u2026* \u201d \n\nFor deep learning, we note that while low-rank initialization is not common practice, low-rank adaptation and other update parametrizations have recently been popular in large model training schemes. See for example, Low-rank Adaptation (LoRA) in Hu et al. (2021). As such, we argue that the impact of low-rank structures on learning dynamics is quite relevant for current AI practices, and our study contributes to examining how having low-rank structures impact the effective learning regime. The methods and results we present here have the potential to be adapted and built upon to study rankedness and learning regime in several settings, and we are keen to see future work stemming from these ideas.\nWe also note that our study has the tangential benefit of informing the deep learning community about potential applications of their models in other fields such as neuroscience. However, due to the significantly heavier balance of Section 4.1 in discussing neuroscience implication, we have removed \u201cDeep Learning\u201d in the section heading. We have updated Section 4.1 reflecting these points. \n\nUpon re-reading Section 4.2, we agree with the reviewer that Section 4.2 is jammed with too many ideas. As per the reviewer\u2019s suggestion, we have now broken 4.2 into smaller paragraphs for readability. We also thank the reviewer for pointing out the long sentence involving neuroscience implications and Tishby\u2019s proposal. This sentence suffers the same problem as the entire section that the reviewer pointed out: too many ideas jammed together, which compromises clarity. We, thus, have removed the mention of Tishby\u2019s proposal since it is creating confusion and distraction from our main point in the sentence, which is asking for deeper exploration into the neuroscience implications in the future. \n\n**Please continue to the comment below**"
                    },
                    "title": {
                        "value": "Response to Reviewer rK41 (2/3)"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700135903362,
                "cdate": 1700135903362,
                "tmdate": 1700136406647,
                "mdate": 1700136406647,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c7aW8Z1KuL",
                "forum": "slSmYGc8ee",
                "replyto": "e6LkQIH361",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rK41 (3/3)"
                    },
                    "comment": {
                        "value": "**Unclear task selection criteria**: We thank  the reviewer for this valuable comment. The primary criteria for our task selection were neuroscience relevance, aligning with our core objectives and benchmark popularity, to ensure we weren't perceived as choosing idiosyncratic tasks that merely optimize our results \u2014 a rationale that also informed our decision to include sMNIST. That said, there are many tasks that fit the criteria due to the wide range of tasks that different species can solve, and the type of tasks we examine fall far short of the pool of all relevant tasks, so we listed the examination of wider range of tasks and architecture as limitation and future work in our initial submission. We remark that because of Theorem 1 and our intuition explained at the beginning of Discussion, we anticipate that our conclusion should hold across a wide range of settings despite having not exhaustively explored all relevant settings. In response to the reviewer\u2019s suggestion, we have revised our Discussion section to reflect this and make propositions for related future work. \n\nDespite that, the reviewer\u2019s feedback made us realize that the strength of our empirical results would be improved if we can show at least one additional task (with neuroscience relevance) that is significantly different from the structure of the existing tasks. For that reason, we have added the sequence generation task inspired from Bellec et al. (2020) (Appendix Figure 15) and a sentence in Discussion alerting interested readers to that figure. We remark that exploration across a broader range of tasks is left for future work, as mentioned in our initial submission, and in particular, it would be interesting to explore the harder neuroscience tasks in Mod-Cog introduced by Khona et al. in the future (we have added the citation of Mod-Cog to that discussion in our updated Limitations & Future Directions).\n\n**Citing Canatar et al.**: We thank the reviewer for catching this missed citation. We worked hard to be comprehensive in our citation, and yet, we still somehow let this highly relevant reference slip through our attention. We have thus added it to exactly where the reviewer suggested. \n\n**Tabula rasa**: we thank the reviewer for bringing this to our attention. \"Tabula rasa\" means \"blank slate\u201d. However, Gaussian or Uniform random initialization, with non-vanishing variance, is not exactly a \u201cblank state\u201d in the strictest sense, as they can still exhibit inherent bias. We have thus replaced \u201ctabula rasa\u201d with \u201crandom\u201d in the offending sentence. \n\n**Citations to Allen and MiCrONS**: we thank the reviewer for catching these and we have now fixed them. \n\n**Sorting eigenspectrum plots and effective rank**: We thank the reviewer for the comment. The eigenvalues were not sorted because we used *numpy.linalg.eigvals()*, which does not guarantee sorted eigenvalues and we didn\u2019t ensure that once we were able to clearly observe the faster decay trend in the eigenspectrum of the experimentally-driven connectivities was still visible. As per the reviewer\u2019s comment, we have now sorted the eigenvalues in the eigenspectrum plots. \n\nAs for the effective rank measure \u2014 which captures the proportion of eigenvalues on the order of the leading one \u2014 we chose it because it has been used before (e.g. Murray et al., ICLR\u201923) and would correspond to the area under the curve of the eigenspectrum plots scaled relative to the leading one, thereby informing us regarding the eigenspectrum decay. Low rank matrices would have fewer eigenvalues on the order of the leading one. That said, singular values are used more generally for capturing the effective rank. Hence, we have also added plots that measure effective rank using singular values (Appendix Figure 13) and a sentence in Simulation Results referring to that figure. These plots all support our main point here: these example experimentally-driven structures exhibit lower effective rank compared to null. \n\n**Combining Figure 2 and 3**: We thank the reviewer for this suggestion and we have now combined them into one figure. This indeed gave us a lot more space to address the reviewers\u2019 important points."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700135927736,
                "cdate": 1700135927736,
                "tmdate": 1700136433676,
                "mdate": 1700136433676,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "190Gw7Z94j",
                "forum": "slSmYGc8ee",
                "replyto": "c7aW8Z1KuL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_rK41"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_rK41"
                ],
                "content": {
                    "title": {
                        "value": "Response to author response"
                    },
                    "comment": {
                        "value": "I thank the authors for their thoughtful and detailed reply to my comments and those of the other reviewers. I think the paper is substantively improved by these changes, and therefore will raise my score. \n\nOne small comment - the heading of Section 4.1 in the currently-visible manuscript reads \"POTENTIAL IMPLICATIONS TO BOTH NEUROSCIENCE;\" the \"both\" should be removed along with the \"deep learning\" that you already cut."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700152536524,
                "cdate": 1700152536524,
                "tmdate": 1700152536524,
                "mdate": 1700152536524,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Oxf3jA9JAi",
                "forum": "slSmYGc8ee",
                "replyto": "28VP8eYrZq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_rK41"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_rK41"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the note, score raised"
                    },
                    "comment": {
                        "value": "I thank the authors for their note. I think the paper should be accepted as is, so have raised my score to 8."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700165535778,
                "cdate": 1700165535778,
                "tmdate": 1700165535778,
                "mdate": 1700165535778,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7URtMiR3F8",
            "forum": "slSmYGc8ee",
            "replyto": "slSmYGc8ee",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission542/Reviewer_SwWy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission542/Reviewer_SwWy"
            ],
            "content": {
                "summary": {
                    "value": "The work investigates how the initial weight structure, especially its (effective) rank, influences network learning dynamics, and in particular whether the network learns in the \"lazy\" (small change in tangent kernel) or \"rich\" (substantial evolution of tangent kernel) regimes. The paper is written using neuroscience as a motivation, citing the fact that connectivity in the brain is substantially more structured and lower-rank than standard initializations used in ML, and thus existing work on lazy/rich regimes may not apply directly to biological learning. The authors find that low-rank initializations typically lead to richer learning, unless the low-rank initialization happens to align with the structure of the task."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is clearly written and technically sound.  The experiments provide solid evidence for the main takeaway of the paper (that lower-rank initializations generally lead to richer learning dynamics), using a variety of tasks and complementary measures of laziness/richness.  Figure 4 provides helpful intuition for understanding this conclusion, suggesting that low-rank initializations tend to incentivize richer learning because there is a greater need for it when the model's kernel at initialization has low alignment with the task structure."
                },
                "weaknesses": {
                    "value": "I have two main concerns about this paper:\n\n1. Given that the proof of Theorem 1 is left to an Appendix, the paper would benefit from providing more explanation / intuition for the main result.  I can imagine an intuition that the network \"needs to\" adjust its representation more to address the misalignment.  But a more thorough presentation of the key proof steps in the main text, and/or illustrative examples to provide intuition for the learning dynamics, would be very helpful.\n\n2. It is not clear to me how the findings of this paper will be useful to either the ML or neuroscience communities.  I do not mean to claim that they aren't useful, but rather that the paper does not present a clear case for why they are.  From an ML standpoint, low-rank initializations are uncommon.  From a neuroscience standpoint, the applicability of this theoretical framework seems uncertain given that the learning algorithms used in the brain are not well characterized and may differ substantially from SGD.  Moreover, it is not clear to me what we gain by knowing that low-rank neural connectivity gives rise to richer learning than a counterfactual in which brains had higher-rank connectivity.  Is the idea to compare between brain regions with connectivities of different ranks to make predictions about different representation learning dynamics?  Or across species?  More concrete and precise proposals for how these findings could be used would be helpful.\n\n3. The richness/laziness of learning dynamics by itself tells us very little about the representations a network learns.  If the goal is to understand the impact of weight initialization on representation learning, the paper would benefit from more direct consideration of this question.  For instance, see the question below."
                },
                "questions": {
                    "value": "Do the kernels associated with low-rank-initialized networks grow more aligned with the target function than those of high-rank-initialized networks?  Or do they merely grow \"as aligned\" as the lazier networks with high-rank initializations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Reviewer_SwWy"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission542/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698714643628,
            "cdate": 1698714643628,
            "tmdate": 1700463815798,
            "mdate": 1700463815798,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wGCT4AzZqN",
                "forum": "slSmYGc8ee",
                "replyto": "7URtMiR3F8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer SwWy (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their positive feedback on the presentation and soundness. More importantly, we thank the reviewer for their concrete suggestions to further improve upon these axes as well as  to better articulate our contribution. Below, we explain how we address the reviewer\u2019s concerns. \n\n**More explanation/intuition of the main theoretical result**: we thank the reviewer for this important comment. Our intuition is indeed in line with that of the reviewer\u2019s. As per the reviewer\u2019s suggestion, we have added a sentence explaining the intuition right after the Theorem statement. The sentence reads as \u201c*The intuition of Theorem 1 result is that, when two random vectors are drawn in high-dimensional spaces, corresponding to the low-rank initial network and the task, the probability of them being nearly orthogonal is very high; this then necessitates greater movement to eventually learn the task direction*\u201c. We have also updated the proof in the Appendix with more explanations for clarity.  \n\nIn addition, we followed the reviewer\u2019s suggestion and updated the main text with an outline of key proof steps; roughly these steps are: 1) The kernel alignment (Eq. 9) consists of three factors: $Tr(K^{(0)} K^{(f)})$, $\\| K^{(0)} \\|$ and $\\| K^{(f)} \\|$. We first derived the expression for each of them, which then gives us an expression for the kernel alignment. 2) Since we are interested in the expected alignment over tasks, we take the expectation of the expression found in step 1 over $\\beta$ (i.e. the task definition). 3) We write the resulting expression in step 2 in terms of the singular values of the weights, and we show that its optimized when the singular values $s_i$ are distributed evenly across dimensions. \n\n**Better articulation of neuroscience and ML implications**: this is another important comment from the reviewer, and other reviewers have also raised this concern. We apologize for having not made these points clear in our initial submission. In response to this, we have updated Section 4.1 in the manuscript and the paragraph reads as: \u201c*We study the impact of effective weight rank on learning regime due to its potential implications in neuroscience. In particular, learning regimes are indicative of the amount of change undergone through learning, which bear consequences for metabolic costs and catastrophic forgetting (McCloskey & Cohen, 1989; Pla\u00e7ais & Preat, 2013; Mery & Kawecki, 2005). These considerations are especially pertinent when we examine the various learning regimes evident in neural systems. For instance, during developmental phases, neural systems undergo resource-intensive, plasticity-driven transformations characterized by significant synaptic changes. These transformations are in contrast to the more subdued adjustments observed in mature neural circuits (Lohmann & Kessels, 2014). Based on this understanding, we predict that a circuit's alignment with specific tasks is likely established either through evolutionary processes or during these early developmental phases. As such, the specialization of a neural circuit (e.g., ventral vs dorsal (Bakhtiari et al., 2021)) likely stems from its engagement with tasks that share overlapping computational requirements, ensuring that each circuit is optimally configured for the tasks it is predisposed to perform. Conversely, circuits with high-rank structures, due to their inherent flexibility, are expected to be less specialized, potentially engaging in the learning of a broader range of tasks. With this in mind, our framework could be used as a tool to compare the connectivities across brain regions (and species) to predict their function and flexibility\u2026*\u201d \n\nFor deep learning, we note that while low-rank initialization is not common practice, low-rank adaptation and other update parametrizations have recently been popular in large model training schemes. See for example, Low-rank Adaptation (LoRA) in Hu et al. (2021). As such, we argue that the impact of low-rank structures on learning dynamics is quite relevant for current AI practices, and our study contributes to examining how having low-rank structures impact the effective learning regime. The methods and results we present here have the potential to be adapted and built upon to study rankedness and learning regime in several settings, and we are keen to see future work stemming from these ideas. We also note that our study has the tangential benefit of informing the deep learning community about potential applications of their models in other fields such as neuroscience. However, due to the significantly heavier balance of Section 4.1 in discussing neuroscience implication, we have removed \u201cDeep Learning\u201d in the section heading. We have updated Section 4.1 reflecting these points. \n\n**Please continue to the comment below**"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700135454340,
                "cdate": 1700135454340,
                "tmdate": 1700135454340,
                "mdate": 1700135454340,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7CtVsZYm43",
                "forum": "slSmYGc8ee",
                "replyto": "7URtMiR3F8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_SwWy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_SwWy"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors for the detailed responses and thorough revisions.  I agree with the authors and other reviewers that they improve the paper, and I now recommend that the paper be accepted (and am updating my score accordingly)."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700463796439,
                "cdate": 1700463796439,
                "tmdate": 1700466612925,
                "mdate": 1700466612925,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QZzQWZHoAX",
                "forum": "slSmYGc8ee",
                "replyto": "86R9OwFfcL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_SwWy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_SwWy"
                ],
                "content": {
                    "comment": {
                        "value": "I have two remaining concerns:\n\n-- While I appreciate the authors' additional analysis in Figure 14, the results in Figure 14D appear to be in tension with the intuition underlying Theorem 1 would predict.  Although the authors say that their findings are not contradictory (obviously they are not, assuming all are true!) it makes the findings of the paper harder to interpret for me.  If the authors have a clear understanding of why high-rank initializations result in greater target alignment during learning, despite being overall in a \"lazier\" regime, an explanation would be very helpful.\n\n-- I am still not convinced of the concrete applications of this work.  The low-rank adaptation connection seems weak to me -- LoRA uses low-rank weight updates, not low-rank initializations.  The implications for the study of learning and plasticity are rather speculative (perhaps necessarily so) given the limited understanding of the plasticity rules underlying learning in neural circuits.  This point would be strengthened if a concrete, non-obvioius prediction about neural data could be made based on the results of this work (ideally one that is testable given existing data)"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700504665495,
                "cdate": 1700504665495,
                "tmdate": 1700504665495,
                "mdate": 1700504665495,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Wk8Z3cfOfA",
                "forum": "slSmYGc8ee",
                "replyto": "7URtMiR3F8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further discussion with Reviewer SwWy (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their additional concrete and important comments to further strengthen our manuscript. Please note that we replaced the headings of subsections 4.1 & 4.2, in the previous manuscript version, with bolded text in the updated manuscript to yield extra space for incorporating the discussion points below. \n\n1) *\u201cWhile I appreciate the authors' additional analysis in Figure 14, the results in Figure 14D appear to be in tension with the intuition underlying Theorem 1 would predict. Although the authors say that their findings are not contradictory (obviously they are not, assuming all are true!) it makes the findings of the paper harder to interpret for me. If the authors have a clear understanding of why high-rank initializations result in greater target alignment during learning, despite being overall in a \"lazier\" regime, an explanation would be very helpful.\u201d*\n\nWe apologize for not having articulated how this new result integrates into our existing one, and **we hope our intuition below will better clarify and suggest how this new result in Figure 14 is actually in line with the main finding of Theorem 1**. The intuition is in line with the intuition that the reviewer asked us to articulate in their previous comment, *\u201cin high-D spaces, when you draw two random vectors corresponding to the task and the low-rank initialization, they have a high chance of being nearly orthogonal to each other\u201d*. This necessitates more movement for the low-rank initialization to be aligned to the task; consequently, this need for greater movement would require more training (as seen in Figure 14B). If training is stopped early (e.g. due to resource limitations), as likely the case in Figure 14D, they would achieve less final alignment within the training window. \n\nRegarding *\u201cIf the authors have a clear understanding of why high-rank initializations result in greater target alignment during learning, despite being overall in a \"lazier\" regime\u201d*, we would like to remark that cannot be concluded from Figure 14D alone. First of all, these different initializations all lead to similar final alignment in the setting in Figure 14B. Second, we mentioned in our previous response to this reviewer that *\u201c... we are not sure if training longer would eventually lead to similar final alignment values across initializations\u2026\u201d* Based on the upward trend at the end of Figure 14D, we predict that the alignment should continue to rise if we train longer. We note that for sMNIST, we concluded our training upon reaching 97% accuracy, a criteria informed by both published results and our computational resources. We also experimented with halving and doubling the training iterations and observed similar trends.  Whether they would all converge to similar alignment values at the end of training under a wide range of settings ties to one of the proposed future directions (see below). \n\nIn response to the reviewer\u2019s feedback, we have updated the caption of Figure 14 clarifying these points. Also, since this discussion is in line with our proposed future direction on deeper investigation of the link between rankedness, the learning regime and the consequent impact on representation (including kernel task alignment) and generalization properties of converged solutions under a wide range of settings, we have updated the corresponding sentence in Discussion alerting the reader to Appendix Figure 14. \n\n**Please continue to the comment below**"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700538442854,
                "cdate": 1700538442854,
                "tmdate": 1700538610946,
                "mdate": 1700538610946,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XmaB8l3zsa",
                "forum": "slSmYGc8ee",
                "replyto": "7URtMiR3F8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Further discussion with Reviewer SwWy (2/2)"
                    },
                    "comment": {
                        "value": "2) *\u201cI am still not convinced of the concrete applications of this work...\u201d*\n\nAlthough LoRA focuses on parameter updates rather than initializations, the exploration of how the rank of these updates influences learning regimes is a crucial area for future research. Our results provide an initial toolkit that can potentially be adapted for different contexts (e.g. with low-rank updates and structure enforced). \n\nWhile different rank initializations, to our knowledge, have been sparsely examined (an example work can be found in Vodrahalli et al. (2022)), our study indicates that they should be examined more. Indeed, our result shows that the learning regime can be influenced by initialization rank (or other structure that has an impact on rank), and that the learning regime can significantly impact the nature of the solutions learned, specifically with respect to generalization (George et al., 2022). Consequently, it's conceivable that inductive biases in the form of ranked initialization could be employed to influence the generalization characteristics of neural networks, an aspect we have identified as a potential direction for future research. We thank the reviewer for pressing us on this point, which we recognize to be important for the ML community. As such, we add this discussion point to our discussion section.\n\nFor concrete neuroscience predictions, continuing the previously added/modified discussion paragraph mentioned in the previous response, *\u201c... With this in mind, our framework could be used as a tool to compare the connectivities across brain regions (and species) to predict their function and flexibility \u201d*, we predict that the effective rank of a circuit, as determined from connectomic datasets, could indicate its level of functional specialization. Low-rank connectivity suggests a higher learning cost for diverse tasks, potentially rendering these circuits less adaptable for generalist roles. However, we acknowledge that the link between rankedness and specialization could be confounded by other factors \u2014 such as the underlying plasticity rule (also recognized by the reviewer) and the task rank that have been mentioned in Discussion, underscoring the need for deeper explorations in the future. \n\nAn additional concrete prediction of our theory would be that for neural circuits learning a new task, connectivity rank would influence how much change in task-dependent neural activity is expected before vs after training. Existing brain-machine interface experimental protocols already allow to explore this question, by measuring changes in activity during learning following readout perturbation, which was done by substituting a new mapping connecting\nneural activity to BCI output positions (i.e. re-initializing the readout weights). In previous work (Sadtler et al. (2014) and Golub et al. (2018)), the authors show that learning following a perturbation differs whether or not the perturbation was within neural activity manifold, or outside of it, necessitating some realignment to the task. One could apply this analysis to test the prediction by examining how the learning differs depending on the rank of the new readout. We have updated Discussion reflecting these points. \n\nOverall, we note that the study of learning regimes is of great interest to the neuroscience community as it can inform ways by which neural circuits may exploit synaptic plasticity to perform credit assignment. A number of recent publications explore this topic, including Bordelon and Pehlevan (2023) that explores the impact of biologically plausible learning rule on learning dynamics and representation in different learning regimes, and Flesch et al. (2022) that compare experimental data to expected neural activity changes in distinct regimes. Overall, much like for the deep learning advantages outlined above, there is an interesting question about the characteristics of solutions that are discovered by different learning regimes, with some being more prone to spurious correlations and therefore, with distinct generalization properties (George et al., 2022) to be further examined in the future. It is likely that different brain regions employ different learning regime strategies and our contribution helps the community effort in building a toolbox to explore this question. \n\nIn summary, we hope we convinced the reviewer that the question of learning regime and connectivity is of great interest from different perspectives, and that our results help contribute to better understanding impacts on both biology and AI."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700538580887,
                "cdate": 1700538580887,
                "tmdate": 1700538628276,
                "mdate": 1700538628276,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ftRsMUHauh",
            "forum": "slSmYGc8ee",
            "replyto": "slSmYGc8ee",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission542/Reviewer_Cn5Y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission542/Reviewer_Cn5Y"
            ],
            "content": {
                "summary": {
                    "value": "This study examines how the initial connectivity of a neural network affects its learning regime (lazy vs rich). In particular. the authors focus on the rank of the connectivity, in contrast to e.g. weight variance studied in previous work. The main motivation for this is the claim that biological networks have low-rank connectivity. Both in theory using feedforward linear networks, and in experiments using recurrent non-linear networks, it is shown that low-rank initialisation lead to richer learning than full-rank initialisation (except, if the low-rank initialisation aligns with the task). This is intuitive as high rank initialisation means it is likely that some (linear combination of the) columns of weight matrix are already aligned with the task matrix, whereas a low-rank matrix will most likely be orthogonal with the task at initialisation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The question of how connectivity influences representation and learning dynamics is of significance, both for the neuroscientists, as well as for machine learning scientists. How low-rank initialisation affects the learning regime has as far as I am aware not been studied in depth, yet networks with low-rank weight matrices are used by both the deep-learning and computational neuroscience communities.\n\nThe paper is well written and the main idea is clearly presented. Multiple experiments are performed that highlight the main result and the supplementary contains a large amounts of controls. The experimental results are supported by theoretical results on linear feedforward networks.\n\nOverall I lean on accepting this paper, and I would increase my score if the concerns below are addressed"
                },
                "weaknesses": {
                    "value": "1. While many controls are done, the initial dynamic regime of the network (stable, unstable or chaotic) is not controlled for (see questions below).\n2. I am not entirely convinced by the evidence given for the statement that the brain has low-rank connectivity. The paper repeatedly cites Song et al., 2005 and Mastrogiuseppe & Ostojic, 2018 as evidence for low-rank connectivity in the brain. The latter is a purely theoretical study, which I am not sure why it used as evidence for biology. The former indeed studies biological neural circuits, and found that the distribution of synaptic connection strength can be fitted by a lognormal distribution, as well as the circuits having overrepresented bidirectional connectives. While my intuition is that this implies low-rank connectivity, it can (and likely should) be made clear if this is the case. In general the relation between local connectivity patterns and (global) rank is not always obvious a priori (potentially, see Shao & Ostojic 2023).\n3. Biological constraints are only used as initialisation and not enforced during training. This decreases the relation of the simulations to biology, as neurons in the brain can (generally) not just decide to forget about e.g. Dale\u2019s law during learning.\n4. The authors claim to study continuous-time networks, however, $dt$ is set equal to $\\tau_m$, and tasks have around 10 time steps after discretisation. It could be questioned how well the simulations reflect the continuous-time equations.\n\nMinor:\n1. Equation 10, last line should say d instead of 3 above the equality sign.\n2. Figure 3B left, title is cut off.\n3. The 5th references seems formatted wrong.\n4. Equation 1. -> It could be named explicit that you are making an exponential Euler approximation (which is not used in the studies cited here)."
                },
                "questions": {
                    "value": "The questions are all related to the initial dynamic regime versus initial connectivity \n\n1.  I would like to the authors to comment on whether the difference in lazy versus rich learning is potentially confounded by the regime of the initial dynamics (stable, unstable or chaotic), instead of the rank of the initial matrix. Three results that lead me to hypothesise there is at least some influence of dynamic regime on the learning:\n\n- For Figure 1, the large full rank networks will likely be initially be chaotic, given a gain of 1.5 (transition at $\\sqrt(2)$ for ReLU networks; Kadmon & Somplinsky 2015). However at least part of the truncated networks (despite rescaling by the norm) will likely be not.\n- The outlier eigenvalue in the networks of Figure 2 might lead to (unstable) dynamics initially exploding in the direction of the corresponding eigenvector, instead of following a chaotic regime. \n- Finally, in Figure 9, the differences between low-rank and full-rank networks diminishes when both are initialised in the stable regime.\n\n2. Were the Dale\u2019s law networks balanced? E.g. increasing inhibitory strength if less then 50% of neurons are inhibitory, so that the expected input to neurons stays zero, would put the Dale\u2019s law networks in similar regimes as the controls (see Rajan & Abbott, 2006). \n\n3. The Eigenspectrum, and as a result the initial dynamics, of the full-rank random networks are most likely approximately constant between networks, whereas the (non-zero part of the) eigenspectrum of the low-rank networks will vary more over initialisations - is this related to the observed high variance in richer learning between the low-rank models?\n\nNote that getting to same dynamics could be partly ameliorated by scaling by the largest singular value instead of the norm (which are realistically only approximately proportional for the large full rank networks). However this also is not a guarantee, as e.g. as stated above balancing also has an influence on dynamics"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Reviewer_Cn5Y",
                        "ICLR.cc/2024/Conference/Submission542/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission542/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698747406179,
            "cdate": 1698747406179,
            "tmdate": 1700211875661,
            "mdate": 1700211875661,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZfPfhAGTTU",
                "forum": "slSmYGc8ee",
                "replyto": "ftRsMUHauh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Cn5Y (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their insightful contextualization of this work, effective articulation of our intuition and providing constructive and executable suggestions to both improve the content and presentation of this work. Below, we explain how we address all of the reviewer\u2019s concerns. \n\n**Confounding factor from dynamical regime**: We thank the reviewer for this insightful comment/question. Indeed, it is plausible that the learning regime in RNNs could be influenced by the initial dynamical regime. With stable dynamics (non chaotic) , for instance, activity typically settles into steady states in absence of inputs over time steps, potentially needing more weight adjustments during training to effectively propagate information to the last time step. The study of learning dynamics and dynamical regime of RNNs is rich and involved and there are multiple ways to control for dynamics stability. A common method is through the leading weight eigenvalue of the connectivity matrix, which directly influences the top Lyapunov exponent dictating the rate of trajectory expansion.\n\nAs such, we now add details about a new control where we compare the leading weight eigenvalue (Appendix Figure 19), and we observed a consistent trend: higher-rank initializations lead to effectively lazier learning post-training. We note that a deeper exploration of the relationship between learning regime and various notions of the dynamical regime is a promising avenue for future work but falls outside the scope of the present paper, and we express this view in the discussion. We thank the reviewer for this insightful comment/question, and in response, we have updated the manuscript that added sentences in Simulation Results to reflect these points and alert interested readers to Appendix Figure 18. \n\n**Evidence that the brain uses low-rank connectivity**: we thank the reviewer for pointing out this important and subtle point. In response to the reviewer\u2019s important point, we have toned down our claim throughout the manuscript (Abstract, Introduction and Discussion in particular): there are evidence (e.g. Song et al.) \\textbf{suggestive} of effective low-rank structures in the brain, rather than hard evidence. We also removed the citation to Mastrogiuseppe & Ostojic here, as the reviewer pointed out. We originally had a sentence in between the two citations but it got lost in the editing. \n\nThe extent to which the brain utilizes low-rank structures remains an open question, given the significant variation in neural circuit structures across regions and species. On top of that, as the reviewer pointed out, while local connectivity statistics can offer some predictive insight into the global low-rank structure, this relationship is not always immediately apparent (Shao & Ostojic, 2023). Our theoretical results contribute to this discourse by providing tools that link connectivity features, particularly effective rank, with learning (see Section 4.1). We have updated the manuscript reflecting this discussion in Related Works and Limitations & Future Directions. \n\n**Please continue to the comment below**"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700135205692,
                "cdate": 1700135205692,
                "tmdate": 1700135216261,
                "mdate": 1700135216261,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MuybX9ldG1",
                "forum": "slSmYGc8ee",
                "replyto": "ftRsMUHauh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Cn5Y (2/2)"
                    },
                    "comment": {
                        "value": "**Biological constraints enforced during training**: we agree with the reviewer that enforcing constraints (e.g. Dale\u2019s law) would be important for biological relevance. We initially didn\u2019t do this to test our theoretical prediction, which assumes gradient-descent update without constraints. Following the reviewer\u2019s comment, we have added a new figure (see Appendix Figure 17) with Dale\u2019s law enforced for the EI experiments and observed similar trend as before: EI initialization led to greater changes post-training. We have also added sentences in Simulation Results alerting readers to this appendix figure. \n\n**Continuous RNN settings**: we thank the reviewer for this important comment. We have now added Appendix Figure 18 to show our main conclusions \u2014 that higher rank random initializations lead to effectively lazier learning \u2014 also hold for the case when $\\tau_m > dt$ and with longer sequence length. Specifically, we kept $\\tau_m=100$ but changed $dt$ from $100$ to $20$, which increased the sequence length by a factor of 5. We have also added sentences in Simulation Results alerting readers to this appendix figure. \n\n**Balance Dale\u2019s Law**: we thank the reviewer for this question and we apologize that it wasn\u2019t clear. We used 80% excitatory and indeed balanced the initialization according to standard practices. We have updated Setup & Simulation Details reflecting this point. \n\n**High variance due to variable eigenspectrum in low-rank network**: However, our newly added Appendix Figure 19, which maintains a relatively stable leading eigenvalue by fixing the dominant eigenvalue across comparisons, still results in high variance for low-rank initializations. This suggests that there may be other factors contributing to this high variance, and it would be interesting to examine this in the future. This point is also reflected in the sentences added to Simulation Results, as a part of responses to the reviewer's earlier comment about the dynamical regime as a possible confounding factor.\n\n**Minor fixes**: we thank the reviewer for catching these and we have fixed them."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700135249443,
                "cdate": 1700135249443,
                "tmdate": 1700136222398,
                "mdate": 1700136222398,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "E4yl0jjCp2",
                "forum": "slSmYGc8ee",
                "replyto": "MuybX9ldG1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_Cn5Y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_Cn5Y"
                ],
                "content": {
                    "title": {
                        "value": "Response to revisions"
                    },
                    "comment": {
                        "value": "First of all, I want to applaud the authors for such a thorough response! I have increase my score, as the following points are now all addressed: \n\n- Whether or not the brain has low-rank connectivity is now phrased in a more appropriate manner\n\n- The case of constraints not being applied during training, and the case of large time integration steps are clearly resolved.\n\n- The control analysis (Figure 19), largely ameliorates the issue of the initial dynamic regime. As noted above this does not 100% fix the issue, but this is also clearly acknowledged in the paper.\n\n\nI found two typos:\n\n- Page 6: archtiecture -> architecture\n\n- Figure 15 Caption:  A reference is broken"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700212351396,
                "cdate": 1700212351396,
                "tmdate": 1700212351396,
                "mdate": 1700212351396,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pLId3si0bY",
            "forum": "slSmYGc8ee",
            "replyto": "slSmYGc8ee",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission542/Reviewer_RNHT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission542/Reviewer_RNHT"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies how structure in the weight matrices -- focusing on the recurrent weight matrices in RNNs, and feedforward matrix in two layer linear feedforward networks -- shapes rich and lazy learning (roughly whether the weights change a lot or negligibly through learning respectively). The paper finds that high-rank initializations lead to so-called \"lazier\" learning, whereas lower rank initializations tend to lead to \"richer\" learning, or larger changes in the weights. If the low-rank intialization is already suitable for the task, there can be negligible changes to the weights as well."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The results (analysis in linear feedforward networks, and experiments in RNNs) appear technically correct, and are in line with existing literature on how weights change during learning. Note that I skimmed through the Appendix and did not closely check the proofs."
                },
                "weaknesses": {
                    "value": "I felt like the paper could provide a more finer-grained description and insight into how the initialization scheme affects the final solution. This could be by providing insight into how the existing metrics (from Sect 2.3) were changing during learning as a function of training epoch (rather than just applied on the final solution, esp. when in the rich regime) and/or through the use of additional finer-grained metrics. As it stands, it feels like there could be different explanations for how the weights are evolving during learning (that I think are interesting and important); for example is the largest rank component changing first or changing in magnitude the most during learning? Does this happen even if the task is low-rank but the (low rank) initialization is not perfectly aligned with the task?\n\nI think this could be addressed both in experiments as well as in the linear setting where the authors make analytical statements. For example, Prop 1 appears considers a low-rank 1 initialization completely aligned with the task (initialized with $\\beta$) -- but I think it would be helpful to understand in general how does a low rank initialization compare with a high rank initialization for learning some fixed (low rank) task, rather than an expectation over all tasks? In other words in general would a low-rank initialization be better for a low rank task and why/why not? also how are weights/singular components evolving to facilitate the learning? \n\nAs an aside, the paper could be made stronger if the case that the theory studied was closer to the experiments (though I understand that it is easier to analyze in the linear FF setting and that the theory still provided insight for the RNN experiments). \n\nThe presentation and writing was generally clear but can be improved. While reading the paper, it felt like, at times, the writing was too verbose and could have been made clearer. For example, \"A nexus between deep learning and neuroscience has expanded the applications of deep learning theoretical frameworks to study the learning dynamics of biological neural network\", and \" Our work builds on these studies by further exploring the precursors of these regime\" could be more clear.  Minor: Fig 3B, left title not visible"
                },
                "questions": {
                    "value": "- For the proof in the Appendix of Thm 1, while do you need the scale $\\sigma = \\||W_i(0)||_F$ to be small? Also small relative to what?\n- Is there evidence that the initial connectivity structures in biology are low-rank?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission542/Reviewer_RNHT"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission542/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698965666698,
            "cdate": 1698965666698,
            "tmdate": 1699635981311,
            "mdate": 1699635981311,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "29Z8Ex2y8D",
                "forum": "slSmYGc8ee",
                "replyto": "pLId3si0bY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RNHT (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their accurate summary of our work. We also thank the reviewer for their insightful comments to enrich the study and concrete suggestions to improve the presentation. We explain below how we address the reviewer\u2019s comments.\n\n**More fine-grained description of the impact of initialization schemes**: In line with the reviewer\u2019s suggestion of tracking impact on not just the final trained network but also during the learning process (and related comments by other reviewers), we have now added Appendix Figure 14 tracking the tangent kernel alignment as well as the alignment of the kernel and task throughout training. Figure 14A examines the kernel alignment (alignment of the current kernel to the initial one) in the idealized linear setting with 2D input in Fig. 2 in Atanasov et al. across different initialization schemes: random rank-1 initialization, random full-rank initialization and initially aligned low-rank initialization. We see that low-rank random initializations lead to greater movements, i.e. growing to be more dissimilar to the initial kernel (lower alignment value). Figure 14B looks at the task kernel alignment, $y^T K y / |y|^2 TrK$. Regardless of the initializations, the network kernel moves to be more aligned to the task over training. Low-rank initialization, without being specifically tuned to the task, is the latest to achieve alignment. \n\nFigure 14C examines the kernel alignment (alignment of the current kernel to the initial one) in a non-idealized setting: sMNIST task. Again, random low-rank initialization leads to more movement over training, i.e. more dissimilar to the initial kernel. For Figure 14D, with multiple (10) output targets, we track the centered kernel alignment (CKA) of the NTK and class label, e.g. used in Baratin et al. (2021). We again saw that all initializations grow to be more aligned with the class label through training, but higher rank initialization gets to a higher alignment value faster and with less kernel rotation. We have already trained for nearly 20000 SGD iterations and we are not sure if training longer would eventually lead to similar final alignment values across initializations. We note that although achieving higher CKA over training can indicate greater degree of feature learning, a hallmark of the standard rich regime, this does not contradict our findings centered on effective learning regime that is defined based on the amount of change post-training (see Introduction).\n\nIn addition, to examine how the leading component changes relative to the rest, we track the evolution of the kernel effective rank, inspired by Baratin et al. (2021) in Appendix Figure 15. Here, the effective rank is the ratio of the trace to the dominant one, thereby capturing how much the leading eigenvalue evolves relative to the rest. We found that the kernel effective rank is getting closer to the target/task dimension over training. \n\nPlease note that we focused the additional analyses on the network kernel rather than individual layer weights, as the former is more reflective of the network\u2019s function as a whole. To incorporate these new findings in the main text, we have added sentences in Simulation Results to bring these Appendix Figures to the attention of an interested reader. \n\n**Feedforward theory and RNN experiments**: We agree with the reviewer\u2019s comment. Note that the new addition of feedforward experiments in non-idealized setting (in response to Reviewer rK41) would be a step closer to what the reviewer suggests about closer theory and experiment setting. \n\n**Improving presentation**: We thank the reviewer for this suggestion. We fixed several more verbose sentences in addition to the one the reviewer pointed out, including the very first sentence in Introduction. We have also fixed the typo that the reviewer pointed out for Figure 3B (now in Figure 2) in the original submission. \n\n**Please continue to the comment below**"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700134523426,
                "cdate": 1700134523426,
                "tmdate": 1700134942248,
                "mdate": 1700134942248,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cvuQqLwJMO",
                "forum": "slSmYGc8ee",
                "replyto": "pLId3si0bY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Request for discussion"
                    },
                    "comment": {
                        "value": "Dear Reviewer RNHT,\n\nAs the author-reviewer discussion period nears its end, we would appreciate any feedback on whether our responses have addressed your concerns. If there are additional questions or points we can address, please let us know. We hope our recent updates have resolved the initial concerns and are committed to further improving our paper through this constructive dialogue.\n\nThank you, Authors"
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700583648537,
                "cdate": 1700583648537,
                "tmdate": 1700583648537,
                "mdate": 1700583648537,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zBQkRPT10S",
                "forum": "slSmYGc8ee",
                "replyto": "pLId3si0bY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_RNHT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission542/Reviewer_RNHT"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the authors for the detailed reply. I have also read the other reviewer comments. I think the presentation and clarity has been improved in the revised manuscript. I also appreciate that the authors have done a large and commendable amount of experiments including the additional ones during the rebuttal period, which have addressed some of my concerns. \n\nHowever, I still am of the sentiment (similar to reviewer SwWy) that the paper does not clearly explain *why* low rank initializations lead to \"richer\" learning. For example, this finding appears to be dependent on the choice of the initial gain $g$ in the recurrent weight matrix (in Fig 8d in Appendix, for gain < 1 weights appears to change more with increasing rank), which suggests there is a more nuanced explanation than only the rank of the initial weight matrix. This also appears to differ to the  feedforward theory which was true when $\\sigma << 1$, which also sets the scale at initialization. Related (and minor): it would be also helpful to clarify the details of the initialization for the new feedforward experiments done in the revision."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission542/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642074698,
                "cdate": 1700642074698,
                "tmdate": 1700681718897,
                "mdate": 1700681718897,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]