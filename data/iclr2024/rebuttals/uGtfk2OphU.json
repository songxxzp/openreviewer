[
    {
        "title": "Boosting Selective Rationalization with Shortcuts Discovery"
    },
    {
        "review": {
            "id": "AVaLQ9f02P",
            "forum": "uGtfk2OphU",
            "replyto": "uGtfk2OphU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9216/Reviewer_LMAN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9216/Reviewer_LMAN"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies selective rationalization. Existing methods suffer at some extent from spurious correlation (i.e., shortcuts). The authors propose shortcuts-fused selective rationalization (SSR) to mitigate spurious correlation. More specifically, they employ semi-supervised rationalization: given an annotated datasets of rationals and labels, they train SSR on it. Then, they train an unsupervised rationalization method on the same data and use the previous model to identify spurious tokens. This new knowledge is then transferred to the unsupervised setup. Since the main method relies on annotated data, the authors propose two data augmentation techniques to mitigate the low-amount of available data.\n\nThe method where one exploits a supervised rationalization model to identify spurious rational tokens from an unsupervised model is interesting, but relies on a \"large\" amount of available rationales. Overall, a supervised rationalization model has to be trained to improve an unsupervised one, which greatly limits the applicability of the method, even though a data augmentation approach is proposed. I would be curious whether transferring the knowledge from one task to another could be possible to some extent (not necessary from movie-dataset-1 to movie-dataset-2).\n\nThe experiment section is lacking unsupervised baselines and standard datasets used in selective rationalization [1-6, to cite a few but more are missing] (should also be included in the related work section). In terms of dataset: beers, hotels, amazon, and the other tasks of ERASER. Moreover, I would highly encourage the authors to conduct a human evaluation regarding the produces rationales. The relationship between the number of augmented data vs task/rational performance is currently unclear. I would appreciate having a graph showing how the performance evolve according the number of added data.\n\n1 Bao et al. 2018, Deriving machine attention from human rationales (EMNLP) 2 Chan et al. 2022, UNIREX: A Unified Learning Framework for Language Model Rationale Extraction (ICML) 3 Antognini et al. 2021, Multi-Dimensional Explanation of Target Variables from Documents (AAAI) 4 Chang et al. 2019, A Game Theoretic Approach to Class-wise Selective Rationalization (NeurIPS) 5 Antognini and Faltings 2021, Rationalization through Concepts (ACL) 6 Yu et al. 2019, Rethinking Cooperative Rationalization: Introspective Extraction and Complement Control (EMNLP)"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Interesting framework to leverage supervised and unsupervised rationalization models\n- The performance (although not the same configuration each time) is closed to supervised baselines"
                },
                "weaknesses": {
                    "value": "- the clarity of the paper could be improved, especially section 3\n- weak experiment section: more baselines, datasets, and analysis would be required\n- lack of human evaluation"
                },
                "questions": {
                    "value": "- How would perform sup-rat with data augmentation?\n- Could you also report metrics regarding comprehensiveness and sufficiency to assess the improvement of the proposed approach to decrease spurious correlation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9216/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698610725265,
            "cdate": 1698610725265,
            "tmdate": 1699637159609,
            "mdate": 1699637159609,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ChbdHOsdbf",
                "forum": "uGtfk2OphU",
                "replyto": "AVaLQ9f02P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9216/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9216/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer LMAN (1/4)"
                    },
                    "comment": {
                        "value": "Thank you for your time and insightful suggestions! According to your comments, we conduct additional experiments and provide the responses as follows:\n\n> **Comment1**:I would be curious whether transferring the knowledge from one task to another could be possible to some extent (not necessary from movie-dataset-1 to movie-dataset-2).\n\nThis is an interesting question! We conduct experiments to illustrate this. As shown in the table, we first train ${SSR}_{unif}$ and AT-BMC (the state-of-the-art (SOTA) supervised rationalization approach) on the BoolQ dataset, and then evaluate them on Movie and MultiRC. \n\nFrom the experimental results, we can see that both AT-BMC and ${SSR}_{unif}$ cannot achieve good results.  \n\nThe reason may be the data distributions are too different.\n\n| ${SSR}_{unif}$ | Task | Token-F1 |      | AT-BMC        | Task | Token-F1 |\n| -------------- | ---- | -------- | ---- | ------------- | ---- | -------- |\n| BoolQ-Movie    | 48.7 | 19.4     |      | BoolQ-Movie   | 50.3 | 19.3     |\n| BoolQ-MultiRC  | 46.0 | 20.7     |      | BoolQ-MultiRC | 45.2 | 28.5     |\n\n\n\n> **Comment2**:The relationship between the number of augmented data vs task/rational performance is currently unclear. I would appreciate having a graph showing how the performance evolve according the number of added data\n\nHere, we compare ${SSR}_{unif}$ with different percentages (0-25%) of semantic DA on the Evidence Inference dataset.\n\nFrom the experimental results, we can observe that both task and rationale performance are improving as the number of added data increases. Among them, the rationale performance improvement is more obvious and has a significant improvement when the number of added data reaches 15% of the total data.\n\n| Method             | 0          |            | 5        |          | 10       |          | 15       |          | 20       |           | 25         |            |\n| ------------------ | ---------- | ---------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | --------- | ---------- | ---------- |\n| ${SSR}_{unif}$     | Task       | Token-F1   | Task     | Token-F1 | Task     | Token-F1 | Task     | Token-F1 | Task     | Token-F1  | Task       | Token-F1   |\n| + $k$% random DA   | 46.8 \u00b1 0.3 | 26.8 \u00b1 0.2 | 47.3\u00b10.5 | 28.5\u00b10.3 | 47.7\u00b10.4 | 29.0\u00b10.5 | 48.5\u00b10.6 | 30.3\u00b10.2 | 49.2\u00b10.4 | 30.7\u00b10.7  | 46.0\u00b10.1   | 33.1\u00b10.2   |\n| + $k$% semantic DA | 46.8 \u00b1 0.3 | 26.8 \u00b1 0.2 | 46.6\u00b10.1 | 28.9\u00b10.4 | 47.1\u00b10.3 | 29.3\u00b10.5 | 47.6\u00b10.7 | 31.9\u00b10.4 | 48.0\u00b10.7 | 32.1\u00b1 0.5 | 48.7 \u00b1 0.2 | 33.5 \u00b1 0.4 |"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9216/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699940285705,
                "cdate": 1699940285705,
                "tmdate": 1699940734984,
                "mdate": 1699940734984,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LXKnS89ByG",
            "forum": "uGtfk2OphU",
            "replyto": "uGtfk2OphU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9216/Reviewer_cE5E"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9216/Reviewer_cE5E"
            ],
            "content": {
                "summary": {
                    "value": "The paper \"Boosting selective rationalization with shortcuts discovery\" proposes an extension to selective text rationalisation methods by using so-called shortcuts in analysis and prediction for text. Here, rationalisation is an attempt to find fragments that influence the final classification The authors note that frequently, in unsupervised approaches, algorithms search for so-called shortcuts, which, while they may be strongly, but spuriously, correlated with the final classification, do not in any way explain the real reasons for a given classification. They therefore suggest a combination of supervised algorithms, where the true rationales (input elements influencing the classifications) are predefined by experts, and unsupervised methods, where the rationales are searched for. The proposal is thus to exclude those unsupervised rationalizations found that are not defined by experts. By excluding these unnecessary shortcuts, the proposed SSR algorithm achieves results that are similar to SOTA approaches, beating many other approaches.\n\nThe use of ChatGPT in appendix C.2 where it, essentially, selects the proposed approach over other methods, is nice and might be entertaining, but it does not introduce anything to the problem at hand. I would remove it, if I were you. But you, naturally, may do as you please.\n\nThe work on this subject is clearly very much needed these days. On the other hand, I think that this paper does not introduce new ideas. The use, or rather the exclusion of the \u201cshortcuts\u201d in a model, does not introduce enough new knowledge to push the model prediction understanding much."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors consider an important problem of rationalisation, understood as the selection of the parts of the classified input that have the greatest impact on the classification of the problem. The issue considered is of the natural language processing tasks. The solution is described in great detail in the form of a mathematical derivation, which is a strength, but in too much detail makes the article hard to read sometimes. It has the advantage of attempting to combine supervised and unsupervised approaches in order to exclude as found rationalisations those fragments that only have spurious correlations with the output, but do not explain anything."
                },
                "weaknesses": {
                    "value": "1. The concept of a shortcut itself is very vague, and the definition and proposed selection algorithm (as described above by discarding the undefined) is too simplistic. The authors use one example of such a spurious correlation that does not describe much of the decision much, throughout all the article.\n2 The entire article is written in a way that is difficult to understand. Lots of equations, with several variables with stacked indices, reduces the readability and the clearness of what the authors want to achieve. \n3. There is no clearly stated hypothesis at the beginning of the text. The approach may be obvious to the author, but readers will not understand and will abandon reading before the end.\n4. The authors introduce a number of loss functions which can be used in different configurations, with no clear intuition which should be used and why.\n5. The authors introduce \u201cdata augmentation\u201d DA approaches into their model. However, they seem to have forgotten the MixedDA solution, which is in the tables but not in the description (section 3.3). The models with and without augmentation are compared, and in some cases of algorithms or data one type of augmentation gives better results, but these results are not consecutive (see table 1). It seems to me that the augmentation ideas not really matter. The differences are small, in any case.\n6. The text introduces a great deal of patterning, both when describing existing methods and the author's own proposal. This does not make it easy to read, as many of them do not explain the next steps in any way, such as the definition of Gumbel-softmax on page 3."
                },
                "questions": {
                    "value": "1. The definition and suggested algorithm for selection (as described above by rejecting the undefined) is too simplistic. The authors use only one example ('received a lukewarm approach' in the film review) throughout the article. Doesn't such a solution reduce the proposal to a supervised approach? Please use another example of a shortcut.\n2 The entire article is written in a way that is difficult to understand. There is no clearly stated hypothesis at the beginning of the text. The approach may be obvious to the author, but readers will not understand and will abandon reading before the end. Could you clearly state your hypothesis in the introduction?\n3. Is the whole of section 2 your proposition, or the definition of possible solutions used now? It is not clear.\n3. A number of cost functions are given that are to be utilized in different configurations.  Since the background models are quite complex (Transformer, both as encoder and encoder/predictor, as well as other generative models) these loss functions tend to be complex too. Some might be removed with more intuition on the more important in exchange.\n4. What actually is the \u201cshortcut imitator\u201d (pages 5 and 6 and later), what is it used for?\n5. Please explain what is the MixedDA augmentation in subsection 3.3.\n6. In the results tables, these with the best value are bold-faced as the best. But the mean differences may be as low as 0.1%, which statistically are not, in any way, significant. The authors should perform some statistical analysis and group the algorithms into groups of statistical equivalence (see e.g. Demsar, Statistical comparisons of classifiers over multiple data sets, JMLR 7, 2006; open software for that approach is available).\n\nLess essential:\n1. Difficulty in reading may come from poor English. I suggest the involvement of a native speaker.\n2. Instead of very many formulas, drawing diagrams of the methods should be shown, which would explain much more. Also, nothing is contributed by the detailed descriptions of all cost functions in the description of the general methods as well as the own proposal.\n3. in table 3 the result 90.7 for SSR_unif with DA is chosen as best, even though that of WSEE with DA of 91.0 mean seems better. That is perhaps a typing error, or is it?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9216/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9216/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9216/Reviewer_cE5E"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9216/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698654455180,
            "cdate": 1698654455180,
            "tmdate": 1699637159498,
            "mdate": 1699637159498,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NZO5Jjnv8y",
                "forum": "uGtfk2OphU",
                "replyto": "LXKnS89ByG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9216/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9216/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer cE5E (1/4)"
                    },
                    "comment": {
                        "value": "We appreciate your comments! To address your concerns, below we prudently justify the details of our proposed method and conduct more experiments.\n\n> **Comment1**: The definition and suggested algorithm for selection is too simplistic. \n\nThank you for your comments, below we present the details of the definition and suggested algorithm for selection.\nDefinition: Given the text input $x={x_{1}, x_{2}, \\ldots, x_{n}}$, the goal of selection is to first generate a mask variable $m=\\{m_{1}, m_{2}, \\ldots, m_{n}\\}$, where $m_{j} \\in\\{0,1\\} $ indicates whether the $i$-th token is a part of the rationale. Finally, the selection function selects the rationales as $z = m \\odot x= \\{m_{1}\\cdot x_{1}, m_{2} \\cdot x_{2}, \\ldots, m_{n} \\cdot x_{n} \\}$.\nBriefly, the goal of the selection is to extract a subsequence from the original text to be utilized as rationales to support the prediction results.\n\nAlgorithm: In order to select whether each token is rationale or not, we reduce the rationale extraction algorithm to a token-level binary classification task, i.e., predicting the probability that a token is a rationale token. Specifically, we map each token $x_{i}$ to the probability of being selected as part of rationale: \n  $p_{\\theta}(m_{i}|x_{i}) = softmax(W_{s_{un}}f_{s_{un}}(x_{i}))$.\nAmong them, $f_{s_{un}}(\\cdot)$ represents an encoder encoding $x_{i}$ into a $d$-dimensional vector, and $W_{s_{un}} \\in {R}^{2 \\times d}$.\n\nThen, in order to train the model to be able to extract rationales, there are different training approaches for unsupervised and supervised rationalization:\n\nFor unsupervised rationalization, due to the lack of labeled rationales, the selection function must be cascaded with the predictor, where the rationale learning signal for unsupervised rationalization must rely on comparing the prediction of the predictor with the ground-truth task label.\n\nFor supervised rationalization, since the labeled rationale is known, we can use the token-level binary cross-entropy (BCE) cost function to train supervised rationalization.\n\n> **Comment2**: The authors use only one example ('received a lukewarm approach' in the film review) throughout the article. Doesn't such a solution reduce the proposal to a supervised approach? Please use another example of a shortcut.\n\nFirst, the shortcut does not reduce the proposal to a supervised approach. Specifically, the example we give in the paper is a real example from the Movie dataset, where the shortcut 'received a lukewarm approach' is obtained by our shortcut discovery strategy, not by a priori human annotation. Besides, it is noted that our shortcut discovery strategy relies on the rationale of the true annotation. However, since the rationale annotation is difficult to obtain for most tasks, shortcuts can not reduce the proposal to a supervised approach in most cases. Therefore, in our SSR, we use a semi-supervised approach.\nFinally, we also visualize some of the shortcuts obtained by our shortcut discovery strategy in  Appendix  C.5, which we further illustrate one of them here:\n\nWe visualize another example on Movies (the label is positive),  where the italic tokens represent the real rationales, and the bolded ones are the predicted rationales.:\n\n| Model    | Visualized example  | Predicted label |\n| - | - | --|\n| Vanilla Un-RAT  | **Mozart is a famous musician** and amadeus is a biographical film about him , ***amadeus is a true work of art*** . it is one of those few movies of the 80 ' s that *will be known for its class , its style , and its intelligence. why is this **such a good film***... | positive        |\n| ${SSR}\\_{unif}$ | Mozart is a famous musician and amadeus is a biographical film about him , ***amadeus is a true work of art*** . it is one of those few movies of the 80 ' s that ***will be known for its class*** , *its style , and its intelligence. why is this **such a good film***... | positive  |\n\nFrom the results, we can find  although both Vanilla Un-RAT and ${SSR}\\_{unif}$ predict the label as positive correctly, Vanilla Un-RAT still extracts shortcuts as rationales. Specifically, \"Mozart is a famous musician\" is the shortcuts. Although Mozart was a great musician, it has no relevance to how good his biographical film is. ${SSR}\\_{unif}$ avoids these shortcuts, but Vanilla Un-RAT extracts these as rationales.\n\n> **Comment3**: Could you clearly state your hypothesis in the introduction?\n\nThank you very much for your suggestion, putting our assumptions in the introduction is really beneficial for readers to read. Therefore, we have revised the introduction (the blue text) in the revised version and uploaded it to ICLR. Please review it, and if there are any problems, please let us know.\n\n> **Comment4**: Is the whole of section 2 your proposition, or the definition of possible solutions used now? It is not clear.\n\nThank you again for your suggestions. Based on your suggestions, we have organized section 2 and updated it in the revised version."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9216/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699940084401,
                "cdate": 1699940084401,
                "tmdate": 1699940084401,
                "mdate": 1699940084401,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rtG4PUrBnZ",
            "forum": "uGtfk2OphU",
            "replyto": "uGtfk2OphU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9216/Reviewer_2gye"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9216/Reviewer_2gye"
            ],
            "content": {
                "summary": {
                    "value": "The paper solves selective rationalization, an NLP problem where the aim is to find a piece of text from the input called \"rationale\" that directly justifies the label (selector problem), then use the rationale as input to do classification (predictor problem). Unlike \"rationales\", there are are pieces of text called \"shortcuts\" that can result in correct prediction but are not proper justifications of the label. The exact difference between rationales and shortcuts is not clearly defined in the paper, so it seems that the distinction is problem-specific and ultimately something that is left to the practitioner. Previous selective rationalization methods can be categorized into supervised, where the rationales are provided during training, and unsupervised, where they have to be inferred during training process. The paper proposes a semi-supervised approach (an extension of a couple of recent papers) where a selector model trained in the unsupervised way is applied to smaller supervised data to identify the shortcuts and retrain the selector model. In addition, two data augmentation methods were proposed to enrich the shortcut discovery. The proposed approach is evaluated in 4 datasets. The model outperforms previous SOTA unsupervised and semi-supervised methods on both rationale prediction and label prediction tasks. The performance is also\ncomparable to the supervised baselines"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The paper introduces innovative techniques to prevent the model from erroneously considering shortcuts as rationales during predictions. Since the objective is to answer the question \u201cWhich text span leads to the final conclusion\u201d, this approach can be beneficial when there are misleading shortcuts in the text. Such predictions can help us analyze the reasoning ability of large language models (LLM).\n- The authors conducted comprehensive experiments on more than 10 variants of the proposed approach. Informative discussions are also presented. Tests are performed on four datasets from diverse domains and results are compared with SOTA baselines from all 3 groups of previous methods. Such rich experiments clearly show how each add-on piece affects the overall model performance. The limitations and potential reasons for certain outcomes are also deeply analyzed and discussed.\n- The data augmentation opens up a new approach to enriching labeled data in this area. Instead of using LLMs to augment new instances, which can be inefficient in both computing source and cost, the authors propose to use random/similar tokens to replace shortcuts. Such simple approaches, especially the random one, surprisingly yield promising results."
                },
                "weaknesses": {
                    "value": "- The task of finding shortcuts remains ambiguous. It's unclear whether shortcuts always exist in the text. If they aren\u2019t, what would the model predict? The usage of this system seems limited.\n- There's a need for a more robust analysis of prior methodologies, particularly the unsupervised ones. The author asserts that unsupervised methods frequently identify shortcuts as inefficient rationales and provides examples. Yet, the reader would be curious about how often that happens, and if the model already yields good results, why do we have to give up shortcuts? I suggest a stronger argument for why finding a good rationale is significant, such as it can be helpful for other reasoning tasks.\n- The manuscript's writing style can be perplexing in several sections, notably in Methodology (Section 3). Mathematical expressions should be consistent, straightforward, and clear, and should only be included when indispensable. For example, instead of writing an algorithm for the semantic data augmentation, the reader might be more interested in seeing how specifically you\ndo the semanticly similar word retrieval in Appendix A.\n- It is hard to understand why sharing selector parameters in both supervised/unsupervised phases is not the default setting. Since the claim is that this is a specific setting in the proposed approach, it would be important to learn why the previous methods are not doing so."
                },
                "questions": {
                    "value": "* Elaborating on data augmentation might be beneficial. For instance, details about the number of augmented instances introduced and the ideal quantity would be insightful.\n* The term datastore can be confusing when discussing random data augmentation since this word is also used when describing the semantic key-value pair in semantic data augmentation."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9216/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813144471,
            "cdate": 1698813144471,
            "tmdate": 1699637159387,
            "mdate": 1699637159387,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ry05Uh6O6k",
                "forum": "uGtfk2OphU",
                "replyto": "rtG4PUrBnZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9216/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9216/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2gye (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your insightful suggestions! According to your comments, below we clarify the misunderstandings, and conduct more experiments.\n\n >**Comment 1:**  It's unclear whether shortcuts always exist in the text. If they aren\u2019t, what would the model predict?\n\nWe argue that shortcuts should always exist in texts such as  entity bias [1,2]  and statistical bias [3]. Previous studies [4,5,6,7] that study shortcuts in texts also support our viewpoint. Moreover, from the causal graph we constructed in Appendix D, we observe that since there always exists a backdoor path S\u2194Z\u2192Y which makes shortcut Z and the label Y spuriously correlated, we conclude shortcuts always exist in the text. Finally, we assume that some datasets have been processed without significant shortcuts, enabling the model to learn the true causal relationships within the data and function as a debiased model. However, this assumption is overly idealistic when applied to real-world datasets.\n\n> **Comment2:**  The author asserts that unsupervised methods frequently identify shortcuts as inefficient rationales and provides examples. Yet, the reader would be curious about how often that happens.\n\nAs in the answer to comment 1, shortcuts commonly occur in text. Meanwhile, [5] has shown that the vanilla rationalization criterion in unsupervised methods is prone to highlighting spurious correlations (shortcuts) between the input features and the output as valid explanations. Therefore, we argue that unsupervised methods will frequently identify shortcuts as inefficient rationales.\n\n> **Comment3:**  If the model already yields good results, why do we have to give up shortcuts? I suggest a stronger argument for why finding a good rationale is significant, such as it can be helpful for other reasoning tasks.\n\nThis is a valuable question! If the shortcut helps us get better results, do we still need to remove the shortcut? Our answer is yes. Specifically, when faced with test data that is distributed with the same distribution as the training data, the shortcut facilitates us to obtain accurate results. However, since shortcuts do not reflect the real causal relationship between the data and labels, when the test data is distributed differently from the training data (i.e., the shortcut does not exist in the test data), a model that relies on shortcuts will have poor prediction results. For example, in the following table (Table 3 in the original manuscript), Vanilla Un-RAT achieves promising results when we test it on an identically distributed dataset IMDB, but it achieves poor predictive results on out-of-distribution data SST-2. Thus, we can conclude that when the model relies on the shortcut in the data for training and prediction, the model fails in the face of new data distributions, further limiting the application of the model.\n\n| Methods|IMDB(ID)|SST-2(OOD)|\n|-|-|-|\n|Vanilla Un-RAT|85.3\u00b10.2|45.3\u00b18.1|\n|SSR\\_unif|90.3\u00b10.2|79.4\u00b10.3|\n|SSR_virt|89.9\u00b10.2|79.9\u00b10.4|\n\nFurthermore, finding a good rationale is significant:\n\n1. Extracting a good rationale can help us avoid extracting shortcuts as rationales, which can help the model focus on the real causal relationship between the data and labels during training and prediction. It can increase the accuracy and robustness of the model when facing the test data with different distributions.\n2. Extracting a good rationale can improve the interpretability of the prediction results, which can be applied in some high-risk domains, such as law [4].\n3. Rationalization can help other reasoning tasks. For example, rationalization is used as a knowledge extractor in [8] to extract the most responsible features for the predictions. After that, [8] expands the extractive rationales using commonsense resources to generate natural language explanations and give the final prediction.\n\n**References**\n\n[1] Yongchun Zhu, Qiang Sheng, Juan Cao, Shuokai Li, Danding Wang, Fuzhen Zhuang. Generalizing to the Future: Mitigating Entity Bias in Fake News Detection. In SIGIR2022.\n\n[2] Fei Wang, Wenjie Mo, Yiwei Wang, Wenxuan Zhou, and Muhao Chen. A Causal View of Entity Bias in (Large) Language Models. In Arixv2023.\n\n[3] Xiaobao Wu,  Chunping  Li, Yishu Miao. Discovering Topics in Long-tailed Corpora with Causal Intervention. In ACL2021.\n\n[4] Linan Yue, Qi Liu, Li Wang, Yanqing An, Yichao Du, Zhenya Huang. Interventional Rationalization. In EMNLP2023.\n\n[5] Shiyu Chang, Yang Zhang, Mo Yu and Tommi Jaakkola. Invariant Rationalization In ICML2020.\n\n[6] Wei Liu and Jun Wang, Haozhao Wang, Ruixuan Li, Zhiying Deng, YuanKai Zhang, and Yang Qiu. D-Separation for Causal Self-Explanation. In NeurIPS2023.\n\n[7] Du M, Manjunatha V, Jain R, et al. Towards Interpreting and Mitigating Shortcut Learning Behavior of NLU models. In NAACL2021.\n\n[8] Bodhisattwa Prasad Majumder, Oana-Maria Camburu, Thomas Lukasiewicz, Julian McAuley. Knowledge-Grounded Self-Rationalization via Extractive and Natural Language Explanations. In ICML2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9216/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699939956482,
                "cdate": 1699939956482,
                "tmdate": 1699939956482,
                "mdate": 1699939956482,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]