[
    {
        "title": "Dynamic Demonstrations Controller for In-Context Learning"
    },
    {
        "review": {
            "id": "IxPboH2DNp",
            "forum": "qH8ADnIVII",
            "replyto": "qH8ADnIVII",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6744/Reviewer_NpsS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6744/Reviewer_NpsS"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposed a dynamic demonstration controller to select the optimal number of demonstrations in the prompt. The proposed method can achieve similar performance with Oracle demonstration selection across different datasets and across different models. The proposed method can be integrated with existing prompt selection methods to achieve higher performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is clearly written and easy to follow.\n\n - The ablation study is comprehensive."
                },
                "weaknesses": {
                    "value": "- The evaluation and discussion can be further improved. \n\n    - It would be interesting to discuss what causes the observations in the pilot experiments. \n\n     - It is important to conduct experiments comparing demonstration number selection and demonstration selection. The original Table 2 shows that the proposed method can further improve based on the demonstration selection. However, it is still unclear which one is more effective among demonstration selection and dynamic demonstration number selection.\n\n\n - The limitation of the method is not fully discussed."
                },
                "questions": {
                    "value": "- In terms of the limitations, when will the method fail, and when will the method have a good performance?\n\n - In Table 2, can you also show the performance of the \u201cdefault\u201d method, which is randomly sampling k-shot demonstrations? And also show the performance of \u201cD2Contoller\u201d along? It will be helpful to understand which one is more effective among demonstration selection and demonstration number selection.\n\n - What may cause the observations in Pilot experiments? For instance, in Figure 2, what aspects of the datasets cause the different optimal k for different datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6744/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698609095965,
            "cdate": 1698609095965,
            "tmdate": 1699636776689,
            "mdate": 1699636776689,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OSw2v0G7Ia",
                "forum": "qH8ADnIVII",
                "replyto": "IxPboH2DNp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NpsS"
                    },
                    "comment": {
                        "value": "Thanks for your appreciation of our clearly written, easy-to-follow, and comprehensive ablation study. We answer your concerns as follows:\n\n> **Q1: It would be interesting to discuss what causes the observations in the pilot experiments. For instance, in Figure 2, what aspects of the datasets cause the different optimal k for different datasets?**\n\n**A1**: Thanks for your constructive feedback. We speculate that adding a demonstration to a prompt will have two effects: (1) Providing more information to the prompt, resulting in improvement in performance. (2) Causing the distribution of the prompt to become more different from the pre-training corpus of LLMs, leading to difficulty in understanding the prompt and reducing performance. When more demonstrations are added, the direction of the change in performance depends on which effect is more influential.  For different datasets and LLMs, when adding more demonstrations, the strengths of Effect (1) and Effect (2) are different, leading to the variation observed in pilot experiments and also causing the difference in the optimal k.\n\n\n\n> **Q2: It is still unclear which one is more effective among demonstration selection and dynamic demonstration number selection.**\n\n**A2**: Thanks for your precious suggestion. As we demonstrated in our paper, KATE (a demonstration selection method) obtains more competitive performance when adapted to these ten classification datasets than our demonstration number selection method. However, KATE uses a default number to select demonstrations and is not able to decide how many demonstrations to select is good. Our method is orthogonal to KATE while also being complementary. Thus, combining two methods can achieve better performance.\n\n> **Q3: In terms of the limitations, when will the method fail, and when will the method have good performance?**\n\n**A3**: Thanks for your valuable comment. Regarding the $D^2Controller$ method, some LLMs exhibit a minor decline in performance on the MPQA, SST-2, and MR datasets compared to the default setting. One possible reason is that these datasets have relatively shorter average demonstration lengths (shown in Table 6), leading to encoded semantic representations that contain less information. Thus, the similarities measured by IICScore based on these representations are inaccurate. In this case, selecting an appropriate demonstration number for these datasets may be more challenging. In contrast, most of the datasets with relatively longer average demonstration lengths perform well with $D^2Controller$."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700397030263,
                "cdate": 1700397030263,
                "tmdate": 1700482333664,
                "mdate": 1700482333664,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7DYio4sRDd",
            "forum": "qH8ADnIVII",
            "replyto": "qH8ADnIVII",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6744/Reviewer_tTZn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6744/Reviewer_tTZn"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to determine the optimal number of example demonstrations for in-context learning. The authors argue that the common belief that the number of demonstrations is positively correlated with model performance does not necessarily hold true. Therefore, it is critical to decide on the optimal number of example demonstrations. In this work, the authors propose a method to select representative in-context learning examples that minimize intra-class distance and maximize inter-class distance for each group of in-context examples from the training dataset. They then use these selected examples as a validation set to adjust the number of demonstrations dynamically. The authors perform experiments on a wide range of datasets and demonstrate the effectiveness of their proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The authors have done an excellent job of motivating the problem and providing a thorough description of their research. The paper is well-written in a high-standard and easy to understand.\n\n2. The authors have conducted extensive experiments to demonstrate that the length of in-context learning examples is not necessarily better. Furthermore, the experimental evaluation shows that their proposed method has promising performance.\n\n3. Validation set selection is critical to in-context learning. Compared to other works, the authors propose a method to carefully curate a representative validation set. It is meaningful and makes sense."
                },
                "weaknesses": {
                    "value": "The novelty of this paper is my main concern. The idea of minimizing intra-class distance and maximizing inter-class distance has been widely used in previous machine learning works [1][2]. Similarly, the paradigm of using a validation set to choose in-context learning examples/tune in-context learning hyperparameters has also been well-explored in previous works [3][4]. If the author can provide more content to illustrate their unique contribution, I will consider improving my score.\n\n[1] Nadagouda, N., Xu, A., & Davenport, M. A. (2023, July). Active metric learning and classification using similarity queries. In Uncertainty in Artificial Intelligence (pp. 1478-1488). PMLR.\n\n[2] Hoffer, E., & Ailon, N. (2015). Deep metric learning using triplet network. In Similarity-Based Pattern Recognition: Third International Workshop, SIMBAD 2015, Copenhagen, Denmark, October 12-14, 2015. Proceedings 3 (pp. 84-92). Springer International Publishing.\n\n[3] Chang, T. Y., & Jia, R. (2023, July). Data curation alone can stabilize in-context learning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 8123-8144).\n\n[4] Li, X., & Qiu, X. (2023). Finding supporting examples for in-context learning. arXiv preprint arXiv:2302.13539."
                },
                "questions": {
                    "value": "Could the authors provide more information on the cost of \u201cEvaluation Examples Selection\u201d and \u201cAccuracy-based Evaluation\u201d stages?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6744/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698631213981,
            "cdate": 1698631213981,
            "tmdate": 1699636776565,
            "mdate": 1699636776565,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vjbJD4hJfA",
                "forum": "qH8ADnIVII",
                "replyto": "7DYio4sRDd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer tTZn"
                    },
                    "comment": {
                        "value": "Thanks for your appreciation of our excellent job, high-standard writing, and meaningful method. We address your concerns as follows:\n\n> **Q1: About novelty and contirbutions.**\n\n**A1**: Thanks for your valuable comment. The core contribution of this paper comes from two aspects: \n\n* **Contribution 1**: We refute the prevailing belief that as the number of demonstrations increases, ICL performance continues to improve. Instead, the optimal numbers of demonstrations vary on different datasets and LLMs; \n\n* **Contribution 2**: Based on the above observation, we propose a method named $D^2Controller$ to dynamically select the number of demonstrations, which is highly scalable and can not only be applied to LLMs but is also compatible with previous ICL methods.\n\n  The core contribution of  $D^2Controller$ is a fresh perspective of selecting small-scale but comprehensive evaluation examples to provide an accurate evaluation of the demonstrations.\n\n  * **Novelty**: To the best of our knowledge, previous work [1] [2] mentioned above both randomly sample examples as a validation set. Different from them, we construct small but comprehensive evaluation examples.\n\n  * **Implementation**: To realize the idea, according to the characteristics of the classification task, we adopt the approach of  \"minimizing intra-class distance and maximizing inter-class distance\". Of course, the approach is replaceable, as long as it can achieve our idea.\n\n  * **Effectiveness**:  To verify the effectiveness of evaluation examples selected by our method, we compare our method with using randomly sampled validation examples (With 3 different sizes, 100, 200 and 300). The results are as follows: \n\n|                     | GPT-2 1.5B | Cerebras-GPT 2.7B | Cerebras-GPT 6.7B | OPT 13B |\n| ------------------- | ---------- | ----------------- | ----------------- | ------- |\n| **Default setting** | 60.0         | 63.0                | 71.7              | 74.5    |\n| **Validation-100**  | 64.9       | 68.3              | 72.6              | 75.8    |\n| **Validation-200**  | 65.4       | 68.5              | 71.8              | 76.1    |\n| **Validation-300**  | 64.9       | 68.3              | 72.6              | 76.4    |\n| $D^2Controller$     | **67.0**         | **69.3**              | **74.0**                | **76.6**    |\n\nBased on these results, we can observe that $D^2Controller$ uses fewer examples but achieves better results compared to random sample examples.\n\n> **Q2: Could the authors provide more information on the cost of** **\u201cEvaluation Examples Selection\u201d and \u201cAccuracy-based Evaluation\u201d stages?**\n\n**A2**: We appreciate your interest in understanding the cost of these stages. In the following, we provide running times for three different sizes of LLMs during the **Evaluation Examples Selection** and **Accuracy-based Evaluation** stages, respectively.\n\n|                               | SST2  | SST5   | MR    | CR    | MPQA  | SubJ  | AGNews | RTE   | CB    |\n| ----------------------------- | ----- | ------ | ----- | ----- | ----- | ----- | ------ | ----- | ----- |\n| **GPT-2 1.5B**                |       |        |       |       |       |       |        |       |       |\n| Evaluation Examples Selection | 1364s | 313s   | 158s  | 31s   | 189s  | 140s  | 1900s  | 36s   | 10s   |\n| Accuracy-based Evaluation     | 915s  | 1978s  | 753s  | 654s  | 1112s | 806s  | 1105s  | 904s  | 1987s |\n| **Cerebras-GPT 2.7B**         |       |        |       |       |       |       |        |       |       |\n| Evaluation Examples Selection | 1662s | 356s   | 183s  | 22s   | 197s  | 158s  | 2943s  | 47s   | 10s   |\n| Accuracy-based Evaluation     | 2360s | 5386s  | 1946s | 3654s | 2778s | 2096s | 3242s  | 2419s | 2694s |\n| **Cerebras-GPT 6.7B**         |       |        |       |       |       |       |        |       |       |\n| Evaluation Examples Selection | 1685s | 405s   | 189s  | 21s   | 188s  | 170s  | 2825s  | 45s   | 10s   |\n| Accuracy-based Evaluation     | 4832s | 10725s | 3942s | 7076s | 5558s | 4223s | 6432s  | 4773s | 5376s |\n\n**References:**\n\n[1] Chang, T. Y., & Jia, R. (2023, July). Data curation alone can stabilize in-context learning. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 8123-8144).\n\n[2] Li, X., & Qiu, X. (2023). Finding supporting examples for in-context learning. arXiv preprint arXiv:2302.13539."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396971103,
                "cdate": 1700396971103,
                "tmdate": 1700476232758,
                "mdate": 1700476232758,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NBsxgtTftK",
                "forum": "qH8ADnIVII",
                "replyto": "jxouqmE4It",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Reviewer_tTZn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Reviewer_tTZn"
                ],
                "content": {
                    "title": {
                        "value": "To authors"
                    },
                    "comment": {
                        "value": "Thank you for your response. While some of my concerns have been addressed, I still maintain that the contribution of this paper is fair. Your statement, \u2018we adopt the approach of minimizing intra-class distance and maximizing inter-class distance. Of course, the approach is **replaceable**, as long as it can achieve our idea,\u2019 does not make sense to me. If you believe that the core contribution of this paper is simply to conclude that \u2018the optimal numbers of demonstrations vary on different datasets and LLMs,\u2019 then your title should not be \u2018Dynamic Demonstrations Controller.\u2019 However, if the proposed method is also a main contribution of your paper that you wish to claim, then it should be highlighted as such. As I mentioned earlier, minimizing intra-class distance and maximizing inter-class distance is an idea widely used in machine learning and cannot be regarded as your core contribution. Therefore, I will keep my score."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697412503,
                "cdate": 1700697412503,
                "tmdate": 1700697412503,
                "mdate": 1700697412503,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "A0cIVzEHTH",
                "forum": "qH8ADnIVII",
                "replyto": "7DYio4sRDd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "Thanks for your feedback. Regarding the $D^2Controller$, the core contribution is we propose a fresh perspective of selecting small but comprehensive evaluation examples to provide an accurate evaluation of the demonstrations.  To achieve comprehensiveness, we co-opt the idea of the fit ability and the generalization ability in ML and adapt it to the ICL for the first time, to the best of our knowledge. As an initial attempt to implement the idea, we propose IICScore to guide us to select examples. The reason we say IICScore is \"replacable\" is because there may be other approaches can also achieve this goal, which leaves room for others to explore. Thanks for your response again."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707574162,
                "cdate": 1700707574162,
                "tmdate": 1700707690131,
                "mdate": 1700707690131,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bkM3vzezXS",
            "forum": "qH8ADnIVII",
            "replyto": "qH8ADnIVII",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors study in-context learning and how different numbers of in-context examples affect an LLM's performance on a classification task. Specifically, the authors design and conduct some pilot experiments and report that a large number of in-context examples does not always guarantee the best model performance. Motivated by this, the authors propose the $D^2$ Controller, a method that dynamically determines an optimal number $k$ for $k$-shot ICL given a dataset. \n\nIn the $D^2$ Controller algorithm, for a given $k$ value, \n- first, $N_s$ groups of in-context examples are sampled; \n- second, for each group, a set of evaluation data points is selected, according to the proposed IICScore, which measures the similarity between a evaluation data point and the in-context examples in the group;\n- third, the accuracy of an LLM on the selected evaluation data, using the corresponding in-context examples, is obtained; \n- averaging all the above accuracy scores over the $N_s$ groups resulting an overall score for $k$;\n- finally, the optimal $k$ is selected according to the setting produces the highest averaged accuracy.\n\nIn experiments, the authors include a wide range of LLMs, including open-sourced LLMs and ones that can only be accessed via online APIs. The author also include 10 classification datasets. Results suggest that their method can indeed determine a better $k$ value than default settings used in prior works."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Useful topic: As the authors describe, there are few work studying how the number of demonstrations impacts an LLM's performance in the ICL setting. I agree this is an important topic because empirically the study could benefit millions of LLM practitioners. \n\n2. Neat idea: I think the method is well designed, I especially like the IICScore part, where it takes both inter- and intra-class similarity into consideration. \n\n3. Experiments and results: The authors study their methods on a wide range of LLMs and ten datasets. The authors run five seeds and report average / standard deviation. Results show that the proposed method outperforms baselines. The authors also provide a list of ablation study to help understand their method."
                },
                "weaknesses": {
                    "value": "Please see my questions and concerns below."
                },
                "questions": {
                    "value": "### Questions and concerns\nQ1. How does $D^2$ Controller compare to a simple baseline where $k$ is optimized as a hyperparameter using a validation set?\n\nQ2. How does $D^2$ Controller work with `classification` tasks where options have no consistent meanings? For instance, below is a datapoint taken from the BigBenchHard dataset:\n  ```\n  Jane quited her job on Mar 20, 2020. 176 days have passed since then. What is the date today in MM/DD/YYYY?\n  (A) 09/12/2020\n  (B) 11/12/2020\n  (C) 12/12/2020\n  (D) 09/12/1961\n  (E) 09/17/2020\n  ```\nIn this case, computing IICScore per class makes less sense. Could the author provide more insights on this?\n\nQ3. How does $D^2$ Controller work when $k < |c|$?\n\nQ4. $D^2$ Controller measures data similarity in representation space. Did the authors compare different text encoders and see whether / how they affect $D^2$ Controller?\n\nQ5. In my opinion, adding GPT-3 in Section 5.4 could make the analysis stronger. \n\nQ6. The authors report a setting where they combine KATE and $D^2$ Controller, this is interesting. Now, KATE is selecting $k$ different IC examples per test data point, where $k$ is determined by $D^2$ Controller at a dataset level. While I understand the setting, could the authors provide some insights on, is it necessary, or is there a way to dynamically determine the $k$ for every test data point? \n\nQ7. Could the authors provide some insights on why sometimes LLMs fail to benefit from more IC examples? Do stronger LLMs (e.g., gpt-4) suffer less from this?\n\n### Typos and minor stuff\n1. There is an extra quotation mark in the 3rd line of Section 5.1, Datasets.\n2. DBPedia does not seem to be a good dataset to include in this work, because the longer text, there can be at most one example per class and thus it is not helpful to demonstrate the $D^2$ Controller. \n3. In Section 5.4.4, the authors mention that they get better performance with fewer demonstrations. Maybe a more straightforward way to present this is to report (on average) how many tokens their method queries an LLM, and how does that compare to prior work (default $k$).\n\n\n### Nov 21\n\nI have read the authors response including those answering other reviewers' questions. I appreciate the authors' effort on clarifying things so I'm happy to raise my score a bit. **However, please note, I give 6 -> 8 only because there is no option of 7. I don't think the current version is as mature as 8.** (E.g., the authors have included quite a bit of new experiments during the rebutal period, mainly in the appendices. It may require some efforts to merge some into the main content, with some non-trivial rewriting.)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6744/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6744/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6744/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698641144319,
            "cdate": 1698641144319,
            "tmdate": 1700572931615,
            "mdate": 1700572931615,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JNxq5CpkJS",
                "forum": "qH8ADnIVII",
                "replyto": "bkM3vzezXS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer t5tL (part 1)"
                    },
                    "comment": {
                        "value": "Thanks for your appreciation of our useful topic, neat idea, and well-designed method. About the mentioned questions, our answers are as follows:\n\n> **Q1. How does $D^2Controller$ compare to a simple baseline where k is optimized as a hyperparameter using a validation set?** \n\n**A1**: Thanks for your valuable comment. Following your suggestion, we randomly sample some examples (i.e., 100, 200, 300) to construct validation sets as a baseline for choosing k. The results are as follows (note that the results we report are the average performance of ten datasets):\n\n|                     | GPT-2 1.5B | Cerebras-GPT 2.7B | Cerebras-GPT 6.7B | OPT 13B |\n| ------------------- | ---------- | ----------------- | ----------------- | ------- |\n| **Default setting** | 60.0         | 63.0                | 71.7              | 74.5    |\n| **Validation-100**  | 64.9       | 68.3              | 72.6              | 75.8    |\n| **Validation-200**  | 65.4       | 68.5              | 71.8              | 76.1    |\n| **Validation-300**  | 64.9       | 68.3              | 72.6              | 76.4    |\n| $D^2Controller$     | **67.0**         | **69.3**              | **74.0**                | **76.6**    |\n\nBased on these results, we can observe that using these examples does not lead to the optimal choice of k, and almost all of the results are inferior to $D^2Controller$. This further underscores the effectiveness of using IICScore to select a small number of representative examples.\n\n> **Q2: How does $D^2Controller$ work with `classification` tasks where options have no consistent meanings? e.g., BigBenchHard dataset. Could the author provide more insights on this?**\n>\n> ```\n> Jane quited her job on Mar 20, 2020. 176 days have passed since then. What is the date today in MM/DD/YYYY?\n> (A) 09/12/2020\n> (B) 11/12/2020\n> (C) 12/12/2020\n> (D) 09/12/1961\n> (E) 09/17/2020\n> ```\n\n**A2**: Thanks for your inspiring comment.  The BigBenchHard dataset mentioned above is essentially not a classification task but rather a QA (Question-Answering) task. A possible way to work with it is to convert the QA form into classification form. Specifically, we pair the question sentence with each answer and label the pair with correct answer as \"yes\" and others as \"no\". Thus, the task is transformed to a 2-class classification task and we can apply our $D^2Controller$ to the dataset.\n\n> **Q3: How does $D^2Controller$ work when k<|c|?**\n\n**A3**: We are sorry that we did not understand exactly the meaning of the above comment. We try answering it:\n\nAccording to our understanding, |c| denotes the number of examples for a class c. When k < |c|, we can certainly sample k-shot examples from each class. When k > |c|, we can sample all examples from each class. In this paper, all ten of our datasets meet the condition where k < |c|.\n\n> **Q4. $D^2Controller$ measures data similarity in representation space. Did the authors compare different text encoders and see whether / how they affect $D^2Controller$?**\n\n**A4**: Thanks for your valuable feedback. In this paper, we use LLM as a text encoder in $D^2Controller$ to measure data similarity. Following your suggestion, we also tried another two text encoders (i.e., BERT-large and RoBERTa-large). The results are as follows:\n\n|                                    | GPT-2 1.5B | Cerebras-GPT 2.7B | Cerebras-GPT 6.7B | OPT 13B |\n| ---------------------------------- | ---------- | ----------------- | ----------------- | ------- |\n| **$D^2Controller$(BERT-large)**    | 65.8       | 66.5              | 71.8              | 76.6    |\n| **$D^2Controller$(RoBERTa-large)** | 66.0         | 64.6              | 72.8              | **77.4**    |\n| **$D^2Controller$**                | **67.0**         | **69.3**              | **74.0**                | 76.6    |\n\nWe can observe that $D^2Controller$(BERT-large) and $D^2Controller$(RoBERTa-large) perform worse than $D^2Controller$ on most of the LLMs (except for OPT 13B), which verifies the superiority of using GPT-architecture LLMs as the text encoder to measure data similarity in representation space."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396344235,
                "cdate": 1700396344235,
                "tmdate": 1700476137854,
                "mdate": 1700476137854,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "c0x9tY35Yw",
                "forum": "qH8ADnIVII",
                "replyto": "bkM3vzezXS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer t5tL (part 3)"
                    },
                    "comment": {
                        "value": "> **Q7. Could the authors provide some insights on why sometimes LLMs fail to benefit from more IC examples? Do stronger LLMs (e.g., gpt-4) suffer less from this?**\n\n**A7**: Thanks for your constructive feedback. We speculate that adding an in-context example to a prompt will have two effects: (1) Providing more information to the prompt, resulting in improvement in performance. (2) Causing the distribution of the prompt to become more different from the pre-training corpus of LLMs, leading to difficulty in understanding the prompt and reducing performance. When more IC examples are added, the direction of the change in performance depends on which effect is more influential. For some datasets on some LLMs, the Effect (2) is stronger, leading to performance degradation when more IC examples are included.\n\nBesides, similar to Section 3, we have conducted pilot experiments with the GPT-4 model on five text classification datasets. Due to budgetary constraints, for each dataset, we use five different seeds to test the model's performance in the 1-shot setting, the default setting (4-shot), and $k_{max}$-shot setting. Note that the maximum input length of the GPT-4 model we use is 8192 tokens, so the maximum shot number for SST-5, CR, MPQA, RTE, and CB is 32, 128, 256, 32, and 16. The results are as follows:\n\n| GPT-4                       | SST-5    | CR       | MPQA     | RTE      | CB       |\n| --------------------------- | -------- | -------- | -------- | -------- | -------- |\n| **1-shot setting**          | 45.3\u00b14.4 | 83.7\u00b11.3 | 67.4\u00b11.0 | 82.7\u00b13.0 | 89.3\u00b11.8 |\n| **Default setting(4-shot)** | 45.7\u00b15.0 | 92.2\u00b12.2 | 83.8\u00b10.3 | 89.1\u00b11.4 | 83.9\u00b12.5 |\n| **$k_{\\max}$-shot setting** | 43.6\u00b10.8 | 95.9\u00b10.3 | 90.2\u00b11.1 | 88.7\u00b10.6 | 82.7\u00b11.0 |\n\nFrom the perspective of a general trend, when the input increases from a 1-shot setting to $k_{max}$- shot setting, the accuracy improves on the CR, MPQA, and RTE datasets while declines on the SST-5 and CB datasets. Moreover, in the above table, the RTE dataset achieves the best performance in the default setting, rather than $k_{max}$- shot setting. Thus, increasing the number of demonstrations in stronger LLM like GPT-4 does not necessarily improve performance.\n\n> **Q8: In Section 5.4.4, the authors mention that they get better performance with fewer demonstrations. Maybe a more straightforward way to present this is to report (on average) how many tokens their method queries an LLM, and how does that compare to prior work (default k).**\n\n**A8**: Thanks for your valuable suggestion. We reported the average number of tokens used by three methods (default k, maximum k, and ours) to query LLM:\n\n|                 | GPT-2 1.5B | Cerebras-GPT 2.7B | Cerebras-GPT 6.7B | OPT 13B |\n| --------------- | ---------- | ----------------- | ----------------- | ------- |\n| **Default k**   | 455.49     | 516.87            | 516.87            | 516.87  |\n| **Maximum k**   | 678.29     | 1345.72           | 1345.72           | 1345.72 |\n| $D^2Controller$ | 603.98     | 885.51            | 1187.37           | 725.89  |\n\nBased on these results, we can observe that our method uses fewer tokens to achieve better performance compared to maximum k. Especially on some LLMs, such as Cerebras-GPT 2.7B and OPT-13B, $D^2Controller$ saves almost 30% and 50% tokens.  Meanwhile, although our method uses more tokens compared to the default k, it achieves an average relative improvement of 5.4% on ten datasets.\n\n> **Q9: About typos.**\n\n**A9**: Thanks for your careful review. We have fixed these typos in the revision."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396752115,
                "cdate": 1700396752115,
                "tmdate": 1700480861881,
                "mdate": 1700480861881,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Hx995OyZE8",
                "forum": "qH8ADnIVII",
                "replyto": "JNxq5CpkJS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
                ],
                "content": {
                    "title": {
                        "value": "Clarify"
                    },
                    "comment": {
                        "value": "**Q3-followup**: \n\nSorry for the confusion, I should have put $|\\mathcal{C}|$ (as defined in Section 2), which to my understanding means the numebr of classes in a specific task, e.g., a 5-way classification task would have $|\\mathcal{C}| = 5$.\n\nThe question was that, for instance, given a 5-way classification task, how does 3-shot IC learning work with the proposed method. \n\nHope this clarifies."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497104851,
                "cdate": 1700497104851,
                "tmdate": 1700497104851,
                "mdate": 1700497104851,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "J9TNq7H3rt",
                "forum": "qH8ADnIVII",
                "replyto": "uf0jqFb98v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
                ],
                "content": {
                    "comment": {
                        "value": "Ah I see, yes you are right. $n$ is the overall number of IC examples. In this work, do you always assume that $n \\ge |\\mathcal{C}|$? Thanks."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700501077520,
                "cdate": 1700501077520,
                "tmdate": 1700501077520,
                "mdate": 1700501077520,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6Q21oCbMyG",
                "forum": "qH8ADnIVII",
                "replyto": "bkM3vzezXS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Reviewer_t5tL"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "I have read the authors response including those answering other reviewers' questions. I appreciate the authors' effort on clarifying things so I'm happy to raise my score a bit. **However, please note, I give 6 -> 8 only because there is no option of 7. I don't think the current version is as mature as 8.** (E.g., the authors have included quite a bit of new experiments during the rebutal period, mainly in the appendices. It may require some efforts to merge some into the main content, with some non-trivial rewriting.)"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700573085575,
                "cdate": 1700573085575,
                "tmdate": 1700573107293,
                "mdate": 1700573107293,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MQwRErhOZh",
                "forum": "qH8ADnIVII",
                "replyto": "bkM3vzezXS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for raising the score"
                    },
                    "comment": {
                        "value": "We are very happy to hear that the reviewer has raised the score! We thank you again for the invaluable feedback and insights. We really appreciate it!"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700574411864,
                "cdate": 1700574411864,
                "tmdate": 1700574523819,
                "mdate": 1700574523819,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9zQ8j27dqE",
            "forum": "qH8ADnIVII",
            "replyto": "qH8ADnIVII",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6744/Reviewer_mRAG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6744/Reviewer_mRAG"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an algorithm to select the right number k of examples per class to compose an in-context learning prompt. The proposed Dynamic Demonstration Controller (D2Controller) algorithm chooses k based on a series of experiments with N different in-context learning example selections. In each experiment a validation set is chosen in a special way from the remaining training data that did not make it into the prompt. The k is chosen to maximize the average validation set performance over the N in-context learning support sets. \n\nThe paper\u2019s novelty is in the selection of the validation set for each of the N in-context learning support sets. For each of the C classes, the paper chooses an example out of the remaining training data by maximizing a score called IICScore. I did not fully understand the intuition behind the score, but it involves balancing the example\u2019s similarities to the class of interest and to the other classes. \n\nThe paper key points are that:\n- D2Controller selects k better than the typical settings from the prior work\n- D2Controller selects k better than taking as many examples as possible\n- D2Controller selects the validation sets better than taking *the same number of validation examples* at random\n- D2Controller is also helpful when it is combined with other demonstration selection or ordering methods"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is most clearly written and methodologically sound. The research question makes sense, the set of baselines is large and appropriate. But there may be one crucial baseline that's missing (see Weaknesses Section)."
                },
                "weaknesses": {
                    "value": "This is basically a hyperparameter selection paper, and as such it is missing a key baseline: what if one uses as many examples as possible for selecting k? That would correspond to the classic setting of having your dataset split into training, validation and test sets. While it would be more computationally expensive at the hyperparameter selection time, the key concern in practical applications of LLMs is the inference speed at test time, which would not be affected by using more validation examples to select k.\n\nI imagine that one justification for using fewer validation examples could be that there might be not that many examples available overall. The paper does not discuss this possible constraint though. The set of examples available for selection with IICScore would have to also be restricted. \n\nSome aspects of the paper were difficult to understand, see the next section of the review. I found Figure 5 very dense and difficult to understand. I did not find the motivation for IICScore clearly explained and compelling."
                },
                "questions": {
                    "value": "- \u201cTo measure similarities, we transform each sentence x to a vector representation x, which essentially is a language modeling distribution, by querying LLMs with x and obtaining the output\u201d - what does this mean exactly?\n- Is your Oracle baseline using the test set examples? If it is, your explanation as to why it is not practical on Page 7 is a bit confusing. Because Oracle would not be a possible practical method, it\u2019s just a hypothetical baseline from above. \n- What set of in-context examples is used at the test time? Is it one the N sets you used to select k, or is it another one?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6744/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698867789706,
            "cdate": 1698867789706,
            "tmdate": 1699636776358,
            "mdate": 1699636776358,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "P0e8Rwb2yR",
                "forum": "qH8ADnIVII",
                "replyto": "9zQ8j27dqE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6744/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer mRAG (part 1)"
                    },
                    "comment": {
                        "value": "Thanks for your appreciation of our sound methodology, make-sense questions, and appropriate baselines. We answer your concerns as follows:\n\n> **Q1: What if one uses as many examples as possible for selecting k?** \n\n**A1**: Thanks for your valuable comment. Following your suggestion, we randomly sample more examples as a baseline to select k. Specifically, we construct three different sizes of validation sets (100, 200, and 300) to select k. The results are as follows (note that the results we report are the average performance of ten datasets):\n\n|                     | GPT-2 1.5B | Cerebras-GPT 2.7B | Cerebras-GPT 6.7B | OPT 13B |\n| ------------------- | :--------: | :---------------: | :---------------: | :-----: |\n| **Default setting** |     60.0     |        63.0         |       71.7        |  74.5   |\n| **Validation-100**  |    64.9    |       68.3        |       72.6        |  75.8   |\n| **Validation-200**  |    65.4    |       68.5        |       71.8        |  76.1   |\n| **Validation-300**  |    64.9    |       68.3        |       72.6        |  76.4   |\n| **$D^2Controller$** |     **67.0**     |       **69.3**        |        **74.0**         |  **76.6**   |\n\nBased on these results, we can observe that using more examples does not lead to the optimal choice of k, and almost all of the results are inferior to $D^2Controller$. This further underscores the effectiveness of using IICScore to select a small number of representative examples.\n\n> **Q2: Why use fewer validation examples to select k? Is it because the number of available validation examples is limited?**\n\n**A2**: We are sorry that there may be a misunderstanding, because our method is not proposed for the situation where the number of available examples is limited. \n\nWe use fewer validation examples to select k mainly due to the following three reasons:\n\n* **Effective**: As described in A1, using a small number of examples selected by $D^2Controller$ is more effective than using a validation set composed of a larger number of randomly sampled examples.\n* **Efficient**: Our method is much more efficient than using a validation set. In the following Table, we report the running time of selecting k using $D^2Controller$ and using a validation set of 300 examples, respectively. Although the cost of hyperparameter selection would not affect the inference speed at test time, it is still worthwhile accelerating the selection process.\n* **Cheap**: For LLMs that require monetary paid-for API (e.g., GPT-3), it is very expensive to use a large-scale validation set to select hyperparameters, especially for academia. Thus, a method that is effective while requiring less money is necessary.\n\nAs for the situation you mentioned in the review, although we do not design our method out of consideration that the available validation examples are limited, we believe our method would be competitive under the situation.\n\n|                       | SST2   | SST5   | MR     | CR     | MPQA   | SubJ   | AGNews | RTE    | CB    |\n| --------------------- | :----- | :----- | :----- | :----- | :----- | :----- | :----- | :----- | :---- |\n| **GPT-2 1.5B**        |        |        |        |        |        |        |        |        |       |\n| $D^2Controller$       | 915s   | 1978s  | 753s   | 654s   | 1112s  | 806s   | 1105s  | 904s   | 1987s |\n| Validation-300    | 5470s  | 4820s  | 4417s  | 3953s  | 6596s  | 4794s  | 3386s  | 5381s  | 2178s |\n| **Cerebras-GPT 2.7B** |        |        |        |        |        |        |        |        |       |\n| $D^2Controller$       | 2360s  | 5386s  | 1946s  | 3654s  | 2778s  | 2096s  | 3242s  | 2419s  | 2694s |\n| Validation-300    | 14700s | 13229s | 11822s | 22346s | 17099s | 12483s | 9771s  | 14572s | 3184s |\n| **Cerebras-GPT 6.7B** |        |        |        |        |        |        |        |        |       |\n| $D^2Controller$       | 4832s  | 10725s | 3942s  | 7076s  | 5558s  | 4223s  | 6432s  | 4773s  | 5376s |\n| Validation-300   | 27653s | 24727s | 23188s | 40582s | 32828s | 25163s | 19100s | 28074s | 6089s |\n\n> **Q3: \"*To measure similarities, we transform each sentence x to a vector representation x, which essentially is a language modeling distribution, by querying LLMs with x and obtaining the output*\" - what does this mean exactly?**\n\n**A3**: Thanks for your valuable feedback. The intended meaning of this statement is that we input each sentence x into LLMs, thereby obtaining sentence vector representations. We have revised it to make it clear."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6744/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396001871,
                "cdate": 1700396001871,
                "tmdate": 1700475971342,
                "mdate": 1700475971342,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]