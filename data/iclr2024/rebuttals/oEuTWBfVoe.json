[
    {
        "title": "Model Based Inference of Synaptic Plasticity Rules"
    },
    {
        "review": {
            "id": "pmixsYv4cv",
            "forum": "oEuTWBfVoe",
            "replyto": "oEuTWBfVoe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3073/Reviewer_s75f"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3073/Reviewer_s75f"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a gradient-based learning framework to infer biologically-plausible synaptic plasticity rules from experimental data. The method models the learning rule using polynomials of presynaptic, postsynaptic activities, current synaptic weight, and reward signal or with a multilayer perceptron. The proposed approach successfully recovers Oja's rule and plasticity in the fruit fly."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper has the following strenghts:\n\n* It addresses a crucial question related to inferring synaptic plasticity from biological data, contributing to the field.\n\n* The experiments conducted are intriguing and validates the proposed method.\n\n* Limitations of the proposed algorithm are discussed at the end of the paper in detail.\n\n* The availability of a documented and clear code enhances the reproducibility of this work."
                },
                "weaknesses": {
                    "value": "I think the paper has several weaknesses. Please see the following list and the questions sections.\n\n* The statement in the introduction regarding the biological plausibility of backpropagation may be too weak (\"While the backpropagation ..., its biological plausibility remains a subject of debate.\"). It is widely accepted that backpropagation is biologically implausible.\n\n* Regarding the following sentence in Section 3 \"We further define a readout ... ,i.e., $\\mathbf{m}^t = f(y^t).$\", did you mean to write $\\mathbf{m}^t = f(\\mathbf{y}^t)$ ($\\mathbf{y}^t$ with boldsymbol)?\n\n* On page 4, \"setting $\\theta_{110} = 1$ and $\\theta_{012} = -1$,\" the second term should be $\\theta_{021}$ rather than $\\theta_{012}$.\n\n* The initialization of polynomial coefficient parameters is not clear, and it seems they are initialized close to zero according to  Figure 2. It would be valuable to explain how they were initialized.\n\n* The paper models synaptic plasticity rules only for feedforward connections. It would be interesting to explore the impact of lateral connections (by adding additional terms in Equation 6). Have you experimented with such a setup?\n\n* In page 7, the authors state that \"In the case of the MLP, we tested various architectures and highlight results for a 3-10-1 neuron topology.\" What are the results for other various architectures? Putting them into the paper would also be valuable (as ablation studies). \n\n* The hyperparameters for the experiments are missing? What is the learning rate, what is the optimizer, etc.?\n\n* I do not see that much difference between the experiment presented in Section 4 and the experiment in (Confavreux et al., 2020) (Section 3.1) except the choice of optimization method. In your experimental setup, you also do not model the global reward. Therefore, I think it makes it more similar to the experiment in (Confavreux et al., 2020). \n\n* Comparison to previous work is missing."
                },
                "questions": {
                    "value": "* As a follow-up question related to my comment about the similarity with (Confavreux et al., 2020): (Confavreux et al., 2020) uses Covariance Matrix Adaptation Evolution Strategy (CMA-ES) as they state it has better scalibility with the network size compared to gradient based strategy. Why do you use gradient based strategy? What is the advantage?\n\n* In the experimental setup in Section 5, if you do not neglect the hypothetical dependencies on $y_i$, would your framework correctly infer the learning rule, i.e., if you use $$g_\\theta = \\sum_{\\alpha, \\beta, \\phi, \\gamma} \\theta_{\\alpha, \\beta, \\phi, \\gamma} x_j^\\alpha r^\\beta y_i^\\phi w_{ij}^\\gamma$$ would your model learn $\\theta_{\\alpha, \\beta, \\phi, \\gamma} = 0 \\quad \\forall \\phi \\neq 0$?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethical concerns were identified in this paper."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Reviewer_s75f",
                        "ICLR.cc/2024/Conference/Submission3073/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3073/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698515195345,
            "cdate": 1698515195345,
            "tmdate": 1700685491266,
            "mdate": 1700685491266,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Di3gJVt1Ru",
                "forum": "oEuTWBfVoe",
                "replyto": "pmixsYv4cv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer s75f (Part 1)"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe thank the Reviewer for their positive assessments of our work and suggestions for improvement. As detailed below, we will make many changes to address your suggestions. \n\n## Replies to points brought up in *Weaknesses* section:\n\n**B1.** We agree. We will modify this sentence to be stronger.\n\n**B2.** Yes. Thank you for catching this typo. We will correct it. \n\n**B3.** Yes. Thank you for catching this typo. We will correct it.\n\n**B4.** The coefficients were randomly initialized i.i.d. from a normal distribution of zero mean and variance 1e-4. We will add this methodological detail to the paper.\n\n**B5.** We agree with the Reviewer that it would be interesting to extend our method to recurrent neural networks. However, we could perform this numerical experiment in our setup without changing Eq. 6. In particular, x would become the presynaptic neuron\u2019s activity, y would become the postsynaptic neuron\u2019s activity, and w would be the weight between these neurons. The bigger difference is that Eq. 1 would need to be updated to incorporate recurrent network dynamics. We have not experimented with recurrence in our model, and this change would entail significant changes to our code bank. We have therefore decided to postpone these experiments for future work.   \n\nB6. We accepted the Reviewer\u2019s suggestion and summarize additional experiments that varied the architecture of the MLP below. We found that the performance of the MLP architecture could be significantly improved by moderately increasing the size of the hidden layer. As suggested, we will include these simulations in our revised manuscript.\n\n### Simulation information and results\nPlasticity MLP architecture: 3 \u2192 h_l \u2192 1\n\nNetwork: 100 \u2192 1000 \u2192 1\n\nGround truth plasticity rule: x.(R - E[R])\n\nTrained on simulated behavioral data\n\n| Number of hidden units (h_l) | R2 weights | R2 activity | % Deviance Explained |\n|------------------------------|------------|-------------|----------------------|\n| 10                           | 0.68       | 0.95        | 62.99                |\n| 50                           | 0.76       | 0.97        | 66.34                |\n| 100                          | 0.62       | 0.93        | 61.32                |\n\n**B7.** We will revise the manuscript to state these details. For the experiments, hyperparameters were fine tuned by grid search, with performance averaged across three random seeds. Hyperparameters included an L1 sparsity regularizer applied to the plasticity coefficients, with the optimal value found to be 5e-3, and a moving average window for calculating the expected reward, which showed minimal impact and was set at a value of 10. In terms of optimizers, our experiments included AdaBelief, Adam, and AdamW, using their default parameters for each. The results were comparable across these optimizers, and the findings presented in the paper are based on the use of Adam.\n\n**B8.** We agree with the reviewer, but we think that the choice of optimization method is highly significant. As explained in the Introduction and Related Work sections, our focus is on fitting a broad range of arbitrary rules, without being constrained by the specific computation they implement or their optimality. This approach reflects the flexible and expansive nature of our model. The method provided here provides an exciting opportunity to infer biological learning rules from real experimental data sets from biology, where the function of the circuit is a priori unknown. For instance, no one knows if the mushroom body is optimal for some specific task, but we were nevertheless able to estimate its learning rule from behavioral data in Figure 4.\n\n**B9.** Can the Reviewer please clarify what comparison they would like to see? We already conceptually compared our work to previous papers in the Related Work section. However, since we\u2019re optimizing different objective functions than almost all of these previous works, apples-to-apples comparisons are usually impossible. In the setting of Figure 4, we could revise the text to compare our model\u2019s performance to the previous model in Rajagopalan et al. Would this help, or does the Reviewer have something else in mind?"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201957983,
                "cdate": 1700201957983,
                "tmdate": 1700202144856,
                "mdate": 1700202144856,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qTf1qPer2s",
                "forum": "oEuTWBfVoe",
                "replyto": "pmixsYv4cv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## Replies to points brought up in *Questions* section:\n\n**B1.** Our method is simpler to implement and appears to work perfectly well for our purposes. We therefore did not explore the CMA-ES approach. We note that Tyulmankov et al. 2022 also successfully used gradient descent to meta-learn plasticity rules, and our implementation more closely follows that paper.\n\n**B2.** This is a good suggestion. We did not explore this learning rule because it involves significantly more coefficients that must be fit, and hypothetical dependencies of the mushroom body\u2019s learning rule on y can be excluded on biological grounds. We will mention this in our revision. We will also try fitting this more complex learning rule in our revision to see whether the coefficients can still be recovered."
                    },
                    "title": {
                        "value": "Reply to Reviewer s75f (Part 2)"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700202027007,
                "cdate": 1700202027007,
                "tmdate": 1700202057906,
                "mdate": 1700202057906,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uqkgyZgWK0",
                "forum": "oEuTWBfVoe",
                "replyto": "qTf1qPer2s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_s75f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_s75f"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\n\nI would like to thank you for your detailed answer. Regarding your following question:\n\n>  Can the Reviewer please clarify what comparison they would like to see? ...  In the setting of Figure 4, we could revise the text to compare our model\u2019s performance to the previous model in Rajagopalan et al. Would this help, or does the Reviewer have something else in mind?\n\nI believe this would be a valuable addition (if it is plausible in the given limited time). Other than that, I am happy to move my Soundness and Presentation scores by 1 given these details will be added to the manuscript."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700323970726,
                "cdate": 1700323970726,
                "tmdate": 1700323970726,
                "mdate": 1700323970726,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fGFpacvcKz",
                "forum": "oEuTWBfVoe",
                "replyto": "3n22f9hQMG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_s75f"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_s75f"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\n\nI would like to thank you for the revised manuscript and the authors' commitment to providing further clarifications. I upgraded my score by one."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685469001,
                "cdate": 1700685469001,
                "tmdate": 1700685469001,
                "mdate": 1700685469001,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GVWgMhnTsu",
            "forum": "oEuTWBfVoe",
            "replyto": "oEuTWBfVoe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3073/Reviewer_qMGi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3073/Reviewer_qMGi"
            ],
            "content": {
                "summary": {
                    "value": "This paper infers synaptic plasticity rules from experimental data on neural activity or behavioral trajectories by parameterizing the plasticity function to provide theoretical interpretability and facilitate gradient-based optimization.\nThey use Taylor series expansions or multilayer perceptrons to approximate plasticity rules and adjust parameters via gradient descent over entire trajectories to match observed neural activity or behavioral data closely.\nThey also learn intricate rules that induce long nonlinear time-dependencies, such as those incorporating postsynaptic activity and current synaptic weights, and validate through simulations, accurately recovering established rules, like Oja's, as well as more complex hypothetical rules incorporating reward-modulated terms."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The framework's ability to parameterize the plasticity function provides a balance between theoretical interpretability and practical optimization.\n\nThe use of established mathematical techniques, like Taylor series expansions and multilayer perceptrons, lends credibility to the approach.\n\nThe method's versatility is evident in its ability to learn both established rules like Oja\u2019s and more complex, hypothetical ones.\n\nReal-world application on Drosophila data and the discovery of an active forgetting component showcase the practical relevance and potential breakthroughs the framework can offer."
                },
                "weaknesses": {
                    "value": "The paper is really interesting, but I have some key concerns. First and most importantly, I think this paper might not be a very good fit for the conference and might be better suited for a neuroscience journal/conference. For example, the paper tries to recover Oja's rule from experimental data. Though it is a good exercise, I feel it would be interesting if this method could be used to model a more generalized learning form and show the performance of using that learning method in small networks - suppose a Hopfield network with the new plasticity. Essentially, improves on top of Oja's method using the added information and makes it more biologically plausible."
                },
                "questions": {
                    "value": "1. How were the plasticity rules shown in Table 1 derived? Were they ad-hoc variations of Oja's rule? It would be interesting if you could use some symbolic regression to find the optimal plasticity rule. \n\n2. Can you explain what you mean by \"fits neural firing rate trajectories over the course of learning\" in Page 2?\n\n3. You mentioned \"Performance benchmarks reveal that our framework\nis capable of executing simulations with up to 106 synapses and 1000-time step trajectories in less\nthan an hour on an NVIDIA A100 GPU.\" - however, from what I understand, the experiments seem to have been done on a much smaller number of synapses. Can you clarify?\n\n4. I could not fully understand the results in Section 4.2. It would be great if the authors  could add more details on \"The remaining (1 \u2212 a) fraction of neurons are modeled by incorporating random noise drawn from the same distribution as the observed neurons.\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Reviewer_qMGi"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3073/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698528518644,
            "cdate": 1698528518644,
            "tmdate": 1700688906875,
            "mdate": 1700688906875,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BvCgkZ2O8U",
                "forum": "oEuTWBfVoe",
                "replyto": "GVWgMhnTsu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qMGi (Part 1)"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your feedback and your recognition of the interesting aspects of our paper. Regarding your concerns:\n\n1. **Machine learning versus neuroscience**: \nWe think that a machine learning conference proceeding is a better fit for our work than a neuroscience paper for two main reasons. First, typical neuroscience papers ask an interesting scientific question and then answer it through some combination of method development, experimentation, data analysis, and modeling. Answering a scientific question is not the point of this work. Instead, we aim to introduce a powerful general methodology and illustrate it with proof-of-concept applications. When neuroscientists write a paper like this, they usually publish it as a methods paper, and ours is a machine learning method that fits a machine learning conference perfectly. It is common for papers like ours to be published in machine learning conferences, as evidenced by the many machine learning conference papers that we cite in our paper. Second, our paper introduces a methodology for understanding learning in neural networks that, while demonstrated within a biological context, has broader applications. The principles and techniques we outline are relevant not only to neuroscience but also to the field of artificial neural networks (ANNs) and deep learning. For instance, our method could be used to learn a simple parameterized learning rule that approximates the learning trajectories of a more computationally intensive method. This interdisciplinary relevance makes our work a good fit for the conference, as it bridges the gap between biological neural mechanisms and computational models in machine learning. \nIn summary, we believe that our work contributes significantly to the understanding of learning in neural networks, with implications that span across neuroscience and artificial intelligence. We are open to further discussions and clarifications on how this aligns well with the conference scope.\n\n2. **Choice of Oja's rule**: \nThe use of Oja's rule in our study is primarily for validation purposes. It serves as an arbitrary, yet well established, benchmark to demonstrate the efficacy of our methodology. Our choice of Oja's rule was driven by its recognizability and established theoretical foundations, making it a suitable candidate for ground truth comparison. However, it's important to note that our methodology is not restricted to Oja's rule; it can be applied to infer a wide range of synaptic plasticity rules. For example, the alternatives in Table 1 were not derived from any theoretical objective, they were merely many examples of learning rules that could be used to generate neural trajectories, and our method was consistently able to recover them. We do not think that it is necessary to use symbolic regression, or any other method, to find the optimal plasticity rule. Although it is interesting to relate the learning rules of single neurons to the output behavior of the whole system, that is not the topic of our paper. Instead, our focus is on fitting a broad range of arbitrary rules, without being constrained by the specific computation they implement or their optimality. This approach reflects the flexible and expansive nature of our model. \n\n3. **Generalized learning forms and network performance**: Your suggestion to model a more generalized learning form and benchmark its performance in networks like a Hopfield network is a good idea. However, that is not the topic of this paper, which you already recognize as \u201creally interesting.\u201d Our current focus is on developing and validating a method for inferring learning rules, rather than on enhancing or modifying specific learning methods like Oja's rule. That our paper suggests another interesting computational problem to the reviewer lends further credence to our view that a machine learning conference proceeding fits our work well."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700201644127,
                "cdate": 1700201644127,
                "tmdate": 1700201644127,
                "mdate": 1700201644127,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mHAucqZ8xM",
                "forum": "oEuTWBfVoe",
                "replyto": "GVWgMhnTsu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_qMGi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_qMGi"
                ],
                "content": {
                    "title": {
                        "value": "Thank you authors"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for their feedback. I like the paper. However, I still don't fully understand the significance. The authors mentioned, \"our method could be used to learn a simple parameterized learning rule that approximates the learning trajectories of a more computationally intensive method\" and \"our methodology is not restricted to Oja's rule; it can be applied to infer a wide range of synaptic plasticity rules\" - I believe it is necessary to show these cases in this paper. Otherwise, I am not very convinced regarding the substantiality of the novelty of the current manuscript.\n\nFor this reason, I will stick to my original score. Thank you, and good luck!"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688888080,
                "cdate": 1700688888080,
                "tmdate": 1700688888080,
                "mdate": 1700688888080,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "w6Pvvtl0q4",
            "forum": "oEuTWBfVoe",
            "replyto": "oEuTWBfVoe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3073/Reviewer_QuAL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3073/Reviewer_QuAL"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes to learn parametrized synaptic plasticity rules in recurrent rate networks by optimizing on loss functions defined on the neural trajectories and/or behavioural data. The method is validated using Oja's rule, and also applied to neural and behavioural data from the fruit fly. In the latter experiment, the method identifies a weight-dependent term that accounts for better predictions of fly behaviour."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea to directly fit plasticity rules to neural or behavioural data, rather than to functional tasks, to get biologically plausible rules is interesting.\n\n2. The experiments with the fly data are also interesting. In particular, the careful exploration to test different hypothesis about the synaptic mechanism underlying fly choice behaviour led to interpretable results on which plasticity rules, and in particular, which terms in the rule could modulate forgetting learned associations, and bidirectional plasticity. \n\n3. The paper is clearly written, concepts and related work are well-explained and overall, quite easy to follow."
                },
                "weaknesses": {
                    "value": "1. The fact that the method is restricted to rate networks precludes interesting synaptic rules from spiking networks (e.g. spike-timing dependent plasticity) that could explain a wider a range of plasticity mechanisms, and thus limits the set of interesting rules that could be inferred using this method.\n\n2. I am skeptical of the generalisability of this method, since the discovered rules would strongly depend on the choice of loss function for the neural / behavioural data. While the experiments in section 4.2 with robustness to noise and sparsity work in the idealised setting, the robustness is demonstrated with Gaussian noise, which the MSE loss is by definition capable of ignoring, in the limit of infinite data. However, with real-world neural/behavioural data, we cannot always pinpoint the exact distribution of noise, and it would be practically quite difficult to construct a loss function that is robust to unknown noise. I am thus skeptical that the method would generalise to arbatrarily complex neural behaviours or trajectories, and that the inferred plasticity rules in these settings would be biologically plausible.\n\n3. Section 7 mentions that \"[a]nother issue is the model's \"sloppiness\" in the solution space; it fails to identify a unique sparse solution even with extensive data\". If this is the case with the current experiments in sections 4-6, how does this affect the interpretation of the results and how much can we rely on the experimental predictions about plasticity mechanisms? For instance, which particular experiment/solution forms the basis for the conclusions about the decay mechanism in 6.1 and bidirectional plasticity in 6.2?\n\n4. The experiments in section 6, appear to add terms to the parametrized rule based on previously hypothesised plasticity mechanisms in the fruit fly. Although, this was an effective method of exploration in this particular instance, how would this generalise to neural / behavioural datasets for which such hypotheses do not exist, or are unsatisfactory? If instead, we could perform rule inference using this method using MLPs or some other form of parametrization, how would we interpret the resulting rules?\n\nTaken together, it seems that although this method provides more biologically plausible rules that plasticity rule inference via optimizing for network function (Tyulmankov et al 2022, Confavreux et al 2020, Lindsey and Litwin-Kumar 2020, etc.), it swaps one set of loss functions for another, but still shares many of the same problems of generalisability and interpretation."
                },
                "questions": {
                    "value": "1. How generalisable is the method, when in its current form, it cannot be applied to spiking networks?\n2. How generalisable is the method, when constructing a loss function on neural activity / behaviour with unknown noise sources?\n3. How interpretable / reliable are the inferred plasticity mechanisms when the model fit is \"sloppy\" with limited data?\n4. How generalisable is the inference mechanism when we do not have satisfactory a priori hypotheses about the underlying plasticity mechanism?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Reviewer_QuAL"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3073/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698776564039,
            "cdate": 1698776564039,
            "tmdate": 1700394667118,
            "mdate": 1700394667118,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vyZovOQiM4",
                "forum": "oEuTWBfVoe",
                "replyto": "w6Pvvtl0q4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer QuAL (Part 1)"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your comments on our work. We address each of the suggested weaknesses/questions below. To summarize, while we agree with the highlighted limitations due to robustness (noise/sloppiness), interpretability, and lack of prior hypotheses, these concerns are applicable to any statistical model-fitting setup. Some of these have standard solutions, but in general they are ubiquitous problems that are outside the scope of our work. We also point out that our method indeed can account for spiking models, and the plasticity rules that we fit are, by definition, biologically plausible. \n\n**Spiking neural network models**\n\nAlthough our approach uses rate networks as the underlying neural network model, our approach is not limited to rate networks. In the case of stochastic spiking models, we demonstrate an analogous scenario by fitting fly behavioral data with a probabilistic model, maximizing the log-likelihood of the model\u2019s output given the data. This can easily be applied to fitting spiking (e.g. Poisson) neural trajectories rather than stochastic behavioral trajectories. \n\nAlternatively, we can think of rate-based neural networks as an abstraction over spiking networks. Given spiking data, we can generate a rate code by smoothing e.g. with a Gaussian kernel, which we can fit immediately with a rate model. Furthermore, STDP rules can be mapped onto Hebbian plasticity in rate networks [1], so rate networks do not preclude STDP as a potential plasticity mechanism (although we do concede that the precise timing of the spikes is lost). \n\nOur approach can also be easily modified to account for spiking data without any preprocessing, using a spiking model. As presented in the current work, the only limitation is the optimization algorithm. If the spiking model is an Hodgkin-Huxley type model with differentiable spike waveforms, we can use our method out-of-the-box \u2013 the only limitation is compute power, since these models have extremely detailed dynamics and many CPU cycles are required to simulate a single spike. If the spiking model is comprised of binary neurons with a Heaviside step function nonlinearity, optimization techniques such as surrogate gradients can be used. In the case of non-differentiable models, e.g. integrate-and-fire neurons, we can use evolutionary algorithms. \n\n**Unknown noise sources and biological plausibility**\n\nWe agree that the noise model and loss function would impact the results of the model fitting. However, this is a problem that is true for any statistical modeling, and therefore much more general than the scope of our work. The Gaussian noise assumption is a common one and is used as the noise model ubiquitously. More importantly, Gaussian noise is also the most likely, assuming the Central Limit Theorem holds, and therefore it is a valid assumption. Similarly, mean-squared error is the standard loss function for many statistical models of real-valued data, and cross-entropy for models of binary data. \n\nIf, however, there is strong prior belief that the noise is non-Gaussian, e.g. if there are correlations, bias, skew, or heavy tails in the noise model, this can be factored into the loss function appropriately. For completeness, we also note that after our initial submission, a preprint was released that directly tackles this problem by using a generative adversarial network to fit neural trajectories rather than an explicit loss function [2]. Although this approach is more general from the perspective of the noise model, it is both more demanding computationally, and a more difficult loss  landscape to optimize due to the use of a GAN. Although we were unable to include this work in the initial submission, we will make this comparison in our final version. \n\nFinally, the concern about the biological plausibility of the inferred plasticity rules in complex neural behaviors or trajectories is an important one. We would like to emphasize that our model infers plasticity rules using only local information, such as presynaptic and postsynaptic activity, current synaptic weight, and global dopaminergic reward signals. This, by definition, constrains the plasticity rules to be biologically plausible."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700200517051,
                "cdate": 1700200517051,
                "tmdate": 1700200517051,
                "mdate": 1700200517051,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Tyy85ATvnl",
                "forum": "oEuTWBfVoe",
                "replyto": "w6Pvvtl0q4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer QuAL (Part 2)"
                    },
                    "comment": {
                        "value": "**Sloppiness in fit and interpretability/reliability**\n\nAlthough the sloppiness of fit is a real problem in our models, we again think that it is a generic problem in statistical model fitting rather than a limitation in our specific approach. Interpretability depends on the functional form of the model (or equivalently, in the case of probabilistic graphical models, its graph structure). We demonstrate our method with an interpretable plasticity model in the form of a Taylor expansion, as well as a less interpretable one in the form of an MLP. The reliability of the method, as with all statistical models, depends on the quality and the quantity of the data. Standard statistical techniques can be used in these cases \u2013 confidence intervals, bootstrapping, cross-validation, etc. Some hypotheses, however, by definition cannot be distinguished with a particular dataset. \n\nWe would also like to highlight the fact that the sloppiness occurs in the specific parameterization of our plasticity rule, rather than in a degeneracy of the rule itself (unlike the results in [2], which, again, we will discuss in the final version of our submission). We find a unique plasticity function, i.e., the shape of the input-output curve on a graph, but not a unique parametrization of that function.As a trivial example, the functions $y = x$ and $y = x^2$ are indistinguishable if the only values of $x$ which we sample are 0 and 1, so if the ground truth is $y = x + x^2$, we can fit any function $ax + bx^2$ with $a + b = 1$.\n\nNevertheless, regardless of the parametrization of the plasticity rule, our method is informative with regard to the inputs that are relevant for a plasticity update, e.g. whether pre- or post-synaptic activity plays a role, or both; or, as we demonstrate in Drosophila, whether a weight decay is present. Following the adage, \u201cAll models are wrong but some are useful,\u201d we believe that our model is useful from this perspective. \n\n**No a priori hypotheses**\n\nThe problem of hypothesis generation is an important and difficult one. Any fitting experiment is limited to the functional family that is being fitted. Since the goal of our work is introducing and demonstrating a new and general computational methodology, not on establishing and interpreting a novel biological finding, we simply chose a hypothesis using prior knowledge established in other work. We demonstrate that our method is reliable for a given hypothesis class. Generating a hypothesis (i.e. the functional family as well as choosing the appropriate inputs) can be done through what has been referred to as \"Box's loop\" [3]. We iterate on hypotheses and do model validation for each one until we reach satisfactory convergence (or a deadline).\n\nIn an extreme case, given sufficient data and computational power, we can simply consider a sufficiently broad hypothesis which includes all the possible inputs and allow the optimization routine to decide which ones should be used and in what way. If the functional family is an interpretable one, such as the Taylor series, we can gain mechanistic insights into the plasticity rule itself. For instance, consider\n\n$$\ng_\\theta = \\sum_{\\alpha,\\beta,\\Phi,\\gamma} \\theta_{\\alpha,\\beta,\\Phi,\\gamma} x_j^\\alpha r^\\beta y_i^\\Phi w_{ij}^\\gamma\n$$\n\nWe did not explore this learning rule because it involves significantly more coefficients that must be fit, and hypothetical dependencies of the mushroom body\u2019s learning rule on y can be excluded on biological grounds. To address the reviewers concern, we will try fitting this more complex learning rule in our revision to see whether the coefficients can still be recovered. \n\nIn a fully general approach, we can even consider a dynamic plasticity model (e.g. an RNN) that, given all possible inputs to a synapse, can learn history-dependent terms such as expected reward (which, this time, we manually included in our function). Although such a model (or even a simpler one such as the MLP) is hard to interpret, it still gives us an input-output relationship that we can use to make predictions. It also allows us to explore which inputs are important e.g. by including/excluding reward as one of the inputs into the MLP. Moreover, it gives us a well-defined functional form of a putative plasticity rule that we can perturb and analyze in ways unavailable in a biological system. Since the input space is low-dimensional, for example, we can visualize the function\u2019s graph. \n\n[1] Sjostrom and Gerstner. Spike-timing dependent plasticity. Scholarpedia, http://www.scholarpedia.org/article/Spike-timing_dependent_plasticity#STDP_versus_Rate_based_learning_rules\n\n[2] Ramesh et al. Indistinguishable network dynamics can emerge from unalike plasticity rules. bioRxiv, https://www.biorxiv.org/content/10.1101/2023.11.01.565168v1.full.pdf\n\n[3] Blei. Build, Compute, Critique, Repeat: Data Analysis with Latent Variable Models. https://www.cs.columbia.edu/~blei/papers/Blei2014b.pdf"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700200543904,
                "cdate": 1700200543904,
                "tmdate": 1700219561068,
                "mdate": 1700219561068,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hF6qlHJHh8",
                "forum": "oEuTWBfVoe",
                "replyto": "w6Pvvtl0q4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_QuAL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_QuAL"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "I thank the authors for their detailed responses to my questions.\n\nRegarding the point on spiking neural network models, I agree that evolutionary algorithms or MLE estimation might indeed be a useful way to extend the framework spiking network models. However, I am still worried about the framework's generalizability, particularly when also accounting for non-Gaussian noise:\n> If, however, there is strong prior belief that the noise is non-Gaussian, e.g. if there are correlations, bias, skew, or heavy tails in the noise model, this can be factored into the loss function appropriately.\n\nFactoring these terms into the loss function might make MLE or evolutionary methods non-trivial to implement and train to convergence. In particular, while the assumption of Gaussian noise / central limit theorem might be ubiquitous, it is not uncommon to find correlated neural trajectories (Smith and Kohn 2005, Bartolo et al 2020, Valente et al 2021) or other shifts away from purely Gaussian noise. \nGiven these difficulties, I am still skeptical about the generalizability of the framework.\n\nRegarding the sloppiness of fit: \n> We would also like to highlight the fact that the sloppiness occurs in the specific parameterization of our plasticity rule, rather than in a degeneracy of the rule itself\n\nI am confused by this -- could the authors elaborate on this point? Following from the example in the response, wouldn't the ambiguity in the values of $a$ and $b$ qualify as degeneracy? In any case, it would be useful to include this point in the discussion in the manuscript.\n\nRegarding a-priori hypothesis:\n> we will try fitting this more complex learning rule in our revision to see whether the coefficients can still be recovered.\n\nThis would be a great addition. Comparisons/Discussion of Ramesh et al or Rajagopalan et al (as pointed out by reviewer s75f) would certainly be useful.\n\nI recognize that this may be difficult to achieve within the time-frame of discussion period. I have increased my score to a 5, on the understanding that these comparisons / discussions will be included in subsequent revisions of the paper if accepted.\n\nHowever, I would like to note that my concerns remain on the generalizability as well as limited novelty of this work."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700394603268,
                "cdate": 1700394603268,
                "tmdate": 1700394643457,
                "mdate": 1700394643457,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CzwuLzxzoU",
            "forum": "oEuTWBfVoe",
            "replyto": "oEuTWBfVoe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3073/Reviewer_Xu3v"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3073/Reviewer_Xu3v"
            ],
            "content": {
                "summary": {
                    "value": "The paper develops a meta-learning model for synaptic plasticity rules. They parameterize the plasticity rule as a polynomial function, or a multi-layer perceptron, of the pre-, post-activity, weight and global reward, and by gradient descent update the learning rule to minimize a loss that depends on the output trajectory. Differently from previous work, they optimize over the whole trajectory, instead of final weights/activity, and apply it also to behavioural data, instead of neural activity. One application has the loss as the distance to a target trajectory, obtained from a ground truth learning rule (Oja\u2019s rule), which is successfully recovered. In the second application, the output activity represents the probability of taking an action on a reward-seeking task, and the target is a trajectory of actions taken. This is applied to experimental data of a fruit fly in a setting where the rewarding action changes over time. A reward-based rule of the form x*(R - E[R]) - a*w is recovered, and variations with and without E[R] or -a*w factors are discussed."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The main novel contributions of the paper are the optimization over trajectories, instead of endpoints, and fitting behavioural data. \n- Optimizing over trajectories might be more efficient and appropriate when such data is available. \n- Fitting a family of plasticity rules to data will strengthen our knowledge of mechanisms at work in different systems.\n- It is significant to propose a new dataset that can be modelled by this approach.\n\nPrevious literature on inferring plasticity rules is properly referred to.\n\nThe simulation results seem sound.\n\nThe general methodology is clear (apart from the questions outlined below)."
                },
                "weaknesses": {
                    "value": "The main weaknesses are:\n- Methodological choices\n- Theoretical grounding of learning rules\n- Limited novelty of trajectory optimization\n\nThere are methodological questions that should be clarified, listed also in the Question section below. \n\nIt is unclear why there are multiple output neurons, how they are pooled, and if they all learn the same thing. Is it the case that one needs multiple output neurons just to have enough data, and it would be equivalent to having many instantiations of the simulation with single output neurons? Do the neurons for Oja's rule all simply learn the first principal component? \n\nRelated to this point, if all neurons in the output layer learn the same thing, the study in Fig.2 with noise and sparseness might simply reflect how many \"trials\" are needed for a single neuron simulation. Noise in this case would just make gradients for the meta-learning less informative, needing more trials, which would be true for any learning simulation.\n\nOne main contribution of the paper relative to previous work is optimizing trajectories, instead of endpoints, but it is not clear if this is a substantial advancement. It would strengthen this point to have more results and discussion on this difference. What kind of data can this model tackle that endpoint optimization can't? Would the results be the same? Is it a matter of data efficiency? How would endpoint optimization behave in the fly dataset? A technical point: is backprop through time used?\n\nOne main contribution of the paper is the fitting of behavioral data. But there is a gap between modelling a synapse and a whole system as if the fly was a single neuron. Why can modelling a single neuron work in this case? Isn't this approach more appropriate for neural data from the relevant neurons in the fly mushroom body?\n\nThere is a lack of theoretical grounding of the learning rules studied, e.g. that the Oja rule will learn the PC1; what are the optimal learning rules for the reward-based task?; what is the effect of the weight decay term on the learning rule? \n\nThere is no discussion on the time scale inherent to the learned weight decay term. How does it relate to trial times? Related, the effect of the time scale of the E[R] is subtle and will have a different effect if the average is within a trial or over multiple trials (see Fremaux, Sprekeler, Gerstner, J Neuroscience, 2010). Related to this point, did the authors try learning the E[R] factor separately, or learning the time scale? The discussion on weight dependent vs. expected reward factor loses strength due to these limitations.\n\nThe MLP rules are included but never discussed. They should be better motivated and referred to.\n\nMinor:\n\nIn the figures, it should show the factors in the ticks (e.g. x*R), instead of the binary parameter indexes, which are hard to decode."
                },
                "questions": {
                    "value": "How are the inputs x_t sampled? N(0,1)?\nHow exactly are the neurons from the output layer pooled in each application?\nDo all neurons in the output layer learn the same thing?\n\nIs the loss and gradient local in time or backpropagated through time?\nHow does the trajectory loss compare with the end goal loss?\n\nWhat do the MLP learning rules learn?\n\nWhy is the E[R] term not learned as a separate term?\nHow does the result depend on the time scale of E[R]? \nWhat is the time-scale inherent to the learned weight decay term?\n\nHow should one relate the learning rule for a single neuron to the output behaviour or a whole system?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3073/Reviewer_Xu3v"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3073/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699300276222,
            "cdate": 1699300276222,
            "tmdate": 1699636252613,
            "mdate": 1699636252613,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SE95lqfUZ2",
                "forum": "oEuTWBfVoe",
                "replyto": "CzwuLzxzoU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer Xu3v (Part 1)"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your insightful comments and constructive feedback on our manuscript. We appreciate the opportunity to clarify and expand upon key aspects of our work. Below, we address each of your concerns in detail.\n\n**Methodological Choices and Theoretical Grounding**\n\nOur decision to include multiple output neurons in our model is primarily to demonstrate scalability. The model effectively functions with a single output neuron, but the use of multiple neurons showcases its applicability to larger, more complex networks. This is not a trivial problem as the loss is computed over the entire trajectory length and parameters are optimized with backpropagation through time. In the context of the behavioral task, the outputs are pooled through a fixed layer followed by a sigmoid function, determining the probability of accept/reject decisions. It's noteworthy that these output neurons typically follow unique trajectories. The convergence to the same outputs in the case of Oja\u2019s rule is a specific instance, not a general trend that holds across learning rules. This aspect also underlines the versatility of our model in fitting diverse rules. \n\nWe will revise the manuscript to mention the link between Oja\u2019s rule and principal component analysis, to state that the theoretical motivation for including the E[R] term is to enable covariance-based learning that leads to operant matching, and to explain that the weight decay term could explain forgetting. However, we do not think that it is necessary to provide a theoretical rationale for the other learning rules that we consider. Instead, our focus is on fitting a broad range of arbitrary rules, without being constrained by the specific computation they implement or their optimality. This approach reflects the flexible and expansive nature of our model. Although we agree that it is interesting to relate the learning rules of single neurons to the output behavior of the whole system, that is not the topic of our paper. \n\nFor the E[R] term, our experiments encompassed various time scales (5, 7, 10, 15, 20) trials, leading to consistent results across these variations. This uniformity in outcomes led us to exclude it as a learnable parameter in our optimization loop. Dynamics within the trial had no bearing on E[R].\n\n*Modelling Synaptic and System-Level Behavior:*\nRecent research, particularly by Aso et al., has demonstrated that activating a specific neuron in the fly mushroom body can influence the fly's upwind movement. This finding is crucial to our experimental setup, where odors flow and the fly's reward-driven upwind movement is a key behavior. This validates our approach of modeling single neurons, as it aligns with the observed behavior in real-world scenarios. Our approach also mimics the setting of a previous biology study by Rajagopalan et al. that we wanted to extend with our methodology. We will modify the text to explain these points and specify the exact neuron referenced in this context for clarity.\n\nOther work from Aso and collaborators has quantified how olfactory memories decay over time. In light of your comments, our revision will include an analysis of how the inferred learning rule leads weights to decay over trials, thereby leading to memory decay. We will compare the inferred learning rule to plasticity mechanisms discussed in Aso\u2019s studies.\n\nWe parameterized the learning rule with an MLP to see whether we could capture the learning rules with a general expressive model that did not match the ground-truth generative model. However, Figure 3 and Table 1 revealed that the MLP usually underperformed the Taylor series representation. We therefore decided to focus Figure 4 on the Taylor series representation, which is both more interpretable and better aligned to the known biology. We will explain these motivations and findings in the revised manuscript. For similar reasons, we did not attempt to quantify what the MLP rules learned in Figure 3. If the MLP approach had been more empirically successful, then we would have interpreted the learned rules by directly plotting the three-dimensional function of presynaptic activity, reward, and weight that they discovered. This could have easily been compared to the exact function specified by the ground-truth generative model."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700199706259,
                "cdate": 1700199706259,
                "tmdate": 1700199706259,
                "mdate": 1700199706259,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2HNvJPvb7Z",
                "forum": "oEuTWBfVoe",
                "replyto": "pOXujSYi4d",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_Xu3v"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Reviewer_Xu3v"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors, thank you for the detailed answer.\n\nOverall, as the authors argue, the main contribution is the optimization over a trajectory, instead of final endpoints or a loss function, using backprop through time. As this is the main contribution, this method and the advantages of this method in comparison with the alternatives should be much clearer. If I'm not mistaken, the paper does not mention backpropagation through time at all. One could also optimize over trajectories without it, which might be more data efficient, with similar results. \n\n> In the context of the behavioural task, the outputs are pooled through a fixed layer followed by a sigmoid function, determining the probability of accept/reject decisions. It's noteworthy that these output neurons typically follow unique trajectories. The convergence to the same outputs in the case of Oja\u2019s rule is a specific instance, not a general trend that holds across learning rules. This aspect also underlines the versatility of our model in fitting diverse rules.\n\nHow are output neurons pooled exactly? Adding more output neurons does not increase scalability if they are all doing the same thing, it only increases data availability, which might be necessary because the method is more noisy and data-hungry. Why do output neurons learn unique trajectories? Shouldn't they all learn the same, if they are pooled to give the same output? Showing that your method works for a more specific case, does not show the versatility to more general cases.\n\n> However, we do not think that it is necessary to provide a theoretical rationale for the other learning rules that we consider. Instead, our focus is on fitting a broad range of arbitrary rules, without being constrained by the specific computation they implement or their optimality. This approach reflects the flexible and expansive nature of our model.\n\nTo argue that the method is more powerful than others, and can infer plasticity rules without priori knowledge, then it should be shown that the method works without such knowledge, e.g. with more polynomial terms than expected. On the contrary, the paper seems to use prior knowledge at multiple points to constrain the number of factors, as in the specific inclusion of E[R] and w, the fixed time constant of E[R], and the exclusion of y."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580421375,
                "cdate": 1700580421375,
                "tmdate": 1700580421375,
                "mdate": 1700580421375,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oZE3tee42C",
                "forum": "oEuTWBfVoe",
                "replyto": "CzwuLzxzoU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the Reviwer for the follow-up questions and concerns. We address each of them below. With these clarifications and planned changes, we believe that we will have been able to address all of the reviewer\u2019s major concerns. Please let us know if there are any lingering issues that prevent the reviewer from considering updating their overall rating.\n\n1. \n\nOur main contribution is indeed optimization over a trajectory with backpropagation through time (BPTT). To be precise, however, we still optimize a loss function, although it is defined as the error between the data and model trajectories, rather than a functional relationship as in previous work [Confavreaux et al. 2021, Tyulmankov et al. 2022]. To optimize this loss function we use BPTT, which was implicit in the definition of the loss function (Eq. 3) and its derivative (Eq. 4) due to the time dependency. We agree that this should be made more clear and explicit, and we will update the text accordingly.\n\nIt might be helpful to distinguish between the optimization *problem* and the used optimization *technique* to solve it. Our approach is fundamentally different from alternative setups in terms of the optimization problem. We provide a discussion and comparison in the \"Related Work\" section. The only other work we are aware of that uses neural trajectories to fit a plasticity rule is [Ramesh et al. 2023], which was only published to *bioRxiv* after our initial submission. We will include a qualitative comparison in the final version of our manuscript nevertheless. In terms of comparison to other optimization techniques, the choice of optimizer is an implementation detail that we could revisit in future work. Indeed, alternatives for computing gradients such as real-time recurrent learning (RTRL) can be used, or approximations to the gradient such as truncated BPTT, or even non-gradient based methods such as evolutionary algorithms.\n\nHowever, any approximations (whether approximations to the gradient or using only endpoints in the loss) will be strictly less data-efficient (although may be more computationally- and memory-efficient), since we would be ignoring long-term dependencies between the parameters and data. As such, we opted for the most powerful methodology because we wanted it to work for arbitrary rules, some of which might be highly nonlinear and benefit from long time dependencies more than others (see below). \n\n\n2.\n\nThe reviewer asked several related questions. Our responses are:\n* Output neurons are uniformly summed (weights equal to 1), and a logistic sigmoid function is applied to that sum to generate a probability of choosing the current odor. \n* Our discussion of  \u201cscalability\u201d refers to our implementation\u2019s ability to handle large networks, rather than any comment about data efficiency.\n* In the general case, learning rules define nonlinear dynamical systems that can depend sensitively on their initial conditions as well as the particular noise instantiation. Because of this, the output neurons do not necessarily follow identical trajectories \u2013 the pooled behavioral readout is then a linear combination of their individual (unique) outputs. As such, additional output neurons do offer additional information about the plasticity rule beyond simple data availability.  However, as with Oja\u2019s rule (which learns weights that align with the first principal component), it may be the case that output neurons behave similarly. Nevertheless, Table 1 shows that the method works for many different learning rules beyond Oja\u2019s rule, and it is inaccurate to say that we\u2019re generalizing because our method \u201cworks for a specific case.\u201d"
                    },
                    "title": {
                        "value": "Clarifications and updates"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591145318,
                "cdate": 1700591145318,
                "tmdate": 1700591292970,
                "mdate": 1700591292970,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bs4NrLAF4u",
                "forum": "oEuTWBfVoe",
                "replyto": "CzwuLzxzoU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3073/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "3.\n\nThe problem of hypothesis generation is indeed an important and difficult one. Here, we simply choose a hypothesis using prior knowledge established in other work. We demonstrate that our method is reliable for a given hypothesis class. Generating a hypothesis (i.e. the functional family as well as choosing the appropriate inputs) can be done through what has been referred to as \"Box's loop\" [Blei, 2014]. We iterate on hypotheses and do model validation for each one until we reach satisfactory convergence (or a deadline).\n\nWe do not claim that plasticity rules can be inferred without any prior knowledge. The most important prior knowledge that underlies this work is that plasticity rules in biology can only local information, such as presynaptic and postsynaptic activity, current synaptic weight, and global dopaminergic reward signals. This, by definition, constrains the plasticity rules that we fit to be biologically plausible. We note that this prior knowledge is far less restrictive than prior knowledge of the circuit\u2019s *computation,* which was assumed in the previous work of Confavreaux et al. and Tyulmankov et al. Given sufficient data and computational power, one could consider a sufficiently broad hypothesis which includes all the possible inputs and allow the optimization routine to decide which ones should be used and in what way. For instance, consider\n$$\ng_\\theta = \\sum_{\\alpha,\\beta,\\Phi,\\gamma} \\theta_{\\alpha,\\beta,\\Phi,\\gamma} x_j^\\alpha r^\\beta y_i^\\Phi w_{ij}^\\gamma\n$$\nWe did not explore this learning rule in our submission because it involves significantly more coefficients that must be fit, and hypothetical dependencies of the mushroom body\u2019s learning rule on $y$ can be excluded on biological grounds. However, to address the reviewer\u2019s concerns, we will try fitting this more complex learning rule in our revision to see whether the coefficients can still be recovered."
                    },
                    "title": {
                        "value": "Clarifications and updates (part 2)"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3073/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591235172,
                "cdate": 1700591235172,
                "tmdate": 1700591311274,
                "mdate": 1700591311274,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]