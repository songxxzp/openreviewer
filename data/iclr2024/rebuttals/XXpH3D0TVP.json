[
    {
        "title": "The Journey, Not the Destination: How Data Guides Diffusion Models"
    },
    {
        "review": {
            "id": "jvdzl5B5LN",
            "forum": "XXpH3D0TVP",
            "replyto": "XXpH3D0TVP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6016/Reviewer_ujFU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6016/Reviewer_ujFU"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a framework for data attribution in diffusion models to attribute generated images back to the training data, allowing for identification of influential training examples. The framework attributes each step of the diffusion process, providing targeted attributions for specific features of the final generated image. The paper introduces metrics for evaluating the attributions and presents a method for computing them."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strengths:\n1) The paper clearly conveys the significance of data attribution in diffusion models, the theoretical validation of the framework, and the development of metrics for evaluating attributions.\n2) The paper also demonstrates the practical applicability of the framework through experiments on real datasets.\n3) Detailed implementation settings and code are provided, which makes for easy reproducing the study."
                },
                "weaknesses": {
                    "value": "Weaknesses:\n1) The structure of the paper is a bit confusing and not easy to follow.\n2) The paper formulated a novel research problem, but the proposed method appears to be relatively primitive compared to the complexity of the problem at hand."
                },
                "questions": {
                    "value": "Please refer to the weakness part. Further, the fine-grained analysis in section C.2 is intriguing. It appears that the model has a tendency to generate images by referencing specific semantic parts of the training images rather than generating the entire images. Therefore, does it still make sense to attribute these generated images to image-level data?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6016/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6016/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6016/Reviewer_ujFU"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6016/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698217593182,
            "cdate": 1698217593182,
            "tmdate": 1699636645973,
            "mdate": 1699636645973,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VlfSLf891E",
                "forum": "XXpH3D0TVP",
                "replyto": "jvdzl5B5LN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6016/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6016/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal Response"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful feedback.\n\n\n### Structure of the Presentation\nTo address the reviewer\u2019s concerns over the structure of the presentation, we have made a number of changes to the structure of the main text:\nWe made revisions to Section 3 (which introduces our attribution framework) to simplify the language and make the presentation more modular. Additionally, we added an in-depth section on TRAK [1] to the background section in order to better contextualize our method.\nWe shortened Section 4 (which describes our method) and made more explicit connections to the preliminaries in Section 2.\n\n### Simplicity of the proposed method\nAs the reviewer acknowledges, our paper formalizes and studies a new research problem. We introduce a method building on top of state-of-the-art work for data attribution in the supervised setting. While our method is relatively simple, we view the simplicity of our method as a feature, not a bug. In particular, we demonstrate through our evaluations that, despite its \u201csimplicity,\u201d our method surfaces attributions that are counterfactually significant to the behavior of diffusion models. Due to its simplicity, our method is easier to implement (by extending upon the open source implementation of TRAK) and easier for other works to build upon. Conceptually, the success of our approach indicates that despite the complexity underlying modern NNs, we can reason about them by approximating them with kernel models.\n\n### Attribution beyond image-level data\nWe agree that it would be interesting to extend the data attribution task to attribute behavior not only to individual training examples, but rather to parts of images (our understanding is that is what the reviewer is suggesting). For example, the diffusion model might be using the background of some training image at an earlier step, but might then use an object in the foreground at a later point (we allude exactly to this in Appendix C.2). More broadly, such a perspective on data attribution  would also be useful in other settings, including supervised tasks. We view this direction as a great potential future extension of the work.\n\nHowever, we believe that it is  still very valuable to attribute generated samples back to image-level data. First, for many possible applications of data attribution, it is most convenient and natural to intervene on image-level data. For example:\nCopyright violations and data leakage are generally only discussed at the level of individual images (or sets of images, e.g., an artist\u2019s body of work).\nData curation is almost always formalized on a per-image level.\nData poisoning is usually performed on individual examples [2].\n\nAdditionally, attributing with respect to patches might limit the scalability of the method. For example, if we divide images into 16 patches, we would need to compute and store 16x more gradients.\n \n[1] Park, S. M., Georgiev, K., Ilyas, A., Leclerc, G., & Madry, A. (2023). TRAK: Attributing model behavior at scale. arXiv preprint arXiv:2303.14186.\n\n[2] Khaddaj, Alaa, et al. \"Rethinking Backdoor Attacks.\" (2023)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6016/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700170512651,
                "cdate": 1700170512651,
                "tmdate": 1700170521723,
                "mdate": 1700170521723,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "djvJfJIYt8",
            "forum": "XXpH3D0TVP",
            "replyto": "XXpH3D0TVP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6016/Reviewer_XavF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6016/Reviewer_XavF"
            ],
            "content": {
                "summary": {
                    "value": "In this work, authors introduce an extension of the Trek method that provides data attribution measurement to the family of diffusion methods. The goal of the analysis is to show that with the proposed methodology we can attribute which training images (and how) influenced the final generation. The evaluation is performed on CIFAR10 and MS COCO dataset with DDPMs and latent diffusion models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This submission tackles an interesting and important problem that to my knowledge was not yet approached in the context of diffusion models\n- The proposed method is a direct application of the Trek method to diffusion models. However, this extension is non-trivial and might have significant impact on some areas of research such as machine unlearning.\n- The evaluation is performed on a big scale (although it is mostly presented in the appendices)"
                },
                "weaknesses": {
                    "value": "-In general, there is a significant mismatch between the goal of the method as expressed at the beginning of the submission and the final experiments being evaluated. This is due to a series of approximations that make the computation possible. The interesting question is how those approximations influence the final observations (e.g. using one-step approximation of $\\hat{x}_0^t$ as an approximation of the distribution\u2019s expectation $E[x_0|x_t]$). If I understand it correctly, this assumption indicates that there would be no change in the final distribution due to later diffusion steps. For some cases with higher t values (e.g. timesteps>600 in Figure 3) this approximation might be wrong.\n- \u201cHowever, the effect of a single time step on the final distribution may be small and hard to quantify. Hence, we assume that attributions change gradually over time and replace the denoising model for a small interval of time steps (i.e., between steps t and t \u2212 \u0394).\u201d - This assumption is counterintuitive to the previous derivations on what authors consider attributions for diffusion models in their framework.\n- The submission is hard to follow without in-depth understanding of the Trak method (Perk et al. 2023) it is heavily based on. It is also almost impossible to understand the experiments without reading the appendix.\n- The presentation of the submission seems ad hoc and sloppy. There are multiple different thoughts that lack cohesion. For example Figure 4 appears on page 5 without any connection to the text, while it is referred to on page 8.\n- The provided code in its current form is far from being useful for the full reproduction of the results presented in this work. It is a total of ~200 useful lines of code (excluding imports and  comments) with some definitions of functions that should be connected to something in an unclear way.\n- The submission does not follow ICLR guidelines - the margins are significantly smaller (1 in instead of required 1.5) and the font is different."
                },
                "questions": {
                    "value": "- Are the CIFAR10 models evaluated in this submission conditioned on the class identity? Otherwise, how for example the plot in Fig 3 (left) calculated - using only 15 examples presented on the right?\n- \u201cThus, if we treat this likelihood as a function of t, the steps at which there is the largest increase in likelihood (i.e., the steepest slope) are most responsible for the presence of this feature in the final image. In fact, it turns out that this likelihood often increases rapidly\u201d -  The example presented in Fig 3 is rather extreme. Do you have any intuition why it is so?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Other reasons (please specify below)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "The submission does not follow ICLR guidelines - the margins are significantly smaller (1 in instead of required 1.5) and the font is different."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6016/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698758932600,
            "cdate": 1698758932600,
            "tmdate": 1699636645828,
            "mdate": 1699636645828,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HQJLm1ImTM",
                "forum": "XXpH3D0TVP",
                "replyto": "djvJfJIYt8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6016/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6016/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal Response (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful feedback.\n\n### Mismatch between goal and final experiments\nThe reviewer raises a concern that \u201cthere is a significant mismatch between the goal of the method as expressed at the beginning of the submission and the final experiments being evaluated [\u2026] due to a series of approximations\u201d. We would like to respectfully disagree with this statement. \n\nOn one hand, we acknowledge that our method indeed involves a series of approximations, which enable us to run large scale experiments. On the other hand, importantly, we do not make these simplifications in our evaluation. In particular, note that in Figure 5 (Retraining without top influencers), we simply retrain the diffusion models (DDPMs and LDMs) without the training examples we flag as influential, and sample directly from $p_\\theta(\\cdot | x_t)$ for each of the resulting models. Then, we report FID between those samples, and the ones generated by models trained on the entire training set. Note that neither of the approximations we employ in our method (using $\\hat{x}\\_0^t$ in lieu of samples from $p_\\theta(\\cdot|x_t)$, and using the training loss instead of the likelihood) is present in this evaluation. Hence, despite the approximations used in computing attribution scores, we show that our method significantly outperforms the similarity-based baselines in attributing the full distribution.\n\nThe reviewer also raises the question whether replacing $\\mathbb{E}\\_{x\\_0 \\sim p\\_{\\theta}(\\cdot|x\\_t)}[x\\_0]$ with $\\hat{x}\\_0^t$ implicitly creates an additional assumption that the later diffusion steps do not contribute to the final generated image. This is not the case: the use of $\\hat{x}\\_0^t$ to approximate $\\mathbb{E}\\_{x\\_0 \\sim p\\_{\\theta}(\\cdot|x\\_t)}[x\\_0]$ simply provides us with an computationally-efficient estimate of $\\mathbb{E}\\_{x\\_0 \\sim p\\_{\\theta}(\\cdot|x\\_t)}[x\\_0]$. As we note in the paper, the additional assumption we introduce is that the diffusion model is approximately consistent, as defined in [2].\n\nOverall, we found that despite the simplicity of the approximations used, our approach enables meaningful attributions. That said, using more sophisticated approximations is an interesting direction for future work.\n\n### Effect of a single step\nThe reviewer raises a concern about the assumption that our attributions change gradually over the course of the diffusion process. First, we note that we empirically observe this phenomenon. In particular, see Figure C.5---we show that there is a very high rank correlation between our attributions for steps in close proximity to each other. Second, we would like to point out that in practice we only use this assumption for small intervals, e.g., <=100 steps within a 1000-step diffusion trajectory. \n\n### Presentation of the submission\nTo address the reviewer\u2019s concerns over the quality of the presentation, we have made a number of improvements to the structure of the main text:\n- \u201cThe submission is hard to follow without in-depth understanding of the Trak method\u201d: We added an in-depth section on TRAK [1] to the background section in order to better contextualize our method.\n- \u201cFigure 4 appears on page 5 without any connection to the text, while it is referred to on page 8\u201d: Some of the figures were indeed poorly placed - we have adjusted the figure placements in the rebuttal, so that they appear closer to where they are referenced.\n- \u201clack of cohesion\u201d: we made revisions to Sections 3 and 4 that introduce our attribution framework and describe our method. In particular, we simplified the language and made the presentation more modular.\n\n\n### Code\nIndeed, we do provide a concise (~200 loc) API built on top of the TRAK API (https://github.com/madrylab/trak/). But we view the simplicity of our implementation as one of the strengths of our method rather than a shortcoming. To address the ease of use of our API, we have added:\n1. Two demo notebooks (`examples/demo_MSCOCO.ipynb` and `examples/demo_CIFAR10.ipynb`) that provides a simple way for users to score images synthesized by an LDM model trained on MS COCO, and a DDPM model trained on CIFAR-10, respectively.\n2. A set of scripts (together with a README with an explicit set of commands) to reproduce the computation of our TRAK scores on both DDPM models trained on CIFAR-10 and LDMs trained on MS COCO.\n\n### Adhering to margin and font\nWe thank the reviewer for pointing out the incorrect margins and font size in our submission. This was an unintentional accident due to a git merge, and we fixed the revised version to adhere to the ICLR guidelines. The margins we used were wider than the ICLR guidelines, however it turns out our font was also wider. After fixing both the font and margins, we found that there was very little difference in the resulting paper length (about one paragraph). We apologize for this error."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6016/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700170435194,
                "cdate": 1700170435194,
                "tmdate": 1700170435194,
                "mdate": 1700170435194,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WoI3eplfK2",
            "forum": "XXpH3D0TVP",
            "replyto": "XXpH3D0TVP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6016/Reviewer_KmFt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6016/Reviewer_KmFt"
            ],
            "content": {
                "summary": {
                    "value": "This work focuses on attribution for diffusion models, i.e. understanding how the underlying training data influences the generation of a sample. This work proposes an approach based on TRAK [1] to attribute a single denoising step back to the training data. The work also proposes metrics based on counterfactual estimation to evaluate attribution approaches and shows comparisons against simple baselines on multiple datasets (CIFAR-10 and MS-COCO).  \n\n[1] Park, Sung Min, et al. \"Trak: Attributing model behavior at scale.\"\u00a0_arXiv preprint arXiv:2303.14186_\u00a0(2023)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The work focuses on an important and timely problem. Attribution for models is an important technical problem to address as generative models become more ubiquitous. This has implications for regulation, copyright, and fair compensation to artists [1].\n2. The proposed solution is reasonably motivated and builds on prior work that achieves SOTA attribution results for discriminative models. The work also compares against reasonable baselines for data attribution and shows results across two different datasets namely CIFAR-10 and MS COCO.\n3. The proposed attribution results look reasonable and are quantitatively supported well via counterfactual evaluation.  Evaluation for attribution approaches is difficult since there exists no ground truth label. The counterfactual evaluation metrics proposed in this paper (inspired via TRAK [2] and DataModels [3]) will be useful for future research.\n4. The writing quality of the paper is good. It was easy to follow the main contributions of the paper and understand the background of data attribution.\n\n[1] https://www.klgates.com/Recent-Trends-in-Generative-Artificial-Intelligence-Litigation-in-the-United-States-9-5-2023 \n[2] Park, Sung Min, et al. \"Trak: Attributing model behavior at scale.\"\u00a0_arXiv preprint arXiv:2303.14186_\u00a0(2023).\n[3] Ilyas, Andrew, et al. \"Datamodels: Predicting predictions from training data.\"\u00a0_arXiv preprint arXiv:2202.00622_\u00a0(2022)."
                },
                "weaknesses": {
                    "value": "1. A limitation of the proposed approach is the fact that attribution scores are only provided for a single denoising step. This is unintuitive, as it requires multiple steps to be analyzed to understand how an image was generated. It would be good to obtain a single-shot attribution score for the entire diffusion trajectory. While simple heuristics can be employed to obtain this from the current approach, it's unclear if these are useful and interpretable.\n\n2. There is little analysis regarding how attributions change throughout the diffusion trajectory. It would be interesting to analyze more how ranking b/w attributions stay consistent b/w different timesteps. For example, what's the correlation coefficient b/w attributions of two timesteps close to each other v/s further away? How many of the +ve influence samples in the initial/middle timesteps stay positive throughout the diffusion trajectory?\n\n3. The claim regarding conditioning likelihood increasing in small time intervals is a bit weak (i.e. features appear in specific timesteps). This should be more rigorously studied for multiple generated images on CIFAR-10 and MS-COCO. \n\nMinor - \n1. The font, and margins of this submission violate ICLR guidelines. This should be corrected in the next version of the paper."
                },
                "questions": {
                    "value": "1. This is merely a suggestion and could help strengthen the paper. It would be interesting to compare attributions using a similar framework as [1] by fine-tuning large text-to-image models such as Stable Diffusion on a few images using a dreambooth-like approach. In this case, the attributions should have a higher +ve influence on the fine-tuning dataset. This can be done even for a small random subset of LAION images, instead of the entire dataset.  This can also be done for text-conditioned models on MS-COCO.\n\n2. Several important details are missing regarding the attribution approach. TRAK uses a random projection matrix to compress gradients to low dimensional space, the dimension hasn't been mentioned at all. Is this random projection step not done for attributing diffusion models? Are multiple checkpoints used to estimate attribution scores? Are these trained on different subsets of training data? How much storage and compute is required for estimating the attribution scores? \n\n[1] Wang, Sheng-Yu, et al. \"Evaluating Data Attribution for Text-to-Image Models.\" arXiv preprint arXiv:2306.09345 (2023)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6016/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6016/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6016/Reviewer_KmFt"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6016/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698808644170,
            "cdate": 1698808644170,
            "tmdate": 1699636645687,
            "mdate": 1699636645687,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dUjKT2Mcx9",
                "forum": "XXpH3D0TVP",
                "replyto": "WoI3eplfK2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6016/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6016/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal Response (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful feedback.\n\n### Attributing individual steps rather than the full trajectory\nIndeed, within our framework we attribute at individual steps. In our view, attributing at either individual steps or the full trajectory have complementary benefits, and studying data attribution with respect to full diffusion trajectory is an important direction for future work. In particular, full-trajectory attribution might be more relevant towards matters of copyright violation and data valuation (as it might better assess how much each training image contributes to the final image). However, as we demonstrate in our work, step-specific attributions help us to gain a more fine-grained understanding of the way in which diffusion models use data, and can help to isolate attributions to individual features. For example, in Figure C.3 in Appendix C.2, we highlight cases in which the same image is highly influential at one step but negatively influential at another step. This shows that influences actually evolve over steps, which we could not have identified if we attributed the full diffusion trajectory as a whole.\n\nThat said, we agree that attributing the full trajectory is an interesting and important future direction to extend our current work.\n\n### How attributions change throughout the trajectory\nWe recap some existing analyses in our paper to study how attributions change throughout the trajectory:\n1. We identify a pattern for how attributions relate to the formation of features over steps. Specifically, we find that positive influencers begin to reflect a given feature as soon as the likelihood of a feature being in the final image begins to increase, while negative influencers begin to reflect a given feature when the likelihood of the feature reaches near 100% probability.\n2. In Appendix C.2, as we mentioned above, we study the overlap between top and bottom influencers. In fact, we find that whether a given training image was one of the top most influencers does not correlate to whether it will be a negative influencer as well at another step.\n\nFollowing the reviewer\u2019s suggestion, in Appendix C.2 we have added a plot of the correlation between attribution scores as a function of their proximity (Figure C.5). As expected, we find that the correlation between steps decreases as the distance between steps increases. Interestingly, we find that once attribution scores are computed at around 500 steps apart, their correlation reaches near zero. These findings again highlight the local nature of attributions.\n\n### Likelihood increasing in small time intervals\nTo address the reviewer\u2019s concerns, we have added a new figure, Figure C.11, to Appendix C.5 that includes additional examples of the appearance of features over the steps of the diffusion trajectory. We would also like to point the reviewer to Figure C.2 in Appendix C.4. Here, we visualize the emergence of features in a sample generated by Stable Diffusion, and find that in this setting features appear often in a short interval of steps.\n\nAdditionally, we would like to highlight that neither our method nor our evaluation strategy depend on this empirical phenomenon. We instead consider this finding as an avenue to bridge features of the synthesized images with intervals of the diffusion process, thus providing a more intuitive explanation of our attributions.\n\n### Adhering to margin and font\nWe thank the reviewer for pointing out the incorrect margins and font size in our submission. This was an unintentional accident that happened due to a git merge, and we fixed the revised version to adhere to the ICLR guidelines. The margins we used were wider than the ICLR guidelines, however it turns out our font was also wider. After fixing both the font and margins, we found that there was very little difference in the resulting paper length (about one paragraph). We apologize for this error.\n\n### Fine-tuning text-to-image models\nWe thank the reviewer for the interesting suggestion. We agree that it would be valuable to compare our method to the data attribution framework in [1], which identifies \u201cground truth\u201d attributions by fine-tuning a text-to-image model on a given training image, guaranteeing that it is highly influential. Since the provided code for this work focused on attributions for Stable Diffusion, to compare to this method we would need to either adapt it to MS COCO models, as suggested, or implement our approach for subsets of LAION. Both of these tasks were not feasible during the rebuttal period, but we will consider implementing this comparison for the camera-ready version of the paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6016/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700170306158,
                "cdate": 1700170306158,
                "tmdate": 1700170306158,
                "mdate": 1700170306158,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "p8WQshVRZx",
            "forum": "XXpH3D0TVP",
            "replyto": "XXpH3D0TVP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6016/Reviewer_Kccm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6016/Reviewer_Kccm"
            ],
            "content": {
                "summary": {
                    "value": "This work attempts to explain the effect of training data points and their features on the synthesized images in a diffusion model. They suggest a framework to first define the notion of attribution for diffusion models and then study the validity of the attributions. The method is tested on two dataset along side two diffusion models (DDPM and LDM)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The choice of problem is a point of strength in this work. To understand the role of the training data in the final sampling result sheds light on the nature of the learned distribution and its properties. Also this question is tightly related to memorization and interpolation of training data which has practical implications such as data privacy."
                },
                "weaknesses": {
                    "value": "The clarity of the writing can be significantly improved. The flow can be more streighforward. At its current form, the paper is too wordy to the extent that the main points are not clearly conveyed. \n\nRelying on a classifier to find emergence of features that are important throughout the diffusion trajectory is problematic. The sharp increase in classification performance under Fig3 might be due to this particular classifier and dataset. For example, for a more nuanced dataset with images with more details, and more categories, the improvement in classification could become more gradual, due to the gradual appearance of large to fine features. \n\nThe results presented under figure 5 although show a significant effect on FID, it is not obvious what the effect shows and how it can be used. What is the relationship between the top k important training examples which are removed and the learned distribution or synthesis? How do we ensure that the increase in FID is not simply the effect of training on a smaller dataset? \n\nIn general, it is not clear to me what we learn from this result. The attribution qualitative results under fig 6 seem to me anecdotal. The results in Fig 7 are too low quality, so it is not easy to judge the effectiveness of the method."
                },
                "questions": {
                    "value": "In order to reduce the cost of generating a distribution of generated conditional samples from $p(.|x_t)$, the conditional sampling is approximated with a one step denoising. We know that if the noise level is high (for larger values of t) the difference between iterative and single step denoising is significant. How is this approximation justified for the large sigma?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6016/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698826808302,
            "cdate": 1698826808302,
            "tmdate": 1699636645577,
            "mdate": 1699636645577,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KUPwzN7HXL",
                "forum": "XXpH3D0TVP",
                "replyto": "p8WQshVRZx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6016/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6016/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal Response (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the helpful feedback.\n\n### Clarity of the submission\nTo address the reviewer\u2019s concerns over the clarity of the presentation, we have made a number of changes to the structure of the main text:\n- \u201cThe flow can be more straightforward\u201d: We made revisions to Section 3 (which introduces our attribution framework) to simplify the language and make the presentation more modular. Additionally, we added an in-depth section on TRAK to the background section in order to better contextualize our method.\n- \u201cthe paper is too wordy\u201d: we shortened Section 4 (which describes our method) and made more explicit connections to the preliminaries in Section 2. \n\n\n### Use of Classifiers to Identify Features\nIn our view, using a classifier is the only reasonable (and scalable) approach to identifying the emergence of features, as any other approach would likely involve manually inspecting images for their presence. However, the reviewer raises a valid concern about the robustness of our approach.\n\nTo address the reviewer\u2019s concerns, we have added an additional figure, Figure C.11, to Appendix C.5. In this figure, we visualize the emergence of a feature in the diffusion trajectory for three generated samples from the CIFAR-10 dataset using three different classifiers (ResNet trained on CIFAR-10, adversarially robust ResNet trained on CIFAR-10, and CLIP zero-shot initialized with the CIFAR-10 class names). We find that in each case, the outputs of all three classifiers are aligned.\n\nAdditionally, we would like to point the reviewer to Figure C.2 in Appendix C.4. Here, we visualize the emergence of features in a sample generated by Stable Diffusion which has images with more details, and find that features still appear often in a short interval of steps.\n\nThat said, we would like to highlight that neither our method nor our evaluation strategy depends on this empirical phenomenon. We instead consider this finding as a way to relate features of the synthesized images to specific steps of the diffusion process, thus providing a more intuitive interpretation of our per-step attributions.\n\n\n### Interpretation of FID evaluation\nWhat the results of Figure 5 illustrate is that (as intended) the top-k most important training examples at step $t$ (as identified with our method) have a significant impact on the conditional distribution $p\\_\\theta(\\cdot|x\\_t)$ of generated images.\nIntuitively, we expect that the top-k (positively influential) images will share features with the original conditional distribution, but less so with the new conditional distribution (resulting after removing those top-k images).\n\nThe increase in FID is not simply the effect of training on a smaller dataset, as we compare our method to the baseline of removing the top k training images according to either CLIP and pixel similarity. In this case, the model is indeed trained on a smaller dataset (with the same number of examples removed), yet the increase in FID is significantly less than the increase resulting from using our attribution scores. \n\n\n### Evaluations of our Method\n\nWe are not sure what aspects of Figure 7 the reviewer is referring to as low quality. In this figure, we show that even though our attribution scores are targeted at a specific timestep, we are still able to leverage them to attribute the full diffusion process, and do so much better than popular baselines of using image similarity for data attribution.\n\nOur patch-based attributions results (Figure 6) are only intended to convey qualitative results. In particular, this subsection of the experiments is intended to showcase a natural extension of our method, rather than a comprehensive evaluation of our framework.  \n\nImportantly, we do not present these results (Figures 6, 7) as the primary evaluation in our work. Our main evaluation is presented In Section 5.2, where we report quantitative results for two metrics for evaluating attribution methods: linear datamodeling score (LDS) and distributional changes (as measured by FID) after removing top influencers. In both cases, our attributions significantly outperform the similarity baselines. Overall, our method is able to identify training examples most important to the generation of a given image, and moreover, precisely quantify the counterfactual impact of those training examples. We believe that these results sufficiently convey the efficacy of our approach."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6016/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700170164440,
                "cdate": 1700170164440,
                "tmdate": 1700170164440,
                "mdate": 1700170164440,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0oWCHyZSfl",
                "forum": "XXpH3D0TVP",
                "replyto": "YQD7M5tbdP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6016/Reviewer_Kccm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6016/Reviewer_Kccm"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response to my comments. \n\nI'm still not sure about the message of the paper. What is it that we are learning from applying your attribution framework on diffusion models? As I re-read the paper, I'm still trying to find the punchline. What is it that your method reveals about the data distribution or the synthesis trajectory? Can you state that message in one paragraph, e.g. in the abstract? \n\nThere is the obvious observation that the features emerge in a coarse to fine manner in the trajectory. This effect has been known since the invention of diffusion models. One shot denoising solution is the posterior mean which results in the coarse to fine generation (due to constant spectrum of white noise, vs. $1/freq$ spectrum of natural images). Obviously, with larger noise, the posterior mean is taken over larger sets of clean images, which results in more ambiguous solutions (related to results in figures 1,2,3). So it is not clear what we learn about diffusion models by applying a classifier to such solutions. Similarly, it's not clear what the results in figures 5,6, and 7 elucidate, beyond the general and obvious observation that removing images of a particular type hurt the learning of the prior over images. \n\nOverall, I think this method can be useful to understand diffusion models and priors with more work, but the results need to be improved. Currently, it seems to me that they are too preliminary and it's not clear what conclusion we can draw from them."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6016/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700509593444,
                "cdate": 1700509593444,
                "tmdate": 1700509593444,
                "mdate": 1700509593444,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]