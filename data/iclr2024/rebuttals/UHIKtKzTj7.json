[
    {
        "title": "PAPM: A Physics-aware Proxy Model for Process Systems"
    },
    {
        "review": {
            "id": "ALSh6fVNl3",
            "forum": "UHIKtKzTj7",
            "replyto": "UHIKtKzTj7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2688/Reviewer_9hXa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2688/Reviewer_9hXa"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces PAPM, a spatio-temporal model to capture complex dynamics which arguably follow similar patters, i.e., a mixture of diffusion and/or convection flows, internal and external source terms. The PAPM architecture encodes the state of the system, and depending on the problem at hand applies either localized, spectral, or hybrid operators to parameterize the different operators. Subsequently, time-stepping schemes are applied to mimic temporal updates. PAPM is tested on 4 known 2D fluid mechanics benchmarks systems."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Introducing parameterized operators is a very interesting contribution."
                },
                "weaknesses": {
                    "value": "- The presentation is slightly hard to follow, it is not clear to me how exactly all these operators are parameterized and how such models can be scaled up. Is there only one operator block used or can these modules be stacked? Pseudocode / real code would definitely help.\n- The models are evaluated on a fixed grid with fixed resolution. For such systems standard models such as modern U-Nets and / or convolutional based neural operators should be used for comparison (Raonic et al, Gupta et al), or even Vision Transformers. An alternative is to showcase resolution independency to justify the comparisons. \n- I am pretty puzzled by the low number of parameters. It seems that hardly any model uses more than 1 million parameters. This is in my opinion a heavy under-parameterization for 2D problems. Compare for example Fig 1 in Gupta et al?\n- The paper makes a strong claim for better physics modeling, i.e., strong physics bias, yet there is no evidence that with low number of samples the performance is better compared to baseline models.\n- Figure 6 is not comparing to the best baseline model but FNO which has 10 times worse performance than Dilated ResNets on the RD2d task.\n- It is impossible to judge how the individual components contribute to the results - ablation would help.\n\n\nRaoni\u0107, B., Molinaro, R., Rohner, T., Mishra, S., & de Bezenac, E. (2023). Convolutional Neural Operators. arXiv preprint arXiv:2302.01178.\n\nGupta, Jayesh K., and Johannes Brandstetter. \"Towards multi-spatiotemporal-scale generalized pde modeling.\" arXiv preprint arXiv:2209.15616 (2022)."
                },
                "questions": {
                    "value": "- How can PAPM be extended to variable grid sizes, or to non regular grids?\n- How can PAPM be scaled up to larger number of parameters?\n- Would it be possible to resort to the standard terminology of \"operator learning\" which is now standard in the community?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2688/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698764898254,
            "cdate": 1698764898254,
            "tmdate": 1699636210105,
            "mdate": 1699636210105,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VjecWSsmeo",
                "forum": "UHIKtKzTj7",
                "replyto": "ALSh6fVNl3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9hXa (1)"
                    },
                    "comment": {
                        "value": "Thank you for your valuable feedback, which has been instrumental in refining our paper. We have carefully considered your suggestions and have made corresponding adjustments to enhance the clarity and depth of our work.\n\n## 1. Clearer Model Presentation\n- 1.1 **Motivation**\n    - We appreciate your interest in our model's motivation. In the field of physics-informed machine learning (PIML), our approach follows the trend of integrating physical knowledge into the model structure. This approach, seen in recent works like PDE-Net [1], FINN [2], PPNN [3], PiNDiff [4] and PeRCNN [5], allows us to embed prior physics dynamics, such as PDEs, to guide our model's structural design and enhance inductive biases. This integration not only boosts the model\u2019s ability to understand dynamic mechanisms for better nonlinear approximation but also significantly trims the number of required parameters. Consequently, we achieve enhanced accuracy and generalization, even with limited data. For instance, PeRCNN, with less than 1k parameters, effectively models diffusion equations.\n    - In contrast, data-driven operator learning models, such as FNO [6], MIONet [7], U-FNet [8] and CNO [9], that rely on increasing the number of parameters can improve nonlinear approximation. But it tends to overfit with limited data, reducing generalization. For example, as demonstrated in **Fig. 5** of our paper, FNO performs well on test sets matching the training data's step size, but its efficacy declines sharply with time extrapolation. Therefore, incorporating more prior physics into the model's structural design emerges as a superior strategy. However, it's important to note that the mechanism information we integrate is incomplete, which precludes the use of loss function embedding in this context.\n\n- 1.2 **Model Design**\n    - Our paper follows this line (**integrating physical knowledge into the model structure**), focusing on operator learning tasks under process model. We have detailed the structured network design (see **Fig.2**) and spatio-temporal stepping method (see **Fig.3**) to provide a comprehensive view. The inclusion of pseudocode (see **Appendix A.4**) and the **source code** (see **supplementary material**) is intended to facilitate better understanding.\n\n## 2. More Comprehensive Experiments\n\n- 2.1 Comparison with Existing Methods\n    - In the revised version, we introduced two new baseline models: U-FNets [1] and Convolutional Neural Operators (CNO) [2], as demonstrated in **Table 1**(below). These additions enrich our comparative analysis, allowing us to explore PAPM's performance in relation to baseline models in terms of accuracy, parameter count, computational speed, and data efficiency in **Table 2**(below). PAPM exhibits the most balanced trade-off between parameter count and performance among all methods evaluated, from explicit structures (Burgers2d, RD2d) to implicit (NS2d) and more complex hybrid structures (Lid2d, NSM2d). Notably, even though PAPM utilizes only 1\\% of the parameters employed by the prior leading method, PPNN, it still outperforms it by a large margin. In a nutshell, our model enhances the performance by an average of 6.4\\% over nine tasks, which affirms PAPM as a versatile and efficient framework suitable for diverse process systems. For the details of the above five datasets, please refer to **Tab. 2,3** and **Fig. 4,5,6** in the revised paper.\n- 2.2 Adaptive resolution experiments\n    -  We have also included adaptive resolution experiments across different resolutions on three datasets, highlighting PAPM's adaptive resolution capabilities. Incorporating physics-based knowledge into our models is crucial for achieving resolution independence. In **Appendix A.7.3**, we delve into the adaptive resolution capabilities of PAPM and our baseline models. We also discuss potential enhancements (see **Table 3 PAPM**, below) based on the concept of operator learning, like expanding the channel domain through lift and project functions to improve model adaptability. As demonstrated in Tab.1, The burgers2d dataset is used as an example to show the results of different baselines and PAPM under four resolutions (scale = $0.5$, $1$, $2$, $4$, The corresponding resolution is $[32, 64, 128,  256]$). The results highlight that modifications to the PAPM structure have notably enhanced its adaptive resolution capabilities across different resolutions, confirming the effectiveness of this architecture. PAPM demonstrates robust performance in various scaling scenarios,  indicating its resilience to resolution changes. Compared to other physical-aware methods, PAPM exhibits superior adaptive resolution ability. Moreover, the results of purely data-driven approaches,  which lack this adaptive resolution capability, underscore the importance of integrating physics priors for enhanced adaptability to varying resolutions. For more details, please refer to **Appendix A.7.3**."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408405154,
                "cdate": 1700408405154,
                "tmdate": 1700408405154,
                "mdate": 1700408405154,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zbjD4LAj0y",
                "forum": "UHIKtKzTj7",
                "replyto": "ALSh6fVNl3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9hXa (3)"
                    },
                    "comment": {
                        "value": "## 3. Analysis on Data Efficiency\n- To evaluate data efficiency, we conducted tests using RD2d dataset (see [12], this dataset can be downloaded at https://github.com/pdebench/PDEBench) as a representative example, with Dil-Resnet and PPNN symbolizing pure data-driven and physics-aware methods (see **Table 4** below). The results, displayed in **Fig.6**, depict PAPM's efficiency concerning data volume and label data step size in training. \n    - 3.1 **Amount of Data**: With a fixed 20% reserved for the test set, the remaining 80% of the total data is allocated to the training set. We systematically varied the training data volume, ranging from initially utilizing only 5% of the training set and progressively increasing it to the entire 100%. PAPM's relative error distinctly outperforms other baselines, **especially with limited data (5%)**. As depicted in **Fig.5(Left)**, PAPM's error consistently surpasses other methods, stabilizing below 2% as the training data volume increases. \n    - 3.2 **Time Step Size**: We varied the data step size from $1/10$ to half of the total, increasing in tenths. Results of  **Fig.5(Right)** reveal that PAPM can achieve long-range time extrapolation with minimal dynamic steps, consistently outshining other methods even with shorter training data step sizes. \n\n**Table 4: Main results $\\epsilon$ in RD2d dataset with time extrapolation task.**\n\n| **Config**      | **RD2d** | \n|-----------------|----------------:|\n| ConvLSTM [10]   |           0.815 |\n| Dil-ResNet [11] |           0.021 |  \n| time-FNO2D [6]  |           0.333 |         \n| MIONet [7]      |           0.247 |             \n| *U-FNet* [8]    |         *0.239* |         \n| *CNO* [9]       |        *0.112*  |             \n| PeRCNN [5]      |           0.212 |                 \n| PPNN [3]        |           0.030 |            \n| **PAPM (Our)**  |       **0.018** |        \n\n## 4. Ablation Study\n- **Setting.** We selected the Burger2d dataset due to its representation of diffusion, convection, and force terms. Several configurations are defined to determine the effects of individual components. **no_DF** excludes diffusion, while **no_CF** omits convection. **no_Phy** retains only a structure with a residual connection, eliminating both diffusion and convection. The **no_BCs** setup removes explicit BCs embedding, **no_All** is purely data-driven, and **no_Iter** bypasses the Iterative Refinement Rounds training strategy.\n- **Results.**  As demonstrated in **Table 5** (below), key findings include recognizing the crucial roles of diffusion and convection in dictating system dynamics. This was evident when the no_DF configuration showed that integrating the viscosity coefficient with the diffusion term was vital. Its absence led to significant errors, most notably in parameter extrapolation tasks. The necessity of boundary adherence to physical laws became clear with the no_BCs approach, as it notably reduced BC's relative errors. Lastly, the no_Iter setup accentuated the importance of the causal training strategy in the model's training process.\n\n**Table 5: Comparison of the main result ($\\epsilon$) and the number of trainable parameters ($N_P$) on Burgers2d.**\n\n| **Config**  | **\\$N_P\\$** | **C Int. \\$\\epsilon\\$** | **C Int. BC \\$\\epsilon\\$** | **C Ext. \\$\\epsilon\\$** | **C Ext. BC \\$\\epsilon\\$** |\n| ----------- | ----------- | ----------------------- | -------------------------- | ----------------------- | -------------------------- |\n| no_DF       | 13.90k      | 0.067                   | 0.051                      | 0.207                   | 0.067                      |\n| no_CF       | 13.93k      | 0.062                   | 0.043                      | 0.131                   | 0.054                      |\n| no_Phy      | 13.84k      | 0.149                   | 0.051                      | 0.210                   | 0.144                      |\n| no_BCs      | 13.99k      | 0.068                   | 0.097                      | 0.136                   | 0.193                      |\n| no_All      | 13.84k      | 0.162                   | 0.195                      | 0.216                   | 0.250                      |\n| no_Iter     | 13.99k      | 0.080                   | 0.039                      | 0.141                   | 0.048                      |\n| **PAPM**    | **13.99k**  | **0.039**               | **0.037**                  | **0.101**               | **0.043**                  |"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408525451,
                "cdate": 1700408525451,
                "tmdate": 1700409927197,
                "mdate": 1700409927197,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Tuj8BEKD0c",
                "forum": "UHIKtKzTj7",
                "replyto": "ALSh6fVNl3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9hXa (4)"
                    },
                    "comment": {
                        "value": "## 5. More complex Applications:\n- **Q**: How can PAPM be extended to variable grid sizes, or to non regular grids?\n- **A**: PAPM be extended to variable grid sizes can see in **Adaptive resolution experiments** (see **2.2** above). And to non regular grids as follows:\n    - **a**. Using bilinear interpolation to convert non-uniform grids to standard grids, minimizing errors especially in dense grid scenarios.\n    - **b**. Employing a lift mapping function, similar to the geo-FNO [13] strategy, to transform non-uniform meshes into uniform ones.\n\n    In our case study of a low-temperature argon plasma discharge (see **Fig. 9**), we chose the first approach due to the high density of the simulation grid, allowing for effective direct interpolation before training the PAPM model. We explore a more complex example of low-temperature argon plasma discharge, which presents a challenging scenario with non-regular grids and complex mechanisms. The mechanism equation of this process is far more complex than Eq. 1 and 2, involving the coupling of multiple physical fields such as the electric field, temperature field, and pressure field. It does not strictly adhere to the definition in Eq. 1. Still, for the physical quantities to be modeled, their overall pattern follows the primary setting in which convection, diffusion, and source terms act together. Therefore, we can still construct a proxy model for plasma through PAPM. As demonstrated in **Table 6**(below), our method surpasses others in accuracy, generalization, and efficiency. For A more detailed introduction, please refer to **Appendix A.8**. We will use this example to show the generalization ability of PAPM further.\n\n**Table 6: Main results ($\\epsilon$), FLOPs, training and inference time cost (iteration/second), and the number of trainable parameters ($N_P$) on Plasma2d.**\n| **Config**    | **\\$\\epsilon\\$** | **FLOPs**  | **Train** | **Test** | **$N_p$**   |\n| ------------- | ---------------- | ---------- | --------- | -------- | ------------- |\n| convLSTM [10]      | 0.750            | 2.05G      | 5.05      | 0.43     | 0.080M        |\n| Dil-ResNet [11]    | 0.316            | 3.90G      | 7.61      | 0.59     | 0.152M        |\n| timeFNO2d [6]     | 0.286            | 0.11G      | **2.37**      | **0.31**     | 0.465M        |\n| U-FNet [8]        | 0.718            | 5.22G      | 9.38      | 1.49     | 10.091M       |\n| CNO [9]           | 0.407            | 3.50G      | 8.46      | 0.92     | 2.674M        |\n| PPNN [3]          | 0.228            | 3.01G      | 4.60      | 0.63     | 1.300M        |\n| **PAPM**      | **0.178**            | **0.07G**      | 4.66      | 0.47     | **0.032M**   |\n\n## 6. Additional Experiments on Scaling Up Parameters\n- **Q**: How can PAPM be scaled up to larger number of parameters?\n- **A**: In terms of scaling up the number of parameters, we have experimented with different configurations, particularly in the source term. For example, in the plasma experiment, we expanded the parameter quantity of PAPM, considering varying hidden channel numbers (hidden\\_channel = $[16, 32, 64]$,), which significantly increased the parameter count (parameters from 3w to 20w), as demonstrated in **Table 7** (below). However, the improvements in model performance were relatively modest when weighed against the substantial increase in computational resources incurred. This discrepancy might be attributed to the limitations posed by the size of the dataset.\n\n**Table 7: Main results ($\\epsilon$), FLOPs, training and inference time cost (iteration/second), and the number of trainable parameters (\\$N_P\\$) on Plasma2d.**\n\n| **Config**    | **$\\epsilon$** | **FLOPs**  | **Train** | **Test** | **$N_p$**   |\n| ------------- | ---------------- | ---------- | --------- | -------- | ------------- |\n| convLSTM [10]    | 0.750            | 2.05G      | 5.05      | 0.43     | 0.080M        |\n| Dil-ResNet [11]   | 0.316            | 3.90G      | 7.61      | 0.59     | 0.152M        |\n| timeFNO2d [6]    | 0.286            | 0.11G      | **2.37**      | **0.31**     | 0.465M        |\n| U-FNet [8]       | 0.718            | 5.22G      | 9.38      | 1.49     | 10.091M       |\n| CNO [9]          | 0.407            | 3.50G      | 8.46      | 0.92     | 2.674M        |\n| PPNN [3]         | 0.228            | 3.01G      | 4.60      | 0.63     | 1.300M        |\n| **PAPM-16**   | 0.178            | **0.07G**      | 4.66      | 0.47     | **0.032M**        |\n| **PAPM-32**   | 0.176            | 2.05G      | 6.94      | 0.60     | 0.082M        |\n| **PAPM-64**   | **0.171**            | 6.41G      | 9.94      | 0.79     | 0.245M        |"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408579248,
                "cdate": 1700408579248,
                "tmdate": 1700445159684,
                "mdate": 1700445159684,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WoJrWtXw0x",
                "forum": "UHIKtKzTj7",
                "replyto": "ALSh6fVNl3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9hXa (5)"
                    },
                    "comment": {
                        "value": "## 7. Terminology Choice\n- **Q**: Would it be possible to resort to the standard terminology of \"operator learning\" which is now standard in the community?\n- **A**: Regarding the terminology, we have opted for 'physical-aware proxy model' and 'spatiotemporal stepping method' to align more closely with our research approach. This choice reflects our focus on embedding physical knowledge into the model structure.\n\nWe hope these responses adequately address your concerns and demonstrate our commitment to advancing research in the PIML field. We are grateful for your constructive feedback and remain open to further discussions.\n\n## **Reference**\n- [1] Long Z, Lu Y, Ma X, et al. Pde-net: Learning pdes from data[C]//International conference on machine learning. PMLR, 2018: 3208-3216.\n- [2] Karlbauer M, Praditia T, Otte S, et al. Composing partial differential equations with physics-aware neural networks[C]//International Conference on Machine Learning. PMLR, 2022: 10773-10801.\n- [3] Liu X Y, Sun H, Zhu M, et al. Predicting parametric spatiotemporal dynamics by multi-resolution PDE structure-preserved deep learning[J]. arXiv preprint arXiv:2205.03990, 2022.\n- [4] Akhare D, Luo T, Wang J X. Physics-integrated neural differentiable (PiNDiff) model for composites manufacturing[J]. Computer Methods in Applied Mechanics and Engineering, 2023, 406: 115902.\n- [5] Rao C, Ren P, Wang Q, et al. Encoding physics to learn reaction\u2013diffusion processes[J]. Nature Machine Intelligence, 2023, 5(7): 765-779.\n- [6] Li Z, Kovachki N B, Azizzadenesheli K, et al. Fourier Neural Operator for Parametric Partial Differential Equations[C]//International Conference on Learning Representations. 2020.\n- [7] Jin P, Meng S, Lu L. MIONet: Learning multiple-input operators via tensor product[J]. SIAM Journal on Scientific Computing, 2022, 44(6): A3490-A3514.\n- [8] Gupta J K, Brandstetter J. Towards multi-spatiotemporal-scale generalized pde modeling[J]. arXiv preprint arXiv:2209.15616, 2022.\n- [9] Raoni\u0107 B, Molinaro R, Rohner T, et al. Convolutional Neural Operators[J]. arXiv preprint arXiv:2302.01178, 2023.\n- [10] Shi X, Chen Z, Wang H, et al. Convolutional LSTM network: A machine learning approach for precipitation nowcasting[J]. Advances in neural information processing systems, 2015, 28.\n- [11] Stachenfeld K, Fielding D B, Kochkov D, et al. Learned coarse models for efficient turbulence simulation[J]. arXiv preprint arXiv:2112.15275, 2021.\n- [12] Takamoto M, Praditia T, Leiteritz R, et al. PDEBench: An extensive benchmark for scientific machine learning[J]. Advances in Neural Information Processing Systems, 2022, 35: 1596-1611.\n- [13] Li Z, Huang D Z, Liu B, et al. Fourier neural operator with learned deformations for pdes on general geometries[J]. arXiv preprint arXiv:2207.05209, 2022."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408607118,
                "cdate": 1700408607118,
                "tmdate": 1700445177496,
                "mdate": 1700445177496,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aP1Tb0pyr0",
                "forum": "UHIKtKzTj7",
                "replyto": "WoJrWtXw0x",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Reviewer_9hXa"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewer_9hXa"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal"
                    },
                    "comment": {
                        "value": "Dear authors,\nthanks to the authors for the rebuttal.\n\nHowever, I got the impression that most of the answers are quite generic and repetitive amongst reviewers. My most important concern, i.e., that baseline models were used with unusual low number of parameters, was unfortunately ignored in the rebuttal. Since I did not get any response on this issue, I am keeping my score."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700585064663,
                "cdate": 1700585064663,
                "tmdate": 1700585064663,
                "mdate": 1700585064663,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RrpVMitzjf",
            "forum": "UHIKtKzTj7",
            "replyto": "UHIKtKzTj7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2688/Reviewer_uLfn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2688/Reviewer_uLfn"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel method, the Physics-Aware Proxy Model (PAPM), aimed at improving the efficiency and accuracy of process systems modeling. PAPM incorporates a portion of prior physical knowledge (including conservation and constitutive relations) into the model and introduces a new Temporal and Spatial Stepping Method (TSSM), which is claimed to enhance the model's applicability and predictive ability. The authors conduct several tests, indicating that PAPM seemingly outperforms existing data-driven and physics-aware models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper addresses a critical issue in the field of process systems modeling, proposing an innovative solution that combines partial prior mechanistic knowledge with a holistic temporal and spatial stepping method.\n2. The PAPM model shows impressive results in terms of both improved performance and reduced computational costs compared to existing methods.\n3. The paper is well-structured and the methodology is clearly explained, with extensive validation."
                },
                "weaknesses": {
                    "value": "1. The paper could dive further into limitations of the method.\n2. The paper could benefit from a more detailed comparison with existing methods. While the authors compare their method to state-of-the-art models, it would be helpful to see a more detailed analysis of why their method outperforms these existing approaches."
                },
                "questions": {
                    "value": "- How well would the PAPM model perform on process systems with less well-understood or more complex physical principles?\n- Could the proposed model be applied to other types of systems beyond process systems?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2688/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828596468,
            "cdate": 1698828596468,
            "tmdate": 1699636210013,
            "mdate": 1699636210013,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2EvxkRZ1Zd",
                "forum": "UHIKtKzTj7",
                "replyto": "RrpVMitzjf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uLfn (1)"
                    },
                    "comment": {
                        "value": "## 1. Method Limitations\n- **Q**: The paper could dive further into limitations of the method.\n- **A**: Thank you for pointing out the importance of discussing the limitations and potential scalability of PAPM. Our approach centers around two primary considerations. \n    - Firstly, we aim to extend our model to more realistic process systems, particularly those used in industrial simulations. While our current validation has been on standard 2D spatio-temporal dynamic systems with well-defined process model mechanisms, PAPM has demonstrated a superior balance in accuracy, operational efficiency, and generalization capabilities. A notable example is our application of PAPM to plasma, a complex case involving multi-physics field coupling. The results from this plasma experiment exemplify PAPM's strengths in handling more intricate process systems. Moving forward, we plan to explore PAPM's architecture in multi-physics field coupling scenarios, such as fluid-structure and thermal fluid-structure coupling problems.\n    - The second consideration is the potential scalability of PAPM concepts to a larger model framework. Since most dynamic systems adhere to three primary aspects \u2013 convection (with advection being a specific case), diffusion, and source terms \u2013 we are keen to integrate this structured design into developing larger-scale models. We aim to construct a foundational model for process systems that can efficiently and accurately model various processes with a unified approach.\n\n## 2. Comparison with Existing Methods:\n- **Q**: The paper could benefit from a more detailed comparison with existing methods. While the authors compare their method to state-of-the-art models, it would be helpful to see a more detailed analysis of why their method outperforms these existing approaches.\n- **A**: To further demonstrate PAPM's effectiveness, we have expanded our experiments. \n    - 1) In the revised version, we introduced two new baseline models: U-FNets [1] and Convolutional Neural Operators (CNO) [2], as demonstrated in **Table 1**(below). These additions enrich our comparative analysis, allowing us to explore PAPM's performance in relation to baseline models in terms of accuracy, parameter count, computational speed, and data efficiency in **Table 2**(below). PAPM exhibits the most balanced trade-off between parameter count and performance among all methods evaluated, from explicit structures (Burgers2d, RD2d) to implicit (NS2d) and more complex hybrid structures (Lid2d, NSM2d). Notably, even though PAPM utilizes only 1% of the parameters employed by the prior leading method, PPNN, it still outperforms it by a large margin. In a nutshell, our model enhances the performance by an average of 6.4% over nine tasks, which affirms PAPM as a versatile and efficient framework suitable for diverse process systems. For the details of the above five datasets, please refer to **Tab. 2,3** and **Fig. 4,5,6** in the revised paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408019370,
                "cdate": 1700408019370,
                "tmdate": 1700408019370,
                "mdate": 1700408019370,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "do1mEGfA8n",
                "forum": "UHIKtKzTj7",
                "replyto": "RrpVMitzjf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uLfn (3)"
                    },
                    "comment": {
                        "value": "## 2. Comparison with Existing Methods:\n- **Q**: The paper could benefit from a more detailed comparison with existing methods. While the authors compare their method to state-of-the-art models, it would be helpful to see a more detailed analysis of why their method outperforms these existing approaches.\n- **A**: To further demonstrate PAPM's effectiveness, we have expanded our experiments. \n\n- 2) We have also included adaptive resolution experiments across different resolutions on three datasets, highlighting PAPM's adaptive resolution capabilities. Incorporating physics-based knowledge into our models is crucial for achieving resolution independence. In **Appendix A.7.3**, we delve into the adaptive resolution capabilities of PAPM and our baseline models. We also discuss potential enhancements (see **Table 3 PAPM**, below) based on the concept of operator learning, like expanding the channel domain through lift and project functions to improve model adaptability. As demonstrated in Tab.1, The burgers2d dataset is used as an example to show the results of different baselines and PAPM under four resolutions (scale = $0.5$, $1$, $2$, $4$, The corresponding resolution is $[32, 64, 128,  256]$). The results highlight that modifications to the PAPM structure have notably enhanced its adaptive resolution capabilities across different resolutions, confirming the effectiveness of this architecture. PAPM demonstrates robust performance in various scaling scenarios,  indicating its resilience to resolution changes. Compared to other physical-aware methods, PAPM exhibits superior adaptive resolution ability. Moreover, the results of purely data-driven approaches,  which lack this adaptive resolution capability, underscore the importance of integrating physics priors for enhanced adaptability to varying resolutions. For more details, please refer to **Appendix A.7.3**.\n\n## 3. More complex Applications:\n- **Q**: How well would the PAPM model perform on process systems with less well-understood or more complex physical principles?\n- **A**: We explore a more complex example of low-temperature argon plasma discharge, which presents a challenging scenario with non-regular grids and complex mechanisms. We consider a more complex process system, low-temperature argon plasma discharge, as depicted in the revised paper's **Fig. 9**. The mechanism equation of this process is far more complex than Eq. 1 and 2, involving the coupling of multiple physical fields such as the electric field, temperature field, and pressure field. It does not strictly adhere to the definition in Eq. 1. Still, for the physical quantities to be modeled, their overall pattern follows the primary setting in which convection, diffusion, and source terms act together. Therefore, we can still construct a proxy model for plasma through PAPM. At the same time, the simulation grid is with non-regular grids. As demonstrated in **Table 4**(below), our method surpasses others in accuracy, generalization, and efficiency. For A more detailed introduction, please refer to **Appendix A.8**. We will use this example to show the generalization ability of PAPM further. Since this work is still in progress, we only show partial results and will show more experimental results later.\n\n**Table 4: Main results ($\\epsilon$), FLOPs, training and inference time cost (iteration/second), and the number of trainable parameters ($N_P$) on Plasma2d.**\n| **Config**    | **\\$\\epsilon\\$** | **FLOPs**  | **Train** | **Test** | **$N_p$**   |\n| ------------- | ---------------- | ---------- | --------- | -------- | ------------- |\n| convLSTM [3]      | 0.750            | 2.05G      | 5.05      | 0.43     | 0.080M        |\n| Dil-ResNet [4]    | 0.316            | 3.90G      | 7.61      | 0.59     | 0.152M        |\n| timeFNO2d [5]     | 0.286            | 0.11G      | 2.37      | 0.31     | 0.465M        |\n| U-FNet [1]        | 0.718            | 5.22G      | 9.38      | 1.49     | 10.091M       |\n| CNO [2]           | 0.407            | 3.50G      | 8.46      | 0.92     | 2.674M        |\n| PPNN [8]          | 0.228            | 3.01G      | 4.60      | 0.63     | 1.300M        |\n| **PAPM**      | 0.178            | 0.07G      | 4.66      | 0.47     | 0.032M        |"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408174622,
                "cdate": 1700408174622,
                "tmdate": 1700445079203,
                "mdate": 1700445079203,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OIdrvJvmSJ",
            "forum": "UHIKtKzTj7",
            "replyto": "UHIKtKzTj7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2688/Reviewer_hyse"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2688/Reviewer_hyse"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a way to leverage process systems, which is a key model that can be used to emulate a number of physics models. The authors claim that process models are in general complex and difficult to understand and can also lead to incorrect results. In this paper they propose PAPM (physics-aware proxy model) which has the claimed benefit of including physics priors to accomplish better performance on prediction tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Paper is mostly well written\n2. Experiments are clear"
                },
                "weaknesses": {
                    "value": "1. While I appreciate the intuitive explanations, process systems are not defined adequately, and this really impedes assessment of the paper. The terms describing this main concept are vague (abstract, introduction and in section 3), and qualitative. Nevertheless, I hope authors can clarify this in the discussion phase (see questions).\n2. It is unclear what is required in training vs. at inference\n3. The experiments seem to be run for one setting (no monte-carlo simulations)\n4. The experiments only consider classical, highly-structured pdes, it is unclear how the proposed model can be used for real-world settings where the dynamics are unknown and may not follow the underlying assumption of (eq.1)"
                },
                "questions": {
                    "value": "### Understanding Process Models: \n\nWhile the contributions seem important it is difficult to understand what process models are. Following are questions which can help authors identify what the reviewer is struggling with, hopefully to help update the paper for a wider audience.\n1. Why are the dynamics/equations of the process model unknown? Isn't it defined by the practitioners?\n2. In relation to 1, it seems that authors consider dynamics which take the form of eq.1, while the exact values that these quantities take are unknown? Is this true? \n3. How are process models different from the proposed model in relation to eq1 and Fig. 3?\n\n### Understanding PAPM:\n4. \\lambda is defined as \"coefficients\" in sec 4.1, but it is unclear how they related to eq 1.\n5. During training the quantities, t, \\lambda, \\Phi_0 etc. are available, but during inference, what all inputs are assumed to be available?\n6. What is the impact of missing quantities on training, can the model still learn?\n7. The structures in Fig 3 (b and c) are still blackboxes, how do these assist in understanding the system as opposed to a process model?\n\n\n### Minor/semantics/other comments:\n1. Why use TSSM for temporal-spatial modeling method (TSSM), TSMM or TSM is more appropriate?\n2. The acronyms DF, CF, IST, and EST can be defined just below eq(1) for clarity.\n3. Decomposing pde as spatial and temporal modules has been studied in PIML. It is important to discuss these similarities in the present work; see Seo 2021. \n\n\nSeo et al. 2021, Physics-aware Spatiotemporal Modules with Auxiliary Tasks for Meta-Learning, IJCAI 2021."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2688/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698872492789,
            "cdate": 1698872492789,
            "tmdate": 1699636209927,
            "mdate": 1699636209927,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yBZ08Dte2z",
                "forum": "UHIKtKzTj7",
                "replyto": "OIdrvJvmSJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer hyse (1)"
                    },
                    "comment": {
                        "value": "Thank you for your insightful questions, which have allowed us to clarify key aspects of our work.\n\n## 1. Understanding Process Models:\n- 1.1 **Q**: Why are the dynamics/equations of the process model unknown? Isn't it defined by the practitioners?\n    - **A**:  Process models, integral to our research, consist of conservation equations governing primary physical quantities (mass, energy, momentum) and constitutive equations that establish relationships between various physical variables. While conservation equations are generally known, constitutive relationships often require empirical determination. Our goal with PAPM is to create a structured model that separately and effectively captures these two equation types. For instance, in a chemical process, conservation equations might dictate how substances react over time, while constitutive equations would define specific reaction rates based on temperature or pressure.\n        - conservation equations\n            $$\n            \\begin{aligned}\n            &\\frac{\\partial \\Phi}{\\partial t}=-\\nabla\\cdot\\left(J_{C}+J_{D}\\right)+q+F\\\n            &J_{C}=\\Phi(x, t) \\cdot v,\\quad J_{D}=-D \\cdot \\nabla \\Phi\n            \\end{aligned}\n            $$\n        - constitutive equations\n            $$\n            \\begin{aligned}\n            & v = v(\\Phi),\\quad D=\\lambda \\\n            & q=h_O(\\Phi),\\quad F=h_F\\left(X_F\\right)\n            \\end{aligned}\n            $$\n- 1.2 **Q**: In relation to 1, it seems that authors consider dynamics which take the form of eq.1, while the exact values that these quantities take are unknown? Is this true?\n    - **A**: No. It's important to clarify that our model primarily focuses on the constitutive relationships between physical quantities, rather than on specific physical quantities themselves. The model inputs \u2013 initial conditions, coefficients, external source terms, and time (t) \u2013 are known during both training and testing phases. The central unknown aspect in our model is the nature of the relationships between these inputs and how they influence the system's state, which embodies the aforementioned constitutive relationships.\n        \n- 1.3 **Q**: How are process models different from the proposed model in relation to eq1 and Fig. 3?\n    - **A**: **Fig. 3** depicts our Temporal-Spatial Stepping Method (TSSM), which is tailored to align with the unique equation characteristics of different process systems by employing stepping schemes through temporal and spatial operations, whether in the physical or spectral space. While strictly adhering to Eq. 1 and Eq. 2, the implementation differs based on the specific context. For explicit structures, such as the Burgers equation, we opt to directly employ convolutional kernels in the physical space to capture system dynamics. However, for implicit structures, such as the Navier-Stokes Equation in vorticity form, we consider mapping operations in the spectral space.\n## 2. Understanding PAPM:\n- 2.1 **Q**: $\\lambda$ is defined as \"coefficients\" in sec 4.1, but it is unclear how they related to eq 1.\n    - **A**: I've made it clear in the new version that $\\lambda$ is defined as \"coefficients\" as follows:\n        $$\n        \\begin{aligned}\n        & v = v(\\Phi),\\quad D=\\lambda \\\n        & q=h_O(\\Phi),\\quad F=h_F\\left(X_F\\right)\n        \\end{aligned}\n        $$\n        where $\\boldsymbol{v}$ denotes the velocity of the physical quantity being transmitted, $D$ is the coefficient. Here, $v$, $h_O$, and $h_F$ are the corresponding algebraic mapping, and this part determines whether NN is needed for learning mapping according to the specific problem.\n\n- 2.2 **Q**: During training the quantities, t, \\lambda, \\Phi_0 etc. are available, but during inference, what all inputs are assumed to be available?\n    - **A**: During training and inference, all inputs are assumed to be available, such as initial conditions $\\Phi_0$ and coefficients $\\lambda$. However, during training, we work with known variables like coefficients, initial conditions, and time, but the specific mappings of these variables are not provided in the model. This design allows PAPM to learn a mapping from a limited number of observations, enabling it to make accurate long-range predictions in the testing phase. \n\n- 2.3 **Q**: What is the impact of missing quantities on training, can the model still learn?\n    - **A**: When missing some quantities on training, the model also learns. For example, when coefficients are unknown, we can define them as a learnable variable."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700407421909,
                "cdate": 1700407421909,
                "tmdate": 1700409170316,
                "mdate": 1700409170316,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Sma0CY2TZX",
            "forum": "UHIKtKzTj7",
            "replyto": "UHIKtKzTj7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2688/Reviewer_La8N"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2688/Reviewer_La8N"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a specific structure to encode physics prior to the training and use Euler/RK for time stepping to achieve good generalization capability under a data-scarce situation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper explicitly takes into account the physics of the system when designing the system, yielding better generalization capability compare to baselines like FNO"
                },
                "weaknesses": {
                    "value": "I am a bit confused with the experimental setting. I really like the argument of baking more physics prior to the model. However, it seems that during the training, the model is still trained with a large-scale dataset - where one needs up to 10^6 times to generate this dataset."
                },
                "questions": {
                    "value": "1. I am curious any thoughts on why FNO performs so badly even with the full dataset for training? This is different from what I generally get from various literature. \n2.  I am curious why different padding strategy corresponds to boundary condition. How does it help enforce the boundary condition?\n3. how could it generalize to mesh base simulation with adaptive resolution?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2688/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699241398240,
            "cdate": 1699241398240,
            "tmdate": 1699636209854,
            "mdate": 1699636209854,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9lUpowcz9m",
                "forum": "UHIKtKzTj7",
                "replyto": "Sma0CY2TZX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer La8N (1)"
                    },
                    "comment": {
                        "value": "Thank you for your insightful queries regarding our experiment and model performance. Your questions have allowed us to clarify further and highlight the strengths of our approach.\n\n## 1. The Experimental Setting\n- 1.1. **Datasets.** We selected three representative papers from the current PIML field and selected their representative two-dimensional datasets, respectively. Burgers with periodic boundary conditions [1], Fitzhugh-Nagumo RD with no-flow Neumann boundary conditions [2], and incompressible Navier-Stokes equation in vorticity [3]. In addition, we have completed two classical fluid field benchmark data sets using COMSOL simulation software. Lid-driven cavity flow and incompressible Navier-Stokes equations with an additional magnetic field. Through these five datasets, the generalization ability of PAPM is comprehensively demonstrated. For the details of the above five datasets, please refer to **Appendix A.5.1**.\n- 1.2  **Evaluation Protocol.** It is worth noting that, unlike other work in PIML field, such as FNO, we consider the model's generalization ability during long-term evolution and strictly distinguish the time step size between the training set and the test set. That is, the training set can only obtain data within the first ($T'$) step, while the test set needs to infer on the full-time step ($T_{end}$). Where $T'\\ll T_{end}$, in this paper the experimental set $T_{end}=100$, and $T'=\\frac{T_{end}}{2}$.\n- 1.3 **Detailed Data Generation Process.** Based on this experimental setting, when simulating through COMSOL, we set the simulation minimum time unit $\\delta t$ as $2\\times10^{-2}$ s, collect a slice every 10 steps, and collect 100 slices for each data. 500 simulations are performed for each dataset, each with a completely different condition (i.e., initial conditions and equation coefficients, in this case, Reynolds numbers). The computational intensity was significant: a single run in the lid-driven scenario took 91 seconds on average, while the magnetic stirring case took 226 seconds.  The total computation time was approximately $10^6$ s for all 500 cases, highlighting the time-consuming nature of such simulations. The intricacy of multi-physics coupling and the extensive computational demand in these simulations point towards the necessity of more efficient methods. \n\nWe hope to build long-range datasets that, in the process, incorporate more complex dynamical behavior of the system rather than the steady-state behavior with short time steps, as demonstrated in the FNO paper. Such datasets can better demonstrate the long-range generalization capability of PAPM. \n\n## 2. FNO Performance\nAddressing your query on FNO, it is a data-driven approach that shows commendable accuracy within its training domain (**i.t., the training and test datasets are under the same time step**) but struggles with time extrapolation [4,5]. As shown in **Fig. 5** in the paper, while FNO demonstrates commendable accuracy within the training domain ($0<T\\leq\\frac{1}{2}T_{end}$), its performance falters significantly outside of it ($\\frac{1}{2}T_{end}\\lt T \\leq T_{end}$). However, our model, PAPM, through its unique physics embedding, maintains high accuracy and performance even in extrapolation scenarios to address this limitation.\n\n## 3. Padding Strategy and Boundary Conditions\nThe boundary condition is critical for dynamic modeling because it reflects the interaction between the system and the outside world. Four common boundary conditions are considered in detail: Dirichlet, Neumann, Robin, and Periodic in four directions. It has different mathematical expressions for boundary conditions, but we can transform the continuous space into a discrete grid of points.\n\nHere, the Robin boundary condition is taken as an example. If the boundary condition is given as \n$$\\alpha \\Phi(X,t) + \\beta \\frac{\\partial \\Phi(X,t) }{\\partial \\mathbf{n}} = f(X,t), X\\in \\partial \\Omega,$$ \nthe discrete form would be \n$$\\alpha \\Phi_{Mj} + \\beta \\frac{\\Phi_{(M+1)j} -\\Phi_{(M-1)j}}{2\\times \\delta x}=f_{j}.$$ \nWe can use a padding method in the convolution kernel $$\\Phi_{(M+1)j}=\\frac{2\\times \\delta x}{\\beta} (f_{j} - \\alpha \\Phi_{Mj}) + \\Phi_{(M-1)j}.$$ \nSo, the padding method can be used to enforce the boundary condition. A more detailed introduction can be found in **Appendix A.2**."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405290328,
                "cdate": 1700405290328,
                "tmdate": 1700405290328,
                "mdate": 1700405290328,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "k87atP1gs9",
                "forum": "UHIKtKzTj7",
                "replyto": "Sma0CY2TZX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers",
                    "ICLR.cc/2024/Conference/Submission2688/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer La8N (2)"
                    },
                    "comment": {
                        "value": "## 4. Generalization to Mesh-Based Simulation with Adaptive Resolution.\n\nWe are actively addressing this issue by breaking it down into two key subproblems:\n-   Generalizing to Mesh-Based Simulation: To adapt to non-uniform meshes common in finite element simulations, we propose two approaches:\n    - a. Using bilinear interpolation to convert non-uniform grids to standard grids, minimizing errors especially in dense grid scenarios.\n    - b. Employing a lift mapping function, similar to the geo-FNO [6] strategy, to transform non-uniform meshes into uniform ones.\n\n    In our case study of a low-temperature argon plasma discharge (see **Fig. 9**), we chose the first approach due to the high density of the simulation grid, allowing for effective direct interpolation before training the PAPM model. We explore a more complex example of low-temperature argon plasma discharge, which presents a challenging scenario with non-regular grids and complex mechanisms. The mechanism equation of this process is far more complex than Eq. 1 and 2, involving the coupling of multiple physical fields such as the electric field, temperature field, and pressure field. It does not strictly adhere to the definition in Eq. 1. Still, for the physical quantities to be modeled, their overall pattern follows the primary setting in which convection, diffusion, and source terms act together. Therefore, we can still construct a proxy model for plasma through PAPM. As demonstrated in **Table 1**(below), our method surpasses others in accuracy, generalization, and efficiency. For A more detailed introduction, please refer to **Appendix A.8**. We will use this example to show the generalization ability of PAPM further.\n\n**Table 1: Main results ($\\epsilon$), FLOPs, training and inference time cost (iteration/second), and the number of trainable parameters ($N_P$) on Plasma2d.**\n| **Config**    | **\\$\\epsilon\\$** | **FLOPs**  | **Train** | **Test** | **$N_p$**   |\n| ------------- | ---------------- | ---------- | --------- | -------- | ------------|\n| convLSTM [7]  | 0.750            | 2.05G      | 5.05      | 0.43     | 0.080M      |\n| Dil-ResNet [8]| 0.316            | 3.90G      | 7.61      | 0.59     | 0.152M      |\n| timeFNO2d [3]| 0.286            | 0.11G      | 2.37      | 0.31     | 0.465M      |\n| U-FNet [9]   | 0.718            | 5.22G      | 9.38      | 1.49     | 10.091M     |\n| CNO [10]      | 0.407            | 3.50G      | 8.46      | 0.92     | 2.674M      |\n| PPNN [11]      | 0.228            | 3.01G      | 4.60      | 0.63     | 1.300M      |\n| **PAPM**      | 0.178            | 0.07G      | 4.66      | 0.47     | 0.032M      |"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700406405519,
                "cdate": 1700406405519,
                "tmdate": 1700409108848,
                "mdate": 1700409108848,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]