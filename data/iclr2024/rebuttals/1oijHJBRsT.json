[
    {
        "title": "Self-Alignment with Instruction Backtranslation"
    },
    {
        "review": {
            "id": "1wxnV25PH0",
            "forum": "1oijHJBRsT",
            "replyto": "1oijHJBRsT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2743/Reviewer_Fnnk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2743/Reviewer_Fnnk"
            ],
            "content": {
                "summary": {
                    "value": "This work investigates scaling the instructing tuning with limited seed data.\nThe authors suggest an iterative self-training approach to increase training instances from large-scale unlabeled data.\nThey first train a instruction generation model (backward model) with high-quality seed data to predict instruction for unlabelled data.\nThen, the initial instruction following model, which is finetuned on the seed data, is prompted to score the pseudo labeled instances.\nNext, a new instruction model is trained on the compound of seed data and selected high-quality pseudo data with system prompt conditioning.\nThis new improved model can continue the next cycle scoring on the pseudo labeled data, then finetuning the second improved model, again and again.\nThe pseudo data is not updated in the above iteration.\nThe authors conducted extensive experiments using LLaMA 7B, 33B, 65B models.\nModel performance is evaluated by the win rate of each model against text-davinci-003 from GPT-4 judgements (AlpacaEval).\nThe generated instructions can increase the task diversity, show better data scaling coefficient than other data sources.\nModels finetuned on the selected data achieved best performance among non-distilled models."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.  The paper cleverly utilizes the traditional self-training method to enhance the instruction data and model performance.  \n2.  The experiments are solid."
                },
                "weaknesses": {
                    "value": "no significant negative issues."
                },
                "questions": {
                    "value": "1. section 3.3, Data quality vs. data quantity. \"We find that training on augmented data without self-curation **does not improve** instruction following performance despite scaling up data quantity\". I did not find any clear evidence from Figure 2 to support the statement \"does not improve.\" Perhaps adding the win rate of the M0 model could help me better understand?\n\n2. What does the \u00b1 in Table 5 mean? Multiple inference of models?\n\n3. I am curious about the performance if we update the backward model using augmented data. It's worth exploring to see how it would perform."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2743/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2743/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2743/Reviewer_Fnnk"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2743/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698461855779,
            "cdate": 1698461855779,
            "tmdate": 1699636217094,
            "mdate": 1699636217094,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "L3no5ObJJ9",
                "forum": "1oijHJBRsT",
                "replyto": "1wxnV25PH0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2743/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2743/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the insightful review and recognition of the impact of the work. The clarification questions are helpful in improving the paper to be more clear:\n\n> 1. section 3.3, Data quality vs. data quantity. \"We find that training on augmented data without self-curation **does not improve** instruction following performance despite scaling up data quantity\". I did not find any clear evidence from Figure 2 to support the statement \"does not improve.\" Perhaps adding the win rate of the M0 model could help me better understand?\n\nThanks for the suggestion of adding the win rate of M_0 model, which is 53.57%. By \u201cdoes not improve\u201d we were referring to the performance of w/o self-curation (the first bar in each group) did not increase as the amount of data is increased, as opposed to the increasing trend with self-curation (the second and third bar in each group).\n\n> 2. What does the \u00b1 in Table 5 mean? Multiple inference of models?\n\nIt refers to the standard error of win rate, averaged over different prompts where each prompt only has one sample of generation.\n\n> 3. I am curious about the performance if we update the backward model using augmented data. It's worth exploring to see how it would perform.\n\nWe did not experiment with using the augmented data to further improve the backward model, i.e. making the augmentation step iterative but it sounds a very interesting idea for future work."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2743/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700608415831,
                "cdate": 1700608415831,
                "tmdate": 1700609303417,
                "mdate": 1700609303417,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EyJjxt2hAr",
            "forum": "1oijHJBRsT",
            "replyto": "1oijHJBRsT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2743/Reviewer_XACc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2743/Reviewer_XACc"
            ],
            "content": {
                "summary": {
                    "value": "The paper aims to build an instruction following language model by fine-tuning. To collect high quality instruction-response pairs automatically, the paper proposes instruction backtranslation, which first uses a seed dataset to fine-tune to generate instructions given a web corpus, and then fine-tunes a stronger model on the filtered instructions. Experiments show the resulting LM outperforms non-distilled LMs on both generation quality and downstream performance. Analysis shows that the self-curation step is critical in selecting high-quality data which leads to further improvement while simply scaling the data size does not."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1.\tInstruction-following is an important aspect of applying LLMs in practice, while high-quality labeled data is critical to elicit this behavior from LLMs. The proposed method does not rely heavily on human annotation and could scale the data size with the data quality being guaranteed.\n2.\tThe paper conducts extensive experiments with both human and automatic evaluation to demonstrate the effectiveness of the proposed method across downstream tasks and model size. In particular, the analysis verifies that data quality plays an important role in improving performance when scaling up the data size.\n3.\tThe paper is easy to follow and well-organized."
                },
                "weaknesses": {
                    "value": "1.\tThe paper assumes that the seed model M0 can somehow provide meaningful evaluation for the generated instructions by just following instructions. This might need further investigation. For example, M0 could be just selecting instructions that are similar to the seeds while discarding other instructions which are still useful but may vary in style or format, etc. Also, the work could consider other filtering methods such as using the language modeling probabilities as the scores or using external models such as those trained with NLI.\n2.\tThe paper assumes that a proportion of the unlabeled data should have the corresponding instructions which is not quite intuitive. One limitation is that this might greatly limit the types of instructions that the backtranslation model can generate. I would suggest a further study to understand the types of segments that do have meaningful instructions and the types of instructions that we could collect from the web corpus."
                },
                "questions": {
                    "value": "1.\tCould you show more concrete examples of the generated instructions and the corresponding text segments? That would be helpful for users to understand why certain texts should have an underlying instruction.\n2.\tWhat are the benefits brought by the proposed method compared to the distilled method?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2743/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698691016819,
            "cdate": 1698691016819,
            "tmdate": 1699636217024,
            "mdate": 1699636217024,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4OxMKMYlZ7",
                "forum": "1oijHJBRsT",
                "replyto": "EyJjxt2hAr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2743/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2743/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your thorough review and great suggestions. We will incorporate them in improving the final version of the paper. \n\n> 1. Could you show more concrete examples of the generated instructions and the corresponding text segments? That would be helpful for users to understand why certain texts should have an underlying instruction.\n\nWe provided some samples of the segments and the generated instructions in the response to Reviewer HdQC. \n\n> 2. What are the benefits brought by the proposed method compared to the distilled method?\n\nThe proposed method does not rely on an external model for data augmentation and curation.\nThe synthetic data generated from the proposed method has human-written text in the responses with model-generated instructions while distilled methods have model-generated text as responses. \nDistillation methods have also been shown to be a ``false promise\u201d as is analyzed in [1], where it appears better at following instructions by mimicking the style of the stronger model but still has a large gap on tasks not supported in the distillation data. \n\n[1] Gudibande, Arnav, Eric Wallace, Charlie Snell, Xinyang Geng, Hao Liu, Pieter Abbeel, Sergey Levine, and Dawn Song. \"The false promise of imitating proprietary llms.\" arXiv preprint arXiv:2305.15717 (2023)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2743/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700608060472,
                "cdate": 1700608060472,
                "tmdate": 1700609368311,
                "mdate": 1700609368311,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CU1bXEfIWC",
            "forum": "1oijHJBRsT",
            "replyto": "1oijHJBRsT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2743/Reviewer_bTHF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2743/Reviewer_bTHF"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a scalable and simple method to curate high-quality instruction data for fine-tuning language models.  Specifically, the proposed method includes two stages: self augmentation, i.e., generate prompts for raw documents, and self curation, i.e., select high-quality augmented data iteratively.  After two rounds of data curation, the constructed data is used to finetune a stronger model, which is demonstrated to outperform non-distilled models. Also this paper presents comprehensive analysis and ablation experiments to show the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1). An intuitive and effective method to construct high-quality and diverse instruction data. It will significantly reduce the human annotation efforts or potential bias of distilled data from strong LLMs like ChatGPT. \n\n2). The self-curation step provides continuous data quality improvement in terms of fine-tuned models performances and the diversity of augmented data can complement seed instruction data.\n\n3). The paper is well-written with comprehensive and clear analysis / experiments."
                },
                "weaknesses": {
                    "value": "No obvious weakness but it would be better to clarify the choices of unlabeled data for augmentation."
                },
                "questions": {
                    "value": "1). One scaling law question:  will the performance be stable (not increase) with the increased numbers of augmented data (w/ curation)? \n\n2).  In the first paragraph of Section 3.3,  does $A^{(2)}_{5}$ mean the subset that scores more than 4.5? \n\n3). In Table7, what if the results of Humpback 65B with 5-shot demonstrations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n.a."
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2743/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839315568,
            "cdate": 1698839315568,
            "tmdate": 1699636216963,
            "mdate": 1699636216963,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pWbl7TgGot",
                "forum": "1oijHJBRsT",
                "replyto": "CU1bXEfIWC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2743/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2743/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your insightful review and clarification questions. Please find our answers below:\n\n> 1). One scaling law question: will the performance be stable (not increase) with the increased numbers of augmented data (w/ curation)?\n\nThat is a great question. The max amount of data we experimented in this paper is 45k examples, which has already demonstrated better data efficiency than other methods (manually annotation, distillation) at that scale. It is definitely an exciting direction to further scale up the augmented data by orders of magnitude or even apply it to pretraining data.\n\n> 2). In the first paragraph of Section 3.3, does $A_5^{(2)}$ mean the subset that scores more than 4.5?\n\nYes. That\u2019s correct. It was rounded up for concise notation. \n\n> 3). In Table7, what if the results of Humpback 65B with 5-shot demonstrations?\n\nThat is an interesting question. The rationale of the comparisons in Table 7 is that few-shot in-context learning is an alternative approach to enable LLM instruction-following capabilities besides finetuning. Therefore, it is more fair to compare the zero-shot performance of finetuned model with few-shot in-context learning from the based model."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2743/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607749868,
                "cdate": 1700607749868,
                "tmdate": 1700609199199,
                "mdate": 1700609199199,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "PUVboIQhGs",
            "forum": "1oijHJBRsT",
            "replyto": "1oijHJBRsT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2743/Reviewer_HdQC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2743/Reviewer_HdQC"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method to generate instruction tuning data from unlabelled data by posing the problem as an \u2018instruction back translation\u2019 problem ie. given a piece of text, generate potential instructions that can be answered by the text. This model is learnt by finetuning a base LLM with seed instruction data in the reverse direction. The examples thus generated are filtered using the seed model, and iteratively the seed model is improved with the filtered data. Unlike distillation-based approaches, the data is not generated using an external, more powerful model \u2013 rather this is self-augmentation that bootstraps a model's capabilities."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "* The paper proposes a method for generating diverse, high-quality instruction datasets using a baseline LLM that does not require an external, more powerful LLM.  \n* The instruction-tuned models so created are better than models trained on small, human-curated corpora and competitive with models trained on data distilled from more powerful models. \n* Evaluation on a diverse set of benchmarks shows the generalizability of this method."
                },
                "weaknesses": {
                    "value": "While instruction tuning backtranslation is a useful method, it is not clear how it compares with self-instruct. If the same seed dataset had also been used to generate instruction tuning data from the same base LLM, that would provide a  good comparison. The distilled models considered in the paper have been trained on different seed datasets and use more powerful LLMs for distillation. Although I don\u2019t see this as a serious limitation of the paper, this study would have helped shed light on how the two approaches compare."
                },
                "questions": {
                    "value": "* What is the impact of self-curation iterations? Is there a value to performing multiple iterations? Did you also consider inference of the document collection on an improved reverse model from the data extracted (making the augmentation step also iterative)?\n* Can you add some samples of extracted instruction dataset instances to the paper? \n* How are the segments selected from ClueWeb. Are entire documents chosen, is there some filtering on criteria like length, etc? Are the inputs to the reverse models entire documents or smaller units like paragraphs? \n* Table 5: What is the model size used in this study? On which benchmark dataset? Does this observation hold over different model sizes? Which configuration has been used to report results in the rest of the paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2743/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699212304670,
            "cdate": 1699212304670,
            "tmdate": 1699636216901,
            "mdate": 1699636216901,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HgNNMXZCJ3",
                "forum": "1oijHJBRsT",
                "replyto": "PUVboIQhGs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2743/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2743/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> What is the impact of self-curation iterations? Is there a value to performing multiple iterations? Did you also consider inference of the document collection on an improved reverse model from the data extracted (making the augmentation step also iterative)?\n\nBoth are excellent questions. We observed improvements in data curation from the seed model $M_0$ to $M_1$. However, from $M_1$ to $M_2$, there was improvement in recall but drop in precision. Therefore, we did not use $M_2$ to conduct a third  iteration of data curation. We did not experiment with making the augmentation step iterative but it sounds a very interesting idea for future work.   \n\n> Can you add some samples of extracted instruction dataset instances to the paper?\n\nBelow are a couple of examples:\n```\nDiamond engagement rings gained in popularity during the Art Deco era with the round old European cut diamond being the favourite.\n\n### Asscher Cut\n\nThe Asscher cut is one of the first patented diamond cuts in the world and was invented by Dutch master diamond cutter, Joseph Asscher of the Royal Asscher Diamond Company in 1902.  Classic asscher cut diamonds are cut into squares and resemble emerald cuts, which are rectangular. Asscher cut diamonds are different to a square emerald cut in that they have larger step facets, a higher crown, smaller table and have more brilliance. The corners are cropped to give the shape an octagonal appearance.\n\n### Baguette Cut\n\nAlthough the baguette cut was invented sometime prior to the mid-1500s, it only gained popularity in 1912 when Cartier reintroduced the cut to the modern world. Its elongated, table cut, rectangular shape became highly fashionable in the geometric craze of the Art Deco period.\n\n### Emerald Cut\n\nThe emerald diamond cut emerged as one of the first faceted diamond cuts, third in line after the point cut and the table cut. The cut has a dramatic hall of mirrors effect and was standardised in the 1940s.  \n\\newline\n```\n*Generated instruction:*\n    List the most popular diamond cuts in the Art Deco era.\n```\nInclusive Sports Coaching provides 1:1 Programs for individuals looking to develop their sporting skills, as well as improve their self confidence and opportunities for social and community inclusion.\n\nWe recommend an 8 or 12 Session program to identify areas for improvement and sporting skills, conduct drills and physical activities to work towards specific outcomes, while engaging with the client in areas such as listening, memory retention, cognitive processing, social interaction, encouraging conversations, accepting and giving constructive feedback, and other areas as needed.\n\nAt the halfway point we produce a status report on progress, and have found parents/carers often share this with OT's, Physios and Teachers as a way to share information on the individual and provide a strong network of support. At the end of the program we produce a final report, with recommendations for ongoing improvement, potential for progress along the person's chosen sport pathway where applicable, etc.\n```\n*Generated instruction:* I have a business called Inclusive Sports Coaching. We provide 1:1 sport coaching for people with disabilities. I want to have some materials on hand to give to parents when they enquire about our services. What do you recommend I include in these materials?\n\n> How are the segments selected from ClueWeb. Are entire documents chosen, is there some filtering on criteria like length, etc? Are the inputs to the reverse models entire documents or smaller units like paragraphs?\n\nWe parse the warc files of ClueWeb in HTML format to extract segments. Each segment is a tree rooted at a header node, including subtrees from lower-level headers. We applied the following filters before sampling segments:\nLength: total length of text between 600 and 3000 characters. \nDuplications: we remove segments with repetitive sentences by computing jaccard similarity of ngrams from pairs of sentences in the segment.\nWe remove segments when containing an empty header or the text is all uppercase, header contains navigation text such as \u201cadvertisement\u201d, \u201cforum\u201d, \u201cquick link\u201d, \u201cfree newsletter\u201d,  etc.\n\n> Table 5: What is the model size used in this study? On which benchmark dataset? Does this observation hold over different model sizes? Which configuration has been used to report results in the rest of the paper?\n\nThese ablations were conducted with the 7B model and the win rates were evaluated on the 250 dev prompts sampled from the combined test prompts from multiple sources. We verified the same trend with the 65B model: combined system prompt: $84.34\\pm2.31$, only system prompt for OA seed data: $80.15\\pm2.51$. Results in the rest of the paper use the combined system prompt in both training and inference, i.e. the configuration corresponding to the first row of Table 5."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2743/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607615643,
                "cdate": 1700607615643,
                "tmdate": 1700607615643,
                "mdate": 1700607615643,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]