[
    {
        "title": "Long-Short-Range Message-Passing: A Fragmentation-Based Framework to Capture Non-Local Atomistic Interactions"
    },
    {
        "review": {
            "id": "PVakXtAHKv",
            "forum": "rvDQtdMnOl",
            "replyto": "rvDQtdMnOl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4407/Reviewer_gmV7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4407/Reviewer_gmV7"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a fragment-based approach to propagate long-range information in Graph Neural Networks (GNNs). A set of fragments is constructed using the BRICS fragmentation method, which leverages chemical structures to define well-behaved fragments. The framework operates at two levels: first, it performs a message-passing step on the short-range graph, and then uses these results to define fragment-level features that are also message-passed at the fragment-level graph. The method demonstrates competitive accuracy on the MD22 benchmark, which contains large structures, and shows some improvements over short-range baselines."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is clearly written and pedagogical.\n- Various ablation studies were conducted on both the long-range modules and the fragmentation methods.\n- Results show improvements over short-range baselines for large molecules.\n- Some limitations of the fragmentation methods are discussed."
                },
                "weaknesses": {
                    "value": "- The main weakness of the method, as shared in the paper, is the definition of fragments. First, as mentioned, it is not clear how to define these for most systems, including materials. My biggest concern is the issue of smoothness. In molecular dynamics (MD) simulations, it is crucial to ensure that the predictions are smooth. I can envision many MD scenarios where such partitioning might cause problems, and I would be very interested in seeing the behavior of this model over long simulations.\n\n- The Equiformer and VisNet models have 4 layers with a 4\u00c5 cutoff, resulting in a receptive field of 32\u00c5 in diameter. Most of the MD22 molecules fit well within their receptive fields. While this does not detract from the improvement offered by the method, it should be clearly highlighted.\n\n- The importance of long-range effects beyond a 12\u00c5 radius is subtle, as large effects are usually screened in most systems. One would expect to see little difference in errors between a short-range and a long-range model. However, observables computed from MD simulations might vary significantly, as these long-range effects do not average out over long timescales. To capture these observables accurately, the most crucial factor is the decay of interactions, rather than raw accuracy. There is no reason to believe that your approach would correctly capture this decay, enabling accurate observables in these simulations. I want to stress that long-range effects in large biomolecular systems are mostly relevant for observables, and justifying the method solely through raw accuracy has limited scientific relevance.\n\n- One of the main challenges of long-range modeling is transferability, especially for models without typical decay behaviors. I would be very interested in seeing how this model extrapolates to longer, unseen molecules, and whether it performs better than a local model in this context. This is the only relevant setting for practical applications, particularly for modeling systems where ab initio computations are not feasible."
                },
                "questions": {
                    "value": "- How well do you expect your model to transfer to new, unseen systems, particularly those of larger sizes?\n\n- Could you plot the typical decay learned by your interactions, assuming the fragmentation approach allows for it? You could try separating two molecules and plotting the energy as a function of distance. Without sensible decay, the model stands little chance of extrapolating effectively."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4407/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4407/Reviewer_gmV7",
                        "ICLR.cc/2024/Conference/Submission4407/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4407/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698774382466,
            "cdate": 1698774382466,
            "tmdate": 1700513143281,
            "mdate": 1700513143281,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "w4SF0N6lYA",
                "forum": "rvDQtdMnOl",
                "replyto": "PVakXtAHKv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal [1/3]"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, they are exceedingly helpful for us to improve our paper. Our point-to-point responses to your comments are given below:\n\n> The main weakness of the method, as shared in the paper, is the definition of fragments. First, as mentioned, it is not clear how to define these for most systems, including materials. My biggest concern is the issue of smoothness. In molecular dynamics (MD) simulations, it is crucial to ensure that the predictions are smooth. I can envision many MD scenarios where such partitioning might cause problems, and I would be very interested in seeing the behavior of this model over long simulations.\n>\n\nWe appreciate your feedback. Research in recent decades has demonstrated that the smoothness issues associated with fragmentation can be mitigated to a negligible level, particularly in Molecular Dynamics (MD) simulations (https://doi.org/10.1021/ar500038z).  In our upcoming experiments, we aim to demonstrate that smoothness is not a practical issue in long-term simulations with our design. \n\nHere, we performed an MD simulation for a relatively large molecule, ATAT, for 20ps, matching the duration of the AT-AT simulation in the MD22 dataset. This was done at a constant energy ensemble (NVE). These simulations were driven by our ViSNet-LSRM and DFT with a time step of \u03c4 = 1 fs, allowing us to analyze the vibrational spectra of the AT-AT molecule. As depicted in Fig. 5 and the provided link https://i.ibb.co/pzKwkjX/vel-auto.jpg, both the trajectory in MD22 and the trajectory simulated by ViSNet-LSRM show similar vibrational spectra, albeit with minor differences in peak intensities compared to DFT. This suggests that our simulations can accurately mimic the actual vibrational modes of the molecules over relatively long time periods.\n\nTo test the model performance in longer time steps, we ran a longer 200 ps NVE simulation with a time step of \u03c4 = 1 fs for this molecule. The total energy profile is displayed in Fig. 6 and the link https://i.ibb.co/pZ2Xz33/etot-vs-steps-0-200000.png. The total energy stays reasonably conserved (fluctuates within 0.0001\\% of the total energy), unlike a problematic energy profile that might drastically increase/decrease over time (fluctuates more than 0.01\\% of the total energy). This implies that the LSR-MP could well adapt to longer simulations."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700311058477,
                "cdate": 1700311058477,
                "tmdate": 1700491518100,
                "mdate": 1700491518100,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5ZDCJc8riu",
                "forum": "rvDQtdMnOl",
                "replyto": "PVakXtAHKv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal [2/3]"
                    },
                    "comment": {
                        "value": "> The Equiformer and VisNet models have 4 layers with a 4\u00c5 cutoff, resulting in a receptive field of 32\u00c5 in diameter. Most of the MD22 molecules fit well within their receptive fields. While this does not detract from the improvement offered by the method, it should be clearly highlighted.\n> \n\nThanks for your valuable feedback, we will highlight this point in our revised paper.\n\n> The importance of long-range effects beyond a 12\u00c5 radius is subtle, as large effects are usually screened in most systems. One would expect to see little difference in errors between a short-range and a long-range model. However, observables computed from MD simulations might vary significantly, as these long-range effects do not average out over long timescales. To capture these observables accurately, the most crucial factor is the decay of interactions, rather than raw accuracy. There is no reason to believe that your approach would correctly capture this decay, enabling accurate observables in these simulations. I want to stress that long-range effects in large biomolecular systems are mostly relevant for observables, and justifying the method solely through raw accuracy has limited scientific relevance. Could you plot the typical decay learned by your interactions, assuming the fragmentation approach allows for it? You could try separating two molecules and plotting the energy as a function of distance. Without sensible decay, the model stands little chance of extrapolating effectively.\n> \n\nThank you for your valuable insights and for highlighting the importance of accurately capturing long-range effects in large biomolecular systems. We appreciate your emphasis on the subtleties of long-range effects in large biomolecular systems and their significance in observables derived from molecular dynamics (MD) simulations. To address your concerns, we would like to politely clarify that long-range effects beyond a 12\u00c5 radius are indeed critical and cannot be neglected, as evidenced in multiple systems[1]. Thus raw accuracy still holds its validity under such settings.\n\nIn our study, detailed in the updated Appendix E.2, we focused on a system with significant electrostatic interactions.  We studied the decay of interactions by separating two molecules in a dimer configuration and plotting the energy as a function of distance. The decay curve can be found in Appendix E.2.1 as well as [https://i.ibb.co/TMnMrPG/nov-16-decay.jpg.](https://i.ibb.co/TMnMrPG/nov-16-decay.jpg) These experiments demonstrate that, compared to a local model, our model exhibits a more appropriate decaying behavior. This finding is crucial as it suggests that our model captures the long-range interactions more effectively, addressing the key issue you raised.\n\n[1]: Frank et al. So3krates: Equivariant attention for interactions on arbitrary length-scales in molecular systems. NeurIPS 2022."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700312314134,
                "cdate": 1700312314134,
                "tmdate": 1700344792116,
                "mdate": 1700344792116,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Kdh0JSDVPa",
                "forum": "rvDQtdMnOl",
                "replyto": "PVakXtAHKv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal [3/3]"
                    },
                    "comment": {
                        "value": "> One of the main challenges of long-range modeling is transferability, especially for models without typical decay behaviors. I would be very interested in seeing how this model extrapolates to longer, unseen molecules, and whether it performs better than a local model in this context. This is the only relevant setting for practical applications, particularly for modeling systems where ab initio computations are not feasible.\n> \n\nTo answer your question, we conducted three experiments to verify the extrapolation capability of our system. \n\n- **Zero-Shot Experiment:** To study transferability, we commence by adopting a zero-shot setup. We trained on molecules including ATAT, Stachyose, DHA, and Ac-Ala3-NhMe, and then tested directly on a larger molecule, ATATCGCG. The zero-shot results are shown in the table below. This experiment revealed that direct transferability without demonstration is challenging for MD22 trajectories.\n\n| zero shot on ATAT-CGCG | Energy (kcal/mol) | Force (kcal/mol/A) |\n| --- | --- | --- |\n| ViSNet | 182.4363 | 10.93 |\n| ViSNet-LSRM | 150.2343 | 10.22 |\n- **Few-Shot Learning Experiment:** To further explore transferability, we conducted a few-shot learning experiment, as shown in Table below. By adding a small set of 50 ATATCGCG training samples to the original zero-shot training set, our model demonstrated significant improvement over the baseline model. This suggests that with minimal additional training data, our model can adapt to new, larger molecular systems more effectively than local models.\n\n| Few shot on ATAT-CGCG | Energy (kcal/mol) | Force (kcal/mol/A) |\n| --- | --- | --- |\n| VisNet | 2.575 | 0.7448 |\n| VisNet-LSRM | 2.167 | 0.6556 |\n- **PubChem:** In light of the few-shot learning experiments, we further assessed our model's capabilities using the PubChem [1] dataset, as elaborated in Appendix E.1. The dataset features **heterogeneous** molecules of size ranging from 40 to 100. We recalculated the dataset using def2-tzvp basis set, and b3lyp xc functional to improve accuracy. Notably, we included molecular force, which remains informative signals given that the molecules were relaxed only through a semi-empirical approach. For dataset division, we used molecules with **fewer than 60** atoms (30,545 samples) for training and those with **more than 60** atoms (3,455 samples) for testing. Our results are shown in the Table below. Compared to the baseline ViSNet model, our model showed enhanced performance on larger and unseen molecules, underlining its robust transferability and wide applicability in diverse molecular contexts.\n\n| PubChem | Energy | Force |\n| --- | --- | --- |\n| VisNet | 4.458 | 0.3303 |\n| VisNet - LSRM | 3.339 | 0.2395 |\n\n[1]: Nakata M, Maeda T. PubChemQC B3LYP/6-31G*//PM6 Data Set: The Electronic Structures of 86 Million Molecules Using B3LYP/6-31G* Calculations. J Chem Inf Model."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700312774222,
                "cdate": 1700312774222,
                "tmdate": 1700345501256,
                "mdate": 1700345501256,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "adoTH9GLBo",
                "forum": "rvDQtdMnOl",
                "replyto": "Kdh0JSDVPa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Reviewer_gmV7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Reviewer_gmV7"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their comprehensive responses. I appreciate the additional experiments, and the results are convincing, particularly regarding the decay of the interactions. I would recommend that the authors continue to plot the DFT points, as their absence might raise concerns. While I still perceive significant limitations in the applicability of the methods, as highlighted in my review, I believe the paper is a valuable contribution to the community working on machine learning force fields. Hence, I recommend its acceptance for the conference.\n\nI would also like to emphasize an important point. The systems mentioned in reference [1], specifically cumulenes, are extreme examples of electronic delocalization. While they are intriguing, these systems do not represent the majority of long-range effects in biological systems, which are predominantly screened beyond 12 \u00c5ngstr\u00f6ms, though they remain significant in the dynamics of these systems. The impact of long-range interactions on the dynamics of neutral molecules is most likely to manifest in the terahertz spectrum."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700513102819,
                "cdate": 1700513102819,
                "tmdate": 1700513102819,
                "mdate": 1700513102819,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "U5E9z1VDan",
            "forum": "rvDQtdMnOl",
            "replyto": "rvDQtdMnOl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4407/Reviewer_GkgW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4407/Reviewer_GkgW"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes new message-passing neural networks that capture long-range interactions by generalizing equivariant graph neural networks inspired by fragmentation-based approaches. For the implementation, BRICS fragmentation was leveraged. The authors demonstrated the effectiveness of the proposed method with a recently proposed architecture ViSNet and achieved considerable improvement in large molecule benchmarks: MD and Chignolin datasets. To evaluate the proposed method\u2019s applicability, the authors provided results with other EGNNs such as Equiformer, PaiNN, and ET. They show consistent improvement."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. **Strong empirical results** The proposed method achieved competitive performance in MD22 and Chignolin datasets. In Table 2 for MD22, the proposed method with ViSNet shows achieved the best performance in various settings. More importantly, the proposed method, LSRM, shows consistent improvement compared to the vanilla model without LSRM.\n2. **General applicability** The proposed method with various EGNNs base networks shows consistent performance improvement. \n3. **Computational efficiency** The proposed method shows great performance without significant computational overhead. Rather, the proposed method has the smallest model size and the shortest training time.\n4. **Comprehensive experimental results** The paper provides many details and additional experiments."
                },
                "weaknesses": {
                    "value": "1. **Limited impact.** The technical contributions of this paper has limited impact. Although the method show overall comparable performance, it is a model that is manually-designed by domain knowledge.\n2. **Narrow perspective.** Basically, the proposed method uses two different types of graphs. Then the problem can be viewed as learning on heterogeneous graphs. In recent years, learning graph neural networks on heterogeneous graphs by manually/automatically transforming graphs has been actively studied. The authors may want to include the related work and potentially compare with them. Beyond long-range dependency, non-local/semantic relations also have been utilized. \n3. **Far-fetched claim.** In Figure 2., I do not see anything but overall performance gap. I do not think that the graphs support the claim that LSRM helps models to capture long-range dependency. All three models exhibit similar behaviors."
                },
                "questions": {
                    "value": "1. How about inference time? It was not clear how ViSNet has more parameters than ViSNet-LSRM. Also, the training time was reported, but inference time was not available. In real-world applications, inference time is more important for deployment. I believe that shorter training time would imply shorter inference time, but it should be explicitly discussed to be more comprehensive. Fig. 2, (c)(f) partially show the inference time for the subset of baselines\n2. Figure 3 is confusing. The legend should be updated. \n3. Table 4 is not explicitly referred to in the text, although the paragraph of the text of Q3 in Section 5.2 discusses the result. It will be a quick fix. \n4. Typo (?) in Proposition 4.1 Hamdard -> Hadamard product (?)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4407/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698821447488,
            "cdate": 1698821447488,
            "tmdate": 1699636414553,
            "mdate": 1699636414553,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "MVNdY1t3rQ",
                "forum": "rvDQtdMnOl",
                "replyto": "U5E9z1VDan",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, and they are exceedingly helpful for us to improve our paper and our point-to-point responses to your comments are given below:\n\n> **Limited impact.**\u00a0The technical contributions of this paper has limited impact. Although the method show overall comparable performance, it is a model that is manually-designed by domain knowledge.\n> \n\nWe would highlight that LSR-MP is a combination of ML techniques and domain knowledge, and this combination should not be considered as a trivial manual design. Furthermore, molecular system modeling inherently necessitates a deep understanding of domain knowledge. This is evident in successful models that incorporate concepts like the CG tensor product (combine angular momenta of atomic orbitals, facilitating the calculation of molecular orbital properties and electron interactions) [1], and angular description (molecular empirical potential always consider the angles between different atoms or bonds) [2]. In AI4Science, the integration of domain knowledge is not just beneficial but often crucial for achieving meaningful and accurate results. Our approach aligns with this paradigm, utilizing the fragmentation approach prevalent in quantum chemistry to improve the model's accuracy to real-world molecular systems.\n\nIn terms of broader impact, our proposed methodologies hold significant potential for application in the realms of molecular property prediction and drug design. This represents a promising avenue for managing large biomolecular systems effectively. Furthermore, the introduction of equivariant networks in our approach opens up possibilities for application in the analysis of some other areas such as point cloud analysis in computer vision. However, it is important to note that our expertise does not extend to the domain of point clouds at this juncture. \n\n[1]: Edmonds, A. R. (1957).\u00a0Angular Momentum in Quantum Mechanics. Princeton, New Jersey: Princeton University Press.\u00a0\n\n[2]: Abell, G. C. (1985). \"Empirical chemical pseudopotential theory of molecular and metallic bonding\".\u00a0*Phys. Rev. B*.\u00a0**31**\u00a0(10): 6184\u20136196.\n\n> **Narrow perspective.**\u00a0Basically, the proposed method uses two different types of graphs. Then the problem can be viewed as learning on heterogeneous graphs. In recent years, learning graph neural networks on heterogeneous graphs by manually/automatically transforming graphs has been actively studied. The authors may want to include the related work and potentially compare with them. Beyond long-range dependency, non-local/semantic relations also have been utilized.\n> \n\nIndeed, our proposed method incorporates learning on heterogeneous graphs. We have thoroughly reviewed related literature in this area, which is detailed in our revised appendix. \n\nIn response to your suggestion, we have conducted benchmarking against a well-known heterogeneous graph learning framework, specifically the Heterogeneous Graph Attention Network (HAN) [3]. Our comparative analysis involved substituting our proposed **Distance-Dependent Bipartite Geometric Transformer** with the HAN in the LSR-MP framework. The results are as follows:\n\n|  | Force MAE (kcal/mol/Angstrom) |\n| --- | --- |\n| Distance-Dependent Bipartite Geometric Transformer | 0.1063 |\n| HAN  | 1.512 |\n\nA critical aspect we wish to highlight is that employing HAN in our framework would inevitably disrupt the symmetry, leading to a non-equivariant function. Achieving equivariance with HAN is non-trivial and presents significant challenges. To our knowledge, few works have been dedicated to modeling heterogeneous geometric graphs.  Our Distance-Dependent Bipartite Geometric Transformer, in contrast, maintains the necessary symmetry and equivariance, ensuring the physical relevance and robustness of our model in capturing molecular interactions.\n\n[3]: Wang, Xiao, et al. \"Heterogeneous graph attention network.\"\u00a0The world wide web conference. 2019."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699893915033,
                "cdate": 1699893915033,
                "tmdate": 1700313596962,
                "mdate": 1700313596962,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xXMbsWkxxn",
                "forum": "rvDQtdMnOl",
                "replyto": "U5E9z1VDan",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal (Cont'd)"
                    },
                    "comment": {
                        "value": "> In Figure 2., I do not see anything but overall performance gap. I do not think that the graphs support the claim that LSRM helps models to capture long-range dependency. All three models exhibit similar behaviors.\n> \n\nWe apologize for any confusion caused by the presentation in Figure 2 of our paper and appreciate the opportunity to clarify the intended message behind it: We highlight two key points regarding Figure 2. \n\n1. **Increasing cutoff induces over-squashing (Panels a, b, c):**\n    - In these panels, we aimed to illustrate that a straightforward approach to tackling long-range dependency, such as increasing the cutoff radius, could lead to information oversquashing. This issue is prevalent across all EGNNs, including the short-range component of VisNet-LSRM. We wanted to emphasize that merely extending the cutoff does not effectively address the long-range dependency challenge due to this inherent limitation.\n2. **Effectiveness of the Long-Range Model (Panels d, e, f):**\n    - The key comparison here is between the depth of short-range models and the integration of long-range modules.  To compare **horizontally**, increasing the depth of the short-range models can only bring marginal improvements to the model, this is attributed to vanishing gradients induced by information-oversquashing. To compare **vertically**, our results demonstrate that augmenting a 3-layer short-range model with 2 long-range modules significantly outperforms an 8-layer pure local model. This enhancement is not only in terms of accuracy but also in inference speed, achieving up to **twice** the speed.\n\nBased on your valuable comments, we have updated **the captions** and **added additional visual cues** to better illustrate  Figure 2.\n\n> How about inference time? It was not clear how ViSNet has more parameters than ViSNet-LSRM. Also, the training time was reported, but inference time was not available. In real-world applications, inference time is more important for deployment. I believe that shorter training time would imply shorter inference time, but it should be explicitly discussed to be more comprehensive. Fig. 2, (c)(f) partially show the inference time for the subset of baselines.\n> \n\nThe inference time is attached below, **and the detailed settings of each model can be found in Appendix L.2.**\n\n| Model (Force MAE kcal/mol/A) | ViSNet (0.16) | ViSNet-LSRM (0.13) | PaiNN (0.35) | ET (0.29) | Allegro (0.13) | Equiformer (0.13) |\n| --- | --- | --- | --- | --- | --- | --- |\n| # of Parameters | 2.21M | 1.70M | 3.20M | 3.46M | 15.11M | 3.02M |\n| Inference Time / per molecule (ms) | 14.9 | 7.45 | 7.23 | 10.52 | 295.41 | 54.52 |\n\n> 2. Figure 3 is confusing. The legend should be updated.\n3. Table 4 is not explicitly referred to in the text, although the paragraph of the text of Q3 in Section 5.2 discusses the result. It will be a quick fix.\n4. Typo (?) in Proposition 4.1 Hamdard -> Hadamard product (?)\n> \n\nWe are grateful for your keen observations and suggestions regarding Figure 3, Table 4, and Proposition 4.1. We have addressed these points as follows in our revised manuscript:\n\n1. **Figure 3**: Updated the legend for improved clarity.\n2. **Table 4**: Added an explicit reference in Section 5.2.\n3. **Proposition 4.1**: Corrected the typo from \"Hamdard\" to \"Hadamard product.\""
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699894086814,
                "cdate": 1699894086814,
                "tmdate": 1700141714758,
                "mdate": 1700141714758,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vXeC3N3stM",
                "forum": "rvDQtdMnOl",
                "replyto": "U5E9z1VDan",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you again for your valuable feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer GkgW,\n\nThank you again for your valuable feedback and comments!\n\nAs the discussion period is ending soon, we would greatly appreciate it if you could let us know whether you are satisfied with our response. We will be happy to address any remaining concerns.\n\nSincerely,\n\nAuthors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700623771546,
                "cdate": 1700623771546,
                "tmdate": 1700623990749,
                "mdate": 1700623990749,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "h1tPYcwuou",
            "forum": "rvDQtdMnOl",
            "replyto": "rvDQtdMnOl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4407/Reviewer_4VzQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4407/Reviewer_4VzQ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel framework for molecular dynamics simulations using machine learning. The framework, called Long-Short-Range Message-Passing (LSR-MP), combines equivariant graph neural networks (EGNNs) with fragmentation-based methods to capture both short-range and long-range interactions among atoms. The authors demonstrate that LSR-MP can achieve state-of-the-art results on large molecular datasets, while being more efficient and effective than existing methods. The authors also conduct ablation studies and analysis to validate the importance of incorporating long-range components and the advantages of using BRICS fragmentation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- **Problem Definition**: This paper addresses a challenging and important problem of modeling large molecular systems with high accuracy and low computational cost.\n\n- **Methodology**: This paper introduces a novel message-passing framework that leverages domain knowledge from quantum chemistry to incorporate long-range interactions efficiently and effectively.\n\n- **Performance**: This paper shows significant performance improvements over existing methods on various benchmarks, while using fewer parameters and offering faster speed.\n\n- **Generalizability**: This paper illustrates the general applicability and robustness of the LSR-MP framework by applying it to different EGNN backbones and showing consistent improvements.\n\n- **Implementation**: This paper provide sufficient details on experimental setups and how the method is implemented."
                },
                "weaknesses": {
                    "value": "- **Novelty**: I could not find any distinct weaknesses in this paper, but I might have missed one since I am not an expert in Molecular Modeling. One major concern is regarding the novelty of the proposed long-range message-passing module. As far as I know, long-range message-passing is one of the highlighted research topics in GNN literature. It would be better to discuss this line of work."
                },
                "questions": {
                    "value": "- As far as I know, there are many long-range message-passing modules designed for graph-structured data. Can you compare the proposed method with other long-range message-passing modules?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4407/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4407/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4407/Reviewer_4VzQ"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4407/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698842118625,
            "cdate": 1698842118625,
            "tmdate": 1699636414437,
            "mdate": 1699636414437,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jNARr73woI",
                "forum": "rvDQtdMnOl",
                "replyto": "h1tPYcwuou",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, they are exceedingly helpful for us to improve our paper. Our point-to-point responses to your comments are given below:\n\n> One major concern is regarding the novelty of the proposed long-range message-passing module. As far as I know, long-range message-passing is one of the highlighted research topics in GNN literature. It would be better to discuss this line of work. As far as I know, there are many long-range message-passing modules designed for graph-structured data. Can you compare the proposed method with other long-range message-passing modules?\n> \n\nRegarding the novelty you mentioned, our work is distinctly inspired by quantum chemistry principles. We introduce a fragmentation-based approach that divides large molecules into smaller subsystems to model their long-range interactions more efficiently and effectively. This is a simple and novel approach has demonstrated superior performance when implemented on various existing EGNNs.\n\nWe have thoroughly reviewed literature pertinent to long-range interactions, which is now included in our revised manuscript (Appendix A). A critical observation from our study is most existing networks would disrupt symmetry (SE(3) Equivariance, see Appendix J for more details) when directly applied to geometric graphs. This disruption could detrimentally impact performance. To demonstrate the efficacy of our proposed model, we performed comparative analyses against the SO3Karates[1], a specialized model designed for long-range interactions in molecular systems, incorporating hidden space rewiring techniques. Additionally, we benchmarked our model against an Equivariant Transformer. We employed a complete graph to effectively represent long-range interactions [2]. The outcomes of these comparative evaluations are detailed as follows:\n\n| Molecule |  | So3Karates | ViSNet-LSRM | Equivariant Transformer (Complete) |\n| --- | --- | --- | --- | --- |\n| Ac-Ala3-NhMe | Energy | 0.337 | **0.0654** | 4.535 |\n|  | Force | 0.244 | **0.0902** | 5.522 |\n| DHA | Energy | 0.379 | **0.0873** | 3.354 |\n|  | Force | 0.242 | **0.0598** | 4.095 |\n| Stachyose | Energy | 0.442 | **0.1055** | 5.531 |\n|  | Force | 0.435 | **0.0767** | 2.382 |\n| ATAT | Energy | 0.178 | **0.0722** | 7.523 |\n|  | Force | 0.216 | **0.0781** | 3.125 |\n| ATATCGCG | Energy | 0.345 | **0.1135** | 6.452 |\n|  | Force | 0.332 | **0.1063** | 3.235 |\n\nThe table shown above demonstrates that our proposed ViSNet-LSRM provides the best accuracy among all the baseline methods.\n\n\n\n\n[1]: Frank et al. So3krates: Equivariant attention for interactions on arbitrary length-scales in molecular systems. NeurIPS 2022.\n\n[2]: TorchMD-NET: Tholke et al. Equivariant Transformers for Neural Network based Molecular Potentials. ICLR 2022."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700324483761,
                "cdate": 1700324483761,
                "tmdate": 1700324483761,
                "mdate": 1700324483761,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uP7zvCta1w",
            "forum": "rvDQtdMnOl",
            "replyto": "rvDQtdMnOl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4407/Reviewer_cAHU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4407/Reviewer_cAHU"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new framework for machine learning of molecular dynamics, called Long-Short-Range Message-Passing (LSR-MP). LSR-MP combines short-range and long-range message passing on graphs to capture both local and non-local interactions in chemical and biological systems. LSR-MP uses a fragmentation-based method inspired by quantum chemistry to divide large molecules into smaller subsystems and model their long-range interactions efficiently and effectively. LSR-MP is implemented on top of an existing equivariant graph neural network (EGNN) called ViSNet, and achieves state-of-the-art results on large molecular datasets with fewer parameters and faster speed. LSR-MP is also applied to other EGNN models and shows consistent improvements, demonstrating its general applicability and robustness."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper presents a novel and elegant framework for long-short-range message passing on graphs, which can capture both local and non-local interactions in chemical and biological systems. \nThe paper draws inspiration from quantum chemistry and adopts a fragmentation-based method to divide large molecules into smaller subsystems and model their long-range interactions efficiently and effectively. This is a clever and creative way to overcome the computational and memory challenges of existing methods. The paper implements the proposed framework on top of an existing equivariant graph neural network (EGNN) called ViSNet, and demonstrates its superior performance on two large molecular datasets, MD22 and Chignolin. The paper shows that the proposed method achieves state-of-the-art results with fewer parameters and faster speed than the baselines, which is impressive and convincing.\nThe paper also applies the proposed framework to other EGNN models, such as PaiNN, ET, and Equiformer, and shows consistent improvements across different architectures and datasets. This demonstrates the general applicability and robustness of the proposed framework, and suggests that it can be easily integrated with other existing methods."
                },
                "weaknesses": {
                    "value": "The paper does not provide a clear analysis of the stability, and error bounds and how sensitive the performance of the method is to the choice of these modules and parameters."
                },
                "questions": {
                    "value": "Q1. How do you justify the choice of the LSR-MP framework as a generalization of the existing EGNNs? What are the advantages and limitations of this framework compared to other possible ways of incorporating long-range interactions, such as attention mechanisms, continuous filters, or Fourier features?\n\nQ2. How do you ensure the stability and accuracy of the BRICS fragmentation method for different types of molecules and systems? How sensitive is the performance of the LSR-MP framework to the choice of the fragmentation method and the number and size of the fragments?\n\nQ3. How do you evaluate the scalability and efficiency of the LSR-MP framework for larger and more complex molecular systems? What are the computational and memory costs of the LSR-MP framework, and how do they compare with the conventional quantum chemical methods and other machine learning methods? How do you handle the trade-off between accuracy and efficiency in the LSR-MP framework?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4407/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699451410770,
            "cdate": 1699451410770,
            "tmdate": 1699636414366,
            "mdate": 1699636414366,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2ztYQdw10K",
                "forum": "rvDQtdMnOl",
                "replyto": "uP7zvCta1w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, they are exceedingly helpful for us to improve our paper. Our point-to-point responses to your comments are given below:\n> The paper does not provide a clear analysis of the stability, and error bounds and how sensitive the performance of the method is to the choice of these modules and parameters.\n> \n\nThank you for your insightful feedback. We recognize the importance of a clear and detailed analysis in our manuscript. We have included a comprehensive sensitivity analysis in the main text and appendix of our manuscript. Specifically, it examines the impact of choices like the number of short-range layers (Figure 2), average fragment size (Figure 11), fragmentation methods (Table 7), and the cutoffs for short (Figure 2) and long-range interactions (Table 9), ablation of the proposed modules (Table 4). We also supplement the analysis on learning rate and batch size for ATATCGCG. We hope this provides a thorough analysis of our model's stability. If there are any other parameters you are interested in, feel free to post them here.\n\n| Batch Size | Energy MAE | Force MAE |\n| --- | --- | --- |\n| 4 | 0.1138 | 0.1065 |\n| 8 | 0.1135 | 0.1064 |\n| 16 | 0.1404 | 0.1224 |\n\n| Learning Rate | Energy MAE | Force MAE |\n| --- | --- | --- |\n| 1e-3 | 0.1422 | 0.1243 |\n| 4e-4 | 0.1135 | 0.1064 |\n| 1e-4 | 0.1492 | 0.1252 |\n\n> How do you justify the choice of the LSR-MP framework as a generalization of the existing EGNNs? What are the advantages and limitations of this framework compared to other possible ways of incorporating long-range interactions, such as attention mechanisms, continuous filters, or Fourier features? What are the advantages and limitations of this framework compared to other possible ways of incorporating long-range interactions, such as attention mechanisms, continuous filters, or Fourier features?\n> \n\nThe strength of our model lies in its superior accuracy and efficiency in characterizing long-range interactions. However, there are limitations within our framework. For instance, when using the MD22 dataset, it became evident that traditional fragmentation methods in quantum chemistry struggle with supramolecules. This necessitated the adoption of canonical clustering methods as an alternative.\n\nWe have thoroughly reviewed literature pertinent to long-range interactions, which is now included in our revised manuscript. It's important to clarify that directly applying most of these networks can **disrupt symmetry**, which could lead to poor performance on geometric graphs. To illustrate our model's capabilities, we conducted comparisons with a model tailored for characterizing long-range interactions in molecular systems: the SO3Karates [1], a method involving hidden space rewiring. Further, we compared our model with an Equivariant Transformer using a complete graph to capture long-range interactions [2]. The results of these comparisons are provided as follows:\n| Molecule |  | So3Karates | ViSNet-LSRM | Equivariant Transformer (Complete) |\n| --- | --- | --- | --- | --- |\n| Ac-Ala3-NhMe | Energy | 0.337 | **0.0654** | 4.535 |\n|  | Force | 0.244 | **0.0902** | 5.522 |\n| DHA | Energy | 0.379 | **0.0873** | 3.354 |\n|  | Force | 0.242 | **0.0598** | 4.095 |\n| Stachyose | Energy | 0.442 | **0.1055** | 5.531 |\n|  | Force | 0.435 | **0.0767** | 2.382 |\n| ATAT | Energy | 0.178 | **0.0722** | 7.523 |\n|  | Force | 0.216 | **0.0781** | 3.125 |\n| ATATCGCG | Energy | 0.345 | **0.1135** | 6.452 |\n|  | Force | 0.332 | **0.1063** | 3.235 |\n\nIt is evident that our proposed ViSNet-LSRM provides the best accuracy among all the baseline methods.\n\n[1]: Frank et al. So3krates: Equivariant attention for interactions on arbitrary length-scales in molecular systems. NeurIPS 2022.\n\n[2]: TorchMD-NET: Tholke et al. Equivariant Transformers for Neural Network based Molecular Potentials. ICLR 2022."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322742080,
                "cdate": 1700322742080,
                "tmdate": 1700439687018,
                "mdate": 1700439687018,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fPHltEron3",
                "forum": "rvDQtdMnOl",
                "replyto": "uP7zvCta1w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4407/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal (Cont'd)"
                    },
                    "comment": {
                        "value": "> Q2. How do you ensure the stability and accuracy of the BRICS fragmentation method for different types of molecules and systems? How sensitive is the performance of the LSR-MP framework to the choice of the fragmentation method and the number and size of the fragments?\n> \n\nIn response to your query, we generally apply the default settings of the BRICS method to most molecules. This approach serves as an effective starting point for optimal performance. We've also developed a strategy for merging to manage the fragment size, detailed in Appendix G. Additionally, we've included an analysis of the fragmentation method selection in Table 7. We've also discussed the performance sensitivity regarding the number and size of the fragments, which are included in the table shown below.\n\n| Average Fragment Size on AT-AT-CG-CG | Fragment Number | Force MAE | Energy MAE |\n| --- | --- | --- | --- |\n| w/o long range | NA | 0.1563 | 0.1995 |\n| k-means (8.43) | 14 | 0.1276 | 0.1246 |\n| 118.00  | 1 | 0.1488 | 0.1698 |\n| 23.60 | 5 | 0.1144 | 0.1384 |\n| 14.75 | 8 | 0.1096 | 0.1372 |\n| 8.43 | 14 | 0.1064 | 0.1135 |\n| 1.00 | 118 | 0.1496 | 0.1610 |\n\n> How do you evaluate the scalability and efficiency of the LSR-MP framework for larger and more complex molecular systems? What are the computational and memory costs of the LSR-MP framework, and how do they compare with the conventional quantum chemical methods and other machine learning methods? How do you handle the trade-off between accuracy and efficiency in the LSR-MP framework?\n> \n\nTo evaluate the scalability for larger and more complex molecular systems, we performed the following experiments:\n\n- **PubChem:** Our model was evaluated on the PubChem dataset (Appendix E.1), which includes molecules of varying sizes (40-100). We recalculated the dataset using the def2-tzvp basis set and b3lyp xc functional for accuracy, also integrating molecular force for informative signals. The training involved molecules with fewer than 60 atoms (30,545 samples), and testing those with more than 60 atoms (3,455 samples). Our results, shown below, indicate our model's superior scalability over the baseline ViSNet model, particularly for larger molecules.\n\n| PubChem | Energy | Force |\n| --- | --- | --- |\n| VisNet | 4.458 | 0.3303 |\n| VisNet - LSRM | 3.339 | 0.2395 |\n\nFor a formal investigation on scalability and efficiency, we conducted an analysis of the computational complexity. The results are displayed in the table shown below:\n\n| Method | Efficiency | Many-body | Long-range | Accuracy |\n| --- | --- | --- | --- | --- |\n| Ab initio Methods | $O(N^a m^b) [a \\geq 3, m = 2\\sim4]$ | \u2714\ufe0f | \u2714\ufe0f | Most Accurate |\n| Fragmentation Methods | $O(N) + O(N_{frag} (N/N_{frag})^a m^b) [a \\geq 3, m = 2\\sim4]$ | \u274c | \u2714\ufe0f | 1 - 5 kcal/mol |\n| EGNN | $O(N^a) [a = 1 \\sim 2]$ | \u2714\ufe0f | \u274c | Optimally < 1 kcal/mol |\n| EGNN + LSR-MP | $O(N^a) [a = 1 \\sim 2]$ | \u2714\ufe0f | \u2714\ufe0f | Optimally < 1 kcal/mol |\n\n$N$ number of atoms, $m$ number of basis. In particular, LSR-MP can well scale to larger bio molecules with minimal computational overhead when compared with quantum chemistry methods.\n\nIn considering the trade-off between accuracy and efficiency, our findings reveal that the utilization of LSR-MP (Long-Short Range Message Passing) significantly boosts accuracy while concurrently providing superior efficiency, as evidenced in Table 3. In practical implementations, we recommend using 4 to 6 layers of short-range and 2 layers of long-range message passing. This configuration provides the best balance between accuracy and efficiency."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4407/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700322951403,
                "cdate": 1700322951403,
                "tmdate": 1700734508453,
                "mdate": 1700734508453,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]