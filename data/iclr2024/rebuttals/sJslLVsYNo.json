[
    {
        "title": "Towards Understanding The Winner-Take-Most Behavior Of Neural Network Representations"
    },
    {
        "review": {
            "id": "otkX5s5agL",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8583/Reviewer_xKTf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8583/Reviewer_xKTf"
            ],
            "forum": "sJslLVsYNo",
            "replyto": "sJslLVsYNo",
            "content": {
                "summary": {
                    "value": "This paper studies a winner-take-most mechanisms in two-layer neural networks for a synthetic dataset S and aggregated MNIST, i.e., a neuron becomes more active (in terms of preactivtion) for one class, but becomes less active for the other class. They also show that neural networks seem to apply a divide-and-conquer strategy, where each neuron focuses on different patterns of the data. I believe the overall story makes sense, but the arguments are not sufficiently supported by empirical evidence."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The overall structure is clear with exhaustive literature review."
                },
                "weaknesses": {
                    "value": "Most empirical findings in this paper are qualitative (which is fine and good for illustrating your idea). To make big claims (winner-take-most, divide-and-conquer), quantitative metrics are needed to evaluate these effects. Although I feel obligated to suggest larger-scale experiments, I feel even the current setups are not fully studied yet. I'm happy to change my score if more in-depth experiments are carried out on your current datasets. See my questions below."
                },
                "questions": {
                    "value": "This paper centers around a key idea \"winner-take-most\"\n* Although I roughly get the idea and think it does make sense, its meaning seems reloaded multiple times. E.g., in Section 4.1 \"a winner-take-most mechanism: patterns with larger average pre-activations are pushed towards even larger pre-activations, while patterns with smaller pre-activations are pushed towards even smaller pre-activations.\" and in Section 4.2, \"A divideand-conquer approach, where different neurons focus on the classification of different clusters, is then perfectly compatible with the winner-take-most phenomenon.\". Are the two definitions equivalent? Is divide-and-conquer just a paraphrase of winner-take-most, or is one contained in the other?\n* The motivation of studying the winner-take-most mechanism is not clear and why it matters, especially given its subtlety (Section 4.2.1-4.2.3).\n* Section 4.2.4/4.2.5 read interesting, but feel incomplete. More experiments need to be carried out to characterize the phenomenon. For example, how to define a metric to quantify divide-and-conquer?\n\nMinor issues:\n* At the end of introduction, missing a period.\n* learning rate 3^{-3}, you mean 10^{-3}?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8583/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8583/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8583/Reviewer_xKTf"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8583/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697207445289,
            "cdate": 1697207445289,
            "tmdate": 1699637074075,
            "mdate": 1699637074075,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "sTyCvzZsbc",
            "forum": "sJslLVsYNo",
            "replyto": "sJslLVsYNo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8583/Reviewer_s4ij"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8583/Reviewer_s4ij"
            ],
            "content": {
                "summary": {
                    "value": "This paper delves into the \"winner-take-most\" dynamic observed in the representations learned by neural networks within binary classification tasks. It discusses how in such scenarios, one class tends to be represented with higher activation magnitudes, while the other is characterized by comparatively lower activations. The paper constructs synthetic data where the data points are the sum of binary masks with noise ($\\sigma_\\text{train}$). A pattern is a sum of 5 distinct binary masks and both classes contain an equal number of distinct and non-overlapping patterns. The model studies is a two-layer neural network that is trained with SGD on this synthetic dataset (setting 1) and also an MLP model trained with different hyperparameters on the MNIST dataset (setting 2).\n\nIn setting 1, the paper finds that the amount of noise in the training set has an important effect on the generalization performance of the model, and a moderate amount of $\\sigma_\\text{train}$ leads to the best generalization performance. They discovered that usually, the activation of one class's patterns will have large activations whereas the activation of the other class' patterns would have small activation (near 0). The paper then studies why this phenomenon occurs and identifies that multiple hidden units, non-linearity, and noise are needed for this \"winner-take-most\" effect to occur.\n\nThe paper then conjectures that the reason why this phenomenon occurs is due to the fact that there are \"difficult\" examples that are close to the other class due to noise. The representation of these difficult examples is first pushed away from the representation of the other examples of the same class (evidenced by the initially increased loss) and then pushed away from the representation of the other class.\n\nFinally, the paper explains the potential role of non-linearity and multiple neurons. The paper also discusses the relationship of the observed phenomena to other phenomena in the literature."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is fairly well-written and proposes several fairly interesting explanations for empirical phenomena.\n- The experimental setup of the paper is carefully designed and well-explained and the conclusions in the paper are presented fairly clearly. They are able to highlight some potential reasons behind the observed phenomena."
                },
                "weaknesses": {
                    "value": "While I find the experiments and proposals interesting, the main concern I have for the paper is that it is not clear to me how much of these conclusions carry to the real data and real architecture. I would be happy to increase my rating if the authors can show more evidence that the claims are really relevant for real models.\n\n- The study primarily relies on a synthetic dataset, raising questions about the applicability of its findings to real-world data and architectures. Experiments on the MNIST dataset already show behaviors that differ from the synthetic data, suggesting that the observations may not be generalizable. For example, I find it odd that the authors chose the Layca optimizer which is not a widely used optimizer. Further experimentation with different optimizers, such as SGD or Adam, particularly on more complex datasets like CIFAR10 (which wouldn't be too hard to run), could provide a clearer indication of the robustness of the conclusions.\n- The research is limited to binary classification. It is unclear how the findings would translate to multiclass problems where the activation dynamics are inherently more complex due to the difficulties of mapping all non-target classes to low magnitudes.\n- The paper\u2019s definition of example difficulty is exclusively tied to the model's initialization rather than the characteristics of the data itself, which seems to oversimplify real-world data complexity.\n- The link between the \"winner-take-most\" phenomenon and model generalization is not convincingly established. Without stronger empirical evidence, it is difficult to determine whether this is a genuine factor in generalization or merely a byproduct of other underlying factors. More empirical evidence could help clarify this relationship.\n\nOverall, while the paper presents interesting initial findings, its conclusions would be significantly strengthened by additional experiments that consider more realistic datasets, optimizers, and classification scenarios, as well as a more nuanced consideration of example difficulty and its implications for model generalization."
                },
                "questions": {
                    "value": "- What happens if you use a more realistic architecture (e.g., ResNet)? It seems to me that all of your analysis would easily be applicable to different architectures as long as it remains a binary classification. This would greatly strengthen my trust in the proposed mechanisms if they still hold.\n- can you apply this reasoning to non-last-layer activations? How does that affect the conclusion of your observations? How does your framework account for the effects of different architecture or features at different depths?\n- For the noise claim, can you show that it holds for real datasets and real architecture? \n- Similarly, for the non-linearity, can you show that it holds for real datasets and real architecture? What if you do not use ReLU but other activations?\n- I don't quite understand the explanation for \"Why does the mechanism affect a single class?\". This in my opinion is one of the most important observations in this paper. Can you provide a more detailed explanation and perhaps some illustrations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8583/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698608552187,
            "cdate": 1698608552187,
            "tmdate": 1699637073965,
            "mdate": 1699637073965,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "7Vqkw1f1Yu",
            "forum": "sJslLVsYNo",
            "replyto": "sJslLVsYNo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8583/Reviewer_u4t5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8583/Reviewer_u4t5"
            ],
            "content": {
                "summary": {
                    "value": "The paper aims to study the winner-take-most behavior of binary classification NNs by using a two-layer MLP and (mainly) a synthetic dataset with Gaussian noises (15 clusters per class) as well as the aggregated MNIST dataset. The paper presents preliminary results on the effect of training noises (Fig 1, 2), the emergence of the winner-take-most behavior (Fig 3, 6) and conditions when it disappears (Fig 4), then discusses the role of training difficulties (noises, Fig 5), ReLU, and number of hidden neurons on the winner-take-most behavior (Sec 4.2), finally cites previous works to support the generality of this paper (Sec 5)."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "+ [Clarity] The paper is overall easy to follow, although can be written more concisely."
                },
                "weaknesses": {
                    "value": "- [Originality] The winner-take-all property has been widely used in previous works such as NN-based clustering algorithms [1] and it\u2019s unclear how this paper contributes novelly to the understanding of this behavior with its extremely simplified settings, especially since most of the findings have been reported in previous works (Sec 5).\n- [Quality] The quality of the paper is unacceptable due to the following issues:\n1) The experimental setup is highly insufficient for a top-tier conference like ICLR, with overly simplified network, datasets and analyses (only scalar plots from single neurons instead of e.g. cluster analysis and/or visualization), leaving the results highly inconclusive.\n2) The observed winner-take-most (divide-and-conquer) behavior could be simply due to insufficient training as it contradicts the neural collapse theory [2] which predicts the opposite, the collapse of all intraclass clusters, leaving the main results highly questionable.\n3) Claiming that training noises are required for generalization on the synthetic dataset (Sec 3.1) is quite problematic, since sufficient training should generally lead to the max-margin solution (which generalizes) even without training noises [3]. The extremely large learning rate (1.0) could be causing the problem.\n- [Significance] Given the critical issues in the paper\u2019s originality and quality as stated above, it\u2019s unfortunately hard to conclude that this work is significant or sufficiently promising.\n\n[1] Clustering: A neural network approach, Neural networks, 2010.\\\n[2] Prevalence of neural collapse during the terminal phase of deep learning training, PNAS, 2020.\\\n[3] The Implicit Bias of Gradient Descent on Separable Data, JMLR, 2018."
                },
                "questions": {
                    "value": "Please address the weaknesses as much as possible."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8583/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699211286233,
            "cdate": 1699211286233,
            "tmdate": 1699637073858,
            "mdate": 1699637073858,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "1EjqxJhCEE",
            "forum": "sJslLVsYNo",
            "replyto": "sJslLVsYNo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8583/Reviewer_hMQT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8583/Reviewer_hMQT"
            ],
            "content": {
                "summary": {
                    "value": "The authors study the generalisation abilities of moderns neural network. To this end, they carry out analyses on model representations  of training data to differentiate between networks that have learned to generalise and networks that merely memorise. In an analysis of a small network, they discover a winner-takes most behaviour, where average pre-activation of the most activated patterns of a class increase and the average pre-activation of the least activated patterns decrease. Further, they find that a divide-and-conquer strategy, different neurons specialising on different class patterns in a classification problem."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper addresses an important problem in machine learning interpretability, representation learning/analysis and model behaviour to study generalisability. The methodology presents a clear and detailed analysis of representations on a toy classification dataset and comes to sound conclusions (winner-takes-most, divide and conquer).\n\nIt is well written and good to follow."
                },
                "weaknesses": {
                    "value": "Despite the soundness of the approach and detailed analyses, I am unsure about the novelty of this approach, as I find that related research is not sufficiently addressed. The NLP community has been producing a substantial body of work, and on different parts of (mostly transformer language) models: Some authors include Geva [1] (mostly on FF-Layers), Elena Voita (Attention mechanism) [2], follow-up work from David Bau, whom the authors cite with an older work (e.g., interpretability and model editing of factual knowledge in neurons [3]), and Anthropic's mechanistic interpretability [4]. As this research is on neuron representations of (textual) data in large language models I find it very important in the context of this work, and partially reminds me of winner-takes-most; except for an older paper from David Bau 2017, however, this is entirely missing from related work. Accordingly, I would encourage the authors to carefully study recent related work and also compare their work.\nFurthermore, the approach only studies a small network on a toy dataset, although it is carried out thoroughly. A quantitative evaluation of this work on real-world data from some of the works pointed out above could be one option to address this issue.\n\n[1] https://scholar.google.com/citations?user=GxpQbSkAAAAJ&hl=en\n[2] https://scholar.google.com/citations?user=EcN9o7kAAAAJ&hl=th\n[3] https://transformer-circuits.pub/2021/framework/index.html\n[4] https://arxiv.org/pdf/2202.05262.pdf"
                },
                "questions": {
                    "value": "How would a comparison, and evaluation in comparison to existing works a language models look like? How does your work relate to research in NLP?\n\nHow could your approach relate to and help in model pruning, which removes not useful and unused neurons (see, e.g., [1]), and also knowledge distillation methods [2]?\n\n[1] https://aclanthology.org/P19-1580/\n[2] https://aclanthology.org/2023.acl-long.818"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8583/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8583/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8583/Reviewer_hMQT"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8583/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699433671252,
            "cdate": 1699433671252,
            "tmdate": 1699637073755,
            "mdate": 1699637073755,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]