[
    {
        "title": "Dual-Balancing for Multi-Task Learning"
    },
    {
        "review": {
            "id": "wiosDoA74B",
            "forum": "8FhwHJGUPZ",
            "replyto": "8FhwHJGUPZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_8dJR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_8dJR"
            ],
            "content": {
                "summary": {
                    "value": "The paper tackles the problem of multi-task learning by proposing a dual-balancing strategy in the hard shared paradigm. For the task-shared parameters, gradients from different tasks are normalized to the maximum norm. For the task-specific parameters, logarithm transformations are applied to the loss so that all losses have similar scales. Ablation studies show that each of the proposed strategies can enhance other complementary methods. Besides, combining the two balancing can surpass all previous methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper proposes two novel strategies in the context of hard parameter sharing multi-task learning, one for gradient balancing and the other for loss balancing, which are well-motivated and easy to follow.\n2. For each of the two strategies, it can boost other complementary methods when integrated, showing the general applicability.\n3. The authors conduct extensive experiments on scene understanding, image classification and molecular property prediction to show the effectiveness of the dual-balancing strategy."
                },
                "weaknesses": {
                    "value": "1. It would be better to compare the training time efficiency of each method.\n2. More discussions can be made on the proposed method, such that the stability, e.g. will the balancing method cause the model to collapse during training?"
                },
                "questions": {
                    "value": "The authors could provide the training dynamics (both loss and gradient) such that readers can better understand how the balancing strategy affects the model learning."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3130/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3130/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3130/Reviewer_8dJR"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3130/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698470653367,
            "cdate": 1698470653367,
            "tmdate": 1699636260085,
            "mdate": 1699636260085,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3uowiuPSWV",
                "forum": "8FhwHJGUPZ",
                "replyto": "wiosDoA74B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 8dJR"
                    },
                    "comment": {
                        "value": "Thanks for your thoughtful review and valuable feedback. We address your concerns as follows.\n\n---\n\n> Q1: It would be better to compare the training time efficiency of each method.\n\n**A1**: As suggested, we provided the comparison of training efficiency for all methods in Figure 7 of the updated paper (Appendix C.4). We can see that the proposed DB-MTL is as efficient as existing gradient balancing methods since all task gradients are computed in every iteration (Line 6 in Algorithm 1 of the paper).\n\n---\n\n> Q2: More discussions can be made on the proposed method, such that the stability, e.g. will the balancing method cause the model to collapse during training?\n\n**A2**: As suggested, we conducted an empirical analysis on the training stability of DB-MTL. Figure 8 (in Appendix C.5 of the updated paper) shows the curves of training loss and gradient norm for EW and DB-MTL on tasks of the *Office-31* dataset. As can be seen, DB-MTL converges as smoothly as EW, suggesting the proposed balancing methods do not affect the training stability.\n\n---\n\n> Q3: The authors could provide the training dynamics (both loss and gradient) such that readers can better understand how the balancing strategy affects the model learning.\n\n**A3**: We provided the training dynamics, including the training loss and gradient norm during the training process in Appendix C.5 of the updated paper. We can see that DB-MTL, which balances tasks across both loss and gradient levels, converges faster than EW."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700460101462,
                "cdate": 1700460101462,
                "tmdate": 1700460101462,
                "mdate": 1700460101462,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tH0NlPtLMY",
                "forum": "8FhwHJGUPZ",
                "replyto": "wiosDoA74B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Reviewer_8dJR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Reviewer_8dJR"
                ],
                "content": {
                    "comment": {
                        "value": "Thank the authors for the rebuttal. I would keep my original rating."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700578145555,
                "cdate": 1700578145555,
                "tmdate": 1700578145555,
                "mdate": 1700578145555,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OkeHOwcoEe",
            "forum": "8FhwHJGUPZ",
            "replyto": "8FhwHJGUPZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_SooC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_SooC"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a fairly simple but effective multi-task optimisation strategy with two key components: i) Optimising on log loss for scale balancing; and ii) applying l2-normalisation on aggregated gradients via EMA for gradient balancing. Each component can actually be combined with existing multi-task optimisation strategies, and have shown improved performance to validate the effectiveness. The paper presents experiments in standard multi-task learning benchmarks on dense prediction tasks, image classification tasks and molecular property prediction tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tIdea is clean and simple and can be universally applied in many multi-task learning optimisation strategies.\n2.\tExperiments are well-rounded and covered in many settings and domains.\n3.\tAblation shows the importance of each design component, presenting gradient-magnitude-balancing possibly is more important than loss-scale balancing."
                },
                "weaknesses": {
                    "value": "No prominent weaknesses. See questions."
                },
                "questions": {
                    "value": "1.\tSince each design component shows to be effective and useful for existing multi-task optimisation strategy, I think it\u2019s important to highlight DB could be considered as a drop-in enhancement to existing multi-task methods to further improve performance. \n2.\tFrom the algorithm 1, it looks like the method should be able to run very fast, as similar to standard weight-based methods. Maybe it\u2019s also useful to highlight its running speed, comparing to other gradient-based methods such as CAGrad, Nash-MTL which take considerably longer training time.\n3.\tIt might be also interesting to see whether DB could also enhance auxiliary learning methods, such as AuxiLearn (Navon et al 2021), GCS (Du et al 2018) and Auto-Lambda (Liu et al 2022). This could further emphasise the design benefits and may approach even wider range of audiences."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3130/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698630789072,
            "cdate": 1698630789072,
            "tmdate": 1699636259990,
            "mdate": 1699636259990,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KGlM8FtxFz",
                "forum": "8FhwHJGUPZ",
                "replyto": "OkeHOwcoEe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer SooC"
                    },
                    "comment": {
                        "value": "Thanks for your thoughtful review and valuable feedback. We address your concerns as follows.\n\n---\n\n> Q1: Since each design component shows to be effective and useful for existing multi-task optimisation strategy, I think it\u2019s important to highlight DB could be considered as a drop-in enhancement to existing multi-task methods to further improve performance.\n\n**A1**: Thanks for your suggestions. We revised the paper accordingly to highlight the logarithm transformation is beneficial to existing gradient balancing methods in the contribution and conclusion parts.\n\n---\n\n> Q2: From the algorithm 1, it looks like the method should be able to run very fast, as similar to standard weight-based methods. Maybe it\u2019s also useful to highlight its running speed, comparing to other gradient-based methods such as CAGrad, Nash-MTL which take considerably longer training time.\n\n**A2**: As suggested, we added the running time for all methods in Figure 7 of the update paper (Appendix C.4). We can see that the proposed DB-MTL runs as fast as previous gradient balancing methods since all task gradients are required to compute at every iteration (Line 6 in Algorithm 1 of the paper).\n\n---\n\n> Q3: It might be also interesting to see whether DB could also enhance auxiliary learning methods, such as AuxiLearn (Navon et al 2021), GCS (Du et al 2018) and Auto-Lambda (Liu et al 2022). This could further emphasise the design benefits and may approach even wider range of audiences.\n\n**A3**: The goals of multi-task learning and auxiliary learning are different: the former expects all tasks to perform well but the latter only focuses on the main task(s). Hence, it is challenging to apply our balancing methods to auxiliary learning directly. We added discussions on the mentioned papers in Appendix D."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700460082328,
                "cdate": 1700460082328,
                "tmdate": 1700460082328,
                "mdate": 1700460082328,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NpnvRNyP3P",
                "forum": "8FhwHJGUPZ",
                "replyto": "KGlM8FtxFz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Reviewer_SooC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Reviewer_SooC"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks for the response and additional evaluations. I believe these additional analyses have resolved all my concerns. I have no other questions and would love to maintain my original rating as weak accept."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700587984174,
                "cdate": 1700587984174,
                "tmdate": 1700587984174,
                "mdate": 1700587984174,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1F8FCdUNjO",
            "forum": "8FhwHJGUPZ",
            "replyto": "8FhwHJGUPZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_gC4S"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_gC4S"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a dual-balancing multi-task learning (DB-MTL) method to alleviate the task-balancing problem in multi-task learning (MTL). DB-MLT attempts to combine a loss-scale balancing and a gradient-magnitude balancing. Specifically, the former performs a logarithm transformation on each task loss to ensure all losses have the same scale. The latter normalizes the gradients of all tasks to have the same magnitude as the maximum gradient norm. This guarantees the gradients contribute equally. Combining the two methods, DB-MTL achieves state-of-the-art performance on several MTL benchmark datasets, including scene understanding, image classification, and molecular property prediction. Ablation studies demonstrate both the loss-scale and gradient-magnitude balancing components are effective."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The method is well-motivated. Experiments on various datasets demonstrate state-of-the-art performance. Ablations validate the efficacy of each component.\n- The dual-balancing framework is reasonable. The loss-scale balancing via logarithmic transformation helps existing gradient methods. Normalizing gradients by the maximum norm is simple yet effective.\n- The problem setup and methods are clearly explained."
                },
                "weaknesses": {
                    "value": "- The novelty of this paper is limited. Loss and gradient balance have been extensively explored, and this paper does not have any new technical insights. It is only a combination of the existing works.\n- The theoretical analysis is not sufficient to suppor the advantage of the proposed method. Proving convergence guarantees or other theoretical properties of DB-MTL could reveal more advantages over existing methods.\n- Detailed experimental analyzing on why DB-MTL outperforms certain baselines is missing.\n- The discription of the intuition is not clear."
                },
                "questions": {
                    "value": "- Can you provide any theoretical analysis for DB-MTL? Convergence guarantees or other properties could reveal advantages over existing methods.\n- For the loss transformation, is there an adaptive way to estimate the scale? Using the maximum seems to work well, but a learned loss scale could be interesting."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3130/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3130/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3130/Reviewer_gC4S"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3130/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839261534,
            "cdate": 1698839261534,
            "tmdate": 1699636259915,
            "mdate": 1699636259915,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "u8sCbfC8JO",
                "forum": "8FhwHJGUPZ",
                "replyto": "1F8FCdUNjO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer gC4S (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your thoughtful review and valuable feedback. We address your concerns as follows.\n\n----\n\n> Q1: The novelty of this paper is limited. Loss and gradient balance have been extensively explored, and this paper does not have any new technical insights. It is only a combination of the existing works.\n\n**A1:** This paper aims to alleviate the task balancing problem from loss and gradient perspectives. The proposed method is simple yet effective and largely outperforms baselines on five datasets.\n\n(i) As discussed in Section 3.1 of the submission, \nlogarithm transformation is only used as a baseline studied in Nash-MTL and its advantages for MTL methods are **NOT** researched there. In our paper, we conducted extensive experiments to show that logarithm transformation is beneficial to various MTL methods. As shown in Figure 1 of the submission, MTL methods integrated with logarithm transformation can boost performance by a large margin. The effectiveness of combining logarithm transformation with MTL methods, **one of our major contributions**, is useful for the MTL community.\n\n(ii) As discussed in Section 3.2 of the submission, the proposed gradient balancing method is different from GradNorm: firstly, GradNorm cannot guarantee all task gradients to have the same magnitude in each iteration since it updates the model parameters and task weights alternately; secondly, GradNorm does not consider the effect of the update magnitude (i.e., $\\alpha_k$ in our paper), which significantly affects the performance (as shown in Figures 4 and 6 in our paper).\n\nWe are the **first** to propose normalizing task gradients to the same magnitude as the maximum gradient norm, and extensively experimental results (like Figure 3, Tables 1 and 6 in the submission) show it achieves better performance than GradNorm and other gradient balancing methods, which is **one of our major contributions**.\n\n(iii) Logarithm transformation and the proposed gradient normalization are two **simple but effective** techniques, which are complementary and can be simply combined together as the proposed DB-MTL. Compared with IMTL, which is complex in learning weights for balancing both losses and gradients, DB-MTL is simpler and more effective (Tables 1, 2, 3, 4, and 5 in the submission). Furthermore, by a simple combination, DB-MTL achieves state-of-the-art performance on various datasets, which is our primary contribution.\n\n(iv) Recent works [1, 2] have conducted extensive experiments to demonstrate the most simple method, equal weighting (EW in our paper), can perform comparably or even better than many complex multi-task/multi-objective methods via tuning some hyperparameters (like the learning rate) in [1] or using some regularization and stabilization techniques in [2]. Hence, we believe proposing simple but effective methods for the MTL field is useful.\n\n---\n\n> Q2: The theoretical analysis is not sufficient to support the advantage of the proposed method. Proving convergence guarantees or other theoretical properties of DB-MTL could reveal more advantages over existing methods.\n\n> Can you provide any theoretical analysis for DB-MTL? Convergence guarantees or other properties could reveal advantages over existing methods.\n\n\n**A2**: As mentioned in our reply to Q1, recent works [1, 2] have conducted extensive experiments to demonstrate the performance of the existing MTL methods are unsatisfactory, although some of them have convergence guarantees. Besides, as discussed in MoCo [3], many MTL methods (like MGDA, PCGrad, CAGrad, etc.) provide the convergence analysis in the deterministic case but they are stochastic algorithms in practice. Although MoCo has a convergence guarantee in the practice stochastic setting, its performance is worse than the proposed DB-MTL (results are reported in Tables 1-5 in the submission). Hence, we believe that it is more important to propose an effective method for the current MTL field. In our paper, extensive experiments on five datasets consistently show that the proposed DB-MTL achieves better performance than existing methods. We will conduct the challenging theoretical analysis in the future."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700460039136,
                "cdate": 1700460039136,
                "tmdate": 1700460039136,
                "mdate": 1700460039136,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hYD5dLzxZy",
                "forum": "8FhwHJGUPZ",
                "replyto": "1F8FCdUNjO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer gC4S (2/2)"
                    },
                    "comment": {
                        "value": "> Q3: Detailed experimental analyzing on why DB-MTL outperforms certain baselines is missing.\n\n**A3**: In the submission, we have conducted extensive experiments on various datasets and provided analysis to demonstrate the superiority of DB-MTL over a large number of baselines. As shown in Tables 1-5, DB-MTL achieves state-of-the-art performance on all five datasets. This is attributed to \n\n(i) Logarithm transformation is a simple but effective loss balancing method. As shown in Figure 1 in the submission, integrating logarithm transformation into various gradient balancing methods boosts the performance largely. Moreover, logarithm transformation is more effective than IMTL-L (Figure 2 in the submission).\n\n(ii) Our gradient-magnitude balancing method is more effective than the existing gradient normalization method (i.e., GradNorm), as shown in Figure 3 of the submission.\n\n(iii) The ablation study in Section 4.4 demonstrates the effectiveness of using loss-scale balancing, gradient-magnitude balancing, and combining them together.\n\n---\n\n> Q4: The discription of the intuition is not clear.\n\n**A4**: We suppose the reviewer asks clarification for the intuition of the choice of $\\alpha_k$. We further clarify it as follows.\n\n(i) When some tasks have large gradient norms and others have small gradient norms, the model $\\theta_k$ is close to a point where the former tasks have not yet converged while the latter tasks have converged. This point is unsatisfactory in MTL, as we hope all tasks achieve convergence. If we use the min-norm strategy, the model will be caught by such a point. Hence, a large $\\alpha_k$ is more suitable to escape the unsatisfactory point, and the max-norm strategy is adopted.\n\n(ii) When all task gradient norms are small, the model $\\theta_k$ is close to a stationary point of all tasks (which is a satisfactory solution in MTL). Even using the max-norm strategy, the $\\alpha_k$ is small as all task gradient norms are small. Hence, the model does NOT escape the stationary point. \n\n---\n\n> Q5: For the loss transformation, is there an adaptive way to estimate the scale? Using the maximum seems to work well, but a learned loss scale could be interesting.\n\n**A5**: As discussed in Section 3.1 of the submission, previous works (e.g., IMTL-L) attempt to learn loss scales by **approximately** solving an optimization problem by one-step gradient descent at every iteration. Our Proposition A.1 in Appendix shows the logarithm transformation is equivalent to IMTL-L when the optimization problem is solved **exactly**. Hence, the loss transformation is better than IMTL-L in solving an optimization problem of learning loss scales. Experimental results (Figure 2 in the submission) show that logarithm transformation is more effective than IMTL-L.\n\n---\n\n**References**\n\n[1] Kurin et al. In Defense of the Unitary Scalarization for Deep Multi-Task Learning. In *Neural Information Processing Systems*, 2022.\n\n[2] Xin et al. Do Current Multi-Task Optimization Methods in Deep Learning even Help? In *Neural Information Processing Systems*, 2022.\n\n[3] Fernando et al. Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach. In *International Conference on Learning Representations*, 2023."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700460057803,
                "cdate": 1700460057803,
                "tmdate": 1700460057803,
                "mdate": 1700460057803,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mFJcbudwu2",
                "forum": "8FhwHJGUPZ",
                "replyto": "1F8FCdUNjO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Have our reply addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer gC4S,\n\nThank you again for your detailed reviews. We have responded to your comments in the above reply and we hope that our reply has satisfactorily addressed your concerns.\n\nIf there is any additional explanation or experiments that can save the reviewer\u2019s time to understand our paper and clarify the concerns, we will be more than happy to do so.\n\nBest,\n\nThe authors"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661981558,
                "cdate": 1700661981558,
                "tmdate": 1700661981558,
                "mdate": 1700661981558,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "8bj6qxTHVq",
            "forum": "8FhwHJGUPZ",
            "replyto": "8FhwHJGUPZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_H1EY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_H1EY"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a straightforward Dual-Balancing Multi-Task Learning (DB-MTL) method with well-conducted experiments across multiple datasets. The method alleviate the task balancing problem by using logarithmic transformation for loss-scale balancing and normalizing gradients to the same magnitude for gradient-magnitude balancing."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. **Simplicity of the Method:** The loss-scale balancing and the gradient-magnitude balancing of the approach are both commendably straightforward.\n2. **Sufficient and Effective Experiments:** The paper demonstrates the effectiveness of DB-MTL through extensive validation across three distinct scenarios and five datasets. The proposed method is optimal on all datasets."
                },
                "weaknesses": {
                    "value": "1. **Imprecise Overview of the MTL Objective:** The MTL objective (Equation 1) in Section 2 is imprecise. It is applicable primarily to existing loss balancing and certain gradient balancing methods. For example, in some gradient balancing methods like PCGrad and CAGrad, the weights of task-specific parameters are all 1, and in all hybrid balancing methods, the weights of task-specific and task-shared parameters are different.\n2. **Omission of Relevant Literature:**   (1) The DB-MTL method, albeit not defined as such within the text, is one of hybrid balancing methods. However, the treatment of hybrid balancing in Section 2 is overly simplistic and lacks a formal definition, along with an inadequate reference to relevant literature. For instance, approaches like RLW, Auto-\u03bb[1] and IGB[2] have also conducted exploratory work combining loss balancing and gradient balancing.    (2) In the discussion part of Section 3.1, IGB[2] has also studied the logarithm transformation and has further extended it into a new loss balancing paradigm.\n3. **Lack of Novelty:** The proposed loss balancing method, as well as the combination of loss and gradient balancing, have been previously discussed and experimented in prior works.\n4. **Lack of Theoretical Analysis:** Though the proposed method is easy to understand intuitively, it lacks theoretical understanding about why the proposed gradient balancing is beneficial for the overall MTL objective. In terms of gradients, the primary factor affecting the MTL performance is gradient conflicts, specifically the conflicts in gradient directions. The discrepancy in the magnitude of gradients does not lead to performance degradation if their directions are aligned. How does the proposed gradient balancing method directly or indirectly mitigate the conflicts in gradient directions? Are there any theoretical analyses, empirical experiments (maybe toy examples), or even intuitive explanations?\n5. **Fairness of Comparative Experiments:** Combining loss balancing and gradient balancing is beneficial. Thus, directly comparing MB-MTL with existing gradient balancing methods might introduce unfairness. In the image classification scenario, when only the proposed gradient-magnitude balancing is employed, the performance is not optimal within gradient balancing methods (NashMTL yields better results). Would combining logarithmic transformation with NashMTL surpass MB-MTL?\n\n[1] Auto-\u03bb: Disentangling Dynamic Task Relationships. TMLR, 2022.\\\n[2] Improvable Gap Balancing for Multi-Task Learning. UAI, 2023."
                },
                "questions": {
                    "value": "See my comments in Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3130/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698960504502,
            "cdate": 1698960504502,
            "tmdate": 1699636259852,
            "mdate": 1699636259852,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9JGqSToIDP",
                "forum": "8FhwHJGUPZ",
                "replyto": "8bj6qxTHVq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer H1EY (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful review and valuable feedback. We address your concerns as follows.\n\n---\n\n> Q1: Imprecise Overview of the MTL Objective: The MTL objective (Equation 1) in Section 2 is imprecise. It is applicable primarily to existing loss balancing and certain gradient balancing methods. For example, in some gradient balancing methods like PCGrad and CAGrad, the weights of task-specific parameters are all 1, and in all hybrid balancing methods, the weights of task-specific and task-shared parameters are different.\n\n**A1**: We have revised Section 2 for clarification:\n\n(i) In the \"Loss Balancing Methods\" paragraph: For loss balancing methods, the task weight $\\gamma_t$ affects both the update of both task-sharing parameter $\\theta$ and task-specific parameter $\\psi$.\n\n(ii) In the \"Gradient Balancing Methods\" paragraph: For most gradient balancing methods (e.g., PCGrad, CAGrad, MoCo, GradDrop, and IMTL), the task weight $\\gamma_t$ affects the update of task-sharing parameter $\\theta$ only. In some gradient balancing methods (e.g., GradNorm, MGDA, and Nash-MTL), task weight $\\gamma_t$ plays the same role as in loss balancing methods.\n\n(iii) In the \"Hybrid Balancing Methods\" paragraph: For hybrid balancing methods, the task weight $\\gamma_t$ is the product of loss and gradient balancing weights.\n\n---\n\n> Q2: Omission of Relevant Literature: (1) The DB-MTL method, albeit not defined as such within the text, is one of hybrid balancing methods. However, the treatment of hybrid balancing in Section 2 is overly simplistic and lacks a formal definition, along with an inadequate reference to relevant literature. For instance, approaches like RLW, Auto-$\\lambda$[1] and IGB[2] have also conducted exploratory work combining loss balancing and gradient balancing. (2) In the discussion part of Section 3.1, IGB[2] has also studied the logarithm transformation and has further extended it into a new loss balancing paradigm.\n\n**A2**: (i) Combining loss balancing and gradient balancing is first proposed in IMTL (as discussed in Related Work in the submission), while the mentioned three follow-up works (RLW, Auto-$\\lambda$ [1], and IGB [2]) combine their balancing methods with some existing loss/gradient balancing methods. We have added the discussion in Section 2 of the updated paper.\n\n(ii) We have revised Section 3.1 accordingly by adding a discussion with IGB. (1) IGB combines the logarithm transformation with **loss** balancing methods to achieve better performance. In our paper, we demonstrate that logarithm transformation benefits existing **gradient** balancing methods, which is a contribution complementary to the exploration in the IGB paper. (2) Furthermore, IGB does not clearly explain why the logarithm transformation can work well. We show that it can address the loss scale problem in multi-task learning.\n\n(iii) We have added IGBv2 as a baseline and compared it with our DB-MTL on five benchmark datasets. As shown in Tables 1-5 of the updated paper, DB-MTL consistently outperforms IGBv2.\n\n---\n\n> Q3: Lack of Novelty: The proposed loss balancing method, as well as the combination of loss and gradient balancing, have been previously discussed and experimented in prior works.\n\n**A3**: (i) The logarithm transformation is one of the components of our proposed DB-MTL, but we do not claim it is proposed in this paper. As discussed in Section 3.1 of the submission, logarithm transformation is only used as a baseline studied in Nash-MTL. Although IGB combines the logarithm transformation with loss balancing methods to achieve better performance, IGB also does not clearly explain why the logarithm transformation can work well. In our paper, we show that the logarithm transformation can address the loss scale problem in multi-task learning, which has not been studied in previous works. Besides, we conduct extensive experiments to show that logarithm transformation is beneficial to existing gradient balancing methods, which is a contribution complementary to the exploration in the IGB paper. As shown in Figure 1 of the submission, existing gradient balancing methods integrated with logarithm transformation can boost performance by a large margin. The effectiveness of combining logarithm transformation with gradient balancing methods, **one of our major contributions**, is useful for the MTL community.\n\n(ii) Logarithm transformation and the proposed gradient normalization are two **simple but effective** techniques, which are complementary and can be simply combined together as the proposed DB-MTL. Compared with IMTL, which is complex in learning weights for balancing both losses and gradients, DB-MTL is simpler and more effective (Tables 1, 2, 3, 4, and 5 in the submission). Furthermore, by a simple combination, DB-MTL achieves state-of-the-art performance on various datasets, which is our primary contribution."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700459973785,
                "cdate": 1700459973785,
                "tmdate": 1700459973785,
                "mdate": 1700459973785,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "37qxlUTKFi",
                "forum": "8FhwHJGUPZ",
                "replyto": "8bj6qxTHVq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer H1EY (2/2)"
                    },
                    "comment": {
                        "value": "> Q4: Lack of Theoretical Analysis: Though the proposed method is easy to understand intuitively, it lacks theoretical understanding about why the proposed gradient balancing is beneficial for the overall MTL objective. In terms of gradients, the primary factor affecting the MTL performance is gradient conflicts, specifically the conflicts in gradient directions. The discrepancy in the magnitude of gradients does not lead to performance degradation if their directions are aligned. How does the proposed gradient balancing method directly or indirectly mitigate the conflicts in gradient directions? Are there any theoretical analyses, empirical experiments (maybe toy examples), or even intuitive explanations?\n\n**A4**: (i) Recent works [3, 4] have conducted extensive experiments to demonstrate the performance of the existing MTL methods are unsatisfactory. Hence, we believe that it is more important to propose an effective method for the current MTL field. In our paper, extensive experiments on five datasets consistently show that the proposed DB-MTL achieves better performance than existing methods. We will conduct the challenging theoretical analysis in the future. \n\n(ii) Intuitively, both gradient-magnitude discrepancies and gradient-direction conflicts can affect the MTL performance, but which one is more crucial is open. A very recent work [5] observes that the negative transfer and gradient-direction conflicts are not strongly correlated. Our experimental results show that the proposed gradient balancing method (i.e., simply normalizing all gradients as the maximum-norm one) is more effective than previous complex gradient manipulating methods like eliminating gradient-direction conflicts in PCGrad. Thus, it seems that gradient-direction conflicts are not crucial to mitigating negative transfer in MTL. This problem is still open.\n\n\\begin{array}{lccccc}\\hline& \\text{\\textit{NYUv2}} & \\text{\\textit{Cityscapes}} & \\text{\\textit{Office-31}} & \\text{\\textit{Office-Home}} & \\text{\\textit{QM9}} \\newline\\hline\\text{PCGrad} & -1.57_{\\pm0.44} & -2.36_{\\pm1.17} & -0.68_{\\pm0.57} & -1.04_{\\pm0.32} & -117.8_{\\pm3.97} \\newline\\text{GradVac} & -1.75_{\\pm0.39} & -2.45_{\\pm0.54} & -0.58_{\\pm0.78} & -1.49_{\\pm0.28} & -150.7_{\\pm7.41} \\newline\\text{gradient-magnitude balancing (\\textbf{ours})} & \\mathbf{+0.76}\\_{\\pm0.25} & \\mathbf{+0.12}\\_{\\pm0.70} & \\mathbf{+0.01}\\_{\\pm0.39} & \\mathbf{-0.78}\\_{\\pm0.49} & \\mathbf{-65.73}\\_{\\pm2.86} \\newline\\hline\\end{array}\n\n---\n\n> Q5: Fairness of Comparative Experiments: Combining loss balancing and gradient balancing is beneficial. Thus, directly comparing MB-MTL with existing gradient balancing methods might introduce unfairness. In the image classification scenario, when only the proposed gradient-magnitude balancing is employed, the performance is not optimal within gradient balancing methods (NashMTL yields better results). Would combining logarithmic transformation with NashMTL surpass MB-MTL?\n\n**A5**: As suggested, we conducted additional experiments on image classification scenarios (*Office-31* and *Office-Home*) to compare \"Nash-MTL + logarithm transformation\" with DB-MTL. The table below shows the results. As can be seen, DB-MTL performs better. Moreover, integrating logarithm transformation into Nash-MTL is better than  Nash-MTL. Furthermore, on *NYUv2*, *Cityscapes*, and *QM9* datasets, the proposed gradient-magnitude balancing method (the 3rd row of Table 6 in the submission) outperforms existing gradient balancing methods (results are reported in Tables 1, 2, and 5 of the submission).\n\n\\begin{array}{lcc}\\hline &\\text{\\textit{Office-31}} & \\text{\\textit{Office-Home}} \\newline\\hline\\text{Nash-MTL} & +0.24_{\\pm0.89} & -0.08_{\\pm0.69} \\newline\\text{Nash-MTL+Log} & +0.71_{\\pm0.44} & +0.06_{\\pm0.38} \\newline\\text{DB-MTL (\\textbf{ours})} & \\mathbf{+1.05}\\_{\\pm0.20} & \\mathbf{+0.17}\\_{\\pm0.44} \\newline\\hline\\end{array}\n\n----\n\n**References**\n\n[1] Liu et al. Auto-Lambda: Disentangling Dynamic Task Relationships. *Transactions on Machine Learning Research*, 2022.\n\n[2] Dai et al. Improvable Gap Balancing for Multi-Task Learning. In *Uncertainty in Artificial Intelligence*, 2023.\n\n[3] Kurin et al. In Defense of the Unitary Scalarization for Deep Multi-Task Learning. In *Neural Information Processing Systems*, 2022.\n\n[4] Xin et al. Do Current Multi-Task Optimization Methods in Deep Learning even Help? In *Neural Information Processing Systems*, 2022.\n\n[5] Jiang et al. ForkMerge: Mitigating Negative Transfer in Auxiliary-Task Learning. In *Neural Information Processing Systems*, 2023."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700460010163,
                "cdate": 1700460010163,
                "tmdate": 1700460010163,
                "mdate": 1700460010163,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MwtzvS2PYS",
                "forum": "8FhwHJGUPZ",
                "replyto": "8bj6qxTHVq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Have our reply addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer H1EY,\n\nThank you again for your detailed reviews. We have responded to your comments in the above reply and we hope that our reply has satisfactorily addressed your concerns.\n\nIf there is any additional explanation or experiments that can save the reviewer\u2019s time to understand our paper and clarify the concerns, we will be more than happy to do so.\n\nBest,\n\nThe authors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661962523,
                "cdate": 1700661962523,
                "tmdate": 1700661962523,
                "mdate": 1700661962523,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zPTw3xhg3P",
            "forum": "8FhwHJGUPZ",
            "replyto": "8FhwHJGUPZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_PmP7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3130/Reviewer_PmP7"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a method to tackle the task-balancing problem in multi-task learning called Dual-Balancing Multi-Task Learning (DB-MTL). The work is grounded on the observation that differences in loss scales and gradient magnitudes across different tasks could negatively impact the performance of some tasks. The DB-MTL method is designed to balance these aspects at both the loss and gradient levels. It involves a logarithmic transformation on each task loss to ensure uniform scale, which is shown to also benefit existing gradient balancing techniques. Moreover, it also includes the normalization of all task gradients to the same magnitude to ensure respective uniformity. The researchers found that setting this magnitude as the maximum gradient norm yields the best performance. Comprehensive experiments have been performed on several benchmark datasets, and the results suggest that DB-MTL can achieve state-of-the-art performance. The primary contributions include the proposal of the DB-MTL method, empirical evidence of its effectiveness, and an illustration of the advantage of combining loss-scale balancing with gradient balancing."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Quality: The authors execute extensive experiments which support their conclusions. The postulations and the experimental results correlate well, strengthening the paper\u2019s credibility. \n\nClarity: The paper is well-written and very easy to understand.\n\nOriginality: The maximum-norm strategy in Section 3.2  has some novelty."
                },
                "weaknesses": {
                    "value": "There is a significant lack of novelty in the presented techniques. The first part discusses scale-balancing loss transformation, which utilizes the common method of applying a log transformation to loss. This technique has already been mentioned by Nash-MTL and therefore doesn't contribute anything substantially new to the field.\nThe second section of the method, gradient normalization, is a modification of the GradNorm technique. The presented maximum-norm strategy essentially ensures all small-task gradients have the same norm as the task with the greatest gradient. While this may present an interesting approach, it is not substantially innovative. The final part of the paper brings together the previous two parts, but again, this combination doesn't present any great novelty or challenges. Consequently, the paper\u2019s primary contribution is the maximum-norm strategy, which is not significant enough.\n\nFrom the writing perspective, this paper reads more like a technical report or experiment report, where effective methods from previous work are summarized, but with few unique thoughts proposed.\n\nFrom an experimental perspective, the explanation of the maximum-norm strategy in section 3.2 lacks experimental support and could benefit from visual analysis. For example, the authors could investigate how using different alpha values impacts the optimization path or the decrease of loss in different tasks. This would provide a much-needed experimental grounding to the theoretical concepts presented in the paper. \n\nOverall, the paper needs more novelty and substantial analysis to make a significant contribution to the field."
                },
                "questions": {
                    "value": "Why are the baseline methods worse than STL on almost all datasets? In previous papers (IMTL etc.), at least on the NYUv2 dataset, the effects of most methods are positive."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3130/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699517468905,
            "cdate": 1699517468905,
            "tmdate": 1699636259775,
            "mdate": 1699636259775,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HmRuqD8g5u",
                "forum": "8FhwHJGUPZ",
                "replyto": "zPTw3xhg3P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer PmP7 (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your thoughtful review and valuable feedback. We address your concerns as follows.\n\n---\n\n> Q1: There is a significant lack of novelty in the presented techniques. The first part discusses scale-balancing loss transformation, which utilizes the common method of applying a log transformation to loss. This technique has already been mentioned by Nash-MTL and therefore doesn't contribute anything substantially new to the field. The second section of the method, gradient normalization, is a modification of the GradNorm technique. The presented maximum-norm strategy essentially ensures all small-task gradients have the same norm as the task with the greatest gradient. While this may present an interesting approach, it is not substantially innovative. The final part of the paper brings together the previous two parts, but again, this combination doesn't present any great novelty or challenges. Consequently, the paper\u2019s primary contribution is the maximum-norm strategy, which is not significant enough.\n\n> From the writing perspective, this paper reads more like a technical report or experiment report, where effective methods from previous work are summarized but with few unique thoughts proposed.\n\n**A1:** This paper aims to alleviate the task balancing problem from loss and gradient perspectives. The proposed method is **simple yet effective** and largely outperforms baselines on five datasets.\n\n(i) As discussed in Section 3.1 of the submission, logarithm transformation is only used as a baseline studied in Nash-MTL and its advantages for MTL methods are **NOT** researched there. In our paper, we conducted extensive experiments to show that logarithm transformation is beneficial to various MTL methods. As shown in Figure 1 of the submission, MTL methods integrated with logarithm transformation can boost performance by a large margin. The effectiveness of combining logarithm transformation with MTL methods, **one of our major contributions**, is useful for the MTL community.\n\n(ii) As discussed in Section 3.2 of the submission, the proposed gradient balancing method is different from GradNorm: firstly, GradNorm cannot guarantee all task gradients to have the same magnitude in each iteration since it updates the model parameters and task weights alternately; secondly, GradNorm does not consider the effect of the update magnitude (i.e., $\\alpha_k$ in our paper), which significantly affects the performance (as shown in Figures 4 and 6 in our paper).\n\nWe are the **first** to propose normalizing task gradients to the same magnitude as the maximum gradient norm, and extensively experimental results (like Figure 3, Tables 1 and 6 in the submission) show it achieves better performance than GradNorm and other gradient balancing methods, which is **one of our major contributions**.\n\n(iii) Logarithm transformation and the proposed gradient normalization are two **simple but effective** techniques, which are complementary and can be simply combined together as the proposed DB-MTL. Compared with IMTL, which is complex in learning weights for balancing both losses and gradients, DB-MTL is simpler and more effective (Tables 1, 2, 3, 4, and 5 in the submission). Furthermore, by a simple combination, DB-MTL achieves state-of-the-art performance on various datasets, which is **our primary contribution**.\n\n(iv) Recent works [1, 2] have conducted extensive experiments to demonstrate the most simple method, equal weighting (EW in the submission), can perform comparably or even better than many complex multi-task/multi-objective methods via tuning some hyperparameters (like the learning rate) in [1] or using some regularization and stabilization techniques in [2]. Hence, we believe proposing simple but effective methods for the MTL field is useful.\n\n---\n\n\n> Q2: From an experimental perspective, the explanation of the maximum-norm strategy in section 3.2 lacks experimental support and could benefit from visual analysis. For example, the authors could investigate how using different alpha values impacts the optimization path or the decrease of loss in different tasks. This would provide a much-needed experimental grounding to the theoretical concepts presented in the paper.\n\n**A2**: We have provided intuitive explanations and extensive empirical experiments on five datasets (Figures 4 and 6 in the submission) to demonstrate the maximum-norm strategy is reasonable. We will further study it in the future."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700459913838,
                "cdate": 1700459913838,
                "tmdate": 1700459913838,
                "mdate": 1700459913838,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Q9o7y2AX1F",
                "forum": "8FhwHJGUPZ",
                "replyto": "zPTw3xhg3P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer PmP7 (2/2)"
                    },
                    "comment": {
                        "value": "> Q3: Why are the baseline methods worse than STL on almost all datasets? In previous papers (IMTL etc.), at least on the NYUv2 dataset, the effects of most methods are positive.\n\n**A3**: (i) There are **two backbones SegNet and ResNet50** widely used in evaluating MTL methods on the NYUv2 dataset. The former, which is used in the mentioned work IMTL, is less powerful and MTL methods can beat STL. The submission has included the results of both backbones. **For SegNet, as can be seen from Table 7 in Appendix C.1, our DB-MTL and most of the MTL methods achieve better performance than STL, which is consistent with previous papers (e.g., IMTL).** \nFor ResNet50, we can see from Table 1 in the main paper that only three MTL methods (CLS, IGBv2, and our DB-MTL) can beat STL.\n\n(ii) For Office-31 and Office-Home datasets, as observed in previous works (Table 8 in RLW paper and Tables 7 and 8 in MoCo paper), most of the baselines are worse than EW in terms of $\\Delta_{\\mathrm{p}}$ (EW is usually worse than STL). As discussed in the Nash-MTL paper, the QM9 dataset is challenging, and all of the existing MTL methods underperform STL.\n\n(iii) Recently, large-scale empirical studies [1, 2] also demonstrated the performance of the existing MTL methods is unsatisfactory, suggesting the importance of developing a more effective MTL algorithm.\n\n---\n\n**References**\n\n[1] Kurin et al. In Defense of the Unitary Scalarization for Deep Multi-Task Learning. In *Neural Information Processing Systems*, 2022.\n\n[2] Xin et al. Do Current Multi-Task Optimization Methods in Deep Learning even Help? In *Neural Information Processing Systems*, 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700459939302,
                "cdate": 1700459939302,
                "tmdate": 1700459939302,
                "mdate": 1700459939302,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Q4zjjhfJUE",
                "forum": "8FhwHJGUPZ",
                "replyto": "zPTw3xhg3P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3130/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Have our reply addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer PmP7,\n\nThank you again for your detailed reviews. We have responded to your comments in the above reply and we hope that our reply has satisfactorily addressed your concerns.\n\nIf there is any additional explanation or experiments that can save the reviewer\u2019s time to understand our paper and clarify the concerns, we will be more than happy to do so.\n\nBest,\n\nThe authors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3130/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661912351,
                "cdate": 1700661912351,
                "tmdate": 1700661912351,
                "mdate": 1700661912351,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]