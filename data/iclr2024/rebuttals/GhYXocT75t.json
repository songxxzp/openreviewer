[
    {
        "title": "Forward-Backward Reasoning in Large Language Models for Mathematical Verification"
    },
    {
        "review": {
            "id": "B8FQpUVaWZ",
            "forum": "GhYXocT75t",
            "replyto": "GhYXocT75t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4976/Reviewer_nUu4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4976/Reviewer_nUu4"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a reasoning verification method for language models for mathematical reasoning tasks. The method, FOBAR, combines forward (self-consistency) and backward chaining for verification. The main idea is to ask the model to go from a candidate answer to a masked quantity in the question. The authors experiment with 3 OpenAI models (text-davinci-003, gpt-3.5-turbo, and gpt-4), finding positive results in 6 mathematical reasoning datasets (including GSM8k). Moreover, an ablation shows that the method is complementary to self-consistency, with the best results coming from a combination of both."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well-written, well-motivated and addresses a current topic - unsupervised verification of chain-of-thought reasoning. The idea is sound for the domain it is proposed for, of mathematical reasoning. Many current mathematical reasoning datasets are amenable to this, as shown by the extensive evaluation.\n\nThe experimental results are quite strong - notably, this almost sets a new state-of-the-art on GSM8k using GPT-4, for instance.\n\nAlso, this idea is likely to \"age well\", i.e. it gets better and more relevant as LLMs become more capable. This is a noticeable feature in the current phase of AIs, where many papers have relevance for at most a few months. In contrast, the idea of backward verification using the LLM itself can potentially be applied to more challenging datasets of the future, as LLMs themselves become more capable of both solving problems and also of producing coherent verification traces."
                },
                "weaknesses": {
                    "value": "The main weakness in my opinion is the relatively narrow scope of the method (mathematical reasoning, and even then mostly on more numerical tasks). While I can see the idea being applicable to other domains, it's not obvious how to do so (if there were other compelling examples, e.g. in logical reasoning tasks, I believe the authors would have likely shown some of them). This is one disadvantage compared to Self-Consistency which, while less effective for math as shown here, is very widely applicable.\n\nFor results, I think the paper currently misses a qualitative discussion on what failure modes FOBAR addresses. While the idea is intuitive, it's not obvious where exactly self-consistency fails as a verification method, when FOBAR would be expected to succeed.\n\nOne baseline that is missing is the recent paper from Ling et al, 2023 on \"Deductive Verification of Chain-of-Thought Reasoning\". Their method is a forward verification method, and it would be interesting to see if (1) the gains from FOBAR + Self-Consistency alone are higher than what they get, and (2) if their method could even be a better drop-in replacement for the \"forward\" part in FOBAR. If there are directly comparable numbers on their paper, I'd strongly suggest citing them here. If cost is an issue, even doing this just for AquA, where you have the lowest absolute results and thus most room for improvement, could be already interesting."
                },
                "questions": {
                    "value": "A minor point that I'd suggest improving on is the mathematical notation. This is not a barrier to understanding, since the idea is very simple, but will just help standardize papers in the community. For each candidate answer, there is an associated \"correct\" random variable. Equations 2 and 3 describe estimators for this unknown quantity. The estimator's name is what you'd put a hat on, not the variable. I'd indicate forward/backward as subscripts in the estimator's name, rather than as a \"parameter\".\n\nQuestions:\n- Are there any examples where self-consistency fails but FOBAR succeeds that help give insights into the failure modes that FOBAR addresses?\n- When self-consistency fails, is it usually when the model consistently proposes a wrong answer, or proposes a completely divergent set of answers that are then ultimately sampled at random?\n- Do you believe FOBAR can be applied outside of numerical mathematical reasoning tasks? If so, what other tasks could be the closest potential targets?\n- Have you observed cases where backward verification is especially hard, while forward verification is not?\n- Do you have a sense of how often backward verification discards correct solutions? In other words, of the remaining failures, how many are cases where the base model fails to give any correct answer at all, versus cases where one of the answers is correct but ends up discarded by FOBAR?\n * Related to this last question, one suggestion that should be simple to implement is computing an \"oracle verifier\", which takes any correct answer from the model if there is one, and otherwise returns any answer. This might help show the potential to improve results by improving the verifier (as FOBAR/self-consistency try to do), versus cases where we would only see improvements if the base model were to improve."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4976/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4976/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4976/Reviewer_nUu4"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4976/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698623378403,
            "cdate": 1698623378403,
            "tmdate": 1699636484981,
            "mdate": 1699636484981,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AtKTgEy1ht",
                "forum": "GhYXocT75t",
                "replyto": "B8FQpUVaWZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer nUu4 (1/4)"
                    },
                    "comment": {
                        "value": "Thank you for your positive review and valuable comments. We address your concerns as follows.\n\n> Q1. \"The main weakness in my opinion is the relatively narrow scope of the method (mathematical reasoning, and even then mostly on more numerical tasks). While I can see the idea being applicable to other domains, it's not obvious how to do so (if there were other compelling examples, e.g. in logical reasoning tasks, I believe the authors would have likely shown some of them). This is one disadvantage compared to Self-Consistency which, while less effective for math as shown here, is very widely applicable.\"\n> \n> \"Do you believe FOBAR can be applied outside of numerical mathematical reasoning tasks? If so, what other tasks could be the closest potential targets?\"\n\nA1. (i) In this paper, **our focus is on mathematical tasks**, which often require a number of reasoning steps to reach the answer and are thus challenging. The proposed backward verification is **simple, general, and can be applied out-of-the-box to any mathematical task.**\n\n(ii) **Extension to non-arithmetic tasks is possible** and follows a similar line. Similar to that for mathematical tasks, we **mask informative word/token/character** and then ask the LLM to predict. We give **two examples (Date Understanding reasoning task [1, 2] and Last-Letter-Concatenation reasoning task [1])** as follows.\n\n`Example 1: Date Understanding`\n\n*Question*: Yesterday was April 30, 2021. What is the date today in MM/DD/YYYY?\n\n*Candidate Answer*: 05/01/2021 (correct), 05/02/2021 (wrong)\n\n*Backward question for the candidate answer 05/01/2021*:\nYesterday was April 30, 2021. What is the date **x** in MM/DD/YYYY? If we know the answer to the above question is **05/01/2021**, what is the English word at **x**?\n\n*Backward question for the candidate answer 05/02/2021*:\nYesterday was April 30, 2021. What is the date **x** in MM/DD/YYYY? If we know the answer to the above question is **05/02/2021**, what is the English word at **x**?\n\nThe LLM is more likely to predict the word \"today\" given the correct candidate answer 05/01/2021. We leave the details as future work.\n\n`Example 2: Last-Letter-Concatenation`\n\n*Question*: Take the last letters of each word in \"Whitney Erika Tj Benito\" and concatenate them.\n\n*Candidate Answer*: yajo (correct), yaji (wrong)\n\n*Backward question for candidate answer yajo*:\nTake the last letters of each word in \"Whitney Erika Tj Benit[]\" and concatenate them. If we know the answer to the above question is **yajo**, what is the character at []?\n\n*Backward question for candidate answer yaji*:\nTake the last letters of each word in \"Whitney Erika Tj Benit[]\" and concatenate them. If we know the answer to the above question is **yaji**, what is the character at []?\n\nNote that we use \"[]\" to mask the character instead of \"x\" (which is also a character). The LLM is more likely to predict \"o\" correctly at [] given the candidate answer yajo than yaji. Hence, the proposed FOBAR can be used in other types of tasks by masking the informative word/token/character in the questions.\n\n(iii) Note that one contribution of the proposed FOBAR is a **novel** method to combine forward and backward reasoning for verification (i.e., $\\mathbb{P}(\\hat{A}_c) \\propto (\\mathbb{P}\\_\\text{forward}(\\hat{A}_c) )^\\alpha (\\mathbb{P}\\_\\text{backward}(\\hat{A}_c) )^{1-\\alpha}$). The proposed method is **general** and **can be integrated into existing verification methods** (such as RCoT [3] and Self-Verification [4]) for non-arithmetic reasoning tasks."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299861736,
                "cdate": 1700299861736,
                "tmdate": 1700299861736,
                "mdate": 1700299861736,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "whTZHNP3h6",
                "forum": "GhYXocT75t",
                "replyto": "B8FQpUVaWZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer nUu4 (2/4)"
                    },
                    "comment": {
                        "value": "> Q2. \"For results, I think the paper currently misses a qualitative discussion on what failure modes FOBAR addresses. While the idea is intuitive, it's not obvious where exactly self-consistency fails as a verification method, when FOBAR would be expected to succeed.\"\n> \n> \"Are there any examples where self-consistency fails but FOBAR succeeds that help give insights into the failure modes that FOBAR addresses?\"\n\nA2. As suggested, we conducted a qualitative analysis on SingleEq using text-davinci-003 with CoT prompting. We observe that a common characteristic of problems that  Self-Consistency fails but FOBAR succeeds is: **Problems are difficult to solve in a forward direction,\nbut the correctness of a candidate answer can be easily verified in a backward manner**. An example is shown below.\n\n*Question*: The sum of three consecutive odd numbers is 69. What is the smallest of the three numbers?\n\n*Ground-truth answer*: 21\n\n*Candidate answers generated by Self-Consistency*: 21 (16 times), 23 (24 times)\n\n*An example of wrong forward reasoning chains*: The sum of three consecutive odd numbers is 69. We can use the formula n + (n+2) + (n+4) = 69 to solve for n. We get n = 23. This is the smallest of the three numbers. The answer is 23.\n\n*Question for backward verification*: The sum of three consecutive odd numbers is ${\\bf x}$. What is the smallest of the three numbers? If we know the answer to the above question is $21$, what is the value of unknown variable ${\\bf x}$?\n\nFor the above backward question, it is easy for the LLM to calculate the value of **x**. We sample 10 backward reasoning chains to solve the question, and all of them predict ${\\bf x}=69$. Hence, in this case, **backward verification is simpler than solving the original question.**\n\n---\n\n> Q3. \"One baseline that is missing is the recent paper from Ling et al, 2023 on \"Deductive Verification of Chain-of-Thought Reasoning\". Their method is a forward verification method, and it would be interesting to see if (1) the gains from FOBAR + Self-Consistency alone are higher than what they get, and (2) if their method could even be a better drop-in replacement for the \"forward\" part in FOBAR. If there are directly comparable numbers on their paper, I'd strongly suggest citing them here. If cost is an issue, even doing this just for AquA, where you have the lowest absolute results and thus most room for improvement, could be already interesting.\"\n\n**A3.** Thanks for bringing this recent paper [5] to our attention. As suggested, we replace the forward part in our FOBAR with the forward verification proposed in [5], and conducted additional experiments on AddSub, GSM8K, and AQuA using the GPT-3.5-Turbo. Table below shows the testing accuracy. As can be seen, **combining our backward verification with their forward verifications consistently boosts the performance.**\n\n\\begin{array}{l c c c}\n\\hline\n&  \\text{AddSub} & \\text{GSM8K} & \\text{AQuA} \\newline\n\\hline\n\\text{Self-Consistency}  & 88.1 & 86.4 & 63.0 \\newline\n \\text{Self-Consistency + Backward Verification} &\\textbf{ 88.4} & \\textbf{87.4} & \\textbf{63.4}\\newline\n\\hline\n\\text{NP [1]}  & 93.67 &  87.05 & 70.34 \\newline\n\\text{NP [1] + Backward Verification}  & \\textbf{93.92} & \\textbf{87.89} & \\textbf{71.65} \\newline\n\\hline\n\\text{NP + DV + UPV [1]} & 93.54 & 86.01 & 69.49  \\newline\n\\text{NP + DV + UPV [1] + Backward Verification}& \\textbf{93.92} &  \\textbf{87.19} & \\textbf{70.86} \\newline\t\n\\hline\n\\end{array}"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299889005,
                "cdate": 1700299889005,
                "tmdate": 1700299889005,
                "mdate": 1700299889005,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RAqHNJMhes",
                "forum": "GhYXocT75t",
                "replyto": "B8FQpUVaWZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer nUu4 (3/4)"
                    },
                    "comment": {
                        "value": "> Q4. \"A minor point that I'd suggest improving on is the mathematical notation. This is not a barrier to understanding, since the idea is very simple, but will just help standardize papers in the community. For each candidate answer, there is an associated \"correct\" random variable. Equations 2 and 3 describe estimators for this unknown quantity. The estimator's name is what you'd put a hat on, not the variable. I'd indicate forward/backward as subscripts in the estimator's name, rather than as a \"parameter\".\"\n\n**A4.** Thanks for your suggestions, and we revised the paper accordingly.\n\n---\n\n> Q5. \"When self-consistency fails, is it usually when the model consistently proposes a wrong answer, or proposes a completely divergent set of answers that are then ultimately sampled at random?\"\n\n**A5.** We conducted an additional analysis on Self-Consistency using the GPT-3.5-Turbo with ComplexCoT prompting. Table below shows the number of failure problems in Self-Consistency, and the number of failure problems with no correct chains or at least one correct chain. We can see that, in total, about 60\\% of the failure problems have correct chains in Self-Consistency, while about 40\\% of the problems have no correct ones and thus cannot be solved by backward verification.\n\n\\begin{array}{cccccccc}\n\\hline\n& \\text{AddSub} & \\text{MultiArith} & \\text{SingleEQ} & \\text{SVAMP} & \\text{GSM8K} & \\text{AQuA} & \\text{Total}\\newline\n\\hline\n\\text{\\\\#fails} & 47 & 7 & 28 & 150 & 179 & 94 & 505\\newline\n\\hline\n\\text{\\\\#has no correct answers} & 28 & 0 & 14 & 57 & 60 & 52 & 211 \\newline\n\\text{\\\\#has the correct answer} & 19 & 7 & 14 & 93 & 119 & 42 & 294 \\newline\n\\hline\n\\end{array}\n\n---\n\n> Q6. \"Have you observed cases where backward verification is especially hard, while forward verification is not?\"\n\t\n**A6.** As suggested, we analyzed the questions in GSM8K (using GPT-3.5-Turbo with ComplexCoT) that  Self-Consistency succeeds but FOBAR fails. There are 24 such questions. We give an example below, where backward reasoning fails to predict the masked numbers.\n\t\n*Question*: Manolo bought 5 lollipops and 4 candies that cost \\\\$3.20. If each lollipop costs \\\\$0.40, how much will 10 lollipops and 10 candies cost him?\n\n*Ground-truth answer*: 7\n\nCandidate answers generated by Self-Consistency:  12 (once), 16 (4 times), 7 (5 times)\n\nNumber of times that the masked number is correctly predicted in backward reasoning: 12 (6 times), 16 (0 times), 7 (0 times)\n\n---\n\n> Q7. \"Do you have a sense of how often backward verification discards correct solutions? In other words, of the remaining failures, how many are cases where the base model fails to give any correct answer at all, versus cases where one of the answers is correct but ends up discarded by FOBAR?\"\n\n**A7.** As suggested, we did an analysis on the failure cases of FOBAR using the GPT-3.5-Turbo with ComplexCoT prompting to study how often FOBAR discards correct solutions. Table below shows the results. As shown, in total, there are 400 problems  FOBAR fails. Among them, nearly half of them have no correct candidate answers, which cannot be improved by enhancing backward verification. Furthermore, there are 189 questions that have forward chains leading to the correct answer but FOBAR fails.\n\n\\begin{array}{cccccccc}\n\\hline\n& \\text{AddSub} & \\text{MultiArith} & \\text{SingleEQ} & \\text{SVAMP} & \\text{GSM8K} & \\text{AQuA} & \\text{Total} \\newline\n\\hline\n\\text{\\\\#samples} & 395 & 580 & 508 & 1000 & 1319 & 254 & 4056\\newline\n\\hline\n\\text{\\\\#succeeds} & 349 & 579 & 479 & 885 & 1153 & 161 & 3606\\newline\n\\text{\\\\#fails} & 46 & 1 & 29 & 115 & 116 & 93 & 400 \\newline\n\\hline\n\\text{\\\\#has no correct answers} & 28 & 0 & 14 & 57 & 60 & 52 & 211  \\newline\n\\text{\\\\#has the correct answer} & 18 & 1 & 15 & 58 & 56 &  41 & 189 \\newline\n\\hline\n\\end{array}"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299917810,
                "cdate": 1700299917810,
                "tmdate": 1700300499786,
                "mdate": 1700300499786,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UszAZ2crnu",
                "forum": "GhYXocT75t",
                "replyto": "B8FQpUVaWZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer nUu4 (4/4)"
                    },
                    "comment": {
                        "value": "> Q8. \"Related to this last question, one suggestion that should be simple to implement is computing an \"oracle verifier\", which takes any correct answer from the model if there is one, and otherwise returns any answer. This might help show the potential to improve results by improving the verifier (as FOBAR/self-consistency try to do), versus cases where we would only see improvements if the base model were to improve.\"\n\n**A8.** We conducted an additional analysis to show the potential of improving performance by enhancing the verifier. Table below shows the accuracy of Oracle Verifier (i.e., pick the ground-truth answer if it is a candidate answer generated by Self-Consistency). We can see that there is a large gap between Oracle Verifier and FOBAR/Self-Consistency. Hence, **improving the verifier is a potential method to boost performance.**\n\n\\begin{array}{c|c |c c c c c c c}\n\\hline\n & \\text{method} & \\text{AddSub} & \\text{MultiArith} & \\text{SingleEQ} & \\text{SVAMP} & \\text{GSM8K} & \\text{AQuA} & \\text{Avg} \\newline\n\\hline\n & \\text{Self-Consistency} & 91.7 &   95.9 & 94.5 & 83.1 &67.9& 55.1& 81.4 \\newline\n\\text{text-davinci-003+CoT}&\\text{FOBAR}   &91.9 & 100.0 & 96.1& 86.8 & 70.8 & 55.1 & 83.5 \\newline\n& \\text{Oracle Verifier} & 97.0 & 100.0  & 98.0 & 92.8 & 84.6 & 85.8 & 93.0 \\newline\n\\hline\n  & \\text{Self-Consistency} & 89.4 &98.5  & 91.1& 82.7 & 79.1 & 58.7 & 83.2 \\newline\n\\text{text-davinci-003+ComplexCoT} & \\text{FOBAR}   & 90.6 &100.0& 95.3 &87.0 & 78.7 & 58.7 & 85.0 \\newline\n& \\text{Oracle Verifier} & 95.4 & 100.0 & 97.4 & 94.5 & 92.2 & 82.7 & 93.7 \\newline\n\\hline\n & \\text{Self-Consistency} &90.6 & 98.6 & 93.1 & 86.4 & 81.9 & 62.6 & 85.5\\newline\n\\text{GPT-3.5-turbo+CoT} & \\text{FOBAR} & 89.4 & 99.3 & 94.5 & 88.9 & 85.1 & 62.6 & 86.6 \\newline\n& \\text{Oracle Verifier} & 93.9 & 100.0 & 96.5 & 93.9 & 92.2 & 89.8 & 94.4\\newline\n\\hline\n & \\text{Self-Consistency} & 88.1 &  98.8 & 94.5 & 85.0&86.4 & 63.0 &  86.0 \\newline\n\\text{GPT-3.5-turbo+ComplexCoT} &\\text{FOBAR} & 88.4 & 99.8& 94.3 & 88.5 & 87.4 & 63.4 & 87.0 \\newline\n& \\text{Oracle Verifier} & 92.9 & 100.0 & 97.2 & 94.3 & 95.5 & 79.5 & 93.2 \\newline\n\\hline\n & \\text{Self-Consistency} & 92.2 &  99.0 & 95.9 & 93.3 & 94.8 & 71.3 & 91.1\\newline\n\\text{GPT-4+CoT}& \\text{FOBAR} & 92.4 & 99.0 & 96.1& 94.1 & 95.4 & 71.3 & 91.4\\newline\n& \\text{Oracle Verifier} & 94.4 & 99.1 & 97.0 & 96.0 & 97.3 & 89.8 & 95.6 \\newline\n\\hline\n & \\text{Self-Consistency} &  91.4 & 98.5 & 94.7 & 93.4  & 96.2 & 75.2 & 91.6 \\newline\n\\text{GPT-4+ComplexCoT} & \\text{FOBAR} & 91.9 & 98.6 & 94.7 & 94.4 & 96.4 & 75.2 & 91.9\\newline\n& \\text{Oracle Verifier} & 94.4 & 98.8 & 96.3 & 95.7 & 98.5 & 91.3 & 95.8 \\newline\n\\hline\n\\end{array}\n\n---\n\n## **References**\n\t\n[1] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Brian Ichter, Fei Xia, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. Neural Information Processing Systems, 2022.\n\n[2] Srivastava et al. (400+ authors). Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on Machine Learning Research, 2023.\n\n[3] Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, and Heng Ji. RCoT: Detecting and rectifying factual inconsistency in reasoning by reversing chain-of-thought. Preprint arXiv:2305.11499, 2023.\n\n[4] Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, and Jun Zhao. Large language models are reasoners with Self-Veri\ufb01cation. Preprint arXiv:2212.09561, 2022.\n\n[5] Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland Memisevic, and Hao Su. Deductive veri\ufb01cation of Chain-of-Thought reasoning. In Neural Information Processing Systems, 2023."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299964474,
                "cdate": 1700299964474,
                "tmdate": 1700300457850,
                "mdate": 1700300457850,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "E6BxxqQt0R",
                "forum": "GhYXocT75t",
                "replyto": "UszAZ2crnu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Reviewer_nUu4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Reviewer_nUu4"
                ],
                "content": {
                    "title": {
                        "value": "Author response"
                    },
                    "comment": {
                        "value": "Thank you for the additional analyses and responses. I think the results with the Oracle experiment are quite promising, and they help justify this line of work. It's also nice to see that there are still some gains on top of Natural Programs, albeit small. It could be interesting to look at inference cost as well, since FOBAR might be less expensive.\n\nI thus would like to maintain my score - I think the paper adds a simple and nice idea to this line of work on mathematical reasoning with language models and shows enough results."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534918154,
                "cdate": 1700534918154,
                "tmdate": 1700534918154,
                "mdate": 1700534918154,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1vBkK4Ep8R",
            "forum": "GhYXocT75t",
            "replyto": "GhYXocT75t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4976/Reviewer_YtZF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4976/Reviewer_YtZF"
            ],
            "content": {
                "summary": {
                    "value": "The authors suggest integrating backward reasoning into answer verification to improve the performance of LLMs in mathematical reasoning tasks. In this approach, a number in the original question is masked and replaced with a variable, prompting the LLM to determine the value of x based on a candidate answer. If a candidate answer is correct, the LLM should accurately predict the masked number given this answer. By combining forward and backward reasoning, the authors demonstrate performance improvements across multiple reasoning tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-written and easy to follow.\n2. The authors propose using backward reasoning to verify the correctness of the candidate answers.\n3. The authors propose using FOBAR, which combines forward and backward reasoning to select the best answer from all the candidates, and they show improvements in experimental results."
                },
                "weaknesses": {
                    "value": "1. Does the proposed backward reasoning have the potential for extension to more complex settings? For some questions, given a candidate number, there can be multiple correct values for the masked number in the question statement. The model may output a number that makes sense, even if it's different from the number in the original question statement. Then, how can we measure the accuracy of the backward reasoning?\n2. Can backward reasoning be more accurate than forward reasoning? If backward reasoning isn't simpler than forward reasoning, poor performance in backward reasoning could negatively impact the accuracy of the final answer."
                },
                "questions": {
                    "value": "Recent work proposes using step-by-step verification for answer verification. The paper also suggests backward reasoning, which involves step-by-step analysis. Is there any relationship between backward reasoning and step-by-step verification?\n\nRelated literature for step-by-step verification:\n\nLet's Verify Step by Step\n\nDeductive Verification of Chain-of-Thought Reasoning"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4976/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4976/Reviewer_YtZF",
                        "ICLR.cc/2024/Conference/Submission4976/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4976/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698696298755,
            "cdate": 1698696298755,
            "tmdate": 1699648821316,
            "mdate": 1699648821316,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "v7UboX4cb3",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer YtZF ((1/2))"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful review and valuable feedback. We address your concerns as follows.\n\n> Q1. Does the proposed backward reasoning have the potential for extension to more complex settings? For some questions, given a candidate number, there can be multiple correct values for the masked number in the question statement. The model may output a number that makes sense, even if it's different from the number in the original question statement. Then, how can we measure the accuracy of the backward reasoning?\n\n**A1.** Yes, our proposed backward reasoning **still works** for the mentioned complex setting.\nIn backward reasoning, we select the candidate answer that leads to the most backward reasoning chains that predict the masked number successfully. **When there are multiple correct values for the masked number, the proposed backward reasoning can work as long as the correct candidate answer is easier for the LLM to predict the masked number than the wrong candidate answers.** We give an example below.\n\n*Question*: Emily and Sophia are sisters. Emily is 30 years old, and Sophia is 43 years old. Calculate the square of their age difference.\n\n*Candidate Answers*: 169 (correct), 139 (wrong)\n\n*Backward question for the candidate answer 169*: Emily and Sophia are sisters. Emily is 30 years old, and Sophia is ${\\bf x}$ years old. Calculate the square of their age difference. If we know the answer to the above question is **169**, what is the value of unknown variable ${\\bf x}$?\n\n*Backward question for the candidate answer 139*: Emily and Sophia are sisters. Emily is 30 years old, and Sophia is ${\\bf x}$ years old. Calculate the square of their age difference. If we know the answer to the above question is **139**, what is the value of unknown variable ${\\bf x}$?\n\nObviously, for the correct candidate answer $169$, the correct value of ${\\bf x}$ is not unique, can be 43 or 17. The proposed backward reasoning for verification still works as the LLM is more likely to predict ${\\bf x} = 43$ given the candidate answer $169$ than given $139$. To validate it, we conduct an experiment as follows. For each candidate answer, we sample 100 reasoning chains to predict ${\\bf x}$. For the candidate answer 169, there are 24 backward reasoning chains that predict ${\\bf x}=43$ (35 chains lead to ${\\bf x}=17$, and the remaining 41 chains lead to either 43 or 17 is ok). However, for the candidate answer 139, none of the backward reasoning chains predict ${\\bf x}=43$, thus, the candidate answer 169 wins. Hence, in the cases where the correct value of ${\\bf x}$ is not unique, the proposed backward reasoning method still works for verification.\n\n---\n\n> Q2. \"Can backward reasoning be more accurate than forward reasoning? If backward reasoning isn't simpler than forward reasoning, poor performance in backward reasoning could negatively impact the accuracy of the final answer.\"\n\n**A2.** (i) In Section 4.3 of the submission, we conducted an ablation experiment to compare the performance of forward and backward reasoning. As shown in Table 2 there, backward reasoning is more accurate than forward reasoning in 5 of 6 settings.\n\n(ii) It is possible that backward reasoning tasks can be complex. However, **even when the masked number is difficult to predict, as long as the correct candidate answer can better predict the masked number than the incorrect candidate answers, this correct candidate will still be picked.** In other words, the correct candidate answer may still lead to a low prediction accuracy on the masked number, but as long as its accuracy is still higher than those of the incorrect candidate answers, the proposed backward reasoning procedure still works. \n\n(iii) By combining forward and backward reasoning, the proposed **FOBAR is a general method to improve forward verification**. As shown in Table 2 of the submission, FOBAR consistently performs better than Self-Consistency, which uses forward reasoning alone."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299674445,
                "cdate": 1700299674445,
                "tmdate": 1700301837227,
                "mdate": 1700301837227,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pjMVIFzwAq",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer YtZF ((2/2))"
                    },
                    "comment": {
                        "value": "> Q3. \"Recent work proposes using step-by-step verification for answer verification. The paper also suggests backward reasoning, which involves step-by-step analysis. Is there any relationship between backward reasoning and step-by-step verification? Related literature for step-by-step verification: (i) Let's Verify Step by Step. (ii) Deductive Verification of Chain-of-Thought Reasoning.\"\n\nA3. (i) Note that the mentioned papers [1, 2] focus on verifying the steps of forward reasoning chains and **DO NOT** use backward reasoning in verification. In [1], the authors label exclusively steps of forward reasoning chains generated by LLMs. The labeled data are then used to train an LLM for verification. Compared with [1], which is computationally expensive in training an LLM and labor-intensive in labeling data, our backward reasoning is training-free for verification and requires no additional data annotation. \n\n(ii) In [2], the authors propose a natural language-based deductive reasoning format that allows the LLM to verify **forward** reasoning steps. In our paper, we use **backward** reasoning to **verify the candidate answers** instead of the steps in forward chains. As backward and forward reasoning are complementary, our backward verification can be combined with their step-by-step forward verifications. We replace the forward verification in our FOBAR (Eq. (4) in our paper) with step-by-step forward verification proposed by [2], and conducted additional experiments on AddSub, GSM8K, and AQuA using GPT-3.5-Turbo. Table below shows the testing accuracy. As can be seen, **combining backward verification with their forward verifications consistently boosts performance**.\n\n\\begin{array}{lccc}\n\\hline \n&  \\text{AddSub} & \\text{GSM8K} & \\text{AQuA} \\newline\n\\hline\n\\text{NP [2]} & 93.67 &  87.05 & 70.34 \\newline\n\\text{NP + Backward Verification} & \\textbf{93.92} & \\textbf{87.89} & \\textbf{71.65} \\newline\n\\hline\n\\text{NP + DV + UPV [2]} & 93.54 & 86.01 & 69.49  \\newline\n\\text{NP + DV + UPV + Backward Verification} & \\textbf{93.92} &  \\textbf{87.19} & \\textbf{70.86} \\newline\n\\hline\n\\end{array}\n\n---\n\n## **References**\n\n[1] Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let\u2019s verify step by step. Preprint arXiv:2305.20050, 2023.\n\n[2] Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland Memisevic, and Hao Su. Deductive veri\ufb01cation of Chain-of-Thought reasoning. In *Neural Information Processing Systems*, 2023."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299710837,
                "cdate": 1700299710837,
                "tmdate": 1700301545460,
                "mdate": 1700301545460,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Cz0Ujb4vAR",
                "forum": "GhYXocT75t",
                "replyto": "pjMVIFzwAq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Reviewer_YtZF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Reviewer_YtZF"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response!"
                    },
                    "comment": {
                        "value": "Thank you for your detailed experiments and explanations. However, I still have unresolved concerns regarding the efficacy of backward reasoning, especially about its applicability to more complex problems.\n\n1. The example provided in A1 does not fully convince me. I am curious about the process used to generate the two candidate answers mentioned. Were they generated by language models? Additionally, in broader scenarios, such as in a reasoning sequence A->B, forward reasoning involves generating B given A. In contrast, backward reasoning requires generating A when conditioned on B. However, there could be an infinite number of conditions, like C, where C->A->B or C->B(C$\\not=$A). Then, how to judge the correctness of the predicted condition, which can be C instead of A?\n\n2. In A2, you claim that backward reasoning is more accurate for correct candidate answers than for incorrect ones. Could you provide experimental evidence to support this claim? Specifically, what is the accuracy of backward reasoning in both scenarios?"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700435539112,
                "cdate": 1700435539112,
                "tmdate": 1700435539112,
                "mdate": 1700435539112,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ax3itZnimo",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Any other concerns"
                    },
                    "comment": {
                        "value": "Dear Reviewer YtZF,\n\nWe would like to thank you again for your detailed reviews.\nWe hope that we have satisfactorily addressed your concerns.\n\nGiven that your current score is 3, we would be grateful if you could let us know whether our response has addressed your concerns or if you still have any other questions.\n\nWe would be happy to do any follow-up discussion or address any additional comments.\n\nBest, \n\nThe authors"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700532945646,
                "cdate": 1700532945646,
                "tmdate": 1700532945646,
                "mdate": 1700532945646,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cwn4aULOit",
                "forum": "GhYXocT75t",
                "replyto": "ax3itZnimo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Reviewer_YtZF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Reviewer_YtZF"
                ],
                "content": {
                    "title": {
                        "value": "My concerns are still here"
                    },
                    "comment": {
                        "value": "Thanks for the explanations and efforts. However, my concerns remain unresolved by your responses.\n\n> For Q4: I am asking if the candidate answer in the specific example is generated using LLMs, rather than the general setting. This is because when I tried with ChatGPT, it was able to provide correct answers.\n\nQuestion: Emily and Sophia are sisters. Emily is 30 years old, and Sophia is 43 years old. Calculate the square of their age difference.\nCandidate Answers: 169 (correct), 139 (wrong)\nBackward question for the candidate answer 169: Emily and Sophia are sisters. Emily is 30 years old, and Sophia is x years old. Calculate the square of their age difference. If we know the answer to the above question is 169, what is the value of the unknown variable x?\nBackward question for the candidate answer 139: Emily and Sophia are sisters. Emily is 30 years old, and Sophia is x years old. Calculate the square of their age difference. If we know the answer to the above question is 139, what is the value of the unknown variable x?\n\n> For Q5: I am inquiring about general settings, not the specific case you provided. This is because for challenging problems like mathematical proofs, one can always replace the condition with a stronger one to reach the same conclusion. How does your method address this issue? (This is actually a major concern. If the method is only suitable for very simple cases, how can it be extended to more complex settings? Otherwise, the work is not as impressive and may not even achieve a borderline score.)\n\n> For Q6: It is necessary to show the **numbers** here. I understand that backward reasoning may improve forward reasoning. However, the performance of backward reasoning also needs to be reported. As mentioned in your response to `A5`, you have a **simple string comparison**, which makes obtaining a metric for backward reasoning possible."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700690175089,
                "cdate": 1700690175089,
                "tmdate": 1700690175089,
                "mdate": 1700690175089,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cb47uv0Xw5",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to remaining concerns (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your further comments and clarification of previous concerns\n\n> Q7. For Q4: I am asking if the candidate answer in the specific example is generated using LLMs, rather than the general setting. This is because when I tried with ChatGPT, it was able to provide correct answers.\n\n**A7.** We agree ChatGPT will provide the correct answer to the simple question (*Emily and Sophia are sisters. Emily is 30 years old, and Sophia is 43 years old. Calculate the square of their age difference*) given in A1. However, this example is designed to showcase how our algorithm works when ${\\bf x}$ has multiple correct values. We apologize for the confusion caused by this example. As searching for such real-world examples from datasets is labor-intensive. Please give us some time, and we will attach examples here later.\n\n---\n\n> Q8. For Q5 `(Additionally, in broader scenarios, such as in a reasoning sequence A->B, forward reasoning involves generating B given A. In contrast, backward reasoning requires generating A when conditioned on B. However, there could be an infinite number of conditions, like C, where C->A->B or C->B (C\nA). Then, how to judge the correctness of the predicted condition, which can be C instead of A?)`: I am inquiring about general settings, not the specific case you provided. This is because for challenging problems like mathematical proofs, one can always replace the condition with a stronger one to reach the same conclusion. How does your method address this issue? (This is actually a major concern. If the method is only suitable for very simple cases, how can it be extended to more complex settings? Otherwise, the work is not as impressive and may not even achieve a borderline score.)\n\n\n**A8.** Thanks for clarifying previous concerns. Our FOBAR algorithm is general and capable of handling the scenarios given in Q5. Indeed, FOBAR only needs to check whether the prediction of backward chains is exactly the same as the masked number by string comparison and does not need to \"*judge the correctness of the predicted condition*\". We show how Algorithm 1 (step 5 - step14) in the submission applies to  the mentioned scenario (existing C s.t. `C->A->B`) as follows (indeed, has no difference between complex scenarios (multiple correct ${\\bf x}$'s) and simple scenarios (unique correct ${\\bf x}$)):\n\n- let $\\\\{B\\_i\\\\}\\_{i=1}^{T}$ be $T$ candidate answers obtained by Self-Consistency, calculate $\\mathbb{P}\\_{\\text{forward}}(B_i)$;\n- for each candidate answer $B\\_i \\in \\\\{B\\_1, \\dots, B\\_T\\\\}$:\n    - mask the number $A$ in the question, sample $M\\_B$ backward chains with predictions $\\{\\hat{A}\\_{B\\_i}^{(n)}\\}\\_{n=1}^{M_B}$;\n    - **count number of correct prediction ${\\bf Z\\_{B\\_{i}} = \\sum_{n=1}^{M\\_B} \\mathbb{I}(\\hat{A}\\_{B\\_i}^{(n)}=A)}$;**\n- compute probability: for $B\\_i \\in \\\\{B\\_1, \\dots, B\\_T\\\\}$, calculate\n$${\\bf \\mathbb{P}\\_{\\text{backward}}(B\\_i)=\\frac{Z\\_{B\\_i}+\\epsilon}{\\sum\\_{j=1}^TZ\\_{B\\_j} + T\\epsilon}},$$\nwhere $\\epsilon$ is a small positive constant;\n- combining forward and backward probability: for $B\\_i \\in \\\\{B\\_1, \\dots, B\\_T\\\\}$, calculate\n$$\\mathbb{P}(B_i)\\propto (\\mathbb{P}\\_{\\text{forward}}(B\\_i))^{\\alpha}(\\mathbb{P}\\_{\\text{backward}}(B\\_i))^{1-\\alpha},$$\nwhere $\\alpha=0.5$.\n\nFor the **more complex scenarios** (an infinite number of values are correct for the masked position), there may not be a single backward reasoning chain that reaches the masked number exactly, and we will get $Z\\_{B\\_{i}}=0$ for all $B\\_i \\in \\\\{B\\_1, \\dots, B\\_T\\\\}$, therefore, **backward verification fails** since $\\mathbb{P}\\_{\\text{backward}}(B\\_i)=\\epsilon$ for all $B_{i}$. Our FOBAR, which combines forward and backward reasoning, becomes Self-Consistency, i.e., $$\\mathbb{P}(B\\_i)\\propto (\\mathbb{P}\\_{\\text{forward}}(B\\_i))^{\\alpha}(\\mathbb{P}\\_{\\text{backward}}(B\\_i))^{1-\\alpha}=(\\mathbb{P}\\_{\\text{forward}}(B\\_i))^{\\alpha}.$$\n\nWe hope our reply can resolve your concerns about how to apply our backward verification and FOBAR to complex scenarios."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700709553737,
                "cdate": 1700709553737,
                "tmdate": 1700731087020,
                "mdate": 1700731087020,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aWqJbuCOfo",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to remaining concerns (2/2)"
                    },
                    "comment": {
                        "value": "> Q9. For Q6: It is necessary to show the numbers here. I understand that backward reasoning may improve forward reasoning. However, the performance of backward reasoning also needs to be reported. As mentioned in your response to A5, you have a simple string comparison, which makes obtaining a metric for backward reasoning possible.\n\n**A9.** Thanks for giving us the opportunity to show the numbers to support an intuition \"**the correct candidate answer can predict the masked number **more accurately** than the incorrect candidate answers**\". We calculate two metrics (averaged over all backward questions across six tasks) in backward reasoning:\n- $\\mathbb{P}({\\bf x}={\\text{the masked number}}|\\text{correct candidate answer})=\\frac{\\text{\\\\#\\\\{backward chains with the correct candidate answer that predict the masked number exactly\\\\}}}{\\text{\\\\#\\\\{backward chains with the correct candidate answer\\\\}}}$\n- $\\mathbb{P}({\\bf x}={\\text{the masked number}}|\\text{incorrect candidate answers})=\\frac{\\text{\\\\#\\\\{backward chains with the incorrect candidate answers that predict the masked number exactly\\\\}}}{\\text{\\\\#\\\\{backward chains with the incorrect candidate answers\\\\}}}$\n\nTable below shows the results.\nWe can see that the correct candidate answer can predict the masked number **much more accurately** than the incorrect candidate answers in predicting the masked number.\nThis is crucial evidence for explaining why backward verification works. We have added Figure 5 and a new Subsection 4.5 in the updated paper. We deeply appreciate the reviewer's suggestion. \n\n\\begin{array}{l| c| c|c}\n\\hline\n& \n\\text{text-davinci-003} & \n\\text{GPT-3.5-Turbo} & \\text{GPT-4} \\newline\n& \\text{CoT}\\quad         \\text{ComplexCoT} &   \\text{CoT}\\quad         \\text{ComplexCoT} & \\text{CoT}\\quad         \\text{ComplexCoT}\\newline\n\\hline \n\\mathbb{P}({\\bf x}={\\text{the masked number} | \\text{incorrect candidate answer}})   & 13.55\\quad   \\quad\\quad\\quad  8.59 & 12.79 \\quad   \\quad\\quad\\quad  11.25 &  25.03 \\quad\\quad\\quad\\quad 19.24\\newline \n\\mathbb{P}({\\bf x}={\\text{the masked number} | \\text{correct candidate answers} })\n & 41.26\\quad   \\quad\\quad\\quad  48.01 & 41.58 \\quad   \\quad\\quad\\quad 42.08  & 47.18  \\quad\\quad\\quad\\quad 53.00\\newline  \n\\hline\n\\end{array}\n\n\nIf there is any additional explanation or experiments that can save the reviewer\u2019s time to understand our paper and clarify the concerns, we will be more than happy to do so."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700709694975,
                "cdate": 1700709694975,
                "tmdate": 1700730451830,
                "mdate": 1700730451830,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9uuyTzAgpl",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Forward reasoning chains"
                    },
                    "comment": {
                        "value": "The below 10 forward reasoning chains are generated by Cot + GPT-3.5-Turbo, temperate=0.7, demonstrations are the same as Table 10 in the CoT paper (https://arxiv.org/abs/2201.11903), as attached in the next replies.\n\n```\nchain 1: Furniture United's offer includes a $1,350 advance payment and 6 monthly installments of $350 each. So the total cost of their offer is 1,350 + 6 * 350 = $3,450.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of their offer is 1,100 + 9 * 250 = $3,350.\nThe cost difference between the two offers is 3,450 - 3,350 = $100. The answer is $100.\n\nchain 2: Furniture United's offer includes an advance payment of $1,350 and 6 monthly installments of $350 each. So the total cost for Furniture United's offer is 1350 + (6 * 350) = 1350 + 2100 = $3,450.\nCozy Homes' offer includes an advance payment of $1,100 and 9 monthly installments of $250 each. So the total cost for Cozy Homes' offer is 1100 + (9 * 250) = 1100 + 2250 = $3,350.\nThe cost difference between the two offers is 3450 - 3350 = $100. The answer is $100.\n\nchain 3: Furniture United's offer includes a $1,350 advance payment and 6 monthly installments of $350 each. So the total cost of their offer is 1,350 + (6 * 350) = 1,350 + 2,100 = $3,450.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of their offer is 1,100 + (9 * 250) = 1,100 + 2,250 = $3,350.\nThe cost difference between the two offers is 3,450 - 3,350 = $100. The answer is $100.\n\nchain 4: Furniture United's offer costs $1350 + 6 * $350 = $3450 dollars in total. Cozy Homes' offer costs $1100 + 9 * $250 = $3350 dollars in total.\nSo the cost difference between the two offers is $3450 - $3350 = 100 dollars. The answer is 100.\n\nchain 5: For Furniture United's offer, the total cost is $1,350 (advance payment) + 6 * $350 (monthly installments) = $3,150.\nFor Cozy Homes' offer, the total cost is $1,100 (advance payment) + 9 * $250 (monthly installments) = $3,350.\nThe cost difference between the two offers is $3,350 - $3,150 = $200. The answer is $200.\n\nchain 6: Furniture United's offer includes a $1,350 advance payment and 6 monthly installments of $350 each, so the total cost is 1,350 + (6 * 350) = $3,150.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each, so the total cost is 1,100 + (9 * 250) = $3,350.\nThe cost difference between the two offers is 3,350 - 3,150 = $200. The answer is $200.\n\nchain 7: Furniture United's offer includes a $1,350 advance payment and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is 1350 + (6 * 350) = $3,150.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is 1100 + (9 * 250) = $3,350.\nThe cost difference between the two offers is 3350 - 3150 = $200. The answer is $200.\n\nchain 8: Furniture United's offer includes a $1,350 advance payment and 6 monthly installments of $350 each. So the total cost for Furniture United's offer is 1350 + (6 * 350) = $3,150.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost for Cozy Homes' offer is 1100 + (9 * 250) = $3,350.\nThe cost difference between the two offers is 3350 - 3150 = $200. The answer is $200.\n\nchain 9: Furniture United's offer includes a $1,350 advance payment and 6 monthly installments of $350 each. So the total cost for Furniture United's offer is 1350 + (6 * 350) = $3,150.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost for Cozy Homes' offer is 1100 + (9 * 250) = $3,350.\nThe cost difference between the two offers is 3350 - 3150 = $200. The answer is $200.\n\nchain 10: Furniture United's offer includes a $1,350 advance payment and 6 monthly installments of $350 each. So the total cost for Furniture United's offer is 1350 + (6 * 350) = $3,150.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost for Cozy Homes' offer is 1100 + (9 * 250) = $3,350.\nThe cost difference between the two offers is 3350 - 3150 = $200. The answer is $200.\n```"
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729828202,
                "cdate": 1700729828202,
                "tmdate": 1700730203998,
                "mdate": 1700730203998,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ikazuDRby1",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Backward reasoning chains for the candidate answer 100"
                    },
                    "comment": {
                        "value": "```\n### chain 1\n```Let's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each, so the total cost of their offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each, so the total cost of their offer is $1,100 + 9 * $250 = $1,100 + $2250 = $3350.\nThe cost difference between the two offers is: (x + $2100) - $3350 = x - $1250.\nWe are given that the cost difference is $100, so we can write: x - $1250 = $100.\nSolving for x, we get: x = $1350.\nThe value of x is $1350.\n\n### chain 2\nLet's think step by step.\nFurniture United's offer includes an advance payment of $x and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes an advance payment of $1,100 and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is $1100 + 9 * $250 = $1100 + $2250 = $3350.\nThe cost difference between the two offers is the difference between the total costs: ($x + $2100) - $3350.\nWe are given that the cost difference is $100, so we can write: ($x + $2100) - $3350 = $100.\nSimplifying the left side, we get: $x + $2100 - $3350 = $100.\nCombining like terms, we get: $x - $1250 = $100.\nAdding $1250 to both sides, we get: $x = $1350.\nThe value of x is $1350.\n\n### chain 3\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is $1100 + 9 * $250 = $1100 + $2250 = $3350.\nThe cost difference between the two offers is the difference between the total costs: ($x + $2100) - $3350 = $x - $1250.\nWe are given that the cost difference is $100, so we can write: $x - $1250 = $100.\nAdding $1250 to both sides, we get: $x = $1350.\nThe value of x is $1350.\n\n### chain 4\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is x + 6 * $350.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is $1,100 + 9 * $250.\nThe cost difference between the two offers is the difference between the total costs: (x + 6 * $350) - ($1,100 + 9 * $250).\nWe are given that the cost difference is $100, so we can write: (x + 6 * $350) - ($1,100 + 9 * $250) = $100.\nSimplifying the left side, we get: x + $2,100 - ($1,100 + $2,250) = $100.\nSimplifying further, we get: x + $2,100 - $3,350 = $100.\nCombining like terms, we get: x - $1,250 = $100.\nAdding $1,250 to both sides, we get: x = $1,350.\nThe value of x is $1,350.\n\n### chain 5\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is: x + 6 * $350 = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is: $1,100 + 9 * $250 = $1,100 + $2250 = $3,350.\nThe cost difference between the two offers is: (x + $2100) - $3,350 = x - $1,250.\nWe are given that the cost difference is $100, so we can write: x - $1,250 = $100.\nSolving for x, we get: x = $1,350.\nThe value of x is $1,350.\n\n### chain 6\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is $1100 + 9 * $250 = $1100 + $2250 = $3350.\nThe cost difference between the two offers is: (x + $2100) - $3350 = x - $1250.\nWe are given that the cost difference is $100, so we can write: x - $1250 = $100.\nSolving for x, we get: x = $1350.\nThe value of x is $1350.\n```"
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729877065,
                "cdate": 1700729877065,
                "tmdate": 1700729877065,
                "mdate": 1700729877065,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AaT1tcdDnT",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Backward reasoning chains for candidate answer 100 (Cont')"
                    },
                    "comment": {
                        "value": "```\n### chain 7\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. The total cost of Furniture United's offer can be calculated as: x + 6 * $350 = x + $2,100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. The total cost of Cozy Homes' offer can be calculated as: $1,100 + 9 * $250 = $1,100 + $2,250 = $3,350.\nThe cost difference between the two offers is: (x + $2,100) - $3,350 = x + $2,100 - $3,350 = x - $1,250.\nWe are given that the cost difference is $100, so we can write: x - $1,250 = $100.\nSolving for x, we get: x = $1,350.\nThe value of x is $1,350.\n\n### chain 8\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost for Furniture United's offer is x + (6 * $350) = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost for Cozy Homes' offer is $1100 + (9 * $250) = $1100 + $2250 = $3350.\nThe cost difference between the two offers is the difference between the total costs: ($3350) - (x + $2100) = $3350 - $2100 - x = $1250 - x.\nWe are given that the cost difference is $100, so we can write: $1250 - x = $100.\nSolving for x, we get: x = $1150.\nThe value of x is $1150.\n```"
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729920867,
                "cdate": 1700729920867,
                "tmdate": 1700729920867,
                "mdate": 1700729920867,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JSysBhO9Sd",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Backward reasoning chains for candidate answer 200"
                    },
                    "comment": {
                        "value": "```\n### chain 1\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is x + 6 * 350 = x + 2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is 1100 + 9 * 250 = 1100 + 2250 = 3350.\nThe cost difference between the two offers is the difference between the total costs: (x + 2100) - 3350 = x + 2100 - 3350 = x - 1250.\nWe are given that the cost difference is 200, so we can write: x - 1250 = 200.\nSolving for x, we get: x = 1450.\nThe value of x is 1450.\n\n### chain 2\nLet's think step by step.\nFurniture United's offer includes an advance payment of $x and 6 monthly installments of $350 each. So the total cost of their offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes an advance payment of $1,100 and 9 monthly installments of $250 each. So the total cost of their offer is $1100 + 9 * $250 = $1100 + $2250 = $3350.\nThe cost difference between the two offers is the total cost of Cozy Homes' offer minus the total cost of Furniture United's offer: $3350 - (x + $2100) = $1250 - x.\nWe are given that the cost difference is $200, so we can write: $1250 - x = $200.\nSolving for x, we get: x = $1050.\nThe value of x is $1050.\n\n### chain 3\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of their offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of their offer is $1,100 + 9 * $250 = $1,100 + $2,250 = $3,350.\nThe cost difference between the two offers is the difference between the total costs: ($3,350) - (x + $2,100) = $3,350 - $2,100 - x = $1,250 - x.\nWe are given that the cost difference is $200, so we can write: $1,250 - x = $200.\nSolving for x, we get: x = $1,250 - $200 = $1,050.\nThe value of x is $1,050.\n\n### chain 4\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost for Furniture United's offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost for Cozy Homes' offer is $1100 + 9 * $250 = $1100 + $2250 = $3350.\nThe cost difference between the two offers is the difference in their total costs: ($x + $2100) - $3350 = $x - $1250.\nWe are given that the cost difference is $200, so we can write: $x - $1250 = $200.\nAdding $1250 to both sides, we get: $x = $1450.\nThe value of x is $1450.\n\n### chain 5\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is x + 6 * 350 = x + 2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is 1100 + 9 * 250 = 1100 + 2250 = 3350.\nThe cost difference between the two offers is the difference between the total costs: (x + 2100) - 3350 = x + 2100 - 3350 = x - 1250.\nWe are given that the cost difference is 200, so we can write: x - 1250 = 200.\nSolving for x, we get: x = 1450.\nThe value of x is 1450.\n\n### chain 6\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost for Furniture United's offer is x + 6*350 = x + 2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost for Cozy Homes' offer is 1100 + 9*250 = 1100 + 2250 = 3350.\nThe cost difference between the two offers is the difference between the total costs: (x + 2100) - 3350 = x - 1250.\nWe are given that the cost difference is $200, so we can write: x - 1250 = 200.\nSolving for x, we get: x = 1450.\nThe value of x is 1450.\n```"
                    }
                },
                "number": 29,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700729960238,
                "cdate": 1700729960238,
                "tmdate": 1700729960238,
                "mdate": 1700729960238,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hJBz0nxTjQ",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Backward reasoning chains for candidate answer 200 (Cont')"
                    },
                    "comment": {
                        "value": "```\n### chain 7\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of their offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of their offer is $1100 + 9 * $250 = $1100 + $2250 = $3350.\nThe cost difference between the two offers is the difference between the total costs: ($x + $2100) - $3350 = $x + $2100 - $3350 = $x - $1250.\nWe are given that the cost difference is $200, so we can write: $x - $1250 = $200.\nAdding $1250 to both sides, we get: $x = $200 + $1250 = $1450.\nThe value of x is $1450.\n\n### chain 8\nLet's think step by step.\nFurniture United's offer includes a $x advance payment and 6 monthly installments of $350 each. So the total cost of Furniture United's offer is x + 6 * $350 = x + $2100.\nCozy Homes' offer includes a $1,100 advance payment and 9 monthly installments of $250 each. So the total cost of Cozy Homes' offer is $1100 + 9 * $250 = $1100 + $2250 = $3350.\nThe cost difference between the two offers is: ($1100 + $2250) - (x + $2100) = $3350 - (x + $2100) = $3350 - $2100 - x = $1250 - x.\nWe are given that the cost difference is $200, so we can write: $1250 - x = $200.\nSolving for x, we get: x = $1050.\nThe value of x is $1050.\n```"
                    }
                },
                "number": 31,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730063653,
                "cdate": 1700730063653,
                "tmdate": 1700730063653,
                "mdate": 1700730063653,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qMWMTKKzPk",
                "forum": "GhYXocT75t",
                "replyto": "1vBkK4Ep8R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Eight CoT demonstrations"
                    },
                    "comment": {
                        "value": "```\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\nA: There are 15 trees originally. Then there were 21 trees after the Grove workers planted some more. So there must have been 21 - 15 = 6 trees that were planted. The answer is 6.\n\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\nA: There are originally 3 cars. Then 2 more cars arrive. Now 3 + 2 = 5 cars are in the parking lot. The answer is 5.\n\nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\nA: Originally, Leah had 32 chocolates and her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39 pieces left in total. The answer is 39.\n\nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\nA: Jason had 20 lollipops originally. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8 lollipops. The answer is 8.\n\nQ: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\nA: Shawn started with 5 toys. He then got 2 toys each from his mom and dad. So he got 2 * 2 = 4 more toys. Now he has 5 + 4 = 9 toys. The answer is 9.\n\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\nA: There were originally 9 computers. For each day from monday to thursday, 5 more computers were installed. So 4 * 5 = 20 computers were added. Now 9 + 20 = 29 computers are now in the server room. The answer is 29.\n\nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\nA: Michael started with 58 golf balls. He lost 23 on Tuesday, and lost 2 more on wednesday. So he had 58 - 23 = 35 at the end of Tuesday, and 35 - 2 = 33 at the end of wednesday. The answer is 33.\n\nQ: Olivia has $23. She bought five bagels for $3 each. How much money does she have left? \nA: Olivia had 23 dollars. She bought 5 bagels for 3 dollars each. So she spent 5 * 3 = 15 dollars. Now she has 23 - 15 = 8 dollars left. The answer is 8.\n```"
                    }
                },
                "number": 32,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730102776,
                "cdate": 1700730102776,
                "tmdate": 1700730102776,
                "mdate": 1700730102776,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uDv3aCL5UM",
            "forum": "GhYXocT75t",
            "replyto": "GhYXocT75t",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4976/Reviewer_PfVM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4976/Reviewer_PfVM"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose forward-backward reasoning prompting. Once candidate answers are generated for a query, a number is masked in the query (replacing it with \u201cx\u201d), and the model is asked to predict the masked number given the candidate answer. Specifically, the following template is used: \u201cIf we know the answer to the above question is ${A_c}$, what is the value of unknown variable x?\u201d The prompt is appended to the query with the masked number and candidate generation. The model is more likely to predict the correct value for \u201cx\u201d if the candidate answer ${A_c}$ is correct. \n\nThis method is tested with three LLMs on six arithmetic reasoning tasks. The method is motivated by the observation that improvements from self-consistency, which chooses an answer by majority voting over multiple reasoning chains, plateau as more reasoning chains are sampled. The authors show that their method outperforms forward reasoning alone."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The problem is well motivated. The authors show that (average) testing accuracy of self-consistency plateaus as more candidate answers are temperature sampled. \n\nThe proposed verification method is straightforward and clear. The proposed verification template does not need to be generated compared to some of the related works.\n\nThe authors did a great job with the experiments comparing FOBAR to multiple reasonable baselines."
                },
                "weaknesses": {
                    "value": "Although the proposed template is straightforward, it would have to be modified according to the tasks on which it\u2019s being applied to. This style of verification always requires something to be predicted. Part of the attractiveness of self-consistency is the fact that it can be applied out-of-the-box to any task; however, the proposed method needs to be modified across tasks and type of responses. \n\nThe method lacks novelty as it bears a strong resemblance to RCoT which tries to re-generate the question conditioned on the candidate response. FOBAR seems essentially as an extension of the factual consistency check within RCoT. Moreover, the marginal difference in results between both methods further supports this perspective.\n\nGiven that the experiments are carried out using OpenAI APIs, which undergo regular updates, it would be advisable to ensure that the baselines are run with the same API snapshots. The slight variance in the scores might be attributed to the differences in the API versions."
                },
                "questions": {
                    "value": "How does the backward reasoning compare to verification of answers? E.g. Once you generate multiple candidate answers using forward reasoning, you can ask a model to \u201cverify\u201d the candidate answer given the whole context (Similar to verifier for GSM8K in Cobbe et al 2021)\n\nRegarding my concern about OpenAI APIs getting updated regularly, have the authors used multiple different seeds for the experiments?\n\nGiven some known LLM behaviors and order of chains of arithmetic reasoning, do you think there will be a noticeable difference in performance if only the numbers at the end of the reasoning chains were masked to be predicted compared to numbers at the beginning of the reasoning?\n\nDo you have any insights on how the verification method would perform on non arithmetic reasoning tasks?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4976/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698847029722,
            "cdate": 1698847029722,
            "tmdate": 1699636484803,
            "mdate": 1699636484803,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9Q0q9wFpCp",
                "forum": "GhYXocT75t",
                "replyto": "uDv3aCL5UM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer PfVM (1/4)"
                    },
                    "comment": {
                        "value": "Thanks for your thoughtful review and valuable feedback. We address your concerns as follows.\n\t\n> Q1. \"Although the proposed template is straightforward, it would have to be modified according to the tasks on which it\u2019s being applied to. This style of verification always requires something to be predicted. Part of the attractiveness of self-consistency is the fact that it can be applied out-of-the-box to any task; however, the proposed method needs to be modified across tasks and type of responses.\"\n> \n> \"Do you have any insights on how the verification method would perform on non arithmetic reasoning tasks?\"\n\t\n**A1.** (i) In this paper, **our focus is on mathematical tasks**, which often require a number of reasoning steps to reach the answer and are thus challenging. The proposed template (i.e., masking a number in the question and then asking the LLM to predict the masked number) is **simple**, **general**, and **can be applied out-of-the-box to any mathematical task**.\n\n(ii) **Extension to non-arithmetic tasks is possible** and follows a similar line. Similar to that for mathematical tasks, we **mask informative word/token/character** and then ask the LLM to predict. We give **two examples (Date Understanding reasoning task [1, 2] and Last-Letter-Concatenation reasoning task [1])** as follows.\n\n`Example 1: Date Understanding`\n\n*Question*: Yesterday was April 30, 2021. What is the date today in MM/DD/YYYY?\n\n*Candidate Answer*: 05/01/2021 (correct), 05/02/2021 (wrong)\n\n*Backward question for the candidate answer 05/01/2021*:\nYesterday was April 30, 2021. What is the date **x** in MM/DD/YYYY? If we know the answer to the above question is **05/01/2021**, what is the English word at **x**?\n\n*Backward question for the candidate answer 05/02/2021*:\nYesterday was April 30, 2021. What is the date **x** in MM/DD/YYYY? If we know the answer to the above question is **05/02/2021**, what is the English word at **x**?\n\nIntuitively, the LLM is more likely to predict the word \"today\" given the correct candidate answer 05/01/2021. We leave the details as future work.\n\n`Example 2: Last-Letter-Concatenation`\n\n*Question*: Take the last letters of each word in \"Whitney Erika Tj Benito\" and concatenate them.\n\n*Candidate Answer*: yajo (correct), yaji (wrong)\n\n*Backward question for candidate answer yajo*:\nTake the last letters of each word in \"Whitney Erika Tj Benit[]\" and concatenate them. If we know the answer to the above question is **yajo**, what is the character at []?\n\n*Backward question for candidate answer yaji*:\nTake the last letters of each word in \"Whitney Erika Tj Benit[]\" and concatenate them. If we know the answer to the above question is **yaji**, what is the character at []?\n\nNote that we use \"[]\" to mask the character instead of \"x\" (which is also a character). The LLM is more likely to predict \"o\" correctly at [] given the candidate answer yajo than yaji. Hence, the proposed FOBAR can be used in other types of tasks by masking the informative word/token/character in the questions.\n\n(iii) Note that one major contribution of the proposed FOBAR is a **novel** method to combine forward and backward reasoning for verification (i.e., $\\mathbb{P}(\\hat{A}_c) \\propto (\\mathbb{P}\\_\\text{forward}(\\hat{A}_c) )^\\alpha (\\mathbb{P}\\_\\text{backward}(\\hat{A}_c) )^{1-\\alpha}$). The proposed method is **general** and **can be integrated into existing verification methods** (such as RCoT [3] and Self-Verification [4]) for non-arithmetic reasoning tasks."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299481055,
                "cdate": 1700299481055,
                "tmdate": 1700299481055,
                "mdate": 1700299481055,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4yEny7Y1In",
                "forum": "GhYXocT75t",
                "replyto": "uDv3aCL5UM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer PfVM (2/4)"
                    },
                    "comment": {
                        "value": "> Q2. \"The method lacks novelty as it bears a strong resemblance to RCoT which tries to re-generate the question conditioned on the candidate response. FOBAR seems essentially as an extension of the factual consistency check within RCoT. Moreover, the marginal difference in results between both methods further supports this perspective.\"\n\n**A2.** We believe there might be some misunderstanding. FOBAR is a **novel** method for verification and does **NOT** bear a strong resemblance to RCoT. \n\n(i) RCoT asks the LLM to reconstruct the conditions (a sentence) of the question and candidate answers, while FOBAR asks the LLM to predict a masked number in the question. Predicting a number is **easier** than reconstructing the condition (a sequence of tokens). Furthermore, **FOBAR is a novel method to combine forward and backward reasoning for verification, while RCoT uses the backward procedure alone for verification**.\n\n(ii) To check factual consistency, **RCoT needs three complex steps** ((1) problem decomposition: decompose the original problem $Q$ and reconstructed problem $\\hat{Q}$ into a list of and conditions $L_Q$ and $L_{\\hat{Q}}$; (2) condition comparison: query the LLM $nm$ times and conduct $mn$ comparisons to check whether their condition lists $L_Q$ and $L_{\\hat{Q}}$ are the same, where $m$ and $n$ are the length of $L_Q$ and $L_{\\hat{Q}}$, respectively; (3) question comparison: ask the LLM to checking whether the question is misinterpreted). However, FOBAR simply checks whether the masked number is predicted correctly, and is **much simpler and easier**. Moreover, the three steps taken by RCoT are not only complex, but also **costly** since the LLM must be queried $nm$ times. On the other hand, **FOBAR only requires performing inexpensive string comparisons**.\n\n(iii) The complex steps of RCoT in checking factual consistency can cause **inaccurate backward verification**. As can be seen from Table 1 of the submission, **FOBAR consistently performs better than RCoT**. Furthermore, the improvements in testing accuracy are large, e.g., on SVAMP (**+3.6**), GSM8K (**+2.8**), AQuA (**+10.1**).\n\n--- \n\n> Q3. \"Given that the experiments are carried out using OpenAI APIs, which undergo regular updates, it would be advisable to ensure that the baselines are run with the same API snapshots. The slight variance in the scores might be attributed to the differences in the API versions.\"\n\n**A3.** (i) Using the OpenAI APIs for CoT-based research is **standard**, e.g.,  Self-Consistency [5], ComplexCoT [6], Least-to-Most Prompting [7], Tree-of-Thoughts [8].\n\n(ii) We conducted the experiments using OpenAI's APIs between 1 August 2023 and 20 August 2023. The baselines (CoT, ComplexCoT, Self-Consistency, Self-Veri\ufb01cation) are based on the (roughly) same model snapshots as our FOBAR (**Note that only OpenAI itself can use the exactly same API snapshot**). For the other baselines (PHP, RE2, RCoT), we copy the results reported in their publications, which is **standard** in CoT-based research as querying OpenAI's API is expensive (e.g., RCoT [3], Self-Verification [4], ComplexCoT [6], Zero-Shot CoT [10], PAL [11]).\n\n(iii) **The improvements of FOBAR over baselines are consistent and large**. Table 1 in the submission shows that FOBAR achieves **higher** accuracies over baselines (e.g.,  FOBAR has much higher accuracy than previous SOTA methods on MultiArith (**+4.1**), SVAMP (**+3.7**), and GSM8K (**+2.9**) when using text-davinci-003 with CoT Prompting). These improvements are attributed to FOBAR, which combines forward and backward reasoning for verifying candidate answers."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299527704,
                "cdate": 1700299527704,
                "tmdate": 1700299527704,
                "mdate": 1700299527704,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "N4hh7FtIoR",
                "forum": "GhYXocT75t",
                "replyto": "uDv3aCL5UM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer PfVM (3/4)"
                    },
                    "comment": {
                        "value": "> Q4. \"How does the backward reasoning compare to verification of answers? E.g. Once you generate multiple candidate answers using forward reasoning, you can ask a model to \u201cverify\u201d the candidate answer given the whole context (Similar to verifier for GSM8K in Cobbe et al 2021)\"\n\n**A4.** Compared with Cobbe et al. (2021) [9] which trains an LLM for verifying answers, our FOBAR has two advantages. \n(i) **(training-free)** Compared with training an LLM for verifying candidate answers [9], which is computationally expensive and labor-intensive in collecting extra annotation data, backward reasoning for verifying is training-free and requires no additional data collection. \n(ii) **(more effective)** As training the GPT-3 (175B) is extremely expensive and their code is not publicly available, we compare our FOBAR with the result reported in Figure 5 of [9], where the candidate answers are generated by GPT-3. Table below shows the accuracy of GSM8K. As shown, FOBAR consistently performs much better than the trained verifier (+14.8). \n\n\\begin{array}{lc}\n\\hline\n\\text{Training GPT-3 (175B) for Verification [9]} & 56.0  \\newline\n\\text{FOBAR (text-davinci-003 + CoT)} & 70.8 \\newline\n\\text{FOBAR (text-davinci-003 + ComplexCoT)} & 78.7 \\newline\n\\text{FOBAR (GPT-3.5-Turbo + CoT)} & 85.1 \\newline\n\\text{FOBAR (GPT-3.5-Turbo + ComplexCoT)} & 87.4 \\newline\n\\text{FOBAR (GPT-4 + CoT)} & 95.4 \\newline\n\\text{FOBAR (GPT-4 + ComplexCoT)} & 96.4 \\newline\n\\hline\n\\end{array}\n\n---\n\n> Q5.Regarding my concern about OpenAI APIs getting updated regularly, have the authors used multiple different seeds for the experiments?\n\n**A5.** (i) As querying OpenAI's models is **costly**, we did not repeat the experiments using different seeds. This indeed is a **standard** practice in the CoT-based research literature (e.g., Self-Consistency [4], ComplexCoT [5], Least-to-Most Prompting [6], Tree-of-Thoughts [7]).\n\n(ii) **Additional experiment.**  To further resolve the reviewer's concern, we conducted an additional experiment on GSM8K using GPT-3.5-Turbo with ComplexCoT prompting. We repeat the experiment with three different seeds. Table below shows the testing accuracy. As can be seen, **FOBAR performs better than Self-Consistency on all three seeds**. Furthermore, **the improvement of FOBAR over Self-Consistency is statistically significant** (according to the pairwise t-test, with a p-value of 0.0013).\n\n\\begin{array}{lcccc}\n\\hline\n& \\text{seed 1} & \\text{seed 2} & \\text{seed 3} & \\text{mean $\\pm$ std} \\newline\n\\hline\n\\text{Self-Consistency} & 86.4 &86.7 & 86.2 & 86.43\\pm 0.25 \\newline\n\\text{FOBAR} & 87.4 &87.6& 87.1 & 87.37\\pm 0.25 \\newline\n\\hline\n\\end{array}\n\n(iii) **The improvements of FOBAR over the baselines are large and sufficient to confirm FOBAR is a better verifier**. As shown in our Table 1, FOBAR with ComplexCoT prompting consistently achieves the highest accuracy. When using CoT as the base prompt, FOBAR always has a higher accuracy than the baselines. These consistent improvements are sufficient to validate FOBAR is more effective in verification."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299560584,
                "cdate": 1700299560584,
                "tmdate": 1700299560584,
                "mdate": 1700299560584,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "U3CZfwLoiX",
                "forum": "GhYXocT75t",
                "replyto": "uDv3aCL5UM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer PfVM (4/4)"
                    },
                    "comment": {
                        "value": "> Q6. \"Given some known LLM behaviors and order of chains of arithmetic reasoning, do you think there will be a noticeable difference in performance if only the numbers at the end of the reasoning chains were masked to be predicted compared to numbers at the beginning of the reasoning?\"\n\n**A6.** There might be some misunderstanding. We mask the number in the question (as shown in Example 3.1 in the submission), **NOT** the number in the reasoning chains. We give another example below to demonstrate how to mask numbers in the question.\n\n*Question*: Gretchen has 110 coins. There are 30 more gold coins than silver coins. How many gold coins does Gretchen have?\n\n*Backward Question*: Gretchen has **x** coins. There are 30 more gold coins than silver coins. How many gold coins does Gretchen have? If we know the answer to the above question is $\\hat{A}_c$, what is the value of unknown variable **x**?\n\n*Backward Question*: Gretchen has 110 coins. There are **x** more gold coins than silver coins. How many gold coins does Gretchen have? If we know the answer to the above question is $\\hat{A}_c$, what is the value of unknown variable **x**?\n\n---\n\n## **References**\n\n[1] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Brian Ichter, Fei Xia, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. Neural Information Processing Systems, 2022.\n\n[2] Srivastava et al. (400+ authors). Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Transactions on Machine Learning Research, 2023.\n\n[3] Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, and Heng Ji. RCoT: Detecting and rectifying factual inconsistency in reasoning by reversing chain-of-thought. Preprint arXiv:2305.11499, 2023.\n\n[4] Yixuan Weng, Minjun Zhu, Shizhu He, Kang Liu, and Jun Zhao. Large language models are reasoners with Self-Veri\ufb01cation. Preprint arXiv:2212.09561, 2022.\n\n\n[5] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-Consistency improves chain of thought reasoning in language models. In International Conference on Learning Representations, 2023.\n\n[6] Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. Complexity-based prompting for multi-step reasoning. In International Conference on Learning Representations, 2023.\n\n[7] Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc V Le, and Ed H. Chi. Least-to-most prompting enables complex reasoning in large language models. In International Conference on Learning Representations, 2023.\n\n[8] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Grif\ufb01ths, Yuan Cao, and Karthik Narasimhan. Tree of Thoughts: Deliberate problem solving with large language models. In Neural Information Processing Systems, 2023.\n\n[9] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Hesse Christopher, and Schulman John. Training veri\ufb01ers to solve math word problems. Preprint arXiv:2110.14168, 2021.\n\n[10] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. In Neural Information Processing Systems, 2022.\n\n[11] Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. PAL: Program-aided language models. In International Conference on Machine Learning, 2023."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700299612574,
                "cdate": 1700299612574,
                "tmdate": 1700299612574,
                "mdate": 1700299612574,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xBTm86JKJP",
                "forum": "GhYXocT75t",
                "replyto": "uDv3aCL5UM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Any other concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer PfVM,\n\nWe would like to thank you again for your detailed reviews.\nWe hope that we have satisfactorily addressed your concerns.\n\nGiven that your current score is 3, we would be grateful if you could let us know whether our response has addressed your concerns or if you still have any other questions.\n\nWe would be happy to do any follow-up discussion or address any additional comments.\n\nBest, \n\nThe authors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700532885256,
                "cdate": 1700532885256,
                "tmdate": 1700532885256,
                "mdate": 1700532885256,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4Fw2o0HlK1",
                "forum": "GhYXocT75t",
                "replyto": "U3CZfwLoiX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Reviewer_PfVM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Reviewer_PfVM"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the responses"
                    },
                    "comment": {
                        "value": "My concern is regarding the extension of the method to other tasks. You mentioned you would \u201cmask informative word/token/character\u201d. How straightforward and beneficial would the method be? Given your example, it seems that for each task one would have to think about what would be the most beneficial part to mask from the input where other similar verification methods don\u2019t need this kind of manual design. \n\nMy question about the novelty was about the verification part of the method which still seems like a special case of RCoT or similar methods which predict the question/query based on candidate answers. \n\nSelf-Consistency [5] and ComplexCoT [6] amongst other methods experiment with different families of language models. Given the inconsistent results or small improvements from Table 1 in the submission, the submission would benefit from including other families of models (where experiments could be cheaper to carry out). \n\nI\u2019m not sure if not repeating experiments with multiple seeds is a \u201cstandard\u201d practice in LLM research [12] and [13] to name a few.\n \n\nRegarding Q6, you\u2019re right. Would there be a noticeable difference in performance if only numbers early in the question are masked compared to numbers towards the end of the questions?\n\n\n[12] Alessandro Sordoni, Xingdi Yuan, Marc-Alexandre C\u00f4t\u00e9, Matheus Pereira, Adam Trischler, Ziang Xiao, Arian Hosseini, Friederike Niedtner, Nicolas Le Roux. Deep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference. Neurips 2023\n\n[13] Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, Pontus Stenetorp. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ACL 2022"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579181694,
                "cdate": 1700579181694,
                "tmdate": 1700579181694,
                "mdate": 1700579181694,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BTG7l7oKaR",
                "forum": "GhYXocT75t",
                "replyto": "uDv3aCL5UM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4976/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to further comments (1/2)"
                    },
                    "comment": {
                        "value": "Thanks for your further comments. We address your concerns as follows.\n\n> Q7. My concern is regarding the extension of the method to other tasks. You mentioned you would \u201cmask informative word/token/character\u201d. How straightforward and beneficial would the method be? Given your example, it seems that for each task one would have to think about what would be the most beneficial part to mask from the input where other similar verification methods don\u2019t need this kind of manual design.\n\n**A7.** (i) Please note that the focus of this work is on **mathematical tasks, as emphasized in the title.** (ii) For mathematical tasks, the proposed template and FOBAR are **very general** (masking a number and predicting it). (iii) The two examples given in A1 are intended to demonstrate the possibility of extending our method to non-arithmetic tasks, which is **NOT the focus of this work**.\n(iv) For mathematical tasks, numbers are informative; However, for non-arithmetic tasks, how to select information words/marks/characters still needs to be manually designed, as two examples are given in A1. Extending FOBAR to non-arithmetic tasks is **future work**. Currently, our FOBAR focuses on mathematical tasks and does **NOT** try to solve **all verification problems**.\n\n---\n\n> Q8. My question about the novelty was about the verification part of the method which still seems like a special case of RCoT or similar methods which predict the question/query based on candidate answers.\n\n**A8.** We have discussed our FOBAR with RCoT in Related Work of the submission and the above reply A2. We reiterate as follows:\n\n`Similarity`: Both RCoT and FOABR **use LLMs** to reconstruct/predict a missing condition in questions for verification.\n\n`Differences` (as summarized in the Table below): \n\n(i) **Where to mask**: \n- RCoT masks **a sequence of tokens**\n- FOBAR masks **a number** in the question. \n\n(ii) **How to check factual consistency**\n- RCoT needs to check the consistency of a sequence of tokens, which is very challenging. Hence, RCoT needs **three complex steps** (problem decomposition, condition comparison, question comparison) and queries the LLM $nm$ times, which is **expensive** ($m$ and $n$ are the lengths of conditions in the original and reconstructed questions, respectively)\n- FOBAR **simply** checks whether the masked number is predicted exactly by **string comparison**, which is **free**.\n\n(iii) **How to verify**\n- RCoT **uses backward verification alone**\n- FOBAR **combine both forward and backward reasoning** for verification.\n\n\n(iv) **Performance**\n- **Three complex** checking steps lead to **inacurate verification** in RCoT.\n- As shown in the table below (or Table 1 of the submission), FOBAR has **much higher** accuracy than RCoT, e.g., SVAMP (**+3.6**), GSM8K (**+2.8**), AQuA (**+10.1**).\n\n\\begin{array}{c|c|c}\n\\hline\n& \\text{RCoT} & \\text{FOBAR} \\newline\n\\hline\n\\text{where to mask} & \\text{a sequence of tokens} & \\text{a number} \\newline\n\\hline \\text{how to check factual consistency} & \\text{three complex steps} & \\text{simple string comparison} \\newline\n\\hline\n\\text{how to verify} & \\text{use backward verification alone} & \\text{combine forward and backward reasoning together} \\newline\n\\hline\n\\text{performance} & \\text{inaccurate} & \\text{much more accurate} \\newline\n\\text{Accuracy on SVAMP} & \\text{84.2} & \\text{88.9 (+3.6)} \\newline\n\\text{Accuracy on GSM8K} & \\text{84.6} & \\text{87.4 (+2.8)} \\newline\n\\text{Accuracy on AQuA} & \\text{53.3} & \\text{63.4 (+10.1)} \\newline\n\\hline\n\\end{array}\n\n---\n\n> Q9. Self-Consistency [5] and ComplexCoT [6] amongst other methods experiment with different families of language models. Given the inconsistent results or small improvements from Table 1 in the submission, the submission would benefit from including other families of models (where experiments could be cheaper to carry out).\n\n**A9.** As shown in Table 1, for all **three** LLMs, our FOBAR achieves **consistently** higher accuracy (averaged over **six** tasks) than previous SOTA. Note that the improvements are **NOT** marginal, e.g., FOBAR has large improvements on MultiArith (+4.1), SVAMP (+3.7), and GSM8K (+2.9) when using *text-davinci-003* with CoT Prompting. Experimenting with other families of models is a good suggestion. However, as experiments in the submission are **extensive** (three SOTA LLMs, six datasets, two base prompts), the **consistent** results are **sufficient** to verify that FOBAR is more effective than previous methods.\n\n---\n\n> Q10. I\u2019m not sure if not repeating experiments with multiple seeds is a \u201cstandard\u201d practice in LLM research [12] and [13] to name a few.\n\n**A10.** Indeed, most CoT-based stuidies (e.g., Self-Consistency [4], ComplexCoT [5], Least-to-Most Prompting [6], Tree-of-Thoughts [7]) do not conduct repeated experiments, as querying OpenAI's API is costly. In addition, we **have provided a repeated experiment** on *GSM8K* in A5 to resolve your concern."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4976/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700587007792,
                "cdate": 1700587007792,
                "tmdate": 1700664082884,
                "mdate": 1700664082884,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]