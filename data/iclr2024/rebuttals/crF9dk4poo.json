[
    {
        "title": "Interpretable Deep Clustering"
    },
    {
        "review": {
            "id": "lMJJcmYtem",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5027/Reviewer_viN8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5027/Reviewer_viN8"
            ],
            "forum": "crF9dk4poo",
            "replyto": "crF9dk4poo",
            "content": {
                "summary": {
                    "value": "The author proposed a new deep-learning framework for tabular data that predicts interpretable cluster assignments at the instance and cluster levels. They also  validated the performance in both synthetic and tabular biological datasets. However, this article overall did not meet the requirements of ICLR."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is easy to follow\n2. The experiments are comprehensive"
                },
                "weaknesses": {
                    "value": "1. The motivation is not clear, I don not understand what is interpretable clustering model and why we need  interpretable clustering model.\n2. The overall method is just the combination of existing approaches, the novelty is limited\n3. I don not agree with the authors the empirical diversity, faithfulness and uniqueness can represent  interpretability\n4. The manuscript was not well prepared. It contains obvious typos, such as the citation \"?\" in third line of page six\n5. The improvement in real-world dataset is not significant"
                },
                "questions": {
                    "value": "1. The motivation is not clear, I don not understand what is interpretable clustering model and why we need  interpretable clustering model.\n2. The overall method is just the combination of existing approaches, the novelty is limited\n3. I don not agree with the authors the empirical diversity, faithfulness and uniqueness can represent  interpretability\n4. The manuscript was not well prepared. It contains obvious typos, such as the citation \"?\" in third line of page six\n5. The improvement in real-world dataset is not significant"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5027/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5027/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5027/Reviewer_viN8"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5027/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697422581260,
            "cdate": 1697422581260,
            "tmdate": 1700445393001,
            "mdate": 1700445393001,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LmImzZrLvI",
                "forum": "crF9dk4poo",
                "replyto": "lMJJcmYtem",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer viN8"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the time and effort spent in this review and for appreciating that the paper is easy to follow and that the experiments are comprehensive. Below, we address all comments raised by the reviewer.\n\nP1 Motivation of interpretable clustering-\n\nThe second paragraph in the introduction motivates our interpretable clustering method. To elaborate on the problem, we offer the following paragraph:\n\nThe main goal of clustering methods is to partition the data into semantically related groups. In some use cases, it is sufficient to assess the separability of the clusters to evaluate the clustering quality. However, clusters are used in many applications for downstream tasks, such as scientific discovery, decision-making, medical analysis, and more. In such cases, cluster assignment interpretations are crucial for annotating the clusters manually. Cluster interpretability is also vital for quality assessment, model validation, and gaining trust in practitioners. \n\nFor example, let\u2019s consider the task of cell clustering (also mentioned in the introduction). Common practice is to use clustering and then manually analyze each cluster to identify which cell types it represents. Cell annotation is vital for downstream tasks, such as drug discovery, personalized treatment, and automated diagnosis and prognosis. In these cases, identifying cluster-level and sample-level informative features is crucial for labeling the clusters and validating the separation. Another example is a medical setting where we seek groups of patients with similar characteristics. In such applications, doctors seek to understand what makes each cluster unique in terms of demographics, genetic information, and diagnostics.\n\n\n\n\nP2- Novelty of technical elements-\n\nWe appreciate the feedback regarding the perceived limited novel elements in our framework. We want to address this comment by highlighting the contributions of our work, which goes beyond the technical algorithmic components. \n\nThe novelty of our work could be briefly summarized as follows:\nFormulate an interpretable clustering task that highlights sample and cluster-level informative features. \nGeneralize the unsupervised feature selection with clustering problem to the dynamic sample-wise setting.\nPresent an end-to-end neural network-based solution to the proposed interpretable clustering problem. Besides integrating existing methodologies, we have also introduced new (or modified) components. These include (1) a pre-training augmentation scheme that does not require domain-specific knowledge (as used in vision, audio, NLP), see full details Appendix G. (2) The gates coding loss (Eq. 4), which encourages uniqueness of the sample-specific gates. (3) Combining a Gumbel-softmax clustering head with the maxima coding rate loss (eq. 6).\nExtensive empirical evaluation of the model's ability to explain its predictions and perform accurate clustering using synthetic and real-world image and tabular data.\n\nAs a final remark about novelty, we want to emphasize that many well-celebrated papers in the machine-learning community rely on the combination and adaptation of existing schemes; examples of such works include [1], [2], [3]. We believe that this should be encouraged by the community. The main novelty here is that the presented problem and solution were never addressed.\n\n[1] He et al.\u201d Deep Residual Learning for Image Recognition, 2016\u201d used skip connections (already an existing technique) to enable gradient propagation in deep layers.\n\n[2] Vaswani et al. \u201cAttention Is All You Need\u201d- They used the attention mechanism (commonly applied for text) to image data.\n\n[3] Devlin et al.\u201d BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u201d- used existing transformer techniques but trained to predict text conditioned on both left and right context in all layers."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5027/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700217123848,
                "cdate": 1700217123848,
                "tmdate": 1700219171239,
                "mdate": 1700219171239,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DwIlBXubhj",
                "forum": "crF9dk4poo",
                "replyto": "lMJJcmYtem",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer viN8 part 2"
                    },
                    "comment": {
                        "value": "P3 Interpretability metrics-\n\nThe main goal of interpretability in ML models is to make the predictions more understandable and transparent for humans; diversity, faithfulness, and uniqueness do not \u201crepresent\u201d interpretability; instead, they were proposed in [1,2] as objective metrics to compare different qualities of interpretability models.\nDiversity measures how well the interpretability model captures the differences between groups (clusters) and is not overly focused on specific features globally.\nFaithfulness evaluates how well the explanations coincide with the mechanism that drives the decision of the ML model. \nUniqueness generalizes diversity by measuring how the interpretability model can capture different nuances within a cluster. For instance, if a specific cluster has high uniqueness values, the user can interpret that the cluster might contain a union of two (or more) subgroups with distinct characteristics.\n\nWe adopt these metrics to provide quantitative comparisons between different schemes. In practice, users can use these metrics to select which method to use and analyze the quality of the clusters and clustering model. We would be happy to include other metrics that the reviewer thinks are more useful for measuring the qualities of our model.\n\nThese metrics were proposed in prior work to evaluate model interpretability quality [1,2]. \nWe agree with the reviewer that interpretability is a broad concept with different implementations. In this work, we do not focus on the model interpretability in terms of its architecture. This work focuses on predictions interpretability, and we follow previous works [1,2] that proposed diversity and faithfulness. In addition, since we claim that the model produces unique explanations for each sample, we propose the uniqueness metric. The intuition is that the dataset staples are generally not exact duplicates, and each sample has its uniqueness.\n\t\n[1] David Alvarez Melis and Tommi Jaakkola. Towards robust interpretability with self-explaining neural networks. Advances in neural information processing systems, 31, 2018.\n[2] Junchen Yang, Ofir Lindenbaum, and Yuval Kluger. Locally sparse neural networks for tabular biomedical data. In the International Conference on Machine Learning, pp. 25123\u201325153. PMLR, 2022. \n\nP4 Typos-\n\nThanks for this comment; we have fixed this issue caused by a technical error. Furthermore, following this comment, we have looked for additional typos. We would be happy to correct any typos the reviewer is aware of.\nP5 Performance improvement- \nWhile in some datasets, clustering accuracy improvement is not significant compared to SOTA baselines; we argue that those results require careful tuning of the unsupervised feature selection method to obtain these competitive results. In contrast, our method does not require any parameter tuning. Since clustering with tabular data is challenging, several works have shown that NN-based solutions tend to be inferior to unsupervised feature selection models followed by K-means [1] [2]. When we compare our result to K-means,  our method leads to an average improvement of more than 37% in clustering accuracy. Furthermore, the main advantage of our method is interpretability, serving as the only method that provides sample-level and cluster-level informative features while improving the SOTA clustering capabilities on most of the datasets. \n\n[1] Abrar et al. Effectiveness of Deep Image Embedding Clustering Methods on Tabular Data, 2023.\n\n[2] Solorio-Fern\u00e1ndez et al. A review of unsupervised feature selection method, 2019\n    \nWe thank the reviewer again for these constructive comments that helped improve our paper.\nWe would happily provide additional information if the reviewer still has any open issues or questions."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5027/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700217210056,
                "cdate": 1700217210056,
                "tmdate": 1700219144457,
                "mdate": 1700219144457,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nRhlwWQHOk",
                "forum": "crF9dk4poo",
                "replyto": "DwIlBXubhj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5027/Reviewer_viN8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5027/Reviewer_viN8"
                ],
                "content": {
                    "title": {
                        "value": "Raising rating"
                    },
                    "comment": {
                        "value": "Thanks for you careful responses.  I agree with the authors the interpretable clustering method is important for many bioinformatics tasks. We did several works about image clustering in the past years. Actually, the recent image clustering methods, such as SCAN[1],  GCC[3] and TCC[4], perform extremely well on many image datasets that are more challenging than MNIST.  In my opinion, the proposed method is relatively outdated. I understand that applying these state-of-the-art approaches to biological information takes time, so I will raise my rating to 5: marginally bellow the acceptance threshold.\n\n[1]Van Gansbeke W, Vandenhende S, Georgoulis S, et al. Scan: Learning to classify images without labels[C]//European conference on computer vision. Cham: Springer International Publishing, 2020: 268-285. \n\n[2]Zhong H, Wu J, Chen C, et al. Graph contrastive clustering[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2021: 9224-9233. \n\n[3]Shen Y, Shen Z, Wang M, et al. You never cluster alone[J]. Advances in Neural Information Processing Systems, 2021, 34: 27734-27746."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5027/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700445318878,
                "cdate": 1700445318878,
                "tmdate": 1700445318878,
                "mdate": 1700445318878,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "v25GxLe9K7",
                "forum": "crF9dk4poo",
                "replyto": "lMJJcmYtem",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer viN8"
                    },
                    "comment": {
                        "value": "We want to thank the reviewer for acknowledging the importance of the addressed problem and for raising the score. Thanks for pointing out these image clustering models. Indeed, the methods presented in [1,2,3] can provide accurate clustering assignments on image data. However, it is important to note that (1) they do not include any interpretability component and, therefore, do not address our primary objective. (2) can not be easily adapted to tabular data while maintaining high clustering capabilities. Specifically, all these methods use self-supervision and, more specifically, rely on data augmentation to create positive and negative pairs. Creating meaningful augmentations is feasible in vision because we understand the different properties of the domain. For example, we know that small color changes, rotations, translations, and rescalings do not change the \u201clabel\u201d of the image and can be used to create positive pairs. In tabular data, we do not have this privilege, and augmentations are restricted to additive noise and masking, which, in practice, do not lead to significant performance gains [4,5,6]. \nNonetheless, following the reviewer's suggestion, we have evaluated the GCC [2,6] method on two datasets (1) MNIST train split (60K samples, 784 features, 10 clusters), (2) a biomed PBMC dataset (20,742 samples, 17,126 features, 2 clusters). We used random zero masks for augmentation, similar to what we used in our paper. The architecture is an MLP with layers: [input, 512, 512, 2048, 512] as a backbone. We train GCC on these datasets during 300 epochs for the MNIST dataset and 100 epochs for the PBMC dataset; we present here the clustering accuracy results:\n| Dataset | ACC (*GCC*)  | ACC (*Our*) |\n|----------|----------|----------|\n| MNIST$_{60K}$ |  63.52 | **87.90** |\n| PBMC-2 | 52.31 | **61.56** |\n\nWe thank the reviewer again for these constructive comments that helped improve our paper.\nWe would be happy to provide additional information if the reviewer still has any open issues or questions.\n\n[1] Van Gansbeke W, Vandenhende S, Georgoulis S, et al. Scan: Learning to classify images without labels[C]//European conference on computer vision. Cham: Springer International Publishing, 2020: 268-285.\n\n[2] Zhong H, Wu J, Chen C, et al. Graph contrastive clustering[C]//Proceedings of the IEEE/CVF international conference on computer vision. 2021: 9224-9233.\n\n[3] Shen Y, Shen Z, Wang M, et al. You never cluster alone[J]. Advances in Neural Information Processing Systems, 2021, 34: 27734-27746.\n\n[4] Mai et al. Understanding the limitations of self-supervised learning for tabular anomaly detection. Arxiv, 2023\n\n[5] Hajiramezanali et al. STab: Self-supervised Learning for Tabular Data. NeurIPS 2022 Workshop on Table Representation Learning.\n\n\n[6] https://github.com/mynameischaos/GCC"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5027/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700604448057,
                "cdate": 1700604448057,
                "tmdate": 1700636932951,
                "mdate": 1700636932951,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Tf9FJb0ruG",
            "forum": "crF9dk4poo",
            "replyto": "crF9dk4poo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5027/Reviewer_AryA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5027/Reviewer_AryA"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces an Interpretable Deep Clustering model that predicts an informative feature set for improved interoperability. Leveraging a self-supervised reconstruction task, the method employs stochastic gates to learn instance-level feature selection, which can be extended to the cluster-level form. The two-stage training process involves losses encompassing reconstruction errors and various constraint terms. Overall, the paper offers valuable insights and demonstrates its superiority in terms of performance and interoperability."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-structured, featuring clear logic and technical explanations that allow readers to easily follow the authors' design. Additionally, the manuscript is well-written overall, demonstrating proficient English grammar and adhering to a formal writing style that aligns with academic standards for technical manuscripts.\n2. The proposed method is technically sound and demonstrates impressive performance on both synthetic and real datasets.\n3. The paper's approach to designing a clustering model with a focus on interoperability offers an intriguing perspective."
                },
                "weaknesses": {
                    "value": "1. The paper's novelty appears to be somewhat incremental, as it combines existing unsupervised feature selection (stochastic gates) with deep clustering, lacking significant novel elements.\n2. The main design of the model lacks a theoretical guarantee. For instance, the reasoning behind choosing an autoencoder (AE) over other self-supervised tasks, such as contrastive learning, requires clarification.\n3. The method's generalizability to unseen data is not adequately explained. Eq. (6) suggests high computational complexity, necessitating a discussion on the complexity for better understanding.\n4. The experiment comparison seems biased. While the proposed method employs strong feature transformation by DNN, competitors like k-means do not. Hence, a fair comparison with state-of-the-art deep clustering models is essential.\n5. It would be beneficial to discuss the model's performance on a large-scale dataset to provide a comprehensive evaluation.\n6. The subscripts in Eq. (6) should be carefully reviewed for accuracy."
                },
                "questions": {
                    "value": "Please see the cons for details."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5027/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698769803212,
            "cdate": 1698769803212,
            "tmdate": 1699636491573,
            "mdate": 1699636491573,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RluybduLeH",
                "forum": "crF9dk4poo",
                "replyto": "Tf9FJb0ruG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer AryA"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the time and effort spent in this review and for appreciating our writing and the quality of our results. Below, we address all comments raised by the reviewer.\n\nP1- Technical novelty-\nWe appreciate the feedback regarding our framework's perceived lack of significant novel elements. We want to address this comment by highlighting the contributions of our work, which goes beyond the technical algorithmic components. \n\nThe novelty of our work could be briefly summarized as follows:\nFormulate an interpretable clustering task that highlights sample and cluster-level informative features. \nGeneralize the unsupervised feature selection with clustering problem to the dynamic sample-wise setting.\nPresent an end-to-end neural network-based solution to the proposed interpretable clustering problem. Besides integrating existing methodologies, we have also introduced new (or modified) components. These include (1) a pre-training augmentation scheme that does not require domain-specific knowledge (as used in vision, audio, NLP), see full details Appendix G. (2) The gates coding loss (Eq. 4), which encourages uniqueness of the sample-specific gates. (3) combining a Gumbel-softmax clustering head with the maximal coding rate reduction loss (eq. 6).\nExtensive empirical evaluation of the model's ability to explain its predictions and perform accurate clustering using synthetic and real-world image and tabular data.\n\nAs a final remark, we want to emphasize that many well-celebrated papers in the community rely on the combination and adaptation of existing schemes; examples include [1], [2], [3]. We believe that this should be encouraged by the community. The main novelty is that the presented problem and solution were never addressed.\n\n[1] He et al.,\u201d Deep Residual Learning for Image Recognition, 2016\u201d used skip connections (already an existing technique) to enable gradient propagation in deep layers.\n\n[2] Vaswani et al. \u201cAttention Is All You Need\u201d- used the attention mechanism (commonly applied to text) for image data.\n\n[3] Devlin et al.\u201d BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u201d- used existing transformer techniques but trained to predict text conditioned on both left and right context in all layers.\n\nP2- AE:\n\nIndeed, contrastive learning is a powerful tool for self-supervision but requires data augmentations to create \u201cpositive pairs.\u201d In vision, audio, and NLP, we can use domain knowledge to design augmentations that preserve each sample's semantic information. Developing such augmentations for tabular data is much more challenging. The main goal of our work is to present a self-supervised scheme for tabular data (for instance, genomic data). Therefore, we decided to use an autoencoder (AE), which was demonstrated effective for clustering and unsupervised feature selection in prior work [4,5,6]. It is important to note that we did not use a standard AE; instead, we have introduced perturbation to the input and latent pairs (see full details Appendix G), which strengthens the ability of our model to identify informative features. We will clarify this in the main text.\nRegarding the theoretical analysis, we are currently working on analyzing the feature selection capabilities of our model, but this requires a particular data model and, therefore, does not fit the message of the current paper.\n[4] Xie, et al. \"Unsupervised deep embedding for clustering analysis\" 2016.\n\n[5] Sokar et al. \"Where to pay attention in sparse training for feature selection?\" 2022.\n\n[6] Li et al. \"Reconstruction-based unsupervised feature selection\" 2017.\n\t\t\t\t\n\n\nP3 - Generalizability-\n\nSince our method is fully parametric, it offers generalization capabilities. Our model can predict cluster assignments and informative features for samples not seen during training. We have verified the generalization capabilities of our model in the MNIST experiment. We have predicted the assignments for 10,000 unseen samples. As indicated by the results presented in Table 3, on unseen samples, our model leads to similar clustering accuracies and uses the same amount of selected features. We will clarify this in the text."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5027/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700216307887,
                "cdate": 1700216307887,
                "tmdate": 1700219265245,
                "mdate": 1700219265245,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pbzjApTw0B",
            "forum": "crF9dk4poo",
            "replyto": "crF9dk4poo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5027/Reviewer_6xNv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5027/Reviewer_6xNv"
            ],
            "content": {
                "summary": {
                    "value": "The authors develop a novel deep clustering and feature selection method. The proposed model employs a two-stage approach. In the first stage, a Gating Network and an autoencoder are used for self-supervised learning of latent representations and sample-level informative features. In the second stage, a clustering head is trained to predict cluster assignments based on these latent embeddings. The model aims to provide both instance-level and cluster-level explanations by selecting a subset of features that are most informative for each cluster. The paper validates the model's performance through a series of experiments conducted on synthetic datasets, including well-known benchmarks like MNIST, FashionMNIST, and CIFAR10. The experiments show the model outperforms other clustering strategies while maintaining interpretability. The paper also includes ablation studies to understand the impact of various components of the model on its performance."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Comprehensive Experiments: the paper conducts a wide range of experiments across multiple datasets, including synthetic datasets, MNIST, FashionMNIST, and CIFAR10. A exploration of the time it takes to run the the method according to dataset size is also provided. \n\nInterpretability Focus: one of the key strengths of the paper is its focus on interpretability. The model aims to provide both instance-level and cluster-level explanations, which is crucial for understanding the model's decisions and could be particularly useful in sensitive applications.\n\nInnovative Approach: the paper proposes a novel two-stage approach that combines self-supervised learning for feature selection and a clustering head for cluster assignment. This is an innovative way to tackle the problem and could inspire future research in this area.\n\nAblation Studies: the paper includes ablation studies to understand the impact of various components of the model, confirming that are components of the method are, indeed, relevant to its performance."
                },
                "weaknesses": {
                    "value": "The paper addresses everything I would expect in a clustering paper, especially with the interpretability focus.\nPerhaps the only weakness would be the lack of a deeper discussion on interpretability and its different perspectives in machine learning, but that does not decrease the quality of the paper."
                },
                "questions": {
                    "value": "-"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5027/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698776285228,
            "cdate": 1698776285228,
            "tmdate": 1699636491451,
            "mdate": 1699636491451,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SzkKURbTDj",
                "forum": "crF9dk4poo",
                "replyto": "pbzjApTw0B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5027/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6xNv"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the time and effort spent in the review and for appreciating our new method and the reported results. Bellow, we address all comments raised by the reviewer\n\n\nThanks for your comment about interpretability; we added the following paragraph to deepen the discussion on interpretability:\n\nInterpretability in machine learning refers to the ability to understand and explain the predictions and decisions made by the predictive models. It's critical for properly deploying machine learning systems, especially in applications where transparency and accountability are essential. Interpretability comes in different forms, to name a few: interpretable model structure, identifying feature importance for model predictions, visualization of data, and generation of explanations for the prediction. In this work, we aim to design a model that achieves interpretability by sample-wise feature selection and generating cluster-level interpretations of model results. This type of interpretability is crucial for biomedical applications, for example, when seeking marker genes that are \u201ctypical\u201d for different clusters in high throughput biological measurements."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5027/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700214958541,
                "cdate": 1700214958541,
                "tmdate": 1700214958541,
                "mdate": 1700214958541,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]