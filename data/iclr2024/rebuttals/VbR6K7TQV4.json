[
    {
        "title": "Learning the Latent Noisy Data Generative Process for Label-Noise Learning"
    },
    {
        "review": {
            "id": "uEugwAfLbj",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
            ],
            "forum": "VbR6K7TQV4",
            "replyto": "VbR6K7TQV4",
            "content": {
                "summary": {
                    "value": "Although inferring noise transition is crucial, its inference is limited from assumptions of the relations between instances and its respective noise transitions. This relation should be trained as latent (by learning noisy data generative process). This paper learns this relation by introducing graph structure. Empirically, it shows good performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The motivation which underlines the problems of the previous studies, the assumption of the similarity of noise transitions, is adequate.\n- The structure is flexible."
                },
                "weaknesses": {
                    "value": "- To the best of my knowledge, BLTM (one of the baselines in the experiment part), which trains a instance-dependent transition matrix network using the distilled dataset, has no assumption for the similarity between noise transition for different instances. I think this study contradicts to author's proposal, which says, there are assumptions of similarity in the previous researches.\n- Since Y is latent, there is no way to prove that Y is true (so that the authors relied on distillation). Therefore, it means the authors actually makes an another assumption saying that the distilled dataset is clean.\n- Since it should generate X (usually an image), time complexity and memory will be large. Why should we generate an image to classify? Also want to see the exact time and memory comparison over several baselines.\n- Lack of any analysis. In the experiment part, nothing but the test accuracy are reported. Please show analytical empirical results for whether the training are processed as authors proposed. For example, at least whether the error of the inferred transition is small or not should be expressed."
                },
                "questions": {
                    "value": "- Can authors show (at least, the empirical) evidences of the proposal saying that \"noise transitions can be inferred of a special group of instances\"?\n- Why should we use graph structure? Can't this structure be changed to other structure?\n- How can we be sure that the process the authors proposed improve the model performance?\n- Why using the estimated clean labels from distillation is not enough? As the authors said, distillation methods are well studied. By pointing out that the model performance of the method the authors proposed should depend on the quality of the estimated clean labels, the distilled labels should be clean enough. If the estimated labels are clean enough, why should we do more process fundamentally?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7806/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697363233948,
            "cdate": 1697363233948,
            "tmdate": 1699636955194,
            "mdate": 1699636955194,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5BLHUf3ROM",
                "forum": "VbR6K7TQV4",
                "replyto": "uEugwAfLbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XDR1"
                    },
                    "comment": {
                        "value": "We sincerely thank you for your time and effort in reviewing our manuscript and providing valuable comments. Please find the response to your comments below.\n\n**Q1: BLTM has no assumption for the similarity between noise transition for different instances, thus the study on BLTM contradicts the author's proposal.**\n\n**A1**: BLTM can learn the noise transition of some examples using a neural network. The authors of BLTM hope the network can generate the noise transition for unseen instances. However, the author does not discuss how to generalize the learned noise transition to other examples, and they do not provide a theoretical guarantee that the noise transition can be generalized. Some hidden assumptions must exist to build the connection. Otherwise, the noise transition can not be generalized to other examples. Our claim focuses on the methods that have theoretical guarantees on the generalization of noise transitions, e.g., the noise transition is class-dependent, and the noise transition for the instances in the same manifold is the same. To avoid confusion, we have modified the paper.\n\nWe are the first to explore when the learned noise transition in some instances can be generalized to other instances in learning with noisy labels. Our aim is to enable deep neural networks to capture the connections of noise transitions among different instances automatically. Since once the connections are captured, the noise transition learned in some examples can be generalized to other examples. To achieve this, we need to model the joint distribution of all variables $p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})$. The noise transition can be obtained through\n$$\np(\\tilde{Y}|\\mathbf{X},Y)=\\frac{\\int_{\\mathbf{Z},\\mathbf{N}}p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})d\\mathbf{Z}d\\mathbf{N}}{\\int_{\\tilde{Y},\\mathbf{Z},\\mathbf{N}}p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})d\\tilde{Y}d\\mathbf{Z}d\\mathbf{N}}.\n$$\nTo obtain this joint distribution, we propose a principled way to model the whole data generative process. Specifically, we not only model the generative process from the latent variable $\\mathbf{Z}$ to the instance $\\mathbf{X}$ but also model and learn causal structure among different latent variables $\\{Z_1,Z_2,\\dots,Z_m\\}$ from observed noisy data. \n\nTo achieve this, the generation of the variable $\\mathbf{N}$ is modeled by a Gaussian distribution. The generation of the latent variable $\\mathbf{Z}$ is modeled by a Structure Causal Model (SCM): $Z_i:=\\mathbf{W}^T_i \\mathbf{Z}+N_i$, where $\\mathbf{W}$ is a matrix used to represent the association among the latent variables. Two generators are used to model the generation of the instance $\\mathbf{X}$ and the noisy label $\\tilde{Y}$, respectively.\n\nMoreover, our paper has analyzed the identifiability of the proposed method theoretically in Appendix C. We discuss the conditions required for identifiability. Specifically, when the number of distinct classes is large (more than the sufficient statistics of the latent variable $\\mathbf{Z}$) and we have a confident example in each class, the latent variable $\\mathbf{Z}$ can be identified up to permutation. \n\n**Q2: The authors actually make another assumption, saying that the selected dataset is clean.**\n\n**A2**: We assume that the selected dataset is likely clean. This assumption is reasonable because the accuracy of the selected dataset is high empirically. For example, when the dataset is CIFAR-10, and the noise type is \"worst\", the accuracy of the selected dataset is 0.9568.\n\nIt is also worth mentioning that without clean labels, recovering the causal factor $\\mathbf{Z}$ is an ambitious goal and generally impossible. This is because the nonlinear mixture function $f(\\cdot)$ used to generate observed variable $\\mathbf{X}$ is unknown. A variable $\\mathbf{Z}'$ can be constructed via a nonlinear function $\\mathbf{Z}'=g(\\mathbf{Z})$. Another nonlinear mixture function $f'(\\cdot)$ can generate the same observation, i.e., $\\mathbf{X}=f'(\\mathbf{Z}')$. Previous studies also prove that it is ill-posed to recover the latent causal factors with only the observed variables [1,2]. Existing methods in causal representation learning also have to use the auxiliary variables to recover the causal factors [3,4]. In the context of learning with noisy labels, auxiliary variables necessitate clean labels.\n\n**Q3: Time complexity and memory will be large.**\n\n**A3**: The proposed method does not increase the time complexity and memory because the encoder and the decoder introduced by our method are lightweight. The training time of the proposed method on CIFAR-10 is 13.68 hours, and the training time of DivideMix is 9.08 hours. The memory used for the proposed method is 7.06 GB, and the memory used for DivideMix is 6.99 GB.\n\nMoreover, the encoder and decoder can be discarded during inference. The inference time is the same as the time of baselines."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700303387127,
                "cdate": 1700303387127,
                "tmdate": 1700694726773,
                "mdate": 1700694726773,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zK7JybcGEK",
                "forum": "VbR6K7TQV4",
                "replyto": "uEugwAfLbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XDR1 (Continue)"
                    },
                    "comment": {
                        "value": "**Q4: Whether the error of the inferred transition is small or not should be expressed.**\n\n**A4**: We have conducted experiments on the dataset CIFAR-10 to calculate the noise transition estimation error. The labels are corrupted manually using the instance-dependent noisy label generation method proposed in [5]. The baselines used to compare the noise transition estimation error are BLTM, MEIDTM and VolMinNet. The experiment results are shown as follows.\n\n|           | IDN-10%               | IDN-20%               | IDN-30%               | IDN-40%               | IDN-50%               |\n| --------- | --------------------- | --------------------- | --------------------- | --------------------- | --------------------- |\n| BLTM      | 0.275 $\\pm$ 0.022     | 0.339 $\\pm$ 0.020     | 0.467 $\\pm$ 0.008     | 0.670 $\\pm$ 0.106     | 0.816 $\\pm$ 0.056     |\n| MEIDTM    | 0.240 $\\pm$ 0.002     | 0.374 $\\pm$ 0.001     | 0.563 $\\pm$ 0.001     | 0.775 $\\pm$ 0.002     | 0.985 $\\pm$ 0.001     |\n| VolMinNet | 0.477 $\\pm$ 0.005     | 0.590 $\\pm$ 0.000     | 0.680 $\\pm$ 0.000     | 0.720 $\\pm$ 0.000     | 0.783 $\\pm$ 0.005     |\n| GenP      | **0.224 $\\pm$ 0.005** | **0.302 $\\pm$ 0.016** | **0.374 $\\pm$ 0.008** | **0.434 $\\pm$ 0.021** | **0.548 $\\pm$ 0.041** |\n\nEmpirical results show that our method can reduce the error of inferred noise transition.\n\n**Q5: Why should we use graph structure?**\n\n**A5**: To model the causal structure among latent variable $\\mathbf{Z}$, the graph structure has to be used. This is because the causal structure among $\\mathbf{Z}$ is a part of the noisy data generative process. As mentioned in A1, modeling the noisy data generative process can obtain the joint distribution $p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})$, then the connections of noise transitions among different instances can be captured automatically. The more accurately the generation process is modeled, the more accurate the joint distribution obtained will be.\n\n**Q6: Evidence of the proposal saying that \"noise transitions can be inferred of a special group of instances\"?**\n\n**A6**: The evidence is the noise transition estimation methods in previous work. For example, the special group of instances can be the anchor points in the dataset, which is stated in Section 2 in [6] and Theorem 3 in [7].\n\n**Q7: If the estimated labels are clean enough, why should we fundamentally do more processes?**\n\n**A7:** The size of selected examples is much smaller than the size of the whole dataset, and the distribution of selected examples is not the same as the distribution of examples in the clean domain. As a result, training classifiers on selected examples with different distributions will lead to the performance degradation of the classifiers because the parameters of the learned classifier are not statistically consistent with the parameters of the optimal classifier defined on the clean domain. \n\nTo guarantee the statistical consistency of classifiers, the information contained in the remaining examples has to be used. Modeling the noise transition for the whole dataset is a way to employ the information contained in the training examples. The reason is that the clean class posterior $p(\\tilde{Y}|\\mathbf{X}=\\mathbf{x})$ for an instance $\\mathbf{x}$ can be inferred through the noise transition $p(\\tilde{Y}|Y,\\mathbf{X}=\\mathbf{x})$ and the noisy class posterior $p(\\tilde{Y}|\\mathbf{X}=\\mathbf{x})$, i.e.,  $p(\\tilde{Y}|\\mathbf{X}=\\mathbf{x})=p(\\tilde{Y}|Y,\\mathbf{X}=\\mathbf{x})p(Y|\\mathbf{X}=\\mathbf{x})$."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700303619136,
                "cdate": 1700303619136,
                "tmdate": 1700694791310,
                "mdate": 1700694791310,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PHznLHqNJm",
                "forum": "VbR6K7TQV4",
                "replyto": "uEugwAfLbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XDR1 (Continue)"
                    },
                    "comment": {
                        "value": "**Q8: How can we be sure that the process the authors proposed improves the model performance?**\n\n**A8**: Our method is conceptually better than other methods. As discussed in the Introduction, to generalize the noise transition learned in some instances to other instances, existing work without theoretical guarantee manually defines similarity for noise transition across various instances. However, the human-defined similarity is hard to verify in the real world. If the similarity is not truthful, the estimation error of the noise transition could be large. Thus, the performance of the classifier would decrease. \n\nTo avoid human-defined similarity, we propose a principled way to capture the connections of noise transitions among different instances automatically. Specifically, our method models the data generative process, and then the joint distribution $p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})$ can be obtained. Thus, the noise transition can be captured  (please refer to the answer in A1). Once the model can capture the connections, the noise transition estimated in some examples can be generalized to other examples. The information contained in other examples can be inferred and learned by the model. Thus, the performance of the model will be improved. The experiment results also have verified the effectiveness of our method.\n\n### References\n\n[1] Hyv\u00e4rinen, Aapo, and Petteri Pajunen. \"Nonlinear independent component analysis: Existence and uniqueness results.\" *Neural networks* 12.3 (1999): 429-439.\n\n[2] Locatello, Francesco, et al. \"Challenging common assumptions in the unsupervised learning of disentangled representations.\" *international conference on machine learning*. PMLR, 2019.\n\n[3] Yang, Mengyue, et al. \"Causalvae: Disentangled representation learning via neural structural causal models.\" *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*. 2021.\n\n[4] Liu, Yuhang, et al. \"Identifying weight-variant latent causal models.\" *arXiv preprint arXiv:2208.14153* (2022).\n\n[5] Xia, Xiaobo, et al. \"Part-dependent label noise: Towards instance-dependent label noise.\" *Advances in Neural Information Processing Systems* 33 (2020): 7597-7610.\n\n[6] Xia, Xiaobo, et al. \"Are anchor points really indispensable in label-noise learning?.\" *Advances in neural information processing systems* 32 (2019).\n\n[7] Patrini, Giorgio, et al. \"Making deep neural networks robust to label noise: A loss correction approach.\" *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2017."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700303690693,
                "cdate": 1700303690693,
                "tmdate": 1700694820788,
                "mdate": 1700694820788,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "l0rIGZMDRl",
                "forum": "VbR6K7TQV4",
                "replyto": "uEugwAfLbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "Thank authors for their sincere efforts to respond to my concerns. Still, my concerns below are not solved yet, and I require the authors to respond to those.\n\n1. I want to know the number of samples and accuracies with regard to the distilled dataset for several noisy dataset settings to support the proposal of authors, saying \"assume the selected dataset is likely clean is reasonable\" in A2 and \"the distribution of selected examples is not the same as the distribution of examples in the clean domain\" in A7. Also want to know the performance comparison when trained only with distilled dataset, since if the peformance only with the distilled dataset is similar to the performance the authors proposed in the paper, I think it will take far less time and memory complexity.\n\n2. If the distribution of selected examples is not the same as the distribution of examples in the clean domain, how can the author can assume the learned causal factor with distilled samples is trustworthy?\n\n3. Time and memory comparison is not enough. Dividemix uses two networks, so it is so certain that this method would spend computation than other baselines. The time and memory comparison with regard to all other baselines, or at least with regard to other transition matrix based methods can tell how much time and memory is used usually and enable the evaluation of the method. \n\nAlso, I think the time and memory gap could be larger when this method is applied to more complicated dataset, e.g. Clothing1M, than CIFAR10.\n\n4. Can the authors specify how they calculated the transition matrix estimation error for the instance dependent transition matrix? e.g. how to measure the difference between the ground truth and the estimated transtion matrix, since the transition matrix should be different for every instance? / What is the meaning of estimation error of other dimensions when a true label of a sample is only one? e.g. the transition matrix error of label dimension 0,1, and 3~9 for 10-class classification when a true label of a sample is 2?\n\n5. I found out the authors did not compare theirs with class-dependent transition matrix estimation based methods. However, I think it should be compared as baselines.\n\n6. Additionally, I doubt the authors lack baselines. e.g. in [1] , which utilizes class dependent transition matrix, they achieved 75.12% for Clothing1M. However, this paper shows 74.81%, even with instance dependent transition. \n\n7. I still cannot trust that the suggested method can significantly increae the resulting classifier's performance. I think this concern can be solved if the authors analyze what the graph structure tells about the relations between samples empirically, and how much different is the similarity inferred from the graph structure and human arbitrarily defined similarity (or currently modeled several instance-dependent transition matrix based methods). \n\n[1] Cheng, D., Ning, Y., Wang, N., Gao, X., Yang, H., Du, Y., ... & Liu, T. (2022). Class-Dependent Label-Noise Learning with Cycle-Consistency Regularization. Advances in Neural Information Processing Systems, 35, 11104-11116."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700469102648,
                "cdate": 1700469102648,
                "tmdate": 1700615716367,
                "mdate": 1700615716367,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GR08GVmVNz",
                "forum": "VbR6K7TQV4",
                "replyto": "uEugwAfLbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XDR1 (Continue)"
                    },
                    "comment": {
                        "value": "### Reference\n\n[1] Hyv\u00e4rinen, Aapo, and Petteri Pajunen. \"Nonlinear independent component analysis: Existence and uniqueness results.\" *Neural networks* 12.3 (1999): 429-439.\n\n[2] Locatello, Francesco, et al. \"Challenging common assumptions in the unsupervised learning of disentangled representations.\" *international conference on machine learning*. PMLR, 2019.\n\n[3] Yang, Mengyue, et al. \"Causalvae: Disentangled representation learning via neural structural causal models.\" *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*. 2021.\n\n[4] Liu, Yuhang, et al. \"Identifying weight-variant latent causal models.\" *arXiv preprint arXiv:2208.14153* (2022).\n\n[5] Xia, Xiaobo, et al. \"Part-dependent label noise: Towards instance-dependent label noise.\" *Advances in Neural Information Processing Systems* 33 (2020): 7597-7610.\n\n[6] Xia, Xiaobo, et al. \"Are anchor points really indispensable in label-noise learning?.\" *Advances in neural information processing systems* 32 (2019).\n\n[7] Cheng, De, et al. \"Class-Dependent Label-Noise Learning with Cycle-Consistency Regularization.\" *Advances in Neural Information Processing Systems* 35 (2022): 11104-11116."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700695370275,
                "cdate": 1700695370275,
                "tmdate": 1700714334555,
                "mdate": 1700714334555,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kpbjX5yHcm",
                "forum": "VbR6K7TQV4",
                "replyto": "uEugwAfLbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
                ],
                "content": {
                    "comment": {
                        "value": "Thank the authors again for their sincere efforts to relieve my concerns. I have questions below:\n\n1. What is the reference [6] and [7]? I think there are only 5 references...\n If [7] is [7] Patrini, Giorgio, et al. \"Making deep neural networks robust to label noise: A loss correction approach.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017., what is the difference between CCR and Forward?\n\n2. I doubt experimental results are chosen since the dataset has changed from CIFAR10-IDN to CIFAR10-N from Q5. If the authors can explain why, I can understand.\n\n3. According to various experimental results, I can compare at least BLTM, MEIDTM and GenP with regard to accuracy, transition matrix error. For accuracy, I found out BLTM<MEIDTM<GenP, while for transition matrix error, it is GenP<BLTM<MEIDTM. I want to say that the order of transition matrix error and accuracy is reversed at least for BLTM and MEIDTM. Is it right? Also, I want to see accuracy comparison with VolMinNet.\n\n4. Is this method applicable to practical situations? For example, if we need 30 times more time (as the authors reported in the responses) for increasing 6% accuracy (as the authors reported in Clothing1M) than the naive cross entropy, is it practical?\n\n5. It is just my curiosity (and it may not be important for the classification accuracy, but I'm not sure). Since GenP reconstructs the image again, can authors show how the image is generated? If the method worked correctly, the image should also have been generated correctly, right? I know that we do not have enough time to run the algorithm totally according to the reported time from the authors for this revision, but I suggest showing this generated image can be a way to show the algorithm has worked as the authors intended."
                    },
                    "title": {
                        "value": "Response to the authors"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712841079,
                "cdate": 1700712841079,
                "tmdate": 1700712892876,
                "mdate": 1700712892876,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "q5C6yeae01",
                "forum": "VbR6K7TQV4",
                "replyto": "uEugwAfLbj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_XDR1"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks the authors for answering all questions that I asked sincerely and sorry for my possible misunderstanding of the authors' intension.\n\nNow I admit that the method of this paper makes instance dependent transition matrix well and it shows good performances for CIFAR-10 and CIFAR-10N dataset. The paper also shows more empirical analyses of why it works.\n\nI still worry that the necessary previous baselines may not be compared enough (e.g. the authors could not state the reason of the superiority of CCR  than their method for Clothing1M during the revision period) and question its applicability to practical settings, regarding time and computation complexity issue.\n\nI hope the authors could reorganize including the analyses done during in this revision period well and upgrade their study and their manuscript for the next conference.\n\nCurrently, I will keep my score as before, but I think this paper is very interesting and promising."
                    }
                },
                "number": 27,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700741127402,
                "cdate": 1700741127402,
                "tmdate": 1700741208972,
                "mdate": 1700741208972,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "eD1MMocPgE",
            "forum": "VbR6K7TQV4",
            "replyto": "VbR6K7TQV4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7806/Reviewer_5Lfr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7806/Reviewer_5Lfr"
            ],
            "content": {
                "summary": {
                    "value": "To deal with noisy labels, this paper models the generation process of noisy data using a learnable graphical model to understand the underlying causal relations, instead of directly defining and utilizing similarity of noise transitions across various instances in previous work. Experiments on various dataset with different types of label noise validate its effectiveness."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.This paper gives an insight into the transition matrix that the instances have similar transition matrix only if the causal factors causing the label noise are similar, which does make sense.\n\n2.Experimental results under various settings show the effectiveness of the approach."
                },
                "weaknesses": {
                    "value": "1.The idea of modeling the generation process of label noise via exploiting the underlying causal relations has been proposed in [1]. Hence, it is suggested to highlight the differences between the two works in Related Work.\n\n2.Figure 2 should be polished up. For example, in Figure 2, the difference between the blue arrow and black arrow should be explained. Meanwhile, the generative process related to Figure 2 in Section 3, the core of this paper, should be give more details about. \n\n3.The assumption that the generation process of causal factors Z is linear seems a bit unreasonable, which should be give more details on.\n\n4.Eq.(1) is very confusing. It seems that $Z_i$ is the element in $\\mathbf{Z}$ but also calculated by $\\mathbf{Z}$, which provides an implicit constraint.\n\n5.Some related works such as [2, 3] are missing.\n\n[1] Yao, Yu, et al. \"Instance-dependent label-noise learning under a structural causal model.\" NIPS, 2021.\n\n[2] Sheng Liu, et al. \u201cEarly-Learning Regularization Prevents Memorization of Noisy Labels.\u201d NIPS, 2020.\n\n[3] Sheng Liu, et al. \u201cRobust Training under Label Noise by Over-parameterization.\u201d ICML, 2022."
                },
                "questions": {
                    "value": "1. What is the meaning of $N_i$? In Section 3, it mentions that $N_i$ is the corresponding latent noise varibable. Could you take Figure 1 as an example to illustrate it?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7806/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698219585344,
            "cdate": 1698219585344,
            "tmdate": 1699636955008,
            "mdate": 1699636955008,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XF6jEW8SOG",
                "forum": "VbR6K7TQV4",
                "replyto": "eD1MMocPgE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5Lfr"
                    },
                    "comment": {
                        "value": "We sincerely thank you for your time and effort in reviewing our manuscript and providing valuable comments. Please find the response to your comments below.\n\n**Q1: Highlight the differences from CausalNL in Related Work.**\n\n**A1**: Our method is different from CausalNL from several points. \n\n- The aim of CausalNL is to exploit the information contained in the distribution of instances to help the learning of classifiers. To achieve this, the generative model is introduced. However, **existing methods do not model the causal structure among latent variables. They only \u201cpartially\u201d model the latent noisy data generative process without identifiablity analysis.**\n\n- Our aim is to enable deep neural networks to capture the connections of noise transitions among different instances automatically. Since once the connections are captured, the noise transition learned in some examples can be generalized to other examples. To achieve this, we propose a principled way to \"fully\" model the data generative process. **Our method also models the causal structure among latent variables. We also analyzed sufficient conditions required for identifiability.**\n\nHere we would like to include more details. Due to limited space, we include the details in Appendix D to avoid confusion.\n\n> CausalNL helps the learning of classifiers by exploiting the information contained in the distribution of instances. To be specific, when the latent clean label $Y$ is a cause of the instance $\\mathbf{X}$, the distribution of instance $p(\\mathbf{X})$ will generally contain some information about the distribution of clean class posterior $p(Y|\\mathbf{X})$. To exploit the information contained in the instances, CausalNL uses the generative model to model the generative relationship between the latent variable $\\mathbf{Z}$ and the observed instance $\\mathbf{X}$. However, they do not model the causal structure among the latent variable $\\mathbf{Z}$. Therefore, their methods only \u201cpartially\u201d model the noisy data generative process. These methods do not analyze the identifiability of the generative process.\n\n> Our aim is to enable deep neural networks to capture the connections of noise transitions among different instances automatically. Since once the connections are captured, the noise transition learned in some examples can be generalized to other examples. To achieve this, we need to model the joint distribution of all variables $p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})$. The noise transition can be obtained through\n\n$$\np(\\tilde{Y}|\\mathbf{X},Y)=\\frac{\\int_{\\mathbf{Z},\\mathbf{N}}p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})d\\mathbf{Z}d\\mathbf{N}}{\\int_{\\tilde{Y},\\mathbf{Z},\\mathbf{N}}p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})d\\tilde{Y}d\\mathbf{Z}d\\mathbf{N}}.\n$$\n\n> To obtain this joint distribution, we propose a principled way to model the whole data generative process. Specifically, we not only model the generative process from the latent variable $\\mathbf{Z}$ to the instance $\\mathbf{X}$ but also model and learn causal structure among different latent variables $\\{Z_1,Z_2,\\dots,Z_m\\}$ from observed noisy data. \n\n**Q2: Difference between the blue arrow and black arrow in Fig 2.**\n\n**A2**: Thanks for your suggestion. The black arrow indicates the causal direction in the structural causal model, while the blue arrow indicates the weights are changed across the clean label $Y$. More details about the generative process are included in Sec 3.\n\n**Q3: The assumption that the generation process of causal factors $\\mathbf{Z}$ is linear should be given more details.**\n\n**A3**: Since causal factor $\\mathbf{Z}$ is latent, discovering the causal structure is a challenging problem. If $\\mathbf{Z}$ is observed, nonlinear causal mechanisms can be discovered easily. However, we do not assume the causal factors are observed. To provide a theoretical guarantee, we assume the causal mechanism among causal factors is linear. We empirically find that the performance of the proposed method is good, which indicates that this simplicity does not have negative effects. \n\n**Q4: Eq.(1) is very confusing.**\n\n**A4**: $\\mathbf{W}$ is an upper triangular matrix with zero-value diagonal elements. When calculating $Z_i$, only the parents nodes of $Z_i$ are used, i.e., $Z_i=\\sum_{j\\in pa_i}W_{i,j}Z_{j}$.\n\n**Q5: Some related works are missing.**\n\n**A5**: Thanks for your advice. We have added these works to the Related Work.\n\n**Q6: What is the meaning of $N_i$.**\n\n**A6**: $N_i$ is an unexplained random variable that determines $Z$ in the structural causal model, i.e., $Z_i:=f_Z(pa(Z_i),N_i)$. This variable is referred as the noise variable in previous work [1], which is different from the noise in the label noise.\n\n### References\n\n[1] Sch\u00f6lkopf, Bernhard, et al. \"Toward causal representation learning.\" *Proceedings of the IEEE* 109.5 (2021): 612-634."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700303324408,
                "cdate": 1700303324408,
                "tmdate": 1700303324408,
                "mdate": 1700303324408,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aiHTn4MMkE",
                "forum": "VbR6K7TQV4",
                "replyto": "XF6jEW8SOG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_5Lfr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_5Lfr"
                ],
                "content": {
                    "comment": {
                        "value": "The authors have adequately addressed the majority of my concerns. I hope that the authors will further revise the manuscript in future versions based on the modification suggestions I have provided, especially regarding Point 3 and 4."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700560257926,
                "cdate": 1700560257926,
                "tmdate": 1700560257926,
                "mdate": 1700560257926,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "H2BCHPDH0y",
            "forum": "VbR6K7TQV4",
            "replyto": "VbR6K7TQV4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7806/Reviewer_qcRj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7806/Reviewer_qcRj"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the challenge of learning with noisy labels, particularly focusing on the critical aspect of understanding noise transitions\u2014the process by which a clean label turns into a noisy one. Traditionally, most methods infer noise transitions based on assumptions about similarities across different instances. However, these assumptions often lack empirical backing and may not accurately reflect real-world data scenarios, leading to incorrect interpretations of both noise transitions and clean labels.\n\nTo overcome these limitations, the authors propose a novel approach that models the generative process of noisy data instead of relying on predefined similarity assumptions. This method uses a learnable graphical model to represent the causal generative process behind the noise in data. By doing this, the model can more effectively identify the underlying causal factors that lead to noise in labels."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The author's effective construction of a causal graph that aligns well with the research's motivation, as well as their adept development of the graphical model and Evidence Lower Bound (ELBO), signifies a robust approach in addressing the research problem."
                },
                "weaknesses": {
                    "value": "Indeed, in the field of noisy label classification, using deep generative models (DGMs) to infer latent true labels is not a novel approach. Various studies have explored this concept, leveraging the capacity of DGMs to model complex data distributions and underlying noise patterns, including [1].\n\n[1] Noisy Prediction Calibration via Generative Model, ICML2022\n\nFrom a critical standpoint, this study distinguishes itself from the ICML 2022 paper \"[1]\" by proposing a graphical model that requires the generation of input instances. A significant advantage of the approach in \"[1]\" is that it does not require input generation. Generating high-resolution instances can be inherently challenging or demand computationally intensive models like diffusion models, making the combination of input instance generation with noisy label classification potentially impractical.\n\nThe primary focus of this study on low-resolution datasets such as MNIST and CIFAR-10 in their experimental evaluations is possibly due to these inherent difficulties. Although they report results for the higher-resolution Clothing1M dataset, the lack of specific mention of standard deviations casts doubt on the reliability of these findings. Furthermore, the performance improvement over DivideMix is marginal, raising questions about the necessity of employing a deep generative model for noisy label classification. This aspect warrants skepticism regarding the scalability and practical applicability of the proposed method, especially for higher-resolution, real-world datasets.\n\nIncorporating a deep generative model in scenarios primarily focused on classification tasks can introduce a significant computational burden. The author should compare the increased computational requirements of this additional modeling with existing baselines to provide a clearer perspective on its practical feasibility. This comparison is crucial for assessing the trade-offs between the potential benefits of improved noise handling and the increased computational demands, particularly for applications where resources are limited or efficiency is a critical factor."
                },
                "questions": {
                    "value": "Q1. The use of \"distillation\" in the paper seems unclear, as it traditionally refers to transferring knowledge from a complex to a simpler model. If this process is not evident in the methodology, the term may be inaccurately applied. The author should clarify or reconsider its use. Using a simply trained network initially does not necessarily constitute distillation, which typically involves transferring knowledge from a more complex model.\n\nQ2. The authors should specify how their use of a DGM framework with causal graphs and inference differs in motivation and application from the work done in CausalNL, detailing the distinct aspects of their approach.\n\nQ3. In the context of noisy label classification, it's not typical to specifically categorize noise types as \"Worst,\" \"Aggregate,\" \"Random 1,\" \"Random 2,\" and \"Random 3\" without clear definitions. These terms are not standard in the literature and require clarification for proper understanding.\n\nQ4. As previously discussed, training a Deep Generative Model (DGM) for this task may impose a significant computational burden. In this context, could the methodology benefit from incorporating pre-trained DGMs to alleviate these computational demands?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Reviewer_qcRj"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7806/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698825795667,
            "cdate": 1698825795667,
            "tmdate": 1700718636760,
            "mdate": 1700718636760,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hA0XHbhlN1",
                "forum": "VbR6K7TQV4",
                "replyto": "H2BCHPDH0y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qcRj"
                    },
                    "comment": {
                        "value": "We sincerely thank you for your time and effort in reviewing our manuscript and providing valuable comments. Please find the response to your comments below.\n\n**Q1: Various studies have explored leveraging deep generative models to model complex data distributions and underlying noise patterns, thus using deep generative models (DGMs) to infer latent true labels is not a novel approach.**\n\n**A1**: Though some previous studies also use generative models, our work is different from previous work in several points. \n\n- The aim of previous work CausalNL and InstanceGM is to exploit the information contained in the distribution of instances to help the learning of classifiers. To achieve this, the generative model is introduced. However, **existing methods do not model the causal structure among latent variables. They only \u201cpartially\u201d model the latent noisy data generative process without identifiablity analysis.**\n\n- Our aim is to enable deep neural networks to capture the connections of noise transitions among different instances automatically. Since once the connections are captured, the noise transition learned in some examples can be generalized to other examples. To achieve this, we propose a principled way to \"fully\" model the data generative process. **Our method also models the causal structure among latent variables. We also analyzed sufficient conditions required for identifiability.**\n\nHere we would like to include more details. We have also included below in Appendix D to avoid confusion.\n\n> Previous work helps the learning of classifiers by exploiting the information contained in the distribution of instances. To be specific, when the latent clean label $Y$ is a cause of the instance $\\mathbf{X}$, the distribution of instance $p(\\mathbf{X})$ will generally contain some information about the distribution of clean class posterior $p(Y|\\mathbf{X})$. To exploit the information contained in the instances, CausalNL and InstanceGM use the generative model to model the generative relationship between the latent variable $\\mathbf{Z}$ and the observed instance $\\mathbf{X}$. However, they do not model the causal structure among the latent variable $\\mathbf{Z}$. Therefore, their methods only \u201cpartially\u201d model the noisy data generative process. These methods do not analyze the identifiability of the generative process.\n\n> Our aim is to enable deep neural networks to capture the connections of noise transitions among different instances automatically. Since once the connections are captured, the noise transition learned in some examples can be generalized to other examples. To achieve this, we need to model the joint distribution of all variables $p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})$. The noise transition can be obtained through\n\n$$\np(\\tilde{Y}|\\mathbf{X},Y)=\\frac{\\int_{\\mathbf{Z},\\mathbf{N}}p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})d\\mathbf{Z}d\\mathbf{N}}{\\int_{\\tilde{Y},\\mathbf{Z},\\mathbf{N}}p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})d\\tilde{Y}d\\mathbf{Z}d\\mathbf{N}}.\n$$\n\n> To obtain this joint distribution, we propose a principled way to model the whole data generative process. Specifically, we not only model the generative process from the latent variable $\\mathbf{Z}$ to the instance $\\mathbf{X}$ but also model and learn causal structure among different latent variables $\\{Z_1,Z_2,\\dots,Z_m\\}$ from observed noisy data. \n\nTo achieve this, the generation of the variable $\\mathbf{N}$ is modeled by a Gaussian distribution. The generation of the latent variable $\\mathbf{Z}$ is modeled by a Structure Causal Model (SCM): $Z_i:=\\mathbf{W}^T_i \\mathbf{Z}+N_i$, where $\\mathbf{W}$ is a matrix used to represent the association among the latent variables. Two generators are used to model the generation of the instance $\\mathbf{X}$ and the noisy label $\\tilde{Y}$, respectively.\n\nMoreover, our paper has analyzed the identifiability of the proposed method theoretically in Appendix C. We discuss the conditions required for identifiability. Specifically, when the number of distinct classes is large (more than the sufficient statistics of the latent variable $\\mathbf{Z}$) and we have a confident example in each class, the latent variable $\\mathbf{Z}$ can be identified up to permutation. \n\n**Q2: The deep generative model introduces a significant computational burden.**\n\n**A2**: The proposed method does not increase the time complexity and memory because the encoder and the decoder introduced by our method are lightweight. The training time of the proposed method on CIFAR-10 is 13.68 hours, and the training time of DivideMix is 9.08 hours. The memory used for the proposed method is 7.06 GB, and the memory used for DivideMix is 6.99 GB.\n\nMoreover, the inference time is the same as the time of baselines because the encoder and decoder can be discarded during inference."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700303224355,
                "cdate": 1700303224355,
                "tmdate": 1700303224355,
                "mdate": 1700303224355,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NVf8nvxL3w",
                "forum": "VbR6K7TQV4",
                "replyto": "Obry3sXN4o",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_qcRj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_qcRj"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "I acknowledge that most concerns regarding other questions have been addressed, and I admit there was some misunderstanding on my part.\n\nHowever, regarding Q1, I specifically requested a direct comparison with NPC [1], but only comparisons with other DGM-based baselines were provided. I would like a detailed discussion on the differences between your approach and NPC, along with the benefits of these differences. A performance comparison would be particularly valuable."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700569599158,
                "cdate": 1700569599158,
                "tmdate": 1700569599158,
                "mdate": 1700569599158,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kAH56WmAh1",
                "forum": "VbR6K7TQV4",
                "replyto": "6c2EA5J2YO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_qcRj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_qcRj"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "The detailed analysis of NPC is expected to greatly aid in the analysis of the DGM-based methodology. Based on this, I will raise my score to 5."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718613845,
                "cdate": 1700718613845,
                "tmdate": 1700718613845,
                "mdate": 1700718613845,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YjkQoDscgS",
            "forum": "VbR6K7TQV4",
            "replyto": "VbR6K7TQV4",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7806/Reviewer_5FMB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7806/Reviewer_5FMB"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a graphical modeling approach for label-noise learning. It addresses the issue of manual assumptions regarding noise transition in previous work, so they design the generative process based on causal factors. These causal factors is latent, so they propose learnable generative models to establish relationships among data instances, clean labels, and noisy labels. The proposed method, GenP, shows better performances than existing methods."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The motivation and problem formulation are reasonable. Designing a graphical model is an effective approach to uncovering the connections related to unknown transitions. The manuscript is well-written."
                },
                "weaknesses": {
                    "value": "1. Missing explanation and comparison with important baselines\n\n* The paper states that there are \"no existing methods that attempt to unveil these latent noisy data generative process\". However, there are previous works that have addressed the generative processes for label-noise learning [1, 2, 3], and even they use [1] for the baseline in the experiments. The paper should provide a comprehensive discussion for these baselines.\n\n* Additionally, there is a lack of discussion regarding related work on label-noise learning. While they use the clean example distillation method via the small-loss trick, it is essential to also survey this related work, such as sample selection methods, for a more comprehensive view of the field.\n\n[1] Yao, Y., Liu, T., Gong, M., Han, B., Niu, G., & Zhang, K. (2021). Instance-dependent label-noise learning under a structural causal model. Advances in Neural Information Processing Systems, 34, 4409-4420.\n\n[2] Bae, H., Shin, S., Na, B., Jang, J., Song, K., & Moon, I. C. (2022, June). From noisy prediction to true label: Noisy prediction calibration via generative model. In International Conference on Machine Learning (pp. 1277-1297). PMLR.\n\n[3] Garg, A., Nguyen, C., Felix, R., Do, T. T., & Carneiro, G. (2023). Instance-dependent noisy label learning via graphical modelling. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 2288-2298).\n\n2. Lack of Experimental Support\n\n* Some results, such as those for CIFAR-10 and CIFAR-10N, do not appear to be statistically significant, and the performance gain observed for Clothing1M is marginal. To further support the effectiveness of the proposed model, it would be beneficial to include experiments on various real-world datasets such as WebVision, ANIMAL-10N, and Mini-Imagenet, or to conduct repeated experiments on Clothing-1M.\n\n* The paper primarily presents the classification performance without conducting an in-depth analysis of the contributing factors behind the performance improvements. A more detailed examination of specific elements that have positively influenced the overall performance is needed. This could include: 1) an ablation study comparing model training with only $L_{semi}$ and with the entire loss, 2) a sensitivity analysis regarding hyperparameters (e.g., $\\lambda_{ELBO}$ and $\\lambda_M$), 3) a comparison between end-to-end learning and alternative learning approaches, and 4) an ablation study based on the number of latent variables, among other potential analyses.\n\n3. Minor Comments\n\n* The first paragraph of Section 3 and the first paragraph of 'Intuition about Inferring Latent Generative Process' have significant overlap. Rephrasing these sentences would improve clarity and avoid redundancy.\n\n* It would be helpful to include a citation when introducing the \"small-loss trick\" to provide proper credit and context.\n\n* Some numbering in the 'Baselines' section appears to be missing (e.g., 5 and 11)."
                },
                "questions": {
                    "value": "Please answer the comments in the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7806/Reviewer_5FMB"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7806/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698892252954,
            "cdate": 1698892252954,
            "tmdate": 1699636954658,
            "mdate": 1699636954658,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TmawqYQBF3",
                "forum": "VbR6K7TQV4",
                "replyto": "YjkQoDscgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5FMB"
                    },
                    "comment": {
                        "value": "We sincerely thank you for your time and effort in reviewing our manuscript and providing valuable comments. Please find the response to your comments below.\n\n**Q1: There is previous work that models the generative processes for label-noise learning.**\n\n**A1**: We are sorry for the confusion. We believe this is caused by a misunderstanding of noisy data generative process.\n\n- The aim of previous work CausalNL and InstanceGM is to exploit the information contained in the distribution of instances to help the learning of classifiers. To achieve this, the generative model is introduced. However, **existing methods do not model the causal structure among latent variables. They only \u201cpartially\u201d model the latent noisy data generative process without identifiablity analysis.**\n\n- Our aim is to enable deep neural networks to capture the connections of noise transitions among different instances automatically. Since once the connections are captured, the noise transition learned in some examples can be generalized to other examples. To achieve this, we propose a principled way to \"fully\" model the data generative process. **Our method also models the causal structure among latent variables. We also analyzed sufficient conditions required for identifiability.**\n\n- Note that **NPC does not model the noisy data generative process but models the generative process of estimated clean labels.**\n\nHere we would like to include more details. We have also included below in Appendix D to avoid confusion.\n\n> Previous work helps the learning of classifiers by exploiting the information contained in the distribution of instances. To be specific, when the latent clean label $Y$ is a cause of the instance $\\mathbf{X}$, the distribution of instance $p(\\mathbf{X})$ will generally contain some information about the distribution of clean class posterior $p(Y|\\mathbf{X})$. To exploit the information contained in the instances, CausalNL and InstanceGM use the generative model to model the generative relationship between the latent variable $\\mathbf{Z}$ and the observed instance $\\mathbf{X}$. However, they do not model the causal structure among the latent variable $\\mathbf{Z}$. Therefore, their methods only \u201cpartially\u201d model the noisy data generative process. These methods do not analyze the identifiability of the generative process.\n\n> Our aim is to enable deep neural networks to capture the connections of noise transitions among different instances automatically. Since once the connections are captured, the noise transition learned in some examples can be generalized to other examples. To achieve this, we need to model the joint distribution of all variables $p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})$. The noise transition can be obtained through\n\n$$\np(\\tilde{Y}|\\mathbf{X},Y)=\\frac{\\int_{\\mathbf{Z},\\mathbf{N}}p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})d\\mathbf{Z}d\\mathbf{N}}{\\int_{\\tilde{Y},\\mathbf{Z},\\mathbf{N}}p(\\mathbf{X},\\tilde{Y},Y,\\mathbf{Z},\\mathbf{N})d\\tilde{Y}d\\mathbf{Z}d\\mathbf{N}}.\n$$\n\n> To obtain this joint distribution, we propose a principled way to model the whole data generative process. Specifically, we not only model the generative process from the latent variable $\\mathbf{Z}$ to the instance $\\mathbf{X}$ but also model and learn causal structure among different latent variables $\\{Z_1,Z_2,\\dots,Z_m\\}$ from observed noisy data. \n\nTo achieve this, the generation of the variable $\\mathbf{N}$ is modeled by a Gaussian distribution. The generation of the latent variable $\\mathbf{Z}$ is modeled by a Structure Causal Model (SCM): $Z_i:=\\mathbf{W}^T_i \\mathbf{Z}+N_i$, where $\\mathbf{W}$ is a matrix used to represent the association among the latent variables. Two generators are used to model the generation of the instance $\\mathbf{X}$ and the noisy label $\\tilde{Y}$, respectively.\n\nMoreover, our paper has analyzed the identifiability of the proposed method theoretically in Appendix C. We discuss the conditions required for identifiability. Specifically, when the number of distinct classes is large (more than the sufficient statistics of the latent variable $\\mathbf{Z}$) and we have a confident example in each class, the latent variable $\\mathbf{Z}$ can be identified up to permutation."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700302771943,
                "cdate": 1700302771943,
                "tmdate": 1700302771943,
                "mdate": 1700302771943,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "L3uDGB8UHX",
                "forum": "VbR6K7TQV4",
                "replyto": "YjkQoDscgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5FMB (Continue)"
                    },
                    "comment": {
                        "value": "**Q2: Need to discuss more related work for learning with noisy labels.**\n\n**A2**: Thanks for your advice. We have added a paragraph in related work after introducing the noise-transition-based method to introduce other approaches, including sample-selection-based methods, other methods using generative models to facilitate learning with noisy labels, and the method leveraging the property of the label noise. Specifically, the paragraph is as follows.\n\n> Some noise-robust algorithms select examples deemed likely to be accurate for training purposes. These selections are based on the memorization effect, which suggests deep neural networks initially learn dominant patterns before progressively learning less common ones. In noisy label environments, accurate labels often constitute the majority, leading networks to prioritize learning from examples with accurate labels, typically indicated by lower loss values. Co-Teaching employs this principle to identify low-loss examples as likely accurate. DivideMix uses a Gaussian Mixture Model to separate training examples into labeled and unlabeled sets based on their training loss, with the labeled set presumed to contain accurate labels. Additionally, some methods use generative models to facilitate learning with noisy labels. CausalNL and InstanceGM utilize instance-specific information to enhance classifier learning. Conversely, NPC focuses on the generative process of estimated clean labels, not the noisy data generation, using generative models for label calibration. Finally, SOP applies the sparse property of the label noise, i.e., incorrect labels are the minority, to prevent models from overfitting to label noise.\n\n**Q3: Include experiments on various real-world datasets such as WebVision, ANIMAL-10N, and Mini-Imagenet.**\n\n**A3:** Thanks for your advice. We are still running experiments on WebVision. We will post the results as soon as possible.\n\n**Q4: An ablation study and sensitivity analysis.**\n\n**A4:** Thanks for your advice. For the ablation study, the method with only $\\mathcal{L}\\_{semi}$ is the same as DivideMix. Thus, the experiment results of the model only trained with $L_{semi}$ are the experiment results of DivideMix. For the sensitivity analysis, we have conducted the sensitivity analysis for $\\lambda_{ELBO}$ and $\\lambda_M$ on the CIFAR-10N dataset with noise type ''worst''. The experiment results are plotted as figures in Appendix E. We also list the experiment results as tables here:\n\n| $\\lambda_{ELBO}$ | 0.1              | 0.05             | 0.01                 | 0.001            | 0.0001           |\n| ---------------- | ---------------- | ---------------- | -------------------- | ---------------- | ---------------- |\n| Accuracy         | 93.00 $\\pm$ 0.20 | 93.86 $\\pm$ 0.10 | **93.87 $\\pm$ 0.11** | 93.56 $\\pm$ 0.15 | 93.59 $\\pm$ 0.11 |\n\n| $\\lambda_{M}$ | 0.2              | 0.1              | 0.01                 | 0.001            | 0.0001           |\n| ------------- | ---------------- | ---------------- | -------------------- | ---------------- | ---------------- |\n| Accuracy      | 93.11 $\\pm$ 0.21 | 93.44 $\\pm$ 0.22 | **93.80 $\\pm$ 0.13** | 93.53 $\\pm$ 0.14 | 93.23 $\\pm$ 0.17 |"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700303019925,
                "cdate": 1700303019925,
                "tmdate": 1700303080316,
                "mdate": 1700303080316,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "js00eaork1",
                "forum": "VbR6K7TQV4",
                "replyto": "L3uDGB8UHX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_5FMB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_5FMB"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response and for providing additional experimental results. It addresses some of my concerns. However, after reading the author's response and the other reviewers' reviews and responses to them, I still have a number of concerns.\n\nIn particular, I still lack evidence that the proposed method is superior, as other reviewers have pointed out. I believe that the author's statement that it is conceptually superior to other methods needs to be supported by a theoretical/experimental basis, which could be ablation studies as I suggested, or the author should have designed an experiment to demonstrate superiority.\n\nTherefore, I find it difficult to decide on acceptance without further analysis of the proposed model."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700464096107,
                "cdate": 1700464096107,
                "tmdate": 1700464096107,
                "mdate": 1700464096107,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mwyEhtQg0s",
                "forum": "VbR6K7TQV4",
                "replyto": "YjkQoDscgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Additional Experiments [Part 1]"
                    },
                    "comment": {
                        "value": "Dear Reviewer 5FMB\n\nThank you for your valuable comments on improving our paper. We have added more experiments.  These experiment results are added to Appendix E and H. Please let us know if there are any further concerns. Many Thanks.\n\n\n1). **The ablation study compares model training with only $\\mathcal{L}_{semi}$ and with the entire loss.** Here, we show the experiment results on CIFAR-10 with instance-dependent label noise. The experimental results indicate that with the increase of noise levels, the benefits of modeling the generative process become more significant (>2% on IDN-40%).\n\n|                                | IDN-10%              | IDN-20%              | IDN-30%              | IDN-40%              | IDN-50%              |\n| ------------------------------ | -------------------- | -------------------- | -------------------- | -------------------- | -------------------- |\n| With only $\\mathcal{L}_{semi}$ | 96.03 $\\pm$ 0.14     | 95.92 $\\pm$ 0.12     | 95.66 $\\pm$ 0.15     | 95.03 $\\pm$ 0.12     | 86.98 $\\pm$ 0.28     |\n| The entire loss                | **96.12 $\\pm$ 0.12** | **96.05 $\\pm$ 0.12** | **95.74 $\\pm$ 0.13** | **95.44 $\\pm$ 0.12** | **89.39 $\\pm$ 0.45** |\n\n*2). A sensitivity analysis regarding hyperparameters ($\\lambda_{ELBO}$ and $\\lambda_{M}$).* \n\nWe have conducted the sensitivity analysis for $\\lambda_{ELBO}$ and $\\lambda_M$ on the CIFAR-10N dataset with noise type ''worst''. The experiment results are plotted as figures in Appendix E. The experiment results show that when the $\\lambda_{ELBO}$ and $\\lambda_M$ are around $0.01$, the test accuracy of the model is highest."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668027471,
                "cdate": 1700668027471,
                "tmdate": 1700737746595,
                "mdate": 1700737746595,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TSx2zv5qg9",
                "forum": "VbR6K7TQV4",
                "replyto": "YjkQoDscgS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Additional Experiments [Part 2]"
                    },
                    "comment": {
                        "value": "*3). A comparison between end-to-end learning and alternative learning approaches.* \n\nWe conduct the experiments of the alternative learning approach, which optimizes $\\mathcal{L}\\_{semi}$ and $ - \\lambda\\_{ELBO} ELBO +\\lambda\\_M (\\| \\mathbf{M\\_X} \\|_1 + \\| \\mathbf{M\\_{\\tilde{Y}}} \\|\\_1)$ alternatively. The dataset is CIFAR-10N. \n\nThe experiment results are shown as follows. Empirically, the performance of the end-to-end learning approach is better than the alternative learning approach.\n\n|             | Worst                | Aggregate            | Random 1             | Random 2             | Random 3             |\n| ----------- | -------------------- | -------------------- | -------------------- | -------------------- | -------------------- |\n| Alternative | 93.72 $\\pm$ 0.07     | 95.21 $\\pm$ 0.19     | 95.14 $\\pm$ 0.12     | 95.28 $\\pm$ 0.09     | 94.99 $\\pm$ 0.15     |\n| End-to-end  | **93.87 $\\pm$ 0.13** | **95.39 $\\pm$ 0.18** | **95.38 $\\pm$ 0.13** | **95.30 $\\pm$ 0.12** | **95.26 $\\pm$ 0.13** |\n\n*4). An ablation study based on the number of latent variables.* \n\nWe have conducted the experiments on CIFAR-10N dataset with the noise type \"worst\". The experiment results are in Appendix H. When the number of latent variables is around 4, the classification performance of the model reaches the peak."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668223050,
                "cdate": 1700668223050,
                "tmdate": 1700668359576,
                "mdate": 1700668359576,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dm6MYrCBTw",
                "forum": "VbR6K7TQV4",
                "replyto": "TSx2zv5qg9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_5FMB"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7806/Reviewer_5FMB"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for providing the ablation studies. I will consider for the response with other reviewers.\n\nAdditionally, I think that the results for the first ablation study come from the Table 2 in the manuscript (so, I think these results are on CIFAR-10, not CIFAR-10N.), as the authors said that the method with only $\\mathcal{L}_{semi}$ is the same as DivideMix. I find that the accuracy of DividMix reported in this paper and in BLTM (Table 7) is quite different (e.g. 96.03 vs 83.31 in IDN-10%). I would like to know the reason, because this difference could affect GenP, since DivideMix is an ablation of GenP."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7806/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726023308,
                "cdate": 1700726023308,
                "tmdate": 1700726023308,
                "mdate": 1700726023308,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]