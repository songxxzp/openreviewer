[
    {
        "title": "Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference"
    },
    {
        "review": {
            "id": "Hdaltgi7cm",
            "forum": "vbebD7QRxP",
            "replyto": "vbebD7QRxP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8025/Reviewer_LB1R"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8025/Reviewer_LB1R"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a method to modularly train deep generative models to perform causal inference in high dimensional data"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is fairly well written and tackles and interesting problem\n- To the best of my knowledge this is a fairly novel approach on training Neural Nets for causal inference \n- The maths appear to be sound \n- The results and evaluation are acceptable"
                },
                "weaknesses": {
                    "value": "- There is a large number of related literature that is missing. There have been too many to enumerate here methods that would be considered related work and should be compared against\n- The Covid chest x-ray dataset is not of high quality , the reviewer would suggest using a more established test dataset.\n- There are multiple typos (trianing -> training) and articles missing \n- The method section could be made a bit better to increase clarity"
                },
                "questions": {
                    "value": "- GANs are notoriously messy and hard to train , plus they can only approximate the data distributions in question. Why is this the chosen backbone and not something else like normalizing flows ? \n\n\nOverall i think this is a good paper, that would benefit the community"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8025/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8025/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8025/Reviewer_LB1R"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8025/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698056641898,
            "cdate": 1698056641898,
            "tmdate": 1700412589214,
            "mdate": 1700412589214,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hqOAoma2pI",
                "forum": "vbebD7QRxP",
                "replyto": "Hdaltgi7cm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8025/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8025/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer LB1R (1/1)"
                    },
                    "comment": {
                        "value": "We are happy that the reviewer found our paper well-written and our work novel.\nBelow we address the reviewer\u2019s concerns.\n\n## Missing literatures:\n\n> \"There is a large number of related literature that is missing\"\n\nWe apologize if we missed some related works that solve high-dimensional interventional and counterfactual sampling\nproblems. We intended to include all the recent works that solve similar problems with deep learning models such as\nGANs, normalizing flow, and diffusion models. We would be happy to include the ones that we missed if the reviewer would\nkindly point us to them.\n\nFor the reviewer\u2019s convenience, here is a list of some recent papers we cited and qualitatively compared our approach\nagainst:\n\n* Balazadeh et al (2022). Partial identification of treatment effects with implicit generative models.\n* Louizos et al (2017). Causal effect inference with deep latent-variable models.\n* Kocaoglu et al (2018). Causalgan: Learning causal implicit generative models with adversarial training.\n* Pawlowski et al (2020). Deep structural causal models for tractable counterfactual inference.\n* Xia et al 2023. Neural causal models for counterfactual identification and estimation.\n* Nemirovsky et al (2020). Countergan: generating realistic counterfactuals with residual generative adversarial nets\n* Xia et al 2021. The causal-neural connection: Expressiveness, learnability, and inference.\n* Bica et al (2020). Estimating the effects of continuous-valued interventions using generative adversarial networks.\n\n## Datasets:\n\n> \"The reviewer would suggest using a more established test dataset\"\n\nWe believe that the performed experiments in our paper illustrate our motivation, contribution, and technical novelty.\nHowever, we would greatly appreciate it if the reviewer could point us to other real-world datasets that they believe is\nsuitable to evaluate our method for high-dimensional causal inference. We would happily include them in our experiments.\n\nFor the reviewer\u2019s convenience, here we provide the set of experiments we discussed in the main paper and in the\nappendix.\n\n* In Section 5.1, we highlight our flexibility to utilize pre-trained models in a front door graph setting with the\n  colored MNIST dataset.\n* In Section 5.2, we experiment on the real-world COVIDx CXR-3 dataset with 30k samples that we associate with a front\n  door graph.\n* In Appendix F.4, we showed our performance on a Colored-MNIST experiment where the causal graph contains 7 discrete\n  variables and 2 image variables.\n* In Appendix F.5, we experiment with the ASIA causal graph (6 nodes) from the popular bnlearn repository (\n  bnlearn.com/bnrepository).\n* In Appendix F.6, we show our algorithm\u2019s performance on the real-world Sachs protein dataset from the bnlearn\n  repository which includes both observational and interventional data.\n* In Appendix F.7, we show performance on a synthetic experiment with a causal graph with 7 nodes.\n\n## Chosen neural network architecture:\n\n> \"Why is GAN the chosen backbone?\"\n\nEven though we learn the desired distribution with GAN training, our modular training routine is not specific to GANs as\nwe mentioned in Appendix H. Essentially, if there is a way to train multiple conditional generative models with the same\nnoise, our results should apply. For example, conditional VAE can be used instead of GANs since its decoder is not\ndifferent from the generator of a GAN in terms of sampling. It just requires a different way of training.\n\n\n> \"Why not something like normalizing flows\"\n\nThis is an interesting question. For a causal graph without any latent: $X \\rightarrow Z \\rightarrow Y$, we can use\nnormalizing flow to get exogenous noise $n_X$, $n_Z$, and $n_Y$ by learning some invertible functions. However, suppose,\nthere exists an unobserved confounder $U$ between $X$ and $Y$. The causal graph is $X \\rightarrow Z \\rightarrow Y; X\n\\leftarrow U \\rightarrow Y$. Now, obtaining $U$ from $X$ and $Y$ and getting back $X$ and $Y$ from $U$ might not be an\ninvertible function. Thus, normalizing flow may not be directly applied. Although Pawlowski et al. (2020) proposed a\nnormalizing flow-based method for interventional and counterfactual sampling, the solution was for causal graphs with no\nunobserved variables. In GAN or conditional VAE, this issue is dealt with by initializing some random Gaussian noise to\nrepresent U and feeding the same noise to multiple networks $X$ and $Y$ while training. As a result, when $X$ and $Y$\nare trained to learn their mechanisms their output will be correlated since they use the same initial random noise. We\nwill add this discussion on the challenges in using different generative models in the presence of unobserved\nconfounders to a discussion section in the camera-ready.\n\nWe again thank the reviewer again for their constructive feedback. We hope we addressed all their concerns. We are looking forward to answering any other questions the reviewer might have."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8025/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700194076444,
                "cdate": 1700194076444,
                "tmdate": 1700194076444,
                "mdate": 1700194076444,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ep3vJmT77i",
            "forum": "vbebD7QRxP",
            "replyto": "vbebD7QRxP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8025/Reviewer_g68Y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8025/Reviewer_g68Y"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors proposed a new modular training algorithm to learn deep causal generative models, given a known causal graph and observational dataset. The method proceeds via factorizing the full joint distribution into its different c-components in the form of $\\mathcal{L}_2$ distributions, and then match each components sequentially leveraging rule 2 of do-calculus. In this way, the authors suggest that in certain cases, pre-trained model might be utilized to improve convergence of the learning process. For example, when certain c-component is a high-dimensional node like images, one can simply plugin a pre-trained generative model. Finally, this enables the identification of interventional or counterfactual queries in the presence of high-dimensional variables."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper is built upon well-known results in causality and proposed a modular training method for deep causal models, which, to the best of my knowledge, is a new contribution to the field. This might have potential use cases in learning realistic counterfactual data generation.\n- For certain cases demonstrated in the paper, the proposed method achieved good performance in terms of faster convergence and better identification quality."
                },
                "weaknesses": {
                    "value": "My primary reservations regarding this work stem from the possibility that the good performance demonstrated in a few hand-crafted scenarios may not extend to more general cases involving high dimensional variables.\n\n- More specifically, in all the experiments presented in the paper, the underlying causal graph fortuitously satisfies the condition wherein the solitary high-dimensional nodes are isolated c-components. However, in more general cases, such as the example depicted in Figure 2, the method would still need to match $p(Z_1, Z_2,Z_3|X_1)$ and $p(X_1, X_2, Z_1, Z_3)$, which does not significantly simplify the original problem of matching $p(X_1, X_2, Z_1, Z_2, Z_3)$, especially considering the added complexity of the proposed algorithm.\n\n- Furthermore, even in the scenarios where the proposed method was successful (experiments 1 and 2), the authors neglected to provide a comparison with an evident baseline: initializing the neural net architecture of the corresponding image node using a pre-trained marginal distribution, followed by fine-tuning the joint model in an NCM fashion. This baseline could serve as a robust ablation study to justify the necessity of c-component decomposition, a critical aspect that is currently absent from the current paper.\n\n- Lastly, the paper's problem setting requires access to the true causal graph, which is a reasonable assumption. However, in many scenarios where high-dimensional deep causal models are required, the true causal graph may not be known. This limitation could potentially restrict the applicability of the proposed method. In contrast, the joint training approach can easily adapt to unknown graph settings, thereby offering more flexibility."
                },
                "questions": {
                    "value": "My questions and concerns are listed above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8025/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698757282811,
            "cdate": 1698757282811,
            "tmdate": 1699636990158,
            "mdate": 1699636990158,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jepN3ruBTB",
                "forum": "vbebD7QRxP",
                "replyto": "Ep3vJmT77i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8025/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8025/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer g68Y (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for considering our work as a new contribution to the literature and appreciate their positive\nperspective about our work.\n\n## Modular training for c-component containing both low and high dimensional nodes\n\nThe reviewer mentioned that the challenge we face while matching the full joint distribution containing low and high\ndimensional variable still exists if a c-component contains both the image and low-dimensional variables.\n\nYes, we agree with the reviewer\u2019s insight. However, please allow us to explain that even in these cases, there is\nutility in using our method compared to the existing work.\n\nSuppose, a causal graph has $N$ variables. Without modularization, we have to match the joint distribution containing\n$N$ (might be large) number of low and high dimensional variables in a single training phase. Matching that joint\ndistribution with deep-learning models, and a complicated confounded causal structure could be difficult since we are\nattempting to minimize a very complicated loss function for a very large neural network. Our proposed method allows us\nto reduce the complexity of this problem tremendously by modularizing the training process to c-components. The size of\na c-component is generally a lot smaller than the whole graph. Thus, even though we have to train mechanisms in a\nc-component together and match a joint distribution involving high and low dimensional variables, the complexity will be\nmuch lower. Without our approach, there is no existing work that can modularize and simplify the training process for a\ncausal graph with latents.\n\nTo back up our argument with empirical evidence, we have considered matching the joint distribution for the following\ngraph.\n\n$I_1 \\rightarrow Digit \\rightarrow I_2 \\rightarrow Color ; I_1 \\leftrightarrow Color \\leftrightarrow Digit$.\n\nHere $I_1$ and $I_2$ are image nodes and the rest are discrete.\n$I_1, Digit, Color$ belong to the same c-component.\n\nOur baseline NCM will attempt to match $P(I_1, D, I_2, C)$ by training mechanisms of all variables at the same time.\nWhereas, we i) first train $I_2$ to match $P(I_2|D)$ and then\nii) train $I_1, D,C$ to match $P(I_1, D, I_2, C)$. At the first step, $I_2$ trains well. In the 2nd step, since we don\u2019t\nhave to train $I_2$ anymore, matching the joint gets easier. Below we report the image quality of our baseline and our\nmethod.\n\nFID scores representing the image quality of $I_1$ (lower is better):\n\n| Epochs/FID | 25     | 50     | 75    | 100   | 125   | 150   | 175   | 200   | 225   | 250   | 275   | 300   |\n|------------|--------|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n| NCM        | 101.00 | 110.11 | 92.11 | 66.00 | 61.03 | 67.82 | 68.09 | 66.01 | 41.91 | 30.78 | 74.41 | 80.54 |\n| Ours       | 79.96  | 65.84  | 41.98 | 33.68 | 35.02 | 35.74 | 29.55 | 36.28 | 31.09 | 32.38 | 30.11 | 32.88 |\n\nFID scores representing the image quality of $I_2$ (lower is better):\n\n| Epochs/FID | 25     | 50    | 75    | 100   | 125   | 150   | 175   | 200   | 225   | 250   | 275   | 300   |\n|------------|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n| NCM        | 112.61 | 98.09 | 78.50 | 62.94 | 60.87 | 67.56 | 77.89 | 43.45 | 50.81 | 45.90 | 64.50 | 65.17 |\n| Ours       | 22.22  | 15.77 | 14.53 | 14.10 | 17.27 | 15.47 | 16.47 | 14.92 | 13.48 | 12.98 | 11.38 | 11.80 |\n\nThe total variation distance for P(D, C) in both methods seems to be similar. But as we observe above, our method\nachieves better image quality than NCM.\n\n> \"Still need to match $P(Z_1,Z_2,Z_3|X_1)$ and $P(X_1, X_2, Z_1, Z_3)$; does not simplify matching $P(\n> X_1,X_2,Z_1,Z_2,Z_3)$\"\n\nWe mention the causal graph here for the reviewer\u2019s convenience: $Z_3 \\rightarrow Z_1 \\rightarrow Z_2; X_1 \\rightarrow\nZ_1 \\rightarrow X_2; Z_3 \\leftrightarrow Z_1 \\leftrightarrow Z_2; X_1 \\leftrightarrow X_2.$\n\nTo match the full joint distribution $P(X_1, X_2, Z_1, Z_2, Z_3)$, the joint training (NCM) has to train mechanisms of\nall $X_1, X_2, Z_1, Z_2, Z_3$ together at the same time. Whereas, in our approach, to match the joint distribution, we first\ntrain $Z_1, Z_2, Z_3$ at the first step and train $X_1, X_2$ at the 2nd step. Based on the above argument, the training\ncomplexity to match the joint distribution reduces in both steps compared to NCM."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8025/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700194830694,
                "cdate": 1700194830694,
                "tmdate": 1700194830694,
                "mdate": 1700194830694,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NzIYHBRjoM",
            "forum": "vbebD7QRxP",
            "replyto": "vbebD7QRxP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8025/Reviewer_UCfX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8025/Reviewer_UCfX"
            ],
            "content": {
                "summary": {
                    "value": "This paper deals with factorization of joint distributions over variables when there are latent and high dimensional variables exist and how to use pre-trained neural networks to model complex distributions among variables. \n\nThe key is to determine which subgraphs can be modeled by one NN (to learn distribution) and in which order. The results are not surprising given existing results on interventional distribution and the factorization of ADMG, but it is novel in a way to combine with generative models and handle high-dimensional variables."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The method is novel in a way to combine with generative models and handle high-dimensional variables."
                },
                "weaknesses": {
                    "value": "Some potential issues or weakness:\n    1. Lack of discussions on assumption 3 and their violation, and some assumptions are hidden in the text besides assumption 1 to 3. \n    2. What is the time efficiency of various approaches?"
                },
                "questions": {
                    "value": "Please see weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8025/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699116588941,
            "cdate": 1699116588941,
            "tmdate": 1699636990058,
            "mdate": 1699636990058,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UIIC8z75UE",
                "forum": "vbebD7QRxP",
                "replyto": "NzIYHBRjoM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8025/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8025/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UCfX (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for acknowledging our novelty in causal sampling involving high-dimensional variables. We happily\naddress each of the mentioned points by the reviewer.\n\n## Lack of discussions on assumption 3:\n\n> \"Lack of discussions on assumption 3 and their violation\"\n\nWe apologize to the reviewer for not clearly explaining it. We will add a simpler statement about this assumption in the\npaper. For the reviewer\u2019s convenience, we restate the assumption here.\n\nAssumption 3: for any h-node $H_k$ in the $\\mathcal{H}$-graph, GAN training of DCM (our method) on dataset $\\mathbf{D}$\nconverges to sample from the conditional distribution $P(H_k , \\mathcal{A}_k | {pa(H_k , \\mathcal{A}_k)})$ for all\n$H_k$, where $\\mathcal{A}_k$ is from Algorithm 2: Modular Training.\n\nAlthough the statement was written in a formal manner, assumption 3 simply says that we assume that GAN training\nconverges and can match the conditional distribution after training on the given dataset. This is a common assumption\nused in many GAN papers in literature ([1], [2], [3], [5]). In our algorithm, we are training the set of all models\nmodularly and matching corresponding conditional distributions. With sufficient representative power of the neural\nnetworks, and motivated by the success of deep generative models, we believe this assumption often holds in practice.\n\nIf this assumption is violated, i.e., if the generator models do not converge properly, our algorithm will output a\nnear-optimal solution. We expect this to only smoothly affect the causal queries of interest but it is a very\ninteresting future direction that we are interested in analyzing, i.e., how imperfect distribution matching affects the\ninterventional samples.\n\n## Hidden assumptions in the text:\n\n> \"Some assumptions are hidden in the text besides assumptions 1 to 3.\"\n\n\nWe agree with the reviewer that we stated some assumptions in the text. However, these are basically restatements, and\nwere already stated in Section 4.2 on page 7 of our paper. For convenience, we restate those main assumptions here:\n\n1) The causal graph is given\n2) The causal model is semi-Markovian and\n3) GAN training can correctly learn the desired conditional data distribution.\n\nTo address the reviewer\u2019s comment, we will cross-reference in-text assumptions with those we listed above.\n\nIn section 4, we assumed that the neural networks have sufficiently many parameters to induce the observed distribution\ninduced by the true SCM. Please note that this is basically assumption 3: GAN convergence.\n\nOnly in section 5.2, for the Covid X-ray experiment, we did not have access to the true causal graph (assumption 1 was\nviolated). Thus, we had to fill its gap with some extra assumptions about the data distribution (no distribution shift\nand selection bias) and the causal relations among variables."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8025/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700194317664,
                "cdate": 1700194317664,
                "tmdate": 1700194317664,
                "mdate": 1700194317664,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1xWPr6CRwc",
            "forum": "vbebD7QRxP",
            "replyto": "vbebD7QRxP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8025/Reviewer_Zypu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8025/Reviewer_Zypu"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an algorithm, WhatIfGAN, for modular learning of generative models for that can then be used for causal inference. WhatIfGAN identifies so-called H-groups of variables from a for which the do-calculus rule-2 holds and allows for separate training of generative models for the different groups. The paper compares the performance of WhatIfGAN to NCMs as well as a GAN without modular training. The results seem to indicate that WhatIfGAN generates superior high-dimensional counterfactuals.\n\n[1] Kevin Xia, Kai-Zhan Lee, Yoshua Bengio, and Elias Bareinboim. The causal-neural connection: Expressiveness, learnability, and inference. Advances in Neural Information Processing Systems, 34:10823\u201310836, 2021."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper tackles the interesting and important problem of high-dimensional causal estimation with unobserved confounding. The authors propose a sound method for modularising the training of deep generative models which allows for efficient estimation of those causal queries. The experiments seem to indicate superior performance to relevant baselines."
                },
                "weaknesses": {
                    "value": "The presentation of the paper could be improved including the presentation of the results and choice of experiments. The notation is inconsistent and changes from $Pa(..)$ to $pa(...)$ or from $P(...\\mid do(x=..))$ to $P_x(...)$. The evaluation relies heavily on visual comparison of sampled data rather than quantifiable metrics. I suggest having a look at [1] for ideas of how to quantify counterfactual estimation capabilities for the CovidX dataset. The synthetic MNIST dataset can be validated against ground-truth distributions and samples using the TVD as done, or likelihood measurements or the likes. Also MSEs for ATE differences or CFs could be interesting.\n\n[1] Monteiro, Miguel, et al. \"Measuring axiomatic soundness of counterfactual image models.\" The Eleventh International Conference on Learning Representations. 2022."
                },
                "questions": {
                    "value": "- Could this be achieved without modular training but by enforcing the noise to be the same between confounded variables? E.g. training $p(z_3)$ using an invertible function to find the noise to pass into training $p(z_1\\mid z_3)$?\n- It would be helpful to better introduce D and A in the MNIST use-case.\n- I would encourage to also test the method on a more complicated synthetic dataset with more than 3 nodes.\n- The paper would benefit from an introduction of TVD."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8025/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699366214706,
            "cdate": 1699366214706,
            "tmdate": 1699636989914,
            "mdate": 1699636989914,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZZShz7X1md",
                "forum": "vbebD7QRxP",
                "replyto": "1xWPr6CRwc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8025/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8025/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Zypu (1/2)"
                    },
                    "comment": {
                        "value": "We are honored that the reviewer found the problem we are solving interesting and important. We also thank them for\nappreciating the soundness of our algorithm.\nHere we address the reviewer\u2019s concerns below:\n\n## Choice of experiments:\n\n> \u201cI would encourage to also test the method on a more complicated synthetic dataset with more than 3 nodes.\u201d\n\nWe agree with the reviewer that the main paper considers causal graphs with 3 nodes. The intention was to illustrate the\nflexibility to utilize available pre-trained models (For example Covid-Xray model) and the significance of\nmodularization. However, we would like to draw the reviewer\u2019s attention to Appendix F of our paper where we also showed\nour algorithm performance on more complicated graphs.\nHere we list the causal graphs we used for our experiments more specifically:\n\n* 3 nodes: in Section 5.1, we highlight our flexibility to utilize pre-trained models and illustrate our performance\n  compared to baselines on the MNIST dataset.\n* 3 nodes: in Section 5.2, we experiment on the real-world COVIDx CXR-3 dataset with 30k samples that we associate with\n  a front door graph.\n* 9 nodes: in Appendix F.4, we showed our performance on a Colored-MNIST experiment where the causal graph contains 7\n  discrete variables and 2 image variables.\n* 6 nodes: in Appendix F.5, we experiment with the ASIA causal graph (6 nodes) from the popular bnlearn repository (\n  bnlearn.com/bnrepository).\n* 4 nodes: in Appendix F.6, we show our algorithm performance on the real-world Sachs protein dataset that includes both\n  observational and interventional data.\n* 7 nodes: in Appendix F.7, we show performance on a synthetic experiment with a causal graph with 7 nodes.\n\nWe believe that our experiments clearly illustrate our motivation, contribution, and technical novelties. Having said\n  that if the reviewer has any specific synthetic/real-world datasets in mind, we would be happy to perform more\n  experiments and demonstrate our performance on them.\n\n## Quantifiable metrics for image results:\n\n> \u201cThe evaluation relies heavily on visual comparison of sampled data rather than quantifiable metrics\u201d.\n\nWe agree with the reviewer that the evaluation relies on visual comparison. Since our aim was not to improve image\nquality but rather to consistently generate interventional and counterfactual samples, we modeled our synthetic dataset\nin such a way that visual inspection is enough to assess the correctness.\n\nTo measure the distance between our predicted distribution and the ground truth, we used the total variation distance (\nTVD) and the KL divergence in all of our experiments. We would like to kindly point to our results in Appendix F (page\n33), where we showed KL divergence as a metric for evaluation of our method.\n\nHowever, to improve our paper according to the reviewer\u2019s suggestion, we added the popular Fr\u00e9chet inception distance (\nFID) as our third metric that represents the quality of generated images. We compare our method with a baseline for the\nfront door MNIST experiment (section 5.1). \n\nThis table shows that we achieve better image quality (lower FID) with more\ntraining epochs compared to the non-modular baseline.\n\n| Epochs/FID     | 25     | 50     | 75    | 100   | 125   | 150   | 175   | 200   | 225   | 250   | 275   | 300   |\n|----------------|--------|--------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n| Non-modular    | 151.41 | 110.02 | 91.71 | 74.95 | 86.77 | 78.69 | 74.38 | 76.62 | 77.86 | 74.32 | 66.96 | 80.65 |\n| Modular (Ours) | 74.34  | 59.26  | 59.19 | 59.56 | 63.05 | 59.46 | 60.81 | 63.11 | 63.58 | 61.05 | 61.41 | 62.83 |\n\nNote that Mean squared error (MSE) is typically used in regression and is not directly applicable to our method since we\nmeasure the distance between the true and fake joint distributions. Although the average treatment effect (ATE) is\nsuitable for binary variables,\nin this simulation we deal with larger support sizes. For variables with larger support sizes, TVD and KL metrics\ncontain more information about the distance between true and fake distribution."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8025/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700193287637,
                "cdate": 1700193287637,
                "tmdate": 1700193437213,
                "mdate": 1700193437213,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]