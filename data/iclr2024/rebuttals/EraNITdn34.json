[
    {
        "title": "Unlocking the Transferability of Tokens in Deep Models for Tabular Data"
    },
    {
        "review": {
            "id": "NxLHx79GuW",
            "forum": "EraNITdn34",
            "replyto": "EraNITdn34",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7306/Reviewer_B5qv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7306/Reviewer_B5qv"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose TabToken which is a regularization & token feature learning method to incorporatee semantics at the token level during pre-training. This is specifically for tabular datasets with a mixture of real and categorical feature values. The authors claim that pretraining features and the top layer model during pre-training and subsequently finetuning the top layer allows better token feature transfers to other types of complex datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Consideration of real world problems: The authors considered using datasets that reflect the complexities of real world datasets where there is a mixture of data formats. \n- Holistic testing: The authors evaluated their method on 10 tabular datasets spanning different domains."
                },
                "weaknesses": {
                    "value": "- Significance: Lin et al. 2023 [1] demonstrated that the output layer of pre-trained text encoders do encode similarities or structure in tokens. This seems to contradict the authors claim and Figure 4 that vanilla training does not contain structure of the features? Is the lack of feature token transferability specific to tabular datasets? If so, is this solving a narrow or a domain specific problem, or would it generalize to any language model that uses a tokenizer?\n- Incremental performance: Table 1 shows that TabToken only leads to a marginal improvement (< 0.2 accuracy and < 3 RMSE), some of the baselines are non deep learning methods. Figure 6, also shows marginal improvement of TabToken compared to other methods with increasing feature ratios. Table 2 also shows incremental improvement or even a decrease in performance when combining existing models with CTR. Is this why the improvement or deprovement with CTR was not highlighted using bold numbers in table 2? \n- Difficulty of datasets used: The number of features in the datasets span between 8 to 54 in table 3. With a small dataset scale, non deep learning methods actually perform better. Could the paper be a case of using an over-engineered solution? More importantly, the benefits of using TabToken to improve deep learning algorithms becomes questionable since the dataset complexity is not at scale to employ deep learning methods. Perhaps pre-training or finetuning only the tokenizer might be relevant and the encoded features can be passed to a non deep learning classifier such as SVM? This could alleviate the complexities of training deep learning classifiers and focus the problem of learning good feature representations.\n\n[1] Lin, Z., Azaman, H., Kumar, M. G., & Tan, C. (2023). Compositional Learning of Visually-Grounded Concepts Using Reinforcement. arXiv preprint arXiv:2309.04504."
                },
                "questions": {
                    "value": "- will the algorithm be released as a pytorch or tensorflow module that can be incorporated into other models? \n- what is the difference between TabToken and CTR? The difference can be delineated better."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Discrimination / bias / fairness concerns"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "The authors work is not of ethical concern. However, I am curious about the bank-marketing dataset that is accessible for ML researchers to train and build models on. I am wondering about its potential to include bias or unfair discrimination against the nature of jobs and the associated financial risk etc."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7306/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7306/Reviewer_B5qv",
                        "ICLR.cc/2024/Conference/Submission7306/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698605710906,
            "cdate": 1698605710906,
            "tmdate": 1700594522660,
            "mdate": 1700594522660,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xruFbTfgXk",
                "forum": "EraNITdn34",
                "replyto": "NxLHx79GuW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7306/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer B5qv (Part 1)"
                    },
                    "comment": {
                        "value": "We express our gratitude to the reviewer for providing valuable feedback. Due to the character limit, we have divided our response into two parts. \n\n**Q1:** Pre-trained text encoders are able to encode similarities or structures in tokens. Is the lack of feature token transferability specific to tabular datasets?\n\n**A1:** \n\nBERT Text Encoder and CLIP Text Encoder, just as mentioned in the paper [1] cited by the reviewer, are pre-trained on vast corpora of data and have large-scale models. Through extensive data and pre-training methods for language model, the pre-trained text encoders possess semantic representation capabilities. However, due to the diverse feature types and different feature dimensions across different tabular tasks, pre-training for tabular data is typically conducted on a single task [A] or on multiple tasks without sharing tokenizers [B]. Because it is currently not feasible to simultaneously train a feature tokenizer on a large volume of heterogeneous tabular datasets, the pre-training tokenizer lacks token transferability.\n\nSo the observation that the learned tabular tokens with poor semantics does not contradict with the semantic tokens of large NLP models. TabToken is solving a problem for tabular data where the learned tokens cannot encode similairities or structures, which makes the encoder of deep tabular models cannot be transfered as those in image processing and natural language processing domains.  In resource-constrained scenarios, our approach may generalize to a language model, assisting the text encoder in obtaining more semantic information.\n\n**Q2:** Some of the baselines are non-deep learning methods. The improvement is not enough.\n\n**A2:** \n\nUnlike the success observed in text and image datasets, deep models still struggle to outperform non-deep models on tabular data. Tree-based models remain competitive on tabular data even without accounting for their superior speed [C]. There is still no universally superior solution among GBDT and deep models [D]. Besides, in the experiments for XTab [B], with hyperparameter optimization, XTab ranks lower than XGBoost. Therefore, our comparison is between the currently strong baselines in both non-deep and deep methods. In our setting, TabToken ranks high across the majority of datasets. In Table 2, due to the diversity of datasets, it is challenging for CTR to achieve universal improvements. However, we still achieved improvements on the majority of datasets. \n\nOne of the main contributions of our approach lies in enhancing the transferability of deep models. As shown in Table 12, when we transfer the pre-trained Transformer and fine-tune it, the pre-training model demonstrates a significantly lower transfer effect compared to TabToken. Therefore, we have made improvements in the transferability of deep tabular models.\n\n**Q3:** Non-deep learning methods perform better on small scale datasets. The dataset complexity is not at scale.\n\n**A3:**\n\nFirstly, the inferior performance of deep learning compared to non-deep models is not primarily due to small-scale issues. In comparisons on large-size datasets, this paper [C] found that, although the advantage of tree models diminishes a little, a gap still exists between deep models and tree models. (The Jannis dataset in our experiments falls into the category of large-size datasets as classified in this paper.) The challenges that hinder deep models from outperforming non-deep models on tabular data stem from various factors [C]: neural networks are inclined towards overly smooth solutions, MLP-like neural networks are more affected by uninformative features, and data lack invariance to rotation.\n\nSecondly, applying deep learning methods to small-scale tabular datasets has received attention in recent literature, such as TabPFN [E], where the deep learning methods are expected to possess the model prior and be transferred to downstream tasks more effectively. In our experiments, we show our TabToken can perform well on small-scale datasets, better than TabPFN.\n\nThanks for the suggestions. We conducted experiments on two larger and more complex datasets. We collect scene recognition dataset (300 features, binary classification) and sylva agnostic dataset (217 features, binary classification) from OpenML. We use the same setting as the experiments in Table 1. The experimental results indicate that non-deep methods remain competitive on complex datasets, showing significant advantages in scene recognition dataset. Moreover, TabToken continues to be an advantageous solution among deep models on complex datasets.\n\n| Acc (%) | XGBoost   | XTab  | TabRet | TabToken  |\n| ------- | --------- | ----- | ------ | --------- |\n| scene   | **56.24** | 42.97 | 39.58  | 53.87     |\n| sylva   | 68.15     | 24.59 | 35.74  | **72.92** |\n\n(In Part 2, we will continue with the response.)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700213894067,
                "cdate": 1700213894067,
                "tmdate": 1700213894067,
                "mdate": 1700213894067,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EAWf7cvBHg",
                "forum": "EraNITdn34",
                "replyto": "NkUWFiBz2o",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7306/Reviewer_B5qv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7306/Reviewer_B5qv"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for your detailed rebuttal and running some additional experiments. I have revised my score to 5. I would recommend the authors including examples to distinguish tabular data types from other canonical data structures for clarity. The paper could potentially be an interesting discussion for ICLR. However, I am still struggling to understand the contribution of the work, while the application to real world data is appealing."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700594794089,
                "cdate": 1700594794089,
                "tmdate": 1700594794089,
                "mdate": 1700594794089,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "edTVtSWl9C",
            "forum": "EraNITdn34",
            "replyto": "EraNITdn34",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7306/Reviewer_yFnT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7306/Reviewer_yFnT"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes introducing semantics to feature tokens in order to improve the transferability of feature tokenizers through (1) averaging to represent an instance, (2) introducing a contrastive token regularization objective in pre-training to minimize the distance between instances and their respective class centers. Proposed solution is quite simple, but yet effective based on the empirical evaluation. I recommend the paper for acceptance, particularly given the importance of the problem they are solving in real-world applications."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(1) Clear and intuitive presentation.\n(2) Well-motivated problem based on the analysis they conduct (see Figure 4 in particular).\n(3) Simple but effective solution based on empirical analysis."
                },
                "weaknesses": {
                    "value": "(1) They do not characterize the heterogeneity of the datasets they evaluate on -- hence, I do not have a sense for how hard it actually is to transfer between feature sets.\n(2) There is no investigation on how the size of the models affect the described behavior of transferrability of feature tokenizers."
                },
                "questions": {
                    "value": "n/a"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698680017487,
            "cdate": 1698680017487,
            "tmdate": 1699636872480,
            "mdate": 1699636872480,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xVstOqpZdm",
                "forum": "EraNITdn34",
                "replyto": "edTVtSWl9C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7306/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer yFnT"
                    },
                    "comment": {
                        "value": "We acknowledge and appreciate the reviewer's thoughtful comments. We respond to the concerns below:\n\n**Q1:** Characterize the heterogeneity of the datasets. \n\n**A1:** \n\nThe heterogeneity of the dataset is reflected in the variations of the feature space. Specifically, there are features in the pre-training dataset that are absent in the downstream tasks, and vice versa, downstream tasks include features that were not encountered during the pre-training phase. The heterogeneity of the dataset can also be reflected in the distinct domains across datasets, as exemplified by the pre-training dataset BRFSS and the downstream datasets Diabetes & Stroke in Table 9. We construct a pre-training task on BRFSS for predicting HIV test experience. The task of Diabetes dataset is to predict whether a subject has diabetes. The Stroke dataset records clinical events and the task is to predict whether a subject is likely to get a stroke. \n\n**Q2:** How hard it actually is to transfer between feature sets.\n\n**A2:**\n\nTraditional tabular models, such as XGBoost, face challenges in adapting to changes in feature inputs during transfer. Each tabular feature has a strong correspondence with model parameters, making it hard to directly transfer pre-trained deep learning models when encountering unseen features. As demonstrated in our ablation study in Table 12, when we fix a certain part of the pre-trained Transformer and fine-tune it, the pre-training model exhibits a lower transfer effect compared to TabToken. The pre-trained deep model faces challenges in achieving the desired transfer effect between feature sets. The scarcity of available samples for fine-tuning on new datasets further complicates the knowledge transfer process.\n\n**Q3:** How the size of the models affect the described behavior of transferrability of feature tokenizers.\n\n**A3:** \n\nFollowing the reviewer's suggestion, we conducted an ablation study with different model sizes on four datasets, altering the number of layers in the transformer during pre-training. We keep the fine-tuning model's number of layers fixed at 3.   We use the same setting as the experiments in Table 1. The experimental results indicate that when the pre-trained model size is relatively small (the number of layers is less than 3), the effectiveness of transfer is impacted. When the number of layers is three or more, the transfer capability of the tokenizer is challenging to further enhance. The impact of model size may be dependent on the difficulty of the task. More complex tasks require larger model sizes to achieve sufficient transferability. The experimental results are as follows:\n\n| Acc (%)       | eye       | jannis    | cardio    | htru      |\n| ------------- | --------- | --------- | --------- | --------- |\n| layer num = 1 | 38.66     | 36.20     | 62.26     | 84.45     |\n| layer num = 2 | 38.56     | 36.45     | 62.06     | 84.55     |\n| layer num = 3 | 39.28     | **36.87** | 62.29     | 84.59     |\n| layer num = 4 | 39.11     | 36.70     | **63.23** | **84.80** |\n| layer num = 5 | **39.59** | 36.49     | 63.08     | 84.33     |\n\nThanks for the suggestion. We will include this ablation study in the appendix.\n\n\n\nWe thank for the beneficial commentary. Please let us know if our response has addressed the concerns. We're keen on promptly addressing any further comments from the reviewer."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700212151605,
                "cdate": 1700212151605,
                "tmdate": 1700212151605,
                "mdate": 1700212151605,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jLfSvuUn5z",
                "forum": "EraNITdn34",
                "replyto": "DLnhlBcA2h",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7306/Reviewer_yFnT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7306/Reviewer_yFnT"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for responding to my questions and the additional ablation. My score remains the same."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700589161177,
                "cdate": 1700589161177,
                "tmdate": 1700589161177,
                "mdate": 1700589161177,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8Ef9HXMPns",
                "forum": "EraNITdn34",
                "replyto": "edTVtSWl9C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7306/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer yFnT"
                    },
                    "comment": {
                        "value": "Thanks a lot for the dedication and feedback. We are pleased that our responses addressed the questions. We have incorporated experiments on different model sizes as suggested by the reviewer into the revision (Table 13). If the reviewer has any other concerns or feedback, we look forward to engaging in more discussions and further enhancing the quality of our paper."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700590018220,
                "cdate": 1700590018220,
                "tmdate": 1700590430472,
                "mdate": 1700590430472,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "i7pzWFmPTm",
            "forum": "EraNITdn34",
            "replyto": "EraNITdn34",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7306/Reviewer_6daM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7306/Reviewer_6daM"
            ],
            "content": {
                "summary": {
                    "value": "This work presents a method to enhance the transferability of deep models on tabular data. Tabular data contain unique column features with their categorical or numerical values, making it challenging to transfer knowledge from pretraining data to unseen downstream data. To address this issue, the authors employ a contrastive regularization objective to learn semantic tokens for each column feature. Few-shot downstream tasks can leverage these overlapping semantic tokens. Experimental results demonstrate that the proposed method outperforms previous approaches in few-shot classification and regression tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is well-written and easily understandable.\n- The proposed method is simple yet effective, delivering superior performance on each dataset compared to previous methods.\n- The paper provides a comprehensive analysis and visualization of the experiments.\n- The proposed method exhibits a slight improvement in standard tabular tasks, which is a noteworthy point."
                },
                "weaknesses": {
                    "value": "- The contrastive loss with the label has limited novelty. \n- The section on related works should be integrated into the main article, as it is difficult to discern the specific improvements in comparison to previous methods.\n- While the authors experimented with diverse domains of datasets, both the pretraining and finetuning datasets for each experiment originate from the same dataset. It remains uncertain whether the proposed method can be generalized across domains.\n- The proposed method necessitates annotated labels for learning semantic tokens, limiting its application to supervised training. A self-supervised pretraining approach without annotations could be more appealing."
                },
                "questions": {
                    "value": "Since the current model focuses on pretraining on one dataset and finetuning on the same dataset, is it feasible to explore pretraining on a large-scale cross-domain dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7306/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7306/Reviewer_6daM",
                        "ICLR.cc/2024/Conference/Submission7306/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699434414445,
            "cdate": 1699434414445,
            "tmdate": 1700501504461,
            "mdate": 1700501504461,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XesYUdiBcE",
                "forum": "EraNITdn34",
                "replyto": "i7pzWFmPTm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7306/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer 6daM (Part 1)"
                    },
                    "comment": {
                        "value": "We greatly appreciate the reviewer's valuable feedback. Due to the character limit, we divide our response into two parts. \n\n**Q1:** The contrastive loss with the label has limited novelty. \n\n**A1:** \n\nPrevious transfer methods have focused on how to leverage large language models [A, B] or enhance the transferability of the top-layer model [C, D]. To the best of our knowledge, we are the first to focus on unlocking the transferability of feature tokens in the realm of tabular data transfer learning. We have unveiled a phenomenon starkly distinct from that observed in other domains: tokens learned by tabular data deep models lack semantic understanding. We devised the \"Contrastive Token Regularization\" (CTR), incorporating token pre-training and token fine-tuning tailored for tabular data.\n\nAlthough the general form of CTR is similar to the commonly used contrastive loss, the specific CTR is designed for deep tabular model. We start by converting a set of feature tokens to instance tokens through token combination. Then, we use token regularization to pull instance tokens towards their class center. This process enables contrastive loss to regularize the feature tokens effectively. Also, we have explored different forms of contrastive loss in Table 7.\n\nMoreover, we emphsize we can improve the semantic of the token through applying CTR over those tokens *before* the transformations in the deep tabular model, as we demonstrated in Figure 4 and Figure 5.\n\nFurthermore, CTR is just one component of TabToken, and the novelty of our approach also comes from the whole pre-training and fine-tuning method. \n\n**Q2:** Move the related work from the appendix to the main text.\n\n**A2:** \n\nThanks for the suggestions. \n\nAlthough we discussed the relationship between our TabToken with previous methods such as Transferring Tabular Models across Feature Spaces, we chose to place the related work section at the beginning of the appendix due to the substantial content of the related work and constraints on the length of the main text. \n\nWe will move the related work to the main text.\n\n**Q3:** Explore pre-training on a large-scale cross-domain dataset. Whether the proposed method can be generalized across domains.\n\n**A3:**  \n\nIn the appendix, we have explored the OOD generlization ability of TabToken in Table 9, where TabToken was pre-trained on BRFSS and fine-tuned on Diabetes & Stroke. BRFSS is the Behavioral Risk Factor Surveillance System dataset with more than 340K samples and more than 300 features from Kaggle. We construct a pre-training task on BRFSS for predicting HIV test experience. The task of Diabetes dataset is to predict whether a subject has diabetes. The Stroke dataset records clinical events and the task is to predict whether a subject is likely to get a stroke. \n\nAlthough these three datasets belong to different domains, they all fall under the category of health diagnosis. Approximately half of the features in the downstream datasets are present in the pre-training dataset, allowing us to apply TabToken. We conducted pre-training in the domain of health behaviours and transferred knowledge to domains for Diabetes or Stroke. The results (as shown in Table 9) indicate that TabToken outperforms other baselines in this natural cross-domain application with overlapping features. TabToken can be generalized across domains.\n\nDue to concerns of data privacy and security in healthcare and financial applications, access to lots of cross-domain datasets with overlapping features is typically restricted. We follow the dataset splitting in [E,F,G,H,I] to construct pre-training and fine-tuning tasks, where the resources are limited and it is challenging to obtain all features at once.\n\n[A] Tabllm: Few-shot classification of tabular data with large language models. AISTATS, 2023.\n\n[B] Transtab: Learning transferable tabular transformers across tables. NeurIPS, 2022.\n\n[C] Xtab: Cross-table pretraining for tabular transformers. ICML, 2023.\n\n[D] TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns. ICLR workshop, 2023.\n\n[E] Heterogeneous ensemble for feature drifts in data streams. PAKDD, 2012.\n\n[F] One-pass learning with incremental and decremental features. IEEE T-PAMI, 2018.\n\n[G] Online Learning from Data Streams with Varying Feature Spaces. AAAI, 2019.\n\n[H] Learning with feature and distribution evolvablestreams. ICML, 2020.\n\n[I] Heterogeneous few-shot model rectification with semantic mapping. IEEE T-PAMI, 2021.\n\n(In Part 2, we will continue with the response.)"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700211275370,
                "cdate": 1700211275370,
                "tmdate": 1700211275370,
                "mdate": 1700211275370,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VwqXp7Wjg5",
                "forum": "EraNITdn34",
                "replyto": "BQTxLhq8S7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7306/Reviewer_6daM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7306/Reviewer_6daM"
                ],
                "content": {
                    "title": {
                        "value": "Response after author rebuttal"
                    },
                    "comment": {
                        "value": "Thanks for the explanation and extra experiments. The authors clarify most of my questions. The result in Appendix Table 9 is good to highlight for cross-dataset transferability, showing it in the main text can further strengthen the contribution. I raised the score to 6."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700501481751,
                "cdate": 1700501481751,
                "tmdate": 1700501481751,
                "mdate": 1700501481751,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]