[
    {
        "title": "Federated Recommendation with Additive Personalization"
    },
    {
        "review": {
            "id": "wlSaz7zJEg",
            "forum": "xkXdE81mOK",
            "replyto": "xkXdE81mOK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4245/Reviewer_QwLj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4245/Reviewer_QwLj"
            ],
            "content": {
                "summary": {
                    "value": "To overcome the challenge of personalization, the authors introduce the Federated Recommendation with Additive Personalization (FedRAP). This method combines global item insights from FL with local, user-specific perspectives. FedRAP ensures efficient communication by promoting sparser global embeddings and uses two regularizers to balance global and local views. The primary contributions include the introduction of the dual personalization approach, the use of two distinct regularizers."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe authors have adeptly addressed communication challenges in Federated Learning by advocating for a sparse global view. This practical strategy can potentially alleviate communication bottlenecks.\n2.\tThe emphasis on federated recommendations is commendable, since data privacy is a priority."
                },
                "weaknesses": {
                    "value": "Clarity and Consistency in Writing: The manuscript requires clarity and consistency checks.\na. In Figure 1's title, \"five dataset\" is mentioned, whereas at the end of Section 1, it states \u201cfour dataset\u201d.\nb. There seems to be a mismatch in presentation; the results from Section 4.4 on Page 7 are introduced as early as Page 2 in the introduction. Is there a specific reason behind placing the experimental results in the introductory section?\n\nExplicit Statement of Motivation and Research Question: The introductory section should more explicitly state the motivation and the central research question. While Paragraph 3 introduces federated recommendation, and Paragraph 4 delineates the main contribution, there's a lack of clarity on the necessity of addressing heterogeneity and personalization in Federated Recommendation (FedRec). The central research questions around the importance of personalization in FedRec and the inadequacies of existing methods demand elaboration.\n\nDifferentiating Heterogeneity from Personalization: The distinction between heterogeneity and personalization needs to be clearer. The manuscript suggests two challenges: heterogeneity, which seems to pertain to varying client interests, and personalization. Given their similarities in this context, why are they presented as two separate challenges?\n\nOrganizational Refinements: There's a need for reorganizing the content, especially in Section 3.1 (Problem Formulation). Here, the authors discuss the loss function and the proposed method's entire framework. A more suitable structure might involve mathematically introducing the problem in the Problem Formulation and discussing the method's framework in a separate section.\n\nClarification on 'Reconstruction Error': Figure 2 illustrates the \"reconstruction error\". As per my understanding, it seems to measure the discrepancy between actual user ratings and predicted ones. The term \"reconstruction error\" suggests that something undergoes reconstruction. Can the authors clarify this?\n\nQuestioning Novelty: The paper's primary innovation appears to be the maintenance of a user-specific item embedding matrix, D(i), for every user, i. Given that local interactions are usually sparse, which motivates federated training, the uniqueness of this approach is incremental. The two regularizers are essentially the normalization of two embedding tables. While differential privacy is prevalent in federated learning, its application here doesn't seem groundbreaking.\n\nComparative Analysis with Relevant Works: The manuscript cites PerFedRec [1] in the related works but doesn't present a comparative analysis in the experiments. It would be insightful for the authors to contrast their work with PerFedRec. Moreover, considering the work on PerFedRec++ [2] could be beneficial, even if it's a recent arXiv publication.\n\nReferences:\n[1] Luo, S., Xiao, Y., & Song, L. (2022, October). Personalized federated recommendation via joint representation learning, user clustering, and model adaptation. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management (pp. 4289-4293).\n[2] Luo, S., Xiao, Y., Zhang, X., Liu, Y., Ding, W., & Song, L. (2023). PerFedRec++: Enhancing Personalized Federated Recommendation with Self-Supervised Pre-Training. arXiv preprint arXiv:2305.06622."
                },
                "questions": {
                    "value": "1.\tWhy is the term \"Reconstruction error\" used in Figure 2? What exactly is being 'reconstructed' in the given context?\n2.\tCould the authors delineate the difference between 'heterogeneity' and 'personalization'? As of now, the distinction is not abundantly clear, and the terms seem somewhat interchangeable.\n3.\tThe paper emphasizes the sparse embedding's ability to reduce communication costs, a known limitation of current methods. Why is this specific aspect not experimentally validated or discussed in the results section? Can the authors provide insights or potential experimental outcomes supporting this claim?\n4.\tGiven that \"PerFedRec\" is cited in the related work and seems to be a relevant approach in this domain, why is it omitted from the experimental comparisons? A comparative analysis could provide a clearer perspective on the proposed method's advantages or potential differences."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4245/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4245/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4245/Reviewer_QwLj"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4245/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698663480720,
            "cdate": 1698663480720,
            "tmdate": 1700709072514,
            "mdate": 1700709072514,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sKf92byseJ",
                "forum": "xkXdE81mOK",
                "replyto": "wlSaz7zJEg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "Thank you for your time and comments! We address your questions and concerns in the following.  \n\n## W1 (Clarity and Consistency in Writing)\nWe reported experimental results on six datasets in the paper and we will make the text consistent. We will move the results to Section 4.4 on Page 7. \n\n## W2 (Statement of Motivation)\n\nIn federated recommendation systems, clients or users have different preference to each item and they may focus on different attributes or charateristics of the item, resulting in data heterogeneity, i.e., the items and their ratings are different across clients. Hence, a global model cannot accurately predict the preference of every user, while a personalized model per user can better address the heterogeneity problem. \n\nMost existing personalized federated recommendation systems focus solely on personalizing user embedding or score function, overlooking the potential impact of user preferences on different attributes of items. While PFedRec considers personalized item embedding, it neglects the knowledge sharing and collaborative filtering across users via global item embedding. To bridge the gap, in this work, we introduce a novel additive personalization that takes both the personalization of item embedding and sparse global collaboration in to account, leading to FedRAP that achieves significant improvement on the federated recommendation benchmarks.\n\nWe will improve the presentation of our motivation and strengthen the connection between the heterogeneity and the personalization proposed. \n\n## W3 & Q2 (Differentiating Heterogeneity from Personalization)\n\nHeterogeneity of users in federated recommendation syetems is the challenge we aim to address and the additive personalization is our proposed approach to address the challenge. So they are not seperated. FedRAP learns a user-specific item embedding and a globally shared item embedding jointly to enhance the performance in federated recommendation.\n\n\n## W4 (Organizational Refinements)\n\nWe will improve the organization and logical flow of the paper as you suggested in the updated draft.\n\n## W5 & Q1 (Clarification on \u2018Reconstruction Error\u2019)\n\nIn our paper, the term \"reconstruction\" refers to predicting the user ratings given in the training data. The reconstruction or prediction of ratings is achieved by the inner product between each user embedding $\\mathbf{u}_i$ and each item embedding, which adds the global item embedding $\\mathbf{C}$ and local item embedding $\\mathbf{D}^{(i)}$ together. The reconstruction error compares the prediction with the ground truth ratings by Eq. (1).\n\n## W6 (Questioning Novelty)\n\nFedRAP addressed a key challenge in federated recommendation and achieved significant improvement compared to existing methods on standard benchmarks. Its performance is unprecedently on par with the centralized recommendation system performance. This is due to the following technical novelties:\n(1) Additive modeling combining a local item embedding with a sparse global item embedding, which has not been studied for the problem; \n(2) A curriculum learning approach with two regularizations, which is critical to achieve the proposed additive modeling. \n\n## W7&Q4 (Comparative Analysis)\n\nWe will cite both PerFedRec and PerFedRec++ and discuss them in our uploaded draft. We are still tuning the hyperparameters for PerFedRec and aiming to include it in our experimental comparisons. Since PerFedRec++ has not released its code and it is a very recent preprint (published later than our preprint), we will try our best to include it in the future version of our paper."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699841112159,
                "cdate": 1699841112159,
                "tmdate": 1699841112159,
                "mdate": 1699841112159,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rEFlGgMrQO",
                "forum": "xkXdE81mOK",
                "replyto": "wlSaz7zJEg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal for W7&Q4 (Comparative Analysis) by Authors"
                    },
                    "comment": {
                        "value": "## W7&Q4 (Comparative Analysis)\n\nWe conducted a comparative analysis of PerFedRec and FedRAP on ML-100K and ML-1M. The results, as shown in Table R3, indicate that FedRAP demonstrates competitive performance compared to PerFedRec. We are still tuning the hyperparameters for PerFedRec on more datasets.\n\nTable R3. Experimental results of PerFedRec and FedRAP shown in percentages on the ML-100K and ML-1M dataset.\n|           | ML-100K | ML-100K |  ML-1M |  ML-1M  |\n|-----------|:-------:|:-------:|:------:|:-------:|\n|           |  HR@10  | NDCG@10 |  HR@10 | NDCG@10 |\n| PerFedRec |  63.56  |  44.40  | 63.84  |  43.99  |\n| FedRAP    |  97.09  |  87.81  | 93.24  |  71.87  |"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700132813571,
                "cdate": 1700132813571,
                "tmdate": 1700178684276,
                "mdate": 1700178684276,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nrlikurI1a",
                "forum": "xkXdE81mOK",
                "replyto": "wlSaz7zJEg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[Discussion ends in <2 days] Would you mind confirming if your concerns have been addressed?"
                    },
                    "comment": {
                        "value": "Dear Reviewer QwLj,\n\nIn the rebuttal, we have rephrased the motivation and novelty, highlighting the role of sparse constraints on $\\mathbf{C}$. We have conducted a comparative analysis of PerFedRec and FedRAP on ML-100K and ML-1M, with the results presented in Table R3. Furthermore, we are refining the manuscript to enhance consistency in expression and reduce typographical errors. In future releases, we plan to cite and discuss PerFedRec++ extensively.\n\nAs we are approaching the midpoint of the discussion period, we would like to cordially inquire about the extent to which we have successfully addressed the concerns outlined in your review. Should there be any lingering points that require further attention, please rest assured that we are enthusiastic about the opportunity to provide comprehensive responses to any subsequent queries or comments you may have.\n\nYour constructive input remains invaluable to us, and we appreciate your dedication to enhancing the quality of our manuscript. Thank you for your time and consideration.\n\nBest,\n\nAuthors"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700537942420,
                "cdate": 1700537942420,
                "tmdate": 1700537942420,
                "mdate": 1700537942420,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IOvLaK3HmW",
                "forum": "xkXdE81mOK",
                "replyto": "sKf92byseJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4245/Reviewer_QwLj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4245/Reviewer_QwLj"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors' rebuttal"
                    },
                    "comment": {
                        "value": "I appreciate the authors' rebuttal. My major concerns on the motivation, novelty, and experiments have been addressed in the rebuttal."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708942954,
                "cdate": 1700708942954,
                "tmdate": 1700708942954,
                "mdate": 1700708942954,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ElQdWC4XC2",
            "forum": "xkXdE81mOK",
            "replyto": "xkXdE81mOK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4245/Reviewer_MAPK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4245/Reviewer_MAPK"
            ],
            "content": {
                "summary": {
                    "value": "Federated Recommendation Systems (FRS) is a promising field, however, existing methods not pay enough attention to personalization . To enhance personalization in the field of FRS, FedRAP proposed by the authors address the challenges of heterogeneity and personalization in FRSs. FedRAP decouples the common knowledge and personalized knowledge by decoupling user embedding to on-server (updated by server-client communication) sparse one and on-client one. Regularization is used to restrict training."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. It points out the shortcomings of the existing FRS methods, and gives a complete solution, which is instructive.\n2. The framework is complete, and the paper is clearly expressed.\n3. Theoretical analysis is sufficient. Proofs of error and differential privacy in federated learning are comprehensive.\n4. Limitations about FedRAP are detailed"
                },
                "weaknesses": {
                    "value": "None"
                },
                "questions": {
                    "value": "None"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4245/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698773206958,
            "cdate": 1698773206958,
            "tmdate": 1699636391505,
            "mdate": 1699636391505,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VA98cJfRRF",
                "forum": "xkXdE81mOK",
                "replyto": "ElQdWC4XC2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your constructive comments and support!"
                    },
                    "comment": {
                        "value": "We would like to appreciate you for your constructive comments and support!"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699840825522,
                "cdate": 1699840825522,
                "tmdate": 1699840825522,
                "mdate": 1699840825522,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "muO59qDtTY",
            "forum": "xkXdE81mOK",
            "replyto": "xkXdE81mOK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4245/Reviewer_eLAA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4245/Reviewer_eLAA"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the problem of federated recommendation and proposes a new method improving the personalization performance. The authors developed a new additive item embedding model that combines a sparse global embedding with a user-personalized embedding, where the federated recommendation only needs to periodically send the sparse embedding between servers and users, and thus saves the communication cost. The user-personalized embedding is only stored at the user devices and optimized for each user so the personalization performance can be improved. They developed a curriculum to facilitate the training of the two embeddings, which learns the personalized ones at first before adding the sparse global one. This method achieved significant improvements on five benchmark datasets of different domains and sizes. The paper also provides a differential privacy analysis to the proposed approach."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Federated recommendation is an important problem that has not been fully explored in the federated learning community. Improving the personalization performance is an open key challenge in the federated recommendation setting.\n2. The proposed additive item embedding model is a novel contribution to the field and addresses two critical challenges in the federated recommendation area, i.e,. reducing communication cost and personalization with knowledge sharing.\n3. The ablation study shows that the curriculum is important to learn the item embedding model.\n4. The performance achieved by the proposed FedRAP is remarkable in Figure 1: on six widely-used benchmarks, it outperforms all the federated recommendation baselines by a substantial margin and largely reduces the gap between federated algorithms and centralized ones---this is nontrivial and worth being highlighted. \n5. The ablation study includes 8 variants of the proposed methods and demonstrates the advantage of most components in the proposed FedRAP. The analysis and experiments regarding differential privacy make their method more trustworthy. \n6. They provided the code, which facilitates reproducible research in the future. I believe this work with the code released can be very interesting to people working in the area of federated recommendation systems."
                },
                "weaknesses": {
                    "value": "1. The variants in the ablation study introduced in Section 4.5 do not come with intuitive explanations of the motivations for comparisions with them. They are unclear to readers if they do not carefully read the following analysis. \n2. There are some typos and grammar errors which should be corrected."
                },
                "questions": {
                    "value": "1. Can you provide an ablation study of the regularization in Eq2? \n2. \"FedRAP-No: Removes item diversity constraint on C\" --- should \"diversity\" be \"sparsity\"? Is this a typo?\n3. In Figure 7, it seems that each user-personalized matrix is row-sparse with most rows to be all-zeros. How do we understand this row-sparsity? Can you (or did you) take advantage of this row-sparsity to further reduce the communication cost (e.g., by only sending the non-allzero rows)?\n4. How do we justify whether the degradation numbers in Table 1 are large or small? Are there any baselines' degradation results to be compared with?\n\nOverall, I think this is a solid work on an important open problem. Their proposed item embedding model has a novel design successfully addressing the communication and personalization problems in federated recommendation. Their reported improvement (when compared to existing federated recommendation approaches) on six well-known benchmark datasets is impressive and significant, demonstrating the effectiveness. The ablation study and differential privacy analysis are thorough and further strengthened the work. The paper is clear overall but there is still some room for improving the writing/presentation. Some questions above need further clarifications."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4245/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4245/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4245/Reviewer_eLAA"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4245/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698830955444,
            "cdate": 1698830955444,
            "tmdate": 1699636391421,
            "mdate": 1699636391421,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zGA6hJ5K1A",
                "forum": "xkXdE81mOK",
                "replyto": "muO59qDtTY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4245/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Rebuttal by Authors"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments and support!\n\n## W1 (Unclear Motivations)\nIn Section 4.5, we introduced eight variants of FedRAP based on three ablation study tasks. Specifically:\n1. To investigate the roles of global item embedding and local item embedding in FedRAP and validate the basic assumption of user preference influencing ratings, we designed FedRAP-C using only global item embedding and FedRAP-D using only local item embedding.\n2. To explore the impact of different constraints on C, we introduced FedRAP-No, which imposes no constraints on C, and FedRAP-L2, which uses the Frobenius norm on C.\n3. To examine the influence of different weight curricula on FedRAP's performance, we introduced FedRAP-fixed using two constants $v_1$ or $v_2$ in hyperparameters, FedRAP-sin using a sine function for hyperparameter variation, and FedRAP-frac using fractional changes in hyperparameters. Additionally, we presented FedRAP-square with a hyperparameter periodically transitioning between zero and constants $v_1$ or $v_2$.\n\nThese three ablation study aim to validate the contributions of three key innovations in FedRAP: two-way personalization, encouraging the sparsity of C, and a curriculum transitioning from full to additive personalization.\n\n## W2 (Improve Writing)\nThank you for bringing this to our attention! We will thoroughly review the paper and address any typos and grammar errors to ensure its clarity and quality. Your feedback is valuable in enhancing the overall presentation of the work.\n\n## Q1 (Ablation Study)\n\nWe introduce a new variant of FedRAP called FedRAP-S, where we remove the regularization $- \\lambda_{(a, v_1)} ||\\mathbf{D}^{(i)} -  \\mathbf{C}||^2_F$ encouraging the difference between the global item embedding $\\mathbf{C}$ and local item embedding $\\mathbf{D}^{(i)}$ from Eq. (3). We trained FedRAP-S five times on the ML-100K dataset and report the results in Table R1, where FedRAP-S shows a significant performance degradation compared to FedRAP. This degradation could be attributed to the absence of constraints between user-specific item information and globally shared item information in FedRAP-S. Without such constraints, the personalized model becomes overly individualized, leading to overfitting on user data and a decrease in generalization ability. Therefore, enforcing differentiation serves as a bridge between personalized and shared models and controls the complexity of the personalized component and preventing overfitting. This ensures a balance between personalization and generalization in the model.\n\nTable R1. Experimental results of FedRAP and FedRAP-S shown in percentages on the ML-100K dataset.\n|          |      HR@10     |     NDCG@10    |\n|----------|:--------------:|:--------------:|\n| FedRAP   | 97.09$\\pm$0.56 | 87.81$\\pm$2.00 |\n| FedRAP-S | 65.86$\\pm$1.34 | 39.99$\\pm$0.46 |\n\n\n## Q2 (Typo)\n\nIt should be \"FedRAP-No: Removes item sparsity constraint on C\" instead of \"diversity.\" This is indeed a typo. We appreciate your keen observation, and assure you that this error will be corrected in the future version of the paper.\n\n## Q3 (Explanation of Fig. 7)\n\nIn Fig. 7, the row-sparsity pattern in each user-personalized matrix, denoted as local item embedding  $\\mathbf{D}^{(i)}$, indicates non-zero elements corresponding to items the i-th user has interacted with. Conversely, all-zero rows signify items that the user has not accessed. To address this, global item embedding $\\mathbf{C}$ is introduced to incorporate global item information, allowing FedRAP to predict whether a user will interact with items they have not engaged with before. It's noted that optimizing the storage of $\\mathbf{D}^{(i)}$ can reduce client-side space cost. However, since FedRAP transmits only $\\mathbf{C}$ between the client and server, optimizing the storage of $\\mathbf{D}^{(i)}$ does not lead to a reduction in communication costs.\n\n\n## Q4 (Baseline Comparison)\n\nWe have evaluated the performances on the Movielens-100K (ML-100K) dataset, comparing FedMF, FedNCF, PFedRec, and FedRAP with and without Differential Privacy (DP). Due to space constraints in the main text, the detailed results of our experiments are provided in Appendix Sec. B.4, as illustrated in Tables 5 and 6. The results demonstrate that FedRAP maintains a performance advantage, even in the presence of privacy-preserving measures. These findings showcase the robustness and efficacy of FedRAP in privacy-preserving federated recommendation scenarios."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4245/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699840712822,
                "cdate": 1699840712822,
                "tmdate": 1699840712822,
                "mdate": 1699840712822,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]