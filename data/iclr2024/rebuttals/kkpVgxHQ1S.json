[
    {
        "title": "Latent Diffusion Counterfactual Explanations"
    },
    {
        "review": {
            "id": "gpbazw2BZ6",
            "forum": "kkpVgxHQ1S",
            "replyto": "kkpVgxHQ1S",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4986/Reviewer_nXBG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4986/Reviewer_nXBG"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a model-agnostic and computationally efficient diffusion model-based framework that can generate counterfactual explanations. Specifically, the model leverages the gradient of the classifier of a conditional diffusion model to filter out the gradient that is not semantically relavent or unimportant, which is natual and reasonable."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "(1) The problem that the paper aims to solve is significant anf appealing. \n(2) The proposed method that uses gradient of the classifier of a conditional diffusion model is straitforward and novel to me.\n(3) They showed good performance in the experimental section, indicating the effectiveness of the method."
                },
                "weaknesses": {
                    "value": "(1) It seems that the counterfactual explanation explained in the paper is very relavent to \"semantic consistency\" in [1]. I would suggest the author also discuss this paper.\n(2) How will the angular threshold affect the model performance? My concern is that if we mask too much then the model might loose too much information to reconstruct the image.\n\n[1] Li et al., Optimal Positive Generation via Latent Transformation for Contrastive Learning"
                },
                "questions": {
                    "value": "Please refer to my comments in \"Weakness\"."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698551758418,
            "cdate": 1698551758418,
            "tmdate": 1699636485959,
            "mdate": 1699636485959,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uUvba2XEP4",
                "forum": "kkpVgxHQ1S",
                "replyto": "gpbazw2BZ6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Review of Submission4986 by Reviewer nXBG"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive review. We are glad that the reviewer finds our method \u201cstraightforward and novel\u201d and acknowledges that it \u201cshowed good performance\u201d. Below we address the remaining concerns.\n\n### Related work\n\nWe are grateful that you brought this work [1] to our attention. We have included it in the updated manuscript. We would briefly mention the similarities as well as differences to our work for sake of completeness. Similar to our work, they also generate images from a latent space of a generative model that remain close to the original image. However, their focus is on obtaining positives for contrastive learning that maintain the semantics (i.e., class). In contrast, our work aims to understand which input features affect the classification of a classifier, thereby we also allow for (and promote) semantic changes.\n\n### Impact of the angular threshold\n\nThe angular threshold controls how much the gradients of the classifier are allowed to deviate from the implicit classifier without being considered adversarial. In the case of large masking (i.e., small angular threshold) this would often remove such gradients and replace them with some overwrite value (in our experiments zeros). Thus, we would have little to no guidance from the classifier. Consequently, our method would only receive guidance from the distance gradients and thereby reconstruct the original image. On the other hand, in case of a large angular threshold, our guidance mechanism will bypass adversarial changes that will flip the decision of the classifier without a semantic change in the counterfactual image. \n\n---\n\n[1] Li, Yinqi, et al. \"Optimal Positive Generation via Latent Transformation for Contrastive Learning.\" NeurIPS 2022."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699983624705,
                "cdate": 1699983624705,
                "tmdate": 1699983624705,
                "mdate": 1699983624705,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wXDpg7eomo",
            "forum": "kkpVgxHQ1S",
            "replyto": "kkpVgxHQ1S",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4986/Reviewer_LUsN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4986/Reviewer_LUsN"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces the Latent diffusion counterfactual explanation which uses latent diffusion models to expedite counterfactual generation and focus on the important semantic parts of the data. They propose a novel consensus guidance mechanism to filter out noisy,\nadversarial gradients that are misaligned with the diffusion model\u2019s implicit classifier."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper proposes a novel approach using class or text foundational diffusion models to generate counterfactual explanations that are both model and dataset-agnostic. The consensus guidance mechanism seems interesting and novel."
                },
                "weaknesses": {
                    "value": "The paper presents a comprehensive study focused on images, but it appears that experiments on tabular datasets are missing. Tabular data is frequently encountered in various applications such as finance, healthcare, and retail, where counterfactual explanations are of significant interest (i.e., loan approval dataset).  Would your proposed method extend to these settings?\n\nThe paper indicated that their method expedites the counterfactual generation process in the main paper however they claim it is slow in the limitations section."
                },
                "questions": {
                    "value": "Address the question last section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698720454647,
            "cdate": 1698720454647,
            "tmdate": 1699636485848,
            "mdate": 1699636485848,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "EBjVNTcQxj",
                "forum": "kkpVgxHQ1S",
                "replyto": "wXDpg7eomo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Review of Submission4986 by Reviewer LUsN"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the constructive review. We are glad that the reviewer finds our consensus guidance mechanism \u201cinteresting and novel\u201d. Below we address the remaining concerns.\n\n### Does our method extend to tabular data?\n\nWe note that the focus of our paper lies in visual counterfactual explanations, similar to previous works, e.g., [1,2]. Thus, we hope that the reviewer understands that generating counterfactuals for tabular data would be out-of-scope for the present work but may be a valuable future direction.\n\nDespite this, we still would like to outline how our approach could be used for tabular data in future works. First, one would need to train a diffusion model, such as TabDDPM [3], on some tabular dataset, such as adult or churn2. Second, we would need to adjust the backward diffusion process, i.e., adopt the consensus guidance mechanism, and can then generate counterfactuals for tabular data.\n\n### Speed-ups of our method\n\nOur method indeed significantly speeds-up counterfactual generation *compared to previous work* (see the penultimate paragraph in Section 4.2). However, the counterfactual generation process *cannot be considered fast overall*, as mentioned in our limitations section. Thus, it is a meaningful direction to further speed it up. One possible direction could be to distill the classifier behavior into the diffusion model. This effectively avoids the computationally-intensive computation of gradients at every iteration step and could significantly expedite counterfactual generation. \n\nComplementary to aforementioned, another benefit of our method is its seamless integration with diffusion models, ensuring that any advancement in speed in the recently very active research field of (text-conditional foundation) diffusion models, e.g., stable diffusion, would directly echo in speed-ups for our method. In a similar vein, our method benefits from improved generative capabilities of such diffusion models.\n\n--- \n\n[1] Goyal, Yash, et al. \"Counterfactual visual explanations.\" ICML 2019.\n\n[2] Augustin, Maximilian, et al. \"Diffusion visual counterfactual explanations.\" NeurIPS 2022.\n\n[3] Kotelnikov, Akim, et al. \"Tabddpm: Modelling tabular data with diffusion models.\" ICML 2023."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699983655278,
                "cdate": 1699983655278,
                "tmdate": 1699983655278,
                "mdate": 1699983655278,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mDBTOvdRYH",
                "forum": "kkpVgxHQ1S",
                "replyto": "EBjVNTcQxj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4986/Reviewer_LUsN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4986/Reviewer_LUsN"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarification on the tabular dataset and the speed of your method. I will keep my score on the accept side."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700717699720,
                "cdate": 1700717699720,
                "tmdate": 1700717699720,
                "mdate": 1700717699720,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Cx71KkaL3q",
            "forum": "kkpVgxHQ1S",
            "replyto": "kkpVgxHQ1S",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4986/Reviewer_wLyZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4986/Reviewer_wLyZ"
            ],
            "content": {
                "summary": {
                    "value": "Counterfactual explanation aims to find the realistic input data with the smallest semantically meaningful change that results in the counterfactual output.\nTo obtain such fake-but-counterfactually-realistic data, the authors utilized latent diffusion models and arbitrary classifier can be jointly adopted.\nThe authors argue that (1) the diffusion process in the latent space allows the proposed LDCE to focus on the important semantics of the data rather than the unimportant details; and (2) the proposed threshold-based consensus guidance mechanism against the implicit classifier can filter out meaningless adversarial gradients so that it enables capturing meaningful gradients for the counterfactual sample."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Strength\n\n- The proposed method is very simple and easy to apply.\n- The paper is easy to follow in general.\n- The proposed method can be utilized to any LDMs.\n- The implementation is properly provided for the reproducibility."
                },
                "weaknesses": {
                    "value": "Weakness\n\n- The paper should be written in more formal way.\n- There lacks explanation on Algorithm 1 in the main body of the paper, which makes it hard to understand the technical connection between the proposed method and algorithm.\n- Some generated counterfactual examples seem to be unrealistic. (Possibly, the threshold-based gradient filter cannot properly filter out the adversarial gradients?)\n- The authors argued that the proposed threshold-based consensus guidance mechanism filters out the meaningless adversarial gradients, but when it comes to Figure 4, it seems that those the consensus guidance mechanism cannot filter out those gradients. For example, in Figure 4(f), intervening \"bulldog\" to \"beagle\" should not affect the grass texture since it should not be sensitive to the breed of dogs. It seems that those factors are not perfectly disentangled in the latent or noise space.\n- Definitely, the proposed method is quantitatively outperformed in the CelebA case."
                },
                "questions": {
                    "value": "Question\n\nCould you provide more detailed explanation on Algorithm 1? How does it derived from Equation 10 and 11?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "none"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4986/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837350634,
            "cdate": 1698837350634,
            "tmdate": 1699636485778,
            "mdate": 1699636485778,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5Bj22mAxph",
                "forum": "kkpVgxHQ1S",
                "replyto": "Cx71KkaL3q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4986/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4986/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Re: Official Review of Submission4986 by Reviewer wLyZ"
                    },
                    "comment": {
                        "value": "We thank the reviewer for taking the time to review our paper and provide constructive criticisms. We are happy to see that the reviewer finds that our method is \u201cvery simple and easy to apply\u201d and that the paper is \u201ceasy to follow\u201d overall. Below we address remaining concerns or questions of the reviewer.\n\nWhile appreciating the valuable feedback by the reviewer, we feel that some of the scores, such as the contribution score of 1, may not be entirely reflected by the written feedback. For the sake of the discussion of our paper, we kindly ask for further clarification from the reviewer. We believe this will greatly contribute to the discussion of our paper.\n\n### Request for more formal writing\n\nWe would appreciate it if the reviewer could point out parts of the submission that should be improved w.r.t. their formality.\n\n### Added explanation to Algorithm 1\n\nAs suggested by the reviewer, we added a brief explanation of Algorithm 1 in the main body.\n\n### Some unrealistic counterfactual examples (e.g., Fig. 4(f))\n\nWe agree that the generated counterfactual examples, e.g., Fig. 4(f), are not perfect. However, note that they are better than the ones from previous works, e.g., Fig. 3(h), where the problem of smoothing of high-frequency details is also prevalent. The deficiency in preserving high-frequency details in LDCE also stems from the application of the counterfactual generation within the lower-dimensional latent space. Here, the autoencoder\u2019s decoder just fills in the high-frequency details. Thus, a better decoder, such as OpenAI\u2019s recent consistency decoder [1], may do a better job filling in these fine details. Besides aforementioned, note that, as can be observed in Fig. 3(h), that changes in grass texture may also indicate a model bias, which may be desirable in the context of counterfactual generation.\n\n### Discussion on Celeb-A HQ results\n\nThe experiments on Celeb-A HQ demonstrate that our method, LDCE, is competitive to methods that are *specifically tailored* for this dataset, i.e., they use generative models pretrained on Celeb-A HQ. In fact, our method typically achieves the first or second rank on most metrics (Table 6) and is only inferior to ACE on Celeb-A HQ.\n\nHowever, we find that LDCE is clearly superior to ACE on the more challenging ImageNet dataset (Table 2) at the same time. Arguably, \u201cImageNet is extremely complex and the classifier needs multiple factors for the decision-making process\u201d [1, p.5] as argued by the authors of ACE. Note that this comparison is an apples-to-apples comparison of the methods, as LDCE-cls also uses a diffusion model that has been trained on ImageNet. It is worth noting that LDCE-txt, which uses stable diffusion as a diffusion model, is also superior to ACE.\n\nHenceforth, we posit that the diminished performance observed on the domain-specific facial data from CelebA HQ can be attributed to the characteristics of the underlying diffusion model used in a specific counterfactual method. In fact, stable diffusion is renowned for its challenges in accurately generating faces and individuals [2]; a point openly acknowledged in both our limitations section and Appendix K. Nonetheless, the inherent merit of employing a non-domain-specific generative model - which has not been done before for counterfactual generation with generative models to the best of our knowledge - lies in its versatility, rendering it applicable across diverse datasets (as demonstrated on CelebA HQ). This flexibility becomes particularly valuable in real-world scenarios, where constraints on data accessibility are prevalent or pose significant challenges.\n\nThough, if one has access to domain data, it is definitely beneficial to utilize it. To adapt our method, one could use low-rank adaptation that finetunes an existing stable diffusion model without the need of extensive computational resources. We expect that this will improve performance also on domain-specific data distributions, such as Celeb-A HQ.\n\n--- \n\n[1] https://github.com/openai/consistencydecoder \n\n[2] Jeanneret, Guillaume, Lo\u00efc Simon, and Fr\u00e9d\u00e9ric Jurie. \"Adversarial Counterfactual Visual Explanations.\" CVPR 2023.\n\n[3] https://huggingface.co/stabilityai/stable-diffusion-2"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4986/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699983717084,
                "cdate": 1699983717084,
                "tmdate": 1700032852532,
                "mdate": 1700032852532,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]