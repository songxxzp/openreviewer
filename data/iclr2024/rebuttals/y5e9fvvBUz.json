[
    {
        "title": "PRISM: Privacy-Preserving Improved Stochastic Masking For Federated Generative Models"
    },
    {
        "review": {
            "id": "NylCIkPhUQ",
            "forum": "y5e9fvvBUz",
            "replyto": "y5e9fvvBUz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a certain binary masking technique for distributed training of generative models. Instead of communicating the model weights, only binary masks are communicated in a stochastic manner. Using the lottery ticket hypothesis, and by combining the masks, aggregator can obtain an efficient generative model."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The paper seems well written and is easy to read.\n\n- The idea of sending only the masks seems interesting. As far as I see, this paper considers a distributed version of the methods proposed by Isak et al. (2022) and Li et al. (2021a)."
                },
                "weaknesses": {
                    "value": "One clear deficit of the paper is that DP aspects of the method are not discussed although DP is heavily emphasised in the title, abstract and intro (\"privacy-preserving\" in the title, differential privacy explicitly mentioned elsewhere). I can see DP discussed only in those seven lines of Section 3.2.\n\nThere is no DP analysis for the method and no $\\varepsilon$'s or $\\delta$'s are reported in the experimental results.\n\nIf I understand the method correctly, the masks would indeed depend on the data, so the $\\varepsilon$ is definitely not $0$."
                },
                "questions": {
                    "value": "- How would you prove the differential privacy guarantees for the proposed method?\n\n- What would be the DP guarantees for the experimental results that you provide?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698745229938,
            "cdate": 1698745229938,
            "tmdate": 1699636242716,
            "mdate": 1699636242716,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vNXZooTvZt",
                "forum": "y5e9fvvBUz",
                "replyto": "NylCIkPhUQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[Response 1/1] Thank for your constructive feedbacks!"
                    },
                    "comment": {
                        "value": "**R5-1. Differential privacy**\n\nPlease see GC1."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700357840456,
                "cdate": 1700357840456,
                "tmdate": 1700357840456,
                "mdate": 1700357840456,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gJzrG79WlH",
                "forum": "y5e9fvvBUz",
                "replyto": "vNXZooTvZt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
                ],
                "content": {
                    "comment": {
                        "value": "I think the epsilon-value 50 is very large and not really in line with what is commonly used.\n\nThis makes me wonder whether DP is suitable for this method:\n\n> Since PRISM assumes that the model size is large enough (due to SLT), we focus on communication efficiency rather than privacy amplification due to bernoulli sampling."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502635688,
                "cdate": 1700502635688,
                "tmdate": 1700502635688,
                "mdate": 1700502635688,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yANMZwED3u",
                "forum": "y5e9fvvBUz",
                "replyto": "6y8bKKcdzd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the reply. I still cannot really follow the privacy analysis, to me it seems there are only the R\u00e9nyi DP parameters of the Bernoulli sampling used. In the RDP analysis, the Gaussian mechanism RDP parameters do not seem to show up. If those are not needed, then why would one perturb that $\\theta$-vector."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689805828,
                "cdate": 1700689805828,
                "tmdate": 1700689805828,
                "mdate": 1700689805828,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "otEieVKoRP",
                "forum": "y5e9fvvBUz",
                "replyto": "yANMZwED3u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
                ],
                "content": {
                    "comment": {
                        "value": "Ps. the paper seems to be currently way over 9 pages."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700690021066,
                "cdate": 1700690021066,
                "tmdate": 1700690021066,
                "mdate": 1700690021066,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "GbHMeRIYph",
                "forum": "y5e9fvvBUz",
                "replyto": "NylCIkPhUQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xZ6u:"
                    },
                    "comment": {
                        "value": "Thanks for providing valuable feedbacks and various concerns that arise in our work.\n\nAs can be seen from Appendix A of our manuscript, after clipping the noise-injected $\\theta$, the privacy budget we have becomes $\\epsilon_{amp}\\leq min\\{\\epsilon, d\\gamma_{\\alpha}(c)\\}$. Here, during the noise injection process, the variance $\\sigma^2$ of the Gaussian noise should become a function of $\\epsilon$, which controls the level of privacy we guarantee. Overall, the perturbing $\\theta$ is necessary to guarantee a certain level of privacy.\nRegarding the privacy amplification, our intention was to theoretically show that the privacy bound can become tighter (or at least does not compromise the bound) by taking advantage of Bernoulli sampling. Depending on various parameters and the model size, it may or may not be amplified, but the key point here is that since we have applied $(\\epsilon, \\delta)$-dp to $\\theta$, there is no case that the privacy bound falls below $\\epsilon$."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718596611,
                "cdate": 1700718596611,
                "tmdate": 1700728285750,
                "mdate": 1700728285750,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vjNEqTpW0B",
                "forum": "y5e9fvvBUz",
                "replyto": "NylCIkPhUQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_xZ6u"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the reply. This is the so-called post-processing property of DP: no matter what data-independent function you apply on the DP output (stochastic or not), the epsilons will not increase (they can decrease though). Thus your privacy guarantees will not get worse with the Bernoulli sampling procedure. But I can imagine that the Bernoulli sampling part could even amplify the privacy guarantees. But that should be then shown mathematically, how much amplification happens. And in case you are not actually using the amplification, as I understand, that should also be clearly stated and also the used privacy bounds should be clearly stated (if they are, e.g., the RDP-bounds of the Gaussian mechanism)."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727373278,
                "cdate": 1700727373278,
                "tmdate": 1700727415335,
                "mdate": 1700727415335,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DtNicJh61w",
            "forum": "y5e9fvvBUz",
            "replyto": "y5e9fvvBUz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_a69J"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_a69J"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes combining the edge-popup algorithm, initially proposed for learning subnetworks in randomly initialized networks, with the problem of training generative models in the federated setting.  During each FL round, clients send a binary mask sampled from the weight scores, instead of the scores themselves, which can save on communication cost. The final learned mask can be applied on the randomly initialized model to obtain an efficient model for inference, since weights are initialized (and kept frozen) from {-sigma, sigma}."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The paper tackles an important subject: efficient and private federated training of generative models\n- The paper is well presented, and cites the relevant literature\n- The proposed method is simple, and the experimental results back the authors' claims\n- The authors experiment with wide variety of datasets, and compare with multiple baselines"
                },
                "weaknesses": {
                    "value": "My main issue with this paper is the lack of novelty. It is a direct application of two previous works: \n- Sparse Random Networks for Communication-Efficient Federated Learning (https://arxiv.org/pdf/2209.15328.pdf), which applies the exact same masking and sampling scheme proposed in this paper, in a federated setting, for classification tasks, even the privacy preserving aspect of the proposed paper is inherited from this paper, as mention in S4.3\n- Can We Find Strong Lottery Tickets in Generative Models? (https://arxiv.org/pdf/2212.08311.pdf), which applies the same subnetwork strategy (edge-pop) for training GANs, and proposes to use the MDD loss for stable training\n\nThis paper just simply combines the two methods to get an FL subnetwork method for generative models, and offers no extra insight beyond those two works in my opinion. It is unfortunately below the acceptance threshold for ICLR, which is why I do not recommend acceptance.\n\n\n\n\nMisc:\n- In Sec 3.1, the edge-pop algorithm was proposed in (https://arxiv.org/pdf/1911.13299v2.pdf), and not in (https://arxiv.org/pdf/1803.03635.pdf)\n- In Tables 1 and 2, PRISM-alpha entries should be directly replaced with the alpha value, since it is fixed, e.g. PRISM-100 and PRISM-70. It is very confusing otherwise.\n- it appears that GANs are growing slightly out of fashion in the generative AI community, which slightly affects the significance of this work."
                },
                "questions": {
                    "value": "- Did the authors experiment with other losses, to further showcase the strength of MDD? It would provide more insight to the results of Tables 1 and 2 if the authors applied the same losses form other methods with their subnetwork strategy. This way one can better understand where the performance improvements are coming from.\n\n- In Tables 1 and 2, what does it mean when an algorithm is private vs. non-private? this seems very reductive and grossly simplifies the notion of privacy. It would be better to quantify it and report that instead. For instance, the hybrid method PRISM-alpha remains \"private\" for all alpha <100, and suddenly becomes non-private when alpha=100?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801326381,
            "cdate": 1698801326381,
            "tmdate": 1699636242647,
            "mdate": 1699636242647,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NHLTS1qCQV",
                "forum": "y5e9fvvBUz",
                "replyto": "DtNicJh61w",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[Response 1/1] Thank for your constructive feedbacks!"
                    },
                    "comment": {
                        "value": "**R4-1. Experiment with other losses.**\n\nPlease see GC1 and R1-1.\nWe want to clarify the distinction between our approach and baselines. Baselines typically  train the weights using GAN loss, while PRISM employs the MMD loss to find the SLT within the dense network. If an SLT is introduced into a baselines method, it essentially becomes PRISM. In that case, there is a potential question to consider whether strong performance emerges when GAN loss is applied to PRISM. To handle this curiosity, we conducted an experiment which utilizes GAN loss as score function for SLT, not MMD loss. In order to learn the generator by GAN loss instead of MMD loss, each client learns the discriminator and generator adversarially. After the local training is completed, the server aggregates and returns only the generator. As seen in Figure.10, the unstable GAN loss fails to find the SLT and proceed the FL normally, which implies that MMD loss is suitable for decentralized setting and SLT.\n\n**R4-2. Differential privacy**\n\nPlease see GC1.\n\n**R4-3. Limited novelty**\n\nPlease see GC2.\n\n**R4-4. GAN is out of fashion**\n\n The tackiness of GAN is discussed in GC1, GC2. Additionally, the reviewer\u2019s question seems to be intended for DDPM, which has recently shown strong performance. Although we have been empirically confirmed that SLT works successfully, there are still several limitations such as slow convergence. \nWe would like to clarify that PRISM uses MMD loss, while the baselines employ GANs. As you mentioned, it\u2019s true that the popularity of GANs has declined with the emergence of diffusion models, but GANs still offer valid advantages such as simplicity and fast inference times [1]. While it\u2019s possible to apply diffusion models to FL setups, the introduction is not straightforward in FL, where communication efficiency becomes a bottleneck. This is because diffusion models require substantial computational resources and slow convergence due to the iterative learning. Importantly, there should be discussions considering various ways in the field of FL for generative models.\n\n**R4-5. Other minor comments in Misc.**\n\nCorrected.\n\n[1] Kang, Minguk, et al. \"Scaling up gans for text-to-image synthesis.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700357787997,
                "cdate": 1700357787997,
                "tmdate": 1700357787997,
                "mdate": 1700357787997,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3e5R65wej6",
            "forum": "y5e9fvvBUz",
            "replyto": "y5e9fvvBUz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_sDDa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_sDDa"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new federated framework tailored for generative models named PRISM, which emphasizes not only strong and stable performance but also resource efficiency and privacy preservation. Experimental results on MNIST, CelebA, and CIFAR10 demonstrate that PRISM outperforms the previous methods in both IID and non-IID cases, all while preserving privacy at the lowest communication cost."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The investigated problem is novel, which addresses the challenges on communication efficiency, privacy, and performance instability altogether for federated generative models.\n\n2. PRISM exhibits robust performance even in non-IID FL settings, unlike traditional GAN-based approaches."
                },
                "weaknesses": {
                    "value": "1. The existing methods have not been comprehensively analyzed for their challenges.  For example, the proposed PRISM is designed with the objective of surpassing existing methods in terms of stable performance, resource efficiency, and privacy preservation. However, the introduction lacks an analysis of the challenges related to privacy preservation in existing works.\n\n2. Is this approach outperforming compared to traditional FL? On one hand, can PRISM attain equivalent efficiency to traditional FL, which directly uploads local parameters? On the other hand, when we consider the attack of inferring the client's local dataset, can PRISM provide robust protection against such attacks? We look forward to the authors conducting relevant experiments to address the questions.\n\n3. How can DP guarantee privacy in generative models? Any proofs? \n\n4. The comparison experiments in the study may not reflect the state-of-the-art, and we anticipate that PRISM will be compared with more advanced methods. For example, whether PRISM's model performance surpasses that of Multi-FLGAN."
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698808926920,
            "cdate": 1698808926920,
            "tmdate": 1699636242573,
            "mdate": 1699636242573,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WN0ijPJXjB",
                "forum": "y5e9fvvBUz",
                "replyto": "3e5R65wej6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[Response 1/1] Thank for your constructive feedbacks!"
                    },
                    "comment": {
                        "value": "**R3-1. Differential privacy**\n\nPlease see GC1.\n\n**R3-2. Comparison to traditional FL**\n\nSince PRISM uploads binary masks instead of float-type weights, PRISM can save communication costs up to 32 times compared to traditional FL. The comparison of efficiency between PRISM and traditional FL can be found in Table.1,2, and 3.\nOn the aspect of security, particularly against attacks aiming to infer clients' local datasets, PRISM offers robust protection. This security is primarily attributed to three factors. First, even if an attacker hijacks the mask used in PRISM, without knowledge of the client's architecture, the information gleaned is effectively meaningless. Second, even if the attacker is aware of the architecture, the lack of precise information about the random initialization renders any attempt to decode the client's data futile. Third, PRISM incorporates differential privacy (DP) techniques. It is well known that DP can prevent various attacks in decentralized environments. For more details on DP, please see GC1 and R3-3. \n\n**R3-3. DP in generative model**\n\nDifferential privacy is an algorithm designed to reduce the influence of single elements on output. Let\u2019s suppose M is a mechanism that we want to guarantee privacy, such as neural network. With adjacent datasets D, D\u2019, M is $(\\epsilon, \\delta)$-differential privacy when $P(M(D)) \\leq e^{\\epsilon}P(M(D\u2019)) + \\delta$ is satisfied. Also, by composability, if all components of M satisfy DP, M itself also satisfies DP. Since generative model is a stacked layer, DP guarantees privacy in generative models.\n\n**R3-4. Comparison with SOTA (e.g., Multi-FLGAN).**\n\nMulti-FLGAN introduces multi-GAN, competing X generators and Y discriminators to select the best-performing generator. Consequently, there exist X*Y sync servers. While Multi-FLGAN achieves excellent performance and stability, it demands a substantial amount of computation resources. According to the paper, authors used four V100 GPUs for experiments on MNIST and FMNIST. However, we agree that comparing PRISM with SOTA models can enhance the contribution of PRISM. We will apply differential privacy to Multi-FLGAN and update the results when experiments are completed.\n\n**(updated)**\n\nAs we discussed above, Multi-FLGAN employs a complex architecture involving multiple generators and discriminators ($X\\times Y$ of each per client), with the server aggregating $N\\times X\\times Y$ models, where $N$ is the number of clients. Our comparison between PRISM and Multi-FLGAN[1] involved a scaled-down Multi-FLGAN setup ($X=2, Y=2$) due to its high resource demands.  \nThe table below details our findings, comparing the standard Multi-FLGAN (default setup introduced in the original paper) and an modified version, Multi-FLGAN+DP version, which incorporates differential privacy ($(\\epsilon, \\delta)=(9.8, 10^{-5})$) for a fair comparison to PRISM and other baseline models. We observed significant performance degradation in Multi-FLGAN when applying DP, likely due to its complex framework involving both generators and discriminators. \nThis raises to two key concerns: \nDP suitability: The complex framework of Multi-FLGAN limits its effectiveness when DP is applied, suggesting that the framework may not be ideally suited for privacy-preserving FL scenarios. \nResource and Communication Overheads: The architecture demands extensive training resources and incurs high communication overhead, posing challenges for practical deployment, especially in resource-constrained environments. \n\n\n|        MNIST              |   Privacy     |      FID      |      P&R                  |      D&C                 |     Cost     |\n|:---------------------------:|:----------------:|:---------------:|:--------------------------:|:-------------------------:|:---------------:|\n|  Multi-FLGAN          |        X        |   44.97      |   0.1461 / 0.3248   |   0.0461 / 0.0868   |    52MB    |          \n|  Multi-FLGAN + DP |        O        |  323.721   |         0.0 / 0.0         |         0.0 / 0.0         |    52MB    |\n|  PRISM                    |        O        |  59.4503   |   0.2594 / 0.3884   |   0.0832 / 0.0852   |   5.75MB  |\n\n[1] Amalan, Akash, et al. \"MULTI-FLGANs: Multi-Distributed Adversarial Networks for Non-IID distribution.\" arXiv preprint arXiv:2206.12178 (2022)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700357723524,
                "cdate": 1700357723524,
                "tmdate": 1700643634657,
                "mdate": 1700643634657,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "a4gcZ86Ezg",
                "forum": "y5e9fvvBUz",
                "replyto": "WN0ijPJXjB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_sDDa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_sDDa"
                ],
                "content": {
                    "title": {
                        "value": "Reply to the Authors' Response"
                    },
                    "comment": {
                        "value": "Thanks for your response! I am still willing to see the comparison results. Also, as pointed out by Reviewer xZ6u, epsilon=50 seems pretty large, making me doubt the practicality."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700536952983,
                "cdate": 1700536952983,
                "tmdate": 1700536952983,
                "mdate": 1700536952983,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wrh0eAHnEt",
                "forum": "y5e9fvvBUz",
                "replyto": "3e5R65wej6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response for R3-4 is updated"
                    },
                    "comment": {
                        "value": "Our response about the comparisons with other SOTA (e.g., Multi-FLGAN) is updated in R3-4."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700643763109,
                "cdate": 1700643763109,
                "tmdate": 1700656076859,
                "mdate": 1700656076859,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "prxAthH82B",
            "forum": "y5e9fvvBUz",
            "replyto": "y5e9fvvBUz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_pni9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_pni9"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a sparse training method in federated learning with generative models -- where the goal is to find a binary mask to sparsify the randomly initialized model without training the parameters by borrowing the methodology in [1]. This approach reduces the communication cost, improves storage and inference efficiency, and amplifies privacy when there is a differential privacy mechanism attached to the framework.\n\n[1] Isik, Berivan, et al. \"Sparse Random Networks for Communication-Efficient Federated Learning.\" The Eleventh International Conference on Learning Representations. 2022."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper successfully adapts the FedPM framework in [1] to generative models and obtains promising empirical results. \n\nThe language and the diagrams are clear. \n\n[1] Isik, Berivan, et al. \"Sparse Random Networks for Communication-Efficient Federated Learning.\" The Eleventh International Conference on Learning Representations. 2022."
                },
                "weaknesses": {
                    "value": "- The paper borrows almost all the main ideas from [1]. The only noticeable difference seems to be applying FedPM in [1] to generative models other than classifiers. So, I would expect the authors to highlight this properly and give credit to [1]. Right now, [1] is listed in the related work section very briefly as if there is not much similarity between the two works while the framework is exactly the same.\n\n- Also, I am not sure if there is a need to give the framework in the current paper a new name, PRISM, given that it's actually the same as FedPM but just with a different model/objective?\n\n- I am not sure how the privacy claims follow. The paper cites [1] and [2] for the statement that PRISM (or FedPM) should amplify privacy -- which is correct. But PRISM (or FedPM) alone is not sufficient to have any differential privacy guarantee. They can only amplify privacy when there is an explicit differential privacy mechanism somewhere in the framework. In the experiments section, specifically in Table 1 and Figure 3, both PRISM and PRISM-$\\alpha$ are put in the \"with privacy\" category. Can the authors explain what their privacy mechanism actually is? And how much does the Bernoulli sampling process amplify this privacy? \n\n\n[1] Isik, Berivan, et al. \"Sparse Random Networks for Communication-Efficient Federated Learning.\" The Eleventh International Conference on Learning Representations. 2022.\n\n[2] Imola, Jacob, and Kamalika Chaudhuri. \"Privacy amplification via bernoulli sampling.\" arXiv preprint arXiv:2105.10594 (2021)."
                },
                "questions": {
                    "value": "- Since the proposed method is the same as FedPM [1], it should be mentioned clearly in the revised version.\n\n- What is the reason the authors renamed FedPM as PRISM given that they are the same?\n\n- Where does the differential privacy guarantee come from given that Bernoulli sampling only amplifies privacy but does not introduce any privacy guarantee alone?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817415745,
            "cdate": 1698817415745,
            "tmdate": 1699636242464,
            "mdate": 1699636242464,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BWWm1WqRpX",
                "forum": "y5e9fvvBUz",
                "replyto": "prxAthH82B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[Response 1/1] Thank for your constructive feedbacks!"
                    },
                    "comment": {
                        "value": "**R2-1. Highlight and give credit to FedPM**\n\nAs the reviewer suggested, we will more clearly outline the relationship between our research and prior works, including FedPM. \n\n**R2-2. Limited novelty. Why rename FedPM as PRISM?**\n\nRegarding the perceived limited novelty and the renaming of FedPM to PRISM, please see GC2 for a detailed explanation. \n\nAs outlined in GC2, our domain faces a significant gap in research that attempts to consider both privacy and communication efficiency simultaneously. This gap, particularly in the context of various losses and frameworks for GANs, results in existing methods underperforming. Our approach addresses this by integrating the MMD loss, which aids in the stable identification of SLT. We also incorporated elements from the decoder structure to improve performance without significantly increasing communication costs. Given these enhancements, we decided to name our method PRISM to reflect its distinctiveness and advancements. Nonetheless, in our revised submission, we will make sure to clarify the evolution from FedPM to PRISM, enabling readers to clearly understand the continuity and progression of ideas. \n\n**R2-3. Differential privacy**\n\nPlease see  GC1."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700357646713,
                "cdate": 1700357646713,
                "tmdate": 1700357646713,
                "mdate": 1700357646713,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bJlr4TpMS2",
                "forum": "y5e9fvvBUz",
                "replyto": "prxAthH82B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_pni9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_pni9"
                ],
                "content": {
                    "title": {
                        "value": "response"
                    },
                    "comment": {
                        "value": "I thank the authors for the rebuttal. The privacy experiments seem rather limited since the privacy cost $\\epsilon=50$ is too high. Also, it's not clear how the privacy amplification is used here without knowing the Renyi privacy parameter $\\alpha$ since there is no amplification if $d \\gamma_{\\alpha}(c) > \\epsilon$.\n\nI appreciate the authors' efforts in extending FedPM framework to generative models. I believe this could be seen as an important contribution when it's presented in a different way by giving enough credit to the original work and highlighting the necessary modifications."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700700442903,
                "cdate": 1700700442903,
                "tmdate": 1700700509569,
                "mdate": 1700700509569,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "z4Gdg1cokf",
                "forum": "y5e9fvvBUz",
                "replyto": "prxAthH82B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Review pni9:"
                    },
                    "comment": {
                        "value": "Thank you for your insights and constructive opinions. Your efforts have been a great help in developing our work! \n\nConcerning privacy amplification, we aim to theoretically demonstrate that the privacy bound can be strengthened (or, at the least, remains uncompromised) through the utilization of bernoulli sampling. The degree of amplification may vary depending on different parameters and the model size. However, the crucial aspect is that, given the application of $(\\epsilon, \\delta)$-dp to $\\theta$, there is no scenario where the privacy bound descends below $\\epsilon$."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700718632475,
                "cdate": 1700718632475,
                "tmdate": 1700721620370,
                "mdate": 1700721620370,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zX53ZYNSBV",
            "forum": "y5e9fvvBUz",
            "replyto": "y5e9fvvBUz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_N7hx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2982/Reviewer_N7hx"
            ],
            "content": {
                "summary": {
                    "value": "Motivated by federated generative models and privacy requirements, this paper proposes a new federated learning scheme. Instead of updating model weights, the authors update a score function for a randomly initialized generator and solely communicate random binary masks. The masks are later used to generate a sub-network for the task. Notably, the network is not trained at all. With the learning scheme, the authors claim it significantly saves communication costs while achieving superior performance in both differentially private (DP) and non-DP settings."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem targeted in this paper is reasonable and practical.\n\n2. The paper is easy to follow.\n\n3. The experimental results are good, though many details are missing."
                },
                "weaknesses": {
                    "value": "1. The novelty is limited. The paper basically applies the prior work [1] in a federated generation setting. However, I did not notice any specialization toward federated learning/generation.\n\n2. Many details and experiments are missing, making it difficult to evaluate the contribution. \n    - What kind of architecture is used in the paper? \n    - Does the choice of architecture affect the performance?\n\n3. It is unclear how the random mask learning benefits from multiple-round federated learning. It seems to me that it is closer to the one-shot learning. The authors should expand this part and provide more insights.\n\n3. The experiments about differential privacy (DP) are either missing or incomplete. The two most critical parameters in DP, $\\varepsilon$ and $\\delta$, are missing in the paper. It is also unclear how to apply DP to the proposed method when generating masks. The experiments regarding DP are not meaningful without mentioning privacy budgets. I even doubt the comparison might be unfair.\n\n[1] Sangyeop Yeo, Yoojin Jang, Jy-yong Sohn, Dongyoon Han, and Jaejun Yoo. Can we find strong lottery tickets in generative models? In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pp. 3267\u20133275, 2023."
                },
                "questions": {
                    "value": "1. The performance in some experiments is somehow too surprisingly good to convince me. I am not fully convinced that a randomly initialized model without training can outperform a carefully designed and trained generative model. Let alone the score selection criterion is MMD, which is known to be suboptimal for image generation. Is it because of data partitioning? Could the authors elaborate more on this part?\n\nOverall, though the work is a straightforward application of the strong lottery ticket hypothesis, it still could be valuable to the community. However, the authors have to specify all the details, especially regarding the DP part. I am willing to reconsider my score after the discussion with other reviewers and the authors."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2982/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698840092724,
            "cdate": 1698840092724,
            "tmdate": 1699636242392,
            "mdate": 1699636242392,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3fq3cLoHik",
                "forum": "y5e9fvvBUz",
                "replyto": "zX53ZYNSBV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[Response 1/2] Thank you for constructive feedbacks!"
                    },
                    "comment": {
                        "value": "**R1-1. Why can SLT outperform a fully trained generative model? Why is MMD loss effective?**\n\nWe interpret your question as probing why the combination of SLT and MMD loss performs so well. We will divide the reviewer\u2019s question into three parts for clarity: \n\n(1) Effectiveness of SLT: Previous research has theoretically shown that in large, randomly initialized models, there often exists a 'strong lottery ticket'--- a subnetwork capable of matching or even surpassing the performance of the full model [1]. To illustrate, consider the analogy of the Library of Babel, where a vast repository of all possible combinations of text exists. In such a library, the probability of finding meaningful books is not negligible. Similarly, in a large enough model, strong and effective subnetworks are likely to exist. This intuitive analogy serves as a foundation for understanding the concept of SLT. Consequently, when such a strong lottery ticket is identified, it has the potential to provide a comparable or sometimes even better performance than fully trained GAN-based models. \n\nOf course, while the theoretical existence of SLTs is significant, the practical challenge lies in the methodology to locate these optimal subnetworks. This requires the careful development of a score function and algorithm tailored to the specific task at hand, which is a highly nontrivial endeavor. (Our contribution lies in this realm, developing a framework that effectively addresses the challenge of creating a federative generative model) Understanding this framework sets the stage to address the reviewer's next question: the effectiveness of MMD loss. \n\n(2) Effectiveness of MMD Loss: \nMMD loss functions by minimizing the mean distance between samples in the Reproducing Kernel Hilbert Space (RKHS). Theoretical evidence suggests that distributions are identical when their statistics in RKHS coincide [2][3]. In practice, this translates to each client computing the L2 distance from the global model to its RKHS statistics during local training, effectively measuring the MMD distance for global statistics. This statistical approach underlies MMD's superiority over traditional GAN-based methods when combined with SLT. This method, as analyzed in the context of WGANs, suggests that MMD, being a distance function, provides more stability in training compared to divergence-based methods like traditional GANs. \n\nThis stability is crucial in federated learning environments, where training can be erratic and unstable due to the inherent challenges such as heterogeneous data distributions across clients. The ability of MMD loss to consistently measure distances in RKHS contributes significantly to mitigating these challenges, thereby enhancing model performance and reliability. Thus, our model leverages the combination of SLTs and the stable training dynamics of MMD loss to achieve its notable performance.\n\n\n(3) Comparing GAN and MMD loss: GAN loss is known for its instability and requires extensive regularization and careful training management. To further confirm the advantage of using MMD loss in our setup, we have also explored the possibility of using the GAN loss to find SLT (Figure 10). Due to the inherent training instability of GAN loss, particularly in federated learning settings with data heterogeneity, this approach proved ineffective. Experiments using GAN loss instead of MMD in our PRISM framework resulted in collapsed images, emphasizing GAN loss's unsuitability for SLT in decentralized environments. Nevertheless, as you rightly pointed out, MMD does have limitations in handling large, complex datasets. Exploring alternative frameworks to overcome these challenges is an intriguing direction for future research. \n\n[1] Ramanujan, Vivek, et al. \"What's hidden in a randomly weighted neural network?.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\n[2] Gretton, Arthur, et al. \"A kernel two-sample test.\" The Journal of Machine Learning Research 13.1 (2012): 723-773.\n\n[3] Gretton, Arthur, et al. \"A kernel method for the two-sample-problem.\" Advances in neural information processing systems 19 (2006).\n\n**R1-2. Limited novelty**\nPlease see GC2. \n\n...\n\nPlease refer the remaining responses in the [Responses 2/2]."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700357400485,
                "cdate": 1700357400485,
                "tmdate": 1700357400485,
                "mdate": 1700357400485,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XpWqHYhmeL",
                "forum": "y5e9fvvBUz",
                "replyto": "zX53ZYNSBV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[Response 2/2] Thank you for constructive feedbacks!"
                    },
                    "comment": {
                        "value": "**R1-3. Which architecture is used? Does the choice matter?**\n\nWe have consistently utilized the ResNet-based generator for both our method and all baseline methods to ensure a fair comparison. Our detailed analysis, shown in Figure 4, compares performance while controlling for the number of parameters. The results demonstrate that PRISM outperforms the other baseline methods, even when matched for capacity and network structure. In addition, our method works generally well for different architectures. Basically, SLT just presumes that a dense network is sufficiently overparameterized to find a useful subnetwork. This implies that SLT has robustness with architecture. To validate our argument, we will evaluate architectures frequently used in generative models. When ongoing experiments are completed, we will update you.\n\n**(updated)**\n\nWe applied various generator architectures that have been studied in the field of generative models to the architecture of PRISM and compared their performance. Review can find the results in Table.8. We kept all settings, including DP, consistent with our framework. Our default configuration is a ResNet-based generator, and architectures such as DCGAN and SNGAN show robust performance on MNIST but exhibit a slight advantage depending on the architecture in CelebA. PRISM can somewhat follow the performance of the architecture since it extracts a subnetwork from the dense network. Still, it consistently finds a stable SLT for various structures.\n\n| MNIST     |   ResNet   |   DCGAN   |   SNGAN    |\n|:--------------:|:---------------:|:----------------:|:----------------:|\n|  FID         |   34.4595  |    36.9683  |   33.4447   |\n| Precision |   0.3784    |    0.3694    |   0.4652     |\n| Recall      |   0.4213    |    0.4848    |   0.3318     |\n| Density    |   0.1418    |    0.1323    |   0.2047     |\n| Coverage |   0.1588    |    0.1490   |   0.2019     |\n\n|  CelebA   |   ResNet   |   DCGAN   |   SNGAN    |\n|:--------------:|:---------------:|:----------------:|:----------------:|\n|  FID         |   51.0857  |    78.4130  |  38.3009  |\n| Precision |   0.5267    |    0.4540    |   0.6851     |\n| Recall      |   0.0631    |    0.0404    |   0.0925     |\n| Density    |   0.2676    |    0.1916    |   0.5378     |\n| Coverage |   0.2012    |    0.0947    |   0.3155     |\n\n\n**R1-4. How does random mask learning benefit from multiple-round federated learning?**\n\nWe interpret your question as probing why we opt for multiple-round learning rather than identifying a Strong Lottery Ticket (SLT) at each client side and then aggregating the final mask in a one-shot manner at the server.\n To answer this, we draw an analogy between each local dataset in our method and a mini-batch in traditional centralized SGD. In this comparison, one-shot aggregation is akin to optimizing with a very large step size. It is well-known in optimization theory that training with a large step size and few epochs can often lead to local minima. Coming back to the perspective of federated learning, by aggregating the scores (or binary masks) of each client through multiple rounds, our goal is to find the global lottery ticket that is not biased towards specific local dataset. To support our opinion, we conducted an experiment in which we performed single aggregation after overfitting MNIST dataset to 500 local iterations. The results can be found in Appendix.C. We observe that it fails to generate proper images.\n\n**R1-5. Differential privacy**\n\nPlease see GC1."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700357510784,
                "cdate": 1700357510784,
                "tmdate": 1700656355282,
                "mdate": 1700656355282,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pY0Ma3l52o",
                "forum": "y5e9fvvBUz",
                "replyto": "zX53ZYNSBV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_N7hx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2982/Reviewer_N7hx"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "I'd like to thank the authors for providing such an informative response. However, as noted by the authors and other reviewers, there are a lot of things to discuss and improve in the paper, such as the difference between prior work and PRISM, privacy analysis, experiments, and some design choices. I am particularly concerned about the privacy part. The authors originally seem to make a wrong statement about the privacy cost of masking ($\\varepsilon$ is larger than zero), and the corresponding experiments are also problematic (e.g.,  Table 2 still claims a privacy-preserving property for the proposed method). Even in the GC, the epsilon values seem not convincing. It may take some time to fix thoroughly.\n\nOverall, though I appreciate the interesting application, I'd lean to rejection concerning the current presentation."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2982/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700697631388,
                "cdate": 1700697631388,
                "tmdate": 1700697631388,
                "mdate": 1700697631388,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]