[
    {
        "title": "Unpaired Image-to-Image Translation via Neural Schr\u00f6dinger Bridge"
    },
    {
        "review": {
            "id": "UL7fA6GPsx",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4501/Reviewer_279L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4501/Reviewer_279L"
            ],
            "forum": "uQBW7ELXfO",
            "replyto": "uQBW7ELXfO",
            "content": {
                "summary": {
                    "value": "The paper presents Unpaired Neural Schr\u00f6dinger Bridge (UNSB), an innovative approach for unpaired image-to-image translation tasks, combining Schr\u00f6dinger Bridge model with adversarial training. It expands the applicability of diffusion models by overcoming the Gaussian prior assumption limitation, which typically restricts them in unpaired image-to-image translations.The experiment results signal the potential of the proposed approach in dealing with high dimensional datasets, commonly referred to as the \"curse of dimensionality.\" Experiments have shown the superiority of the proposed method where comparisons are conducted with their method and multiple baseline I2I methods on multiple I2I datasets. An ablation study is conducted with clear analyses."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1 The paper is aligned with recent advancements in stochastic generative modeling, image-to-image translations, and optimal transport, pushing the boundary of what's possible in these domains.\n\n2 The experimentation shows promising results in I2I tasks in terms of multiple metrics.\n\n3 The paper clearly explains the underlying mathematical conventions for Schr\u00f6dinger Bridge and UNSB models and their connection with stochastic differential equations.\n\n4 The authors have taken additional steps to ensure reproducibility of their work by providing code and detailed descriptions of hyperparameters in the paper."
                },
                "weaknesses": {
                    "value": "There are no significant weaknesses. It could be valuable to include the reverse translations (such as Zebra to Horse, Winter to Summer) in the supplementary material, providing more comprehensive experimental results."
                },
                "questions": {
                    "value": "See the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4501/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697121405274,
            "cdate": 1697121405274,
            "tmdate": 1699636426216,
            "mdate": 1699636426216,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jhFH5dzT7V",
                "forum": "uQBW7ELXfO",
                "replyto": "UL7fA6GPsx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer 279L"
                    },
                    "comment": {
                        "value": "We thank the Reviewer for the insightful review, which has been incorporated into the revised paper. We address the Reviewer's concern below.\n\n> **Q1 : It could be valuable to include the reverse translations (such as Zebra to Horse, Winter to Summer) in the supplementary material, providing more comprehensive experimental results.**\n\nWe kindly refer the Reviewer to Appendix C.5, where we provided an additional result on Zebra2Horse translation, and observed UNSB beats CycleGAN. We plan to include more results in the future."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700105657465,
                "cdate": 1700105657465,
                "tmdate": 1700105657465,
                "mdate": 1700105657465,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ttL7CiyrLH",
                "forum": "uQBW7ELXfO",
                "replyto": "UL7fA6GPsx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Reviewer_279L"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Reviewer_279L"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "The response adequately addressed my concerns, and I am inclined to keep my rating as 6."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700333264836,
                "cdate": 1700333264836,
                "tmdate": 1700333279585,
                "mdate": 1700333279585,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bSbYJlpTeT",
            "forum": "uQBW7ELXfO",
            "replyto": "uQBW7ELXfO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4501/Reviewer_PUqf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4501/Reviewer_PUqf"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a method leveraging Schr\u00f6dinger Bridge (SB) to bypass the limitation of applying Diffusion Models (which assume a Gaussian prior) to Image-to-Image (I2I) translation. Although previous approaches for utilizing SB to I2I translation have been explored, the proposed method, UNSB, is designed to be directly applied to I2I and scalable to high resolution images. The method is implemented as a composition of generators learned via adversarial learning that overcome the curse of dimensionality with advanced discriminators, showing success in several unpaired I2I translation tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The formulation of SB as a composition of generators learned via adversarial learning seems novel. Moreover, the ability to apply patch-level discriminators is crucial for data with diverse textures as the ones considered in the paper.\n2. The translation quality and faithfulness seem to be good.\n3. The paper is well written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. I think that some relevant baselines were not included in the experimental section. Could the author compare the proposed method to EGSDE [1] (Diffusion-based model)?\n\n[1] Zhao et al. EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations. In NeurIPS, 2022.\n\n2. The authors attribute the failure of SB for unpaired image-to-image translation to the curse of dimensionality. However, methods such as EGSDE and SDEdit do achieve successful translations in translating high resolution images. Could the authors elaborate on the difference between the cases?\n\n3. Following my previous point, the datasets considered in the paper are all of \u201cscene-level\" image to image translation (in which mostly color and texture need to be altered during translation). In most of other I2I translation works, many \"object-level\" datasets are evaluated e.g. CelebA-HQ Male-to-Female, Cat-to-dog, etc. Do the authors expect different performance for the latter case? I believe it would be helpful to include benchmarks for at least some of these additional datasets to understand the strengths and the limitations of the proposed method."
                },
                "questions": {
                    "value": "1. The description of the Stochasticity analysis (Fig. 7) is not clear to me. Could the author describe this ablation experiment and what does the generated map tell us? I understand that high pixel-wise std implies greater diversity, but why is it surprising that the std is greater for the foreground pixels? What is the scale of the std?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4501/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4501/Reviewer_PUqf",
                        "ICLR.cc/2024/Conference/Submission4501/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4501/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698511074295,
            "cdate": 1698511074295,
            "tmdate": 1700303550452,
            "mdate": 1700303550452,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "I4POVMlWKd",
                "forum": "uQBW7ELXfO",
                "replyto": "bSbYJlpTeT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer PUqf"
                    },
                    "comment": {
                        "value": "We thank the Reviewer for the insightful review, which has been incorporated into the revised paper. We address the Reviewer's concerns and questions below.\n\n> **Q1 : I think that some relevant baselines were not included in the experimental section. Could the author compare the proposed method to EGSDE [1] (Diffusion-based model)?**\n\nWe kindly refer the Reviewer to Appendix C.3, where we compared UNSB with EGSDE, StarGAN v2, and NOT on the Male2Female translation task, and observed UNSB beats all baselines.\n\n> **Q2 : The authors attribute the failure of SB for unpaired image-to-image translation to the curse of dimensionality. However, methods such as EGSDE and SDEdit do achieve successful translations in translating high resolution images. Could the authors elaborate on the difference between the cases?**\n\nWe kindly refer the Reviewer to Appendix D, where we added a discussion on the Reviewer\u2019s question.\n\n> **Q3 : Following my previous point, the datasets considered in the paper are all of \u201cscene-level\" image to image translation (in which mostly color and texture need to be altered during translation). In most of other I2I translation works, many \"object-level\" datasets are evaluated e.g. CelebA-HQ Male-to-Female, Cat-to-dog, etc. Do the authors expect different performance for the latter case? I believe it would be helpful to include benchmarks for at least some of these additional datasets to understand the strengths and the limitations of the proposed method.**\n\nWe kindly refer the Reviewer to Appendix C.3, where we performed an additional experiment on Male2Female, and observed good results for UNSB.\n\n> **Q4 : The description of the Stochasticity analysis (Fig. 7) is not clear to me. Could the author describe this ablation experiment and what does the generated map tell us? I understand that high pixel-wise std implies greater diversity, but why is it surprising that the std is greater for the foreground pixels? What is the scale of the std?**\n\nThe following discussion has been added to Appendix C.2.\n\nFig. 7 serves as evidence that UNSB indeed solves the SB problem. Specifically, a SB between two domains is stochastic, so it does one-to-many translation. Thus, a necessary condition for a model to be a SB is stochasticity. Fig. 7 shows that UNSB satisfies this necessary condition. \n\nGreater std for foreground pixels tells us UNSB does one-to-many generation, and generated images lie in the target domain. For instance, a model which simply adds Gaussian noise also does one-to-many generation, but is not meaningful. UNSB output shows high variation for locations which are relevant to the target domain (Zebra).\n\nMinimum and maximum values of pixel standard deviation in Figure 7 are 0.0031 and 0.7940, respectively. We note that all pixel values are normalized into [0,1]."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700105532972,
                "cdate": 1700105532972,
                "tmdate": 1700105532972,
                "mdate": 1700105532972,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KyV9iWvdlb",
                "forum": "uQBW7ELXfO",
                "replyto": "I4POVMlWKd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Reviewer_PUqf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Reviewer_PUqf"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their detailed response.\n\nI find the results from the additional experiments on Male2Female to exhibit lower perceptual quality compared to the baselines (EGSDE and StarGAN-v2) even though it is not reflected in the FID for some reason. Similar degradation in the generated quality appear in the other experiments as well (e.g. blurred blending between the foreground zebras and the background). However, it indeed seems that the structural layout is better preserved using the proposed method, which is an appreciated contribution. I believe that a better balance of this tradeoff can be further explored in future work.\n\nI have updated my score accordingly."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700303519822,
                "cdate": 1700303519822,
                "tmdate": 1700303519822,
                "mdate": 1700303519822,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1kS7igqarM",
            "forum": "uQBW7ELXfO",
            "replyto": "uQBW7ELXfO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4501/Reviewer_f3t2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4501/Reviewer_f3t2"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a method for unpaired image-to-image translation based on Schr\u00f6dinger bridge. The authors combine several ideas to obtain a practically-sounding method. At first, they propose to learn their model in a multistep manner, which is a natural and worth-considering given the recent success of diffusion models. Secondly, they propose to use the additional GAN loss to better match the target distribution. Additionally, the authors report the usefulness of the additional regularization applied at the training stage. Overall, the proposed approach demonstrates good practical results and has clear theoretical motivation.\n\n**Update**: My concerns seems to be addressed. I rise my score to 6"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is overall-well written. It has clear motivation (unpaired image-to-image translation via entropic optimal transport (or Schr\u00f6dinger bridge) problems. The idea of multistep approach, where the timeline of the Schr\u00f6dinger process is discretized into several steps and a practitioner learn a kind of \u201cdenoising\u201d model (an intuition from diffusion models) is fresh and worth to be considering. Moreover, it seems that the considering several steps indeed improves the qualitative performance, as shown by the practical experiments. The practical results are also encouraging."
                },
                "weaknesses": {
                    "value": "My concerns are covered in the questions section (see below). I expect the authors to address them."
                },
                "questions": {
                    "value": "- I have some doubts regarding the statement (end of page 1) that \u201cno work has successfully trained SBs for direct translation between high-res images\u201d and (end of page 2) \u201cour work represents the first endeavor on this problem\u201d. For example, [1], [2] deals with $64 \\times 64$ images and tackles unpaired image-to-image problems. I am not sure, if the methods from [1], [2] works with $256 \\times 256$, but, anyway, [1] and [2] should be covered as the related works and the competitive methods.\n- Regarding the competitive methods (GANs), the authors miss the StarGAN and StarGAN v2 [3]. The latter model demonstrates a good quality on the unpaired image2image and I think this model is a good baseline method. Please, add it to the comparison.\n- I have one concern about objective (14). The transition from constrained problem (9)-(10) to the combination of losses (14) is non-trivial and not fully theoretically justified. I am not sure, that the objective (14) indeed solves the SB problem. Some comments/clarifications will contribute to the clearness of the manuscript flow.\n- I ask the authors to add the clarifications how to estimate the entropy with samples, a technique introduced at the beginning of page 6. It will facilitate the comprehension and smoothness of the reading. \n- I strongly encourage the authors to evaluate how does their approach solve SB problem on a nontrivial setup beyond gaussian2gaussian case. In particular, there is a recent paper [4] which proposes benchmark pairs of distributions with known GT EOT/SB solutions, even for images data. The validation on such a benchmark will highly contribute to the quality of the paper and will probably answer the question (3).\n- I have one more question regarding the baseline methods. The authors choose the work [5] (called them as NOT) \u201cas the representative of OT [methods]\u201d. This choice really surprised me because [5] also deals with SB problem, and, as I understand, their method is not designed for image data (at least, the authors of [5] does not consider image data use cases). That is why comparing with [5] seems strange. I recommend authors take [6, 7, 8] as the representative of OT methods instead. These methods also has a possibility to generate the samples of controllable diversity, have GAN-resembling objective. Moreover, they are designed specifically for unpaired image2image problems.\n\n[1] Diffusion Schr\u00f6dinger Bridge Matching, NeurIPS\u20192023\n\n[2] Entropic Neural Optimal Transport via Diffusion Processes, NeurIPS\u20192023\n\n[3] StarGAN v2: Diverse Image Synthesis for Multiple Domains, CVPR\u20192020\n\n[4] Building the Bridge of Schr\u00f6dinger: A Continuous Entropic Optimal Transport Benchmark, NeurIPS\u20192023\n\n[5] Transport with support: Data-conditional diffusion bridges, arxiv\n\n[6] Neural Optimal Transport, ICLR\u20192023\n\n[7] Neural Monge Map estimation and its applications, TMLR\n\n[8] Kernel Neural Optimal Transport, ICLR\u20192023"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4501/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4501/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4501/Reviewer_f3t2"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4501/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698746178644,
            "cdate": 1698746178644,
            "tmdate": 1700726001619,
            "mdate": 1700726001619,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "A7kOrXN1bJ",
                "forum": "uQBW7ELXfO",
                "replyto": "1kS7igqarM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer f3t2"
                    },
                    "comment": {
                        "value": "We thank the Reviewer for the insightful review, which has been incorporated into the revised paper. We address the Reviewer's concerns and questions below.\n\n> **Q1 : I have some doubts regarding the statement (end of page 1) that \u201cno work has successfully trained SBs for direct translation between high-res images\u201d and (end of page 2) \u201cour work represents the first endeavor on this problem\u201d. For example, [1], [2] deals with 64x64 images and tackles unpaired image-to-image problems. I am not sure, if the methods from [1], [2] works with 256x256, but, anyway, [1] and [2] should be covered as the related works and the competitive methods.**\n\nThank you for informing us about [1] and [2]. We added a discussion regarding [1] and [2] in Section 2. We also attempted to implement [1,2] on our experiments, but faced scalability issues. Concretely, as noted in [1], [1] takes about 1 day to learn a SB between 28x28 grayscale images, with 2 GPUs. As noted in [2], [2] takes 7 days to learn a SB between 64x64 color images, with 2 GPUs. Compare this to UNSB: for instance, on Summer2Winter, UNSB takes 20 hours with 1 GPU to learn a SB between 256 x 256 color images.\n\n> **Q2 : Regarding the competitive methods (GANs), the authors miss the StarGAN and StarGAN v2 [3]. The latter model demonstrates a good quality on the unpaired image2image and I think this model is a good baseline method. Please, add it to the comparison.**\n\nWe kindly refer the Reviewer to Appendix C.3, where we compared UNSB with StarGAN v2, EGSDE, and NOT on the Male2Female translation task, and observed UNSB beats all baselines.\n\n> **Q3 : I ask the authors to add the clarifications how to estimate the entropy with samples, a technique introduced at the beginning of page 6. It will facilitate the comprehension and smoothness of the reading.**\n\nThank you for the constructive feedback. We provided more detail on entropy calculation in Appendix B of the revised paper.\n\n> **Q4 : I have one concern about objective (14). The transition from constrained problem (9)-(10) to the combination of losses (14) is non-trivial and not fully theoretically justified. I am not sure, that the objective (14) indeed solves the SB problem. Some comments/clarifications will contribute to the clearness of the manuscript flow. I strongly encourage the authors to evaluate how does their approach solve SB problem on a nontrivial setup beyond gaussian2gaussian case. In particular, there is a recent paper [4] which proposes benchmark pairs of distributions with known GT EOT/SB solutions, even for images data. The validation on such a benchmark will highly contribute to the quality of the paper and will probably answer this question.**\n\nThanks for the important comment. The transition from constrained problem to an unconstrained formulation arises from using the Langragian and dual formulation. Furthermore, we would like to refer the Reviewer to Appendix C.4, where we added a result on the suggested benchmark [4], and observed positive results.\n\n> **Q5 : I have one more question regarding the baseline methods. The authors choose the work [5] (called them as NOT) \u201cas the representative of OT [methods]\u201d. This choice really surprised me because [5] also deals with SB problem, and, as I understand, their method is not designed for image data (at least, the authors of [5] does not consider image data use cases). That is why comparing with [5] seems strange. I recommend authors take [6, 7, 8] as the representative of OT methods instead. These methods also has a possibility to generate the samples of controllable diversity, have GAN-resembling objective. Moreover, they are designed specifically for unpaired image2image problems.**\n\nThanks for pointing out the typo. We attached a wrong reference to NOT in our paper. NOT in our paper refers to [6] mentioned by the Reviewer, and all experiment results for NOT are carried out with [6]. We apologize for the mistake, and we fixed this reference in our revised paper."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700105000631,
                "cdate": 1700105000631,
                "tmdate": 1700105000631,
                "mdate": 1700105000631,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3wWWsAxRDz",
                "forum": "uQBW7ELXfO",
                "replyto": "1kS7igqarM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Have we addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer f3t2,\n\nAs the deadline for the Reviewer-Author discussion phase is fast approaching (there is only a day left), we respectfully ask whether we have addressed your questions and concerns adequately.\n\nSincerely,\n\nThe Authors."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551880721,
                "cdate": 1700551880721,
                "tmdate": 1700551880721,
                "mdate": 1700551880721,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pJhbejIJPe",
                "forum": "uQBW7ELXfO",
                "replyto": "1kS7igqarM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "[Reminder] Summarization of our rebuttal"
                    },
                    "comment": {
                        "value": "Dear reviewer f3t2,\n\nWe would like to gently remind you that the **discussion period ends in approximately 10 hours**. We would appreciate it if you could let us know whether our comments addressed your concerns, as summarized below.\n\n- In **Section 2** we covered [1] and [2] as related works and competitive methods in the revised paper.\n\n- In **Section 5** we fixed a wrong reference for Neural Optimal Transport (NOT) [3], and clarified [3] is used as a representative for OT in all our experiments.\n\n- In **Appendix C.3** we conducted an additional experiment on Male2Female translation with CelebA-HQ-256 images with baselines EGSDE, StarGAN v2, and NOT, and observed UNSB beats the baselines.\n\n- In **Appendix B** we clarified how to approximate entropy in detail.\n\n- In **Appendix C.4** we validated UNSB on the suggested benchmark [4], and observed positive results.\n\n- In **Appendix C.7** we validated UNSB on Cat2Dog with AFHQ $512 \\times 512$, which further demonstrates the scalability of our proposed approach.\n\nBest regards, Authors\n\n[1] Diffusion Schr\u00f6dinger Bridge Matching, NeurIPS\u20192023\n\n[2] Entropic Neural Optimal Transport via Diffusion Processes, NeurIPS\u20192023\n\n[3] Neural Optimal Transport, ICLR\u20192023\n\n[4] Building the Bridge of Schr\u00f6dinger: A Continuous Entropic Optimal Transport Benchmark, NeurIPS\u20192023"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702656194,
                "cdate": 1700702656194,
                "tmdate": 1700702656194,
                "mdate": 1700702656194,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3M6cM0VGd9",
                "forum": "uQBW7ELXfO",
                "replyto": "3wWWsAxRDz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Reviewer_f3t2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Reviewer_f3t2"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Sorry for the delay. My concerns seems to be addressed. I rise my score to 6"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726023830,
                "cdate": 1700726023830,
                "tmdate": 1700726023830,
                "mdate": 1700726023830,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hKYPteqqvC",
            "forum": "uQBW7ELXfO",
            "replyto": "uQBW7ELXfO",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4501/Reviewer_ek8v"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4501/Reviewer_ek8v"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to address the problem that the diffusion model based unpaired image translation tasks rely on the Gaussion prior assumption. It resorts to Schr\u00f6dinger Bridge and proposes the Unpaired Neural Schr\u00f6dinger Bridge (UNSB) to express SB problem as a sequence of adversarial learning problems. By this formulation, SB can regarded as Lagrangian formulation under the constraint on the KL divergence between the true target distribution and the model distribution. This formulation leads to the composition of generators learned via adversarial learning that overcome the curse of dimensionality with advanced discriminators. Experiments demonstrated the effectiveness of the proposed method compared to its competitors."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper experimentally identifies the cause behind the failure of previous SB methods for image-to-image translation\nas the curse of dimensionality, by a toy task.\n\nThe proposed method gives a new formulation of SB, which benefits on addressing the identified curse of dimensionality.\n\nThe proposed method shows better results than existing methods."
                },
                "weaknesses": {
                    "value": "The paper claimed that \"none of SB models so far have been successful at unpaired translation between highresolution images\", however, the experiments in this paper do not include highresolution images yet (256x256 can not be regarded as highresolution). How will the proposed method perform on this setting is still unclear.\n\nIt is unclear that the findings by ablation study are still valid for other datasets?\n\nWhen presenting the stochasticity analysis, it only gives results for one image. It would be better if the paper can provide statistical numbers across many different images/cases."
                },
                "questions": {
                    "value": "no"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4501/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698910566544,
            "cdate": 1698910566544,
            "tmdate": 1699636425958,
            "mdate": 1699636425958,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Pk51lpDF5k",
                "forum": "uQBW7ELXfO",
                "replyto": "hKYPteqqvC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Reviewer ek8v"
                    },
                    "comment": {
                        "value": "We thank the Reviewer for the insightful review, which has been incorporated into the revised paper. We address the Reviewer's concerns and questions below.\n\n> **Q1 : The paper claimed that \"none of SB models so far have been successful at unpaired translation between high resolution images\", however, the experiments in this paper do not include high resolution images yet (256x256 cannot be regarded as high resolution). How will the proposed method perform on this setting is still unclear.**\n\nWe kindly remind the Reviewer that multiple works [1,2,3] view 256x256 as high-resolution. Moreover, numerous representative methods for unpaired image-to-image translation [4,5] use 256x256 resolution images. Although we believe that our method can be scaled to higher resolution such as 512x512 or 1024x1024, and are running the experiments now, due to the limiting computational resource, it is a pity that we cannot provide the results during the rebuttal period.\n\n[1] High-Resolution Image Synthesis with Latent Diffusion Models, Rombach et al., CVPR, 2022.\n\n[2] EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations, Zhao et al., NeurIPS, 2022.\n\n[3] Dual Diffusion Implicit Bridges for Image-to-Image translation, Su et al., ICLR, 2023.\n\n[4] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, Zhu et al., ICCV, 2017.\n\n[5] Contrastive Learning for Unpaired Image-to-Image Translation, Park et al., ECCV, 2020.\n\n> **Q2 : It is unclear that the findings by ablation study are still valid for other datasets?**\n\nWe would like to refer the Reviewer to Appendix C.6, where we performed an additional ablation study on the Summer2Winter translation task, and observe similar trends as before.\n\n> **Q3 : When presenting the stochasticity analysis, it only gives results for one image. It would be better if the paper can provide statistical numbers across many different images/cases.**\n\nWe kindly refer the Reviewer to Appendix C.2, where we provide more stochasticity analysis results."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700104391493,
                "cdate": 1700104391493,
                "tmdate": 1700104391493,
                "mdate": 1700104391493,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gP94GMGhyM",
                "forum": "uQBW7ELXfO",
                "replyto": "hKYPteqqvC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Have we addressed your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer ek8v,\n\nAs the deadline for Reviewer-Author discussion is fast approaching (there is only a day left), we respectfully ask whether we have addressed your questions and concerns adequately.\n\nSincerely,\n\nThe Authors."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551828270,
                "cdate": 1700551828270,
                "tmdate": 1700551828270,
                "mdate": 1700551828270,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ATjs1vZreU",
                "forum": "uQBW7ELXfO",
                "replyto": "gP94GMGhyM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4501/Reviewer_ek8v"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4501/Reviewer_ek8v"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks the authors for the active responses. I will keep my initial score as my concerns have been adequately solved."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4501/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700575930884,
                "cdate": 1700575930884,
                "tmdate": 1700575930884,
                "mdate": 1700575930884,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]