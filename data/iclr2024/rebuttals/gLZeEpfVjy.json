[
    {
        "title": "Understanding and Robustifying Sub-domain Alignment for Domain Adaptation"
    },
    {
        "review": {
            "id": "QOiw3Uzt8F",
            "forum": "gLZeEpfVjy",
            "replyto": "gLZeEpfVjy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8560/Reviewer_p9oY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8560/Reviewer_p9oY"
            ],
            "content": {
                "summary": {
                    "value": "This paper establishes a theoretical foundation for sub-domain alignment in domain adaptation. Under certain plausible assumptions, they demonstrate that this bound is as tight, if not tighter, than those of full-domain alignment approaches. Drawing from this theorem, they introduce the Domain Adaptation via Rebalanced Sub-domain Alignment (DARSA) to address the challenge of marginal sub-domain weight shifts. Empirical evidence shows that their method, with sub-domains based on class labels, outperforms other leading domain adaptation methods in label shift scenarios."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The theoretical analysis regarding the sub-domain alignment is thorough and insightful. The method proposed is clearly grounded in this theory. While I haven't delved into every detail of the derivation, the conclusions seem sound.\n2. The paper is well-structured and reader-friendly.\n3. The effectiveness of their approach, when segmenting by class to form subdomains, is confirmed by results on both Digits and TST for the label shift scenario."
                },
                "weaknesses": {
                    "value": "1. While the theory behind sub-domain alignment is certainly compelling, in its practical application, it merely utilizes class labels to segment subdomains. This results in a method that essentially merges class importance weighting with W1 distance to gauge domain discrepancies. While this is a fresh approach, it's not exceptionally innovative. It would enhance the paper if the author explored alternative sub-domain segmentation techniques.\n\n2. It would enrich the study if the author included baselines that are specifically designed for label shift scenarios, like the method outlined in [1]. Many of their referenced baselines, such as DANN and ADDA, are primarily constructed for the covariate shift setting.\n\n\n[1] Yan, Hongliang, et al. \"Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8560/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8560/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8560/Reviewer_p9oY"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698469958523,
            "cdate": 1698469958523,
            "tmdate": 1699637070682,
            "mdate": 1699637070682,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3chyTC6r52",
                "forum": "gLZeEpfVjy",
                "replyto": "QOiw3Uzt8F",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer p9oY, \n\nThank you for your comments. Please see below our response to your concerns. \n\n---\n> While the theory behind sub-domain alignment is certainly compelling, in its practical application, it merely utilizes class labels to segment subdomains. This results in a method that essentially merges class importance weighting with W1 distance to gauge domain discrepancies. While this is a fresh approach, it's not exceptionally innovative. It would enhance the paper if the author explored alternative sub-domain segmentation techniques.\n\nWe would like to clarify that the primary focus of this work was not on algorithmic novelty, but rather on addressing a critical challenge observed in imbalanced scenarios. Our analysis revealed that subdomain-based methods tend to falter under such conditions. To counter this, we introduced an algorithm with **theoretical guarantee** to enhance the robustness of sub-domain based methods. The effectiveness of our approach is not just theoretical but is also supported by empirical evidence from our study. With the theoretical foundation provided by our work, we expect following works with more advanced algorithms.\n\n> It would enrich the study if the author included baselines that are specifically designed for label shift scenarios, like the method outlined in [1]. Many of their referenced baselines, such as DANN and ADDA, are primarily constructed for the covariate shift setting.\n\n**Baselines.** We have indeed included baselines specifically designed for label shift scenarios, such as Cluster Alignment with a Teacher (CAT). Since we are a theory-focused paper to theoretically understand the effectiveness of sub-domain based methods, our selection also includes theoretically robust methods such as DANN as well as top-performing methods in digit transfer learning tasks, recognized on the Papers with Code website [2]. It's worth noting that most of our domain adaptation accuracy is strong (over 90%), which naturally limits the margin for further improvement by adding additional benchmarks.\nWe address a different level of imbalance compared to [1]. In [1], the focus is on the original class distributions of digit datasets, highlighting biases across domains (for example, the higher weights of classes 0 and 1 in USPS, and 1 and 2 in SVHN). These scenarios can be considered as **no additional label distribution shifts**, which is significantly different from the experiment setup in our work. In our work, we modified digit datasets to induce label distribution shifts. Here, the parameter $\\alpha$ denotes the class imbalance rate, representing a ratio such as 1:$\\alpha$ and $\\alpha$:1 for the odd:even distribution in the source and target datasets, respectively. And we evaluated both weak ($\\alpha=3$) and strong imbalance scenarios (($\\alpha=8$)).\nIn line with your suggestion, we have demonstrated experiments with **no additional label distribution shifts** for a more direct comparison of DARSA with other methods. The results, presented in the subsequent tables, clearly demonstrate that DARSA significantly outperforms [1], reinforcing the effectiveness and robustness of our approach in these specific scenarios.\n|                       |     USPS to MNIST         |  SVHN to MNIST  | \n| ------------------:| :------------------------------:| :----------------------:| \n|  DANN     |   \t  74.5 \t                      |   73.9                 | \n| **WDAN**  [1]     |    65.4\t                      |   67.4                 | \n|  WDGRL |      84.8                           |    59.3                  |\n|  DSN        |      91.0                           |    82.7                |\n|  ADDA       |      90.1                        |    76.0                |\n|  CAT          |      80.9                         |   98.1                 |\n|  CDAN   |     98.0                         |   89.2                 |\n|  pixelDA   |     87.6                           |   71.6                   |\n|  DRANet  |     97.8                        |   59.7                   |\n|  DARSA          |     97.4                          |    98.6                   |\n\nTable: Performance of DARSA and baseline methods without label shifting.  \n\n---\n\n[1] Yan, Hongliang, et al. \"Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.\n\n[2] https://paperswithcode.com/task/domain-adaptation"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700288816542,
                "cdate": 1700288816542,
                "tmdate": 1700425132661,
                "mdate": 1700425132661,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AuuDuW7mQJ",
                "forum": "gLZeEpfVjy",
                "replyto": "3chyTC6r52",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8560/Reviewer_p9oY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8560/Reviewer_p9oY"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your comments"
                    },
                    "comment": {
                        "value": "Thanks for your comments. I will keep my score as 6."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634578691,
                "cdate": 1700634578691,
                "tmdate": 1700634578691,
                "mdate": 1700634578691,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "k3hSvonC7K",
            "forum": "gLZeEpfVjy",
            "replyto": "gLZeEpfVjy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8560/Reviewer_epCK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8560/Reviewer_epCK"
            ],
            "content": {
                "summary": {
                    "value": "This paper first presents a theoretical analysis to establish that the sub-domain based methods are in fact optimizing a generalization bound that is at least as strong as the full-domain-based objective functions. Besides, the paper presents a UDA algorithm, Domain Adaptation via Rebalanced Sub-domain Alignment (DARSA), which addresses the case when marginal subdomain weights shift. DARSA optimizes reweighted classification error and discrepancy between sub-domains of the source and target task."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(1) This work provides a theoretical foundation for subdomain-based methods in domain adaptation, addressing their previous lack of rigorous understanding.\n(2) The authors design a DARSA model, aiming to address shifted marginal sub-domain weights, which adversely impact existing sub-domain based methods.\n(3) The experimental results on different benchmarks show the effectiveness of the proposed framework over other existing UDA methods."
                },
                "weaknesses": {
                    "value": "(1) Most of the compared UDA methods were published before 2020. To fully validate the superiority of the proposed DARSA model, more SOTA UDA methods should be included in comparison experiments. \n\n(2) More insightful analyses should be provided. For example, the visualization of the subdomain rebalancing weights should be shown. \n\n(3) The current experiments are conducted on two datasets, which is not sufficient. It is recommended to conduct on large-scale datasets."
                },
                "questions": {
                    "value": "(1) Most of the compared UDA methods were published before 2020. To fully validate the superiority of the proposed DARSA model, more SOTA UDA methods should be included in comparison experiments. \n\n(2) More insightful analyses should be provided. For example, the visualization of the subdomain rebalancing weights should be shown. \n\n(3) The current experiments are conducted on two datasets, which is not sufficient. It is recommended to conduct on large-scale datasets."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8560/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8560/Reviewer_epCK",
                        "ICLR.cc/2024/Conference/Submission8560/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698767424805,
            "cdate": 1698767424805,
            "tmdate": 1700658758472,
            "mdate": 1700658758472,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "liWplYS903",
                "forum": "gLZeEpfVjy",
                "replyto": "k3hSvonC7K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer epCK, \n\nThank you for your comments. Please see below our response to your concerns. \n\n---\n\n### *Responses to Weakness/Question (1) and (3)*\n**Rationale Behind Baseline Selection:**  Regarding the selection of compared methods, our benchmarks were meticulously chosen to demonstrate the robustness and effectiveness of our proposed algorithm. This includes theoretically solid methods such as DANN, and methods that have top performances in digit transfer learning tasks as recognized on the Papers with Code website  [1]. We also included relevant sub-domain-based methods [2, 3], aligning perfectly with our research's core focus. This strategic selection of baselines was not only comprehensive but also directly relevant to our algorithm's intended application area.\n\n**Rationale Behind Datasets Selection:** Regarding the number of datasets used, our focus was on depth and relevance rather than quantity. The datasets selected are highly pertinent to the real-world applications we aim to impact. Specifically, our theoretical analysis indicates that DARSA should perform competitively in scenarios with a manageable number of classes, which is particularly applicable to fields like medical applications. These areas demand high precision and reliability, qualities that our algorithm has been demonstrated to fulfill effectively. \n\nIn addition, as a theory-focused paper, we conducted comprehensive examinations to validate our theoretical propositions. This includes 1) empirically confirming the superiority of the sub-domain-based generalization bound; 2) verifying that the assumptions for Theorem 4.10 are empirically satisfied in real-world datasets; 3) demonstrating the vital role of subdomain weight re-balancing and showing DARSA's robustness to minor weight estimation discrepancies (Section 6.2); and 4) conducting an ablation study to evaluate the impact of each component within our objective function.\n\n---\n\n### *Responses to Weakness/Question (2)*\n\nIt appears that the reviewer has neglected the analysis provided in our submitted manuscript. Section 6.2 presents experiments on the Digits datasets to demonstrate the importance of (i) weights re-weighting and (ii) the accuracy of target subdomain weights estimation. As shown in Table 1, while the oracle case provides the best performance, DARSA algorithm demonstrates a very similar level of effectiveness, demonstrating that the weights in the DARSA algorithm provide nearly the same quality of predictions. In addition, it can be seen  from Table 1 that DARSA is robust to minor divergence in weights estimation and varying imbalance rates.\n\nIn addition, we would like to clarify that the primary indicator of the effectiveness of our method, DARSA, is the improvement in prediction accuracy, which directly reflects the precision of our estimated weights. However, to directly address your request and provide further transparency, we have included an additional analysis. This analysis involves comparing the difference between the actual ground truth target weight $w_T$ and our estimated target weight $\\hat{w_T}$ across epochs. \n\nAs illustrated in the figure 6 in Appendix F, our estimation aligns closely with the ground truth towards the end of the training process. This proximity indicates the effectiveness of our weight estimation approach within the DARSA algorithm.\n\n---\n\n[1] https://paperswithcode.com/task/domain-adaptation\n\n[2] Deng, Zhijie, Yucen Luo, and Jun Zhu. \"Cluster alignment with a teacher for unsupervised domain adaptation.\" Proceedings of the IEEE/CVF international conference on computer vision. 2019.\n\n[3] Long, Mingsheng, et al. \"Conditional adversarial domain adaptation.\" Advances in neural information processing systems 31 (2018)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700288532175,
                "cdate": 1700288532175,
                "tmdate": 1700288565500,
                "mdate": 1700288565500,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5Erzg4qZYg",
                "forum": "gLZeEpfVjy",
                "replyto": "k3hSvonC7K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8560/Reviewer_epCK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8560/Reviewer_epCK"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your comments. Some concerns have been addressed, and thus I raise my score."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658741007,
                "cdate": 1700658741007,
                "tmdate": 1700658788912,
                "mdate": 1700658788912,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IyozwOXevn",
                "forum": "gLZeEpfVjy",
                "replyto": "k3hSvonC7K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer epCK,\n\nAs the discussion period approaches its end, we would like to again express our sincere gratitude for your help and dedication to the review of our work. In light of our discussions, we wish to highlight the core contributions that we believe are important to the field of domain adaptation research:\n\n**Main Contributions:**\n\na. Theoretical Contributions: \n\nOur work analyzes and provides a theoretical foundation for sub-domain based methods in domain adaptation, addressing their previous lack of rigorous understanding. **Our theoretical framework not only supports our algorithm but can be extended to other methods, contributing to broader impact and value in the field.** \n\nb. Algorithmic Strengths: \n\nOur theoretical analysis leads to our algorithm DARSA, showing superior performance in various real-world applications. We also detail the circumstances where our algorithm excels or may face challenges. **This transparency, along with potential strong performance in applications such as medical applications, makes our algorithm highly valuable.** Specifically, our theoretical analysis indicates that DARSA should perform competitively in scenarios with a manageable number of classes, which is particularly applicable to fields like biomedical applications. For example, as illustrated in Table 3, our experiments on a neural biology dataset involve transferring knowledge between a bipolar disorder model (Clock-\u220619) and control mice, each subjected to three behavioral assays. This scenario exemplifies the typical biomedical context with a manageable number of classes. Similarly, in predicting diabetes types among patients from different hospitals, we generally deal with a limited set of categories (type 1, type 2, and gestational diabetes). These cases highlight the practical significance of our algorithm in fields that demand high precision and reliability.\n\nWe believe that our paper's blend of theoretical rigorousness, novel methods, and convincing empirical results represents a significant contribution to the field of domain adaptation. We are delighted that our effort has addressed some of your concerns, and deeply grateful for your recognition of our rebuttal, as reflected in the raised scores.\n\nBest regards,\n\nThe Authors of Paper 8560"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700689066174,
                "cdate": 1700689066174,
                "tmdate": 1700689282566,
                "mdate": 1700689282566,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JbiAZczKSR",
            "forum": "gLZeEpfVjy",
            "replyto": "gLZeEpfVjy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8560/Reviewer_W1Lh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8560/Reviewer_W1Lh"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the understanding and robustifying of the application of sub-domain alignment to unsupervised domain adaptation. To achieve this goal, this paper provides a theoretical foundation for sub-domain alignment methods and an algorithm DARSA to address the shifted marginal sub-domain weights. The experiments show that the proposed method outperforms some previous methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(1)This paper is well-written, and it is enjoyable to read.\n(2)The proposed algorithm is simple yet effective to some extent."
                },
                "weaknesses": {
                    "value": "(1)The theoretical analysis is not instructive. The theoretical analysis has two main theorems, Sub-domain-based Generalization Bound (Theorem 4.5) and Benefits of Sub-domain Alignment (Theorem 4.7 and 4.10). Theorem 4.5 shows that the error of the target domain can be bounded by the weighted error of the source domain and the weighted error of the sub-domain distance. However, some works [1][2] have pointed out similar conclusions. Theorem 4.10 shows that the error bound of Theorem 4.5 is at least as strong as the full domain generalization bound without the sub-domain information. However, the authors may overlook the finiteness of real datasets, which is also important for reliable generalization bound and thus may lead to a different conclusion. Considering that the sub-domains have fewer samples than the whole domain, the finiteness improves more value of the sub-domain generalization bound than the whole-domain generalization bound. \n(2)Although the paper is based on previous sub-domain alignment works, the previous works are not well connected in theoretical analysis, algorithm, or experiments. The author should give some examples of how the work enhances the understanding and robustifying of previous methods. \n(3)The experiments are not sufficient to show the effectiveness of the proposed algorithm. First, the number of datasets used for the experiments is too small. Second, the compared methods are not advanced enough.\n[1] Jiang X, Lao Q, Matwin S, et al. Implicit class-conditioned domain alignment for unsupervised domain adaptation[C]//International Conference on Machine Learning. PMLR, 2020: 4816-4827.\n[2] Wen J, Greiner R, Schuurmans D. Domain aggregation networks for multi-source domain adaptation[C]//International conference on machine learning. PMLR, 2020: 10214-10224."
                },
                "questions": {
                    "value": "As the weakness above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "I have no ethics concerns."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8560/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8560/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8560/Reviewer_W1Lh"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8560/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698916413169,
            "cdate": 1698916413169,
            "tmdate": 1700698349976,
            "mdate": 1700698349976,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fBaBjCGcAX",
                "forum": "gLZeEpfVjy",
                "replyto": "JbiAZczKSR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer W1Lh, \n\nThank you for your comments. Please see below our response to your concerns. \n> The theoretical analysis is not instructive. The theoretical analysis has two main theorems, Sub-domain-based Generalization Bound (Theorem 4.5) and Benefits of Sub-domain Alignment (Theorem 4.7 and 4.10). Theorem 4.5 shows that the error of the target domain can be bounded by the weighted error of the source domain and the weighted error of the sub-domain distance. However, some works [1][2] have pointed out similar conclusions.\n\nWe indeed have already included [1] in our Related Work section. This is one great example of sub-domain-based domain adaptation method that uses class-conditioned domain alignment to address within-domain class imbalance and between-domain class distribution shift. Our theoretical framework provides a foundation for subdomain based methods, addressing their previous lack of rigorous understanding. One of the key messages we hope to deliver is that **Our theoretical framework not only supports our algorithm but can be extended to other methods, contributing to broader impact and value in the field.**  Contrasting with the focus of [2] on **multi-source** domain adaptation, where source domains are aggregated based on their relevance to the target domain (with weights assigned accordingly), our work focuses on **single source** domain adaptation. Specifically, we focus on aligning corresponding sub-domain distributions. For example, we align label 1 in the source domain with label 1 in the target domain. Our weighting logic also differs \u2013 rather than relying on the relevancy of source sub-domains, our method gives priority to the important sub-domains within the target domain. This fundamental difference underscores the uniqueness and strength of our methodology in addressing domain adaptation challenges.\n\n> Theorem 4.10 shows that the error bound of Theorem 4.5 is at least as strong as the full domain generalization bound without the sub-domain information. However, the authors may overlook the finiteness of real datasets, which is also important for reliable generalization bound and thus may lead to a different conclusion. Considering that the sub-domains have fewer samples than the whole domain, the finiteness improves more value of the sub-domain generalization bound than the whole-domain generalization bound. \n\nWhile the variance increases with fewer samples, this does not imply that the realized error bound is necessarily larger than the expected one because it is equally likely that the realized error bound is smaller than the expected one. We have proved that in expectation, the sub-domain-based generalization bound presents a tighter estimation. Moreover, please note that the classical domain generalization bound have about $O(n^{-1/2})$ concentration while in the sub-domain-based generalization bound, the averaged error have about $O(m^{-1})$ variance reduction where $m$ is the number of class. This leads to $O((mn)^{-1/2})$ concentration, i.e., the variance is in fact reduced by a multiple of $m$ compared to the non-subdomain-based one. Intuitively, this is similar to the classical result in information theory where conditioning on the class random variable can only decrease entropy. In addition, as shown in Section 6.1, our empirical results demonstrate that the subdomain-based generalization bound is empirically much stronger than the non-sub-domain-based bound, corroborating our insights for the effectiveness of sub-domain based methods.\n\n> Although the paper is based on previous sub-domain alignment works, the previous works are not well connected in theoretical analysis, algorithm, or experiments. The author should give some examples of how the work enhances the understanding and robustifying of previous methods. \n\nIt appears that there is some misunderstanding that our paper primarily build upon previous sub-domain alignment works. Instead, our paper introduces a fresh perspective by analyzing and providing a much-needed theoretical foundation for sub-domain based methods which are popular yet theoretically underexplored. To further clarify, our theoretical analysis does not simply follow the trajectory of existing literature; it carves a new path in understanding how subdomain based methods function and can be optimized. This contributes not only to a deeper comprehension of these methods but also offers tools that can be used to enhance their robustness and efficacy. By doing so, our work extends its impact beyond just supporting our algorithm; it enriches the field of domain adaptation with a solid theoretical base that can be used to re-examine, refine, and strengthen existing subdomain based methods. We believe that such a theoretical foundation is important to the field and merits recognition."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700288176190,
                "cdate": 1700288176190,
                "tmdate": 1700424905216,
                "mdate": 1700424905216,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "F84xZ6enFE",
                "forum": "gLZeEpfVjy",
                "replyto": "JbiAZczKSR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8560/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> The experiments are not sufficient to show the effectiveness of the proposed algorithm. First, the number of datasets used for the experiments is too small. Second, the compared methods are not advanced enough.\n\n**Rationale Behind Baseline Selection:**  Regarding the selection of compared methods, our benchmarks were meticulously chosen to demonstrate the robustness and effectiveness of our proposed algorithm. This includes theoretically solid methods such as DANN and methods that have top performances in digit transfer learning tasks as recognized on the Papers with Code website [1]. We also included relevant sub-domain-based methods [2, 3], aligning perfectly with our research's core focus. This strategic selection of baselines was not only comprehensive but also directly relevant to our algorithm's intended application area.\n\n**Rationale Behind Datasets Selection:** Regarding the number of datasets used, our focus was on depth and relevance rather than mere quantity. The datasets selected are highly pertinent to the real-world applications we aim to impact. Specifically, our theoretical analysis indicates that DARSA should perform competitively in scenarios with a manageable number of classes, which is particularly applicable to fields like medical applications. These areas demand high precision and reliability, qualities that our algorithm has been demonstrated to fulfill effectively. \n\nIn addition, as a theory-focused paper, we conducted comprehensive examinations to validate our theoretical propositions. This includes 1) empirically confirming the superiority of the sub-domain-based generalization bound; 2) verifying that the assumptions for Theorem 4.10 are empirically satisfied in real-world datasets; 3) demonstrating the vital role of subdomain weight re-balancing and showing DARSA's robustness to minor weight estimation discrepancies (Section 6.2); and 4) conducting an ablation study to evaluate the impact of each component within our objective function.\n\n---\n\n[1] https://paperswithcode.com/task/domain-adaptation\n\n[2] Deng, Zhijie, Yucen Luo, and Jun Zhu. \"Cluster alignment with a teacher for unsupervised domain adaptation.\" Proceedings of the IEEE/CVF international conference on computer vision. 2019.\n\n[3] Long, Mingsheng, et al. \"Conditional adversarial domain adaptation.\" Advances in neural information processing systems 31 (2018)."
                    },
                    "title": {
                        "value": "Continuation"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700288220319,
                "cdate": 1700288220319,
                "tmdate": 1700424995516,
                "mdate": 1700424995516,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "D9osuWXrTk",
                "forum": "gLZeEpfVjy",
                "replyto": "F84xZ6enFE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8560/Reviewer_W1Lh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8560/Reviewer_W1Lh"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your comments.Most of my concerns have been addressed, I have modified my scores."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8560/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700698309216,
                "cdate": 1700698309216,
                "tmdate": 1700698309216,
                "mdate": 1700698309216,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]