[
    {
        "title": "Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation"
    },
    {
        "review": {
            "id": "KLhOjUfK0x",
            "forum": "QzQSR56JZr",
            "replyto": "QzQSR56JZr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3948/Reviewer_8JQp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3948/Reviewer_8JQp"
            ],
            "content": {
                "summary": {
                    "value": "This paper 28K sentence-level natural language to First Order Logic pairs collected from GPT-4. The authors also present a LLaMA-13B model fine-tuned on this dataset which combined with GPT3.5 achieves GPT-4 level performance on the NL-FOL translation tasks.\n\nThe combination method with GPT3.5 is interesting because it relies on using RLHF method to correct synthetically perturbed NL-FOL pairs and using a first order logic verifier as a reward model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper presents a new method for gathering RLHF feedback based on iterative correction which is a non-trivial extension of previous methods."
                },
                "weaknesses": {
                    "value": "The techniques in the paper are not novel and fine-tuning LLAMA for a downstream task can be considered engineering at this point instead of active research. The novelty of the proposed approach is not totally clear."
                },
                "questions": {
                    "value": "Even though the paper says that the LogicLLAMA is finetuned using RLHF there is no human feedback involved. It should probably be called something else ?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3948/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698644243412,
            "cdate": 1698644243412,
            "tmdate": 1699636355588,
            "mdate": 1699636355588,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9qqBqTdleI",
                "forum": "QzQSR56JZr",
                "replyto": "KLhOjUfK0x",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3948/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3948/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for your comments and we appreciate your positive feedback on our work. Our responses are as follows:\n\n\n***\u201dThe novelty of the proposed approach is not totally clear\u201d***\n\nWe thank the reviewer for acknowledging the novelty of our proposed RLHF method. We would like to further highlight two important aspects of our work to clarify the overall novelty:\n\n**LogicLLaMA and MALLS are significant contributions to the logic and NLP literature.**\nNL-FOL translation has been a long-standing challenge in both NLP and the formal logic literature, and it plays a central role in many logic-based AI systems [1-4].\nSolving this task could open up a wide range of applications, yet there lacks such a translation model that scales to real-world data, preventing these systems from applying to real-world NLP problems.\n\nWe believe LogicLLaMA is a significant contribution to the literature (As also acknowledged by reviewer wVqn) as it, for the first time, provides a GPT4-level performance translation model that is cheap, open-source, and can be extended for downstream tasks.\n\n\n\n**The creation of MALLS dataset is non-trivial; prior work with similar scope is widely appreciated.**\nThis work shares a similar scope as those self-instruct LLM work such as Alpaca [5], Vicuna [6], and LLaVa [7]: most of them use the existing models and training algorithms, and the main contributions are \u201cengineering\u201d work such as dataset creation, prompting techniques, and so on, yet they are highly influential and significant to the community.\n\nWe note the creation of the MALLS dataset is also one of the main contributions of this work and should not be neglected. Given the importance of NL-FOL translation in many logic-based NLP systems, a high-quality real-world NL-FOL pair dataset is highly valuable to the literature and can open up possibilities for many downstream applications. In this regard, MALLS stands out as it is significantly larger (14x times compared to FOLIO) and more diverse in terms of logical expression and context.\n\n\n\n**RLHF naming**\n\nSorry for the confusion. Yes, there is indeed no human feedback involved. Technically, it should be RL with FOL verifier feedback, but since the overall algorithm remains the same we keep the same naming convention. We have included clarification for this in the draft.\n\n\n[1] Abzianidze, L. (2017). LangPro: Natural Language Theorem Prover. Proceedings of the 2017 Conference on Empirical Methods in Natural           Language Processing: System Demonstrations, 115\u2013120.\n\n[2] Bos, J., & Markert, K. (2005). Recognising Textual Entailment with Logical Inference. Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, 628\u2013635.\n\n[3] Lu, X., West, P., Zellers, R., Bras, R. L., Bhagavatula, C., & Choi, Y. (2021). NeuroLogic Decoding: (Un)supervised Neural Text Generation with Predicate Logic Constraints (arXiv:2010.12884).\n\n[4] Wang, S., Zhong, W., Tang, D., Wei, Z., Fan, Z., Jiang, D., Zhou, M., & Duan, N. (2021). Logic-Driven Context Extension and Data Augmentation for Logical Reasoning of Text (arXiv:2105.03659).\n\n[5] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model.\n\n[6] Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng,Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023.\n\n[7] Liu, Haotian, et al. \"Visual instruction tuning.\" arXiv preprint arXiv:2304.08485 (2023)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3948/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700168655975,
                "cdate": 1700168655975,
                "tmdate": 1700168655975,
                "mdate": 1700168655975,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WUEysgkO9J",
            "forum": "QzQSR56JZr",
            "replyto": "QzQSR56JZr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3948/Reviewer_6TG1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3948/Reviewer_6TG1"
            ],
            "content": {
                "summary": {
                    "value": "The paper aims to address the challenge of translating natural language sentences into first-order logic (FOL). A new dataset, MALLS, is proposed, which is generated by leveraging LLMs and applying filtering rules to eliminate bad cases. The paper proposed fine-tuning LLaMA on MALLS to enhance LLaMA's FOL generation ability. The model is tested on LogicNLI, FOLIO, and MALLS to demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper demonstrates considerable effort in conducting numerous experiments to achieve its objective.\nThe motivation to enhance FOL generation ability is interesting."
                },
                "weaknesses": {
                    "value": "1. The paper lacks novelty. Most contributions are either engineering work or published work including: prompting LLM to generate data, various prompting and dataset filtering methods, supervised fine-tuning, and RLHF. Moreover, the conclusions are predictable: fine-tuning LLM on a specific domain can improve its performance, potentially surpassing the best LLM for open domains.\n2. The proposed methods do not show significant improvement. As per Table 2, the majority of the gain comes from vanilla supervised fine-tuning on MALLS, and the newly proposed methods only bring marginal gains, especially when compared to the gain from the baseline to vanilla fine-tuning."
                },
                "questions": {
                    "value": "1. The abstract should be written in a single paragraph.\n2. Consider reducing the use of markers like C1-C2, Q1-Q2, T1-T4. The frequent use of these symbols indicates a struggle to explain clearly, and it can be challenging for readers to understand by locating the definition. Short names might be more effective.\n3. Try to limit the number of your contributions and new terms. Highlight only the most significant things you want readers to remember. Currently, you have five prompting methods to create the dataset, four rules to filter the dataset, four fine-tuning methods to train LLaMA, and the experiment aims to address four research questions. This approach dilutes each contribution and makes it difficult to determine whether it works and can be generalized to new problems.\n4. Can your method generate more examples, since your generation and filtering are automatically executed?\n5. How do you assess the coverage or diversity of your dataset? LLM may only generate high-frequency knowledge.\n6. While the natural language input generated from LLM is often fluent and grammatically correct, real human inputs can be noisy. How do you address this issue?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3948/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698759193306,
            "cdate": 1698759193306,
            "tmdate": 1699636355488,
            "mdate": 1699636355488,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tVNvimABSx",
                "forum": "QzQSR56JZr",
                "replyto": "WUEysgkO9J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3948/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3948/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for your comments. Our responses are as follows:\n\n&nbsp;\n\n***\u201dThe paper lacks novelty\u201d***\n\nWe clarify this point on three aspects:\n\n\n**The iterative correction with RLHF is technically novel.**\nWe emphasize that the iterative correction with RLHF is a novel extension (as also acknowledged by reviewer 8JQp) to the original RLHF setup. Prior work either realized iterative correction via pure prompting [1] with closed-source models such as ChatGPT, or utilized RLHF for other tasks [2] such as instruction-following fine-tuning. Ours is the first method that uses RLHF to fine-tune language models for logical understanding with non-trivial settings, such as FOL rule perturbation and logical equivalence evaluation.\n\n\n**LogicLLaMA and MALLS are significant contributions to the logic and NLP literature.**\nNL-FOL translation has been a long-standing challenge in both NLP and the formal logic literature, and it plays a central role in many logic-based AI systems [3-6].\nSolving this task could open up a wide range of applications, yet there lacks such a translation model that scales to real-world data, preventing these systems from applying to real-world NLP problems.\n\nWe believe LogicLLaMA is a significant contribution to the literature (As also acknowledged by reviewer wVqn) as it, for the first time, provides a GPT4-level performance translation model that is cheap, open-source, and can be extended for downstream tasks.\n\n\n\n**The creation of MALLS dataset is non-trivial; prior work with similar scope is widely appreciated.**\nThis work shares a similar scope as those self-instruct LLM work such as Alpaca [7], Vicuna [8], and LLaVa [9]: most of them use the existing models and training algorithms, and the main contributions are those so-called \u201cengineering work\u201d: dataset creation, prompting techniques, and so on, yet they are highly influential and significant to the community.\n\nWe emphasize the creation of the MALLS dataset is also one of the main contributions of this work and should not be neglected. Given the importance of NL-FOL translation in many logic-based NLP systems, a high-quality real-world NL-FOL pair dataset is highly valuable to the literature (for benchmarking or fine-tuning) and can open up possibilities for many downstream applications. In this regard, MALLS stands out as it is significantly larger (14x times compared to FOLIO) and more diverse in terms of logical expression and context.\n\n&nbsp;\n\n***\u201d The proposed methods do not show significant improvement\u201d***\n\nAs stated above, we disagree that one views RLHF as the sole proposed method and the rest two modes as the baselines\u2014they are different modes of a LLaMA model proposed in this work for NL-FOL translation, and they are trained and evaluated on a dataset is non-trivial to collect and process.\n\nNevertheless, we are glad to share that we have resolved a few implementational issues with RLHF and rerun the experiments. We find the updated iterative correction performs significantly better compared to the two other modes, leading to ~10% increase in both FOL BLEU and FOL LE on FOLIO and MALLS (whereas scores for  LogicNLI are already saturated). We have updated the RLHF scores in Table 2.\n \n&nbsp;\n\n***\u201d Can your method generate more examples?\u201d***\n\nYes, and we plan to collect more FOL rules in future work.\n\n&nbsp;\n\n***\u201d How do you assess the coverage or diversity of your dataset? LLM may only generate high-frequency knowledge.\u201d***\n\nWe believe the **Pair diversity** paragraph in section 3.3 has sufficiently addressed this concern. During the data collection phase, we implemented several prompting techniques to encourage rule and term diversity. As a result, *\u201cMALLS has a total term vocabulary size of 49394 and the most frequent terms occur less than 2K times (Figure 8 in Appendix B), suggesting a diverse vocabulary distribution.\u201d*. We also show in Table 1, Figure 1, and 7 that MALLS covers a wide range of concepts as well.\n\n&nbsp;\n\n***\u201dWhile the natural language input generated from LLM is often fluent and grammatically correct, real human inputs can be noisy. How do you address this issue?\u201d***\n\nAs stated in Table 1 and Section 2, FOLIO consists of NL-FOL pairs written by humans, and we believe evaluating LogicLLaMA on this benchmark shows how well the model performs with *real human inputs*. As a result, Table 2 suggests that LogicLLaMA performs well on it."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3948/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700168579837,
                "cdate": 1700168579837,
                "tmdate": 1700168579837,
                "mdate": 1700168579837,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Eh3E4WOxuN",
                "forum": "QzQSR56JZr",
                "replyto": "WUEysgkO9J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3948/Reviewer_6TG1"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3948/Reviewer_6TG1"
                ],
                "content": {
                    "title": {
                        "value": "Concerns about the novelty"
                    },
                    "comment": {
                        "value": "I agree with the author regarding the value of the MALLS dataset. However, I have some concerns about the contributions:\n\n1. LogicLLaMA: Unlike Alpaca, Cicuna, and LLaVA, which aim to enhance open-domain instruction following ability or multi-modal ability, LogicLLaMA primarily focuses on first-order generation ability. I am concerned that this gain may result from adapting open-domain to a specific domain, potentially harming open-domain ability. To address this concern, could the author provide tests of LogicLLaMA on tasks beyond logic translation? At a minimum, please test the model on logical, reasoning, and math-related datasets, which may benefit from the ability to generate logic expressions.\n\n2. Performance of RLFH correlation: Based on the updated Table 2, the gain of RLHF correlation is still marginal. I agree with the author that the \"LogicLLaMA-13B Trans.\" setting achieves more than a 10% gain compared to \"LLaMA2-13B 5-shot\", demonstrating that fine-tuning with MALLS can improve performance on these three datasets. However, when evaluating the proposed methods \"Corre\" and \"RLHF Corre\", we should compare them with the \"trans\" setting. Most of the gains are less than 1%, which is marginal. To support my concern, could the author run the fine-tuning experiment multiple times and report the variance of the results?\n\n3. Creation method of MALLS: Does the creation method possess novelty that could benefit the community and generalized to creation of other datasets? I am unable to determine this on my own."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3948/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700457513164,
                "cdate": 1700457513164,
                "tmdate": 1700457551617,
                "mdate": 1700457551617,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2R5cyDD1L4",
            "forum": "QzQSR56JZr",
            "replyto": "QzQSR56JZr",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3948/Reviewer_wVqn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3948/Reviewer_wVqn"
            ],
            "content": {
                "summary": {
                    "value": "This paper contributed the MALLS dataset and the LogicLLAMA models for natural language to first-order-logic translation tasks. The authors also describe a multi-stage training paradigm using closed-source GPT models to generate datasets for training open-source LLAM for the NL-FOL translation tasks. Experiments are conducted to demonstrate the effectiveness of the proposal."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "\u2022 Investing the possible links between large language models and logical reasoning is an important topics to advance the methodology for AI.\n\u2022 The paradigm of training open-sourced NL-FOL from open-sourced LLMs using data sourcing from close-sourced LLMs is a reasonable way to create NL-FOL models.\n\u2022 Experiments demonstrate almost start-of-the-art performance of NL-FOL tasks with the proposed LogicLLAMA model from LLAMA."
                },
                "weaknesses": {
                    "value": "\u2022 The targeting FOL language lacks a formal characterization. Is it an fully expressive First-order logic language or just the logic program subset? \n\u2022  The description of iterative correction via RLHF is difficult to follow lacking a few explicit description to task T4. In particular, it took me multiple-pass to understand why T4 is different from T3. It might worth a few rewriting to make this more explicit and easy to follow regarding the format of training data and loss functions."
                },
                "questions": {
                    "value": "1. Page 7, regarding logical equivalence, which exact semantic models of FOL do you refer to? It is better to explicitly name the exact semantic models, such as Herbrand structure/universe if there is any; otherwise there might be ambiguity rendering the FOL being just a subset of FOL --- even if only a subset of FOL is supported it is already meaningful but please be specific. \n2.  Please formally define the 4 training tasks T1-T4 with explicit input-output definitions and loss definitions (if not enough space, putting them into supplemental materials is acceptable)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3948/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699197661096,
            "cdate": 1699197661096,
            "tmdate": 1699636355404,
            "mdate": 1699636355404,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZJZRWMM68R",
                "forum": "QzQSR56JZr",
                "replyto": "2R5cyDD1L4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3948/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3948/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for your comments. We appreciate your positive feedback on our work! Our responses are as follows:\n\n\n***\u201dIs it a fully expressive First-order logic language or just the logic program subset?\u201d***\n\nYes, both MALLS dataset and LogicLLaMA are for general FOL rules. When collecting and validating the FOL rules, we do not enforce specific semantic models such as the Herbrand structure. On the logic expression level, the dataset does have some biases, where it contains more entailment-type FOL rules and fewer rules with rare logical operators such as xor. For measuring logical equivalence, we follow a similar protocol as in FOLIO[1] that converts them to propositional rules and compares the truth table.\n\n\n\n**Iterative correction presentation; input, output, and loss functions of T1-T4**\n\nThank you for the suggestions. We have included a summary of these items in Appendix C, where we summarize the input, output, and objectives of the four tasks.\n\n\n[1] Han, S., Schoelkopf, H., Zhao, Y., Qi, Z., Riddell, M., Benson, L., Sun, L., Zubova, E., Qiao, Y., Burtell, M., Peng, D., Fan, J., Liu, Y., Wong, B., Sailor, M., Ni, A., Nan, L., Kasai, J., Yu, T., \u2026 Radev, D. (2022). FOLIO: Natural Language Reasoning with First-Order Logic (arXiv:2209.00840). arXiv. http://arxiv.org/abs/2209.00840"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3948/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700168288270,
                "cdate": 1700168288270,
                "tmdate": 1700168288270,
                "mdate": 1700168288270,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T4RrwD74XJ",
                "forum": "QzQSR56JZr",
                "replyto": "ZJZRWMM68R",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3948/Reviewer_wVqn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3948/Reviewer_wVqn"
                ],
                "content": {
                    "comment": {
                        "value": "Thank the authors for making the efforts to response to my questions. After reading response, the nature of the targeting first-order logic still needs a few clarifity (e.g. whether it only supports finite domain predicates or infinite domains). Regarding the novelty, please address the concerns of other reviewers."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3948/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700727668413,
                "cdate": 1700727668413,
                "tmdate": 1700727668413,
                "mdate": 1700727668413,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]