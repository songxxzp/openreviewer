[
    {
        "title": "FreeDyG: Frequency Enhanced Continuous-Time Dynamic Graph Model for Link Prediction"
    },
    {
        "review": {
            "id": "lqqT7ZCded",
            "forum": "82Mc5ilInM",
            "replyto": "82Mc5ilInM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1591/Reviewer_VgR1"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1591/Reviewer_VgR1"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors considered the temporal link prediction task on continuous-time dynamic graph (CTDG) and proposed a novel FreeDyG method, which to my knowledge, is the first work to use a frequency-based discrete Fourier transform (DFT) to capture the evolving patterns of CTDG. The overall presentation of this paper is clear. The experiments are also comprehensive and sufficient that can validate the effectiveness of FreeDyG."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1. The overall presentation of this paper is clear, which is easy to grasp the key ideas.\n  \nS2. Using the frequency-based Fourier transform to capture the evolving patterns of dynamic graphs is novel and interesting.\n\nS3. The authors conducted comprehensive and sufficient experiments covering both transdutive and inductive settings of temporal link prediction."
                },
                "weaknesses": {
                    "value": "**W1. From my perspective, some of the motivations regarding model designs need further verification or validation.**\n  \nIn Section 1, the authors argued that RW, TPP, and ODE are computationally expensive. However, the proposed method includes a sampling procedure that samples $L$ first-hop historical neighbors for both source and target nodes. It seems that such a sampling procedure has a complexity similar to those of conventional methods (e.g., RW-based and PPT-based), according to my background knowledge. To verify this motivation, is is recommended to add the comparison of time complexity for sampling/feature extraction in both training and testing phases.\n  \nIt is also suggested to add pseudocode of each procedure (e.g., first-hop historical neighbors sampling, FFT, extraction of node interaction frequency, etc.) even in the appendix since the details of some modules in current version of manuscript are still unclear.\n  \nMoreover, the authors claimed that self-attention acts as persistent low-pass filter and the utilization of DFT can tackle its limitation. How this superiority of the proposed method is validated in the experiments?\n\n***\n\n**W2. As stated in Section 2, the authors only considered CTDG with edge addition events. It seems that the proposed method cannot handle the deletion of edges.**\n  \n***  \n\n**W3. It semes that there are some inconsistent and unclear statements.**\n  \nIn Eq. (1) $n$ starts from 0 but in the 2nd paragraph of Section 2, the authors defined that ${x_n}_{n=1}^N$, where $n$ starts from 1. It is also similar for $ {X_k} _{k=1}^N$.\n  \nIn the 2nd paragraph of Section 3.1, the definitions of $\\alpha$ and $\\beta$ are not given.\n  \nIn Eq. (11), what is the dimensionality setting of $W^{agg}$? It is still unclear how to derive a vector $h_*^t$ based on a matrix $Z_*^l$. Moreover, there is no $t$ in the right side of Eq. (11) but how can we know $t$ in the left side?\n \n***\n\n**W4. There are also some minor errors.**\n\ne.g., 'In addition, We specifically encode' > 'In addition, we specifically encode'"
                },
                "questions": {
                    "value": "According to my background knowledge, a significant property of CTDG is that the difference between two successive time steps can be irregular. However, as shown in Table 4, each dataset has an item 'Duration'. What does this item mean? Does is mean that the time steps of all the datasets are still regularly spaced?\n  \n  In some previous studies, the inductive settings include the prediction between (i) one previously observed node and one newly added node as well as (ii) between two new nodes. It is unclear that the inductive setting in this study refers to which case?\n  \n  According to my understanding, the inductive inference of the proposed method and other baselines relies on the availability of graph attributes (i.e., node and edge attributes in this study). Consider an extreme case, when attributes are unavailable, can the proposed method still support the inductive temporal link prediction?\n  \n  In addition to the commonly used settings of temporal link prediction in this study (i.e., the prediction of unweighted feature links), there are some other studies considered the advanced temporal link prediction tasks for weighted dynamic graphs [1-4], which should not only determine the existence of a future link but also the corresponding edge weight. Can the proposed method be extended to handle such an advanced settings?\n  \n  [1] GCN-GAN: A Non-linear Temporal Link Prediction Model for Weighted Dynamic Networks. IEEE InfoCOM, 2019.\n\n  [2] An Advanced Deep Generative Framework for Temporal Link Prediction in Dynamic Networks. IEEE IEEE Transactions on Cybernetics, 2020.\n\n  [3] High-Quality Temporal Link Prediction for Weighted Dynamic Graphs via Inductive Embedding Aggregation. IEEE TKDE, 2023.\n\n  [4] Temporal link prediction: A unified framework, taxonomy, and review. ACM Computing Surveys, 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1591/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698487143330,
            "cdate": 1698487143330,
            "tmdate": 1699636087793,
            "mdate": 1699636087793,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OlHN7dIavQ",
                "forum": "82Mc5ilInM",
                "replyto": "lqqT7ZCded",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, and they are exceedingly helpful for us to improve our paper. We have carefully incorporated them in the revised paper. \nIn the following, your comments are first stated and then followed by our point-by-point responses.\n\n**W1. From my perspective, some of the motivations regarding model designs need further verification or validation.**\n\nResponse: Thank you for your comments. We give our point-by-point responses as follows:\n\n(1) The FreeDyG model employs a sampling strategy that differs from other methods. Specifically, it involves directly sampling a fixed number of first-order neighbors from the historical interactions of the target node, prioritizing their temporal proximity. This is achieved by selecting the $L$ most recent neighbors from the historical interactions, a process with a time complexity of $O(1)$. \nAs a result, the sampling method used in FreeDyG is more efficient than RW-based and TPP-based.\n\n(2) We have added the pseudocode of our algorithm in Appendix D of the revised paper. Please refer to Algorithm 1 and Algorithm 2.\n\n\n(3) Further experiments are carried out to demonstrate the efficiency of our filter layer. \nSpecifically, we replace the frequency-enhanced MLP-Mixer layer with Transformer and RNN models to compare their performances, as detailed in the following table. \nFollowing reviewer Gxoa's recommendation, we employ the micro-F1 score as the evaluation metric. \nThe results reveal that our FreeDyG model, equipped with the filter layer, delivers the highest performance across all datasets.\n|              | Wiki                | Reddit              | MOOC                | LastFM              | Enron               | Social Evo          | UCI                  |\n|--------------|---------------------|---------------------|---------------------|---------------------|---------------------|---------------------|----------------------|\n| **FreeDyG**  | **95.92 \u00b1 0.09**    | **96.03 \u00b1 0.07**    | **76.74 \u00b1 0.97**    | **88.89 \u00b1 0.38**    | **88.91 \u00b1 0.20**    | **93.87 \u00b1 0.07**    | **90.25\u00b1 0.08**      |\n| Transformer  | _94.83 \u00b1 0.13_      | _95.89 \u00b1 0.14_      | _74.89 \u00b1 1.20_      | _87.57 \u00b1 0.38_      | 87.01 \u00b1 0.39        | _92.86 \u00b1 0.24_      | _88.32\u00b1 0.64_        |\n| RNN          | 93.94 \u00b1 0.31        | 95.03 \u00b1 0.20        | 74.31 \u00b1 1.18        | 87.19 \u00b1 0.75        | _87.74 \u00b1 0.61_      | 92.23 \u00b1 0.29        | 87.85\u00b1 0.58          |\n\n\n**W2. As stated in Section 2, the authors only considered CTDG with edge addition events. It seems that the proposed method cannot handle the deletion of edges.**\n\nResponse: Thank you for your comment. \nOur method FreeDyG currently can not handle the deletion of edges. As described in the Conclusion, we plan to expand our research to include edge deletion in future works.\n\n**W3. It seems that there are some inconsistent and unclear statements**\n\nResponse: Thank you for your feedback. \nIn the revised paper, we have addressed and corrected all inconsistencies and ambiguities. The adjustments made are as follows:\n\n(1) In Eq. (1), we have modified the starting point of $n$ to begin from $1$.\n\n(2) The hyperparameters $\\alpha$ and $\\beta$ are set to ensure that $t_{max} \\times \\alpha^{-(i-1) / \\beta}$ approaches 0. The time encoding method used in our study is sourced from GraphMixer, as detailed in their publication available at [https://arxiv.org/pdf/2302.11636.pdf]. \nFor more comprehensive information on this, please refer to the GraphMixer documentation.\nIn our experiments, we have chosen the values of both $\\alpha$ and $\\beta$ to be 10.\n\n(3) The parameter $\\mathbf{W^{agg}}\\in \\mathbb{R}^{1 \\times L}$ is a trainable parameter that is designed to adaptively determine the significance of various interactions. \nWith $\\mathbf{W^{agg}}$, we transform matrix $Z_*^l$ into vector $h_*^t$ with Equ. (11).\nAdditionally, the inconsistency in the superscript $t$ arises from its omission in Section 3.1 for simplicity's sake. \nThose $Z_*^l$ is short for $Z_*^{l,t}$.\nWe apologize for any confusion this may have caused."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1591/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700650680189,
                "cdate": 1700650680189,
                "tmdate": 1700650940647,
                "mdate": 1700650940647,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Rvsa1NInrO",
            "forum": "82Mc5ilInM",
            "replyto": "82Mc5ilInM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1591/Reviewer_VGzm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1591/Reviewer_VGzm"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a new GNN for CTDG. The concept of Node Interaction Frequency (NIF) Encoding appears to be a simplified version of SEAL, a link prediction technique for static graphs, and it further introduces a frequency-enhanced MLP-Mixer layer that has functions of Fourier transform and inverse transform with weight learning. Evaluation is conducted in various experimental settings, including transductive/inductive and three negative sampling strategies."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "S1. The overall architecture is well-designed. Of particular interest, the Node Interaction Frequency (NIF) Encoding and frequency-enhanced MLP-Mixer layer are novel and highly effective.\n\nS2. The proposal achieves performance higher than the state-of-the-art. Particularly, achieving high efficiency and high quality is impressive. The ablation study verifies that each technical component is effective for high accuracy. \n\nS3. The experimental settings are detailed, encompassing evaluation experiments across 9 methods, 7 real-world datasets, and various settings including transductive/inductive and three negative sampling strategies."
                },
                "weaknesses": {
                    "value": "W1. Since the proposal's effectiveness varies across datasets, it is essential to discuss the impact of Node Interaction Frequency (NIF) Encoding and the frequency-enhanced MLP-Mixer layer by investigating the characteristics of each dataset. For instance, if a certain dataset is known to exhibit periodicity, it would be reasonable to understand the benefits of the frequency-enhanced MLP-Mixer layer. Similarly, an analysis should be conducted to determine which data characteristics justified the effectiveness of NIF Encoding.\n\nW2. Some design decisions are not clear. For example, while it is crucial that F^t_* represents common neighbors and their past interactions, further explanation is needed regarding the idea behind Equation 3.\n\nW3. The equation transformation involving w_k^{(t)} in Equation (9) is not clear. Additional clarification is necessary to understand this transformation."
                },
                "questions": {
                    "value": "Q1. It would be valuable to discuss how the proposal outperforms other approaches, such as using RNN or transformers, which are known to capture some temporal patterns. This comparison can provide insights into the superior performance of the proposal.\n\nQ2. Could you please clarify whether the optimization is conducted in an end-to-end fashion?\n\nQ3. What is the mean of the circle sizes in Figure 2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Reviewer_VGzm"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1591/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698790384543,
            "cdate": 1698790384543,
            "tmdate": 1699636087717,
            "mdate": 1699636087717,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xfrKnnohwl",
                "forum": "82Mc5ilInM",
                "replyto": "Rvsa1NInrO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, and they are exceedingly helpful for us to improve our paper. We have carefully incorporated them in the revised paper. \nIn the following, your comments are first stated and then followed by our point-by-point responses.\n\n**W1: Since the proposal's effectiveness varies across datasets, it is essential to discuss the impact of Node Interaction Frequency (NIF) Encoding and the frequency-enhanced MLP-Mixer layer by investigating the characteristics of each dataset. For instance, if a certain dataset is known to exhibit periodicity, it would be reasonable to understand the benefits of the frequency-enhanced MLP-Mixer layer. Similarly, an analysis should be conducted to determine which data characteristics justified the effectiveness of NIF Encoding.**\n\nResponse: Thank you for your question. \nThe ablation study experiments depicted in Figure 3 were conducted under the random negative sampling setting, where the target node of a negative edge is sampled from the entire graph. In this setting, the negative samples are significantly easier to distinguish, and the model tends to predict future interactions between node pairs that have interacted previously. Consequently, the NIF encoding, which captures neighbor interactions, assumes a more critical role.\n\nFurthermore, the following table presents additional experimental results from the ablation study conducted using the historical negative sampling setting. In this setting, the target node of a negative edge is sampled from the source node's historical neighbors. It is evident that the FE component holds greater significance in this setting. The reason behind this is that in this setting, the NIF encoding may introduce more false positives on negative samples, necessitating the importance of FE in capturing temporal pattern or shifting signals. For more detailed information, please refer to Figure 5 in the revised version of the paper.\n|              | Wiki                  | Reddit               | MOOC                 | LastFM               | Enron                | Social Evo           | UCI                   |\n|--------------|-----------------------|----------------------|----------------------|----------------------|----------------------|----------------------|-----------------------|\n| **FreeDyG**      | **91.59 \u00b1 0.57**      | **85.67 \u00b1 1.01**     | **86.71 \u00b1 0.81**     | **79.71 \u00b1 0.51**     | **78.87 \u00b1 0.82**     | **97.79 \u00b1 0.23**     | **86.10\u00b1 1.19**       |\n| w/o NIF      | 90.01 \u00b1 0.21          | 82.51 \u00b1 1.22         | 84.64 \u00b1 1.13         | 76.61 \u00b1 0.50         | 77.28 \u00b1 1.29         | 96.01 \u00b1 0.30         | 85.11\u00b1 1.07           |\n| w/o FE       | 87.31 \u00b1 0.31          | 81.79 \u00b1 0.75         | 85.01 \u00b1 1.18         | 76.54 \u00b1 0.62         | 75.74 \u00b1 0.61         | 96.43 \u00b1 0.20         | 83.09\u00b1 1.54           |\n\n**W2.Some design decisions are not clear. For example, while it is crucial that $F^t_*$ represents common neighbors and their past interactions, further explanation is needed regarding the idea behind Equation 3.**\n\nResponse: Thank you for your comments. \nIn our study, we utilize $F^t_u$ to denote the historical common neighbors between node $u$ and $v$. Diverging from previous approaches that only calculate the count of common neighbors, our model defines $F^t_u$ as a 2-dimensional vector aimed at capturing the temporal patterns concealed within these common neighbors. \nThe motivation of Equation 3 is straightforward. We use a sum pooling operation to consolidate the count information (which is mapped to a vector with dimension $d_F$ by function $f$) pertaining to common neighbors of nodes $u$ and $v$ and interaction frequency between nodes $u$ and $v$.\n\n**W3. The equation transformation involving $w_k^{(t)} $in Equation (9) is not clear. Additional clarification is necessary to understand this transformation.**\n\nResponse: Thank you for your feedback. \nIn Equation (9), we have $w_k^{(t)} = \\sum_{m=1}^{N} h_m^{(t)} e^{-\\frac{2 \\pi i}{N} k m}$.\nThe description has been incorporated into the revised paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1591/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651308917,
                "cdate": 1700651308917,
                "tmdate": 1700651620147,
                "mdate": 1700651620147,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "m4kNIYyoNP",
                "forum": "82Mc5ilInM",
                "replyto": "xfrKnnohwl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1591/Reviewer_VGzm"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1591/Reviewer_VGzm"
                ],
                "content": {
                    "comment": {
                        "value": "The authors' response clarifies all of my concerns."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1591/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700702500628,
                "cdate": 1700702500628,
                "tmdate": 1700702500628,
                "mdate": 1700702500628,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YesuCJe589",
            "forum": "82Mc5ilInM",
            "replyto": "82Mc5ilInM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1591/Reviewer_Gxoa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1591/Reviewer_Gxoa"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel method called FreeDyG for link prediction in dynamic graphs. The method devised a novel frequency-enhanced MLP-Mixer layer to learn the periodic temporal patterns and the \u201dshift\u201d phenomenon present in the frequency domain. The effectiveness of the FreeDyG model was validated on several real-world datasets, showing performance improvement in AUC-ROC against baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed frequency-enhanced MLP-Mixer is novel and effective.\n2. The experiments of link prediction are comprehensive. It is conducted on seven datasets and compares the performance against 9 baselines in two dynamic settings, which is solid and comprehensive to validate the effectiveness of FreeDyG in link prediction.\n3. The paper is well written, especially the problem formulation and methodologies."
                },
                "weaknesses": {
                    "value": "1. The motivation of delving into the frequency domain needs to be further clarified. I am wondering about the intuitions behind capturing the \u201dshift\u201d phenomenon hidden in the frequency domain.\n2. The authors claim that FreeDyG is the first work that considers the frequency information for dynamic graph embedding, which is overclaimed.\n3. The authors argue that random walk based approaches are computationally expensive. However, conducting Fourier transform are also very computationally expensive. In addition, I think FreeDyG also relied on some random walk based approach to obtain the continuous-time dynamic graph from the raw graph data.\n4. The proposed FreeDyG seems computationally expensive. However, there is no time complexity analysis. The authors are suggested to present the time complexity empirically or theoretically.\n5. In a dynamic graph, some nodes will have more edges, but others will have fewer. Using AUC-ROC as the evaluation metrics cannot tell how good the performance of link prediction for minority nodes. I suggest reporting the Micro- and Macro-F1 scores in the link prediction tasks."
                },
                "questions": {
                    "value": "1. Why does this work only focus on the link prediction? How is applying this work applicable to other graph mining tasks like node classifications?\n2. For the LastFM, what is the summit of the performance when sampling more neighbor nodes? Could you please clarify the experiment details about training every baseline using the same amount of information as FreeDyG in the experiments?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Reviewer_Gxoa"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1591/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698805565782,
            "cdate": 1698805565782,
            "tmdate": 1700705995801,
            "mdate": 1700705995801,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lHJ90kO2LA",
                "forum": "82Mc5ilInM",
                "replyto": "YesuCJe589",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, and they are exceedingly helpful for us to improve our paper. We have carefully incorporated them in the revised paper. \nIn the following, your comments are first stated and then followed by our point-by-point responses.\n\n**W1:The motivation of delving into the frequency domain needs to be further clarified. I am wondering about the intuitions behind capturing the 'shift phenomenon hidden in the frequency domain.**\n\nResponse: Thank you for your suggestion. \nIn the field of time series analysis, examining the frequency domain has become a popular method for effectively capturing temporal signals over time. Similarly, continuous-time graph data also display temporal signals, such as the occurrence of 'shift' phenomena. These phenomena involve significant changes in the interaction patterns of nodes at specific moments. These changes in the connection patterns often result in outlier values or sudden variations in the representation vector $Z^t_*$. The basic idea of our model is straightforward: we aim for our adaptive frequency filter to capture the frequency patterns associated with temporal outliers or sudden changes.\n\n\n**W2:The authors claim that FreeDyG is the first work that considers the frequency information for dynamic graph embedding, which is overclaimed.**\n\nResponse: Thank you for pointing out this problem. We have reorganized our statement in the revised paper as follows: *Instead of the temporal domain, FreeDyG tries to address this problem by delving into the frequency domain*.\n\n\n**W3:The authors argue that random walk based approaches are computationally expensive. However, conducting Fourier transform is also very computationally expensive. In addition, I think FreeDyG also relied on some random walk based approach to obtain the continuous-time dynamic graph from the raw graph data.**\n\nResponse: Thank you for your comments.\n\n**Time complexity of Fourier transform:** The time complexity of the Fast Fourier Transform (FFT) is given by $O(L \\log L)$, where $L$ represents the number of sampled neighbors from historical interactions. When it comes to random walk-based methods such as CAWN, the primary computational cost lies not in the sampling process, but rather in how they utilize these walks. \nSpecifically, after getting multiple walks, CAWN uses RNN to encode each walk as a representation and uses self-attention to aggregate the representations of multi-walks into a single vector for downstream tasks. In Figure 2, we present a comparison between our approach, FreeDyG, and the random walk-based method CAWN. It is worth noting that the training time required for CAWN on Wikipedia is double that of FreeDyG. More specifically, FreeDyG and CAWN take $67$ and $150$ seconds per training epoch, respectively. Furthermore, when applied to larger datasets such as Reddit, CAWN incurs a significantly higher time cost in comparison to FreeDyG.\n\n**Sampling strategy of FreeDyG:** The FreeDyG model employs a sampling strategy that differs from random walk-based approaches. Specifically, it involves directly sampling a fixed number of first-order neighbors from the historical interactions of the target node, prioritizing their temporal proximity. This is achieved by selecting the $L$ most recent first-hop neighbors from the historical interactions, a process with a time complexity of $O(1)$. \n\n**Raw graph data:** The continuous-time dynamic graph is defined as a chronological sequence of interactions between specific node pairs as explained in Section 2. \nFor our experiments, the raw graph data is also organized in the form of an edge list, consisting of source nodes, target nodes, and timestamps. As a result, there is no need for additional operations to derive the continuous-time dynamic graph from the raw graph data."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1591/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700649323888,
                "cdate": 1700649323888,
                "tmdate": 1700650230961,
                "mdate": 1700650230961,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "R3CUD3KVwl",
                "forum": "82Mc5ilInM",
                "replyto": "YesuCJe589",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W4: The proposed FreeDyG seems computationally expensive. However, there is no time complexity analysis. The authors are suggested to present the time complexity empirically or theoretically.**\n\nResponse: Let $L$ represent the number of sampled neighbors and $d$ denote the dimension of the embdedding size. Our FreeDyG model comprises several components, each with its respective time complexity. The sampling process, which acquires the $L$ most recent neighbors, exhibits a time complexity of $O(1)$, while the encoding module operates at a time complexity of $O(Ld)$. The time complexity of the filter layer is determined by the FFT and IFFT operations, which amount to $O(L \\log L)$. Additionally, the MLP-Mixer layer has a time complexity of $O(Ld)$. Consequently, the overall time complexity of FreeDyG is at most $O(L \\log Ld)$. We note that the time complexity of our FreeDyG is lower than the self-attention with $O(L^2 d)$.\nFigure 2 in our experimental analysis displays the performance of all competing methods, along with their corresponding training time and parameter size. Notably, our FreeDyG outperforms all other approaches, achieving the highest performance while maintaining a moderate training cost.\n\n**W5:In a dynamic graph, some nodes will have more edges, but others will have fewer. Using AUC-ROC as the evaluation metrics cannot tell how good the performance of link prediction for minority nodes. I suggest reporting the Micro- and Macro-F1 scores in the link prediction tasks.**\n\nResponse: Thank you for your suggestion. \nThe results for Micro-f1 and Macro-f1 scores across all competitors are presented in Tables 7-10 in revised paper. These outcomes align with the findings from AP and AUC-ROC measurements. Notably, our model FreeDyG demonstrates superior performance compared to other baseline models in a majority of the test cases. The average ranking of FreeDyG approximates to 1 in most settings, significantly outstripping its closest competitor, DyGFormer.\n\n**Q1.Why does this work only focus on the link prediction? How is applying this work applicable to other graph mining tasks like node classifications?**\n\nResponse: Thank you for your comments.\nIn this paper, our primary focus is on the task of link prediction using the proposed method. Nonetheless, by altering the task layer and loss function settings, it can also be adapted for node classification tasks. We have performed experiments for node classification on the Wiki dataset with metric AUC-ROC (experiments on other datasets are still running). The results indicate that our method outperforms most baseline models.\n|             | **JODIE**         | DyRep            | TGAT             | TGN              | CAWN             | TCL              | GraphMixer       | DyGFormer        | FreeDyG          |\n|-------------|-------------------|------------------|------------------|------------------|------------------|------------------|------------------|------------------|------------------|\n| **Wiki**    | **88.78 \u00b1 1.13**  | 86.35 \u00b1 1.27 | 84.43 \u00b1 1.46 | 86.27 \u00b1 2.09  | 85.41 \u00b1 1.51  | 76.91 \u00b1 1.99  | 86.59 \u00b1 0.88 | 87.44 \u00b1 1.08     | _87.87 \u00b1 1.13_   |\n\n**Q2.For the LastFM, what is the summit of the performance when sampling more neighbor nodes? Could you please clarify the experiment details about training every baseline using the same amount of information as FreeDyG in the experiments?**\n\nResponse:  Thank you for your comments. We have conducted experiments with Micro-F1 metric on LastFM with $L=10,20,32,64,100,128, 160, 200$ in the following table.\nWe can see that LastFM exhibits optimal performance when $L=100$. \nThis requirement for a larger number of historical neighbors in LastFM is attributed to its higher average node degree, quantified as $|\\mathcal{E}|/|\\mathcal{V}|=653$. \nwhich is considerably higher compared to other datasets such as Reddit ($61$), Wiki ($17$), and MOOC ($57$).\n|        | L=10           | L=20           | L=32           | L=64           | L=100          | L=128          | L=160          | L=200          |\n|--------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|\n| LastFM | 81.28 \u00b1 0.71   | 84.63 \u00b1 0.43   | 88.06 \u00b1 0.49   | 87.76 \u00b1 0.44   | **88.89 \u00b1 0.38** | 88.84 \u00b1 0.39   | 88.27 \u00b1 0.51   | 88.20 \u00b1 0.42   |"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1591/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700649722068,
                "cdate": 1700649722068,
                "tmdate": 1700651464550,
                "mdate": 1700651464550,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JouZ2yQiQT",
                "forum": "82Mc5ilInM",
                "replyto": "R3CUD3KVwl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1591/Reviewer_Gxoa"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1591/Reviewer_Gxoa"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for providing a more comprehensive evaluation which is very helpful to understand the usefulness of the proposed FreeDyG. I am raising my score to 6."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1591/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706075468,
                "cdate": 1700706075468,
                "tmdate": 1700706075468,
                "mdate": 1700706075468,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SFZxddrVct",
            "forum": "82Mc5ilInM",
            "replyto": "82Mc5ilInM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1591/Reviewer_Wgp4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1591/Reviewer_Wgp4"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose the FreeDyG graph neural network (GNN) model for continuous-time dynamic graphs. It incorporates frequency-based representations of the nodes to attempt to capture periodic patterns in the dynamic graph. It also contains a novel node interaction frequency encoding approach. The authors demonstrate impressive link prediction accuracy in both transductive and inductive settings compared to other GNNs for dynamic graphs on a variety of real data sets. They also perform favorably in terms of training time and size of the trained model when compared to other methods.\n\n*After author rebuttal:* The authors have partially addressed my concerns in their rebuttal and revision, particularly regarding the usefulness of the frequency encoding. After reading through the other reviews, I am still in support of this paper."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Proposed FreeDyG model contains several novel elements, including the design of the node interaction frequency (NIF) encoding and incorporating frequency-based representations.\n- Comparison of accuracy, training time, and model size shown in Figure 2 is a nice inclusion. This shows that improvements in accuracy are not at the cost of significantly increased training time or a very large model.\n- Strong improvements in accuracy compared to other approaches. These improvements hold over different negative sampling strategies and evaluation metrics.\n- Mostly well written and organized paper. In my opinion, the authors made good choices on which results and details should be presented in the main paper rather than the appendices."
                },
                "weaknesses": {
                    "value": "- The positioning of the paper is a bit deceiving. From reading the paper, it would appear as though the main contribution is incorporating the frequency information. However, from the results of the ablation study in Figure 3, we see that the NIF encoding plays a much bigger role in improving accuracy than the frequency-based representations.\n- The authors present no evidence that the frequency-based representations are actually able to capture periodic patterns, which they used as their motivation for using the FFT.\n\nMinor concerns:\n- Table 3 is probably not the best way to present the hyperparameter study. Typically, one would be looking for trends as you vary the number of historical neighbors $L$. Such trends are difficult to pick out from the table. I would suggest instead using plots with AP or AUC-ROC on one axis and $L$ on the other.\n- Page 7, second last paragraph: \"neigh encoding\""
                },
                "questions": {
                    "value": "1. Is there a way you could inspect your trained model to identify whether any type of periodic patterns are being captured by your frequency-enhanced MLP-Mixer layer?\n2. Why is the NIF encoding more important than the frequency-based representations for improving link prediction accuracy?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1591/Reviewer_Wgp4"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1591/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698973690615,
            "cdate": 1698973690615,
            "tmdate": 1700704575225,
            "mdate": 1700704575225,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "72G54F9RCl",
                "forum": "82Mc5ilInM",
                "replyto": "SFZxddrVct",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1591/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your constructive comments and suggestions, and they are exceedingly helpful for us to improve our paper. We have carefully incorporated them in the revised paper.\nIn the following, your comments are first stated and then followed by our point-by-point responses.\n\n**Concerns 1: Table 3 is probably not the best way to present the hyperparameter study. Typically, one would be looking for trends as you vary the number of historical neighbors. Such trends are difficult to pick out from the table. I would suggest instead using plots with AP or AUC-ROC on one axis and on the other.\\***\n\nResponse: Thank you for your suggestion. In Appendix D of the revised paper, we use Figure 4 to show the trends of AP along different numbers of sampled historical first-hop neighbors.\n\n**Concerns 2: Page 7, second last paragraph: \"neigh encoding\"**\n\nResponse: Thank you for pointing out the typo error, we have fixed it in the revised paper.\n\n**Q1: Is there a way you could inspect your trained model to identify whether any type of periodic patterns are being captured by your frequency-enhanced MLP-Mixer layer?**\n\nResponse: Thank you for your comments. The frequency-enhanced MLP-Mixer layer is used to capture the periodic and shift patterns among the representation space of the historical first-hop neighbors.\nDifferent from the time series analysis problem, the periodic patterns in the hidden space of a graph may be caused by multiple interaction patterns between nodes such as repeated interactions with the same node, similar frequency of interactions, or even high-order statistic repetition.\n\n**Q2: Why is the NIF encoding more important than the frequency-based representations for improving link prediction accuracy?**\n\nResponse: Thank you for your question.\nThe ablation study experiments depicted in Figure 3 were conducted under the random negative sampling setting, where the target node of a negative edge is sampled from the entire graph. In this setting, the negative samples are significantly easier to distinguish, and the model tends to predict future interactions between node pairs that have interacted previously. Consequently, the NIF encoding, which captures neighbor interactions, assumes a more critical role.\n\nFurthermore, the following table presents additional experimental results from the ablation study conducted using the historical negative sampling setting. In this setting, the target node of a negative edge is sampled from the source node's historical neighbors. It is evident that the FE component holds greater significance in this setting. The reason behind this is that in this setting, the NIF encoding may introduce more false positives on negative samples, necessitating the importance of FE in capturing temporal or shifting signals. For more detailed information, please refer to Figure 5 in the revised version of the paper.\n|              | Wiki                  | Reddit               | MOOC                 | LastFM               | Enron                | Social Evo           | UCI                   |\n|--------------|-----------------------|----------------------|----------------------|----------------------|----------------------|----------------------|-----------------------|\n| **FreeDyG**      | **91.59 \u00b1 0.57**      | **85.67 \u00b1 1.01**     | **86.71 \u00b1 0.81**     | **79.71 \u00b1 0.51**     | **78.87 \u00b1 0.82**     | **97.79 \u00b1 0.23**     | **86.10\u00b1 1.19**       |\n| w/o NIF      | 90.01 \u00b1 0.21          | 82.51 \u00b1 1.22         | 84.64 \u00b1 1.13         | 76.61 \u00b1 0.50         | 77.28 \u00b1 1.29         | 96.01 \u00b1 0.30         | 85.11\u00b1 1.07           |\n| w/o FE       | 87.31 \u00b1 0.31          | 81.79 \u00b1 0.75         | 85.01 \u00b1 1.18         | 76.54 \u00b1 0.62         | 75.74 \u00b1 0.61         | 96.43 \u00b1 0.20         | 83.09\u00b1 1.54           |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1591/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647582791,
                "cdate": 1700647582791,
                "tmdate": 1700659421039,
                "mdate": 1700659421039,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]