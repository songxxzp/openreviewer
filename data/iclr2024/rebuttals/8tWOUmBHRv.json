[
    {
        "title": "Offline Tracking with Object Permanence"
    },
    {
        "review": {
            "id": "l4jONW0I24",
            "forum": "8tWOUmBHRv",
            "replyto": "8tWOUmBHRv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5425/Reviewer_SgKx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5425/Reviewer_SgKx"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces an offline tracking method utilizing point clouds, specifically designed to handle challenging heavy occlusions on vehicles. This method comprises three key components: a tracker, a Re-ID module for linking trackless segments before and after occlusions, and a track completion module that interpolates missing tracks caused by occlusions. The study showcases the method's efficacy in tracking objects even under conditions of occlusion."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper proposes a method to handle the occluded object tracking."
                },
                "weaknesses": {
                    "value": "The paper has limited novelty. The tracker, Re-ID, and track completion components all employ established techniques, resulting in a relatively straightforward solution."
                },
                "questions": {
                    "value": "1. In tracklet association, there appears to be a division between the utilization of map and motion data. However, it's worth considering their complementary contributions. For instance, map information could enhance the accuracy of motion association. Separating these aspects might lead to a loss of crucial information.\n2. Appearance features could serve as a pivotal factor in tracklet association. Even when an object becomes temporarily occluded and untrackable, its re-emergence could still benefit from utilizing appearance data for accurate association.\n3. Considering the use of map information, it's important to assess its impact on association when an object undergoes occlusion and a simultaneous lane change. This scenario introduces an additional layer of complexity that warrants thorough investigation."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5425/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698508154217,
            "cdate": 1698508154217,
            "tmdate": 1699636551163,
            "mdate": 1699636551163,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CnIgtJBHiE",
                "forum": "8tWOUmBHRv",
                "replyto": "l4jONW0I24",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5425/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission5425/Reviewers/Submitted"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5425/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Addressing the questions"
                    },
                    "comment": {
                        "value": "Thanks a lot for your questions! Here are some concise responses to them.\n\n1. Indeed, the fusion of the two features can theoretically improve performance. That is also exactly what we did. In the map branch of the Re-ID model, the map feature is fused with the motion feature via spatial attention [1]. So the map branch takes both motion information and map information as inputs.\n\n2. Thanks for your suggestion! We have also tried to extract appearance features from point clouds for Re-ID. We used the same technique for point cloud aggregation as in [2], only that we used CenterPoint [3] as the feature extractor. Then we applied contrastive learning to learn the appearance affinity between the appearance features of tracklets in a latent space. However, the result is not satisfying so we eventually abandoned this. We think this is because the model can only implicitly extract the object size information from the point cloud and learns the affinity based on this, which is not accurate. The location and motion information in point clouds are also provided by the motion feature. That is also the reason why the appearance feature extracted from the point cloud is mainly used to refine the bounding box size in [2,4]. However, we are planning to explore a more effective way to extract it so that it can help tracklet association. A more trivial way is to use extract appearance feature from camera images, which contains much richer appearance information for Re-ID. \n\n3. Indeed, lane change under occlusion would be an interesting scenario for the evaluation of our model. We will add this to our evaluation in the future! \n\n[1] Ming Liang, Bin Yang, Rui Hu, Yun Chen, Renjie Liao, Song Feng, and Raquel Urtasun. Learning lane graph representations for motion forecasting. In ECCV, pp. 541\u2013556. Springer, 2020.\n\n[2] Bin Yang, Min Bai, Ming Liang, Wenyuan Zeng, and Raquel Urtasun. Auto4d: Learning to label 4d objects from sequential point clouds. arXiv preprint arXiv:2101.06586, 2021.\n\n[3] Tianwei Yin, Xingyi Zhou, and Philipp Krahenbuhl. Center-based 3d object detection and tracking. In CVPR, pp. 11784\u201311793, 2021.\n\n[4] Charles R Qi, Yin Zhou, Mahyar Najibi, Pei Sun, Khoa Vo, Boyang Deng, and Dragomir Anguelov. Offboard 3d object detection from point cloud sequences. In CVPR, pp. 6134\u20136144, 2021."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5425/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700728887605,
                "cdate": 1700728887605,
                "tmdate": 1700728887605,
                "mdate": 1700728887605,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NVlxpeFUPL",
            "forum": "8tWOUmBHRv",
            "replyto": "8tWOUmBHRv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5425/Reviewer_tT1W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5425/Reviewer_tT1W"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a non-causal MOT technique for labelling large datasets in autonomous driving without human intervention. The technique reconsiders three well-known steps: 1) finding tracklets using causal MOT, 2) associating those tracklets by Re-ID and 3) trajectory completion compensating occlusions. The authors propose novel neural models for each step, including bipartite matching for association. The paper is well structured and readable; the literature research at least shows recent work to compare with."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper shows an elaborated approach to noncausal MOT. The neural models used seem innovative and novel and the attempt to combine tracklet association with a priori knowledge of lane maps in one end-to-end framework is promising."
                },
                "weaknesses": {
                    "value": "Unfortunately, the paper is difficult to understand for the reader. Many details are presented in a course to a more detailed manner.\nAfter reading the paper, it is not clear what exactly the contribution is. The idea of using object permanence for tracking has been introduced previously (Tokmakov et al.). The three steps of MOT are not new (Zhang, Li, Nevatia, Global Data Association for Multi-Object Tracking Using Network Flows, 2012).\nThe neural models seem novel. However, the claim in the abstract that the new models improve IDS by 45% is not confirmed by the experimental results. Table 2 shows the causal MOT of Wang et al., 2021 with 109 IDS better than the proposed method with 147+ depending on the version. The performance measures do not show significant evidence for improvement over the causal MOT approach, neither for table 1 nor for table 3."
                },
                "questions": {
                    "value": "Considering the result of your experiments, as shown in table 1 - 3, why is the proposed method superior to the compared causal trackers?\nWhy is the proposed method better suited for offline labelling than the online trackers?\nDoes the proposed methods with approx. AMOTP 0.603 and IDS 145 allow the labelling of datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5425/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698773911008,
            "cdate": 1698773911008,
            "tmdate": 1699636551045,
            "mdate": 1699636551045,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "tJ5MpSYviV",
            "forum": "8tWOUmBHRv",
            "replyto": "8tWOUmBHRv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5425/Reviewer_GvzN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5425/Reviewer_GvzN"
            ],
            "content": {
                "summary": {
                    "value": "To track occluded objects, this paper proposes an offline tracking framework, including an online tracker to generate initial tracklets, a reid module to associate tracklets, and a track completion module to complete the fragmented tracks. Through aggregating and decoding outputs from several different encoders, the track completion model will output the final refined trajectory. Experiments are performed on nuScenes dataset with different evaluation setups."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed framework is novel, which embeds both the motion and lane map to obtain the final matching matrix, and also fuses the time query embeddings to implement the trajectory regression.\n2. This paper evaluates the proposed method under different evaluation setups, which demonstrate the effectiveness of the method more clearly in addressing occlusion situations."
                },
                "weaknesses": {
                    "value": "1. Experiments are only performed on the validation split of nuScene dataset, and compared with few SOTA methods, which lack evidence of its effectiveness to some extent.\n\n2. Based on Table1&2, the effect of the motion embedding doesn't seem obvious. Besides, there are no more ablation studies to show the effectiveness of other designs, like the impact of training with augmented GT data instead of tracker outputs, the impact of embedding time query, and so on.\n\n3. The three modules in the proposed framework are separate from each other, rather than a unified end-to-end model, which makes the proposed framework a bit complicated."
                },
                "questions": {
                    "value": "The issues I am concerned about are listed in order in the above \"Weaknesses\". I'll change my rating if the authors explain the first two issues well."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5425/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698818427083,
            "cdate": 1698818427083,
            "tmdate": 1699636550934,
            "mdate": 1699636550934,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "o2DYqsJ6lZ",
            "forum": "8tWOUmBHRv",
            "replyto": "8tWOUmBHRv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5425/Reviewer_S5GM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5425/Reviewer_S5GM"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an offline tracking framework with object permanence to reduce the expensive labor cost in labeling large-scale autonomous driving datasets. The proposed approach can be briefly summarised as several steps: 1) applying the off-the-shell detector and tracker to generate initial tracklets; 2) using the Re-ID module for tracklet association; 3) employing the track completion module for trajectory completion. Specifically, the effectiveness of the model is validated on the nuScenes validation split."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- This paper aims to solve an essential problem in autonomous driving dataset labelling.\n- Quantitative and qualitative results show some superiority of the proposed approach over the compared approaches."
                },
                "weaknesses": {
                    "value": "- The technical contribution is limited. The proposed approach heavily relies on off-the-shell detectors/tracker, and are inspired from existing approaches a lot (especially for the track completion module), which seems not significant enough as the main contributions by considering the object permanence conception had already been proposed in previous works [1].\n- Missing details about the training hyper-parameters for reproduction.\n- The proposed approach does not show significant improvements over the compared Immortal tracker (See Tables 1-3). Is there any specifically design in Immortal tracker making the comparison unfair? Otherwise, it cannot effectively show the superiority of the proposed approach in this paper.\n\n[1] Pavel Tokmakov, Jie Li, Wolfram Burgard, and Adrien Gaidon. Learning to track with object permanence. In ICCV, pp. 10860\u201310869, 2021."
                },
                "questions": {
                    "value": "- The technical contribution is limited. The proposed approach heavily relies on off-the-shell detectors/tracker, and are inspired from existing approaches a lot (especially for the track completion module), which seems not significant enough as the main contributions by considering the  object permanence conception had already been proposed in previous works [1].\n- Missing details about the training hyper-parameters for reproduction.\n- The proposed approach does not show significant improvements over the compared Immortal tracker (See Tables 1-3). Is there any specifically design in Immortal tracker making the comparison unfair? Otherwise, it cannot effectively show the superiority of the proposed approach in this paper.\n\n[1] Pavel Tokmakov, Jie Li, Wolfram Burgard, and Adrien Gaidon. Learning to track with object permanence. In ICCV, pp. 10860\u201310869, 2021."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5425/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698841343252,
            "cdate": 1698841343252,
            "tmdate": 1699636550827,
            "mdate": 1699636550827,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]