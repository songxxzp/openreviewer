[
    {
        "title": "VBH-GNN: Variational Bayesian Heterogeneous Graph Neural Networks for Cross-subject Emotion Recognition"
    },
    {
        "review": {
            "id": "T96Ts8nvxe",
            "forum": "EArTDUmILF",
            "replyto": "EArTDUmILF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6021/Reviewer_zn1U"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6021/Reviewer_zn1U"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a Domain adaptation method for a cross-subject emotion recognition task by aligning spatial-temporal relationships of multimodal physiological signals. The method is implemented as follows: the model contains temporal and spatial Relationship Distribution Adaptation (RDA) components, each of which represents the multimodal spatio-temporal relationships as edge distributions of a heterogeneous graph and aligns them twice."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Exploiting the correlation of multimodal physiological signals to address individual differences in cross-subject emotion recognition is a simple but often overlooked detail in the past. Multimodal data has been shown to provide more information compared to single modalities, and making full use of multimodal data can improve model performance. In other words, it is a common approach to utilise the complementary of multimodal data for feature fusion to generate better feature representations. However, VBH-GNN adopts a different perspective, i.e., exploiting the relationship between multimodal data to solve the problem of individualised differences. This is like in NLP, different languages may be completely different in pronunciation and writing, but there must be similar correlations in semantic structure. This multimodal relationship will be better represented in the field of physiology, because various physiological signals correspond to the physiological system interactions of the human body. In the final experimental section (4.6) the authors also provide a good demonstration of the hypothesis that there is cross-subject similarity in the inter-signal relationships, despite individual differences in signals.\n\nDomain alignment via heterogeneous graph edge distributions is a novel idea in the field of BCI.DA has been used relatively rarely in EEG tasks, but most of the concerns are about finding domain invariant features. These features are often signal-level features. The authors argue that domain invariant features tend to trap the model in sub-optimal solutions due to individual differences in physiological signals. Therefore VBH-GNN looks for domain-invariant distributions (although in a sense the spatio-temporal relationship distribution is also a signal feature, I think there is a difference between the feature representation and the distribution), which has not been seen in previous EEG tasks.\n\nBayesian graph inference (BGI) is a generalised method. It implements a distribution with infinite parameter n in a neural network by an ingenious method and backpropagation of this infinite parameter n in network by an upper bound. It provides a feasible method to implement infinite parameters in neural networks as well as to perform backpropagation."
                },
                "weaknesses": {
                    "value": "The explanation of the (Emotional graph transform) EGT step lacks depth. Although the authors demonstrate in their experiment (4.5) the difference between EGT and BGI, which is able to transform an intermodal heterogeneous graph into a more emotion-specific graph, the motivation for this step is not clear enough to me, and it seems more like a step based on experimental attempts to determine what to do; in other words, the authors seem to know what has to be done and how it should be done, but are unable to explain why it allows HetG to be transformed in an emotionally weighted way. what has to be done and how it should be done, but are unable to explain why doing so allows HetG to undergo an emotionally relevant weighting transformation. I think it should be that EGT creates an Attention-like effect between the original input and the HetG weights, and in training this ATTENTION tends to notice the HetG edges that are more emotionally relevant. I think the authors should experimentally demonstrate what makes EGT work and provide a more direct explanation in the paper.\n\nLack of a flowchart of the overall model. This paper contains a large number of formulas that are difficult to read, and coupled with the lack of a flowchart of the overarching model, I had a hard time imagining what the complete model would look like, how the temporal and spatial RDA components would be linked, and how the heterogeneous edges would be generated. Although the authors used formulas to explain the steps, this piling up of formulas in the presence of a large number of formulas rather made it difficult for me to understand the framework of the model, at least for me I would have liked a clearer flowchart as a guide.\n\nThe choice of Baseline is rather narrow. Although several baselines are included, they are basically methods in the BCI area. There are many DA methods in other fields, such as Maximum Classifier Discrepancy proposed in CVPR and a series of methods derived from it. I think adding more diversity of DA methods to compare and analyse can make the results more convincing, as DA is a relatively uncommon method in the BCI domain. Because multimodal data in other area do not necessarily correlate across subject as well as physiological signals, so comparison with methods in other area can demonstrate the applicability of VBH-GNN in the field of physiological signals."
                },
                "questions": {
                    "value": "Is the BCI in Figure 2 trying to represent BGI?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6021/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698392212785,
            "cdate": 1698392212785,
            "tmdate": 1699636646811,
            "mdate": 1699636646811,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Eodo8zCQoT",
                "forum": "EArTDUmILF",
                "replyto": "T96Ts8nvxe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer zn1U (1/2)"
                    },
                    "comment": {
                        "value": "Thank you so much for the positive rating and insightful comments. Your valuable suggestions are beneficial for further strengthening our paper. We have revised our paper according to your comments.\n\n## Answer to Weakness 1:\n\nIf we understand the reviewers correctly, the reviewer believes that our explanation of what and how EGT plays a role in RDA was unclear. Thanks to the reviewers' suggestions, we have updated the description of the EGT section. Here, we would like to clarify the role of EGT in terms of its rationale.\n\n**The role of EGT is to distinguish between the latent relationship distribution founded by BGI in different emotions**. We have mentioned it in our paper:\n\n> EGT divides the clustering centers of the two emotion categories in the source and target domains into two.\n\nTherefore, the EGT is a component designed for downstream ER tasks for extracting emotion-related information representations from HetG (output of BGI). As shown in our paper in Fig.4\uff08c\uff09, the distribution after EGT can be more adapted to the downstream classification task. As shown in Section 4.3 ABLATION EXPERIMENTS, there is a significant decrease in the accuracy after the EGT Loss is removed. We have summarized the effect of EGT on VBH-GNN as follows:\n\n> For EGT loss, its effect on the model is to determine the degree of convergence.\n\nIn other words, the EGT can be regarded as a bridge between downstream tasks and BGI. It makes the domain-invariant relationship distribution inferred from BGI more suitable for downstream tasks.\n\n**The EGT is achieved by transforming the HetG by weighting each edge with a conditional variable**. This conditional variable is a Gaussian distribution computed from edge embedding and conditioned on the edges of HetG:\n\n> $\\mathcal{N} _{s\\lor lt}|Z _{\\text{HetG}} \\sim \\mathcal{N}(Z _{\\text{HetG}} \\times \\bar{\\mu} _{s\\lor lt}, Z _{\\text{HetG}} \\times \\bar{\\sigma }^2 _{s\\lor lt})$\n\nIt integrates the emotion information from node embedding into the graph structure. Therefore, we use the re-parameterization trick on this conditional variable to make it a weight related to the emotion, which will be applied further to transform the HetG to EmoG. \n\n## Answer to Weakness 2:\n\nAccording to the reviewer's suggestion, **we have added a flowchart of the VBH-GNN in our paper (Please check Figure 2 in our revised PDF version)**. We have shown the workflow of the VBH-GNN and the critical components. We also added a more detailed explanation of each component in Section 3.1. We hope this will help the reader to understand VBH-GNN better."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404896474,
                "cdate": 1700404896474,
                "tmdate": 1700404896474,
                "mdate": 1700404896474,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aGFTOTx9fI",
                "forum": "EArTDUmILF",
                "replyto": "T96Ts8nvxe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer zn1U (2/2)"
                    },
                    "comment": {
                        "value": "## Answer to Weakness 3:\n\nWe apologize for not clearly stating our criteria for baseline selection. We and the reviewers have some different perspectives on baseline selection, so we wanted to share our opinions. We strongly agree with the reviewers and have added new experiments to broaden the scope of our baseline.\n\n**First, the physiological signal is a time series signal, and the MCD series method is unsuitable for this scenario**. The MCD series of methods are more likely to perform tasks such as object classification. Compared with this type of data, physiological signals have a significant feature: time correlation. Therefore, the model needs to analyze the spatial-temporal relationship of the data. Due to different data scales, these models are difficult to transplant to cross-subject ER tasks directly.\n\n**Second, to increase baseline diversity, we added two baselines from other fields**. Baseline in [1] and [2] apply graphs to learn spatial relationships between multivariate time series data. This kind of data is consistent with the multimodal physiological signals we use. We have updated the experimental results in Table 1:\n\n| Method | DEAP |  |  |  | DREAMER |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n|  | Arousal |Arousal  | Valence | Valence | Arousal | Arousal | Valence |Valence   |\n|  | Accuracy | F1 Score | Accuracy | F1 Score | Accuracy | F1 Score | Accuracy | F1 Score |\n| MTGNN [8] | $67.46 \\pm 11.51$ | $63.03 \\pm 12.19$ | $64.77 \\pm 7.98$ | $67.24 \\pm 8.33$ | $66.66 \\pm 9.54$ | $66.24 \\pm 11.5$ | $63.35 \\pm 6.29$ | $64.01 \\pm 9.39$ |\n| RAINDROP [9] | $66.06 \\pm 10.11$ | $63.7 \\pm 12.43$ | $65.59 \\pm 7.38$ | $64.29 \\pm 7.98$ | $65.74 \\pm 8.99$ | $62.17 \\pm 10.82$ | $65.85 \\pm 7.61$ | $62.44 \\pm 8.07$ |\n| Our VBH-GNN | **73.5** $\\pm$ **7.22** | **71.53** $\\pm$ **10.86** | **71.21** $\\pm$ **6.41** | **71.85** $\\pm$ **7.38** | **70.64** $\\pm$ **7.74** | **69.66** $\\pm$ **9.51** | **73.38** $\\pm$ **4.21** | **69.08** $\\pm$ **6.98** |\n\nHowever, these models do not perform well because the data in their applicable scenarios differ from physiological signals regarding the sparsity and sampling rate, etc.\n\n[1] Zonghan Wu, et al. \"Connecting the dots: Multivariate time series forecasting with graph neural networks.\" ACM SIGKDD, 2020\n\n[2] Xiang Zhang, et al. \"Graph-Guided Network for Irregularly Sampled Multivariate Time Series.\" ICLR, 2022.\n\n\n\n## Answer to Question 1:\n\nWe thank the reviewer for carefully reading our manuscript and pointing out this typo. **We examined the manuscript thoroughly and tried our best to correct all the typos we found**. We also have redrawn Figure 2 (Now it is Figure 3 in the current version). We hope this could provide readers with a better reading experience."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404985926,
                "cdate": 1700404985926,
                "tmdate": 1700404985926,
                "mdate": 1700404985926,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sZZAPWWlm1",
            "forum": "EArTDUmILF",
            "replyto": "EArTDUmILF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6021/Reviewer_D38r"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6021/Reviewer_D38r"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses cross-subject emotion recognition using EEG data. It proposes a Variational Bayesian Heterogeneous Graph Neural Network (VBH-GNN) with Relationship Distribution Adaptation (RDA) to align spatio-temporal relationships between multi-modal physiological signals, instead of aligning individual features. The method outperforms existing approaches in experiments on two public datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The authors come up with an interesting method to combat heterogeneity across patients by using multiple modalities. \n- The authors provide a rigorous proof and interpretability of their method."
                },
                "weaknesses": {
                    "value": "- In Table 1, there is a typo. I believe DEAT should read DEAP. Additionally, Mathod should be Method. Additionally, expanding Table 1 by including which modalities were used for each baseline would be more comprehensive. \n- Expanding Table 3 by seeing the effect of all modalities used would be more comprehensive."
                },
                "questions": {
                    "value": "- The paper assumes an infinite number of edges between nodes with probabilities $p_n\u200b$ tending to zero in section 3.2.1. Could the authors clarify a bit more on the reasoning behind the assumption?\n- Could the authors clarify $\\epsilon$ in equation 12 in the main paper. They mention it is a \"very small hyperparameter.\" Does this mean that it is close to 0?\n- Did the authors confirm that for Table 1, the comparable methods are all using the same experimental conditions as the authors (e.g., cropped experiment, experiment setup, modalities used)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6021/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6021/Reviewer_D38r",
                        "ICLR.cc/2024/Conference/Submission6021/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6021/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698720533020,
            "cdate": 1698720533020,
            "tmdate": 1700680797440,
            "mdate": 1700680797440,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HAXOsgIIl3",
                "forum": "EArTDUmILF",
                "replyto": "sZZAPWWlm1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer D38r (1/2)"
                    },
                    "comment": {
                        "value": "We sincerely thank the reviewer for the positive rating and insightful comments. Your valuable suggestions are beneficial for further strengthening our paper. We have revised our paper according to your advice.\n\n## Answer to Weakness 1:\nThank you for carefully reading our manuscript and pointing out the typos. **We have revised these two typos**.\n\nFollowing the reviewer's suggestion, **we have added the modality information in Table 1**. The Deap dataset contains EEG, EOG, EMG, and GSR modalities, and the Dreamer dataset contains EEG and ECG modalities. Since our method and baselines all utilize the full modalities available in each dataset, we do not specify the modalities used for individual baselines due to space constraints. Instead, we annotate the modalities included in each dataset in the table headers (see Table 1 on Page 8). Besides we have also added the description of modality information in the experiment setting section (see 4.1 EXPERIMENTAL SETTING).\n\n\n## Answer to Weakness 2:\nAccording to the reviewer's suggestion, **we have substantially expanded Table 3 to include experimental results for all individual and combined modalities**. The updated Table 3 with these additional results can be found on page 8 of the revised PDF paper."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700403701743,
                "cdate": 1700403701743,
                "tmdate": 1700403817633,
                "mdate": 1700403817633,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "X8MNk3ymtM",
                "forum": "EArTDUmILF",
                "replyto": "sZZAPWWlm1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer D38r (2/2)"
                    },
                    "comment": {
                        "value": "## Answer to Question 1:\nWe will explain this hypothesis through the physiological phenomena behind it as well as similar examples from other fields.\n\n**The explanation of the infinity edges**: Physiological systems are highly complex and contain many biological processes that interact with each other in multiple ways. While some of these interactions are medically proven, such as heart rhythms altering skin temperature and unconscious eye movements due to brain activity, there are more complex and yet-to-be-fully explored interrelationships [3]. We, therefore, use edges that tend to be infinite to represent the complexity and diversity of signal relationships in physiological systems.\n\n**The explanation of the probability of existence for edges close to 0**: Physiological systems often have multiple regulatory mechanisms, and the relationships between physiological signals may be multilevel and sublinear. Thus, most relationships between physiological signals are insignificant, and only a few relationships are meaningful in specific situations (e.g., emotions). Therefore, to reflect the sparsity of the relationships between physiological signals, we assumed that the probability of the existence of edges tends to 0 before determining the pattern of emotions. \n\n**Similar examples**\uff1aSimilar assumptions are applied to the natural language field. For example, as mentioned in [1] and [2], there are relational structures between consecutive utterances, such as comments, analogies, and contrasts. Before producing complex relational structures among utterances, the listener unconsciously generates an infinite amount of similar data structures while the probability of relation existence is minimal (close to 0).\n\n\n\n## Answer to Question 2:\n\nThe $\\epsilon$ is a hyperparameter with a very small value 1e-5. **The $\\epsilon$ had been listed in Table 5 in Appendix (A.5) of our original submission, but we inappropriately used a different symbol**.\nWe have updated the $\\epsilon$ in Table 5 in the Appendix (A.5), and we have also added the description of $\\epsilon$ in our revised submission for better clarification (see Line xxx).\n\n| Hyper-parameter | Value |\n| :--- | :---: |\n| $\\vdots$ | $\\vdots$ |\n| eps ($\\epsilon$) | $1 \\mathbf{e}-5$ |\n| $\\vdots$ | $\\vdots$ |\n\n## Answer to Question 3:\n\nYes, all the comparable methods use the same experimental conditions(i.e., cropped experiment, training strategy, and modalities). We have a shared Dataloader for all models.\nHere are some more specific descriptions of our experiment settings:\n\n**Modalities:**\nIn Table 1, **all baselines use the same modalities**: the EEG, EOG, EMG, and GSR modalities from DEAP and the EEG and ECG modalities from DREAMER.\n\n**Training strategy:**\n**We adopt the \"leave-one-subject-out\" (LOSO) paradigm to divide the dataset and implement a shared Dataloader**. We use one subject as the target domain and the remaining as the source domain. The training set consists of all source domain and some target domain data, and the remaining target domain data are divided into validation and testing sets.\n\n**Cropping Experiment:**\n**We employed a specific data cropping strategy for each trial**, segmenting the data into 4-second non-overlapping intervals for all methods. This data segmentation was conducted only after dividing the dataset into training and testing sets. Given the inherent time-series nature of physiological signals, adjacent segments are naturally correlated. If these segments were distributed before splitting training and testing sets, it could lead to data leakage, inflating model performance metrics like accuracy and F1 score. To ensure the reliability of our results, we applied the same cropping strategy across all models. This approach helps prevent abnormally high performance resulting from data leakage, ensuring a fair and accurate evaluation of model efficacy.\n\n\n## Reference\n[1] Murai, Yuki, and Yuko Yotsumoto. \"Optimal multisensory integration leads to optimal time estimation.\" Scientific reports 8.1 (2018): 13068.\n\n[2] Alexander, Patricia A. \"Relational thinking and relational reasoning: harnessing the power of patterning.\" NPJ science of learning 1.1 (2016): 1-7.\n\n[3] Andreassi, John L. Psychophysiology: Human behavior and physiological response. Psychology press, (2010)."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700403800483,
                "cdate": 1700403800483,
                "tmdate": 1700403800483,
                "mdate": 1700403800483,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mg7rcrTLrb",
                "forum": "EArTDUmILF",
                "replyto": "sZZAPWWlm1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Reviewer_D38r"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Reviewer_D38r"
                ],
                "content": {
                    "title": {
                        "value": "Response to Rebuttal"
                    },
                    "comment": {
                        "value": "Hello Authors,\n\nThank you for the clear explanations and expansions to existing tables and experiments.\nI have raised my initial score of 6 to a 8."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680779143,
                "cdate": 1700680779143,
                "tmdate": 1700680806742,
                "mdate": 1700680806742,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bfe0FYWZmY",
            "forum": "EArTDUmILF",
            "replyto": "EArTDUmILF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6021/Reviewer_Pxr2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6021/Reviewer_Pxr2"
            ],
            "content": {
                "summary": {
                    "value": "This paper designs a Variational Bayesian Heterogeneous Graph Neural Network (VBH-GNN) with Relationship Distribution Adaptation (RDA) for cross-subject emotion recognition (ER) that does not align the distribution of signal features but rather the distribution of spatio-temporal relationships between features. Extensive experiments demonstrate the superiority of the method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This method is novel and intuitive.\n2. The experiments have clearly demonstrated the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1. The quality Figure 2 needs to be improved.\n2. Statistical results in tables will be more convincing. In addition, the optimal results in Table 1 should all be highlighted."
                },
                "questions": {
                    "value": "1. What is the difference between Spatial-RDA and Temporal-RDA, and what roles do they play in this task?\n2. Are the weights of each loss function in Formula 5 the same? Are the weights of each loss function considered?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6021/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6021/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6021/Reviewer_Pxr2"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6021/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698739929990,
            "cdate": 1698739929990,
            "tmdate": 1699636646483,
            "mdate": 1699636646483,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7zoIUl4MTj",
                "forum": "EArTDUmILF",
                "replyto": "bfe0FYWZmY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Pxr2"
                    },
                    "comment": {
                        "value": "Thank you so much for your thoughtful comments and the time to provide constructive feedback to strengthen our work further! We have revised the paper to address your concerns as follows.\n\n## Answer for Weakness 1:\n**We have redrawn Figure 3 (i.e., Figure 2 in the original version) to improve the readability of the RDA module**. Specifically, we use different background colors to denote different sub-modules and thus make the figure details more transparent.\n\n\n## Answer for Weakness 2: \n\nIn the tables of our original submission, we only report two types of statistical results, i.e., Accuracy and F1 Score. Following the reviewer's suggestion, we have added a new type of statistical results in Table 1. **We have added the standard deviation of all Accuracy and F1 Score**. Please see Table 1 in our revised PDF version. We have been conducting experiments to calculate the standard deviation of accuracy results for other tables.\n\nTo increase the readability of the results in Table 1, we have highlighted the best, second-best, and third-best results in red, green, and blue, respectively. \n\n\n## Answer for Question 1: \n\n**Structurally, Spatial RDA and Temporal RDA are the same; functionally, they infer and align relationship distributions of domains in the temporal and spatial dimensions, respectively**. Physiological signals are often interrelated in both time and space. Therefore, to fully infer and utilize this spatio-temporal relationship, we used a Spatial RDA and a Temporal RDA for the multi-modal physiological signals in different stages, respectively.\n\nWe have added a global flow chart in Figure 2 to illustrate the role of each module (e.g., Spatial RDA and Temporal RDA). We have also updated the description of the two RDAs in our paper as follows:\n\n> RDA, as the core component of VBH-GNN, accepts node embeddings for domain alignment and updates the weights of node embeddings. The VBH-GNN contains structurally consistent Temporal RDA and Spatial RDA, which perform inference and alignment of relationship distributions in the temporal and spatial dimensions. The details of RDA will be explained in Section 3.2.\n\n\n## Answer for Question 2: \n**Yes, the weights of all the loss functions in Formula 5 are set to be the same; specifically, the weights are equal to one**.\n\nWe have conducted additional experiments to find the best weight combination. We found that using a weight of 1 for all terms achieves the best experimental results. Therefore, we omitted the weights symbolic in the previous submission version. Based on the reviewer's comment, we have added the weight symbols in Formula 5 for a better understanding. The revised Formula 5 is as follows:\n\n> **Loss of VBH-GNN** contains two types of loss: the RDA Loss for aligning the source domain and target domain and the prediction loss of the classifier. The final loss function is formulated as \n> $${\\cal L} _{\\text{VBH-GNN}} = \\lambda _{1}{\\cal L} _{\\text{SRDA}}+\\lambda _{2}{\\cal L} _{\\text{TRDA}}+ \\lambda _{3}{\\cal L} _{SBCE}+\\lambda _{4}{\\cal L} _{TBCE}$$ where ${\\cal L} _{\\text{SRDA}}$ and ${\\cal L} _{\\text{TRDA}}$ are loss of Spatial RDA and Temporal RDA (will be further explained in Section 3.2.3), ${\\cal L} _{SBCE}$ and ${\\cal L} _{TBCE}$ are Binary Cross-Entropy Loss for source and target domain classification. $\\lambda _{1}$, $\\lambda _{2}$, $\\lambda _{3}$, and $\\lambda _{4}$ are loss weights, which are all set to $1$ in the experiments.\n\nWe hope that our answers clarify your concerns. Thank you for your time and feedback! We are glad to have any further discussion."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405214997,
                "cdate": 1700405214997,
                "tmdate": 1700405214997,
                "mdate": 1700405214997,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Z1IaAnHLVv",
            "forum": "EArTDUmILF",
            "replyto": "EArTDUmILF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6021/Reviewer_QvEM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6021/Reviewer_QvEM"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses the emerging field of research on human emotion using electroencephalogram (EEG) data, with a focus on cross-subject emotion recognition (ER). The challenges in this area include the neglect of multi-modal physiological signals and the difficulty in matching signal features across different domains. To address these issues, the authors propose a novel approach called Variational Bayesian Heterogeneous Graph Neural Network (VBH-GNN) with Relationship Distribution Adaptation (RDA). This method does not align the distribution of signal features but rather focuses on the distribution of spatio-temporal relationships between features. Through extensive experiments on DEAP and Dreamer datasets, the VBH-GNN with RDA demonstrates superior performance compared to state-of-the-art methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This article offers an in-depth analysis of the current challenges within the emerging domain of human emotion recognition using electroencephalogram (EEG), with a specific emphasis on cross-subject emotion recognition (ER).\n2. Author introduces the novel VBH-GNN method, and conducts comprehensive experiments to showcase the model's competitive performance."
                },
                "weaknesses": {
                    "value": "1. It is essential to provide a more detailed explanation of how each component contributes to addressing the proposed issue, e.g., clarify the necessity of graph neural network and the specific problem it aims to solve.\n2. The readability and visual appeal of the process diagram for RDA in Figure 2 could be improved.\n3. The experimental setting of dividing source and target domains is unrealistic."
                },
                "questions": {
                    "value": "1. After constructing the emotional graph, did the author only perform a single convolution layer by multiplying an adjacency matrix with node embeddings? Did the author consider using multiple convolution layers or using the more expressive graph neural network?\n2. Due to the necessity of employing Bayesian graph inference to construct multiple graphs in the author's method, I am concerned about whether the performance benefits outweigh the increased computational burden.\n3. In Table 1, VBH-GNN achieves optimal accuracy, but the F1 scores consistently demonstrate poor performance. Does this observation imply the class imbalance issue in the predicted results of the method?\n4. The authors used leave-one-subject-out paradigm to divide the source and target domains is unrealistic. In this case, the target domain is actually a validation set, which is not the real domain adaptation setting.\n5. The heterogeneity (e.g., EEG, ECG) in this paper can be regarded as multi-variant time series data. Please clarify the difference between the heterogeneity and multi-variant time series. The experiments should also include the baseline methods for learning multi-variant time series (e.g., learning a graph structure to represent the spatio relationships in multi-variant time series)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6021/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6021/Reviewer_QvEM",
                        "ICLR.cc/2024/Conference/Submission6021/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6021/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699940439157,
            "cdate": 1699940439157,
            "tmdate": 1700705432599,
            "mdate": 1700705432599,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NgieDiCjMx",
                "forum": "EArTDUmILF",
                "replyto": "Z1IaAnHLVv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer QvEM (1/4)"
                    },
                    "comment": {
                        "value": "We sincerely thank the reviewer for the insightful and valuable comments! We have addressed the points raised by the reviewer in detail below and updated our paper based on your comments. The response is a bit late since we have supplemented some experiments during the rebuttal period. Please accept our apologies. Please do not hesitate to post additional comments and questions; we will be more than happy to address them.\n\n## Answer to Weakness 1:\n\nIf we understand correctly, the reviewer means that our explanation of several essential components (e.g., BGI, EGT) in RDA is not detailed enough, which causes difficulties in understanding. Thank you for pointing out this weakness, and **we have updated our paper with more detailed descriptions for each module of RDA**. Here, we explain its core components.\n\n**The Bayesian Graph Inference (BGI) ensures that the model can find the latent relationship distribution of multi-modal physiological signals shared by the source subjects and the target subject**. As we analyzed in Section 4.3: \n\n> BGI loss determines whether the model converges or not or whether the model can learn the spatio-temporal relationship distribution of modalities.\n\nWhen the BGI is removed, the model fails to converge due to its inability to learn this latent relationship distribution.\n\n\n**The Emotional Graph Transform (EGT) ensures that the model can distinguish between the latent relationship distribution of multi-modal physiological signals in different emotions**. In Section 4.3:\n> For EGT loss, its effect on the model is to determine the degree of convergence.\n\nWhen the EGT is removed, there is a significant decrease in classification accuracy, and thus, it determines how well the model converges on the ER task.\n\n**We have also added a flow chart of our method VBH-GNN to illustrate different modules.** We graphically show the different modules, including Wav-to-Node, Spatial RDA, Temporal RDA, and Classifier, and also update their function description in Section 3.1.\n\n## Answer to Weakness 2:\n\nWe have redrawn Figure 3 (i.e., Figure 2 in the original version) to improve the readability of the RDA module. Specifically, we use different background colors to denote different sub-modules and thus make the figure details more transparent. We have also added a global flow chart in Figure 2 to illustrate the role of each module in the overall process. Please check Figure 2 and Figure 3 in our revised PDF version."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700402848798,
                "cdate": 1700402848798,
                "tmdate": 1700402848798,
                "mdate": 1700402848798,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NZFF2yTrf1",
                "forum": "EArTDUmILF",
                "replyto": "Z1IaAnHLVv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer QvEM (2/4)"
                    },
                    "comment": {
                        "value": "## Answer to Weakness 3 and Question 4:\n\nWe used the leave-one-subject-out (LOSO) paradigm to divide source and target domains. If we understand correctly, the reviewer means that the validation and testing sets should originate from different domains (subjects) and should not overlap. We explain why we use LOSO as follows.\n\n**First, there are differences between domain adaptation (DA) and domain generalization (DG).** Our paper aims at the DA problem in a cross-subject emotion recognition (ER) task. The DA is similar to DG, and we speculate whether this might be causing the misunderstanding.\n\nThe main difference between DG and DA is whether the model can use the data from the target domain in the training process. For the DG, the subjects in the testing set are regarded as the target domain, and these subjects should be unseen to the trained model. To evaluate the trained model, the validation set should also be from the target domain but use a different subject from the testing set. In this case, using LOSO is unrealistic. However, for the DA, the training set typically contains data from both the source and target domains. Without access to target domain data, models cannot appropriately adapt to the new unknown domain during initial training. In other words, the DA implies using data from source subjects and the target subject for ER, so the LOSO can be used to select the target subject.\n\n\n**Second, the LOSO is a commonly used experiment setup for domain adaptation (DA) in EEG-based cross-subject ER**. To support our point, we cite several typical papers and quote their relevant contents as follows:\n\n1. Mentioned in ref [1]: \n> Specifically, only one experiment from each subject is involved in the **leave-one-subject-out** cross strategy to study the inter-subject variability.\n\n2. Mentioned in ref [2]: \n> Based on the above EEG dataset, we adopt the **leave-one-out-cross-validation** method in the following experiments to evaluate the performance of the models in cross-subject scenarios.\n\n3. Mentioned in ref [3]: \n> On the control experiments, we employ two transfer paradigms, i.e., 'one-to-one' and **'multi-to-one'**. ... . In the latter paradigm, when **one subject serves as the target, all the remaining subjects form the source**.\n\nDespite their different paradigm names, they all randomly select one subject as the target domain and the rest of the subjects as the source domain. We follow their settings in our experiments.\n\n**Third, the division of the training, testing and validation sets in our experiments is also common, and there is no data leakage**. We will explain this with the content of a published paper.\n\nMentioned in the baseline MMDA-VAE [4]:\n\n> **The training set consisted of the source data and the labelled target data**, i.e., all the samples from the source session and samples from the first three or four trials (one trial per class) in the other target session. \n\nThis means that the training set contains source and target domain data.\n\n> We used **samples from the second three or four trials in the target session as the validation set**. \n\nThis indicates that the validation set comprises part of the target domain data.\n\n> The samples from **the rest of the twelve or sixteen trials in the target session were used to evaluate classification accuracy**.\n\nThis suggests that the testing set is also derived from the target domain but does not intersect with the training and validation sets. This experiment setting is the same as ours, where part of the target domain is included in the training set, while the training, validation, and testing sets do not overlap.   \n\n**In summary, our experiment setting (i.e., LOSO paradigm) is commonly used in the cross-subject ER field and does not result in data leakage**. At the same time, we agree with the experiment setting that the reviewer suggested, and we will take the relatively more challenging DG task as our further research direction. We look forward to discussing this with you and thank you for noting the details of the experiment setup.\n\n[1] Zhao, Li-Ming, Xu Yan, and Bao-Liang Lu. \"Plug-and-play domain adaptation for cross-subject EEG-based ER.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 1. 2021.\n\n[2] Gu, Rong-Fei, et al. \"Cross-Subject Decision Confidence Estimation from EEG Signals Using Spectral-Spatial-Temporal Adaptive GCN with Domain Adaptation.\" 2023 International Joint Conference on Neural Networks (IJCNN). IEEE, 2023.\n\n[3] Peng, Yong, et al. \"Joint feature adaptation and graph adaptive label propagation for cross-subject ER from EEG signals.\" IEEE Transactions on Affective Computing 13.4 (2022): 1941-1958.\n\n[4] Wang, Yixin, et al. \"Multi-modal domain adaptation variational autoencoder for eeg-based ER.\" IEEE/CAA Journal of Automatica Sinica 9.9 (2022): 1612-1626."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700402907094,
                "cdate": 1700402907094,
                "tmdate": 1700402907094,
                "mdate": 1700402907094,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "l8Dn0nscxD",
                "forum": "EArTDUmILF",
                "replyto": "Z1IaAnHLVv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer QvEM (3/4)"
                    },
                    "comment": {
                        "value": "## Answer to Question 1: \n\nIf we understand the reviewer correctly, the reviewer asks whether we considered using a more expressive network layer to replace the RDA's Graph Attention (GA) module. We have tried using Graph Convolutional Network layers (GCNs) instead of GA, but it is unnecessary. The reasons are as follows.\n\n**The output of EGT (EmoG) already adequately represents the relationships between nodes, so it does not need more expressive networks (such as GCNs) to represent such relationships again**. We found in our experiments that using GCNs does not improve performance compared to using GA. This is because the core idea of GCNs is to infer the relationship between nodes based on the input adjacency matrix and node embeddings and then update the node embeddings based on this relationship. However, the function of inferring the relationship between nodes is precisely accomplished by BGI and EGT. The EmoG has adequately represented the relationship between nodes under specific emotions, and the GA operation is also more efficient than the convolution layers or graph neural networks. Therefore, we simplify the GCNs to GA that retain only the function of updating node embeddings.\n\n\n## Answer to Question 2:\n\nIf we understand the reviewer correctly, the reviewer is concerned that there is a step in BGI that couples $n$ relationships between multi-modal signals. This step constructs multiple graphs, thus incurring a substantial computational burden. However, this step does not construct multiple graphs and, therefore, does not increase the computational burden. \n\n\n**The BGI does not directly align the graphs between domains, but rather the edge existence probability distributions, so it doesn't construct multiple graphs**. In the paper, we mentioned:\n\n> From this, we define the prior HetG edge distribution from the source domain as follows: \n> $$P(\\text{HetG}|E_s) \\sim \\text{BIN}(n, p_s)$$\n\nwhere $p_s \\in \\mathbb{R} ^{B \\times N_{e} \\times 1}$ is computed by the network and mathematically represents the probability of the existence of each of the $N_e$ edges. It is much smaller than the edge embedding matrix $E_s\\in \\mathbb{R}^{B \\times N_{e} \\times D_e}$.\n\nTo align domains by such probability distributions, we design the BGI Loss (essentially Kullback-Leibler Divergence (KLD)), which is used to minimize the divergence between the two probability distributions. However, as the reviewer is concerned, the direct computation of this KLD imposes a substantial computational burden due to the presence of $n$. To make this computation possible in the network, we propose Theorem 2, which mathematically computes an upper bound for this KLD:\n> $$\\mu_{lt} \\log \\frac{\\mu_{lt}+\\epsilon}{p_s+\\epsilon} +(1-\\mu_{lt}) \\log \\frac{1-\\mu_{lt}+{\\mu_{lt}}^2 / 2+\\epsilon}{1-p_s+{p_s}^2 / 2+\\epsilon}$$\n\nwhich is not directly related to $n$. The computational complexity of this equation is $O(B \\cdot N_e)$, which will not impose a significant computational burden. \n\n\n## Answer to Question 3:\n\nYes, the class imbalance issue is a common and challenging problem in cross-subject EEG ER. Detailed investigation of the imbalance issue will be part of our future effort. Actually, our method achieves the second-best results regarding the F1 score among all methods in most cases. For a better illustration, we updated Table 1 and highlighted the top 3 performances to show the advantages of our method.\n\n## Answer to Question 4:\n\nSee the answer in Weakness 3."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700402974170,
                "cdate": 1700402974170,
                "tmdate": 1700402974170,
                "mdate": 1700402974170,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xIiGu18lek",
                "forum": "EArTDUmILF",
                "replyto": "Z1IaAnHLVv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer QvEM (4/4)"
                    },
                    "comment": {
                        "value": "## Answer to Question 5\n\nThank you for bringing this to our attention! We agree that the heterogeneity (e.g., EEG, ECG) mentioned in our paper can be regarded as multi-variant time series data.\n\nThe heterogeneous data in our paper is to emphasize the diversity of physiological signals captured by different sensors. The term \"heterogeneity\" is commonly used in multi-modal or EEG ER [5][6][7]. The multi-variant time series data is the sequential observations (e.g., physiological signals and vital signs) that may be irregularly sampled by sensors [9]. Therefore, the heterogeneous data and multi-variant time series data **have little differences in data format**.\n\nAs suggested by the reviewer, the baseline methods for learning multi-variant time series can also be used for the ER task. We adopt two graph structure based methods [8][9] as our new baselines. Their preliminary experimental results are as follows:\n\n| Method | DEAP |  |  |  | DREAMER |  |  |  |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n|  | Arousal |Arousal  | Valence | Valence | Arousal | Arousal | Valence |Valence   |\n|  | Accuracy | F1 Score | Accuracy | F1 Score | Accuracy | F1 Score | Accuracy | F1 Score |\n| MTGNN [8] | $67.46 \\pm 11.51$ | $63.03 \\pm 12.19$ | $64.77 \\pm 7.98$ | $67.24 \\pm 8.33$ | $66.66 \\pm 9.54$ | $66.24 \\pm 11.5$ | $63.35 \\pm 6.29$ | $64.01 \\pm 9.39$ |\n| RAINDROP [9] | $66.06 \\pm 10.11$ | $63.7 \\pm 12.43$ | $65.59 \\pm 7.38$ | $64.29 \\pm 7.98$ | $65.74 \\pm 8.99$ | $62.17 \\pm 10.82$ | $65.85 \\pm 7.61$ | $62.44 \\pm 8.07$ |\n| Our VBH-GNN | **73.5** $\\pm$ **7.22** | **71.53** $\\pm$ **10.86** | **71.21** $\\pm$ **6.41** | **71.85** $\\pm$ **7.38** | **70.64** $\\pm$ **7.74** | **69.66** $\\pm$ **9.51** | **73.38** $\\pm$ **4.21** | **69.08** $\\pm$ **6.98** |\n\n\n\nWe observe that **the baselines designed for multi-variant time series data perform not that good when applied to emotion recognition on our heterogeneous data. This is because the heterogeneous data and the multi-variant time series data have different characteristics, such as data sparsity and sampling rate.**\n\n\n\n\n[5] Ziyu Jia, et al. \"HetEmotionNet: two-stream heterogeneous graph recurrent neural network for multi-modal ER.\" ACM MM, 2021.\n\n[6] Linlin Gong, et al. \"Emotion recognition from multiple physiological signals using intra-and inter-modality attention fusion network.\" Digital Signal Processing, 2024.\n\n[7] Wei Li, et al. \"Can emotion be transferred?\u2014A review on transfer learning for EEG-Based Emotion Recognition.\" IEEE TCDS, 2021.\n\n[8] Zonghan Wu, et al. \"Connecting the dots: Multivariate time series forecasting with graph neural networks.\" ACM SIGKDD, 2020.\n\n[9] Xiang Zhang, et al. \"Graph-Guided Network for Irregularly Sampled Multivariate Time Series.\" ICLR, 2022.\n\nWe hope that our answers clarify your concerns. Thank you for your time and valuable feedback! We are glad to have any further discussion."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700403047246,
                "cdate": 1700403047246,
                "tmdate": 1700403047246,
                "mdate": 1700403047246,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "y40bvOkyvD",
                "forum": "EArTDUmILF",
                "replyto": "xIiGu18lek",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6021/Reviewer_QvEM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6021/Reviewer_QvEM"
                ],
                "content": {
                    "title": {
                        "value": "Increase my rate to 6"
                    },
                    "comment": {
                        "value": "I want to thank the authors for addressing my concerns. I'll increase my rate to above the threshold."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6021/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700705417309,
                "cdate": 1700705417309,
                "tmdate": 1700705417309,
                "mdate": 1700705417309,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]