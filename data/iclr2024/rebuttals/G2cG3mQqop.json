[
    {
        "title": "Image Clustering Conditioned on Text Criteria"
    },
    {
        "review": {
            "id": "Dcfx4Y5XMe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6858/Reviewer_heiR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6858/Reviewer_heiR"
            ],
            "forum": "G2cG3mQqop",
            "replyto": "G2cG3mQqop",
            "content": {
                "summary": {
                    "value": "The authors proposed a new image clustering paradigm IC|TC, which performing image clustering based on user-specified criteria in the form of text by leveraging modern Vision-Language Models and Large Language Models.  IC|TC can effectively cluster images with various criteria, such as human action, physical location, or the person\u2019s mood, significantly outperforming baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is well organized and the presentation is pretty good.\n2. The paradigm of IC|TC is new\n3. The experimental part is detailed and the clustering results are amazing"
                },
                "weaknesses": {
                    "value": "1. Since the model size of LLaMA-2 and GPT-4 are too big, the author can give more testing results on smaller models.\n2. Some baseline models are missing, such as GCC[1] and TCC[2]\n\n[1]Zhong H, Wu J, Chen C, et al. Graph contrastive clustering. Proceedings of the IEEE/CVF international conference on computer vision. 2021: 9224-9233. \n\n[2]Shen Y, Shen Z, Wang M, et al. You never cluster alone[J]. Advances in Neural Information Processing Systems, 2021, 34: 27734-27746."
                },
                "questions": {
                    "value": "1. Since the model size of LLaMA-2 and GPT-4 are too big, the author can give more testing results on smaller models.\n2. Some baseline models are missing, such as GCC[1] and TCC[2]\n\n[1]Zhong H, Wu J, Chen C, et al. Graph contrastive clustering. Proceedings of the IEEE/CVF international conference on computer vision. 2021: 9224-9233. \n\n[2]Shen Y, Shen Z, Wang M, et al. You never cluster alone[J]. Advances in Neural Information Processing Systems, 2021, 34: 27734-27746."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6858/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697428119880,
            "cdate": 1697428119880,
            "tmdate": 1699636795748,
            "mdate": 1699636795748,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rLuxOefaoc",
                "forum": "G2cG3mQqop",
                "replyto": "Dcfx4Y5XMe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6858/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6858/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Individual response to Reviewer heiR"
                    },
                    "comment": {
                        "value": "We are happy to hear that the reviewer appreciates our experimental results and our paradigm's novelty.\n\n\n$\\\\phantom{X}$\n\n**Response to \"Since the model size of LLaMA-2 and GPT-4 are too big, the author can give more testing results on smaller models.\"**\n\nWe conducted an ablation study on object clustering using Llama 2 7B, 13B, 70B, GPT-3.5, and GPT-4 (Figure 3). GPT-4 showed the highest performance, but even the smallest model, Llama-2 7B, demonstrated a comparable performance. Llama-2 7B is one of the smaller large language models among the widely used open-source ones.\n\n\n$\\\\phantom{X}$\n\n**Response to \"Some baseline models are missing, such as GCC[1] and TCC[2]\"**\n\nThank you for the pointers. We have added them to the related work section in the revised manuscript."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6858/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606907708,
                "cdate": 1700606907708,
                "tmdate": 1700606907708,
                "mdate": 1700606907708,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6hxfdiaNT3",
            "forum": "G2cG3mQqop",
            "replyto": "G2cG3mQqop",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6858/Reviewer_t6rL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6858/Reviewer_t6rL"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new clustering paradigm that aims at clustering images based on the criterion provided by users. By leveraging the pre-trained VLM and LLM, the proposed method could understand the user's request and partition images accordingly."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. I think the problem this work tackles is very interesting. By using the pre-trained VLM and LLM, the proposed paradigm could cluster the images based on the user's criterion, which favors real-world applications.\n2. The proposed method improves the clustering explainability by providing the cluster names.\n3. The effectiveness of the method is proved by experiments on both user-specified clustering and classic semantic clustering."
                },
                "weaknesses": {
                    "value": "1. The paper is more like an engineering guidance instance of a research work. In other words, the proposed method \"violently\" clusters the images, all based on pre-trained VLM and LLM. Though I acknowledge the good question and paradigm raised by this work, I feel it is better to incorporate some clustering techniques into the paradigm (maybe in future works).\n2. The refinement operation also seems a bit violent. It seems that if the user is not satisfied with the current clustering results, the whole process is simply repeated. I wonder if the refinement could integrate the experience learned from the last process.\n3. 100 samples from 10 location classes might have biases by random sampling. I suggest enlarging the datasets of location and mood so that they would become reliable benchmarks for future studies.\n4. What is the difference between sending the image description in step 1 and the main object in step 2 into step 3?\n5. There is a related recent work Image Clustering with External Guidance (arXiv 2023) that also leverages the text modality to enhance image clustering, which the authors are encouraged to include in the related works."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6858/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698031028718,
            "cdate": 1698031028718,
            "tmdate": 1699636795634,
            "mdate": 1699636795634,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YA4OhCDdtQ",
                "forum": "G2cG3mQqop",
                "replyto": "6hxfdiaNT3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6858/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6858/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Individual response to Reviewer t6rL"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive and constructive feedback. We are particularly excited to hear that the reviewer recognizes the problem we are tackling to be interesting and our experimental results convincing.\n\n\n$\\\\phantom{X}$\n\n**Response to \"The paper is more like an engineering guidance instance of a research work. In other words, the proposed method \"violently\" clusters the images, all based on pre-trained VLM and LLM. Though I acknowledge the good question and paradigm raised by this work, I feel it is better to incorporate some clustering techniques into the paradigm (maybe in future works).\"**\n\nThe reviewer makes a great suggestion, namely incorporating existing clustering techniques into the IC|TC paradigm. This is something we had explored, and one approach that somewhat worked was using IC|TC as an initialization scheme for k-means.\n\nSpecifically, we view the output of IC|TC as an initial clustering assignment, similar to the smart initial clustering assignment of k-means++. Then, we update the clusters through steps inspired by k-means, as more precisely described by the pseudo-code in the subsequent post. In our experiment with Stanford 40 Action, the clusters stabilized (converged) after 4 iterations. However, we did not observe a significant performance improvement to justify incorporating the result into the paper. Nevertheless, combining existing clustering techniques with IC|TC is indeed an interesting direction of future work that we plan to pursue.\n\n\n$\\\\phantom{X}$\n\n**Response to \"The refinement operation also seems a bit violent. It seems that if the user is not satisfied with the current clustering results, the whole process is simply repeated. I wonder if the refinement could integrate the experience learned from the last process.\"**\n\nIn the refinement process, it is not necessary that all three steps be repeated from scratch. In the Fair clustering experiment of section 4.4, we examined the results of Steps 1 through 3 and determined that it was enough to repeat Step 3 in the refinements.\n\n\n$\\\\phantom{X}$\n\n**Response to \"100 samples from 10 location classes might have biases by random sampling. I suggest enlarging the datasets of location and mood so that they would become reliable benchmarks for future studies.\"**\n\nThe reviewer raises a good point. We have additionally labeled 1000 images for the 'location' and 'mood' clustering tasks for the Stanford 40 action dataset and will release the label data so that it can be used as benchmarks for future studies. Based on these additional labels, we updated the evaluation numbers, and we found them to be similar to the prior numbers that we obtained with fewer labels.\n\n\n\n\n$\\\\phantom{X}$\n\n**Response to \"What is the difference between sending the image description in step 1 and the main object in step 2 into step 3?\"**\n\nThe reviewer raises a great question, and this is indeed something we investigated ourselves. As an example, let us suppose that the image contains a singing man and an applauding audience and that we are using the text criterion 'action'. We may safely assume that, due to the expressive output from the VLMs, the output of step 1 will contain all information related to \"singing\" and \"applauding.\" However, the output of step 2a, the raw label, may only capture \"singing\". Now, suppose that after step 2b, where the cluster names are obtained from the raw labels, there is a cluster name relating to 'applauding' but none directly related to 'singing'. Then, it is necessary for the LLM to be provided with the full textual description, not just the raw label, to properly assign the image to the cluster 'applauding'. In the initial stage of our work, we tried both methods and empirically observed that providing the output of Steps 1 to Step 3 showed superior performance compared to providing the output of Step 2a to Step 3.\n\n\n\n\n$\\\\phantom{X}$\n\n\n**Response to \"There is a related recent work Image Clustering with External Guidance (arXiv 2023) that also leverages the text modality to enhance image clustering, which the authors are encouraged to include in the related works.\"**\n\nThank you for this pointer. We have incorporated the discussion of this concurrent work into our revised manuscript."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6858/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606580274,
                "cdate": 1700606580274,
                "tmdate": 1700606580274,
                "mdate": 1700606580274,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Aie2x6lNo3",
                "forum": "G2cG3mQqop",
                "replyto": "6hxfdiaNT3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6858/Reviewer_t6rL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6858/Reviewer_t6rL"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I have a few concerns after reading the authors' response:\n\nQ3: Clustering results on 700 samples of PPMI (K=7) based on location also need to be reported.\n\nQ4: The corresponding discussions need to be added to the manuscript.\n\nQ5: Sorry but I did not see the mentioned discussion."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6858/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700618389069,
                "cdate": 1700618389069,
                "tmdate": 1700618401717,
                "mdate": 1700618401717,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sxk4Kyz5gm",
                "forum": "G2cG3mQqop",
                "replyto": "KEBbFAHOXe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6858/Reviewer_t6rL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6858/Reviewer_t6rL"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thanks for the response. My concerns have now been addressed."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6858/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700638185377,
                "cdate": 1700638185377,
                "tmdate": 1700638185377,
                "mdate": 1700638185377,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Sq83XcHrCM",
            "forum": "G2cG3mQqop",
            "replyto": "G2cG3mQqop",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6858/Reviewer_zuGS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6858/Reviewer_zuGS"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose an image clustering technique based on text criteria driven by LLMs. They correctly point out that unsupervised clustering often does not yield results that would satisfy a human. They therefore propose clustering based on user specified criteria, which they ask the user to provide and then build on with prompt engineering. They use a three step process to first get the user criteria from the user, then extract relevant textual features from the images and then cluster based on those textual features."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Good literature survey.\n2. Interesting proposed algorithm for clustering.\n3. Interesting results."
                },
                "weaknesses": {
                    "value": "1. I am not convinced that this problem is not merely a form of retrieval based on user specifications. \n2. The approach is inherently not testable at scale unless the authors expend a huge amount of human resources.\n3. That is probably why the authors choose relatively small datasets of images that have strong structures.\n4. I would be more favorably inclined if the authors could show that the proposed method is scalable to millions of images as per the state of the art."
                },
                "questions": {
                    "value": "Please see my comments on weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6858/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698786094988,
            "cdate": 1698786094988,
            "tmdate": 1699636795517,
            "mdate": 1699636795517,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7HG1hkOq9b",
                "forum": "G2cG3mQqop",
                "replyto": "Sq83XcHrCM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6858/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6858/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Individual response to Reviewer zuGS"
                    },
                    "comment": {
                        "value": "We are happy to hear that Review zuGS finds our algorithm and results interesting. We positively address the reviewer's concerns in the following, including running a large-scale experiment to demonstrate that our approach is indeed scalable.\n\n\n$\\\\phantom{X}$\n\n\n**Response to \"I am not convinced that this problem is not merely a form of retrieval based on user specifications.\"**\n\nThe task of clustering requires (i) finding the clusters and (ii) cluster assignment. While image retrieval techniques can certainly be used for cluster assignment, finding the clusters is, in our view, not a form of retrieval. We discuss this point further in our individual response to Reviewer 32Bv.\n\n\n$\\\\phantom{X}$\n\n\n\n**Concerns about scalability**\n\nWe clarify that our method *is* scalable. In principle, a simple back-of-the-envelope calculation shows that the algorithmic complexity of IC|TC is essentially linear in the number of images. To show that IC|TC is scalable in practice, we conducted an experiment with a quarter-million images during the rebuttal period. (Scaling to a million images, as suggested by the reviewer, would be possible if we had just a few more days to run the experiments.) Specifically, we used the Places dataset [20] and used 50 subclasses, each with 5,000 images, to create a quarter-million dataset. With the text criterion 'place', we achieve 70.5\\% accuracy, which is competitive with the state-of-the-art image classification results. (There is some nuance to this comparison that we discuss in the main writing.) We detail the experimental setting and the results in Appendix C of our revised manuscript. We hope this quarter-million experiment alleviates the reviewer's concerns about scalability.\n\n[20] B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva. Learning deep features for scene recognition using places database. 2014.\n\n$\\\\phantom{X}$\n\n**Response to \"The approach is inherently not testable at scale unless the authors expend a huge amount of human resources.\"**\n\nEvaluating/testing clustering and most unsupervised learning methods at scale is an inherent challenge to the task, but it is possible to carry out an approximate evaluation by sub-sampling a few data points from each cluster and obtaining human labels for those samples. In this sense, an approximate but fair evaluation IC|TC or any comparable image clustering method at scale does not require an inordinate amount of human resources.\n\nWe also clarify that the text-criterion refinement of section 3.4 is an optional step and that it does not require a huge amount of human effort. It simply requires that the user roughly examine the clustering results to determine if they are satisfied; in fact, examining the results and fine-tuning hyperparameters is something a user of any clustering method will do in practice.\n\n\n$\\\\phantom{X}$\n\n**Response to \"That is probably why the authors choose relatively small datasets ... I would be more favorably inclined if the authors could show that the proposed method is scalable to millions of images ....\"**\n\nWe hope our additional large-scale experiment addresses the reviewer's concern.\n\n\n$\\\\phantom{X}$\n\nWe thank the reviewer for the constructive feedback. We believe we have addressed the reviewer's main concern about scalability. Since we do show that our proposed method is scalable to a quarter-million images, we kindly ask the reviewer to consider raising the score."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6858/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606446906,
                "cdate": 1700606446906,
                "tmdate": 1700606446906,
                "mdate": 1700606446906,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HRU8TjVhly",
            "forum": "G2cG3mQqop",
            "replyto": "G2cG3mQqop",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6858/Reviewer_32Bv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6858/Reviewer_32Bv"
            ],
            "content": {
                "summary": {
                    "value": "The paper describes a simple prompting method to perform image clustering using existing vision-language models and LLMs. Although it appears to be useful, the method is very obvious, incorporating a few prompts, with no algorithmic novelty."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Interactive editing of the criterion to refine clustering results is a significant strength of the approach. This feature is practical, and intuitive for users, as is the basic premise of the user providing an initial clustering criterion."
                },
                "weaknesses": {
                    "value": "The comparison to related work does not include the body of work in language-guided image retrieval, which seems highly relevant here, particularly since many of those methods use a vision-language encoder and indexing scheme that clusters the image archive according to linguistic concepts, as the proposed approach does implicitly. However, given that the method does not address the underlying representation, but just relies on the LLM to perform clustering as a black box, this is a minor concern.\n\nThe discussion of prior work in deep clustering is also very brief, and does not position the proposed contributions against current, relevant work. \n \nThe method requires prior specification of the number of clusters, which is a significant limitation and drawback. \n\nThe method is very simple, just a set of straightforward text prompts. The crucial step of doing the clustering is just deferred to the LLM itself, by asking it to cluster N labels into K categories. There is no significant algorithmic contribution here, and the paper is likely to be of little interest to the ICLR community."
                },
                "questions": {
                    "value": "none"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6858/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699050554483,
            "cdate": 1699050554483,
            "tmdate": 1699636795397,
            "mdate": 1699636795397,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0SxmRXGmFC",
                "forum": "G2cG3mQqop",
                "replyto": "HRU8TjVhly",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6858/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6858/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Individual response to Reviewer 32Bv"
                    },
                    "comment": {
                        "value": "Reviewer 32Bv raises a valid criticism regarding missing comparisons with the image retrieval literature. We acknowledge that this is an important omission on our part caused by our lack of publication experience in the area of image retrieval, so we provide a thorough literature survey on image retrieval techniques in our revised manuscript. However, we disagree with the other points of criticism, and we feel that the reviewer is being overly harsh in the assessment.\n\n$\\\\phantom{X}$\n\n**Comparison with language-guided image retrieval.**\n\nThe task of clustering is a combination of two sub-tasks: Finding the clusters and assigning individual data points to the clusters. (The standard K-means algorithm is literally an alternation of solving these two sub-tasks.) On the other hand, language-guided image retrieval is the process of searching for an image in a database that contains reference features from a given source image and language. Although these tasks may be related, they are certainly not the same; image retrieval techniques are very relevant to the sub-task of cluster assignment but not to the sub-task of finding the clusters. As a concrete example, we may cluster images based on the musical instrument being played, and IC|TC can automatically find the categories \"brass instrument\" and \"string instrument\" when we specify K=2 clusters. Image retrieval techniques can certainly retrieve images based on the precise instrument or the instrument category, but image retrieval, by itself, cannot determine that  \"brass instrument\" and \"string instrument\" are the best K=2 clusters for the specific dataset at hand.\n\n\n$\\\\phantom{X}$\n\n**Response to \"The discussion of prior work in deep clustering is also very brief, and does not position the proposed contributions against current, relevant work.\"**\n\nWe do not think the blanket statement that our discussion is \"very (overly) brief\" is accurate. Our discussion of prior work on deep clustering is split across Section 2 *'Comparison with classical clustering'* and Section 5 *'Related work'*, and we do position our proposed contributions against the relevant current state-of-the-art methods. (Incidentally, we, the authors, do have publication experience in clustering methods, unlike in image retrieval.) If the reviewer feels that relevant references in deep clustering have been overlooked, please provide specific pointers, and we will incorporate them into our discussion.\n\n$\\\\phantom{X}$\n\n\n**Response to \"The method requires prior specification of the number of clusters, which is a significant limitation and drawback.'\"**\n\nMost clustering algorithms, including the state-of-the-art methods, require the user to specify target cluster numbers. Therefore, we do not consider this feature to be a limitation or a drawback when positioned against current, relevant work.\n\n\n\n$\\\\phantom{X}$\n\n**Response to \"The method is very simple, just a set of straightforward text prompts. The crucial step of doing the clustering is just deferred to the LLM itself, by asking it to cluster N labels into K categories.\"**\n\nIn our view, the simplicity and straightforwardness of the method is a *strength*, not a weakness. Indeed, our contribution is a reframing of the clustering task in a way that defers the algorithmic heavy lifting to the VLM and LLM. However, finding and exploiting reductions (reframing a certain problem as an instance of another problem for which powerful tools exist) is a classical approach in computer science and machine learning, so it is unclear to us why the reviewer considers this reduction-based approach a weakness.\n\nThe reviewer seems to agree that the task of clustering with text criterion is useful. We ask the reviewer to consider whether the experimental results (rather than the novelty of the method) are convincing and of interest to the ICLR community."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6858/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606395128,
                "cdate": 1700606395128,
                "tmdate": 1700606395128,
                "mdate": 1700606395128,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]