[
    {
        "title": "Causal analysis of social bias in CLIP"
    },
    {
        "review": {
            "id": "zsLbbHttMD",
            "forum": "Dk10QugVHb",
            "replyto": "Dk10QugVHb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7341/Reviewer_mYoV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7341/Reviewer_mYoV"
            ],
            "content": {
                "summary": {
                    "value": "The paper analyzes social bias in CLIP image and text embeddings by comparing the cosine similarity between images of faces and attributes extracted from social psychology. The paper claims to study causality rather than correlations using a synthetic dataset, CausalFace."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is well-written and well-motivated, it is easy to read and understand and it does a good job at positioning itself with respect to the related work, which is relevant and up-to-date."
                },
                "weaknesses": {
                    "value": "W1. The novelty of the paper may be limited, as there is already abundant literature studying correlations between image and attribute embeddings in CLIP (many already cited in the related work). The contributions of this study are 1) using attributes from social psychology instead of a self-defined list of words, and 2) claiming causality instead of correlation. The first contribution may not be enough by itself, whereas the second contribution is challenged in the following point. \n\nW2. The paper argues that the analysis conducted on the CausalFace dataset, in contrast to FairFace, implies causality and not only correlation because the elements/confounders in CausalFace can be controlled by the generation process. However, it could be argued there is not enough evidence to assume there are no confounders in CausalFace just because it has been generated synthetically. \n\nSpecifically, images in CausalFace have been generated using a GAN by imitating a training distribution. The training distribution may very likely present biases, which could be learned and transferred to the synthetic images. Hence, concluding that using synthetically generated images implies causality may not stand. It would be interesting to discuss how the potential biases in the image generation algorithm can affect the results of this study.\n\nW3. I would say the main paper is not self-contained. Many necessary details to understand the flow of the paper and its conclusions are placed in the supplementary material. This is a subtle way of evading the 9-page limitation. The supplementary material should be used for extra information only. Some examples:\n- The metrics computation, especially the cosine similarity between the image and attribute embeddings is essential to understand the results in, e.g. Table 1, but its definition is in Appendix A1.\n- The whole section 4.1 discusses results that are not in the paper but in Appendix B."
                },
                "questions": {
                    "value": "- I am curious to know why the authors chose to use the phrase \u201c*legally* protected attributes\u201d to refer to demographic attributes such as race, gender, or age, as the adjective *legal* (i.e. referring to the law) has different interpretations in different places of the world.\n\n- Why only use 3 groups (Asian, Black, White) from FairFace instead of all the data?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7341/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698126641094,
            "cdate": 1698126641094,
            "tmdate": 1699636878347,
            "mdate": 1699636878347,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pAtWWnYeKt",
                "forum": "Dk10QugVHb",
                "replyto": "zsLbbHttMD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7341/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7341/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Reply Addressing Identified Weaknesses and Questions."
                    },
                    "comment": {
                        "value": "We thank reviewer mYoV for their insightful remarks. \n\n**W1**: The reviewer's observation that our paper employs ``attributes from social psychology instead of a self-defined list of words\" may not fully acknowledge the depth and scientific rigor associated with using psychometrically validated scales; We refer to [Furr (2021)](https://books.google.ch/books?hl=en&lr=&id=xto9EAAAQBAJ&oi=fnd&pg=PT14&dq=Psychometrics:+An+Introduction&ots=FeGG0pXykH&sig=qeu28wVVW03Ji9G1Hzv3H3_t2SE&redir_esc=y#v=onepage&q=Psychometrics%3A%20An%20Introduction&f=false) for an introduction to the field of Psychometrics. Moreover, the widespread adoption of the SCM and ABC models underscore their practical relevance in measuring stereotype perception. Thus, our decision to utilize validated scales in our study is not a mere preference for a different list of words but a deliberate choice to enhance the contribution of our research to the field.\n\n**W2**: Yes, it is important to check for biases, artifacts, and confounds. If the referee has specific concerns, we will be the first ones to want to hear about them. The reviewer asks for \"evidence of absence of confounders\". Unfortunately, that is typically impossible to come by. However, the evidence for the presence of confounders is precious. We selected the Liang (2023) dataset precisely because it was carefully controlled. They verified that attribute manipulations were equally effective across different demographics using the ratings of five annotators per image (Fig. 3, Liang 2023). They checked for visible image artifacts (Sec 4.1) and excluded all images containing artifacts from their dataset. We have added to the manuscript a sentence discussing this (please also see response to referee 3zN2). Are we sure that all possible confounds and biases have been eliminated? Of course not. That would be foolish. In the history of science, there are many examples of important experiments where confounds and biases were hammered out year after year by generations of scientists. The crucial point is adopting the scientific method, which is based on experimentation, and experiments may be refined over time. We argue that measurements of bias in AI models now can, and thus must, move beyond correlations. Generative methods offer a practical way forward toward controlled experiments and causal conclusions. Thanks to progress in generative AI and constructive scrutiny from an engaged community of scholars, we expect our measurements to become more accurate with time.\n\n**W3**: We have thoroughly revised our paper in light of the reviewer's critique. We concur on the need to clarify the definition of cosine similarity, therefore we introduced equation (1) in section 3.1. Although our paper also utilizes metrics like WEAT, mean cosine similarities, and markedness, we have chosen to keep their detailed descriptions in the appendix. This decision aligns with common academic practices of detailing mathematical methodologies in supplementary materials, rather than in the main text, especially since these metrics are well-established and not novel contributions of our work. Section 4.1 was moved to the appendix, now appendix C, as we think it is not part of the main results of our paper but rather a supporting analysis that helps interpreting the results in Fig. 2.\n\n**Q1**: Despite variations in national laws, global human rights standards set by the United Nations\u2014like UDHR, ICCPR, ICESCR, and CEDAW\u2014mandate non-discrimination based on race, age, and gender. While some countries may not legally protect these attributes, the majority do. Hence, we refer to these variables as legally protected, aligning with the scholarly consensus in various fields.\n\n**Q2**: Our study compares FairFace to CausalFace; The latter however only includes three races: Asian, White, and Black. Some researchers might be interested in analyzing social perceptions across all FairFace races without comparing them to CausalFace. We will open-source our code, which allows those researchers to adapt our experiments to all racial categories in FairFace."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700139583999,
                "cdate": 1700139583999,
                "tmdate": 1700151674364,
                "mdate": 1700151674364,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "D8kDQDTWbv",
                "forum": "Dk10QugVHb",
                "replyto": "zsLbbHttMD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7341/Reviewer_mYoV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7341/Reviewer_mYoV"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "The reviewer thanks the authors for their response.  The reviewer acknowledges the time and effort invested in elucidating the raised concerns. While the reviewer values the comprehensive insights provided in the response, the reviewer has concerns about the choice of tone in response W2. The reviewer understands that discussions in the scientific community merit a respectful and collaborative tone. The reviewer's intentions were only to raise constructive criticism to improve the scientific contribution of the reviewed work. \n\nIn the following, the reviewer addresses the specific points raised in the response:\n\nW1: The initial review did not intend to overlook the significance and scientific rigor linked with the utilization of psychometrically validated scales. On the contrary, the original review explicitly recognized this aspect as a primary contribution of the paper. The central query posed in the initial review pertains to whether this particular contribution, in isolation, constitutes a sufficient basis to warrant submission to ICLR. Regrettably, the authors have not yet addressed this specific concern in their response.\n\nW2: The reviewer remains unconvinced regarding the assumption that synthetic datasets do not introduce artifacts or confounds. This concern is fundamental, given the paper's assertion of studying causality rather than correlation. It is incumbent upon the authors to provide a robust justification to assure readers that the study indeed warrants claims of causality. Notably, ample evidence suggests the presence of gender artifacts in visual datasets across various image levels [1]. Consequently, it remains unclear whether the utilization of a synthetic dataset eliminates these artifacts or if they are learned and transferred within the generative model.\n\nW3: Thanks for reviewing the paper to make it self-contained.\n\nQ1 and Q2: Thank you for answering the questions.\n\nReference: [1] Meister et al. Gender Artifacts in Visual Datasets. ICCV 2023."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700636348110,
                "cdate": 1700636348110,
                "tmdate": 1700636528507,
                "mdate": 1700636528507,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LRwITvesFK",
            "forum": "Dk10QugVHb",
            "replyto": "Dk10QugVHb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7341/Reviewer_qwQ3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7341/Reviewer_qwQ3"
            ],
            "content": {
                "summary": {
                    "value": "This paper conducts an analysis of bias in CLIP using a generated dataset of faces, leveraging its generated nature to draw more precise, causal-type conclusions. They examine cosine similarity in CLIP space to various words from well-known social psychological frameworks. They present a number of empirical takeaways, including that conclusions from finely-controlled generated data can differ from pre-existing, real data and that several confounding variables (e.g. \"smiling\") can also affect bias measurements."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- this is an interesting empirical analysis which makes some important points about bias evaluation \n- makes intelligent choices in evaluation design, a good example of what this can look like\n- interesting takeaways around difference between synthetic and real data, as well as confounding variables"
                },
                "weaknesses": {
                    "value": "- I think the title should be a little more precise - specifically this is around \"social bias in CLIP for face images\" or something, it's not studying all areas of bias\n- Figure B.1 was unclear to me - I'm not sure how to read the point about within vs cross valence similarities off this plot\n- Sec 4.2: I get a little confused about a few of the evaluation procedures here. For instance, I think \"mean cosine similarities\" could be explained a bit more - I can guess what it might be but don't know for sure. Also I think markedness is not explained so clearly: not clear what \"relative preference frequency\" is or a \"neutral prompt\" - again I could guess but should be written out.\n- I think the point about positive correlation between positive and negative terms is a good one, I think this could be shown more strongly with a \"control group\" of words: is it that some images are just correlated to all words? words of a certain type?\n- the word \"intensity\" is used without definition - what does this mean?\n\n\n\nSmall notes:\n- typos: bottom of p1: 'sd',\n- Sec 3.4: unclear how these thresholds are determined or what they really mean (e.g. 0.7 for age)\n- what is the x-axis in Fig 3a?\n- Fig 3b and commentary at end of 4.4: if I'm reading this correctly, most groups negative associations decrease as smiles intensify - it's stated here that this is unusual for black males."
                },
                "questions": {
                    "value": "- I think the observation that \"the widely held belief that age- and gender-induced variations are strong factors needs to be reconsidered\" is misguided (end of 4.5 and 5). The authors seem to believe that social factors like gender receive special attention since they are causes of particularly strong deviations - I think this misses an important point. It isn't that these factors necessarily cause the largest deviations (of course other visibly salient factors will matter), it's that these factors are important for socially determined reasons, and therefore measuring model impacts and mitigating disparities/harms where they exist matters more"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7341/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698775021640,
            "cdate": 1698775021640,
            "tmdate": 1699636878229,
            "mdate": 1699636878229,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "chI4F78pMq",
                "forum": "Dk10QugVHb",
                "replyto": "LRwITvesFK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7341/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7341/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Reply Addressing Identified Weaknesses, Small Notes, and Question."
                    },
                    "comment": {
                        "value": "We thank reviewer qwQ3 for their positive assessment and insightful remarks.\n\n**W1**: You are inviting us to make our title more specific and we agree:  *\"A causal analysis of social bias towards faces in CLIP.\"*\n\n**W2**: We agree with the reviewer that the figure caption (now Figure C.3)  was unclear. The interpretation of the figure was moved to the appendix and a mathematical definition was added: *\"Specifically, let $a^+_1$ and $a^+_2$ be two text embeddings of attributes of the positive valence agency dimension, and $a^-_1$ and $a^-_2$ be text embeddings of attributes of the negative valence agency dimension. The within-valence similarity is given by calculating the cosine similarities $ \\cos{(a^+_i, a^+_j)}$ for all positive attribute pairs \\( (i,j) \\). The cross-valence similarity is determined by calculating $ \\cos{(a^+_i, a^-_j)}$ for all mixed attribute pairs \\( (i,j) \\).\"*\n\n**W3a**: We agree that mean cosine similarities were not defined sufficiently. For clarification, we moved Eq. 1 from the appendix to the main paper (see. Sec. 3.1.). In addition, we added further explanation in the results section when discussing Table 1, which reads as follows: *\"Mean cosine similarities are calculated as the mean of cosine similarities between an image category and all attribute categories of SCM and the positive attribute categories of ABC (see Equation (1))\"*.\n\n**W3b**: We added appendix A.3 to further explain and mathematically define markedness.\n\n**W4**: We show the positive correlation of positive and negative valence attributes in Figure 2. The high correlation is however only visually assessed. We agree with the reviewer that we should calculate a correlation coefficient. We did so for each dimension (agency, belief, communion) and for each intersecting group separately. We plot and interpret a heatmap of correlations in Figure C.4.\n\n**W5**: Indeed, it was not obvious what the term \"intensity\" means in the context or study. Therefore, we added the following explanation when it was first introduced: *\"In this context, we use valence as the direction of change in cosine similarity (increasing or decreasing) and intensity as the magnitude or absolute difference in change.\"*\n\n**SN2**: To maintain consistency with Liang (2023), we kept the original scales for smiling (-2.5 to 4) and age (0.8 to 4.4), as shown in Figures D.2 and D.3. For smiling, the non-equidistant levels range from -2.5 to 4. We selected a threshold of 0.7 to distinguish between sufficiently different smiling faces, deliberately excluding the 0.5 increments. A similar approach was applied to age. To avoid confusing a future reader, we introduced the following footnote: *\"The effect of the thresholds can be better understood by looking at the scale of Figures D.2 and D.3\"*\n\n**SN3**: To avoid redundancy between the title and the x-axis label in Figure 3a, the x-axes are unlabeled. To clarify, we have added to the figure caption: *'The three panels depict the variations in smiling, lighting, and pose on the x-axis.'*\n\n**SN4**: We agree that we should have been more precise with the use of language at this point. The patterns of all gender-race intersections look similar, with one exception: Male-blacks. Only for this group does smiling lead to an increase in positive social perception. The interpretation needs to be more nuanced. There is a subtle but existing difference between stating a \"glass is half full\" versus \"a glass is half empty\". Similarly, there is a subtle but existing difference between describing someone with less negative terms or more positive terms. Black males are the only group that is described predominantly with more positive terms as the smile increases. We changed the corresponding description in the paper to: *\"For \"belief\", only black males deviate from the pattern consistently observed for the remaining subgroups.\"*\n\n**Q1**: We appreciate the reviewer's insightful feedback on our discussion of variations in legally protected versus non-protected variables. We acknowledge that the original phrasing might have led to misunderstandings. We concur with the reviewer that gender, race, and age are socially significant factors, meriting the focused research they receive. Their importance indeed underscores our call for greater precision in measurement and a thorough examination of potential confounds in statistical analyses. To clarify our position, we have revised the statement at the end of section 4.4: *\"Our observations suggest that non-protected attributes are important and should be taken into consideration to obtain a clear measurement of the socially relevant age- and gender-induced variations.\"*"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700139245792,
                "cdate": 1700139245792,
                "tmdate": 1700139886024,
                "mdate": 1700139886024,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oxwQrW6KFm",
                "forum": "Dk10QugVHb",
                "replyto": "chI4F78pMq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7341/Reviewer_qwQ3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7341/Reviewer_qwQ3"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks for this rebuttal - I appreciate the clarifications and the paper (still) looks good to me. I'm going to follow up on a discussion in another review that I think raises a good point."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497658835,
                "cdate": 1700497658835,
                "tmdate": 1700497658835,
                "mdate": 1700497658835,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ysK1Oimsb7",
                "forum": "Dk10QugVHb",
                "replyto": "zsLbbHttMD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7341/Reviewer_qwQ3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7341/Reviewer_qwQ3"
                ],
                "content": {
                    "title": {
                        "value": "Raises a good point re: confounders"
                    },
                    "comment": {
                        "value": "Just wanted to chime in here that I think reviewer mYoV raises a good point about the possibility of confounders in this generated dataset making this signal less clean. I think this is actually fairly essential to this paper and something I hadn't thought of in my review. The authors response that this is something considered in the original dataset is good and I appreciate that it was added to the discussion section - in my opinion, given how important this is, the evidence that these confounders are minimal should be moved up to 3.2 where the CausalFace dataset is introduced.\n\nExtra thought: the authors are quite dismissive of this point in their rebuttal and the response around the \"history of science\" comes off as somewhat condescending imo. In fact, this is an extremely reasonable and important critique of the paper on which the legitimacy of its contribution rests, and it was something which was not addressed at all in the original draft. In the \"history of science\", I agree that experiments are not guaranteed to come without confounds, but this mostly applies to observed phenomena (e.g. natural experiments): here, we are dealing with entirely controlled settings and should be aiming for a higher bar, particularly given the (strong) claims of the paper."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700498048366,
                "cdate": 1700498048366,
                "tmdate": 1700498048366,
                "mdate": 1700498048366,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iu7SYwQL6C",
            "forum": "Dk10QugVHb",
            "replyto": "Dk10QugVHb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7341/Reviewer_3zN2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7341/Reviewer_3zN2"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies biases in CLIP using a synthetic dataset of images generated by GAN, which they refer to as CausalFace. The authors argue that synthetic data offers the opportunity to control for possible confounding factors, such as lighting and pose, leading to a more accurate assessment of biases in CLIP. In their experiments, they consider different labels (e.g. \"friendly\", \"conservative\", etc) that are borrowed from prior works in social psychology (namely the the ABC Model and the Stereotype Content Model) and compare their embeddings with the image embeddings using cosine similarity.\n\nUsing this setup, the authors present several interesting findings. First, they find that non-protected attributes, such as pose and smiling, can have a non-trivial impact. In particular, the variance in the cosine similarity by changing lighting, smiling, and pose is comparable to the variance induced by changing protected attributes. In fact, the impact of \"pose\" is stronger than the impact of \"age.\" The authors study the effect of such factors at a greater depth; e.g.  image-related confounding factors, such as lightning, have less effect that subject-related factors, such as pose and smile. So, non-protected attribute can cause a significant amount of noise when doing bias-related analysis of CLIP. Second, the authors show that because such confounding factors can be controlled in CausalFace, new patterns emerge in CausalFace that are not visible in datasets like FairFace. This is demonstrated, for example, in Figure 2. \n\nOverall, the paper offers an interesting and useful insight when studying biases in multimodal systems. It highlights that confounding factors need to be taken into account, and that correlational studies would typically underestimate biases in models such as CLIP (because of the noise introduced by the confounding factors)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper offers several interesting insights in a topic that is becoming increasingly important. The experimental results are convincing, and the overall message is quite useful to the community. The authors take care in handling several potential issues; e.g. by demonstrating that synthetic data are statistically similar to real images, among others."
                },
                "weaknesses": {
                    "value": "- The first limitation is that the authors use a single dataset only in their analysis, which is FairFace. There are other datasets such as UTK Face and CelebA that can be included to support the argument further. It's not clear if the conclusions in FairFace would continue to hold so showing that they hold in other datasets would strengthen the argument. In addition, MIAP (https://paperswithcode.com/dataset/miap) is quite different from FairFace in that it collects images in natural settings (not just face images) so I would expect those confounding factors to be even more prominent in that dataset. This would be a useful message to point out.\n- There are important places that need further clarity. For instance, can you please provide a precise mathematical definition of \"markedness,\" similar to how WEAT is defined in the appendix? Page 5 explains it a bit but a precise definition should be included. Also, which specific prompts did the authors use to create various levels of \"pose,\" \"lightning\", and \"smile\"? They are not described in the paper or the appendix as far as I can see.\n- The authors focus on sentiment related attributes, such as warmth, communion, competence, etc. It would make sense for these attributes to be impacted by confounders, such as pose and smiling. But, there are other equally important association biases, such as relating gender with occupation, that may not be as sensitive to those issues. These are not studied in the paper."
                },
                "questions": {
                    "value": "- What does \"neutral lightning\" mean? It seems from Figure 3 that neutral lightning may lie at the middle of the scale, which would reveal a pattern that is different from random noise.\n- When comparing the impact of \"smiling\" in Figure 3.b, why did you choose to compare -1.5 with 3.0 instead of going for the extreme ends; i.e. -2.5 with 4.0? \n- In Section 4.4,  the authors claim that \"black males\" deviate from the expected pattern in Figure 3.b because they are \"the only subgroup showing amplified positive associations with intensified smiles.\" I'm curious to know why the authors think this is unexpected? Shouldn't the fact that the other groups don't exhibit this be the unexpected pattern?\n- Which specific prompts did the authors use to create various levels of \"pose,\" \"lightning\", and \"smile\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7341/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698859475242,
            "cdate": 1698859475242,
            "tmdate": 1699636878117,
            "mdate": 1699636878117,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "v2j6mzRnOK",
                "forum": "Dk10QugVHb",
                "replyto": "iu7SYwQL6C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7341/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7341/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Reply Addressing Identified Weaknesses."
                    },
                    "comment": {
                        "value": "We thank reviewer 3zN2 for their positive assessment and insightful remarks.\n\n**W1**: We appreciate the reviewer's suggestion regarding the selection of face datasets for our analysis. In response, we have thoroughly evaluated each of the proposed datasets and would like to share our rationale behind their consideration: MIAP does not have face crops and, therefore, would introduce a significant amount of noise from contextual elements. These are additional confounding factors that could result in visible differences compared to FairFace. It is not the main goal of our paper to control for these types of confounds; instead, we focus on face-related confounds. MIAP would, therefore, not directly support our findings, and thus, we decided to focus on face-cropped datasets. CelebA meets our criteria but we do not consider it ideal for assessing biases in race, gender, or age groups for the following reason: It is likely that celebrities occur in the training data of CLIP. Therefore, we would assume that embeddings are overly specific to individuals rather than representative of broader demographic groups. Unlike FairFace, which includes only a limited selection of celebrities, CelebA is comprised entirely of celebrity individuals. We recognize UTKFaces as a viable alternative to FairFace for our analysis. We are in the process of extending our study to include this dataset and plan to integrate these results before the end of the rebuttal period.\n\n**W2a**: Thank you for highlighting the need for clarity in the definition of markedness. To address this, we have added Appendix A.3 which succinctly reviews related works, illustrates the concept with examples, and provides a precise mathematical definition.\n\n**W2b**: We do not generate synthetic images ourselves but the dataset was pre-generated and made available to us by Liang (2023).\nSmiling, lighting, and pose are dimensions generated through latent space traversals using a GAN to create face images. The specific manifestations of these dimensions in the images are illustrated in Appendix D. Upon reviewing our paper's section on image datasets, we acknowledge a potential source of confusion. Initially, we mentioned \"we generate variations,\" which we have now revised to *\"we sample variations\"* to better reflect our methodology. \n\n**W3**: The reviewer hypothesizes that cosine similarities between warmth/competence-related text prompts and images might fluctuate more significantly due to varying smile/pose levels than those between job type-related prompts and images with similarly varying smiling/pose levels. This is an interesting hypothesis and we do not investigate the relation of smiling/pose to occupation in generative AI and we are not aware of literature that does so. However, research investigating humans suggests that facial attributes do systematically vary with occupation: Facial appearance matters for leader selection [(Stocker 2016)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0159950). More specifically, the width-to-height ratio seems to distinguish CEOs [(Lewis 2013)](https://www.sciencedirect.com/science/article/abs/pii/S0191886912000049) . \nFurthermore, men and women smiled more in response to a low-status job than to a high-status job [(Vrugt 2002)](https://onlinelibrary.wiley.com/doi/10.1002/ejsp.99)--suggesting that smiling may be a more significant predictor of job type than gender. More generally, smiling has been found to differ across age and gender [(Morse 2010](https://www.tandfonline.com/doi/abs/10.1080/00223980.1982.9915318),\n[LaFrance 2003](https://pubmed.ncbi.nlm.nih.gov/12696842/),[Otta 1998](https://pubmed.ncbi.nlm.nih.gov/9923165/),\n[Doff 1999](https://link.springer.com/article/10.1007/BF03395325),\n[DeSantis 2005)](https://pubmed.ncbi.nlm.nih.gov/16342596/). Therefore, we assume that occupation is also sensitive to smiling/pose. \nConsequently, there is no clear answer to the question of which outcome metric is more sensitive to varying levels of smiling/pose. \nThis is an interesting question to ask therefore, we add the following paragraph to the discussion: *\"Our study uses social perception as the primary outcome metric, revealing that smiling and pose significantly affect this measure. Research in human contexts shows that smiling in particular, influences not only social but also job-related perceptions. Future research could focus on practical metrics such as occupation, investigating how varying degrees of smiling and pose impact these aspects in generative AI.\"*"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138173866,
                "cdate": 1700138173866,
                "tmdate": 1700138238150,
                "mdate": 1700138238150,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Lc9bwqnpPN",
                "forum": "Dk10QugVHb",
                "replyto": "iu7SYwQL6C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7341/Reviewer_3zN2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7341/Reviewer_3zN2"
                ],
                "content": {
                    "title": {
                        "value": "Thanks"
                    },
                    "comment": {
                        "value": "Thanks for the reply. Adding UTKFace would strengthen the findings of the paper. Also, thanks for clarifying the misunderstanding about generating the samples, and fixing it in the paper. I agree that adding the last paragraph to the discussions section would be useful to the reader.\n\nBy \"neutral lighting,\" I meant a value of -1 in Figure 3(a), which you have now clarified."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503523497,
                "cdate": 1700503523497,
                "tmdate": 1700503706988,
                "mdate": 1700503706988,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kBOiNTMGnG",
            "forum": "Dk10QugVHb",
            "replyto": "Dk10QugVHb",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7341/Reviewer_SWyU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7341/Reviewer_SWyU"
            ],
            "content": {
                "summary": {
                    "value": "In this work the authors investigate social perception biases in CLIP through the lens of social psychology. For this analysis, the authors use real-images and synthetic image datasets. The analysis reveal several interesting findings: pose and facial expression can have strong social perception, legally protected variables do not introduce greater biases than non-protected attributes."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**1. Originality:** I found this paper sufficiently novel. It deviates from the traditional way of measuring biases and systematically controlling the factors while measuring the biases.\n\n**2. Well explained motivation:** The motivation provided in the introduction is excellent. It lays out the  disadvantages of the current bias studies and how they aim to solve those.\n\n**3. Strong analysis along multiple axes:** The authors did an excellent job in providing detailed analysis along multiple axes eg: intersectional biases in Figure-2."
                },
                "weaknesses": {
                    "value": "**1. Clarity:** I found the paper little difficult to follow especially in the sections 3.2 in which the authors describe about theoretical frameworks of social phycology. The authors can provide more context about these frameworks and how are they related in the proposed study in the form of examples, figures etc.\n\n**2. Unaddressed questions about biases in synthetic datasets:** The authors didn't include discussion about potential limitations in the synthetic faces created using GANs."
                },
                "questions": {
                    "value": "1. Can these findings be applicable to other vision-language models?\n\n2. Is there any reason to authors not using bias metrics like max-skewness or NDKL?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7341/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7341/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7341/Reviewer_SWyU"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7341/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698991971405,
            "cdate": 1698991971405,
            "tmdate": 1699636877928,
            "mdate": 1699636877928,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0m50d6XOHW",
                "forum": "Dk10QugVHb",
                "replyto": "kBOiNTMGnG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7341/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7341/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Initial Reply Addressing Identified Weaknesses and Raised Questions"
                    },
                    "comment": {
                        "value": "We thank reviewer SWyU for their positive assessment and insightful remarks.\n\n**W1**: To address the reviewer's concerns concerning clarity, we have made the following revisions: Firstly, we revised section (formerly) 3.2/ now 3.1 and additionally include mathematical notation. Additionally, we improved the caption of Figure B1, which now conveys our methodology more transparently. Secondly, recognizing the constraints of paper length, we have introduced Appendix A.4, which contains a detailed discussion of social psychology's view on stereotypes, and add additional references. This should provide an in-depth background for readers with a specific interest in the theoretical underpinnings of our study.  We also made concise changes to section 2.2 to logically connected both models by stating: \n*\"A more recent framework, the ABC Model, Koch(2016), proposes beliefs as alternative central dimension, and subdivides the Warmth and Competence differently into two categories.\"* Furthermore, we introduce both theories by stating that *\"social psychology has long been recognized for delineating the primary dimensions of beliefs about stereotypes.\"* Thirdly, we justified the integration of social psychology frameworks within our study as follows in 2.2: *\"Given the reflection of human-like biases in Generative AI, our study employs two leading theoretical frameworks from social psychology\u2014long recognized for quantifying cognitive biases\u2014to measure stereotypes systematically\"*. In all sections, we have striven for consistency in terminology, using \"dimensions\" and \"attributes\" to describe the components of the SCM and ABC models consistently. We hope these changes address your concerns, and we invite your further feedback to refine our manuscript.\n\n**W2**: Thank you for pointing this out. Yes, we should have commented on this. We have included the following statement in the discussion: *\"Generative models, in particular GANs and Diffusion Models, can now generate face images that look realistic to human observers, and one can effectively control some of the facial attributes. There are three caveats. First, manipulating one attribute may induce unwanted changes in other attributes;  Balakrishnan (2021) show how to address this issue systematically, and it should be checked by visual inspection, as was done for the dataset we use (Liang 2023). Second, it is possible that some physiognomies are generated more frequently than others. E.g., within the European group, it is possible that more Mediterranean-looking and fewer Scandinavian-looking physiognomies are generated. If this were a concern for a study, one would have to come up with a fine-grained definition of race and control this attribute directly, as our dataset does for the main racial groups. Third, it is possible that facial attribute manipulations are more or less effective for some or the other demographic groups. For the dataset we use, this was excluded by direct verification with human annotators (Liang 2023, Fig. 3.). Generative methods and techniques to validate their output are progressing fast. Thus, the experimental method we advocate, based on carefully controlled synthetic data, will become an increasingly attractive option for researchers.\"*\n\n**Q1**: One could expect that bias stems from training data (i.e., text-image pairs) rather than the model architecture. Therefore, we would expect that our findings apply to other models if they are trained on similar datasets. We present our method primarily as a tool for investigating biases in such models. Following the reviewer's question, we have updated the discussion section to emphasize the applicability of our approach to future research on a broader range of vision-language models.\n\n**Q2**: Besides WEAT, we considered max-skewness and NDKL as alternative bias metrics but eventually omitted these results. Responding to the reviewer's interest, we are now reintegrating these findings into the paper and will present them before the rebuttal period concludes."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7341/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700138192587,
                "cdate": 1700138192587,
                "tmdate": 1700138192587,
                "mdate": 1700138192587,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]