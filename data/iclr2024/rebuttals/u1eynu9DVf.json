[
    {
        "title": "What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement"
    },
    {
        "review": {
            "id": "CWtzyRwa8U",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4813/Reviewer_PJD2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4813/Reviewer_PJD2"
            ],
            "forum": "u1eynu9DVf",
            "replyto": "u1eynu9DVf",
            "content": {
                "summary": {
                    "value": "The paper presents a method for mitigating catastrophic forgetting in instruction tuned language models, by building an interpretable forecasting model that predicts which training examples will be forgotten during model refinement, and replaying these examples. The authors compare a logit-based approach, which predicts how token logits on a pretraining example change before and after the model sees the online learning example, and a representation-based approach, which directly predicts whether the online learning example will cause a pretraining example to become erroneous using the latent representations of each example. Although the logit-based approach is more directly interpretable, the representation-based approach is robustly stronger at forecasting as well as mitigating forgetting across various settings (tuning heads only vs. LORA vs. all weights, different types of models)."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This presents a novel and simple approach to tackle catastrophic forgetting, with clear problem formulation and strong motivation (Fig. 1-2 are very good). The paper is easy to read and clearly presented. The authors perform very thorough and thoughtful experiments that convincingly support their proposed method."
                },
                "weaknesses": {
                    "value": "The computational efficiency discussion is very good, but I think reporting actual runtimes for some example settings would also be helpful. E.g. tuning the head only should be faster than the whole model, so I think the asymptotic complexity only tells half the story. It will also help practitioners consider how feasible this method is for their own application."
                },
                "questions": {
                    "value": "Not sure if I missed this but why do the authors hypothesize the logit-based approach is less effective on FLAN vs BART?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4813/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4813/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4813/Reviewer_PJD2"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4813/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697316930096,
            "cdate": 1697316930096,
            "tmdate": 1699636464578,
            "mdate": 1699636464578,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3NZNXFUp5u",
                "forum": "u1eynu9DVf",
                "replyto": "CWtzyRwa8U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer PJD2"
                    },
                    "comment": {
                        "value": "We thank the reviewer for thoughtful and positive comments.\n\n**Q: Reporting actual runtimes for some example settings would also be helpful. E.g. tuning the head only should be faster than the whole model, so I think the asymptotic complexity only tells half the story.**\n\nWe thank the reviewer for the suggestion. We agree that tuning the head is faster than tuning the whole model, and it is also more efficient to obtain ground truth forgotten examples when tuning the head only (assuming that pre-head outputs of upstream training examples can be cached). We discussed computation complexity of two cases separately in our initial version of Sec. 5.4, and concluded that our forecasting methods have better advantages when tuning the entire model.\n\nWe additionally obtained the number of FLOP (number of floating point operations) of forecasting methods as an empirical statistic that measures computational efficiency, which is agnostic to the hardware that we use. We experimented with FLAN-T5-large with 100 examples sampled from each of the 36 pre-training tasks while fine-tuning the entire model.\n\nMethod | FLOP \n-- | --\nRepresentation-based | $1.35e^{10}$\nTrainable Logit-based | $2.15e^{11}$\n \nAs a comparison, the FLOP of running inference on a single example is $2.51e^{11}$ flops. Without forecasting methods, obtaining ground truth forgotten examples requires about $9.02e^{14}$ flops. Our forecasting methods are much more efficient.\n\nWe have included the results in Appendix D and added pointers where we originally discussed computation complexity in Sec. 5.4.\n\n**Q: Why do the authors hypothesize the logit-based approach is less effective on FLAN vs BART?**\n\nWe appreciate the question from the reviewer. In paragraph \u201cPerformance with LoRA or Full Fine-Tuning\u201d in Sec. 5.1, we hypothesized that trainable logit-based forecasting has greatly simplified the dynamics of logits in Eqn. 2; for FLAN-T5, such a simplified model cannot fit the ground truth dynamics; in contrast, the learning dynamics of BART0 may be closer to a linear model and can be captured by our forecasting model. Empirically, we notice that FLAN-T5 models of all sizes (small, base, large, xl) present a similar behavior that logit-based forecasting is less effective. Therefore, we hypothesize that model size is not a key factor; instead, some details during the pre-training phase of these LMs may be crucial. We consider that dissecting factors that contribute to dynamics of logits during continual learning would be an interesting future work."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4813/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700475972925,
                "cdate": 1700475972925,
                "tmdate": 1700475972925,
                "mdate": 1700475972925,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sgDWt06fZy",
                "forum": "u1eynu9DVf",
                "replyto": "3NZNXFUp5u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4813/Reviewer_PJD2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4813/Reviewer_PJD2"
                ],
                "content": {
                    "title": {
                        "value": "Thanks authors"
                    },
                    "comment": {
                        "value": "Thanks for the helpful response. It seems the main criticism of other reviews is that the empirical performance is not strong enough for the method to be practical. I believe the novelty of this method and the general performance improvements over baselines are sufficient to make this an interesting paper at ICLR, so I keep my accept rating."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4813/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700586422316,
                "cdate": 1700586422316,
                "tmdate": 1700586422316,
                "mdate": 1700586422316,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Cp41qRPrgW",
            "forum": "u1eynu9DVf",
            "replyto": "u1eynu9DVf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4813/Reviewer_o5oZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4813/Reviewer_o5oZ"
            ],
            "content": {
                "summary": {
                    "value": "The authors address the challenge of catastrophic forgetting in language models during continual refinement. They introduce a framework to predict which pretraining examples will be forgotten when a model is fine-tuned on new tasks. They propose some baselines and new approaches based on estimating logit change in pretraining sample when a model is finetuned on a new sample. Empirically, the proposed approach work only in one setting on BART models and fails on FLAN-T5 models (more commonly used and large scale)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Problem statement is well motivated\n- Thorough experimentation with proper baselines considered \n- The paper builds up and formalizes an interesting problem which is going to be studied a lot in near future."
                },
                "weaknesses": {
                    "value": "- Writing is quite poor for the methods section. Even after repeated reading, I could not understand how exactly $h$ is being learned for the trainable logit based forecasting. How does one train a LM which maps inputs to h(x), where h(x) is supposed to model the gradient of the model at x wrt $\\theta$. I cannot find any details about this or some reference about this. \n- Authors should clarify in Table 1 that they are predicting a minority class of forgotten examples in a binary classification setting. Hence F1 scores lower than 50% still make sense. In general, the writeup is quite poor. \n- Poor empirical results on real large scale models : The proposed approach is heavily reliant on order 1 approximations of training dynamics, which do not hold true of large models as seen empirically. There are quite marginal gains of vanilla baseline of frequency based forgetting prediction on FLAN. Although I do thank the authors for acknowledging this fact, it still remains a major concern about efficacy and practicality of proposed approaches in the paper."
                },
                "questions": {
                    "value": "See weakness section"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4813/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698646190316,
            "cdate": 1698646190316,
            "tmdate": 1699636464466,
            "mdate": 1699636464466,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JOZAAH0ejw",
                "forum": "u1eynu9DVf",
                "replyto": "Cp41qRPrgW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer o5oZ"
                    },
                    "comment": {
                        "value": "We thank the reviewer for thoughtful comments. \n\n**Q: Writing is quite poor for the methods section. Even after repeated reading, I could not understand how exactly h is being learned for the trainable logit based forecasting.**\n\nWe thank the reviewer for bringing up the clarity issue. In the updated version, we added algorithm boxes for logit-based and representation-based forecasting methods to enhance clarity of the methods in Appendix C.\n\nRegarding the question about how $h(x)$ is computed: the logit-based forecasting method requires a kernel $\\Theta$ that measures similarity between two examples. The first-order analysis in the beginning of Sec. 3.2 suggests that $\\Theta$ should be dot products between gradients of the parameters, which is computationally infeasible, because it requires output length * vocab size backward passes to obtain all required gradients. We therefore propose to approximate with a lower-dimensional learnable kernel $\\tilde{\\Theta}=h(x)h(x)^T$. Here $h(\\cdot)$ is a trainable LM encoder (either BART0 or FLAN-T5, depending on our experiment setup) and $h(x)$ has a much smaller dimension than actual gradients; $h(x)$ is explicitly trained to predict logit updates with a margin loss objective in Eq. 3.\n\n\n**Q: Authors should clarify in Table 1 that they are predicting a minority class of forgotten examples in a binary classification setting. Hence F1 scores lower than 50% still make sense.**\n\nWe thank the reviewer for the suggestion. We have updated the captions in Table 1 to highlight the skewed nature of the class distribution.\n\n**Q: Poor empirical results on real large scale models**\n\nThank you for pointing out the issue. We also acknowledged in abstract that logit-based forecasting performs well on BART0 but not on T5 models. However, for the other proposed method, representation-based forecasting, the performance improvement is clearer when we replay forecasted examples, as we see in Table 4. For example, we reduce EM drop ratio from 1.489 to 0.301 on FLAN-T5 with LoRA tuning.\n\nAs a pioneering work on forecasting forgotten examples, we hope our findings can inspire future study on further algorithmic improvement."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4813/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700475260784,
                "cdate": 1700475260784,
                "tmdate": 1700475260784,
                "mdate": 1700475260784,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DSTERlUVim",
                "forum": "u1eynu9DVf",
                "replyto": "JOZAAH0ejw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4813/Reviewer_o5oZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4813/Reviewer_o5oZ"
                ],
                "content": {
                    "title": {
                        "value": "Significance of the numbers"
                    },
                    "comment": {
                        "value": "I am still not convinced with the empirical results which authors provide. For example, in Table 4, the authors show a decrease in EM drop from 1-3% (with random replay) to almost no drop i.e. 0.5% with their approach. How significant this improvement is? It looks like the initial drop in EM itself on the $D_{PT]$ was low itself. \nAlternatively put, how many more samples would have to be replayed with random replaying, if we wanted to achieve a similar EM ratio like the proposed approach? (I am sure that more random replay can match the performance, so it would be a good indicator to highlight the importance or significance of the numbers). I am fine even if the authors give a vague estimate. \n\nMy concerns above also stem from Table 3, where the numbers do not make sense at all to me. The EM drop with vanilla FT seems to be < 1% (unless the numbers are in the range 0-1, which would be a weird choice). If the numbers are <1%, I would suggest the authors to choose a better problem setting where they show the efficacy of their approach.\n\nFinally, I take a strong exception to the authors self-claiming of their work as a \"pioneering work\" repeatedly, even in the response to the other reviewer. While I understand everyone loves their work (and no issues with that), please avoid these extravagant claims, as it is something one should leave to the community. I am not really sure which reviewer or org or conference gave this work the label of \"pioneering work in forecasting forgotten examples\""
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4813/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700545983484,
                "cdate": 1700545983484,
                "tmdate": 1700545983484,
                "mdate": 1700545983484,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ajpS5orTAE",
                "forum": "u1eynu9DVf",
                "replyto": "Cp41qRPrgW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to follow-up comments"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the prompt response and follow up comments. \n\n**Q: How many more samples would have to be replayed with random replaying, if we wanted to achieve a similar EM ratio like the proposed approach?**\n\nWe thank the reviewer for suggesting this comparative study. We additionally show EM Drop ratio on FLAN-T5-large (Full FT) when we replay more mini-batches of upstream examples. In our default setup, we replayed 1 mini-batch every 10 update steps (Sec. 4.2), which corresponds to 3 mini-batches while learning a single online learning example (as we use 30 steps to learn an example).\n\n**Table: Fixing single errors (setups in Table 3)**\n\n#. Replayed examples | EM Drop Ratio %\n-- | --\n3 | 0.068 \n6 | 0.064 \n15 | 0.122\n30 | 0.138 \n\n**Table: Continually fixing multiple errors (setups in Table 4)**\n\n#. Replayed examples | EM Drop Ratio % \n-- | --\n3 | 1.129 \n6 | 0.869 \n15 | 0.038 \n30 | -0.141 \n\nWhen fixing single errors, increasing the number of replayed examples over a certain limit causes increased forgetting. Replaying more examples cannot achieve improvement brought by Replay w/ Threshold (0.024) or Replay w/ Representation (-0.026) in Table 3.\n\nWhen continually fixing multiple errors, increasing the number of replayed examples consistently reduces forgetting. By comparing to the results in Table 4, the EM Drop Ratio % of replaying 3 mini-batches in Replay w/ Representation (0.582) is between that of replaying 6 to 15 mini-batches of random examples.\n\nIn the manuscript, we included the results and discussions above in Appendix E.2. \n\n**Q: It looks like the initial drop in EM itself on $D_{PT}$ was low, especially in Table 3. I would suggest the authors to choose a better problem setting where they show the efficacy of their approach.**\n\nWe agree with the reviewer that the forgetting of FLAN-T5 models is small when updating models on a single online learning example. In some problem setups, e.g., when online learning examples represent conflicting knowledge, we may expect more severe forgetting.\n\nHowever, our intention was to simulate a common setup where online learning examples and upstream data are not clearly conflicting. We see intriguing cases where learning one example causes forgetting of an irrelevant example (as exemplified in Figure 1).  For this purpose, we did not go over manual construction procedures of online learning examples; instead, we just collected mispredicted examples from some standard NLP benchmarks. As our results indicate, LMs like FLAN-T5 models only forget <1% of upstream examples (Table 3) (which also makes forecasting more challenging due to class imbalance). Still, we see the forgetting accumulates over continual updates and reaches 1-3% of EM Drop with replaying (Table 4) and may potentially get worse with a longer stream of online examples.\n\nAfter discussions with the reviewer, we consider it meaningful to extend to setups where forgetting is more severe in nature by (1) finding more dataset setups (2) longer data streams. Given the tight deadline, we have to leave them in future work. Still, we hope the results in the presented setup can be helpful to the community.\n\nFinally, it is not our intention to bring extravagant claims. I apologize for misunderstanding the degree of the term \u201cpioneering work\u201d. I just wanted to show the novelty of the problem setup. Thank you for pointing this out this language use issue."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4813/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700648257682,
                "cdate": 1700648257682,
                "tmdate": 1700648339483,
                "mdate": 1700648339483,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BVt4bMUZkW",
                "forum": "u1eynu9DVf",
                "replyto": "ajpS5orTAE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4813/Reviewer_o5oZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4813/Reviewer_o5oZ"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the reviewers for their efforts in trying to resolve my concerns. As the authors themselves stated, this paper can gain much more from better empirical evaluations, where the comparisons (and the forgetting phenomenon to start with) are much more meaningful. I honestly feel that this paper can really gain a lot from another cycle of submission, where they try to incorporate my comments, search for better experimental settings and show better gains. Hence, I would like to maintain by current score of 5, \"weak reject\"."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4813/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700690146733,
                "cdate": 1700690146733,
                "tmdate": 1700690146733,
                "mdate": 1700690146733,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "L6llKrARKt",
            "forum": "u1eynu9DVf",
            "replyto": "u1eynu9DVf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4813/Reviewer_rXCe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4813/Reviewer_rXCe"
            ],
            "content": {
                "summary": {
                    "value": "In a continual learning framework focused on LM\u2019s the authors study the problem of  predicting which samples from the upstream data a model is likely to forget after it has been trained on new data.  This is then also used to improve the samples selected for replay from upstream data (focusing on the ones to be forgotten)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The authors focus on a timely and relevant setting of continual learning for LMs\n- The approach is computationally efficient and reasonably well motivated\n- The authors point out an interesting phenomenon of logit change\n- Results of using forecasting for augmenting replay seem to be promising"
                },
                "weaknesses": {
                    "value": "- The experiments can benefit from some quantitative results about the computational efficiency, for example in Table 4 what is the overhead of the approach compared to replay w/random\n- The authors describe several prior works on forecasting (albeit not in the LM space) it would be interesting to experimentally compare these methods to the proposals"
                },
                "questions": {
                    "value": "It would be interesting to know if the method and observations are applicable to classification problems or other continual learning domains"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4813/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699038993969,
            "cdate": 1699038993969,
            "tmdate": 1699636464396,
            "mdate": 1699636464396,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "onJMG0d9xX",
                "forum": "u1eynu9DVf",
                "replyto": "L6llKrARKt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer rXCe"
                    },
                    "comment": {
                        "value": "We thank the reviewer for thoughtful comments. We address the reviewer\u2019s comments below.\n\n**Q: The experiments can benefit from some quantitative results about the computational efficiency, for example in Table 4, what is the overhead of the approach compared to replay w/random?**\n\nWe thank the reviewer for the question. In the new version, we included the number of FLOP (floating point operations)  of forecasting methods in Appendix (assuming 100 examples per pretraining task and full fine-tuning of FLAN-T5-large) and added pointers in Sec. 5.4. We believe the FLOP are good empirical statistics that complement theoretical complexity analysis already presented in Sec. 5.4.\n\nMethod | FLOP \n-- | --\nRepresentation-based | $1.35e^{10}$\nTrainable Logit-based | $2.15e^{11}$\n \nAs a reference, without forecasting methods, obtaining ground truth forgotten examples requires   about $9.02e^{14}$ Flop.\n\nFurthermore, the number of replayed examples is controlled across all replay-based methods in Table 4. Therefore, the results above are the only overhead of replaying forecasted examples compared to replay w/random.\n\n**Q: The authors describe several prior works on forecasting (albeit not in the LM space) it would be interesting to experimentally compare these methods to the proposals**\n\nWe discussed several related works that analyze features of forgotten examples and learning dynamics in Sec. 6. However, none of them studies the challenge of \u201cforecasting\u201dexample forgetting. We believe we are the first to propose the task, set up baselines, and evaluate the performance of forecasting. \n\n**Q: It would be interesting to know if the method and observations are applicable to classification problems or other continual learning domains**\n\nWe thank the reviewer for the suggestion. In this paper we formulated all NLP tasks as sequence-to-sequence generation tasks (Sec. 2) and experimented on P3, MMLU datasets that consist of diverse NLP tasks. These tasks include classification problems (e.g. sentient analysis, natural language inference) that are answered in a sequence-to-sequence format. We believe it is an interesting future work to apply the approach in other continual domains, such as vision domains, given the increasing interest in model refinement in various scenarios."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4813/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700475061728,
                "cdate": 1700475061728,
                "tmdate": 1700475061728,
                "mdate": 1700475061728,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "croUqninNv",
            "forum": "u1eynu9DVf",
            "replyto": "u1eynu9DVf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4813/Reviewer_QYTw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4813/Reviewer_QYTw"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a method to predict what kind of information is forgotten when further training language models.\nIn particular, it proposes a partially inter-pretable forecasting model based on the observation that changes in pre-softmax logit scores of pre-training examples resemble that of online learning examples. Further a black-box classifier based on inner products has improved the forecasting performance. Based on the forecasting model, using examples that are forcasted to be forgotten to train the model can mitigate the forgetting issue."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea of predicting forgotten examples are novel.\n2. The method is quite easy to understand and implement.\n3. Solving the forgetting issue has practical application values in pretrained language models."
                },
                "weaknesses": {
                    "value": "1. The experiment results reveal that the improvement over the baseline is quite marginal.\n2. A more insightful experiments could be done to analyze why some examples are more import than others when training the model in terms of forgetting.\n3. The relation between the further-training and forgetting is not quite clearly explained."
                },
                "questions": {
                    "value": "1. Are the predicted samples sensitive to the training order of the same set of samples?\n2. How the forgotten samples are related to the training data, learning rate, etc?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4813/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4813/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4813/Reviewer_QYTw"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4813/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699347541963,
            "cdate": 1699347541963,
            "tmdate": 1699636464324,
            "mdate": 1699636464324,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "22TbB4wiUc",
                "forum": "u1eynu9DVf",
                "replyto": "croUqninNv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4813/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer QYTw"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the thoughtful comments. We address the questions and comments below.\n\n**Q: The experiment results reveal that the improvement over the baseline is quite marginal**\n\nThank you for pointing this out. We also acknowledged in abstract that logit-based forecasting performs well on BART0 but not on T5 models. \n\nNevertheless, the other algorithm we presented, representation-based forecasting, improves over baseline consistently. In fact, the performance improvement is clearer when we replay forecasted examples (Table 4). As an example, we reduce EM drop ratio from 1.489 to 0.301 on FLAN-T5 LoRA.\n\nAs a pioneering work on forecasting forgotten examples, we also hope our findings can inspire further algorithmic improvement.\n\n**Q: Are the predicted samples sensitive to the training order of the same set of samples?**\n\nWe perform additional experiments to address the question from the reviewer. We notice that examples that are forgotten at the end of the stream are not sensitive to the order of the examples. We see the standard deviation of F1 scores of the forecasting methods are small as we alternate the order of training examples (over 5 different orders).\n\nMethod | Average(std) forecasting F1\n--- | ---\nThreshold | 28.91 $\\pm$ 0.4\nRepresentation-based | 31.24 $\\pm$ 0.9\n\n**Q: How are the forgotten samples related to the training data, learning rate, etc?**\n\nWe thank the reviewer for the question. Certain factors, such as learning rate, have a clear effect on edit success rate and EM drop ratio (forgetting) in continual model updates, as shown below for FLAN-T5-large (full fine-tuning).\n\nLearning rate | Edit success | EM Drop Ratio.\n-- | -- | --\n1e-4 |  95.7 | 24.897\n1e-5 (default) |  95.7 | 3.302\n2e-6 |  93.5 | 1.820\n\nWhen we evaluate the forecasting model trained in the default setup on other learning rate setups, we notice that the precision scores almost remain the same, indicating a common subset of examples are forgotten in three setups; while recall scores differ, because a great number of examples are forgotten only when using larger learning rates. We added the new results in the Appendix E."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4813/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474931469,
                "cdate": 1700474931469,
                "tmdate": 1700474931469,
                "mdate": 1700474931469,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]