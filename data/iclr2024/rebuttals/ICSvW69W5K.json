[
    {
        "title": "Semantic Parsing with Candidate Expressions for Knowledge Base Question Answering"
    },
    {
        "review": {
            "id": "z7KDM4q5Nw",
            "forum": "ICSvW69W5K",
            "replyto": "ICSvW69W5K",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2430/Reviewer_iWQY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2430/Reviewer_iWQY"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a constraint decoding method for semantic parsing. The paper leverages pretrained neural models and tried to narrow down decoding search space by defining IR, type, candidate expressions (whitelisting) to improve semantic parser performance. It goes into details telling the reason why constraint decoding is needed and how it's implemented. Experiment is conducted against KB, and results looks good. The authors put together a complex neural semantic parsing pipeline and proposed a solution for the problem of constrained decoding for non-terminal nodes in structured decoding. On `multi-hop` and `qualifier` test sets, there are decent improvements."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The constraint decoding approach shows decent improvements in experiments.\n- The authors designed an intermediate representation system based on s-expression which is more generic comparing with other constrained decoding method like Picard. The candidate expression is built as a trie tree structure. Comparing with previous work, this work expands the constraints to internal nodes (non-terminal nodes) which would be helpful to narrow down search space. \n- The writing is clean and easy to follow"
                },
                "weaknesses": {
                    "value": "- This is a relatively incremental work. Constraint decoding is not a new idea which is actually widely used in semantic parsing field. The trie tree structure for candidate expression decoding is also not new (similar to GENRE). The novel part is to expand it to non-terminal node. \n- In the era of LLMs, the improvement seems marginal comparing with using large LMs and with more training data."
                },
                "questions": {
                    "value": "- Comparing with using production rules etc, have you tried unstructured decoding method? Maybe this should be a good baseline. \n- Clearly with more data, the constrained decoding doesn't help much. Have you explored data augmentation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2430/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2430/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2430/Reviewer_iWQY"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2430/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697683041624,
            "cdate": 1697683041624,
            "tmdate": 1699636178773,
            "mdate": 1699636178773,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tMCzfw3cV2",
                "forum": "ICSvW69W5K",
                "replyto": "z7KDM4q5Nw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iWQY"
                    },
                    "comment": {
                        "value": "We sincerely thank you for spending your precious time to review our paper.\n\n**Response to Questions**\n\nWe first reply to your questions.\n\n>Comparing with using production rules etc, have you tried unstructured decoding method? Maybe this should be a good baseline.\n\nBART KoPL [1] can be a good baseline that uses unstructured decoding.\nBART KoPL predicts logical forms written in KoPL, which is linearized in postfix representations.\nAn example output sequence of BART KoPL is\n```\n<s>FindAll <func> FilterStr <arg> official website <arg> http://www.thesiege.com/ <func> FilterConcept <arg> visual artwork <func> QueryAttrQualifier <arg> publication date <arg> 1999-01-21 <arg> place of publication</s>\n```\nwhich are represented in our model as\n```\n(query-attr-qualifier (filter-concept (filter-str all-entities \"official website\" \"http://www.thesiege.com/\")\n                                      \"visual artwork\")\n                      \"publication date\" \"1999-01-21\" \"place of publication\")\n```\n\nUnlike ours, BART KoPL splits symbols (e.g. FindAll or FilterStr) into tokens (e.g. Find, All, Filter, Str), then the model has slightly longer output sequences.\n\nWe also analyzed the speed of ours and BART KoPL in the reply to the reviewer pMus.\n\n>Clearly with more data, the constrained decoding doesn't help much.\n\nWe think that constraints on the syntax don't much enhance performance with a large training set,\nsince the limited number of syntactic patterns are repeated in the training set.\nAs your comment, experiment results also show that candidate expressions are less effective with a large training set.\nHowever, we still think that candidate expressions are useful, especially when inferring KB components (e.g. entities or relations) that are unseen during training.\nSimilarly with GENRE [4], candidate expressions would guide semantic parsers when a KB is updated after training (e.g. new entities are added).\n\n>Have you explored data augmentation?\n\nKQAPRO [1] was semi-automatically constructed in two steps [9]; (1) automatically generating pairs of canonical utterances and logical forms by using SCFG, and (2) paraphrasing the canonical utterances by crowdsourcing.\nIn addition, zero-shot semantic parsing [10] showed decent performance without manually annotated training and validation sets.\nAnother interesting work generates syntactic pairs of canonical utterances and logical forms during weakly-supervised learning [11].\n\nThe core of data synthesis method is using SCFGs, which consist of pairs of production rules that generate canonical utterances and logical forms.\nIf we additionally add templates for canonical utterances to all node classes, our grammar can be considered as a SCFG, where a complete intermediate representation can generate a pairs of a canonical utterance and a logical form from two kinds of templates.\n\nWe think that grammar-based data synthesis is a good research area for semantic parsing.\n\n**Additional Explanation**\n\nPlease let us explain more about our paper with respect to your comments.\n\n>In the era of LLMs, the improvement seems marginal comparing with using large LMs and with more training data.\n\nAs your comment, LLMs can achieve high performance with many training examples.\nIn addition, LLMs such as GPT3 enables in-context learning, where our method cannot be directly applied.\nHowever, we've recently found interesting semantic parsers that generate tokens (not production rules) but contrain tokens with respect to SCFGs [2,3].\nFollowing [3], our method can be combined with Earley\u2019s algorithm [12], where our intermediate representations can replace dotted production rules.\nIn our revision, we'll describe [2,3] and the idea of applying our method to [2,3].\n\n**TODO**\n\nWe're going to update our paper during the discussion period.\n\n- Constrained decoding methods [2,3] for pretrained seq2seq will be added to \"Related work\".\n  - We will also briefly describe how our method can be combined with [2,3].\n\n**Gratitude**\n\nWe again greatly thank you for your reviews and feedback.\nIf you have any more comments or questions, please feel free.\n\n**Reference**\n\n[1] KQA Pro: A Dataset with Explicit Compositional Programs for Complex Question Answering over Knowledge Base  \n[2] From Paraphrasing to Semantic Parsing: Unsupervised Semantic Parsing via Synchronous Semantic Decoding  \n[3] Constrained Language Models Yield Few-Shot Semantic Parsers  \n[4] Autoregressive Entity Retrieval  \n[9] Building a Semantic Parser Overnight  \n[10] On The Ingredients of an Effective Zero-shot Semantic Parser  \n[11] Weakly Supervised Semantic Parsing by Learning from Mistakes  \n[12] An Efficient Context-Free Parsing Algorithm"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699982048423,
                "cdate": 1699982048423,
                "tmdate": 1699983160926,
                "mdate": 1699983160926,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ytzRarGteH",
            "forum": "ICSvW69W5K",
            "replyto": "ICSvW69W5K",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2430/Reviewer_4fJL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2430/Reviewer_4fJL"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an approach to semantic parsing over knowledge base using candidate expressions, which improves the accuracy of semantic parsers on knowledge bases. They evaluate their approach on KQAPro and show that it outperforms other state-of-the-art methods. The authors also conduct an ablation study to analyze the contribution of candidate expressions to the performance of the semantic parser. Overall, the paper's contributions include a new approach to semantic parsing using candidate expressions, and an evaluation of the effectiveness of candidate expressions in improving the accuracy of semantic parsers."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- This paper provides a clear and detailed explanation of their proposed approach, including the grammar and inference algorithm used to generate candidate expressions.\n- This paper conducts an ablation study to analyze the contribution of candidate expressions to the performance of the semantic parser. This analysis provides insights into the effectiveness of candidate expressions and how they can be used to improve the accuracy of semantic parsers.\n- The paper is of high quality, with clear and well-organized writing and thorough experimental evaluation."
                },
                "weaknesses": {
                    "value": "The major weakness of this work is its incremental contribution over previous grammar-based methods like [1] and [2]. In particular, [2] uses similar grammars for knowledge base question answering. It is unclear what new techniques or insights this work adds beyond existing grammar-based approaches for this task. To strengthen the paper, the authors could focus more on novel grammar designs or representations that improve performance.\n\nAdditionally, the experimental validation is limited to a single dataset (KQAPro). Testing the approach on an additional challenging dataset like GrailQA [3] would better verify effectiveness and generalization. With only one dataset, it is hard to determine if the performance gains are dataset-specific or represent a robust advancement for grammar-based decoding. Expanding the experimental evaluation would make the results more convincing.\n\nIn summary, clearly situating the contributions relative to prior grammar-based work and testing across more datasets could help address concerns around novelty and experimental validation. Focusing on where this work provides specific technical innovations or new insights would strengthen the paper. \n\n[1]. A Syntactic Neural Model for General-Purpose Code Generation\n[2]. ReTraCk: A Flexible and Efficient Framework for Knowledge Base Question Answering\n[3]. https://dki-lab.github.io/GrailQA/"
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2430/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2430/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2430/Reviewer_4fJL"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2430/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698836486147,
            "cdate": 1698836486147,
            "tmdate": 1699636178685,
            "mdate": 1699636178685,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "q6wBrWhbns",
                "forum": "ICSvW69W5K",
                "replyto": "ytzRarGteH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4fJL (Part 1)"
                    },
                    "comment": {
                        "value": "We sincerely thank you for spending your precious time to review our paper.\n\n**Additional Explanation**\n\nPlease let us explain more about our paper with respect to your comments.\n\n>The major weakness of this work is its incremental contribution over previous grammar-based methods like [1] and [2]. In particular, [2] uses similar grammars for knowledge base question answering.\n\nThank you for letting us know ReTraCk [13], which also uses grammar-based decoding [5,6,7] and which is also applied to KBQA.\nWe checked ReTraCk and found that ReTraCk has the \"Checker\" module which uses constraints that are specialized for KBQA.\nWe think ReTraCk has a good modular design and robust constraints.\nWe'll cite ReTraCk in our revision.\n\nHowever, please let us explain the difference between ours and previous semantic parsers, including ReTraCk, which use grammar-based decoding.\nThe purpose of our paper to apply constraints based on a grammar to a pretrained __seq2seq__ models, such as BART or T5, which have pretrained __decoders with tokenizers__.\nTo exploit a pretrained seq2seq model, the output sequences should be composed of tokens that are also used during pretraining.\nIn contrast, previous semantic parsers [7,8,13] (e.g. ReTraCk) that have constraints on KBs (or structured data) treat KB components (e.g. entities or relations) as atomic units, which are not further split into tokens.\nTherefore, the semantic parsers with the sophisticated constraints couldn't benefit from pretrained decoders, so the models chose custom LSTMs as their decoders.\n\nMeanwhile, semantic parsers based on pretrained seq2seq models have shown good performance [14,15,16], but they haven't used grammar-based decoding.\nTherefore, we applied grammar-based decoding [5,7] to a pretrained seq2seq model, and introduced candidate expressions which enable constraints on KBs for the pretrained seq2seq model.\nThe current application of candidate expressions with trie data structures is similar to \"Instance-level Checking\" of ReTraCk, but our constraints are for pretrained seq2seq models.\nWe also thinks that candidate expressions can be applied to other constraints, such as \"Ontology-level Checking\" of ReTraCk.\n\nIn addition, we've recently found interesting semantic parsers that generate tokens (not production rules) but constrain tokens with respect to SCFGs [2,3].\nFollowing [3], our method can be combined with Earley\u2019s algorithm [12], where our intermediate representations can replace dotted production rules.\nIn our revision, we'll describe [2,3], and the idea of applying our method to [2,3].\n\n>It is unclear what new techniques or insights this work adds beyond existing grammar-based approaches for this task.\n\nWe appreciate your pointing out the problem. We should've exactly distinguished previous work and our contributions.\nIn our revision, we'll more exactly describe the difference between previous work and ours.\n\n>With only one dataset, it is hard to determine if the performance gains are dataset-specific or represent a robust advancement for grammar-based decoding.\n\nAs you and the reviewer Ntkc commented, using only one dataset is a critical disadvantage of our paper.\nWe acknowledge that experimenting on more than one dataset could enhance the validity of our method.\n\nHowever, at least in KQAPRO [1], we tried to compare our method with previous work as fairly as possible.\nWe and previous work use the BART-base model, and we adapt hyperparameters from BART KoPL [1],\nNevertheless, we admit that it cannot be an excuse for using only one dataset.\n\n**TODO**\n\nWe're going to update our paper during the discussion period.\n\n- ReTraCk [13] will be added to \"Related work\".\n- Constrained decoding methods [2,3] for pretrained seq2seq will be added to \"Related work\".\n  - We will also briefly describe how our method can be combined with [2,3].\n- The difference between previous work and ours will be more clearly described.\n\n**Gratitude**\n\nWe again greatly thank you for your reviews and feedback.\nIf you have any more comments or questions, please feel free."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699981037686,
                "cdate": 1699981037686,
                "tmdate": 1699983148564,
                "mdate": 1699983148564,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JyxxLFPGUu",
                "forum": "ICSvW69W5K",
                "replyto": "ytzRarGteH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4fJL (Part 2)"
                    },
                    "comment": {
                        "value": "**Reference**\n\n[2] From Paraphrasing to Semantic Parsing: Unsupervised Semantic Parsing via Synchronous Semantic Decoding  \n[3] Constrained Language Models Yield Few-Shot Semantic Parsers  \n[5] A Syntactic Neural Model for General-Purpose Code Generation  \n[6] TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation  \n[7] Neural Semantic Parsing with Type Constraints for Semi-Structured Tables  \n[8] RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers  \n[12] An Efficient Context-Free Parsing Algorithm  \n[13] ReTraCk: A Flexible and Efficient Framework for Knowledge Base Question Answering  \n[14] Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?  \n[15] UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models  \n[16] PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699981065522,
                "cdate": 1699981065522,
                "tmdate": 1699981065522,
                "mdate": 1699981065522,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oB0xYtz8nc",
                "forum": "ICSvW69W5K",
                "replyto": "ytzRarGteH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Reviewer_4fJL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Reviewer_4fJL"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment from Reviewer 4fJL"
                    },
                    "comment": {
                        "value": "Hi Author,\n\nThanks for your detailed response! While the author's response exhibits potential, it falls short of addressing the principal concerns. To merit a score increase, I recommend the author undertake at least one of the following actions:\n\n- **Zero-shot evaluation**: Although the author emphasizes the advantage of their approach in making language models compatible with pre-defined grammars without a specific decoder, this might not pose a significant issue for fine-tuned models based on my experience. However, it could be a substantial challenge for zero-shot setting. Providing additional evidence, even preliminary experimental results, particularly on zero-shot outcomes (perhaps based on gpt2 or other language models such as llama), would strengthen the credibility of the results.\n\n- **Add Benchmark Results**: It is essential for the author to extend the evaluation of their methods beyond the KQAPro benchmark. Exploring other benchmarks, such as other KBQA benchmarks or text-to-SQL benchmarks, would be acceptable. Additionally, given the combination of an autoregressive language model with predefined grammars under specific grammatical constraints, the author should acknowledge and differentiate their work from related works, such as UniSAR [1], especially if conducting experiments in the text-to-SQL domain. Clear articulation of distinctions, especially in comparison to UniSAR's constrained decoding, is crucial.\n\n- **Comparison to Previous Grammar-based Decoding Method Using the BART Encoder**: The author should conduct a comparative analysis of their method against previous grammar-based approaches that utilize a specific grammar-based decoder, restricting the usage to only the encoder part of the model. This comparison will provide a more comprehensive understanding of the proposed method's strengths and weaknesses in relation to existing techniques.\n\nBest,\n\nReviewer 4fJL"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700531398676,
                "cdate": 1700531398676,
                "tmdate": 1700531542343,
                "mdate": 1700531542343,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RemD0eYFbL",
                "forum": "ICSvW69W5K",
                "replyto": "ytzRarGteH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4fJL"
                    },
                    "comment": {
                        "value": "We greatly thank you for the additional comment!\n\nIf we perform some of the three additional experiments you suggested, our method would be more reliable.\n\n**About the suggested experiments**\n\n>Zero-shot evaluation\n\nWe agree that learning a semantic parser with less supervision is important, and it would be good setting for our method.\nThank you for the comment.\n\n>Add Benchmark Results\n\nAs your previous comment, evaluating on more than one dataset would enhance validity of our method.\nIn addition, we checked the paper of UniSAR, and we found that UniSAR also has similarity with our method in that both use trie data structures for constraints on structured data, such as KBs or DB schemas.\nComparing with their method would be needed when experimenting in text-to-SQL domain.\nThank you for providing us the paper.\n\n>Comparison to Previous Grammar-based Decoding Method Using the BART Encoder\n\nAs your explanation, to emphasize the use of a pre-trained decoder, comparing with a custom decoder is reasonable.\nThank you for making a good point.\n\n**Weakly-supervised setting**\n\nUnfortunately, we couldn't perform the suggested experiments.\nHowever, last night, we instead performed preliminary experiments for application to weakly-supervised learning (Appendix C).\nSince weakly-supervised learning is less addressed for pretrained seq2seq models, such as BART or T5, our results woudld be promising.\nWe are going to develop the full process of weakly-supervised learning from now on.\n\n**Gratitude**\n\nWe once again thank you so much for your feedback."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735500765,
                "cdate": 1700735500765,
                "tmdate": 1700735640135,
                "mdate": 1700735640135,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bNgLoAxZLh",
            "forum": "ICSvW69W5K",
            "replyto": "ICSvW69W5K",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2430/Reviewer_pMus"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2430/Reviewer_pMus"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a grammar-based semantic parser for knowledge-based question answering. The grammars are specialized with fine-grained types and candidate expressions. During decoding, type constraints and candidate constraints can be enforced to search for the desired programs more effectively."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "A well-executed work on designing grammars for knowledge-based question answering. The revisit of traditional grammar-based methods provides insights on whether prior information such as types are still useful in the current era of pre-trained models.  (But I also feel the question whether grammar-based constraints are still useful for large models needs to be studied more)"
                },
                "weaknesses": {
                    "value": "The main contribution, as the author points out,  is \u201cTo the best of our knowledge, our work is the first to use production rules as actions for semantic parsers based on pre-trained seq2seq models.\u201d. First, I\u2019m not sure what is the underlying challenge of extending traditional grammar-based seq2seqs to their pretrained counterparts? That is, I'm not sure about the technical contribution of the paper. Second, there are already existing works in this direction (as cited in the related work). For example, RAT-SQL (based on BERT) extends TRANX which expands production rules incrementally during decoding."
                },
                "questions": {
                    "value": "- What is generation speed of the grammar-based parser compared with the baseline BART? I\u2019m wondering that with more constraints, the parser might suffer from much slower inference speed\n- would it be an issue if the size of the set of candidate expressions become too large? E.g., certain class (e.g., keyword-entity) has too many candidates."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2430/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698902169167,
            "cdate": 1698902169167,
            "tmdate": 1699636178602,
            "mdate": 1699636178602,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZD7TQBgUdm",
                "forum": "ICSvW69W5K",
                "replyto": "bNgLoAxZLh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer pMus (Part 1)"
                    },
                    "comment": {
                        "value": "We sincerely thank you for spending your precious time to review our paper.\n\n**Response to Questions**\n\nWe first reply to your questions.\n\n>What is generation speed of the grammar-based parser compared with the baseline BART?\n\nDoes \"the baseline BART\" mean BART KoPL [1]?\nWe could run BART KoPL on the validation set by using the publicly released code [1].\nIn the following table, we compare the average time to convert tokens of utterances to tokens of logical forms (or actions), where the batch size is 64.\n\n| Model                             | Time (ms) |\n|---|---|\n| BART KoPL                         |       4.5 |\n| Ours with $\\Psi^\\textrm{NONE}$    |       3.8 |\n| Ours with $\\Psi^{\\textrm{TYPE}-}$ |      10.0 |\n| Ours with $\\Psi^\\textrm{TYPE}$    |      10.0 |\n| Ours with $\\Psi^\\textrm{HYBR}$    |      10.2 |\n\nOur decoding with $\\Psi^\\textrm{NONE}$ is slightly faster than BART KoPL, although both don't use constraints during decoding.\nIt's because the average length of action sequences of our model is shorter than the average length of output token sequences of BART KoPL; the average length is 28.8 for ours and 35.1 for BART KoPL.\n\nAn example output sequence of BART KoPL is\n```\n<s>FindAll <func> FilterStr <arg> official website <arg> http://www.thesiege.com/ <func> FilterConcept <arg> visual artwork <func> QueryAttrQualifier <arg> publication date <arg> 1999-01-21 <arg> place of publication</s>\n```\nwhich is identical with the following logical form.\n```\n(query-attr-qualifier (filter-concept (filter-str all-entities \"official website\" \"http://www.thesiege.com/\")\n                                      \"visual artwork\")\n                      \"publication date\" \"1999-01-21\" \"place of publication\")\n```\n\nSince BART KoPL splits symbols (e.g. FindAll or FilterStr) into tokens (e.g. Find, All, Filter, Str), the model has slightly longer output sequences.\n\n>I\u2019m wondering that with more constraints, the parser might suffer from much slower inference speed\n\nWe think that additional contraints by types or candidate expressions don't much slow down the speed.\nType constraints depend on valid actions $\\Psi^\\textrm{TYPE}(r({\\boldsymbol{a}^\\star}))$ for the current intermediate representation $r({\\boldsymbol{a}^\\star})$, and $\\Psi^\\textrm{TYPE}(r({\\boldsymbol{a}^\\star}))$ can be efficiently cached for the type of the leftmost non-terminal $\\nu(r({\\boldsymbol{a}^\\star}))$.\nConstraints by candidate expressions depend on the time complexity of trie data structures.\nRetrieving valid actions $\\Psi^\\textrm{CAND}(r({\\boldsymbol{a}^\\star}))$ from a trie only takes $O(\\text{length of prefix})$ time.\n\n>would it be an issue if the size of the set of candidate expressions become too large? E.g., certain class (e.g., keyword-entity) has too many candidates.\n\nThe speed bottleneck of our constrained decoding is assigning $-\\infty$ scores (Eq. 6) to all invalid actions ($\\mathcal{A} - \\Psi(r({\\boldsymbol{a}^\\star}))$), but this process can be efficiently computed in the most cases by GPUs.\nInitially, we make a mask tensor whose size is same with $|\\mathcal{A}|$, which is the number of all actions, and update all the tensor's elements with $-\\infty$ (processed by GPUs).\nThen, we can update the tensor depending on one of two cases:\n1. if $|\\Psi(r({\\boldsymbol{a}^\\star}))| < \\frac{1}{2} |\\mathcal{A}|$, we update the tensor's elements that correspond to $\\Psi(r({\\boldsymbol{a}^\\star}))$ with 0 (processed CPUs).\n2. if $|\\Psi(r({\\boldsymbol{a}^\\star}))| > \\frac{1}{2} |\\mathcal{A}|$ (e.g. $\\Psi(r({\\boldsymbol{a}^\\star}))$ = all production rules that generate nlt nodes), we update all tensor's elements with 0 (processed by GPUs) then update the tensor's elements that do not correspond to $\\Psi(r({\\boldsymbol{a}^\\star}))$ (e.g. all production rules constructing compositional structures) with $-\\infty$ (processed by CPUs).\nThe computed tensor is added to log-probabilities of actions.\nSince $|\\Psi(r({\\boldsymbol{a}^\\star}))|$ is usually very small or very large, the tensor is efficiently computed.\n\nIn the worst case, if $|\\Psi(r({\\boldsymbol{a}^\\star}))| = \\frac{1}{2} |\\mathcal{A}|$, GPUs cannot be efficiently exploited, then CPUs should take $O(\\mathcal{A})$ time (c.f. $|\\mathcal{A}|$ = 53 + 50,260).\nHowever, we think that the worst case does not easily occur.\nFor your information, when given an empty prefix, the number of tokens that are returned from the trie $\\tau(\\texttt{keyword-entity})$ is 5,072; in addition, the number of tokens would be smaller when given a non-empty prefix."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699980851609,
                "cdate": 1699980851609,
                "tmdate": 1700400295122,
                "mdate": 1700400295122,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6O9yjLDtiT",
                "forum": "ICSvW69W5K",
                "replyto": "bNgLoAxZLh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer pMus (Part 2)"
                    },
                    "comment": {
                        "value": "**Additional Explanation**\n\nPlease let us explain more about our paper with respect to your comments.\n\n>The main contribution, as the author points out, is \u201cTo the best of our knowledge, our work is the first to use production rules as actions for semantic parsers based on pre-trained seq2seq models.\u201d.\n>First, I\u2019m not sure what is the underlying challenge of extending traditional grammar-based seq2seqs to their pretrained counterparts? That is, I'm not sure about the technical contribution of the paper.\n>Second, there are already existing works in this direction (as cited in the related work). For example, RAT-SQL (based on BERT) extends TRANX which expands production rules incrementally during decoding.\n\nWe regret using the arrogant expression \"To the best of our knowledge ...\" to describe the difference with previous neural seq2seq semantic parsers.\nAt the time of writing, we hadn't seen semantic parsers that take production rules as actions and that are based on pretrained seq2seq models, such as BART or T5.\nSince we consider BERT, which are used by [8], as a pretrained auto-encoding model, which has no pretrained decoder, rather than a pretrained seq2seq model, we thought our model has difference with the previous semantic parsers.\nHowever, as you commented, applying [5,6,7] to BART or T5 is not technically difficult.\nIn addition, we've recently found other previous work [2,3] that take tokens (not production rules) as actions but constrain the tokens by using production rules.\nWe'll remove \"To the best of our knowledge ...\" and add descriptions of [2,3].\n\n**TODO**\n\nWe're going to update our paper during the discussion period.\n\n- The sentence beginning with \"To the best of our knowledge ...\" will be removed.\n- Constrained decoding methods [2,3] for pretrained seq2seq will be added to \"Related work\".\n  - We will also briefly describe how our method can be combined with [2,3].\n\n**Gratitude**\n\nWe again greatly thank you for your reviews and feedback.\nIf you have any more comments or questions, please feel free.\n\n**Reference**\n\n[1] KQA Pro: A Dataset with Explicit Compositional Programs for Complex Question Answering over Knowledge Base  \n[2] From Paraphrasing to Semantic Parsing: Unsupervised Semantic Parsing via Synchronous Semantic Decoding  \n[3] Constrained Language Models Yield Few-Shot Semantic Parsers  \n[5] A Syntactic Neural Model for General-Purpose Code Generation  \n[6] TRANX: A Transition-based Neural Abstract Syntax Parser for Semantic Parsing and Code Generation  \n[7] Neural Semantic Parsing with Type Constraints for Semi-Structured Tables  \n[8] RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699980915262,
                "cdate": 1699980915262,
                "tmdate": 1699983929079,
                "mdate": 1699983929079,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "thDSt9zrFz",
                "forum": "ICSvW69W5K",
                "replyto": "bNgLoAxZLh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Reviewer_pMus"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Reviewer_pMus"
                ],
                "content": {
                    "title": {
                        "value": "Clarification of technical novelty"
                    },
                    "comment": {
                        "value": "Thanks for the response!\n\nThough the authors acknowledge more related work, it's still unclear what is the main technical contribution. As I read from the response to other reviewers, the authors seem to suggest that the main challenge of combing grammar +  pretrained models is to handle the vocabulary discrepancy (i.e., pretrained models have their own tokenizers which is not the same vocabulary used in grammar), which I think is not a significant issue. Regarding the future work mentioned on combining Earley with pretrained decoder, there are very related work in this direction[1,2].  And I think the way of handling candidate expression can be viewed as a special case of Earley-based constraining used in [1,2]. \n\n[1] Synchromesh: Reliable code generation from pre-trained language models\n\n[2] Grammar Prompting for Domain-Specific Language Generation with Large Language Models"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700095898084,
                "cdate": 1700095898084,
                "tmdate": 1700095907486,
                "mdate": 1700095907486,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Gf9cOugeTf",
                "forum": "ICSvW69W5K",
                "replyto": "bNgLoAxZLh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Clarifying technical novelty"
                    },
                    "comment": {
                        "value": "We greatly thank you for the additional comment!\n\nThe two latest papers [17,18] you inform us about are related to our work and our vague idea for future work.\nWe reorganize our thoughts with respect to\nthe scope of work, contributions, and future work.\nWe very appreciate your feedback!\n\n**Scope of Work**\n\nWe deal with the problem of developing a semantic parser that is fine-tuned from a pre-trained seq2seq model.\nEspecially, the semantic parser constructs a logical form that contains components (e.g., entities, relations) from a KB which could be large.\nWe assume the KB components in logical forms (or intermediate representations) are represented in naturual language.\n\n**Contributions**\n\nOur main contribution is combining the two previous constrained decoding methods for\n- constructing compositional structures [5,7] and\n- generating valid KB components, which are represented as candidate expressions [4]\n\nThe resulting method is designed with respect to the following principles:\n- Scalability\n  - $\\Psi^\\textrm{TYPE}$ and $\\Psi^\\textrm{CAND}$ can be scaled up for various types and many KB components\n  - Related Work: Synchromesh [17]\n    - [17] also uses context-sensitive constraints on structured data (e.g., constraints on DB schemas)\n    - However, their constrained decoding is inappropriate to exploit many elements of structured data (e.g., entities of KBs)\n    - [17] dynamically constructs a regular expression, which represents all possible next tokens, for context-sensitive constraints\n    - Therefore, defining a constraint on many elements of structured data is costly and results in a huge regular expression\n- Efficiency\n  - $\\Psi^\\textrm{HYBR}$ instantly retrieves all valid actions $\\Psi^\\textrm{HYBR}(r({\\boldsymbol{a}^\\star}))$ for a given $r({\\boldsymbol{a}^\\star})$.\n  - We also generalize the [PrefixConstrainedLogitsProcessor](https://github.com/huggingface/transformers/blob/913d03dc5e78b82c24be7a52c9ad06dd1022f1e2/src/transformers/generation/logits_process.py#L1052) method [4] to work with our semantic parser. It corresponds to the method that computes a mask tensor, which is the speed bottleneck, described in the first reply to pMus.\n  - Related work: PICARD [16], Synchromesh [17]\n    - [16,17] devised a predicate which takes a prefix of a logical form then returns a boolean value whether the prefix is valid for a logical form language\n    - [16] only consider tokens with top-k probabilities\n    - [17] test many tokens, although they use trie data structures to keep \"rejected\" tokens and skip testing for the tokens that have the rejected tokens as prefixes.\n    - [22] also points out high overhead of existing constrained decoding for seq2seq models\n- Effectiveness\n  - The ablation study shows that performance benefits from candidate expressions\n  - A node class with more candidate expressions usually contributes more to the performance\n  - Therefore, constraints on many elements of KBs are important\n- Generalization\n  - Our method can be applied to many types of KB component categories\n  - Our method is generalization of the constrained decoding by [19]\n\n**Future work**\n- Weakly-supervised learning [7,20,21]\n  - An initial semantic parser, which is less trained, can efficiently make various search branches, since all valid actions $\\Psi^\\textrm{HYBR}(r({\\boldsymbol{a}^\\star}))$ are instantly retrieved.\n\n**TODO**\n\nWe're going to update our paper to include the content of this comment.\n\n**Gratitude**\n\nWe once again thank you so much for your feedback.\n\n**Reference**\n\n[2] From Paraphrasing to Semantic Parsing: Unsupervised Semantic Parsing via Synchronous Semantic Decoding  \n[3] Constrained Language Models Yield Few-Shot Semantic Parsers  \n[4] Autoregressive Entity Retrieval  \n[5] A Syntactic Neural Model for General-Purpose Code Generation  \n[7] Neural Semantic Parsing with Type Constraints for Semi-Structured Tables  \n[16] PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models  \n[17] Synchromesh: Reliable Code Generation from Pre-trained Language Models  \n[18] Grammar Prompting for Domain-Specific Language Generation with Large Language Models  \n[19] TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Base  \n[20] Learning Dependency-Based Compositional Semantics  \n[21] Iterative Search for Weakly Supervised Semantic Parsing  \n[22] Unveiling the Black Box of PLMs with Semantic Anchors: Towards Interpretable Neural Semantic Parsing"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700263923506,
                "cdate": 1700263923506,
                "tmdate": 1700339987960,
                "mdate": 1700339987960,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SHu5dbPRoR",
            "forum": "ICSvW69W5K",
            "replyto": "ICSvW69W5K",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2430/Reviewer_Ntkc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2430/Reviewer_Ntkc"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a grammar augmented with candidate expressions for KB-QA. The grammar decoder enforces the type of candidate expressions during the decoding phrase. The proposed method achieves the state-of-the-art performance on KQAPRO datasets. The ablation study shows the effectiveness of the method. However, the paper fails to show the proposed method works for other KB-QA tasks. And it is not sure what is the scope of the problem the proposed method could outperform the beselines."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The method is proposed for KBQA tasks is noval.\n* A state-of-the-art performance on KQAPRO\n* The abalation study shows the effectiveness of this method"
                },
                "weaknesses": {
                    "value": "* In this paper, the performance of the model is recorded only in one KB-QA dataset. It is not known how good is this method among all KB-QA tasks."
                },
                "questions": {
                    "value": "* Are there any results on KB-QA datasets other than KQAPRO for the proposed method? It would be better to show the performance of the proposed method on more than one dataset. The datasets could be (but not limited to) Complex Web Questions and Grail QA.\n\n* [Not critical] This paper compares their decoding method with Picard's paper to show the proposed method has a good latency. Why are the two models in different tasks (KBQA vs Spider), different model architectures (BART vs T5), and different hardwares comparable?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2430/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698979931315,
            "cdate": 1698979931315,
            "tmdate": 1699636178502,
            "mdate": 1699636178502,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZqLGrmTNAQ",
                "forum": "ICSvW69W5K",
                "replyto": "SHu5dbPRoR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2430/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Ntkc"
                    },
                    "comment": {
                        "value": "We sincerely thank you for spending your precious time to review our paper.\n\n**Response to Questions**\n\nWe first reply to your questions.\n\n>Are there any results on KB-QA datasets other than KQAPRO for the proposed method? It would be better to show the performance of the proposed method on more than one dataset. The datasets could be (but not limited to) Complex Web Questions and Grail QA.\n\nWe haven't performed experiments on another dataset, although we're considering other datasets, whose tasks could be KBQA, Text-to-SQL or others.\nAs you and the reviewer 4fJL commented, using only one dataset is a critical disadvantage of our paper.\nWe acknowledge that experimenting on more than one dataset could enhance the validity of our method.\n\nHowever, at least in KQAPRO [1], we tried to compare our method with previous work as fairly as possible.\nWe and previous work use the BART-base model, and we adapt hyperparameters from BART KoPL [1],\nNevertheless, we admit that it cannot be an excuse for using only one dataset.\n\n>[Not critical] This paper compares their decoding method with Picard's paper to show the proposed method has a good latency. Why are the two models in different tasks (KBQA vs Spider), different model architectures (BART vs T5), and different hardwares comparable?\n\nWe wanted to compare our method with constrained decoding for __pretrained seq2seq model__, such as BART or T5.\nAt the time of writing, PICARD was only method we know for the scenario (however, we've recently found other previous work [2,3]).\nWe think that methods based on production rules have better efficiency, so we wanted to emphasize it.\nAs your comment, the comparison would be fair if we could implement our method on both Spider and KQA Pro.\n\nWith respect to hardware, CPUs and GPUs may affect latency, so we specified the exact spec of our own hardware, where our model could run __solely__ in the machine.\nHowever, when we measured latency on other environments (e.g. a cluster with V100), the latency was not much different.\n\n**Additional Explanation**\n\nPlease let us explain more about our paper with respect to your comments.\n\n>And it is not sure what is the scope of the problem the proposed method could outperform the beselines.\n\nWe appreciate your pointing out the problem. As your comment, the scope, where our method can be effectively applied, is less explained in our paper.\nSemantic parsing on KBs (or structured data) produces logical forms that include KB components (e.g. entities or relations).\nHowever, if some KB components are hardly seen or unseen during training, semantic parser cannot properly infer the correct expressions of the KB components, especially when the counterparts in NL utterances have different expressions.\nFor example, a KB component (relation) is \"country of citizenship\" and its NL counterpart is \"a citizen of\" (Figure 1).\nThis problem usually occurs when a KB is large (e.g. KQAPRO), or when a KB is updated after training (e.g. adding new entities) [4].\nWe will add more explanation about the scope of the problem.\n\n**TODO**\n\nWe're going to update our paper during the discussion period.\n\n- Constrained decoding methods [2,3] for pretrained seq2seq will be added to \"Related work\".\n  - We will also briefly describe how our method can be combined with [2,3].\n- Explanation about \"the scope of the problem\" where our method can be effectively applied will be added to one of \"Introduction\", \"Related Work\" or \"Appendix\".\n\n**Gratitude**\n\nWe again greatly thank you for your reviews and feedback.\nIf you have any more comments or questions, please feel free.\n\n**Reference**\n\n[1] KQA Pro: A Dataset with Explicit Compositional Programs for Complex Question Answering over Knowledge Base  \n[2] From Paraphrasing to Semantic Parsing: Unsupervised Semantic Parsing via Synchronous Semantic Decoding  \n[3] Constrained Language Models Yield Few-Shot Semantic Parsers  \n[4] Autoregressive Entity Retrieval"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2430/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699979716405,
                "cdate": 1699979716405,
                "tmdate": 1700020927553,
                "mdate": 1700020927553,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]