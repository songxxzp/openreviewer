[
    {
        "title": "Unraveling the Key Components of OOD Generalization via Diversification"
    },
    {
        "review": {
            "id": "C7e5KXjYyK",
            "forum": "Lvf7GnaLru",
            "replyto": "Lvf7GnaLru",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5419/Reviewer_WG9i"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5419/Reviewer_WG9i"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the class of  \u201cdiversification\u201d methods that address OOD problem, and identify the key components contributing to their performance. Some findings are provided through research\uff0cthat can help guide the development of approaches. Some experiments are conducted to support their results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) This paper investigates the \u201cdiversification\u201d methods from theoretically from different aspects. Some key results are provided.\n2) Valid experiments have proved the rationality of their views. \n3) Some showcase are provided to validate the meaning of the findings."
                },
                "weaknesses": {
                    "value": "1) What are the unique advantages of \u201cdiversification\u201d methods to solve OOD problems\uff1fDoes it contribute much to OOD community to study the components of \u201cdiversification\u201d? More discussion of motivation and related works are needed.\n2) Despite the limitation talked in paper, I think experimental setup of the paper is still simple. More complicated diversification loss, approaches, need to be included."
                },
                "questions": {
                    "value": "In addition to the methods used in the paper, does it need to consider more models to support the conclusions of the paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "nan"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5419/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5419/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5419/Reviewer_WG9i"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5419/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698746736646,
            "cdate": 1698746736646,
            "tmdate": 1699636550258,
            "mdate": 1699636550258,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iHnSpa0S5Y",
                "forum": "Lvf7GnaLru",
                "replyto": "C7e5KXjYyK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WG9i"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time reviewing and providing useful feedback, we kindly answer raised questions as follows.\n\n> What are the unique advantages of \u201cdiversification\u201d methods to solve OOD problems\uff1fDoes it contribute much to the OOD community to study the components of \u201cdiversification\u201d?\n\nWe kindly refer to the \u2018The focused scope of our work\u2019 section in the general response for a detailed answer. We will be sure to add more discussion in the next revision.\n\n> More complicated diversification loss, approaches, need to be included. In addition to the methods used in the paper, does it need to consider more models to support the conclusions of the paper?\n\nAt the time of writing, to the best of our knowledge, there were no other diversification losses or approaches that are fundamentally different from D-BAT and DivDis. The two methods differ not only on diversification losses but also on the optimization strategies, thus representing a spectrum of possible dynamics in this learning framework well.\n\nThroughout the paper, we convey crucial messages that provide insights to guide the future design of diversification methods and the usage of current ones, and each message is supported by theoretical proofs (proposition 1, proposition 2), and experimental verifications as below:\n\n- For proposition 1, we further justify the performance of diversification methods is highly dependent on spurious ratio by firstly verifying the solution of synthetic 2D illustrative example and secondly showing the conclusion holds in practice with datasets in different scales (M/C, M/F, and CeleA-CC).\n- For proposition 2, we show with 10 models (spanning different training strategies) that diversification alone cannot lead to OOD generalization the inductive bias brought by the used learning algorithm is important.\n\nFor the reasons above, we believe our conclusions are well-supported. However, we would be very glad to provide further evidence, but was wondering which kind of models or approaches the reviewer would be interested to see?"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700165972756,
                "cdate": 1700165972756,
                "tmdate": 1700165972756,
                "mdate": 1700165972756,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7HtmkjTLur",
                "forum": "Lvf7GnaLru",
                "replyto": "iHnSpa0S5Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_WG9i"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_WG9i"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the clarifications. After rebuttal, I will maintain my initial score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661373299,
                "cdate": 1700661373299,
                "tmdate": 1700661373299,
                "mdate": 1700661373299,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "j2xyF3QlfC",
            "forum": "Lvf7GnaLru",
            "replyto": "Lvf7GnaLru",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE"
            ],
            "content": {
                "summary": {
                    "value": "The authors study 2 recently proposed supervised learning \"diversification\" methods (DivDis and D-Bat) which aim to achieve high accuracy out-of-distribution (OOD) by generating a diversity of hypotheses each of which fit the training data but which disagree on additional unlabelled data from a different distribution  and then picking one final hypothesis from the list . The process is intended to reduce the odds of yielding a model which relies on spurious correlations which would not persist under distributional shift.  Through a mix of theory , toy experiments and real-world-data experiments, the authors arrive at a number of findings which warn that neither DivDis nor D-Bat (nor any particular diversification method ) is likely to work well in all situations. The performance of diversification methods is shown to be highly sensitive to the distribution of the unlabelled data on which diversity is measured.  There is an interaction between the learning algorithm and the unlabelled data distribution such that each affects the optimality of the other. The appropriateness of the inductive bias of the learning algorithm is shown to be critical to the success of diversification methods. Increasing the number of hypotheses generated by the diversification methods does not necessarily fix these concerns...the interplay between learning algorithm and unlabelled distribution and the importance of inductive bias persist."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The work is original to the best of my knowledge.  \n\nThe paper is well written and clear. I have a few suggested typo-style edits in the weaknesses section, but the writing is certainly strong. \n\nI did not notice any errors or incorrect conclusions in the findings. Although I didn't have time to go through every result in extreme detail, I have a reasonable amount of confidence in the correctness of the results, generally.\n\nGeneralization which is robust to out-of-distribution shifts is certainly a worthy topic."
                },
                "weaknesses": {
                    "value": "My main concern with the paper is whether its results are significant enough to merit acceptance at ICLR. I'm open to being persuaded that the paper is significant enough, but that's not clear to me, for a few different reasons.  I offer these concerns with only moderate confidence, since I am not an expert specifically on distributional shift literature.\n\nThe paper focuses largely on the pitfalls and limitations of 2 papers from ICLR 2023, the Lee DivDis and the Pagliardini D-Bat approaches. I don't doubt that these papers are high-quality and significant, but they simply haven't been around long enough to know for sure how significant it is to critique them and scrutinize their flaws. I'm not saying that critiquing them is unworthy- it's just hard to tell whether it's a highly significant contribution. \n\nAlso, although the authors do use real-world data to an extent, I find the applications to still be a bit contrived and not illustrative of a clear real-world situation where distributional shift needs to be handled and cannot be avoided.  The MNIST-CIFAR concatenations and Waterbirds-CC are both contrived, i.e., constructed to have spurious correlations, rather than spurious correlations arising naturally.  Office-Home with Art, Product, Clipart, Real-World is somewhat better, but nonetheless, the authors of that dataset did manage to assemble all four sources and so the sensible thing to do would seem to be to train on a dataset with all 4 sources mixed together. I can see how you could have a real-life situation where e.g. only Art, Product, Clipart are available and then you have to design a system which peforms well on Real-World, but the paper would be stronger if a problem domain was studied where that was a real constraint that made distributional shift unavoidable. The most obvious scenario would be distribution shift over time, e.g. , we had to collect images during sunny weather in the summer and then had to deploy the system in darker weather when it was raining...something along those lines. \n\nMy other significance concern is the findings (while common-sense) seem a bit unsurprising to me. We've  known since the 1990s from the Wolpert No Free Lunch theorems, the bias-variance tradeoff, etc  that the right inductive bias is crucial to supervised learning success, in general. While it's worthwhile to illustrate a version of this principle for these recently-developed diversification methods, the finding that the principle holds seems more like common sense to me than like a surprising finding that advances the field in a major way. Maybe I'm wrong, though, and maybe I\"m expecting too much from a paper worthy of ICLR acceptance.\n\nAnother significance concern I have comes from a reaction I had to a sentence on page 4: \"We, therefore, focus on studying the first stage and assume access to the oracle that chooses the best available hypothesis in the second stage\". While I can see that it's true that the first stage is crucial to the success of the whole diversification approach, as someone who is not that familiar with diversification methods or OOD-robust algorithms, it's not that clear to me that we can assume that the second stage will succeed if the first stage succeeds. I guess the idea is that if K is small, then we only need a modest amount of supervised holdout data to choose from among the K diverse hypotheses generated, e.g. the in-sample bias of picking from among a low-K list using validation data is modest? I suppose that could be true, but I would appreciate more background on that topic. \n\nGiven what I wrote in the previous paragraphs and given the focus on 2 papers just published in 2023, the whole paper leans a little bit too far in the direction of assuming that what the authors are studying is very important rather than making the case for the importance of the topic to someone who isn't already deeply involved in OOD and diversification.\n\nTypos:\n\npage 5 function. And the training distribution -> function, and the training distribution (don't start a new sentence here)\npage 9 \"This is in consistence with\" -> This is consistent with"
                },
                "questions": {
                    "value": "Can you add some more background for how OOD concerns can arise in industry? Even though the experiments use real world data in some sense, the tweaking of the real world data to introduce spurious correlations makes the experiments a bit less compelling in terms of real-world evidence. \n\nCan you explain a bit about why I can assume that stage 2 (disambiguation ) probably is doable? I need to be reasonably confident that stage 2 is also doable in order to care about the success of stage 1."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5419/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE",
                        "ICLR.cc/2024/Conference/Submission5419/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5419/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698784464623,
            "cdate": 1698784464623,
            "tmdate": 1700683567853,
            "mdate": 1700683567853,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7pHfCyWX4z",
                "forum": "Lvf7GnaLru",
                "replyto": "j2xyF3QlfC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer MHwE (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time reviewing and providing useful feedback, we kindly answer raised questions as follows.\n\n> The focused methods of our work\n\nWe would like to clarify that our analysis shows unique axes that make diversification methods work, and is actually acknowledging the significance (rather than criticizing) and providing further investigation and evidence to support these methods to stand the test of time. We kindly refer to the \u2018The focused scope of our work\u2019 section in the general response for a detailed answer.\n\n> The significance of the no-free-lunch results\n\nWe kindly refer to the \u2018The significance of the no-free-lunch results\u2019 section in the general response to all reviewers.\n\n> Concerns on the datasets and problem setup we considered / Can you add some more background for how OOD concerns can arise in the industry?\n\nWe kindly answer the two questions together. As shown in [1, 2], when multiple predictive features are present in the training set, neural networks tend to learn the simple (but can be spurious) feature rather than the true causal features because of their ''simplicity'' inductive bias. The case where multiple predictive features co-exist but only the true feature is generalizable is called spurious correlation. This can cause real-world and industrial failure cases, for example:\n\n- In a chest X-ray dataset [3], many images of patients with pneumothorax include a thin drain used for treating the disease. An empirical risk minimization (ERM) model trained on such a dataset can erroneously identify such drains as a predictive feature of the disease, while it's actually a spurious feature. A good deployable model for the model would require sensitivity to physiological signals while being invariant to environmental or operational signals that can change between deployment contexts. (please see https://wilds.stanford.edu/datasets/ for more real-world examples)\n\nwhich is especially crucial when the reliability of the model is expected to be high, such as in medical/financial/self-driving fields. This has motivated the community to study spurious correlation and the problem has become a main branch of OOD generalization problem and is long-standing, well-defined, realistic but challenging. Following the many existing methods (e.g., [5, 7, 8]), both D-BAT & DivDis and our work use the *well-established* and *real-world* baselines and benchmarks (CelebA, WaterBirds, Camelyon17, etc). Going one step further, D-BAT and DivDis also try to handle a more difficult case, where the spurious feature/hypothesis *always* correlates with the true feature/hypothesis, and this is important because:\n\n- Sometimes it's hard to acquire minor group samples due to temporal or spatial reasons (e.g., a particular species can only be observed in a specific time/location).\n- Therefore, the model has to work on this harder case in order to reliably work on simpler cases.\n- As an example, the medical images of a specific disease tissue are solely available in a hospital/research lab, and the medical model fails to recognize the disease because it learns to only look at the hospital token rather than the tissue.\n\nFor our purpose, using MNIST-CIFAR and Waterbirds-CC unlocks more controlled experiments (e.g., a more fine-grained analysis under various spurious ratios) to simulate the different scenarios that could arise in the industry, which makes it possible to understand the conditions required for the diversification methods to work, which, in turn, allows for developing more reliable and powerful methods for real-world applications."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700165759730,
                "cdate": 1700165759730,
                "tmdate": 1700165759730,
                "mdate": 1700165759730,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4LZTaB7f01",
                "forum": "Lvf7GnaLru",
                "replyto": "r7DJ2KSfxP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I have read the rebuttal of the authors. I appreciate the explanation regarding the contrived datasets...that it allows for control over the spurious ratio. I will raise my score to a 6."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700499872748,
                "cdate": 1700499872748,
                "tmdate": 1700499872748,
                "mdate": 1700499872748,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "i4ZgcsCllF",
                "forum": "Lvf7GnaLru",
                "replyto": "l4BqQ8wbJJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE"
                ],
                "content": {
                    "title": {
                        "value": "Fixed it- changed to 6"
                    },
                    "comment": {
                        "value": "Changed my score to 6, apologies for not doing that the first time."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683612056,
                "cdate": 1700683612056,
                "tmdate": 1700683612056,
                "mdate": 1700683612056,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YuiCZfpCqF",
                "forum": "Lvf7GnaLru",
                "replyto": "i4ZgcsCllF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_MHwE"
                ],
                "content": {
                    "title": {
                        "value": "Not a first time reviewer"
                    },
                    "comment": {
                        "value": "FYI, I checked the 'first time reviewer' box by accident. I am not a first time reviewer, but it won't let me uncheck it.\n\nMaybe the UI design should be changed there. It's an easy mistake to make, since the default behavior for \"code of conduct\" next to it is to check that box."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700683738602,
                "cdate": 1700683738602,
                "tmdate": 1700683738602,
                "mdate": 1700683738602,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7ZE4TiweU4",
            "forum": "Lvf7GnaLru",
            "replyto": "Lvf7GnaLru",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5419/Reviewer_xY3D"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5419/Reviewer_xY3D"
            ],
            "content": {
                "summary": {
                    "value": "The paper critiques recent trend of building diverse models and then selecting one at test time, as a way of enhancing OOD generalization. It presents empirical and theoretical results on why the methods may not always work."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I really like this paper. Given so many methods being proposed for OOD generalization, it is important to take a step back and analyze which ones are likely to work and under what conditions. \n\nThis paper finds that the literature on diversification of hypotheses may not be conceptually well-motivated. The key result is that the success of this technique depends on inductive bias of the model architecture and the same architecture may not work well for different kinds of test set. \n\nIn hindsight, many of the observations seem obvious. for example, given that the methods use 2-3 different hypotheses, they obviously are relying on the training procedure's inductive bias (otherwise how can 2-3 samples explore the full space of \"good\" hypotheses?). But still, the authors do a good job of articulating multiple such issues in a single paper."
                },
                "weaknesses": {
                    "value": "While the analysis is compelling, I'm wondering whether these limitations matter in practice. What if we do model selection over multiple architectures and multiple diversity algorithms? Is the risk that the results we get on a cross-validation set may not generalize to the test set?\n\nIf so, what are the summary statistics of the test set that the above procedure would need to know? For example, if the spurious ratio of the (unseen) test set is known, can that be used to simulate a pseudo-test set and then do model selection over it?\n\nOverall, I'm unclear of main takeaway of this paper. Should we not use diversification algorithms? What is the better alternative?\nPersonally, I feel a better message from the paper can be that it identifies the axes on which model selection should be done, if some summary statistics of the test set can be provided in advance."
                },
                "questions": {
                    "value": "See the weaknesses above. \nIn particular, can the authors setup a model selection expt where the spurious ratio of the unseen test set is known and the test set is simulated. Would it always lead to the correct model? What else do we need to know about the test set? Can that be summarized, or is that not possible (and hence there is no way to know the best model apriori)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5419/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698909260704,
            "cdate": 1698909260704,
            "tmdate": 1699636550008,
            "mdate": 1699636550008,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "r68qFrQv2K",
                "forum": "Lvf7GnaLru",
                "replyto": "7ZE4TiweU4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xY3D (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time reviewing and providing useful feedback, we kindly answer raised questions as follows.\n\n> Given that the methods use 2-3 different hypotheses, they obviously are relying on the training procedure's inductive bias (otherwise how can 2-3 samples explore the full space of \"good\" hypotheses?)\n\nIndeed, it is expected that one needs to outline many hypotheses to considerably explore the hypothesis space (as shown in proposition 2). However, D-BAT and DivDis were shown to work in practice with only two hypotheses, making us curious about the components (we study inductive bias and data distribution property) that they rely on to confine the hypothesis space enough to achieve this efficiency. We investigate this and show that the spurious ratio, architecture, and pretraining strategy are important components of the success of these methods. Furthermore, we show the influence of each component (Sec 4 and Sec 5) and their interaction (Sec 5.3).\n\n> What if we do model selection over multiple architectures and multiple diversity algorithms? Is there risk that the results we get on a cross-validation set may not generalize to the test set?\n\nAs shown in Figure 3, diversification methods do not work well without pretraining, so the model selection boils down to choosing a diversification loss and a pre-trained model (which includes pretraining strategy and architecture).\n\nAs mentioned above (also shown in Figure 3), the pretraining performance on ImageNet is surprisingly not a good proxy for selecting the pretraining strategies. However, a validation set can be used as one of the ways of model selection, and the risk of results' generalization to the test set depends:\n\n- When the validation set is i.i.d to the test set, we can safely do the model selection. Through this work, we have provided important axes (diversification loss, pretraining methods, and their combination) to identify the best model.\n- In terms of cross-validation, i.e., assuming the validation set is i.i.d to the training set and not to the test set, it is not possible to do the model selection. To the best of our knowledge, existing methods in the field do not consider this case and there is generally no solution for this setting.\n- Finally, when the validation set is i.i.d to the unlabeled data, which may be non-i.i.d to the test set, it depends on how many spurious features are present in the dataset.\n    - When there is only 1 spurious feature, knowing the spurious ratio of the test set can help in simulating the corresponding validation set, and the model selection can be done across diversification loss, architectures, and pretraining strategies.\n    - When there is more than 1 spurious feature, knowing such summary statistics is still good, but there is a risk that the results may not generalize to the test set. (see further discussion in the next answer)\n\n> What are the summary statistics of the test set that the above procedure would need to know? For example, if the spurious ratio of the (unseen) test set is known, can that be used to simulate a pseudo-test set and then do model selection over it?\n> \n\nAs discussed above, the number of spurious hypotheses and the spurious ratio of each of those hypotheses are good summary statistics to know. In most cases, the number of spurious hypotheses is equal to 1 and there will therefore be only one spurious ratio.\n\nHowever, as shown in Sec 5.3, when there are more than 1 (2 in this case) spurious hypotheses ($h_1$ & $h_2$) present in the training set, things can be a bit different. Having the spurious ratio for each spurious hypothesis may not help, as different types of the model may latch on a different spurious hypotheses because of their inductive bias, and it\u2019s known to be hard to measure such inductive bias apriori. Thus, the given spurious ratio may not be valid to simulate a pseudo test-set which is valid for all models.\n\nAlthough there is risk in some cases where no good model selection strategy is available, we would like to highlight and clarify that, the efforts done in this work are focused on the diversification stage (first stage of the two-stage framework shown in Sec 3.2). In cases where there is no reliable way of model selection, which can be known when given the above summary statistics, an ultimate way of model selection can be considering all the axes (diversification loss, pretraining, architecture) above and conducting the second stage (the disambiguation stage) with the hypotheses produced by spanning those axes. Therefore, in the second stage, the best diversification loss & pretraining strategy can still be easily selected with a small amount of additional human supervision, e.g., labeled data points or human observation on the Grad-CAM [1] feature map. This means the diversification method is still useful but may have to pass more burden to the second stage in order to reliably find the hypothesis that is close to the true one."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700165515304,
                "cdate": 1700165515304,
                "tmdate": 1700165515304,
                "mdate": 1700165515304,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "T3cpMbGWwJ",
            "forum": "Lvf7GnaLru",
            "replyto": "Lvf7GnaLru",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5419/Reviewer_shsk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5419/Reviewer_shsk"
            ],
            "content": {
                "summary": {
                    "value": "This paper examines two recently proposed algorithms for improving out-of-domain generalization through diverse hypothesis selection with respect to both a labeled and unlabeled dataset. The algorithms try to find hypotheses that agree with the labels on the labeled data but disagree with one another on the unlabeled data.\n\nThe authors essentially find that there is \"no free lunch\" for improving out of domain generalization in that the set of diverse hypotheses selected will depend on which unlabeled data was used to find the diverse hypotheses, which underlying model class was used, and which metric is used to quantify the diverseness of a set of hypotheses.\n\nThe diverse hypothesis selection algorithms examined in the paper are:\n1. diversify and disambiguate aka \"DivDis\" (Lee et al. 2023)\n2. diverisity by disagreement training aka \"DBAT\" (Pagliardini et al., 2023)\n\nDivDis and DBAT use different metrics to assess the diversity of a set of hypotheses.\n\nThe main contributions of the paper are:\n1. Proposition #1 which states that DivDis and DBAT will select different second hypotheses w.r.t. an unlabeled dataset depending on the extent to which the first hypothesis selected (i.e., the ERM) agrees with the true hypothesis on the unlabeled data.\n2. Proposition #2 which states that the number of diverse hypotheses generated by an algorithm like DivDis or DBAT needs to be super-linear in the number of unlabeled datapoints in order to ensure that at least one has greater than 50% accuracy with respect to the true hypothesis.\n3. Experiments on synthetic and real datasets to support propositions #1 and #2, and which also show that the success of a diverse hypothesis generation algorithm jointly depends on the underlying model class and the unlabeled set of data selected."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper really dives into the intricacies of the diverse hypothesis generation problem and does a wonderful job illustrating how complex the problem truly it is; that is, success simultaneously depends on all variables. In my opinion, this message should be communicated more frequently in conference proceedings.\n\nIn particular, proposition #1 is quite illuminating in that it shows how DivDis and DBAT select different diverse hypotheses from one another, and there are different regimes defined in terms of the agreement with the true hypothesis on the unlabeled data where each is superior. And here, it was nice to see how the experiments on the synthetically constructed datasets (e.g., MNIST/CIFAR) supported the theoretical findings."
                },
                "weaknesses": {
                    "value": "This paper has a number of weaknesses. I found the presentation more confusing and dense than it could be:\n\n  1. In particular, there is some terminology and notation that can be improved for greater understanding. The \"spurious ratio\" index is a poorly named quantity because it's literally the accuracy of the selected hypothesis with respect to the true hypothesis h*. Namely, h* has the maximum spurious ratio value of 1.0, but it's definitely NOT spurious as it's the true hypotheis. Another name, like the \"agreement ratio\" would be much clearer.\n\n  2. Similarly, the plots on the left side of figure 2 do not seem to agree with the description of the synthetic problem in the first paragraph of section 4.1, which made it very hard to understand what was being communicated (I elaborate on my confusion below).\n\nAnd though a good message to repeat, the no-free-lunch findings discussed in the paper are known in the supervised learning setting, so they definitely need to hold for this harder setting with labeled + unlabeled data. Could this research direction become even more constructive by making certain statistical assumptions? In the paper, D_u can be any \"out of distrubtion\" distribution; and the capacity of the learning algorithm is assumed to be infinite in proposition 2, even though in other parts of the paper, inductive biases of different model classes are highlighted (which suggests that there the model class has less than infinite capacity in practice).\n\nThe results for DivDis in table 1, section 5.2 for increasing K are not convincing because alpha needs to increase as the square of the number of hypotheses in the set (i.e., O(K^2)). Otherwise the regularization becomes too strong and dwarfs the empirical risk. But the text makes it seem like a fixed alpha was used, which would needlessly harm DivDis' performance as K gets larger."
                },
                "questions": {
                    "value": "Regarding figure 2, h* is defined in the text such that instances with x1 > 0 should be labeled as positive examples. I assume that x1 is the horizontal axis such that points to the right are positive. But the plot and its legend shows points to the left are positive (Class 1). Is my interpretation correct here?\n\nAssuming it is correct, hyperplanes are typically defined by their normal, in which case is should be that h*(x) = h(x; 0), not h*(x) = h(x; pi/4), since theta=0 radians points in the positive horizontal direction to the right, whereas theta=pi/4 radians points up to the top of the page."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5419/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5419/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5419/Reviewer_shsk"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5419/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699051981537,
            "cdate": 1699051981537,
            "tmdate": 1700719438479,
            "mdate": 1700719438479,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ScSfsMARSv",
                "forum": "Lvf7GnaLru",
                "replyto": "T3cpMbGWwJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer shsk"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time reviewing our paper and providing useful feedback, we kindly answer the raised questions as follows.\n\n> Regarding Weakness 1: the spurious ratio\n\nThanks for pointing out the confusion. Indeed, this can be confusing and we will carefully consider a better name (e.g., agreement ratio as suggested) in the next revision. The new definition can be:\n\nDefinition 1 (Agreement Ratio) Given a hypothesis h, the agreement ratio $r_D^h$, with respect to a distribution $D$ and its true labeling function $h^\u2217$ is defined as the proportion of data points where $h^\u2217$ and $h$ agree, i.e., have the same prediction: $r_D^h = \\mathbb{E}_{x \\sim D}[h^*(x) = h(x)]$.\n\nWe also would like to comment that, though $h^*$ has $r_D^{h^*}=1$, this relation is not symmetric, i.e., a hypothesis $h$ with $r_D^{h}=1$ does not mean $h=h^*$. This is because the quantity is defined on a distribution $D$. For example, on $D_t$ where complete spurious correlation exists, there exists a $h$ such that $r_{D_t}^{h}=1$, but on unlabeled data $D_u$, the same $h$ may have $r_{D_u}^{h} \\in [0,1]$. In the scope of our work, we mostly examine this quantity on $D_u$, and we assume the test set $D_{ood}$ is a distribution where no spurious correlation exists, i.e., $r_{D_ood}^{h} \\approx 0.5$ (so that the test set can reflect how well the diversification methods find the true hypothesis $h^*$). We hope this could address your confusion.\n\n> Regarding Weakness 2: Figure 2 and definition of hyperplanes\n\nAs mentioned in the description of Sec 4.1, $x_1$ is the horizontal axis and in this case, the reviewer is correct that $h^*(x)=\\mathcal{I}\\{x_1 > 0\\}$ would be 1 for the points on the right. This is indeed a typo, and we thank the reviewer for noticing it. We will correct it. However it should be noted that this doesn't make any difference in the conclusions made in Proposition 1, and in the behavior illustrated in Figure 2, given that we're in the symmetric binary classification case and the classes are balanced.\n\nFor defining the hyperplanes, we wanted to match what D-BAT does (in Figure 17) and therefore used the radian of the classification plane w.r.t horizontal axis $x_1$ as mentioned in Sec 4.1, instead of the normal. We hope this allows for a better readability.\n\n> Regarding the no-free-lunch findings\n\nWe kindly refer to the \u2018The significance of the no-free-lunch results\u2019 section in the general response for a detailed answer.\n\n> The results for DivDis in Table 1, section 5.2 for increasing K are not convincing because alpha needs to increase as the square of the number of hypotheses in the set (i.e., O(K^2)).\n\nWe assume the reviewer means alpha needs to *decrease* (rather than increase) when increasing K in order for the regularization not to become too strong. The reviewer's concerns are correct given Equation 2, as the diversification losses are summed, and the value is not normalized w.r.t the number of hypotheses K. In practice, however, we always *average* the diversification losses instead of summing them up, which results in having $\\alpha_K = \\frac{\\alpha}{K(K-1)}$. The $\\alpha$ in the numerator is what we keep fixed in practice, which corresponds to scaling the loss by a factor of $~1/K^2$ as the reviewer rightfully suggested. We thank the reviewer for noticing this confusion. We will update the loss function to reflect the normalization term.\n\nWe hope we have addressed your questions, and we of course remain at your disposal for any further questions you may have."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700165319091,
                "cdate": 1700165319091,
                "tmdate": 1700165319091,
                "mdate": 1700165319091,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oHI8e2UK2T",
                "forum": "Lvf7GnaLru",
                "replyto": "T3cpMbGWwJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_shsk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5419/Reviewer_shsk"
                ],
                "content": {
                    "title": {
                        "value": "Replying to authors' response to my review"
                    },
                    "comment": {
                        "value": "Thank you for replying to my questions and concerns. Here are my responses:\n\n1. Regarding the spurious ratio, I had understood that r_D^(h) depends on D and that r_D^(h) can be 1 even when h != h*.  But thank you for verifying I was aware of this.\n\n2. On figure 2 and the definition of hyperplanes, thank you for confirming my assumption and dispelling my confusion. I had stared at that figure for a long time :-)\n\n3. Regarding alpha and table 1, that you for clarifying that there was a hidden correction for the number of hypotheses, \"K\". I am now convinced for the results in table 1. \n\n4. Finally, on the NFL, you state that \"your results do do not directly follow from the original NFL, similar to the results that researchers in the meta-learning field [2,3] or other fields [4,5] obtained, which can also be seen as expected in hindsight.\" \n\nBut actually I think they do follow from NFL. Imagine that a diversification method existed called \"DivBest\" was in fact sufficient for OOD generalization.  Then one could have a free lunch in the supervised setting by:\ni) Collecting a large training set of labeled examples.\nii) Discarding half or more of the labels to form an unlabeled data set.\niii) Running DivBest on the labeled + unlabeled data to learn a model \\hat{M} with DivBest's OOD generalization guarantees.\n\nYou have addressed 3/4 of my concerns so I will revise my overall score upward.\n\nThe larger concern that \"results follow from the no-free-lunch theorem\" still seems open to me. Or, if the results do not follow from NFL, the paper in its current form does not make it clear why. If the authors have insights here, I'd be appreciate if they could share them."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5419/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719036013,
                "cdate": 1700719036013,
                "tmdate": 1700719327394,
                "mdate": 1700719327394,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]