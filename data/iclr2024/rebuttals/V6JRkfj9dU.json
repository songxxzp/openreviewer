[
    {
        "title": "How many samples are needed to train a deep-ReLU neural network?"
    },
    {
        "review": {
            "id": "jKsbDhV1pE",
            "forum": "V6JRkfj9dU",
            "replyto": "V6JRkfj9dU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3380/Reviewer_xTTm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3380/Reviewer_xTTm"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose that the generalization error of neural networks scales with a rate of 1/\\sqrt{n}. Their theoretical analysis establishes a mini-max risk by assuming bounded parameter norms, while empirical evidence supports the 1/\\sqrt{n} rate in MNIST and CHP datasets.\n\nWhile the paper addresses an important question related to the scaling law, I find the theoretical evidence somewhat lacking. The main point of the paper is not entirely clear, and the authors need to articulate their primary contribution better. Moreover, there is limited discussion of the technical challenges and the extension of previous work to ReLU networks. (See limitation part for more details.)\n\nTherefore, I cannot recommend acceptance for the time being."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The authors establish a mini-max bound for ReLU neural networks, which appears to be valid.\n2. While the main contribution needs further clarification, the topic itself is interesting."
                },
                "weaknesses": {
                    "value": "My major concern is that it seems that the justification of this paper is not enough. \nI am still confused about which point is the main point that the authors want to show. \nThere are many alternatives, but they did not convince me.\nFor example, the technical contributions? The authors claim that previous works cannot be applied to ReLU networks, but I am not sure whether this extension has many technical difficulties.\nAnother one is that the theory can match the practice, but I believe that the empirical observations in this paper are not enough to support this (with only the MNIST and CHP datasets).\nSo I suggest that the authors could first tell me what the *major contribution* is and then convince me that the major contribution is significant. \nI would increase my score then.\n \nFor the theory part:\n1. The authors assume a bounded weight norm. However, this is not true. Some existing papers [e.g., uniform convergence may be unable to example generalization in deep learning] have pointed out that the weight norm may increase with n, which may change the rate.\n2. The authors only focus on the mini-max rate without considering the optimization performance. This is dangerous.\n3. The result requires d to be large enough. How large? Would it be exponential with the sample size n?\n\nFor the empirical part:\n1. More experiments (e.g., CIFAR-10, ImageNet) should be added.\n2. The theory shows that the network size is not important; can the authors provide more experiments on this? \n3. If there are experiences that do not perform 1/\\sqrt{n} rate, could the authors provide some reasons?\n\nBesides, I do not think adding too many derivations in the main body of the paper is good. This only harms readability. Why not provide some insights and defer all the details to the appendix?\n\nIn conclusion, while this paper touches on an important topic, it requires substantial improvements in terms of theoretical clarity, empirical evidence, and overall presentation."
                },
                "questions": {
                    "value": "See limitations."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3380/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698236082245,
            "cdate": 1698236082245,
            "tmdate": 1699636288772,
            "mdate": 1699636288772,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JJutyuwjwl",
                "forum": "V6JRkfj9dU",
                "replyto": "jKsbDhV1pE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3380/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3380/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Overall response"
                    },
                    "comment": {
                        "value": "We appreciate your insightful comments and thank you for your valuable suggestions for further improvement. Your points of view are very insightful. \n\n1- We would like to note that, non-convexity and optimization difficulties of the problem are not considered in this work, and we assumed that global minimizers are available. But extensions are possible for future works using the ideas from these works (https://arxiv.org/abs/2205.04491 , https://ieeexplore.ieee.org/abstract/document/9875215)\n\n\n2- Taking into account your valuable suggestions, we have introduced three additional network settings in the empirical part for the MNIST dataset. This addition aims to illustrate that network size is not a crucial factor in practice, aligning with our theoretical findings. Additionally, we conducted experiments with the CIFAR-10 dataset to augment our empirical results.\n\n3- We are appreciative of you for raising this meticulous point regarding how large d would be. Now, we first have added $d>=10$ (based on the proof of Lemma~6 in Appendix) have added the following explanations after Lemma~6:\n\nBy quantifying the lower bound of the packing number, it provides valuable insights into the capacity and potential complexity of these networks. For small values of $\\\\delta$, a sufficiently wide network becomes necessary.  This observation is particularly interesting as it provides valuable insights into selecting an appropriate width for the network based on the input dimension. The larger the input dimension $d$, the wider the network should be.\n\n4- We would like to note that the challenges arising from the ReLU activation function, particularly in the absence of the separation of the estimation method and the function space, and without considering any smoothness for the function space, become more pronounced in the calculation of step 1 in Lemma 6, specifically in Equation 7. However, for other activation functions, this equation can be computed much more easily with simple arithmetic."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3380/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700738272150,
                "cdate": 1700738272150,
                "tmdate": 1700739665074,
                "mdate": 1700739665074,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XgnPzeh0JV",
            "forum": "V6JRkfj9dU",
            "replyto": "V6JRkfj9dU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3380/Reviewer_NyqE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3380/Reviewer_NyqE"
            ],
            "content": {
                "summary": {
                    "value": "This paper studied how much data is required to get a well-generalized neural network. It explores the generalization error of neural networks and suggests that it scales at $1/\\sqrt{n}$ in terms of the sample size $n$. In detail, the authors provide both the upper and lower bounds for a specific neural network architecture and data distribution.  The authors also conducted some experiments to support their claims."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This paper offers theoretical insights into the generalization error of neural networks, providing both upper and lower bounds.\n\n- This paper not only establishes a bound for deep-ReLU networks but also empirically validates its findings."
                },
                "weaknesses": {
                    "value": "- This paper appears to overclaim its results. Titled \"HOW MANY SAMPLES ARE NEEDED TO TRAIN A DEEPRELU NEURAL NETWORK?\" it investigates a much narrower setting than suggested. Firstly, the paper overlooks the training process, assuming that the optimizer can derive the best learner from a given function class. Therefore, the term \"train\" in the title is misleading. Secondly, the scope is limited to feed-forward neural networks with square loss, neglecting widely used structures like CNNs and transformers. In light of this, I recommend that the authors either provide additional commentary within the paper or refine the title and contributions to reflect the actual scope of the study.\n\n- The paper adopts a teacher-student network setting with Gaussian input $x$ and noise $u$. The impact of the scale of $x$ and noise $u$ on the results in Theorem $1$ remains unclear. Additionally, the l1 constraint $v_1$ mentioned in Theorem 1 is not reflected in the final bound in (5), and the reason for this omission is not clear.\n\n- Various papers demonstrate that a faster rate $O(1/n)$ is achievable under specific settings. It would be beneficial if the authors could address these findings, particularly discussing the conditions under which this faster rate could be realized for DNNs.\n\n[1] https://dl.acm.org/doi/pdf/10.5555/3455716.3455772\n\n[2] https://dl.acm.org/doi/pdf/10.5555/3455716.3455772\n\n[3] https://proceedings.mlr.press/v54/mehta17a/mehta17a.pdf\n\n[4] https://proceedings.neurips.cc/paper_files/paper/2015/file/acf4b89d3d503d8252c9c4ba75ddbf6d-Paper.pdf"
                },
                "questions": {
                    "value": "- What will happen if we consider a noiseless teacher-student model, i.e., $\\sigma = 0$?\n\n- This paper considers the setting where the input $x$ is isotropic. Will the results still hold when the covariance of the input $x$ is not identity?\n\n- Each optimization algorithm has its own implicit bias. Will the results improve or worsen, given another specific data model and a specific algorithm?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3380/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698888067737,
            "cdate": 1698888067737,
            "tmdate": 1699636288703,
            "mdate": 1699636288703,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Emm5DiJCeS",
                "forum": "V6JRkfj9dU",
                "replyto": "XgnPzeh0JV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3380/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3380/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Overall response"
                    },
                    "comment": {
                        "value": "We appreciate your insightful comments and thank you for your valuable suggestions for further improvement.\n\n1- Thank you for raising this point regarding the scope of our work. You are absolutely right. Now, we\u2019ve changed the title of the paper to \u201cHow many samples are needed to train a ReLU feed-forward neural network? \u201d to make our setting more clear. For the future work, we are going to consider the setting for CNN and RNN as well. \n\n2- Taking your thoughtful recommendation into account regarding directly reflecting the influence of $v_1$, we have revisited the final bound in Equation 5 to explicitly highlight the role of $v_1$. This revision not only enhances the clarity of our presentation but also provides a more transparent understanding of how the bound is influenced by the magnitude of $v_1$.\n\n3- We would like to note that, non-convexity and optimization difficulties of the problem are not considered in this work, and we assumed that global minimizers are available. But extensions are possible for future works using the ideas from these works (https://arxiv.org/abs/2205.04491 , https://ieeexplore.ieee.org/abstract/document/9875215)\n\n\n4- One fundamental part of our theoretical framework involves calculating the KL divergence between two normal distributions and subsequently establishing an upper bound for mutual information. As expressed in the proof of Lemma 4, the symbol $\\\\sigma$ denotes the standard deviation of these normal distributions. The derived upper bound for the mutual information (Lemma 4) is crucial for applying Fano\u2019s method. Although our method doesn't directly apply to a noiseless teacher-student model, exploring the noiseless teacher-student model in itself would be intriguing.\n\n5- You are absolutely right; the input $x$ is isotropic, and the covariance is identity. We would like to note that the assumption on $x$ is made for the sake of simplicity , in particular, in the calculation of Equation 7. However, extensions to other distributions are also feasible with more sophisticated methods. This assumption simplifies the calculation of Lemmas 11, 12, and 13."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3380/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737846825,
                "cdate": 1700737846825,
                "tmdate": 1700739311379,
                "mdate": 1700739311379,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QqEW0xjBxG",
            "forum": "V6JRkfj9dU",
            "replyto": "V6JRkfj9dU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3380/Reviewer_NcCL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3380/Reviewer_NcCL"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces an algorithm-free lower bound on the generalization error for deep ReLU neural networks by building up on Fano's inequality from information theory. The lower bound scales as $\\frac{1}{\\sqrt{n}}$ instead of the usual $\\frac{1}{n}$ which proposes that when considering data-agnostic scaling laws, $-\\frac{1}{2}$ exponent is more suitable than $-1$."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "I like the step-by-step explanations of the paper and I like that it is focused on the rate $\\sqrt{\\frac{\\log(d)}{n}}$ of the generalization error. \nI was not familiar with Fano's inequality but the refs in the paper to Wainwright are to the point and it was sufficient to understand the results of this paper.\n\n- Elegant use of Fano's inequality for ReLY nets\n- It is interesting that deep networks follow the same rate as shallow networks. This is consistent with the literature.\n- Simulations show better fit to $c_1 \\frac{1}{\\sqrt{n}} + \\alpha $."
                },
                "weaknesses": {
                    "value": "Although the authors do a good job of explaining the important components of their main result, the organization of the paper can be improved much further. See below for some points  \n\n- I'd prefer deferring the proof of theorem 1 to the appendix as it is not very insightful (In fact the proof is a straightforward combination of the lemmas). \n- For the proof of Lemma4, the authors give an 8-step explanation which is simply reading through each step in the following inequalities. I'd prefer it if the most important step was emphasized and the other steps were left to the reader. For me the most important step there is the explicit integral formulation of $D_\\text{KL}$ but I have no idea where $\\frac{1}{\\sigma^2}$ comes from. \n\nOn the other hand, I find the empirical evaluation limited as it is. There is only one architecture used for Figure 1 (a certain width and depth, which would be good to include in the caption). Is this proposed scaling law also valid for really narrow networks like say width 20? The rate here does not depend on the architecture, is it also reflected in practice?\n\nMinor feedback:\n- Eq (2), please specify that all activation functions are ReLU already here. \n- In conclusion, please specify \"networks\" as deep ReLU feedforward networks."
                },
                "questions": {
                    "value": "I am confused about the input data distribution. It is specified as $\\mathcal{N}(0, I)$ at the beginning of Section 2 however layer then the authors introduce $L_2(\\mathbb{P}_x)$ norm. Is $\\mathbb{P}_x$ here Gaussian. If so, $h(x)$ comes from the metric $\\rho$, not from the density of the distribution $\\mathbb{P}_x$?\n\nI would increase my score if the authors provided more experiments (see weaknesses) and/or provided an alternative in-depth discussion/intuition instead of the proof of 4.1."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3380/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699313669523,
            "cdate": 1699313669523,
            "tmdate": 1699636288641,
            "mdate": 1699636288641,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "A1kRKQJ3pT",
                "forum": "V6JRkfj9dU",
                "replyto": "QqEW0xjBxG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3380/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3380/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Overall response"
                    },
                    "comment": {
                        "value": "We appreciate your insightful comments and thank you for your valuable suggestions for further improvement  and we appreciate all of your encouragement and constructive feedback. We agree with all the suggestions and have carefully revised the paper, incorporating them.\nHighlights of the new version based on your comments:\n\n1- We have introduced three different network settings in the empirical part, featuring three very narrow shallow-ReLU feed-forward neural networks. And demonstrate that the scaling is valid also for shallow- ReLU feed-forward neural networks.\n\n2- Additionally, we conducted experiments with the CIFAR-10 dataset to provide more empirical results.\n\n3- Addressing the suggestion to move the proof of Theorem~1 to the Appendix section was indeed a good point, and we have implemented this change.\n\n4- Specifying the ReLU activation function at the beginning of defining our neural network model was also insightful, and we have followed your instructions in this regard.\n\n5- Given that our work focuses solely on ReLU feed-forward neural networks, we have explicitly considered this point throughout the paper to enhance clarity.\n\n6- To enhance clarity and readability, we have included the structure of the networks (specifying the number of hidden layers and the number of hidden nodes) in the captions.\n\nIn the following, we address your questions in more detail.\n\n\nWe appreciate your meticulous point of view regarding your question about the distribution of $x$.\nAs mentioned in Section~ Problem formulation and main result, $\\\\mathbb{P}_{x}=\\\\mathcal{N}(\\\\boldsymbol{0},\\\\Identity)$, and we need this assumption in the calculation of Lemma~12. Regarding the relationship between $h(x)$ and $\\\\rho$:\n\n$h(x)$ is not directly coming from $\\\\rho$; instead $h(x)$ is used in the calculation of the $L_{2}(\\\\mathbb{P}_{x})-$norm. \nThe density function $h(x)$, plays a role in quantifying the \"distance\" of two functions $\\\\widehat{f}, f^{*}$ with respect to the Gaussian distribution $\\\\mathbb{P}_{x}$. We've also added the term ``fixed'' to emphasize that the marginal distribution $\\\\mathbb{P}_{x}$ is fixed.\n\n In response to your inquiry about the rationale behind $1/\\\\sigma^{2}$: In Lemma~9, we compute the Kullback-Leibler divergence between two distinct multivariate normal distributions. The term $1/\\\\sigma^{2}$ indeed arises from the definition of the KL divergence, considering that  $\\\\mathbb{P}{f{\\\\theta^{j}}}$ and $\\\\mathbb{P}{f{\\\\theta^{k}}}$ correspond to the distributions associated with ${f_{\\\\theta^{j}}}(x)$ and ${f_{\\\\theta^{k}}}(x)$, respectively. Reviewing Equation~6 could provide additional insight into this matter. The $\\\\sigma$ is the variance of $n$ i$\\\\cdot$i$\\\\cdot$d$\\\\cdot$\\@ noises $u_{i}$. And based on the view of Lemma~9, we need to have a positive variance."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3380/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700736887048,
                "cdate": 1700736887048,
                "tmdate": 1700740119700,
                "mdate": 1700740119700,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]