[
    {
        "title": "Functional Classification Under Local Differential Privacy with Model Reversal and Model Average"
    },
    {
        "review": {
            "id": "DMT6tEjPYw",
            "forum": "cNi2EJ8OCh",
            "replyto": "cNi2EJ8OCh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3366/Reviewer_WLyT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3366/Reviewer_WLyT"
            ],
            "content": {
                "summary": {
                    "value": "The authors have provided a method for adding noise to functional classifiers to satisfy Local Differential Privacy (LDP). In the context of federated learning, the authors introduce the idea of using more clients to evaluate the performance of weak classifiers and propose the concept of model reversal, which involves inverting the parameters of models with poor accuracy. Additionally, the authors propose a federated learning approach for the heterogeneous multi-server setting under LDP."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1.The paper introduces a novel approach to functional data classification under Local Differential Privacy (LDP), a topic that has not been extensively explored in the existing literature.  \n2.The introduction of model reversal is particularly innovative, as it provides a unique solution to enhance the performance of weak classifiers by inverting their parameters when their accuracy is below a certain threshold."
                },
                "weaknesses": {
                    "value": "1.Differential Privacy (DP) has already proven to be sufficiently effective in protecting individual privacy, for instance, in defending against membership inference attacks. Moreover, there are numerous existing methods within DP for adding noise to functional input data, where the idea of projecting onto a set of finite bases is also quite common. From this perspective, the innovation of projection might not be high enough, and the necessity of employing Local Differential Privacy (LDP) remains to be further examined.At the same time, the performance degradation caused by residuals has not been analyzed theoretically. The expressive power of a finite basis is quite limited, and for some functions, their residuals could be fatal.\n\n2.Regarding the ideas of model average and model reversal proposed by the authors, compared to traditional ensemble techniques, model average utilizes more clients in the evaluation process, aiming to select better weak classifiers. For each poor classifier, a model reversal approach is employed for improvement. However, since only a small number of clients are used to train the parameters, the classifiers might generally perform poorly; model reversal can enhance the performance of the learners, but it may not necessarily improve them to a satisfactory level. Theorem three provides an expected conclusion, but it does not directly lead to a high-probability bound; the theoretical analysis of model reversal is still lacking."
                },
                "questions": {
                    "value": "1..Are there specific scenarios or use cases where LDP provides a clear advantage over DP in functional data classification?\n\n2.The idea of projecting data onto a finite basis is quite common in the realm of DP. Could you clarify how your approach innovates or differs significantly from existing methods?\n\n3.The theoretical analysis of model reversal seems to be lacking. Could you provide more details or elaborate on the theoretical foundations of this technique?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3366/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3366/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3366/Reviewer_WLyT"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3366/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698325486129,
            "cdate": 1698325486129,
            "tmdate": 1699636287032,
            "mdate": 1699636287032,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AR3QFyUkv7",
                "forum": "cNi2EJ8OCh",
                "replyto": "DMT6tEjPYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WLyT (part 1/4)"
                    },
                    "comment": {
                        "value": "We are pleased that the reviewer found our model reversal approach particularly innovative. We thank the reviewer for the valuable comments and suggestions for improvement, and we have incorporated relevant discussions and modifications into our paper. Below, we provide detailed responses to the reviewer's questions, aiming to encourage a reconsideration of our paper's evaluation.\n\n### Weakness 1 (1/2):\n\n> Differential Privacy (DP) has already proven to be sufficiently effective in protecting individual privacy, for instance, in defending against membership inference attacks. Moreover, there are numerous existing methods within DP for adding noise to functional input data, where the idea of projecting onto a set of finite bases is also quite common. From this perspective, the innovation of projection might not be high enough, and the necessity of employing Local Differential Privacy (LDP) remains to be further examined. \n\nWe thank the reviewer for the insightful comments. In response to these concerns, we provide responses from the following two perspectives.\n\n1. **A comparison of DP and LDP**: Indeed, **Differential Privacy (DP)** is a foremost framework for privacy-preserving statistical analyses. It offers a rigorous and interpretable definition of data privacy, limiting the amount of information that attackers can infer from publicly released database queries. In most scenarios, the privacy protection required can be adequately addressed with DP. **Local Differential Privacy (LDP)**, on the other hand, is designed for more extreme cases, such as when the data collector is untrustworthy or malicious, or when privacy must be safeguarded right from the data collection stage, particularly in instances involving highly sensitive or personal data. **For example**, LDP is crucial in situations like smart home devices collecting user behavior data, mobile keyboard apps processing sensitive text inputs, and health monitoring wearables tracking personal health metrics.\n\n2. **Functional data analysis (FDA) under LDP vs DP**: As the reviewer pointed out, there are existing works about projecting data onto a finite basis within DP. In the revised manuscript's **Section 2**, we've summarized existing DP methods for adding noise to functional data. However, FDA under LDP and DP faces different challenges. **First of all**, under DP, the server can access all the raw data and achieve privacy protection by utilizing knowledge of the covariance function and sensitivity of functional objects. In contrast, LDP requires each functional object to be privatized before senting to the server. **Furthermore**, under LDP, the emphasis is on the performance of models trained on the noised functional observations from clients, rather than on the recovery of functional data."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492015101,
                "cdate": 1700492015101,
                "tmdate": 1700492015101,
                "mdate": 1700492015101,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "k5fsRrWl24",
                "forum": "cNi2EJ8OCh",
                "replyto": "DMT6tEjPYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WLyT (part 2/4)"
                    },
                    "comment": {
                        "value": "### Weakness 1 (2/2):\n\n> At the same time, the performance degradation caused by residuals has not been analyzed theoretically. The expressive power of a finite basis is quite limited, and for some functions, their residuals could be fatal.\n\nThanks for pointing out the problem about expressive power of a finite basis. In the revised manuscript, we offered a detailed discussion on finite basis projection from various perspectives in **Section 3.1**, present some **theoretical analysis in Appendix B.1**, and provide a more intuitive demonstration using **real data in Appendix A.5**. We explained the acceptability of finite basis projection under LDP from the following perspectives:\n\n1. **Functional data fitting**: According to [Eubank, 1999], when fitting functional observations with common basis functions, the number of basis needed for optimal estimation risk increases slowly with the number of observed time points $T$. Taking cubic B-Spline (with order $m=4$) as an example, the estimation risk decays at the optimal rate of $T^{-2m/(2m+1)}$ as the number of inner knots $K$ grows like $T^{1/(2m+1)}$. With the number of basis $d=m+K$, finite B-Spline basis can effectively fit the data;\n\n2. **Performance of projection-based classifiers**: **Lemma 1 in Appendix B.1** demonstrates that under certain conditions, classifiers based on projection with finite basis can achieve the lowest possible misclassification rate among all possible classifiers;\n\n3. **Functional projection under LDP**: Projection-based methods enable the server to efficiently capture data patterns of interest, such as using Fourier basis for specific frequency bands or B-Spline for certain intervals. Employing finite basis helps capture population-level patterns while preventing overfitting to individual differences and enhances communication efficiency;\n\n4. **Real data**: **Figure 8 in Appendix A.5** visualizes functional observations from a phonemes dataset analyzed in **Section 6**. It also shows the curves reconstructed after finite basis projection and transformation. The projection (and transformation) erases individual detail information but retains the fluctuating pattern of individual curves, and the population-level group differences is also preserved.\n\n[Eubank, 1999] Randall L Eubank. Nonparametric regression and spline smoothing. CRC press, 1999."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492038470,
                "cdate": 1700492038470,
                "tmdate": 1700581535401,
                "mdate": 1700581535401,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1t8uUGQobm",
                "forum": "cNi2EJ8OCh",
                "replyto": "DMT6tEjPYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WLyT (part 3/4)"
                    },
                    "comment": {
                        "value": "### Weakness 2:\n\n> Regarding the ideas of model average and model reversal proposed by the authors, compared to traditional ensemble techniques, model average utilizes more clients in the evaluation process, aiming to select better weak classifiers. For each poor classifier, a model reversal approach is employed for improvement. However, since only a small number of clients are used to train the parameters, the classifiers might generally perform poorly; model reversal can enhance the performance of the learners, but it may not necessarily improve them to a satisfactory level. Theorem three provides an expected conclusion, but it does not directly lead to a high-probability bound; the theoretical analysis of model reversal is still lacking.\n\nThanks for pointing out the potential issues within Model Reversal (MR). We have addressed these in our revised manuscript by adding experimental results of classifiers based on MR, including experiments with weak classifiers trained using varying sample sizes, and by revising the content of Theorem 3.\n\n**Experimental Performance of MR**\n\n- From **Figure 1 in Section 5**, we observed that MR significantly improves the performance of all types of weak classifiers. And compared to Model Average (MA), the MRMA-based classifiers further substantially enhances the performance of SVM and CG classifiers;\n- In **Appendix A.4**, experimental results show that the number of clients used to train weak classifiers does not affect the efficacy of MR or MRMA in improving classifier performance. Additionally, when more client data is available, allocating more data for validation (i.e., for MR and MA) yields better results than using it solely to strengthen weak classifiers.\n\n**Theoretical Analysis of MR**\n\n- Given a classifier's accuracy rate distribution under $\\varepsilon$-LDP as $p_\\varepsilon(r)$ with $r\\in[0,1]$, **Theorem 3** measures the potential improvement in classification accuracy through MR;\n\n- Although a detailed theoretical analysis of the distribution $p_\\varepsilon(r)$ for various classifiers is beyond this paper's scope, it's evident from **Figure 1 in Section 5** and **Figure 3 in Appendix A.2** that different weak classifiers have varying sensitivities to noise and exhibit different distributions $p_\\varepsilon(r)$. This variation explains why MR offers more improvement for SVM and CG classifiers than Logistic and DWD classifiers in experiments, especially at lower values of $\\varepsilon$."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492065810,
                "cdate": 1700492065810,
                "tmdate": 1700492065810,
                "mdate": 1700492065810,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VqAYXdPeLo",
                "forum": "cNi2EJ8OCh",
                "replyto": "DMT6tEjPYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WLyT (part 4/4)"
                    },
                    "comment": {
                        "value": "### Q1) Are there specific scenarios or use cases where LDP provides a clear advantage over DP in functional data classification?\n\nWe apologize for not clearly distinguishing between LDP and DP in the original manuscript. As mentioned in the revised manuscript's Introduction and in response to **Weakness 1 (1/2)**, DP is sufficient for privacy protection in most scenarios. LDP is designed for more extreme cases, such as when dealing with untrustworthy or malicious data collectors, especially in situations involving highly sensitive or personal data. Here are two specific examples concerning remote health monitoring and fitness data where it is necessary to add noise at the individual data level before centralization:\n\n1. **Remote Health Monitoring Scenario** Consider a scenario where a remote health monitoring system is implemented by a healthcare provider. In this scenario, continuous health data, such as heart rate, blood pressure, and sleep patterns, are collected from patients through wearable devices. This sensitive data, once acquired by an untrusted server, could potentially be used to infer medical conditions or health status categories of the patients. Such inferences could then be utilized for various purposes, ranging from personalized healthcare and treatment plans to potentially more intrusive uses like health insurance premium adjustments or targeted advertising based on perceived health risks.\n\n2. **Fitness Data Collection Scenario** In another scenario, a fitness app collects detailed data on user activities, including step count, exercise routines, and physiological responses to workouts, from wearable fitness trackers. If this data falls into the hands of an untrusted server, it could be used to deduce categories such as fitness levels, lifestyle habits, or even underlying health issues of the users. Consequently, this information might be exploited for purposes like customizing fitness programs, but it also raises concerns about privacy breaches, where users\u2019 fitness data could be used for unsolicited health product marketing or influence health insurance policies without the users' explicit consent.\n\n### Q2) The idea of projecting data onto a finite basis is quite common in the realm of DP. Could you clarify how your approach innovates or differs significantly from existing methods?\n\nWe apologize for not making everything clear. The idea of projecting data onto a finite basis is indeed a commonly employed method. However, as we discussed in **Section 2** of the revised manuscript and in our response to **Weakness 1 (1/2)**, functional data analysis under DP or LDP faces distinctly different challenges. In the context of LDP, privacy learning with functional data, through finite basis projection, effectively reduces dimensionality to lessen noise interference, while simultaneously ensuring less impact on the efficacy of the learned models. Our paper is the first to consider privacy learning with functional data under LDP. We also propose novel techniques, Model Reversal and Model Average, tailored for LDP, to enhance classifier performance.\n\nFor a detailed overview of the novelty of our work, we refer to **General response** for a discussion.\n\n### Q3) The theoretical analysis of model reversal seems to be lacking. Could you provide more details or elaborate on the theoretical foundations of this technique?\n\nWe thank the reviewer for the kind advice. In the revised version of our paper, we have updated the content of **Theorem 3 in Section 3.3** and provided some discussion on it. And in our response to **Weakness 2**, we have discussed in detail the theoretical analysis of Model Reversal. We hope this adequately addresses the reviewer's concerns.\n\n\n\nOnce again, we appreciate the reviewer's valuable time. We look forward to the opportunity to engage in more detailed discussions to dispel any concerns."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492098764,
                "cdate": 1700492098764,
                "tmdate": 1700492098764,
                "mdate": 1700492098764,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iwHeXgej3u",
                "forum": "cNi2EJ8OCh",
                "replyto": "DMT6tEjPYw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Seeking Feedback on Our Responses and Revised Submission"
                    },
                    "comment": {
                        "value": "Dear Reviewer WLyT,\n\nThank you once again for your valuable insights and the time you have dedicated to reviewing our work. Your feedback has been instrumental in enhancing our revised manuscript, and we are keen to hear any additional comments or suggestions you might have.\n\nWith the discussion deadline nearing, we would be grateful for your reply to ensure that all your concerns have been adequately addressed in our latest revision. Your guidance is invaluable to us, and we eagerly await your response at your earliest convenience. \n\nBest regards!"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700623362091,
                "cdate": 1700623362091,
                "tmdate": 1700623362091,
                "mdate": 1700623362091,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tiLMRGo8nl",
            "forum": "cNi2EJ8OCh",
            "replyto": "cNi2EJ8OCh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3366/Reviewer_D9bv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3366/Reviewer_D9bv"
            ],
            "content": {
                "summary": {
                    "value": "Functional data is infinite-dimensional data which can be approximated by a linear combination of basis functions; this paper explores how to classify functional data under the constraint of local differential privacy (LDP). The authors demonstrate how to construct \u201cweak\u201d functional data classifiers under LDP, and then demonstrate how to boost the weak classifiers\u2019 performance using model averaging (which combines the weak classifiers) and the novel technique of \u201cmodel reversal\u201d (which flips the signs of a weak classifier\u2019s coefficients). The authors combine these techniques into algorithms for both single-server and multi-server (i.e., federated learning) settings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem setting as well as the proposed algorithms are quite novel. In particular, I think that the idea of model reversal is kind of fun and creative.\n\n2. The experimental results also seem to show that using the proposed methods does improve classification accuracy."
                },
                "weaknesses": {
                    "value": "1. The setting seems obscure and not very well-motivated. I don\u2019t really understand the significance of functional data and where it\u2019s found in real-world applications.\n\n2. I\u2019m not fully convinced by the empirical evaluation. The experimental results show that the proposed techniques improve classification performance, but at the same time the baselines don\u2019t set a particularly high bar to beat. While I understand that a little-explored setting won\u2019t have much previous work to compare to, it is still hard to judge the importance of the methods without them. And touching back on Weakness #1, the experiments are all conducted on a synthetic dataset and so it\u2019s unclear how well the methods will generalize to real-world data."
                },
                "questions": {
                    "value": "1. Would it be possible to give more details on the practicality of functional data? For example, are there realistic datasets that are considered to be \u201cfunctional data\u201d and how do the properties of functional data translate to the real world?\n\n2. Is there a formal definition for a \u201cweak classifier\u201d?\n\n3. The functional data classifiers are constructed under LDP, and then it seems to me that the LDP setting is kind of irrelevant to the rest of the paper (or at least, to the model average and model reversal techniques). Similarly for the functional data setting, after dimensionality reduction and re-scaling. Do MA and MR actually have anything to do specifically with LDP (or with functional data), or are they general techniques that could be used to improve the performance of any collection of weak classifiers?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3366/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3366/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3366/Reviewer_D9bv"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3366/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698629124240,
            "cdate": 1698629124240,
            "tmdate": 1699636286935,
            "mdate": 1699636286935,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mrG83JXe6b",
                "forum": "cNi2EJ8OCh",
                "replyto": "tiLMRGo8nl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer D9bv (part 1/2)"
                    },
                    "comment": {
                        "value": "We are delighted that reviewer found the idea of Model Reversal fun and creative. We thank the reviewer for the insightful and constructive comments. Below, we provide detailed responses to each comment and explain how we have revised our manuscript accordingly.\n\n### W1) The setting seems obscure and not very well-motivated. I don\u2019t really understand the significance of functional data and where it\u2019s found in real-world applications.\n\nThanks for pointing it out! We've realized our article lacked an introduction to functional data and its privacy aspects. In response, we have now included in **Section 1 (Introduction)** a brief overview of functional data and the importance of privacy preservation, along with relevant examples. Additionally, **Section 6 (Real Application)** has been updated to include a real data application to demonstrate these concepts in practice.\n\n- **Functional data analysis (FDA)** is a branch of statistics that deals with data that is densely observed over a continuum, such as time or space. This type of data is distinct from traditional multivariate data, which typically consists of a finite number of variables measured at a discrete set of points. FDA is widely used in various fields **such as** economics (for analyzing financial time series), environmental sciences (for studying climate change effects), health sciences (for analyzing continuous health monitoring data), and engineering (for signal processing). And privacy preservation in functional data is also crucial in domains **such as** health informatics, where hospital patient monitoring systems can reveal sensitive health information, and in behavioral science, where data from smart devices can provide deep insights into an individual's lifestyle and habits.\n\n### W2) I\u2019m not fully convinced by the empirical evaluation.\n\n> The experimental results show that the proposed techniques improve classification performance, but at the same time the baselines don\u2019t set a particularly high bar to beat. While I understand that a little-explored setting won\u2019t have much previous work to compare to, it is still hard to judge the importance of the methods without them. And touching back on Weakness #1, the experiments are all conducted on a synthetic dataset and so it\u2019s unclear how well the methods will generalize to real-world data.\n\nWe thank the reviewer for the insightful comments. In the revised version of our paper, we have supplemented it with comparative experiments and added a real-world application.\n\n- **Experimental Results**: In **Figure 1 of Section 5**, we supplemented results for classifiers based on classic aggregation methods, \"Voting\" and \"Averaging\". It\u2019s evident that under LDP, these classic methods are ineffective. However, our proposed techniques, both Model Reversal (MR) and Model Average (MA), significantly improve the performance of all types of weak classifiers, even at lower $\\varepsilon$ values, which corresponds to higher levels of privacy protection. MRMA, in particular, substantially further enhances the performance of SVM and CG classifiers. Similar results can also be found in **Figure 7 in Appendix A.4**. As the reviewer mentioned, since this is the first paper to study functional classification, our simulations lacked existing methods for comparison. If there are any additional suggestions for comparison, please let us know.\n\n- **Real Application**: In **Section 6 (Real Application)**, we employed our methods on a phonemes dataset derived from the TIMIT Speech Corpus. To ensure the robustness and reliability of our results, we conducted 500 random splits of the dataset into test, training, and validation sets. The performance of various methods in this real-world application was similar to that observed in the simulations, with classifiers based on MR and MA still showing good performance."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700491913283,
                "cdate": 1700491913283,
                "tmdate": 1700581701528,
                "mdate": 1700581701528,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lsFH8OoWgE",
                "forum": "cNi2EJ8OCh",
                "replyto": "tiLMRGo8nl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer D9bv (part 2/2)"
                    },
                    "comment": {
                        "value": "### Q1) Would it be possible to give more details on the practicality of functional data? \n\n> For example, are there realistic datasets that are considered to be \"functional data\" and how do the properties of functional data translate to the real world?\n\nWe thank the reviewer for the kind advice. In the revised version of our paper, we introduced functional data and provided examples of its practical applications in the first paragraph of **Introduction**. And in our response to **W1)**, we give functional data examples in various fields. We hope this sufficiently addresses the reviewer's concern.\n\n### Q2) Is there a formal definition for a \"weak classifier\"?\n\nI apologize for the lack of clarity in our paper. We introduced the process of generating weak classifiers during the training phase in **Section 3.3** of our paper. And in the context of machine learning, a \"weak classifier\" generally refers to a simple model that performs only slightly better than a random guesser in classifying instances into classes. This concept is often discussed in ensemble learning methods, particularly in boosting algorithms.\n\n### Q3) The functional data classifiers are constructed under LDP [...]\n\n> The functional data classifiers are constructed under LDP, and then it seems to me that the LDP setting is kind of irrelevant to the rest of the paper (or at least, to the model average and model reversal techniques). Similarly for the functional data setting, after dimensionality reduction and re-scaling. Do MA and MR actually have anything to do specifically with LDP (or with functional data), or are they general techniques that could be used to improve the performance of any collection of weak classifiers?\n\nWe apologize for not making the relationship among LDP, functional data, and MRMA clear. In this paper, we proposed a new technique, **Model Reversal**, to enhance the performance of a single weak classifier under LDP. We also introduced a **Model Average** approach tailored for LDP to obtain a better collection of weak classifiers. And the data allocation ratio for training and validation sets, as well as the validation process used in our MRMA technique, are all specifically designed for LDP.\n\nHere, we provide a more detailed explanation of the relationship among LDP, functional data, and MRMA:\n\n- **LDP and MR (Model Reversal)**: MR is a new technique we developed to improve the performance of weak classifiers under LDP. Under LDP, it's common for weak classifiers to have misclassification rates greater than $50\\%$ due to high noise in the data, and using MR can lead to significant improvements. In **Theorem 3 of Section 3.3**, we measured the enhancement that model reversal can bring to the classifier;\n\n- **LDP and MA (Model Average)**: MA in our paper is designed specifically for LDP challenges. Specifically, we proposed a method to evaluate the performance of weak classifiers under LDP in **Theorem 2 of Section 3.3**. And based on the evaluation, we assigned more suitable weights to these classifiers during the collection process;\n\n- **Functional data and MRMA**: Our MRMA algorithm is applicable to functional data as well as other data types. After obtaining weak classifiers trained on various data types under LDP, it can be used to construct a better-performing classifier.\n\n\n\nOnce again, we are grateful for the time and effort the reviewer has invested in evaluating our work. And we welcome any additional dialogue to clarify any aspects of our research."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700491944538,
                "cdate": 1700491944538,
                "tmdate": 1700491944538,
                "mdate": 1700491944538,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PHTufPJyhb",
                "forum": "cNi2EJ8OCh",
                "replyto": "lsFH8OoWgE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Reviewer_D9bv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Reviewer_D9bv"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks very much for the detailed clarifications. The revised paper is looking good!\n\nMost of my concerns have been addressed, but I do share Reviewer sTQT\u2019s sentiment that the techniques proposed in the paper aren\u2019t tailored specifically to the problem setting (of functional data and LDP). For example, I agree that model reversal seems advantageous in the LDP setting (because the large amount of noise required by LDP could cause weak classifiers to have misclassification rates greater than 50%). But it\u2019s still not clear to me how or if the functional data setting is relevant to the proposed algorithms.\n\nI also need some help interpreting Theorem 3 in Section 3.3. Theorem 3 seems to tell us that model reversal has an effect under LDP, but doesn\u2019t tell us *what* the effect is (without knowing anything about the distribution $p_{\\epsilon}(r)$). Even if it is beyond the scope of the paper to analyze these distributions, perhaps it would be possible to describe some general behaviors of $p_{\\epsilon}(r)$ that would make model reversal more effective?"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542779950,
                "cdate": 1700542779950,
                "tmdate": 1700542779950,
                "mdate": 1700542779950,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6wJNabb002",
                "forum": "cNi2EJ8OCh",
                "replyto": "tiLMRGo8nl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer D9bv"
                    },
                    "comment": {
                        "value": "Thank you for acknowledging the revisions made in our paper and for expressing satisfaction that we have addressed most of your concerns. Below are our responses to your new comments, and we hope these will further satisfy your queries and considerations.\n\n> I do share Reviewer sTQT\u2019s sentiment that the techniques proposed in the paper aren\u2019t tailored specifically to the problem setting (**of functional data and LDP**). For example, I agree that model reversal seems advantageous in the LDP setting (...). But it\u2019s still not clear to me how or if the functional data setting is relevant to the proposed algorithms.\n\nWe understand your concern. As mentioned in our response to Reviewer sTQT, our newly proposed techniques, Model Reversal (MR) and Model Averaging (MA), are not exclusively tailored for functional data. However, they are indeed specifically designed for LDP scenarios, and suitable for scenarios that necessitate the improvement and combination of weak classifiers. They have demonstrated good performance in both experiments and real application. \n\n> I also need some help interpreting Theorem 3 in Section 3.3. Theorem 3 seems to tell us that model reversal has an effect under LDP, but doesn\u2019t tell us *what* the effect is (without knowing anything about the distribution $p_{\\epsilon}(r)$). \n\nWe apologize for any lack of clarity in Theorem 3. We plan to update Theorem 3 as follows to address this issue. If our explanation is still not clear enough or if you have any suggestions for further modifications, please let us know.\n\n**Theorem 3**. For a classifier $f_\\varepsilon$ that adheres to $\\varepsilon$-LDP, let's denote its classification accuracy rate as $r(x)=P(\\text{sign}(f_\\varepsilon(x))=y|x)$. Additionally, let $r_\\delta$ represent the potential enhancement in classification accuracy that could be achieved for $f_\\varepsilon$ through the application of model reversal.\n\n1. If $r(x)=r_0$ for all $x(t)$, then $r_\\delta=\\max\\lbrace1-2r_0,0\\rbrace$.\n\n2. Otherwise, let's denote the distribution of classification accuracy rate as $p_\\varepsilon(r)=P(x(t) \\in A_{\\varepsilon,r})$ with $r\\in[0,1]$, where $A_{\\varepsilon,r}=\\lbrace x(t)| r(x)=r \\rbrace$. Then\n   $$\n   \\mathbb{E}(r_\\delta)=\\int_0^1 p_\\varepsilon(r)\\max\\lbrace 1-2r,0\\rbrace dr=\\int_0^{1/2} p_\\varepsilon(r)(1-2r) dr.\n   $$\n\nTheorem 3 quantifies the enhancement in classification accuracy that model reversal can contribute to a classifier. We would also like to emphasize the following two points:\n\n1. In practical scenarios, even if we have no information about the distribution $p_\\varepsilon(r)$, employing MR will not worsen the results. It will either improve them or, at least, maintain them at their current level;\n\n2. When $\\varepsilon$ is sufficiently large, it represents a scenario with no LDP constraints. This implies that this theorem is also applicable in non-LDP contexts.\n\n\n\n> Even if it is beyond the scope of the paper to analyze these distributions, perhaps it would be possible to describe some general behaviors of $p_{\\epsilon}(r)$ that would make model reversal more effective?\n\nWhen a classifier has a lower classification accuracy, meaning the distribution $p_\\varepsilon(r)$ is more concentrated in the range $r \\in [0, 1/2)$, using model reversal can bring about a more significant improvement.\n\nThe four types of classifiers presented in our paper demonstrate differences in their distributions. We will update our paper soon to showcase the distributions of classification accuracy rates $p_\\varepsilon(r)$ for different classifiers. In the meantime, you may refer to **Figure 1 in Section 5**, which includes error bars of the misclassification rate, and **Figure 3 in Appendix A.2**, which shows the boxplots, of various types of weak classifiers. These classifiers exhibit varying sensitivities to noise and demonstrate different distributions. For example, in **Figure 3**, the misclassification rate of the CG classifier remains highly volatile at smaller $\\varepsilon$ values, ranging between $10$% and $90$%, instead of converging around $50$% as other methods do. This indicates that its performance can be significantly enhanced through model reversal.\n\nWe appreciate your ongoing engagement in this discussion. Should there be any further points needing clarification or if you have additional questions, please do not hesitate to bring them up. Any additional feedback for enhancing our paper is highly valued. We are hopeful that these efforts will positively reflect in the paper's evaluation."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700550470407,
                "cdate": 1700550470407,
                "tmdate": 1700550979778,
                "mdate": 1700550979778,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "N8KwQzX5by",
            "forum": "cNi2EJ8OCh",
            "replyto": "cNi2EJ8OCh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3366/Reviewer_rZaz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3366/Reviewer_rZaz"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies functional classification under local DP constraints. Specifically, the paper proposes a privatization step for each client using a projection-based dimensionality reduction technique. Then this paper also proposes a model average and a model reversal method to enhance the performance of the classifier. Finally, this paper also studies the same problem under heterogeneous multi-server setting."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper is the first to study functional classification with LDP constraints.\n2. The proposed method is simple and practical."
                },
                "weaknesses": {
                    "value": "1. It would be better if the authors could add some intuition and discussion about the result in Theorem 2 and 3.\n2. The proposed method is built on the dimension reduction scheme and laplace mechanism which does not seem to be very novel."
                },
                "questions": {
                    "value": "Please see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3366/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698819910254,
            "cdate": 1698819910254,
            "tmdate": 1699636286807,
            "mdate": 1699636286807,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WOlBZnOn65",
                "forum": "cNi2EJ8OCh",
                "replyto": "N8KwQzX5by",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rZaz"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive evaluation of our paper and the recognition of our method. Below, we do our best to address the reviewer's questions adequately.\n\n\n\n### W1) It would be better if the authors could add some intuition and discussion about the result in Theorem 2 and 3.\n\nThanks for the kind advice. We have now incorporated discussions in the revised manuscript.\n\n- In **Theorem 2**, we demonstrated that the validation process adheres to Local Differential Privacy (LDP). We then provided an unbiased estimate of the classifier's accuracy rate and the variance of this estimate. The accurate assessment of the classifier's performance is a fundamental prerequisite for the subsequent enhancement of the classifier's performance through  Model Reversal and Model Average (MRMA).\n- We have enriched the content of **Theorem 3**. This theorem measures the improvement in classification accuracy that can be achieved through Model Reversal (MR) when the distribution of classification accuracy rate of a classifier, constructed under $\\varepsilon$-LDP, is known to be $p_\\varepsilon(r)$ with $r\\in[0,1]$.\n\n\n\n### W2) The proposed method is built on the dimension reduction scheme and laplace mechanism which does not seem to be very novel.\n\nWe apologize for not sufficiently highlighting the novelty of our work in the original submission. Indeed, the dimension reduction scheme and the Laplace mechanism are well-established methods. However, our paper focuses more on building a functional classifier and proposing the MRMA algorithm tailored for LDP to enhance classifier performance under LDP.\n\nFor a detailed overview of the novelty of our work, we refer to **General response** for a discussion.\n\n\n\nOnce again, we deeply appreciate the reviewer\u2019s time for reviewing our manuscript. We are keen to continue the conversation and address any remaining points of confusion."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700491825819,
                "cdate": 1700491825819,
                "tmdate": 1700544197651,
                "mdate": 1700544197651,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kHLdCWHpIj",
                "forum": "cNi2EJ8OCh",
                "replyto": "N8KwQzX5by",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Seeking Feedback on Our Responses and Revised Submission"
                    },
                    "comment": {
                        "value": "Dear Reviewer rZaz,\n\nWe would like to thank you again for the precious time and constructive comments. In response to your comments, we have submitted a revised manuscript and would greatly appreciate any further thoughts or feedback you might have on these updates.\n\nAs the discussion deadline is approaching, we are eager to address any remaining concerns or questions you may have regarding our revised submission. We deeply appreciate your advice and look forward to your prompt feedback.\n\nBest regards!"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700623297726,
                "cdate": 1700623297726,
                "tmdate": 1700623297726,
                "mdate": 1700623297726,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "R0BNKpTL1O",
            "forum": "cNi2EJ8OCh",
            "replyto": "cNi2EJ8OCh",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the problem of (binary) classification for functional data, under local differential privacy.\n\nTheir approach is as follows: First they project the functional data onto a finite subspace and express it in a finite basis. This would make the data look like a point in $\\mathbb{R}^d$. In order to reduce sensitivity, they apply either the $\\tanh$ or the $\\min$-$\\max$ transformation to each point to make each coordinate bounded. This would give us bounded sensitivity. After that they train a classifier on the privatized transformation of the data.\n\nIn order to mitigate the effect of the noise they use a boosting technique, specifically they use model averaging: they divide the users into two groups, one for training and one for validation, and divide each of those two into $B$ parts. Then they design $B$ weak classifiers, one for each part of the training set and the evaluate them on the corresponding part from the validation set. Each validation user then outputs the result of the validation, with a randomized response mechanism to ensure privacy. If the answer from the aggregation of randomized response is less than 50% accurate, we negate the sign of the classifier to obtain a better classifier (Model Reversal). In order to design a final classifier using the $B$ weak classifiers and the validation outputs, they use the validation outputs to design a set of weights, and then to create the final classifier, they take a weighted average of the $B$ weak classifiers (Model Averaging).\n\nThey also provide a similar technique for combining the results of $K$ servers.\n\nThey run several experiments to compare the performance of their model against the naive model that uses all of the training data to train a single classifier and compare different threshold levels for Model Averaging."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I think this is the first paper that considers the problem of functional classification under local differential privacy.\n\nFrom their experiments it seems like the accuracy of their approach is better than the naive baselines by 10 to 20 percent. The naive baselines include: all of the data is used to train one model, or we're doing model averaging but all of the weights are equal."
                },
                "weaknesses": {
                    "value": "My main concern is limited novelty in the techniques. Apart from the part initial dimensionality reduction and encoding part, which are standard techniques, I think the rest of the techniques are independent of the functional classification setting specifically. Overall, it seems like once we're done with dimensionality reduction and encoding everything is the same as in $\\mathbb{R}^d$.\n\nThe effect of model reversal in the experiments seems pretty small."
                },
                "questions": {
                    "value": "It is mentioned that the ignored residual function contributes to privacy protection. I think that requires more explanation.\n\nI think the budgeting for privacy at the top of page 4 is wrong. When running the Laplace mechanism and assuming sensitivity is some $\\Delta$ you need to sample noise from $\\mathcal{L}(\\frac{\\Delta}{\\epsilon})^{\\otimes d}$. You don't need to add a multiplicative $d$ for each dimension."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3366/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT",
                        "ICLR.cc/2024/Conference/Submission3366/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3366/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698834854341,
            "cdate": 1698834854341,
            "tmdate": 1700705681180,
            "mdate": 1700705681180,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RV2izdzhig",
                "forum": "cNi2EJ8OCh",
                "replyto": "R0BNKpTL1O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer sTQT (part 1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the thorough review and excellent summarization of our work. We have carefully addressed each comment below and outlined the respective modifications made to our manuscript in light of the reviewer's feedback.\n\n\n### W1) My main concern is limited novelty in the techniques. \n\n> Apart from the part initial dimensionality reduction and encoding part, which are standard techniques, I think the rest of the techniques are independent of the functional classification setting specifically. Overall, it seems like once we're done with dimensionality reduction and encoding everything is the same as in $R^d$.\n\nWe thank the reviewer for the detailed and insightful comments. Dimensionality reduction and encoding are indeed standard techniques, while our paper is the first to integrate them into an algorithm for functional classification under Local Differential Privacy (LDP), where we proposed the MRMA algorithm tailored for LDP. And in our revised manuscript, we provided a detailed discussion about functional projection in **Section 3.1**. Additionally, in **Appendix B.1**, we offered further theoretical analysis on projection-based functional classification and measure the information loss induced by projection.\n\nRegarding \"the rest of the techniques\", we would like to emphasize the following points:\n\n- **Model Reversal (MR)**: This is a new technique we developed to enhance the performance of weak classifiers under LDP. In **Theorem 3 of Section 3.3**, we measured the improvement that model reversal can bring to a classifier;\n- **Model Average (MA)**: In our paper, we introduced a MA algorithm tailored for LDP. It includes our methods of evaluating the performance of weak classifiers under LDP (see **Theorem 2 of Section 3.3**), and assigning more suitable weights to these classifiers based on the evaluation;\n- **Regarding the Validation Process**: We advocate for allocating a larger proportion of clients to evaluate the performance of weak learners, especially when dealing with multivariate observational data under LDP. Since the evaluation is typically scalar, the noised client's evaluation of a model usually contains less noise than his noised observational vector under the same privacy protection level;\n- **Experimental and Real Data Results**: In Sections 5 and 6, our techniques, MR and MA, have significantly improved the performance of weak classifiers, especially in scenarios with large noise interference. Furthermore, the experimental results in Appendices A.3 and A.4 also validate our assertions regarding sample allocation.\n\nFor a detailed overview of the novelty of our work, we refer to **General response** for a discussion.\n\n\n### W2) The effect of model reversal in the experiments seems pretty small. \n\nWe appreciate the feedback and apologize for any confusion caused by the presentation of our images. We have made revisions to the original figures and included additional simulations to better illustrate the improvements in classifier performance brought about by model reversal.\n\nSpecifically, in **Figure 1 of Section 5**, we demonstrated the effectiveness of MR by comparing classifiers' performance with and without MR, where MR significantly improves the performance of all types of weak classifiers. And compare to MA, MRMA further enhances the performance of SVM and CG classifiers substantially. Similar results can also be found in **Fugure 2 in Section 6** (Real Application) and **Figure 7 in Appendix A.4**."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700491602005,
                "cdate": 1700491602005,
                "tmdate": 1700581659417,
                "mdate": 1700581659417,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lTwLAFvt6p",
                "forum": "cNi2EJ8OCh",
                "replyto": "R0BNKpTL1O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer sTQT (part 2/2)"
                    },
                    "comment": {
                        "value": "### Q1) It is mentioned that the ignored residual function contributes to privacy protection. I think that requires more explanation.\n\nWe thank the reviewer for the kind advice. We have added a more detailed discussion about finite basis projection in **Section 3.1** of the revised manuscript. Additionally, in **Figure 8 Appendix A.5**, we illustrated the impact of projection and transformation on functional observations using a real dataset.\n\n- As we discussed in **Section 3.1**, under LDP, compared to recovering true observational data, the primary concern is the performance of models trained on noised data. Utilizing finite basis projection is advantageous for capturing population-level pattern information, rather than individual differences. Ignoring the individual residual function, which contains personal information, does not significantly impact classifier performance while still effectively protecting user privacy.\n- **Figure 8 in Appendix A.5** visualizes functional observations from a phonemes dataset analyzed in Section 6. It also shows the curves reconstructed after finite basis projection and transformation. The projection (and transformation) erases individual detail information but retains the fluctuating pattern of individual curves, and the pattern of population-level group differences is also preserved.\n\n\n\n### Q2) The budgeting for privacy at the top of page 4 is wrong. \n\nWe apologize for the possible confusion. Maybe there was a misunderstanding in our original manuscript regarding the sensitivity $\\Delta$. To clarify, $\\Delta$ refers to the sensitivity of each element of the vector $\\boldsymbol{z}^*$, i.e., $z_k^*$ , not the sensitivity of the vector $\\boldsymbol{z}^*$. Therefore, according to the sequential composition theorem, to achieve $\\varepsilon$-LDP for a $d$-dimensional vector, it is necessary to ensure that each dimension complies with $\\varepsilon/d$-LDP. This underlines one of the challenges of handling high-dimensional data under LDP constraints.\n\n\n\nOnce again, we appreciate the reviewer's precious time. We are eager to engage in further discussions to clear out any confusion."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700491661166,
                "cdate": 1700491661166,
                "tmdate": 1700581628284,
                "mdate": 1700581628284,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1p3D70o0ig",
                "forum": "cNi2EJ8OCh",
                "replyto": "R0BNKpTL1O",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT"
                ],
                "content": {
                    "comment": {
                        "value": "I have reviewed the responses and the updates in the paper. I thank the authors for their response. I will maintain my score for the time being.\n\n**W1**. My main criticism was that the techniques presented here, don't seem to be tailored to the setting of the problem, which is functional classification. After dimensionality reduction and encoding, the rest of the techniques apply to any data in $[-1,1]^d$. I don't think the authors have addressed this concern.\n\n**W2**. I have reviewed the new plots. I think comparing to the average misclassification rate of the weak classifiers as a baseline can be misleading. The authors should compare their results with the setting that there's no boosting style technique used. In their example $50$ weak classifiers are trained using $500$ of the $3000$ total clients. And then a final model is selected based on verification results that use on the weak classifier, using the remaining $2500$ clients. How would your models perform if you used the $3000$ clients on training a single classifier and assessed its performance? Same for the setting where real data is used.\n\n**Q1**. I understand the intuition that if we're summarizing the data, privatizing it should be easier. That being said, I wonder if there's any formalization of this claim.\n\n**Q2**. I see, I thought your goal is to privatize $\\mathbf{z}^*$. In that case the $\\ell_1$ sensitivity would have been $2d$. The final result is the same."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700531297391,
                "cdate": 1700531297391,
                "tmdate": 1700543117024,
                "mdate": 1700543117024,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yWRbrCxdmq",
                "forum": "cNi2EJ8OCh",
                "replyto": "c8yxMft3tz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their response.\n\n**W1.** I see, thank you.\n\n**W2.** Thank you for adding the all data accuracy plots. I'm curious, it's a bit surprising that the average model trained on $50$ samples has only slightly worse performance than a model trained on $3000$ samples. For example that is the case in Figure 1 (a), at $\\varepsilon = 2$. Is there a good explanation for that? Also the behavior of the accuracy curve seems to differ significantly across different models. In figure 1, logistic and DWD, start deviating from $\\varepsilon = 1$, while SVM and CG start deviating from $\\varepsilon = 0.1$, is there an explanation for that behavior?\n\n**Q1.** I see. I think the wording in the paper makes it sound like we have strong evidence to suggest that ignoring the residual function would help with privacy. I suggest at least changing the wording, or alternatively providing evidence.\n\n> thereby enhancing privacy protection as the residual function \u03be(t), containing personal information, is ignored."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628411570,
                "cdate": 1700628411570,
                "tmdate": 1700628411570,
                "mdate": 1700628411570,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "h9KyEfSjx8",
                "forum": "cNi2EJ8OCh",
                "replyto": "DN47yY6ZEs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3366/Reviewer_sTQT"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the explanation. I think now I understand why there is not much improvement in accuracy in the high sample setting. \n\nI think the authors have addressed most of my concerns regarding the experiments. I will slightly increase my score. That being said, I still think the presentation of this work as an algorithm for classification of functional data is not accurate."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3366/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700705660341,
                "cdate": 1700705660341,
                "tmdate": 1700705660341,
                "mdate": 1700705660341,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]