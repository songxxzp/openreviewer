[
    {
        "title": "Removing Multiple Shortcuts through the Lens of Multi-task Learning"
    },
    {
        "review": {
            "id": "TCn822jSec",
            "forum": "rJKlmCpOQ7",
            "replyto": "rJKlmCpOQ7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_JtYi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_JtYi"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the problem of training an accurate unbiased model using a dataset with multiple biases. Conventional training methods (e.g. ERM) lead to undesirable shortcuts in the model due to the spurious correlations in the dataset. To counter this, debiased training algorithms have been proposed but most of them focus on a single bias at a time. Hence, this work focuses on the problem of multiple biases in a dataset, which is more practical. They first divide the dataset into multiple groups such that each group exerts the same bias on model training, using labeled bias attributes. They formulate the problem in terms of multi-task learning (MTL) where the model has to learn to handle each group correctly. Towards this, they derive a multi-objective optimization algorithm to dynamically update task weights so that model parameters can converge to a Pareto-stationary point. For experiments, they re-purpose the CelebA dataset (called MultiCelebA) using multiple attributes that are spuriously correlated with the target class. On MultiCelebA and other benchmarks, they achieve state-of-the-art performance for both multiple bias and single bias settings."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The interpretation of debiased training as an MTL problem seems interesting and novel.\n\n* The proposed method is simple, intuitive, and effective.\n\n* The paper is fairly well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "* Debiased training as MTL\n    * Debiased training actually seems closer to multi-domain learning (MDL) [W1] rather than MTL. Because MTL clearly means learning different tasks (i.e. task labels are different) as the paper also mentions on Page 2. \n    * On the other hand, MDL involves the same target classes but data coming from different domains, and the goal is to achieve good performance on all domains simultaneously.\n    * Also it seems like debiased training has a lot in common with long-tailed learning [W2]. For example, upweighting and upsampling baselines are also employed in long-tailed learning.\n    * Overall, I wonder why MTL is chosen over these other two. Also, it might be interesting to see how more advanced techniques from MDL or long-tailed learning perform when adapted to debiased training.\n    * Note: the above two references are just examples, there are many more papers in both sub-topics.\n\n* Regarding dataset contribution\n    * It is unclear how MultiCelebA is a new dataset compared to CelebA. There are no new images or new labels. Even the choice of attributes is based on the analysis from a prior work. \n    * The contribution of a new dataset seems misleading, only a new experimental setting based on an existing dataset is proposed.\n\n* Design choices\n    * The design choices for the main algorithm are not well explained. Please see questions for more details.\n\n* Practicality and significance of dataset\n    * Simple methods like upsampling and upweighting give very good improvements over the ERM baseline and are quite close to even the proposed method (Table 1). This raises a question on whether the proposed MultiCelebA is practical or challenging enough to provide new insights into evaluating debiased training methods.\n    * See questions for more details.\n\n### References\n\n[W1] Sebag et al., \"Multi-Domain Adversarial Learning\", ICLR19\n\n[W2] Cao et al., \u201cLearning Imbalanced Datasets with Label-Distribution-Aware Margin Loss\u201d, NeurIPS19"
                },
                "questions": {
                    "value": "* Please also see the weaknesses section.\n\n* Regarding practicality and significance of datasets and debiased training\n    * Ideally, one would expect new datasets or benchmarks to improve over existing datasets by providing more challenging scenarios (or at least more data). While the overall accuracy numbers of MultiCelebA seem lower than UrbanCars (but similar to Multi-Color MNIST), upsampling and upweighting are consistently good on all three datasets. \n    * So MultiCelebA seems similar in terms of difficulty compared to existing datasets (i.e. there seems to be no advantage to having real images over synthetic images in the other datasets).\n    * Another question is whether complicated debiased training methods (like the proposed method) themselves provide any significant improvements to be deemed of practical significance. This is because we observe a similar trend where upsampling and upweighting perform very well compared to all the supervised debiased learning methods.\n\n* Regarding design choices (Algorithm 1)\n    1. Why is $\\theta$ updated again (outside the \"for loop\") after updating it for $U$ number of times?\n    2. Why do $\\bar{\\alpha}$ and $\\lambda$ need to be updated once every $U$ iterations and not every iteration?\n    3. Also, why not have $\\bar{\\alpha}$ and $\\lambda$ updates be at different frequencies like every $U_1$ and every $U_2$ iterations instead of together after $U$ iterations?\n    * These design choices need to be explained and justified since this is the core idea being proposed.\n\n* Minor comments\n    * Page 3 (5th line of \u201cFairness with MTL\u201d paragraph): use \\cite instead of \\citet\n    * Sec. 3.1 (first paragraph): mention dimensions of $\\theta$, should be $\\mathbb{R}^n$ as per usage in Definition 2.\n    * Fig. 3: x-axis title has typos: \u201cinteration\u201d \u2192 \u201citeration\u201d.\n    * Page 10: Citation for Fernando et al. (MoCo) is incorrect, it should be ICLR 2023 and not ICLR 2022."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1800/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1800/Reviewer_JtYi",
                        "ICLR.cc/2024/Conference/Submission1800/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1800/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698730241452,
            "cdate": 1698730241452,
            "tmdate": 1700708671623,
            "mdate": 1700708671623,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "d33wXjDeBY",
                "forum": "rJKlmCpOQ7",
                "replyto": "TCn822jSec",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer JtYi (1/2)"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your insightful feedback and constructive suggestions that helped improve our paper substantially. All the suggestions will be incorporated, and additional discussions will be added to the main text. Please find our detailed responses to the comments below.\n____\n>**[Weakness 1] Debiased training as MTL: Debiased training actually seems closer to multi-domain learning (MDL) [W1] rather than MTL. Because MTL clearly means learning different tasks (i.e. task labels are different) as the paper also mentions on Page 2.**\n>- On the other hand, MDL involves the same target classes but data coming from different domains, and the goal is to achieve good performance on all domains simultaneously. Also it seems like debiased training has a lot in common with long-tailed learning [W2]. For example, upweighting and upsampling baselines are also employed in long-tailed learning.\n>- Overall, I wonder why MTL is chosen over these other two. Also, it might be interesting to see how more advanced techniques from MDL or long-tailed learning perform when adapted to debiased training.\n>- Note: the above two references are just examples, there are many more papers in both sub-topics.\n\nThank you for interesting and insightful suggestions! As you mentioned, both long-tailed classification and multi domain learning are relevant in mitigating spurious correlation in the context of data imbalances. Based on your comments, we will consider integrating techniques from MDL or long-tailed learning for debiasing in the future work. However, we believe MTL can be more naturally incorporated with debiased training for the following reasons. Debiasing focuses on training an unbiased model with respect to spurious correlations. While MDL addresses data imbalance among different domains and long-tailed classification deals with data imbalance among target classes, debiasing tackles the imbalance among bias attributes within a given target label in training dataset. For instance, in bird species classification, if most waterbirds in the dataset are with water background and ERM erroneously uses the water background as a shortcut for classifying waterbirds, waterbirds and water background have  spurious correlation. Therefore, we designed a learning algorithm that causes task conflicts when a model relies on shortcuts by defining tasks according to adherence of samples to spurious correlations using our grouping policy. Adopting MOO to resolve task conflicts is an effective approach for training an unbiased model by removing shortcuts.\n____\n>**[Weakness 2] It is unclear how MultiCelebA is a new dataset compared to CelebA. There are no new images or new labels. Even the choice of attributes is based on the analysis from a prior work. The contribution of a new dataset seems misleading, only a new experimental setting based on an existing dataset is proposed.**\n\nThanks for the comment, and we have replaced \u201cnew dataset\u201d with \u201cnew benchmark\u201d in the manuscript to address the concern. Despite this change, we still believe that, as a realistic and challenging benchmark, MultiCelebA will contribute substantially and promote future research in the field of debiased training. We also would like to highlight that reprocessed datasets/benchmarks like MultiCelebA have long been recognized by the community; examples include bFFHQ, a dataset for debiasing derived from FFHQ, and those for long-tailed classification such as ImageNet-LT (from ImageNet), CIFAR-LT (from CIFAR), and Places-LT (from Places)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700577383670,
                "cdate": 1700577383670,
                "tmdate": 1700577383670,
                "mdate": 1700577383670,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HVtlxjH93o",
                "forum": "rJKlmCpOQ7",
                "replyto": "TCn822jSec",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_JtYi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_JtYi"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thanks for your efforts in the discussion period. Some of my concerns have been addressed.\n\n* However, I am still unconvinced by the argument that MTL is more suitable than MDL. I agree that either may be practically used but MDL still seems more intuitive. As per the author response, there is a task conflict when the model relies on spurious correlations, which is what MDL also tries to solve. For example, in a setup with two domains: day and night images, the spurious correlation is time of day and the model may rely on that to make the prediction. Then, it is the domain that is changing and not the task itself, the task of classification stays the same.\n\nOverall, I update my rating to \"6: marginally above acceptance threshold\"."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700708659137,
                "cdate": 1700708659137,
                "tmdate": 1700708688337,
                "mdate": 1700708688337,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Be2VlNHKNG",
            "forum": "rJKlmCpOQ7",
            "replyto": "rJKlmCpOQ7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_4jDT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_4jDT"
            ],
            "content": {
                "summary": {
                    "value": "The paper effectively highlights the challenge of training models on biased datasets and the potential pitfalls of spurious correlations. The proposed method based on multi-task learning (MTL) is an innovative approach to addressing the problem of multiple biases in training data. This introduces a new perspective on debiased training. The introduction of a new real-image dataset, MultiCelebA, is a valuable contribution. It allows for evaluation under more realistic and challenging scenarios compared to existing synthetic-image datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Application of multitask learning in the context of multiple shortcuts is a novel idea.\n2.  MultiCelebA dataset can be instrumental for future research on evaluating shortcut learning algorithms."
                },
                "weaknesses": {
                    "value": "Limitation:\n1. No related works on shortcuts. Relevant literature can be found in\nDiscover and Cure: Concept-aware Mitigation of Spurious Correlation Wu et al. ICML 2023.\n\n2. The paper is not easy to follow. The writing could have been better.\n\n3. No code, so limited reproducibility.\n\n4. The major issue with the approach is knowing so many different subgroups a priori. In a more challenging setting, it is almost impossible to know all possible different subgroups beforehand to design the training strategy. I would like see an experiment where out of 3 subgroups the authors include two in their training, leaving one unidentified and how their method performs.\n\n5. There is a recent notion of difficulty in shortcuts. For example, some shortcuts are easy to learn, and some are difficult to learn. If the authors are using different subgroups to design multitask losses, the losses should be weighted corresponding to the shorcut difficulty. For example, a hard shortcut loss will be penalized less than an easy shortcut loss, as the mode is more prone to latching on the easy shotcut. The paper on shortcut difficulty is as follows:\nBeyond Distribution Shift: Spurious Features Through the Lens of Training Dynamics. Murali et al. TMLR 2023.\n\nThis setting will be more realistic.\n\n6. The dataset MultiCelebA is good for evaluation, but I would like to see a more realistic dataset like NIH-chesttube in the shortcut paper in #5.\n\n7. Also, with multiple groups involved in the multitask loss, the overall performance may drop.\n\n8. This is related to #4. All the possible groups may not be a shortcut. In this regard, can the shortcut discovery be aligned with the notion of slice discovery (ex DOMINO) to detect if really a spurious correlation going on before applying their method? This is a nice-to-have comment. I request the authors to think about this as a future work.\n\n\n**Post rebuttal**\n\nThanks for the response. I agree about point 5 and 6 but request the authors to think about it. I would like to thank the authors for  considering the point 4 and would like to give a score of 7. Unfortunately, I cant assign that so i would keep my score."
                },
                "questions": {
                    "value": "See the weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1800/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1800/Reviewer_4jDT",
                        "ICLR.cc/2024/Conference/Submission1800/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1800/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698796770447,
            "cdate": 1698796770447,
            "tmdate": 1700890509380,
            "mdate": 1700890509380,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5d5UgwZLL5",
                "forum": "rJKlmCpOQ7",
                "replyto": "Be2VlNHKNG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer 4jDT (1/2)"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your insightful feedback and valuable suggestions that helped improve our paper substantially. All the suggestions will be incorporated and additional experiments will be added to the main text and the supplementary. Please find our detailed responses to the comments below.\n____\n>**[Weakness 1] No related works on shortcuts. Relevant literature can be found in Discover and Cure: Concept-aware Mitigation of Spurious Correlation Wu et al. ICML 2023.**\n\nWe appreciate your thoughtful comments. We will refer to them as soon as possible.\n____\n>**[Weakness 2] The paper is not easy to follow. The writing could have been better.**\n\nWe have made revisions in line with comments from other reviewers. If there are any aspects that remain unclear or if you have any additional questions, please let us know. \n____\n>**[Weakness 3] No code, so limited reproducibility.**\n\nIn camera ready, we are committed to making our code publicly available. We understand the importance of transparency and community access in research, and we will ensure to adhere to these principles.\n____\n>**[Weakness 4] The major issue with the approach is knowing so many different subgroups a priori. In a more challenging setting, it is almost impossible to know all possible different subgroups beforehand to design the training strategy. I would like see an experiment where out of 3 subgroups the authors include two in their training, leaving one unidentified and how their method performs.**\n\nThank you for your constructive suggestion! We have added a new experimental setting in which only \u2018Gender\u2019 and \u2018Age\u2019 labels are visible during training on the three biases setting of MultiCelebA . As shown in Table R2 and Table A7, our method significantly outperforms existing methods. Interestingly, GroupDRO and upweighting, all of which utilize bias labels, are outperformed by LfF, a debiasing algorithm that does not use bias labels. These results indicate that our method could be effective in mitigating not only known biases but also unknown biases. \n\n**[Table R2] Performance in Unbiased, Worst, and InDist (%) on MultiCelebA in three biases for evaluation two biases for training setting. We mark the best and the second-best performance in bold and underline, respectively.**\n| Method | Unbiased | Worst | InDist | \n|----------|----------|----------|----------|\n|   ERM |  $64.1_{\\pm \\text{0.6}}$  |  12.0$_{\\pm \\text{1.2}}$  |  **96.7**$_{\\pm \\text{0.2}}$ | \n|   LfF  | $71.7_{\\pm \\text{0.6}}$  |  $47.7_{\\pm \\text{5.5}}$  |  $81.2_{\\pm \\text{2.9}}$ | \n|   Upsampling  |  $\\underline{74.1}_{\\pm \\text{1.7}}$  |  48.9$_{\\pm \\text{2.0}}$  |  84.1$_{\\pm \\text{3.0}}$ | \n|   Upweighting  |  69.7$_{\\pm \\text{15.4}}$  |  42.2$_{\\pm \\text{24.0}}$  |  79.5$_{\\pm \\text{9.5}}$  | \n|   GroupDRO  | 73.7$_{\\pm \\text{0.7}}$  |  46.6$_{\\pm \\text{0.8}}$  |  83.4$_{\\pm \\text{0.6}}$ | \n|   LISA  | $75.6_{\\pm \\text{1.0}}$  |  $\\underline{52.2}_{\\pm \\text{2.0}}$  |  $\\underline{87.3}_{\\pm \\text{0.8}}$  | \n|   Ours  |  $\\textbf{78.1}_{\\pm \\text{0.6}}$  |  $\\textbf{58.0}_{\\pm \\text{5.4}}$  |  83.8$_{\\pm \\text{0.7}}$ | \n____\n>**[Weakness 5] There is a recent notion of difficulty in shortcuts. If the authors are using different subgroups to design multitask losses, the losses should be weighted corresponding to the shortcut difficulty. For example, a hard shortcut loss will be penalized less than an easy shortcut loss, as the mode is more prone to latching on the easy shortcut.**\n\nAccording to the ICLR 2024 Reviewer Guidelines, the paper by Murali et al., published one month after our submission date, is considered concurrent work. We sincerely appreciate your diligence in bringing this to our attention and will revise the draft to discuss the paper and compare our method with it. To clarify, Murali et al. categorize spurious correlation as either benign or harmful, while our goal is to eliminate \u2018shortcuts\u2019 stemming from easy-to-learn spurious correlations. We empirically demonstrated that the bias types in MultiCelebA are such easy-to-learn spurious correlations, as shown in Section A.3.\n____\n>**[Weakness 6] This setting will be more realistic: The dataset MultiCelebA is good for evaluation, but I would like to see a more realistic dataset like NIH-chesttube in the shortcut paper in [Weakness 5].**\n\nThank you for your suggestion! However, the metrics used for evaluating models on the NIH-chesttube benchmark differ from those commonly used to evaluate debiasing methods, which makes direct comparisons of debiasing methods on this benchmark challenging. Currently, it is difficult to complete the experiment immediately due to the lack of time, but we aim to include it in the camera-ready if it is completed in time."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700546178075,
                "cdate": 1700546178075,
                "tmdate": 1700546178075,
                "mdate": 1700546178075,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LGmhgb50ZM",
            "forum": "rJKlmCpOQ7",
            "replyto": "rJKlmCpOQ7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_juPf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_juPf"
            ],
            "content": {
                "summary": {
                    "value": "This paper points out the challenge of training an unbiased and accurate machine learning model using a biased dataset containing multiple biases, which lead to undesirable shortcuts during training. Connecting this problem to a multi-task learning problem, this work proposes a novel debiased training algorithm. In particular, the method optimizes both the weights and model parameters by training a single model for all tasks with a weighted sum of task-specific losses. Also, they built a new real-image multi-bias dataset (MultiCelebA) for this problem. that divide the training data into several groups based on the effects of biases on the model and define each task in MTL as solving the target problem for each group."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This paper associates multiple biases issue in a biased dataset with a multi-task learning problem.\n- The proposed new multi-bias dataset for debiased training is crucial for this area.\n- Extensive experiments demonstrate the superiority of the proposed method.\n- The paper is well-written and easy to understand."
                },
                "weaknesses": {
                    "value": "- The relationship between multiple biases issue and multi-task learning is intriguing. However, the absence of comparisons with traditional multi-task learning (MTL) methods raises a question. If traditional MTL methods can also effectively optimize the problem, it would strengthen the connection between multiple biases issue and multi-task learning."
                },
                "questions": {
                    "value": "- GradNorm [1] also adopts the gradient of loss weight to optimize the loss weight. Could you please discuss the relation and the difference between your algorithm and GradNorm? In addition, GradNorm is an important reference for this paper.\n- Could you please conduct additional comparisons with traditional MTL methods to solidify the connection between multiple biases issue and multi-task learning?\n\n[1] Chen et al. GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks. In ICML 2018."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1800/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1800/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1800/Reviewer_juPf"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1800/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812120446,
            "cdate": 1698812120446,
            "tmdate": 1699636109369,
            "mdate": 1699636109369,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OLgSLK0SCo",
                "forum": "rJKlmCpOQ7",
                "replyto": "LGmhgb50ZM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer juPf"
                    },
                    "comment": {
                        "value": "We sincerely appreciate your insightful feedback and constructive suggestions that helped improve our paper substantially. All the suggestions will be incorporated, and additional discussions will be added to the main text. Please find our detailed responses to the comments below.\n___\n>**[Weakness 1]  The relationship between multiple bias issue and multi-task learning is intriguing. However, the absence of comparisons with traditional multi-task learning (MTL) methods raises a question. If traditional MTL methods can also effectively optimize the problem, it would strengthen the connection between multiple biases issue and multi-task learning.**\n\nThank you for your valuable comments! As you mentioned, the application of an existing MOO/MTL method along with our grouping policy showed improved performance compared to not adjusting group weights, as shown in Table 5, which strengthened the connection between multiple biases and MTL/MOO. However, the methods fall short of the desired level of unbiased performance. This highlights the superiority of our method in scenarios involving multiple spurious correlations.\nSpecifically, in response to your comment, we have included the results of GradNorm in Table 5, as well as in the subsequent Table R1. GradNorm adjusts group weights based on a specific criteria, namely the inverse training rate. However, it has been known that reweighting task losses based on specific criteria can lead to instability [1], as demonstrated by the high standard deviation in Table W1. GradNorm improved the performance on bias-guiding samples, but it showed lower performance on bias-conflicting samples, even compared with that of (i) No adjusting grouping weights. Therefore, under our grouping policy, finding Pareto optimal with MOO is effective in training an unbiased model. \n\n**[Table R1] Comparison among different strategies for adjusting $\\alpha$**\n|  | GG | GC | CG | CC | Unbiased | Worst | InDist |\n |----------|----------|----------|----------|----------|----------|----------|----------|\n| (i) No adjusting group weights | 79.6$_{\\pm \\text{2.9}}$ | 80.0$_{\\pm \\text{2.2}}$ | 79.0$_{\\pm \\text{1.9}}$ | 78.4$_{\\pm \\text{1.3}}$ | 79.2$_{\\pm \\text{1.4}}$ | 70.8$_{\\pm \\text{2.7}}$ | 78.5$_{\\pm \\text{5.7}}$ | \n| (ii) MGDA | 81.6$_{\\pm \\text{3.5}}$ | 85.1$_{\\pm \\text{2.1}}$ | 80.1$_{\\pm \\text{1.3}}$ | 82.3$_{\\pm \\text{3.2}}$ | 82.3$_{\\pm \\text{0.4}}$ | 73.9$_{\\pm \\text{0.2}}$ | 82.7$_{\\pm \\text{3.7}}$ | \n| (iii) GradNorm | **85.9**$_{\\pm \\text{5.8}}$ | **86.9**$_{\\pm \\text{2.4}}$ | 78.1$_{\\pm \\text{3.5}}$ | 76.6$_{\\pm \\text{6.5}}$ | 81.9$_{\\pm \\text{0.6}}$ | 70.9$_{\\pm \\text{4.9}}$ | **86.5**$_{\\pm \\text{5.4}}$ |\n| (iv) MoCo | 81.7$_{\\pm \\text{1.3}}$ | 81.8$_{\\pm \\text{2.6}}$ | 77.2$_{\\pm \\text{0.9}}$ | 74.9$_{\\pm \\text{1.2}}$ | 78.9$_{\\pm \\text{1.5}}$ | 72.1$_{\\pm \\text{2.7}}$ | 83.8$_{\\pm \\text{1.6}}$ | \n| (v) Ours | 82.4$_{\\pm \\text{0.9}}$ | 85.1$_{\\pm \\text{0.4}}$ | **81.7**$_{\\pm \\text{0.4}}$ | **82.6**$_{\\pm \\text{1.0}}$ | **82.9**$_{\\pm \\text{0.2}}$ | **77.9**$_{\\pm \\text{0.2}}$ | 84.3$_{\\pm \\text{0.9}}$ |\n\n[1] Fernando, Heshan, Han Shen, Miao Liu, Subhajit Chaudhury, Keerthiram Murugesan, and Tianyi Chen. \u201cMitigating Gradient Bias in Multi-Objective Learning: A Provably Convergent Stochastic Approach.\u201d ICLR 2023.\n___\n>**[Question 1] GradNorm [2] also adopts the gradient of loss weight to optimize the loss weight. Could you please discuss the relation and the difference between your algorithm and GradNorm? In addition, GradNorm is an important reference for this paper.**\n\nThank you for informing us! Our algorithm updates group weights by minimizing the weighted sum of group losses and the norm of the weighted sum of gradients to perform well on all groups, while GradNorm updates group weights towards inverse training rate so that different tasks train at similar rates. We will add GradNorm in our revised manuscript. \n\n[2] Chen, Zhao, Vijay Badrinarayanan, Chen-Yu Lee and Andrew Rabinovich. \u201cGradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks\u201d. ICML 2018.\n\n___\n>**[Question 2] Could you please conduct additional comparisons with traditional MTL methods to solidify the connection between multiple biases issue and multi-task learning?**\n\nPlease see our answer to [Weakness 1]."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700545916246,
                "cdate": 1700545916246,
                "tmdate": 1700545916246,
                "mdate": 1700545916246,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zCJYyPIs2l",
                "forum": "rJKlmCpOQ7",
                "replyto": "OLgSLK0SCo",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_juPf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_juPf"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer Response"
                    },
                    "comment": {
                        "value": "Thank you for your comprehensive response, which has effectively addressed my concerns. This work deserves a score of 7, but since our rating system does not include this option, I am unable to assign it. As I am not an expert in this area, I will maintain my original score."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679853143,
                "cdate": 1700679853143,
                "tmdate": 1700679853143,
                "mdate": 1700679853143,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "l53kVRbEPM",
            "forum": "rJKlmCpOQ7",
            "replyto": "rJKlmCpOQ7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_tCm5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_tCm5"
            ],
            "content": {
                "summary": {
                    "value": "The authors address the challenge of mitigating multiple spurious correlations. They introduce a novel dataset splitting method and construct a multi-task learning problem based on the split dataset. Their proposed algorithm identifies a Pareto-stationary parameter within this multi-task learning setup, which then becomes the model's resultant parameter. Additionally, they created the MultiCelebA dataset to benchmark the issue of multiple spurious correlations. Experimental results show that their method surpasses existing approaches in mitigating spurious correlations across three multi-bias and three single-bias datasets."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is articulate and well-structured, making it accessible to readers.\n\n2. The authors provide comprehensive experimental comparisons between their approach and existing methods. These results convincingly establish that the proposed method is superior in specific aspects, underscoring its advantages."
                },
                "weaknesses": {
                    "value": "1. The rationale behind the algorithm design remains ambiguous. Although the authors mention that a Pareto-stationary point with a flat loss landscape helps resolve between-group conflicts, the underlying logic is not evident. Rigorous definitions of spurious correlations and the conditions under which they are fully eliminated would benefit readers.\n\n2. The MultiCelebA dataset appears inadequate in distinguishing between spurious and non-spurious correlations. The authors have not elaborated on the dataset's construction, even in supplementary materials. Furthermore, while they label certain correlations between target attributes and specific attributes as spurious, the these correlations seem to compose of the spurious and non-spurious ones.  An isolated evaluation of spurious correlations is essential for gauging the efficacy of methods designed to counteract them. Thus, relying on experiments with the MultiCelebA dataset might be questionable.\n\n3. Tables 2-4 present diverse evaluation metrics, raising concerns about potential cherry-picking to favor the proposed method. Without including metrics both UNBIASED and WORST consistently, the experiments might come off as biased and not entirely objective.\n\n4. The credibility of evaluating spurious correlations using the MultiCelebA dataset is questionable, as mentioned above. While results derived from Multi-Color MNIST might be more reliable, the proposed method's minimum group-wise accuracy is lower than that of GroupDRO. This undermines the claim that the proposed method is superior to GroupDRO."
                },
                "questions": {
                    "value": "1. What underpins the expectation that the proposed method will effectively address multiple spurious correlations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1800/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698827513321,
            "cdate": 1698827513321,
            "tmdate": 1699636109293,
            "mdate": 1699636109293,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "32JalBQ6AK",
                "forum": "rJKlmCpOQ7",
                "replyto": "l53kVRbEPM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer tCm5 (1/2)"
                    },
                    "comment": {
                        "value": "Thank you for dedicating your time and expertise to review our manuscript. Your insights are invaluable to us. We will do our best to address all of them in the revision. Please find our responses to the comments below.\n___\n>**[Weakness 1-1] Rigorous definitions of spurious correlations and the conditions under which they are fully eliminated would benefit readers.**\n\nThank you for your comprehensive suggestion! We will revise our manuscript to include the following content to our paper. \n\nA spurious correlation is a statistical relationship between two variables that appears to be causally related but is actually due to a coincidence. Spurious correlations appear in a majority of training data, but not the majority in testing data. For example, in bird species classification, if most waterbird images in a dataset have water backgrounds, there exists a spurious correlation between waterbird and water backgrounds. A model trained with ERM may erroneously use the water background as a shortcut for classifying waterbirds, leading to misclassification of test waterbird images with no water backgrounds. The model that learns such shortcuts is referred to as a biased model. A biased model well classifies bias-guiding samples (i.e., samples that agree with the spurious correlations) but fails to correctly classify bias-conflicting samples (i.e., those disagreeing with the spurious correlations). On the contrary, when a model learns the target task while avoiding shortcuts, it learns a feature space free from spurious correlations while representing the target task. As a result, the model exhibits unbiased accuracy between bias-guiding samples and bias-conflicting samples.\n\n>**[Weakness 1-2] The rationale behind the algorithm design remains ambiguous. Although the authors mention that a Pareto-stationary point with a flat loss landscape helps resolve between-group conflicts, the underlying logic is not evident.**\n\nIn the presence of a biased training dataset, when a model relies on spurious correlations as shortcuts for target classification, it becomes a biased model. This biased model performs well when classifying bias-guiding samples but struggles with bias-conflicting samples. Our policy groups data according to their adherence to spurious correlations and defines each task for each of such groups so that, if a model is spuriously correlated with a bias type, tasks that adhere to the bias and those that do not adhere conflict with each other. These conflicts are analogous to task conflicts in MTL, and MOO has been adopted to resolve task conflicts of MTL. Following this, we proposed a new training objective based on MGDA, which is one of MOO methods, to relieve task conflicts by finding Pareto stationary which is a point where no further improvement can be made in any objective. In our scenarios, since all tasks aim to solve the same target classification, there in principle exists an optimal solution i.e., a feature space free from spurious correlations, and fits perfectly across all groups. Therefore optimization towards Pareto optimality with our grouping policy drives the model towards being unbiased.\n___\n>**[Weakness 2] The MultiCelebA dataset appears inadequate in distinguishing between spurious and non-spurious correlations. The authors have not elaborated on the dataset's construction, even in supplementary materials. Furthermore, while they label certain correlations between target attributes and specific attributes as spurious, these correlations seem to compose of the spurious and non-spurious ones. An isolated evaluation of spurious correlations is essential for gauging the efficacy of methods designed to counteract them. Thus, relying on experiments with the MultiCelebA dataset might be questionable.**\n\nWe would like to kindly note that Section A.3 and Figure A3 empirically demonstrated that the bias types in MultiCelebA are spuriously correlated to the target class, High Cheekbones. Additionally, Figure 2 and Table A1&A2 present statistics of MultiCelebA. If you have already reviewed these sections and find any aspect unclear or have specific concerns, we would greatly appreciate further clarification on which parts you found problematic."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700578976127,
                "cdate": 1700578976127,
                "tmdate": 1700578976127,
                "mdate": 1700578976127,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NsrSgo17WZ",
            "forum": "rJKlmCpOQ7",
            "replyto": "rJKlmCpOQ7",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_B9DR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1800/Reviewer_B9DR"
            ],
            "content": {
                "summary": {
                    "value": "This work addresses the problem of avoiding that models use _several_ biases (or spurious correlations) from the data to perform predictions, whereas previous work has focused in avoiding a _single_ bias. To this end, the authors relate the problem of debiasing a model with multitask learning (MTL) and proposed to group the dataset into different groups/tasks based on their proposed grouping criteria. Then, they propose to train the MTL model by introducing learnable convex task weights that are regularized to reduce the norm of the loss gradient. Finally, the authors introduce a dataset based on CelebA that contains multiple biases, and use it to compare their proposed approach with a number of previous methods. Moreover, the authors also compare their method in different single-bias experiments and ablate the different components of the proposed solution."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The problem of addressing several biases in the dataset (rather than a single one) is interesting, and a sensible middle-ground between single-bias settings and settings with no annotations.\n- The proposed approach to divide the dataset into groups is also pretty interesting and novel, to the best of my knowledge.\n- The paper is well-written and easy to follow.\n- The empirical results are quite positive, and they also shed light on the behaviour of existing methods when multiple biases are present in the data."
                },
                "weaknesses": {
                    "value": "- W1. While MultiCelebA is interesting and useful, selling it as a \"new dataset\" is too much of a stretch for my taste.\n- W2. Saying that this is the first work connecting \"unbiasing\" with MOO or MTL (which is quite freely interpreted) is arguable at best. First, one could argue that even importance-weighting approaches are already interpreting the problem as MOO, but there are even works such as FairGrad [4] that connect biases (this one, in the context of fairness, which does not necessarily imply data-imbalance) which adaptively scale gradients.\n- W3. Statements about MOO and Pareto Optimality in the manuscript makes me worry about whether the authors have fully understood these concepts. For example:\n  - I don't understand what it means to \"address spurious correlations based on a theory of MOO\".\n  - \"Finding _the_ Pareto-optimal parameter\". There are _many_ Pareto-optimal parameters.\n  - The goal is that \"performance should not be biased towards a certain group\". Pareto-optimality does not guarantee this. Indeed, MGDA is known to be biased towards tasks with low magnitudes. The concept the authors refer to is known as \"task impartiality\" in MTL (see, e.g., [1, 2]).\n  - Saying that MoCo is the SotA of MOO is quite a stretch to say the least.\n- W4. The arguments towards \"finding a flat optima\" are rather hand-wavy and unconvincing.\n- W5. Related with W3, it is quite unclear to me what makes the proposed method work at all:\n  - MGDA minimizes in each iteration the regularizer in Eq. 3, and it is biased towards dominated tasks (which is observed in Table 5). However, the proposed approach (which is an interpolation between ERM and MGDA, similar to CAGrad [3]) works well. Is it the interpolation? Or learning $\\alpha$ using along the parameters?\n  - It is rather intriguing that the grouping policy does not work well on its own. In principle, I don't see why the grouping and the training approach should not be independent.\n- W6. Experiments lack statistics like standard deviations, making the effectiveness of some design choices (e.g. the update frequency $U$) quite unclear.\n- W7. The results in UrbanCars are quite different from those that can be found in other works. Just as an example, the worst variant of ERM recorded in [Papers with code](https://paperswithcode.com/sota/out-of-distribution-generalization-on) has a gap of -15.4, while the one reported in the paper is of -69.2 (worse than any result of the PwC table). \n\n[1] Javaloy, A., & Valera, I. (2022). RotoGrad: Gradient Homogenization in Multitask Learning. ICLR.\n\n[2] Liu, L., Li, Y., Kuang, Z., Xue, J., Chen, Y., Yang, W., ... & Zhang, W. (2021). Towards impartial multi-task learning. ICLR.\n\n[3] Liu, Bo, et al. \"Conflict-averse gradient descent for multi-task learning.\" Advances in Neural Information Processing Systems 34 (2021): 18878-18890.\n\n[4] Maheshwari, G., & Perrot, M. (2022). Fairgrad: Fairness aware gradient descent. arXiv preprint arXiv:2206.10923."
                },
                "questions": {
                    "value": "-Q1. When using MGDA in Table 5, does it mean that $\\alpha$ is tuned as in Eq. 3 but only with the regularization? Or is $\\alpha$ fully solved in each iteration?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1800/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698835272626,
            "cdate": 1698835272626,
            "tmdate": 1699636109204,
            "mdate": 1699636109204,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5ugUtwbn5V",
                "forum": "rJKlmCpOQ7",
                "replyto": "NsrSgo17WZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for dedicating your time and expertise to review our manuscript. Your insights are invaluable to us. However, it appears that some aspects of the review may have been based on certain confusions regarding our methodology and experimental results. We are eager to address these points in the rebuttal, and will accordingly revise our paper for improving its clarity. \n___\n>**[Weakness 1] While MultiCelebA is interesting and useful, selling it as a \"new dataset\" is too much.**\n\nThank you for your constructive suggestion! In response to your comment, we have replaced \"new dataset\" with \"new benchmark\" in the manuscript. Despite this change, we still believe that, as a realistic and challenging benchmark, MultiCelebA will contribute substantially and promote future research in the field of debiased training. We also would like to highlight that reprocessed datasets/benchmarks like MultiCelebA have long been recognized by the community; examples include bFFHQ, a dataset for debiasing derived from FFHQ, and those for long-tailed classification such as ImageNet-LT (from ImageNet), CIFAR-LT (from CIFAR), and Places-LT (from Places).\n___\n\n>**[Weakness 2] Saying that this is the first work connecting \"unbiasing\" with MOO or MTL is arguable. One could argue that even importance-weighting approaches (ex. FairGrad) are already interpreting the problem as MOO.**\n\nThank you for your valuable and insightful feedback! We recognize the widespread use of reweighting methods like GroupDRO in the field. It is important to note that none of such prior work, including GroupDRO, explicitly relates their frameworks with MOO/MTL. However, our work explicitly frames debiasing from a perspective of MOO for the first time, which enables us to develop a new and effective algorithm based on recent advances in MOO. Our algorithm substantially outperformed standard reweighting techniques, and we believe its outstanding performance highlights the impact of viewing debiasing through a lens of MOO explicitly. \n\nRegarding FairGrad (TMLR 2023): According to the ICLR 2024 Reviewer Guidelines, FairGrad, published one month before our submission date, is considered as concurrent work. However, we sincerely appreciate your diligence in bringing this to our attention, and have revised the draft to discuss the paper and compare our method with it. Moreover, we would like to clarify that FairGrad focuses on grouping based on sensitive labels for fairness, a notable distinction from our work that aims to remove spurious correlations by MOO. Despite the existence of FairGrad, we thus assert that our paper is still the first to introduce MOO for mitigating spurious correlations. \n___\n\n>**[Weakness 3-1]  I don't understand what it means to \"Finding the Pareto-optimal parameter\" and \"address spurious correlations based on a theory of MOO\". There are many Pareto-optimal parameters. And, Pareto-optimality does not guarantee that not being biased towards a certain group.**\n\nThank you for your perceptive observation. You correctly note that, in typical MTL settings, Pareto optimality does not necessarily guarantee unbiased performance across groups: there is a trade-off between tasks in terms of performance due to the conflicts between them (i.e., different tasks have different goals), and consequently a Pareto optimal model may be biased towards a certain task. However, in our setting, since tasks share exactly the same objective, a single model that works for all the tasks exists in principle (i.e., a model free from spurious correlations); \u201cthe\u201d Pareto optimal parameter indicates such a single, ideal model in our paper. We will clarify this in the draft soon!\n\n>**[Weakness 3-2] MGDA is known to be biased towards tasks with low magnitudes.**\n\nMGDA tends to be biased towards tasks with low magnitudes as commented, and such a behavior is in fact beneficial for our framework. We first would like to note that, as demonstrated in Section A.2, our grouping strategy and group-wise loss result in the minority group (CC) with significantly low loss magnitude. This is mainly because (1) all the groups contribute to training equally, regardless of their population, through the group-wise loss, and (2) it is easy to reduce the loss for the minority group due to the low complexity of its data distribution. Hence, MGDA allows our algorithm to focus more on the minority group (with low loss magnitudes) during training and consequently resolve the data imbalance issue between the groups.\n\n>**[Weakness 3-3] Saying that MoCo is the SOTA of MOO is quite a stretch.**\n\nWe agree, and have revised the draft to refer to MoCo as \"the latest technique for MOO\" instead."
                    },
                    "title": {
                        "value": "Response to the Reviewer B9DR (1/4)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700149687314,
                "cdate": 1700149687314,
                "tmdate": 1700151473485,
                "mdate": 1700151473485,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ogbbKZ2uCm",
                "forum": "rJKlmCpOQ7",
                "replyto": "NsrSgo17WZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">**[Weakness 4] The arguments towards \"finding a flat optima\" are rather hand-wavy and unconvincing.**\n\nThis statement does not imply that a flat minima leads to an unbiased model. Our intention in the paper was that the second term in Eq. (3), which is originally introduced to achieve Pareto stationarity, can be also interpreted as an approximate curvature of the loss, according to previous work [1]. \nTo be specific, the trace norm of hessian tr(H) is known to represent loss curvature, and the trace norm of the empirical Fisher information $tr(F)=\\mathbb{E}\\left[\\left\\lVert \\boldsymbol{\\alpha}^{\\top}(\\nabla L(\\theta))\\right\\rVert_2^2\\right]$, which is equivalent to the second term in Eq. (3), approximates $tr(H)$ [2, 3]. Therefore, minimizing the second term in Eq. (3) encourages to find a flat optima. Also, such a flat optima has been known to improve models\u2019 generalization capability [1, 4, 5, 6]. \nTo further understand the impact of the term on the loss curvature, **we have included a new ablation study in Section A.7.** The experimental results suggest that a higher weight on this term leads to a smaller loss curvature in the model parameter space.\n\n[1] Xian Li and Hongyu Gong. Robust optimization for multilingual translation with imbalanced data. In Proc. Neural Information Processing Systems (NeurIPS), volume 34, 2021.\n\n[2] Stanislaw Jastrzebski, Devansh Arpit, Oliver Astrand, Giancarlo Kerg, Huan Wang, Caiming Xiong, Richard Socher, Kyunghyun Cho, and Krzysztof Geras. Catastrophic \ufb01sher explosion: Early phase \ufb01sher matrix impacts generalization. arXiv preprint arXiv:2012.14193, 2020.\n\n[3] Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian, Danxiang Zhu, Hao Tian, and Hua Wu. Ernie: Enhanced representation through knowledge integration. arXiv preprint arXiv:1904.09223, 2019.\n\n[4] Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Pe- ter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. In Proc. International Conference on Learning Representations (ICLR), 2017.\n\n[5] Gintare Karolina Dziugaite and Daniel M Roy. Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data. arXiv preprint arXiv:1703.11008, 2017.\n\n[6] Yiding Jiang, Behnam Neyshabur, Hossein Mobahi, Dilip Krishnan, and Samy Bengio. Fantastic generalization measures and where to find them. In Proc. International Conference on Learning Representations (ICLR), 2020."
                    },
                    "title": {
                        "value": "Response to the Reviewer B9DR (2/4)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150247667,
                "cdate": 1700150247667,
                "tmdate": 1700151482156,
                "mdate": 1700151482156,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RxKwp8t63x",
                "forum": "rJKlmCpOQ7",
                "replyto": "NsrSgo17WZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the Reviewer B9DR (3/4)"
                    },
                    "comment": {
                        "value": ">**[Weakness 5-1] MGDA minimizes in each iteration the regularizer in Eq. 3, and it is biased towards dominated tasks (which is observed in Table 5). However, the proposed approach works well.**\n\nFirst of all, we would like to correct potential misunderstandings: The records of MGDA in Table 5 suggest that it works well for the minority task (CC) **but not for the dominant task (GG)**. Please note that G and C indicate whether a group includes bias-guiding or bias-conflicting samples for each bias type, respectively, as defined in Section 5.1. This is also discussed in our answer to [Weakness 3-2]. \n\n>**[Weakness 5-2] Is the proposed method an interpolation between ERM and MGDA, similar to CaGrad? Or learning $\\alpha$ using the parameter?**\n\nOur objective is not an interpolation between ERM and MGDA since both the first and the second terms of Eq. (3) involve $\\alpha$. Furthermore, $\\alpha$ is not a scalar weight but a learnable vector, enabling dynamic adjustment of group-wise importance during training. This is a significant departure from CAGrad, which employs a constant $c$ for interpolation of ERM and MGDA. Please check out Algorithm 1 in the paper, which clearly illustrates how our method utilizes $\\alpha$ in a fundamentally different way from interpolation.\n\n>**[Weakness 5-3] It is rather intriguing that the grouping policy does not work well on its own. Why should the grouping and the training approach not be independent?**\n\nWe would like to emphasize that our grouping policy is not designed to operate independently. Its purpose is dedicated to facilitating the effectiveness of our training algorithm in mitigating spurious correlations. Our policy groups data according to their adherence to spurious correlations and defines each task for each of such groups so that, if a model is spuriously correlated with a bias type, tasks that adhere to the bias and those that do not adhere conflict with each other. Then mitigating such conflicts by MOO resolves the spurious correlations and leads to an unbiased model consequently. Therefore, the grouping policy and the training strategy are inherently interconnected in our algorithm, each playing a vital role in addressing spurious correlations, as empirically demonstrated in Table 5 and 6 of the paper.\n\n>**[Weakness 5-4] It is unclear what makes the proposed method work.**\n\nThe key ideas in our method involve framing the mitigation of spurious correlation as MTL and adapting MOO for debiasing. Specifically, due to the following reason, achieving Pareto optimality under our grouping policy aligns that the model learns a feature space free from spurious correlations. \n1. There is an optimal solution that fits perfectly across all groups since they all share the same objective. (Please see our answer to [Weakness 3-1].)\n2. If a model falls into shortcuts during training, the model\u2019s performance will be reduced on certain groups, which deviates from Pareto optimality in the context of our grouping policy. \n3. Hence, optimization towards Pareto optimality with our grouping policy drives the model towards being unbiased."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700150372965,
                "cdate": 1700150372965,
                "tmdate": 1700228334057,
                "mdate": 1700228334057,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Dg2wmcqdjy",
                "forum": "rJKlmCpOQ7",
                "replyto": "ryr13K1GxY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_B9DR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_B9DR"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors, thanks for the detailed rebuttal, and excuse me for the late reply. A few points to follow up from your response:\n\n**[Weakness 5-1 and 5-4]** I still believe the term Pareto-optimality is not fully clear: it does not give any guarantee of the ones claimed in the manuscript and rebuttal. One solution could perfectly fit a group while completely neglecting another, and it would still be Pareto optimal. Indeed, any point in the Pareto front (which can go from balanced solutions to unbalanced ones) is Pareto optimal.\n\n**[Weakness 5-1]** Thanks for the clarification, there were no misunderstanding. I said dominated tasks (CC), not dominating tasks (GG). The answer **[Weakness 3-2]** rather clarified this point and **[Weakness 5-3]**.\n\n**[Weakness 5-2]** I still do believe your method to tune $\\alpha$ is an interpolation between solving ERM (first term) and MGDA (second term), controlled by $\\lambda$ (instead of $c$ in CAGrad). \n\n**[Question 1]** Good, all clear. However, this detail should also be clarified in the manuscript, as MGDA solves the optimization problem in each iteration."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700508282403,
                "cdate": 1700508282403,
                "tmdate": 1700508282403,
                "mdate": 1700508282403,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rh5EsaDJ5s",
                "forum": "rJKlmCpOQ7",
                "replyto": "NsrSgo17WZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for your response! Based on your comments, we will add the details in the manuscript and address remaining concerns below. We hope this response effectively resolves the remaining concerns.\n___\n>**[Weakness 5-2] I still do believe your method to tune $\\alpha$ is an interpolation between solving ERM (first term) and MGDA (second term), controlled by $\\lambda$ (instead of c in CAGrad).**\n\nFirstly, we would like to clarify that the first term in Eq. (3) is not the ERM but rather the weighted sum of group-wise losses. In contrast to conventional multi-task scenarios that compute all task losses from a single input, we group the dataset and calculate a task (group) loss within the group to which the input belongs. Therefore, the sum of group-wise losses is not equivalent to ERM in our grouping. ERM is a special case of the first term when $\\alpha_i$ is proportional to the number of samples in the $i$-th group since the number of samples varies in each group. The first term becomes ERM on MultiCelebA when $\\alpha_i$ is $\\frac{\\text{the number of samples in } i\\text{-th group}}{\\text{the number of samples in the training set}}$. However, since $\\alpha$ is initialized as $[\\frac{1}{(\\text{the number of groups)}}, \u2026, \\frac{1}{(\\text{the number of groups)}}]$ and dynamically updated to minimize Eq. (3), the first term is hardly considered as ERM.\n\nFurthermore, we update $\\alpha$ by minimizing interpolation with **a learnable parameter** $\\lambda$ between **the weighted sum of group-wise losses** and MGDA. The weighted sum of group-wise losses serves as a prior for increasing the group weight of the CC group, as detailed in Section A.2. As training progresses and the $\\lambda$ increases, this prior intensifies in the early stages of training, and the impact of MGDA gradually strengthens. \n\nWe would like to note that CAGrad updates model parameters by minimizing the interpolation between ERM and MGDA, whereas our algorithm minimizes the weighted sum of group-wise losses without MGDA for updating model parameters. \n\n___\n>**[Weakness 3-1 and 5-4] I still believe the term Pareto-optimality is not fully clear: it does not give any guarantee of the ones claimed in the manuscript and rebuttal. One solution could perfectly fit a group while completely neglecting another, and it would still be Pareto optimal. Indeed, any point in the Pareto front (which can go from balanced solutions to unbalanced ones) is Pareto optimal.**\n\nWe would like to illustrate this concept with an example. Assume that the task is to classify images in MultiCelebA as either having high cheekbones or not. We categorize the dataset into groups using our grouping policy. All groups have the common training objective of classifying images based on high cheekbones. When considering training a group, the solution space for groups with bias-guiding images can be broader than that of the bias-conflicting groups because they can exploit the spurious correlations to solve the task. The simple example is as follows:\n\n$\\text{Solution}\\_{GG}=${$ \\theta_{\\text{high cheekbones}}, \\theta_{\\text{gender}}, \\theta_{\\text{age}}$}\n\n$\\text{Solution}\\_{GC}=${$\\theta_{\\text{high cheekbones}}, \\theta_{\\text{gender}}$}\n\n$\\text{Solution}\\_{CG}=${$\\theta_{\\text{high cheekbones}}, \\theta_{\\text{age}}$}\n\n$\\text{Solution}\\_{CC}=${$\\theta_{\\text{high cheekbones}}$}\n\nIn this example, $\\theta\\_{\\text{high cheekbones}}$ is the optimal solution that performs well on all groups. $ \\theta_{\\text{gender}}$ or $\\theta_{\\text{age}}$ (i.e., the solutions that perfectly fit a group while completely neglecting the other) are not a Pareto optimal because while they decrease the group-wise losses only for bias-guiding groups and increase the group losses for bias-conflicting groups, there exists a better solution $\\theta\\_{\\text{high cheekbones}}$ that decreases the groups losses for all groups. \n___\n>**[Weakness 5-1], [Question 1]**\n\nThank you! We will add the details in the manuscript."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580211489,
                "cdate": 1700580211489,
                "tmdate": 1700637810146,
                "mdate": 1700637810146,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "crUD4x24zL",
                "forum": "rJKlmCpOQ7",
                "replyto": "rh5EsaDJ5s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_B9DR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_B9DR"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors, thanks for your answer, but I am afraid they did not address my concerns. Namely:\n\n**[Weakness 3-1 and 5-4]** Of course, those solutions are not Pareto-optimal because there exists another one that dominates them. But that is all under the hypothesis in your example that there exists a solution that dominates all of them, which is _far_ from the spirit of multi-objective optimization. In MOO, there are plenty of Pareto-optimal solutions (those points not Pareto-dominated by any other) which form the Pareto front. If your assumption is that the Pareto front of your model is composed of a _single_ point (i.e., your model can fit all the losses perfectly), this should be stated clearly from the very first page. Now:\n  - If this is the case, then _any_ linear combination of losses (static or dynamic) will yield that one optimum if the optimization works properly (since the hyperplane composed by the task weights always intersects with the same point in the Pareto front, see e.g. Boyd's book).\n  - If that is not the case, then there exists many Pareto optima that yield different trade-off solutions between the groups, and the balanced solution you seek is just one of them.\n\nThanks again for the response."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646432656,
                "cdate": 1700646432656,
                "tmdate": 1700646432656,
                "mdate": 1700646432656,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "furK7iSn9f",
                "forum": "rJKlmCpOQ7",
                "replyto": "NsrSgo17WZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Finally, we sincerely thank you for your dedication and providing generous suggestions and comments until the end of the author-reviewer discussion period. They are indeed of great help that improves our work substantially!"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739392822,
                "cdate": 1700739392822,
                "tmdate": 1700739464660,
                "mdate": 1700739464660,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "b9w6hk4Plz",
                "forum": "rJKlmCpOQ7",
                "replyto": "furK7iSn9f",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_B9DR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1800/Reviewer_B9DR"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\nI am glad that my comments are of help, and that we have arrived to an agreement of the underlying assumptions in the manuscript.\n\nI am going to keep my score, and I will let the AC weigh my review when making a decision. \n\nThe main reason I keep my score is that the argument of the paper after the rebuttal have shifted from MOO (as traditionally understood), to the training dynamics of a MOO problem which has a single Pareto-optimal point (which could sound not too multi-objective). This is a fundamentally different (and interesting!) topic, but far from the one discussed in the paper, as now we are talking about optimization issues, and not about choosing an optimum point of a vector-valued loss.\n\nAgain, whether to accept or reject the paper comes down to how much importance one gives to these details, and I am glad of having a fruitful discussion with you."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1800/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740275882,
                "cdate": 1700740275882,
                "tmdate": 1700740275882,
                "mdate": 1700740275882,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]