[
    {
        "title": "Don't forget private retrieval: distributed private similarity search for large language models"
    },
    {
        "review": {
            "id": "vvQ7cBJrLQ",
            "forum": "JTcaziw7G1",
            "replyto": "JTcaziw7G1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6214/Reviewer_zJDJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6214/Reviewer_zJDJ"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors present a privacy-preserving similarity search system for large language models. Their design aims to address the privacy issue when LLM-based systems want to involve external information in the current generation process. The authors consider a scenario where the user sends queries to LLM and the LLM asks for several external server to supply extra information when generating the response. During this process, the proposed design aims to protect both users\u2019 queries and external servers\u2019 data privacy against the LLM owner. To achieve this goal, the authors proposed to use the Shamir\u2019s shares, which guarantees the data privacy in an honest majority setting. The authors leverage a series of primitives based on the Shamir\u2019s shares to compute and retrieve the top-k similarity results from an indexed database without revealing any information to compromised servers. The authors test their design with both synthetic and real-world dataset to demonstrate their system\u2019s performance for exact and approximate queries."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tAddress the privacy issue in the LLM augment generation process.\n2.\tThe design provides security guarantees for both users and external information supplier."
                },
                "weaknesses": {
                    "value": "1.\tThe design is ad-hoc, just combining existing protocols together without design efforts.\n2.\tThe approximate search design in Sec 2.5 may lead to the leakage of centroids, which is not well-elaborated.\n3.\tThe design is very slow and impractical."
                },
                "questions": {
                    "value": "1.\tIt seems that such design can also be implemented with other linear secret sharing schemes, why do you choose to use the Shamir\u2019s shares (instead of arithmetic secret shares, replicated secret shares, etc.)?\n\n2.\tThe authors claim that it is possible to use perturbations to mitigate the leakage in the approximate search design, but it is unclear what the suitable parameters is for this noise.\n\n3.\tAlso, it is unclear the security level after adding the noise, a proof sketch is required to understand whether the countermeasure is effectively addressing the leakage.\n\n4.\tThe proposed scheme becomes very slow (at least 50s needed) when the database size goes to a million scale, but such database is quite common in the real-world. This renders the impracticality of proposed design.\n\n5.\tEven if we take the approximate design into consideration, it is still slow with a large k, I am wondering whether a large k is also common in the real-world systems because the LLM may want to embed more external resources to produce a general response for queries."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698646909427,
            "cdate": 1698646909427,
            "tmdate": 1699636677872,
            "mdate": 1699636677872,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "bdQ1S3jZoi",
            "forum": "JTcaziw7G1",
            "replyto": "JTcaziw7G1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6214/Reviewer_LqCL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6214/Reviewer_LqCL"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces PRAG, which uses multi-party computation to secure the privacy of vector search. The proposed method transmits queries to a distributed set of servers containing a privately constructed database, from which it gets the approximate top-k documents. The paper is mainly about data privacy. It is more suitable to be discussed in the security or database communities."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper focuses on the data privacy of dense retrieval, which is a critical in practice. The multi-party computation is a meaningful method to tackle this problem."
                },
                "weaknesses": {
                    "value": "This paper is entitled \"distributed private similarity search for language language models\". However, it literally has nothing to do large language models. Besides, the paper is neither about other seemingly related topics, like dense retrieval or text representation. The paper should be re-directed to other venues in security or database communities, which is more appropriate to justify its technical value."
                },
                "questions": {
                    "value": "Please check the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698655939245,
            "cdate": 1698655939245,
            "tmdate": 1699636677759,
            "mdate": 1699636677759,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "oDOoqK9Zsw",
            "forum": "JTcaziw7G1",
            "replyto": "JTcaziw7G1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6214/Reviewer_Ut5B"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6214/Reviewer_Ut5B"
            ],
            "content": {
                "summary": {
                    "value": "The work studies the problem of private data retrieval for use in LLMs.\nSpecifically, it extends retrieval augmented generation techniques to the distributed setting where the data is assumed to be sensitive and secret shared among several servers, and the query is also secret shared.\nThis problem is essentially an application of $k$-NN in MPC.\nThe authors provide a number of solutions. The first is an exact top-$k$ computation using an off-the-shelf secure dot product protocol to compute the score, followed by an off-the-shelf argmax protocol.\nThe second solution uses IVF (a clustering-based technique) to reduce the runtime by only searching in specific clusters.\nFinally, the fastest version uses IVF but leaks the centroid of the closest cluster."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Very well-written paper, clear and easy to understand writing.\n- An interesting new problem of protecting the privacy of retrieval in LLMs.\n- While the solutions are not too novel regarding the MPC protocols they use, they present a nice variety of trade-offs in terms of runtime and privacy."
                },
                "weaknesses": {
                    "value": "## Pre-computation Assumptions\nThe paper makes a number of bold assumptions about pre-computation:\n- They assume to compute the cosine similarity that the data is normalized beforehand. If this normalization is only within each data point, that could be okay, but if the whole dataset is normalized, this would need to be done in MPC and adds non-trivial overhead.\n- Similarly, the clustering for IVF would be a significant overhead in MPC that is ignored in the paper.\n\n\n## Output privacy\nI am concerned that, like federated learning, this technique gives a false sense of security. The paper mentions that their approach makes it possible to utilize private data for inferences. However, the privacy of the output of the MPC protocol is not considered. There needs to be at least some discussion of the threat of the output of the protocol leaking information about 1) which query was made and 2) the private data retrieved.\n\n\n## Evaluation\n- This paper is missing a lot of the rigour typically found in papers about MPC protocols. For example, there is no security proof or formal description of certain parts of the protocol.\n\n- There is also no evaluation under network delay. Network delay is a realistic bottleneck of MPC that would drastically affect the runtimes in the evaluation section. \n\n## Minor comments\n- Is it realistic to consider $d$ a constant?\n- Could some citations be added to 2.2.3?\n- Some extra details on which truncation protocol was used would be helpful."
                },
                "questions": {
                    "value": "Can the authors respond to the issues highlighted above?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6214/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6214/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6214/Reviewer_Ut5B"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698674020637,
            "cdate": 1698674020637,
            "tmdate": 1699636677622,
            "mdate": 1699636677622,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "OWypBdaFDp",
            "forum": "JTcaziw7G1",
            "replyto": "JTcaziw7G1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6214/Reviewer_Hhh4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6214/Reviewer_Hhh4"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a secure information retrieval method to provide retrieval augmented generation for large language models. It is an MPC-friendly inverted file approximate search protocol."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper proposes an interesting question of secure distributed retrieval augmentation for LLM, and introduces a framework that takes into account both query privacy and database privacy."
                },
                "weaknesses": {
                    "value": "1. The experiment section does not provide a detailed introduction of the dataset, as well as the experimental settings.\n2. There is a lack of comparative experiments under non-MPC settings to demonstrate the performance of the paper's method.\n3. In the experiment section, the paper provides only a brief explanation of the F1 score results without presenting a complete table under different experimental settings.\n4. The experiment section does not address the impact of retrieval augmentation on the performance of the Large Language Models.\n5. The description of the analysis of computational complexity and communication complexity could be more detailed and standardized.\n6. The full name of the abbreviation \"IR\" is not provided when it is first introduced."
                },
                "questions": {
                    "value": "1. This paper is about secure similarity search for LLM, but it still seems to approach it from an information retrieval perspective. Please explain the relevance of the approach described in this paper to LLM.\n2. Regarding risks, the paper appears to lack in-depth analysis. For example, would there be risks of model inversion attack under the scenario of multiple servers?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6214/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6214/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6214/Reviewer_Hhh4"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6214/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698837965778,
            "cdate": 1698837965778,
            "tmdate": 1699636677482,
            "mdate": 1699636677482,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]