[
    {
        "title": "Adapting Large Language Models via Reading Comprehension"
    },
    {
        "review": {
            "id": "RchCyvLhNR",
            "forum": "y886UXPEZ0",
            "replyto": "y886UXPEZ0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2192/Reviewer_pD3t"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2192/Reviewer_pD3t"
            ],
            "content": {
                "summary": {
                    "value": "The paper reveals that domain-specific pre-training greatly reduces LLMs'  prompting ability. The authors introduce a method to transform raw texts into comprehension tasks, aiming to enhance LLM's domain knowledge without sacrificing prompting skills. Experiment results show their 7B model is competitive with larger models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Interesting observation: Pre-training on domain-specific datasets leads to a decline in LLM's prompting ability.\n2. The proposed idea is straightforward, simple, and has the potential for broad applicability with clear motivation.\n3. Experimental findings indicate that domain-specific reading comprehension texts enhance the model's performance."
                },
                "weaknesses": {
                    "value": "1. The novelty seems somewhat constrained, especially regarding the idea of incorporating reading comprehension tasks during the pre-training phase, which appears similar to the following paper:\nRECKONING: Reasoning through Dynamic Knowledge Encoding. \n2. The authors conducted experiments only on the 7B model. It's uncertain whether consistent results would be observed on larger-scale models, and it's unclear if the proposed method is effective on models after RLHF. (However, I think this weakness doesn't undermine the contribution.)"
                },
                "questions": {
                    "value": "I'm confused why pre-training on domain-specific knowledge leads to a decrease in LLM's prompting ability. Could you clarify?\nEspecially in the explanation, does the term 'input-output patterns' pertain to limited data patterns or is it referring to something else?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2192/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2192/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2192/Reviewer_pD3t"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2192/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727833040,
            "cdate": 1698727833040,
            "tmdate": 1699636153115,
            "mdate": 1699636153115,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AYmj3YgtZh",
                "forum": "y886UXPEZ0",
                "replyto": "RchCyvLhNR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer pD3t"
                    },
                    "comment": {
                        "value": "Thank you for recognizing the interesting observations in our paper and acknowledging the effectiveness of our method. In response to your questions regarding the comparison with RECKONING [1], other models, and the decrease in prompting ability, we provide the following analysis.\n\n### Q1: Comparison with RECKONING [1]\nThank you for providing such a valuable reference. Below is a comparison between our work with RECKONING, and we have incorporated RECKONING into our paper.\n\nRECKONING enhances reasoning ability by incorporating contextual knowledge into the model's parameters before exposing it to a question at inference time. If we view the model's learning from contextual knowledge as the \"reading\" process and the model's predicting on the question as the \"comprehension\" process, the overall RECKONING process can be viewed as a form of reading comprehension.\n\nHowever, our reading comprehension differs from RECKONING in many aspects:\n\n- The most obvious difference lies in the goal: RECKONING enhances reasoning ability, while we improve domain expertise. \n- Another difference is the timing of model parameter updates: RECKONING performs these updates at inference time, whereas we perform updates during the pre-training stage.\n- Moreover, if I understand it correctly, RECKONING learns contextual knowledge specifically for ad-hoc single or multiple related questions (the number of knowledge-related questions is set up to 18 in the experiment), while we learn domain-specific knowledge for various downstream tasks.\n\n### Q2: Uncertain whether consistent results would be observed on larger-scale models and models after RLHF.\nMany thanks to your inspirational suggestion! Please see the General Response where **we conduct experiments on a larger model---LLaMA-13B**. Moreover, we find our reading comprehension is well-suited to the data format of **the model after RLHF, contributing to significant gains!**\n\n### Q3: Why pre-training on domain-specific knowledge leads to a decrease in LLM's prompting ability. Does the term 'input-output patterns' pertain to limited data patterns?\n\nThanks again for your insightful advice! Your explanation of the term \"input-output patterns\" is right, it relates to limited data patterns in the domain-specific raw corpora.\n\nHowever, we'd like to clarify that it is not the domain-specific knowledge that hurts the prompting ability for question answering; instead, **it is the limitation of data patterns within the domain-specific raw corpora that impacts this ability**. We provide an analysis on the data patterns of domain-specific corpora below, and this analysis has also been included in our paper.\n\n**Domain-Specific Corpora Have Fewer QAs than General Corpora.**\nWe conduct a case study on the question answering pattern. Specifically, we search over all three domain-specific corpora and a representative corpora in the general domain---RedPajama [2]---to estimate how many sentence pairs follow the question-answering pattern, utilizing this mining pattern:\n\n```text\n{What|Who|When|Where|Why|Which|How}{SENT1}? {SENT2}\n```\nThe following table lists the number of tokens belonging to the mined question-answering pairs per million tokens. Compared with the general corpora, domain-specific corpora have much lower rates of data following the question-answering pattern, which could lead to the observed decrease in question-answering ability.\n\n|Pre-train Corpora | BioMed | Law | Finance | General (RedPajama) |\n|---------------------------------|--------|-----|---------|----------------------|\n| # QA tokens  | 22.5   | 0.8 | 236.8   | **490.26**           |\n\n\n### References:\n\n[1] Zeming Chen et al. RECKONING: reasoning through dynamic knowledge encoding. CoRR, abs/2305.06349, 2023.\n\n[2] Together Computer. Redpajama: an open dataset for training large language models, 2023."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2192/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581970744,
                "cdate": 1700581970744,
                "tmdate": 1700583115395,
                "mdate": 1700583115395,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aemorleVkC",
            "forum": "y886UXPEZ0",
            "replyto": "y886UXPEZ0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2192/Reviewer_qcCv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2192/Reviewer_qcCv"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to adapting LLMs via reading comprehension for QA. The authors conduct extensive experiments on various QA datasets. The results show the effectiveness of the proposed method. The paper is well written and the solution is clear."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The authors conduct extensive experiments on various QA datasets. The results show the effectiveness of the proposed method.\n2.  The paper is well written and the solution is clear."
                },
                "weaknesses": {
                    "value": "1. I download the Supplementary Material and find that there are many missing files, such as codes and the full data sets. \n2. The implemtation details are not clear, such as GPU and memory size and  the parameters."
                },
                "questions": {
                    "value": "1. I download the Supplementary Material and find that there are many missing files, such as codes and the full data sets. \n2. The implemtation details are not clear, such as GPU and memory size and  the parameters."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2192/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698758217393,
            "cdate": 1698758217393,
            "tmdate": 1699636153033,
            "mdate": 1699636153033,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kUtIl7Cy79",
                "forum": "y886UXPEZ0",
                "replyto": "aemorleVkC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qcCv"
                    },
                    "comment": {
                        "value": "Thank you very much for your great appreciation of our work! Below, we provide clarifications on the supplementary materials and implementation details.\n\n### Q1: More Supplementary Materials\nThank you for the feedback on our supplementary material. In the original supplementary material, we included the code for transferring raw texts to reading comprehension texts, and the evaluation datasets. To address your concerns, **we provide more code and data through this [anonymous link](https://anonymous.4open.science/r/anonymous_supp).**\n\n### Q2: Implementation Details\nWe appreciate your feedback. The implementation details, including the use of 32 V100-32GB GPUs, were presented in Appendix B. To enhance accessibility for readers, **we have incorporated more explicit descriptions in the main body of our paper**, making it easier for the readers to locate the implementation details."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2192/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700581214854,
                "cdate": 1700581214854,
                "tmdate": 1700581214854,
                "mdate": 1700581214854,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wUDKm35EYA",
            "forum": "y886UXPEZ0",
            "replyto": "y886UXPEZ0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2192/Reviewer_aRRU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2192/Reviewer_aRRU"
            ],
            "content": {
                "summary": {
                    "value": "The paper focuses on the investigating domain-adaptation pretraining method for LLMs, where they continued training on domain-specific corpora and found the approach hurts the LLMs' prompting ability. Thus, the author proposes to convert the corpora into reading comprehension texts to preserve the prompting performance. The experiments show the effectiveness of the method in three different domains (biomedicine, law, and finance)."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- The proposed prompts are very effective, as showed with a significant zero-shot performance improvement across 3 domains, and the 7B model used in the experiment can outperform larger models (50B).\n- The paper is well-written. The author puts a comprehensive details on the experiments and analysis."
                },
                "weaknesses": {
                    "value": "- Some ablation studies are essential to understand the effectiveness of the components (e.g., how the verbalizer affects the performance)\n- The baselines are not comparable to the results reported by the authors. E.g., GPT-J 6B. It will be great to have the AdaptLLM result on top of the baselines wherever the models are publicly available."
                },
                "questions": {
                    "value": "- How did you choose the set of strings for the verbalizer?\n- Are there any analyses or findings on why the model performance improvement on domain \"law\" is the least? \n- Does the approach benefit another type of models? e.g., encoder-decoder model? or other decoder-only models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2192/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801197443,
            "cdate": 1698801197443,
            "tmdate": 1699636152958,
            "mdate": 1699636152958,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nsHojbALWF",
                "forum": "y886UXPEZ0",
                "replyto": "wUDKm35EYA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aRRU (Part 1)"
                    },
                    "comment": {
                        "value": "Many thanks for your appreciation of our soundness and contribution! We hope the following analysis can address your questions about the verbalizer, baseline, law domain improvement, and another type of model.\n\n### Q1: How did you choose the verbalizer? How the verbalizer affects the performance?\nThanks for your in-depth suggestion, we conduct the following analysis.\n\n**Verbalizer Selection:**\nOur choice of verbalizers for the Natural Language Inference (NLI) task type aligns with [1], where the effectiveness has been verified. Then, we observe that the entailment relationship in NLI can be extended to other task types like Commonsense Reasoning and Paraphrase Detection. In Table 3 in our paper, you may observe that the verbalizers for NLI are also applied to Commonsense Reasoning and Paraphrase Detection. Finally, we complement verbalizers for the remaining task types based on commonsense; for example, a verbalizer like \"is defined as\" can be commonly accepted to connect a concept with its definition.\n\n\n**Verbalizer Effect:**\nIntuitively, our hypothesis is that **a greater diversity of verbalizers leads to a broader range of comprehension tasks, ultimately enhancing performance**. To test this hypothesis, we conduct an ablation by preserving only one verbalizer for each task type. Specifically, we preserve only the first verbalizer in each row in Table 3, and remake the reading comprehension data to observe the effect.\n\nFirst, **the most direct impact is that the number of mined task examples decreases**. When using all the verbalizers (All Verbal), we mine an average of 2.1 examples per text, while using one verbalizer (Single Verbal) results in 1.4 examples per text.\n\n\n|                                | All Verbal | Single Verbal |\n|--------------------------------|--------------------------|-----------------------------|\n| # Mined examples per text | **2.1**                     | 1.4                         |\n\nNext, we conduct an experiment to train the general model using the new data, and the task results are as follows: \n\n|          | All Verbal | Single Verbal |\n|----------|:------------------------:|:---------------------------:|\n| Average Score  | **44.3**                 | 42.7                        |\n\nThese results demonstrate that with fewer verbalizers, the downstream task performance declines, verifying that **including more verbalizers can contribute to better performance**.\n\n### Q2: The baselines are not comparable to the results reported by the authors. E.g., GPT-J 6B. It will be great to have the AdaptLLM result on top of the baselines wherever the models are publicly available.\n\nWe included GPT-J-6B as one baseline to facilitate a comparison with LexGPT-6B, which was trained from GPT-J-6B, and LexGPT-6B was the only publicly available large language model in the English-language law domain when we submitted our paper. To address your concern, we conduct experiments on GPT-J-6B and our method shows a positive average score compared to GPT-J-6B:\n\n|                 | GPT-J-6B | LexGPT-6B | AdaptLLM-6B |\n|-----------------|:--------:|:---------:|:-----------:|\n| SCOTUS-mic-F1   | 15.9     | 16.9      | 18.8        |\n| SCOTUS-mac-F1   | 13.6     | 7.7       | 20.1        |\n| CaseHOLD-mic-F1 | 34.9     | 27.0      | 34.7        |\n| CaseHOLD-mac-F1 | 34.9     | 27.0      | 34.7        |\n| UNFAIR-ToS      | 79.8     | 81.9      | 80.0        |\n| AVERAGE         | 35.9     | 32.1      | **37.7**    |\n\nConsidering that you may also be curious about our comparison with another baseline, MedAlpaca-13B, which is trained from LLaMA-13B, we conduct experiments on LLaMA-13B and observe favorable results.\n\n|          | LLaMA-13B | MedAlpaca-13B | AdaptLLM-13B |\n|----------|:---------:|:-------------:|:------------:|\n| PubMedQA |   59.6    |     60.7      |   62.5   |\n| ChemProt |   42.8    |     38.4      |   44.4   |\n| MQP      |   49.3    |     57.4      |   72.8   |\n| RCT      |  56.7 |     51.3      |     54.4     |\n| USMLE    |   34.7    |    39.0   |     34.6     |\n| AVERAGE  |   48.6    |     49.4      |   **53.7**   |\n\n\nWe've updated Table 4 in our paper, so now that we can achieve the great goal to **have the AdaptLLM result on top of the baselines wherever the models are publicly available**!\n\n(continue in part 2)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2192/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580211523,
                "cdate": 1700580211523,
                "tmdate": 1700581520849,
                "mdate": 1700581520849,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "h1QXhqqoyg",
                "forum": "y886UXPEZ0",
                "replyto": "wUDKm35EYA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aRRU (Part 2)"
                    },
                    "comment": {
                        "value": "### Q3: Why the performance improvement on domain \"law\" is the least?\n\nThanks for your careful review, but actually we do not have a very definitive explanation for this phenomenon. By comparing pre-training data in the three domains, we infer that the **low readability of law pre-training corpora** might be the reason:\n\n- Biomedicine---PubMed Abstract [2]: Each text is an abstract for a research paper, which means the text should be highly clear, concise and readable. A randomly sampled example is as follows:\n\n```text\nPattern-recognition receptors: signaling pathways and dysregulation in canine chronic enteropathies-brief review.\nPattern-recognition receptors (PRRs) are expressed by innate immune cells and recognize pathogen-associated molecular patterns (PAMPs) as well as endogenous damage-associated molecular pattern (DAMP) molecules. With a large potential for synergism or convergence between their signaling pathways, PRRs orchestrate a complex interplay of cellular mediators and transcription factors, and thus play a central role in homeostasis and host defense. Aberrant activation of PRR signaling, mutations of the receptors and/or their downstream signaling molecules, and/or DAMP/PAMP complex-mediated receptor signaling can potentially lead to chronic auto-inflammatory diseases or development of cancer. PRR signaling pathways appear to also present an interesting new avenue for the modulation of inflammatory responses and to serve as potential novel therapeutic targets. Evidence for a dysregulation of the PRR toll-like receptor (TLR)2, TLR4, TLR5, and TLR9, nucleotide-binding oligomerization domain-containing protein (NOD)2, and the receptor of advanced glycation end products (RAGE) exists in dogs with chronic enteropathies. We describe the TLR, NOD2, and RAGE signaling pathways and evaluate the current veterinary literature-in comparison to human medicine-to determine the role of TLRs, NOD2, and RAGE in canine chronic enteropathies.\n```\n\n- Finance---Stock News: We collect stock news using the codebase of FinGPT [3], which could ensure the data quality. A randomly sampled example is as follows:\n\n```text\nChevron, Johnson & Johnson share gains lead Dow's 100-point jump\nPowered by strong returns for shares of Chevron and Johnson & Johnson, the Dow Jones Industrial Average is up Wednesday morning. Shares of Chevron CVX, -2.35% and Johnson & Johnson JNJ, -0.13% are contributing to the blue-chip gauge's intraday rally, as the Dow DJIA, -1.01% is trading 105 points higher (0.3%). Chevron's shares have climbed $3.84, or 2.4%, while those of Johnson & Johnson are up $2.85, or 1.8%, combining for an approximately 44-point boost for the Dow. Merck MRK, -0.25%, Apple Inc. AAPL,, and Intel INTC, -1.95% are also contributing significantly to the gain. A $1 move in any one of the 30 components of the benchmark equates to a 6.59-point swing. Editor's Note: This story was auto-generated by Automated Insights, an automation technology provider, using data from Dow Jones and FactSet. See our market data terms of use.\n```\n\n- Law\u2014--FreeLaw Opinions [2]: Each text is a legal opinion from federal and state courts, documenting many oral snippets. In contrast, the corpora in the other domains mainly consist of written passages. We infer that the unique feature of incorporating spoken language may affect the overall readability of law corpora. A randomly sampled example is as follows (with certain portions omitted and presented as (...)). We can observe that the readability of law corpora appears to be lower than that of the other two domains. \n\n\n```text\n92 P.3d 294 (2004)                                                                                                                                \n2004 WY 71                                                                                                                                        \nSTATE of Wyoming, ex rel., WYOMING WORKERS' SAFETY AND COMPENSATION DIVISION, Appellant (Petitioner),                                             \nv.                                                                                                                                                \nAnthony N. SAVICKI, Appellee (Respondent).                                                                                                        \n(...)\nWe have previously entertained the Division's dissatisfaction with our failure to consider subsequent wage increases based upon merit and said this:\n(...)\n[\u00b6 16] Conner rejected the notion that an employee may be penalized by wage increases earned for merit at a later time. We reiterate that the pivotal question is whether the employee's injury has caused a loss of earning capacity and, if so, whether a comparison of the pre-injury wage to the post-injury wage offered is compensable under the applicable statute. In this case, Savicki's post-injury wage is compensable, and the order awarding benefits is affirmed.\n```\n\n(continue in part 3)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2192/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580501501,
                "cdate": 1700580501501,
                "tmdate": 1700581577583,
                "mdate": 1700581577583,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MhJUd9SXii",
                "forum": "y886UXPEZ0",
                "replyto": "wUDKm35EYA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aRRU (Part 3)"
                    },
                    "comment": {
                        "value": "### Q4: Does the approach benefit another type of models?\n\nThank you for the insightful suggestion. As shown in the General Response above, **we add experiments on another type of model---Pythia [4]---and demonstrate positive effects of our method!**\n\n### References:\n\n[1] Mozes van de Kar et al. Don\u2019t prompt, search! mining- based zero-shot learning with language models. In EMNLP, Association for Computational Linguistics, 2022.\n\n[2] Leo Gao et all. The pile: An 800gb dataset of diverse text for language modeling. CoRR, abs/2101.00027, 2021.\n\n[3] Hongyang Yang et all. Fingpt: Open-source financial large language models. CoRR, abs/2306.06031, 2023.\n\n[4] Stella Biderman et al. Pythia: A suite for analyzing large language models across training and scaling. In ICML, volume 202 of Proceedings of Machine Learning Research, PMLR, 2023."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2192/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580882604,
                "cdate": 1700580882604,
                "tmdate": 1700581621673,
                "mdate": 1700581621673,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "aH9NAcSiXe",
            "forum": "y886UXPEZ0",
            "replyto": "y886UXPEZ0",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2192/Reviewer_Cte9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2192/Reviewer_Cte9"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces an approach for continuing the pretraining of Large Language Models (LLMs) on domain-specific corpora. Initially, the authors find that conventional domain-adaptive pretraining enhances knowledge probing while detrimentally affecting the model's prompting ability. Subsequently, they propose transforming domain-specific documents into a reading-comprehension style format. In this format, certain sentences are altered via mining patterns to pose NLP tasks such as summarization and commonsense reasoning, accompanied by their respective answers. The experiments, spanning the biomedical, finance, and law domains, demonstrate that the proposed approach yields marginal improvements in the performance of LLMs on domain-specific tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed approach is straightforward yet effective in enhancing performance on domain-specific tasks, which has potential applicability to other models and domains.\n- The experiments include three representative domains and six mining tasks, which may have sufficient coverage in terms of domains and tasks.\n- The paper is well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "- In Table 4, the performance improvements appear marginal to me (3% in biomedicine, 4.8% in finance, and 4.3% in law). I am uncertain whether the benefits gained from using the proposed approach justify the effort required to transform corpora into reading comprehension texts.\n- The authors only use the LLaMA 7B model for verifying their proposed method. It remains unclear whether the approach is similarly effective for smaller and larger models."
                },
                "questions": {
                    "value": "- Texts in corpora may possess their own document structure, and mining NLP tasks could potentially disrupt it, impacting readability and coherence. Have the authors manually verified whether their transformation is effective without compromising the integrity of the text?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2192/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698840959461,
            "cdate": 1698840959461,
            "tmdate": 1699636152878,
            "mdate": 1699636152878,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KzDIoUi4ep",
                "forum": "y886UXPEZ0",
                "replyto": "aH9NAcSiXe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2192/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Cte9"
                    },
                    "comment": {
                        "value": "Thanks for your positive attitude! We hope the following analysis can address your concerns about performance improvement, effectiveness for smaller and larger models, and integrity of transformation.\n\n### Q1: Whether the performance improvements are significant.\n**Demonstrating an average improvement on our evaluation benchmarks is challenging** because the diversity of tasks within each domain requires consistent gains across multiple tasks.\n\nAs shown below, in the biomedicine domain, MedAlpaca-7B, trained on diverse domain-specific data, exhibits significant improvements on certain tasks (e.g., 7.6% on ChemProt and 2.2% on USMLE). However, the improvements are not consistent across other tasks, resulting in an average improvement of 0.9%, whereas we achieve 3.1%. This trend is also noticeable in LLaMA-13B, where MedAlpaca-13B outperforms the LLaMA-13B by 0.8% on average, while we achieve a 5.1% absolute gain.\n\n|                                      | LLaMA-7B    |           |          | LLaMA-13B   |           |          |\n|--------------------------------------|-------------|-----------|----------|-------------|-----------|----------|\n|                                      | General LLM-7B | MedAlpaca-7B | AdaptLLM-7B | General LLM-13B | MedAlpaca13B |AdaptLLM-13B* |\n| PubMedQA | 59.6        | 58.6      | 63.3     | 59.6        | 60.7      | 62.5     |\n| ChemProt | 31.4        | 39.0      | 35.2     | 42.8        | 38.4      | 44.4     |\n| MQP      | 50.7        | 50.7      | 54.4     | 49.3        | 57.4      | 72.8     |\n| RCT      | 45.1        | 40.8      | 50.4     | 56.7        | 51.3      | 54.4     |\n| USMLE    | 34.5        | 36.7      | 33.1     | 34.7        | 39.0      | 34.6     |\n| AVERAGE                              | 44.2        | 45.1      | 47.3     | 48.6        | 49.4      | 53.7     |\n| **Absolute gain w.r.t. General LLM** | /           | +0.9      | **+3.1** | /           | +0.8      | **+5.1** |\n\n(* AdaptLLM-13B is trained from LLaMA-13B using our method) \n\nIn the law domain, LexGPT outperforms its base model GPT-J on one task but does not exhibit the same trend on other tasks, resulting in less favorable average performance. In finance, our average improvement enables us to compete with BloombergGPT-50B.\n\n### Q2: Whether the approach is similarly effective for smaller and larger models.\nThanks for your helpful suggestion, please refer to the General Response above to see that **our approach remains effective for smaller and larger models!**\n\n### Q3: Have the authors manually verified whether their transformation is effective without compromising the integrity of the text?\n\n**Yes! We have manually checked the transformed texts** before the training process. First, in the mining stage, our strategy is based on [1], where the authors have verified the reliability of the mining strategy. Besides, we have made some simple but effective modifications, such as requiring longer sentence lengths and avoiding the newline character `\\n`, to ensure data quality. Second, in the transformation stage where the data is converted into reading comprehension, each transformation template has been manually checked.\n\nTo further address your concerns, we sample 200 reading comprehension texts from each domain and **manually evaluate the readability and coherence. The results indicate high satisfaction**:\n\n|                           | BioMed. | Finance | Law    |\n|---------------------------|---------|---------|--------|\n| Quality of Transformation | 95.8  | 89.0  | 86.5 |\n\n### Reference:\n\n[1] Mozes van de Kar et al. Don\u2019t prompt, search! mining-based zero-shot learning with language models. In EMNLP, Association for Computational Linguistics, 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2192/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700580041102,
                "cdate": 1700580041102,
                "tmdate": 1700581349291,
                "mdate": 1700581349291,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]