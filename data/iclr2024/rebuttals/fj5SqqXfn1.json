[
    {
        "title": "Avoiding Pitfalls for Privacy Accounting of Subsampled Mechanisms under Composition"
    },
    {
        "review": {
            "id": "FfCHDWnsNh",
            "forum": "fj5SqqXfn1",
            "replyto": "fj5SqqXfn1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses potential pitfalls when using so called numerical privacy accounting to compute the $(\\varepsilon,\\delta)$-guarantees for compositions of DP algorithms. Especially, the paper focuses on two points (citations from the paper):\n\na) \"some privacy accountants assume that the privacy guarantees for the composition of a subsampled mechanism are determined by self-composing the worst-case datasets for the uncomposed mechanism\" \n\nand \n\nb) \"Poisson subsampling is sometimes assumed to have similar privacy guarantees compared to sampling without replacement.\"\n\n\nSome background: Using the R\u00e9nyi divergence has been a popular way of analysing compositions of DP mechanisms since the works of Abadi et al. (2016) and Mironov (2017), especially due to the tightness of the RDP accounting compared to purely analytical approaches. So called numerical accounting and was proposed in works by Sommer et al. (2019), Koskela et al. (2020) and Gopi et al. (2021). It directly approximates the hockey-stick divergence and often gives tighter bounds than the RDP approach which incurs a small loss when converting the RDP parameters to $(\\varepsilon,\\delta)$-bounds. Zhu et al. (AISTATS 2022, https://proceedings.mlr.press/v151/zhu22c/zhu22c.pdf) set the hockey-stick divergence based methods on a more rigorous footing by introducing the concept of dominating pairs of distributions. This also allows obtaining rigorous $(\\varepsilon,\\delta)$-bounds for adaptive compositions of DP mechanisms."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Generally well-written paper and a timely topic. The auditing methods are getting all the time more accurate at estimating the $\\varepsilon$-values, so it would be good to get the accurate computing of the formal guarantees right. It seems there are still no clear subsampling amplification result in the literature for, e.g., carrying out accounting using the dominating pairs of distributions in case of substitution neighbourhood relation of datasets (related to the \u201csecond pitfall\u201d), so it makes sense to consider this problem."
                },
                "weaknesses": {
                    "value": "All in all, I think the contribution of the paper is very limited. And I think the paper is outdated in a sense that neither of the mentioned issues are actually pitfalls in numerical accounting (explained below). \n\nAbout the pitfalls:\n\nThe point a) was addressed by the work of Zhu et al. (2022) which considers the dominating pairs of distributions. As the authors point out, generally there are no neighboring datasets $X$ and $Y$ such that the $(\\varepsilon,\\delta)$-bound for pairs of outcomes $\\big(\\mathcal{M}(X),\\mathcal{M}(Y)\\big)$ would be $(\\varepsilon,\\delta)$-bounds for all neighboring datasets. Outside of the mechanisms that use additive Gaussian noise, there are numerous such examples. Consider, e.g., the exponential mechanism, for which obtaining accurate $(\\varepsilon,\\delta)$-bounds is very tedious:\n\nDong, J., Durfee, D., & Rogers, R. (2020, November). Optimal differential privacy composition for exponential mechanisms. In International Conference on Machine Learning (pp. 2597-2606). PMLR.\n\nThe issue that you don't have a worst-case pair of datasets is exactly what the definition of the dominating pairs of distribution addresses. Also, Zhu et al. (2022) also show that a tightly dominating pair distributions always exists for a given mechanism.\n\nFor the pitfall b) I agree that the claim that the pair of distributions $P = q \\cdot \\mathcal{N}(1,\\sigma^2) + (1-q) \\cdot \\mathcal{N}(0,\\sigma^2)$, $Q = q \\cdot \\mathcal{N}(-1,\\sigma^2) + (1-q) \\cdot \\mathcal{N}(0,\\sigma^2)$ gives a dominating pair of distributions in case of subsampling without replacement and substitute neighbourhood relation of datasets is not correct. I believe it is true for the Poisson subsampling in case of substitute neighbourhood relation of datasets, I think you can show this as in case of the R\u00e9nyi divergence and use the analysis for the Poisson subsampling and add/remove neighborhood relation of datasets, which is given in\n\nMironov, I., Talwar, K., & Zhang, L. (2019). R\\'enyi differential privacy of the sampled gaussian mechanism. arXiv preprint arXiv:1908.10530.\n\nThe correct bound for hockey-stick divergence in the case of subsampling without replacement and substitute neighbourhood relation of datasets is given in Proposition 30 by Zhu et al. (2022). So, as far as I see, this problem is solved, and in the most well-known software libraries that use numerical accounting and dominating pairs of distributions, namely the \"autodp\" by Wang et al. and \"PRV accountant\" by Gopi et al., Opacus and Google DP library, correct formulas are used.\n\nI think that the claim that \"Poisson subsampling is sometimes assumed to have similar privacy guarantees compared to sampling without replacement\" is not true in that Proposition 30 by Zhu et al. (2022) gives bounds for both. And they are of the same form, but in of them the pair $(P,Q)$ is a dominating pair under the add/remove relation and in the other one under the substitute relation, so it is clear that the latter leads to higher $\\varepsilon$-values. The bounds are in two parts and one can determine a numerical dominating pair of distributions using, e.g, methods by\n\nDoroshenko, V., Ghazi, B., Kamath, P., Kumar, R., & Manurangsi, P. (2022). Connect the Dots: Tighter Discrete Approximations of Privacy Loss Distributions. Proceedings on Privacy Enhancing Technologies, 4, 552-570."
                },
                "questions": {
                    "value": "- What is special about the hockey stick divergence when thinking about the worst-case pairs of datasets and worst-case pairs of distributions? All the potential problems w.r.t. to finding the worst-case pair of distributions for the hockey-stick divergence would be problems for RDP accounting (or when using other $f$-divergences than the $\\alpha$-divergence) as well, right? Commonly the worst-case pairs of distributions are 1-dimensional and can be seen as some sort of general post-processing of the outcomes from neighboring datasets, and then the worst-case distributions for the hockey-stick divergence would similarly be worst-case distributions for other $f$-divergences and for the R\u00e9nyi divergence as they satisfy the data-processing inequality.\n\n- Comment: it would be interesting to see some new results related to this topic, e.g., on how would the analytically expressed pair of dominating distributions look like under the subsampling amplification (in all cases) as the bounds of Proposition 30 by Zhu et al. (2022) (which you also cite) are given in two parts."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698769408064,
            "cdate": 1698769408064,
            "tmdate": 1699636679980,
            "mdate": 1699636679980,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CzDZUgWn6t",
                "forum": "fj5SqqXfn1",
                "replyto": "FfCHDWnsNh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6226/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your thorough review.\n\n> The point a) was addressed by the work of Zhu et al. (2022)...\n\nThe intent of our example was not to show that some mechanisms do not have worst-case datasets. As you point out there are many such mechanisms. Our example with the Laplace mechanism simply shows that even a simple mechanism that has a worst-case pair of datasets might not have a worst-case pair of datasets under subsampling and composition. We will make this point more explicit in the paper. As for whether or not this is still a pitfall for privacy accountants please see our response below.\n\n> The correct bound for hockey-stick divergence in the case of subsampling without replacement and substitute neighbourhood relation of datasets is given in Proposition 30 by Zhu et al. (2022). So, as far as I see, this problem is solved, and in the most well-known software libraries that use numerical accounting and dominating pairs of distributions, namely the \"autodp\" by Wang et al. and \"PRV accountant\" by Gopi et al., Opacus and Google DP library, correct formulas are used.\n\nProposition 30 gives the upper bound of the hockey-stick divergence for a single iteration. However, it is not a dominating pair of distributions since the order of the pair differs between alpha below or above 1. In Section 7 we show that the pair of datasets considered in Proposition 30 is not sufficient to give tight bounds under composition for general mechanisms. You are correct that Zhu et al. give a construction of a dominating pair of distributions in Corollary 32. However, there is no implementation of this construction to the best of our knowledge. \nRegarding implementations of accountants for the subsampled Gaussian mechanism: the \u201cPRV accountant\u201d/Opacus (and PLD Accountant) only computes the \u201cremove\u201d relation. The \u201cautodp\u201d and Google DP library correctly computes both the \u201cadd\u201d and \u201cremove\u201d relations and takes the point-wise maximum, as in Theorem 11 of Zhu et al. As mentioned in our response to Reviewer LTUo we conjecture that in the case of the Gaussian mechanism, it is sufficient to consider the \u201cremove\u201d datasets for subsampling without replacement under the substitution relation. However, we are not aware of any proof and therefore we disagree with the claim that this problem is solved.\n\n> ...the claim that \"Poisson subsampling is sometimes assumed to have similar privacy guarantees compared to sampling without replacement\" is not true\u2026\n\nWe agree that this claim is too strong as is and should be rephrased. The privacy parameters are not assumed to be identical. However, the privacy parameters are sometimes assumed to be close as is the case between the add/remove and substitution neighboring relations. We base this claim on the fact that accountants for Poisson subsampling are often used when it is not the implemented sampling scheme. \n\n> What is special about the hockey stick divergence\u2026?\n\nThe RDP accountant computes the RDP guarantees of a single iteration for a given order and then applies the RDP composition theorem. Due to the privacy scaling under the RDP composition theorem, it is sufficient to find the worst-case datasets for only a single iteration when using the RDP accountant. One could use a similar approach for hockey-stick divergence by computing a single (\u03b5, \u03b4)-DP guarantee and applying the advanced composition theorem. However, (\u03b5, \u03b4)-DP guarantees do not compose as well as the RDP guarantee. Therefore, the problem of determining the worst-case datasets under composition only seems to arise for exact accountants."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700329040313,
                "cdate": 1700329040313,
                "tmdate": 1700329040313,
                "mdate": 1700329040313,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xsxZPHT1Ch",
                "forum": "fj5SqqXfn1",
                "replyto": "FfCHDWnsNh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the reply.\n\n> Our example with the Laplace mechanism simply shows that even a simple mechanism that has a worst-case pair of datasets might not have a worst-case pair of datasets under subsampling and composition. \n\nI still don't fully understand why would one want to find the worst-case pair of datasets. I think it is clear that one has to consider a bound that holds for all pairs of datasets.\n\n> You are correct that Zhu et al. give a construction of a dominating pair of distributions in Corollary 32. However, there is no implementation of this construction to the best of our knowledge.\n\nSuch a construction can also be found in \"Doroshenko et al. (2022). Connect the Dots: Tighter Discrete Approximations of Privacy Loss Distributions. Proceedings on Privacy Enhancing Technologies.\" and it is a fairly simple algorithm. But I agree this should be addressed more thoroughly.\n\n> Regarding implementations of accountants for the subsampled Gaussian mechanism: the \u201cPRV accountant\u201d/Opacus (and PLD Accountant) only computes the \u201cremove\u201d relation. The \u201cautodp\u201d and Google DP library correctly computes both the \u201cadd\u201d and \u201cremove\u201d relations and takes the point-wise maximum, as in Theorem 11 of Zhu et al. \n\nThat is an interesting observation (and perhaps someone should tell the authors), but I don't think these findings make a sufficient contribution for a paper.\n\n> As mentioned in our response to Reviewer LTUo we conjecture that in the case of the Gaussian mechanism, it is sufficient to consider the \u201cremove\u201d datasets for subsampling without replacement under the substitution relation.\n\nI think proving this (even if it holds only for the Gaussian mechanism) would strengthen the paper. \n\n> The privacy parameters are not assumed to be identical. However, the privacy parameters are sometimes assumed to be close as is the case between the add/remove and substitution neighboring relations. We base this claim on the fact that accountants for Poisson subsampling are often used when it is not the implemented sampling scheme.\n\nIt indeed seems to be the case that the accountants for Poisson subsampling (with remove/add neighbourhood relation) are often used when they shouldn't be. And I think the same often happens in case of RDP accountants. Anyhow, I think the differences between neighbourhood relations and sampling schemes are correctly reflected in the results of Zhu et al. (2022). I think it would be interesting to see what are (as tight as possible) dominating pairs (either numerical or analytical) in various cases.\n\n> The RDP accountant computes the RDP guarantees of a single iteration for a given order and then applies the RDP composition theorem.\n\nAs far as I understand, the RDP accountants commonly compute the RDP guarantees for several orders and then convert the RDP-epsilons of different orders to approximate DP-guarantees using some conversion rule. \n\n> Due to the privacy scaling under the RDP composition theorem, it is sufficient to find the worst-case datasets for only a single iteration when using the RDP accountant. One could use a similar approach for hockey-stick divergence by computing a single (\u03b5, \u03b4)-DP guarantee and applying the advanced composition theorem. However, (\u03b5, \u03b4)-DP guarantees do not compose as well as the RDP guarantee. Therefore, the problem of determining the worst-case datasets under composition only seems to arise for exact accountants.\n\nI don't exactly follow here. If we want to have an accurate RDP accountant, we would need to have RDP bounds for several RDP orders (the conversion in the end). \n\nAll in all I think the topic is actual and the subtleties of hockey stick vs. R\u00e9nyi divergence based accountants haven't been fully addressed, but this paper does not really propose any solutions and also I think the criticism is not sharp enough to make for a paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700347044474,
                "cdate": 1700347044474,
                "tmdate": 1700552061553,
                "mdate": 1700552061553,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "or9UE0eBWb",
                "forum": "fj5SqqXfn1",
                "replyto": "FfCHDWnsNh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
                ],
                "content": {
                    "comment": {
                        "value": "Still getting back to this:\n\n> Due to the privacy scaling under the RDP composition theorem, it is sufficient to find the worst-case datasets for only a single iteration when using the RDP accountant. One could use a similar approach for hockey-stick divergence by computing a single (\u03b5, \u03b4)-DP guarantee and applying the advanced composition theorem. However, (\u03b5, \u03b4)-DP guarantees do not compose as well as the RDP guarantee. Therefore, the problem of determining the worst-case datasets under composition only seems to arise for exact accountants.\n\nI believe that different RDP orders could have different worst-case pairs of datasets, similarly as you might not have a worst-case pair for the hockey-stick divergence. To get the benefit out of RDP accounting, one should keep track of several RDP orders. Often the dominating pairs of distributions are obtained by some post-processing (consider e.g. additive Laplace or Gaussian noise), and the resulting pair is a dominating pair for both R\u00e9nyi and HS divergence, and often this pair is even tight in sense that it exactly gives the divergence of the mechanism evaluated on different dataset pairs (e.g., Gaussian mechanism). If we don't have a worst-case pair of datasets (consider, e.g., the exponential mechanism) but want to find tight bounds for a given divergence, I think one encounters difficulties both with R\u00e9nyi and HS divergence based accounting.\n\n(By the way, I would rather use the term numerical accounting than exact accounting when talking about the HS divergence based approach.)\n\n> even a simple mechanism that has a worst-case pair of datasets might not have a worst-case pair of datasets under subsampling and composition.\n\nThinking about this, I believe that the same pair of datasets would be the worst-case pair for compositions as well as for a single call of the mechanism (at least for non-adaptive compositions, I don't think we can expect to find worst-case pairs of datasets for adaptive compositions in general). For subsampling, again, the possible difficulties when trying to find the worst-case dataset pairs would be shared by other accounting methods such as the RDP, I think.\n\nI also share the criticism with reviewer dGjF in that Figure 1 should not be used as a proof (Proposition 11). I also think that the example with Laplace noise is a bit difficult to follow, some more formal derivation e.g. in the appendix would have helped (I suppose that could be even dealt analytically).\n\nI think the paper has some interesting points, but still needs more work. Some constructive results would definitely strengthen the paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700520092272,
                "cdate": 1700520092272,
                "tmdate": 1700552228517,
                "mdate": 1700552228517,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mRYMn8ga1B",
                "forum": "fj5SqqXfn1",
                "replyto": "ctouNFdR3Y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the reply and the discussion. \n\nI understand that that is the case (substitute relation and subsampling without replacement has a dataset-dependent bound in general), and as said, here would be interesting to find tight bounds for that case. And/or as tightly as possible dominating pairs. E.g. that Gaussian case you mentioned earlier would be interesting. If you look at the RDP analysis in that case, my understanding is that it is looser compared to e.g. the Poisson sampling bounds with add/remove relation.\n\nI believe that that construction by Doroshenko et al. would give a dominating pair of which hockey-stick divergence would very accurately give the privacy profile given in Zhu et al. (Proposition 30). And that it would not be lossy under compositions either. I think that that DP library for computing the (eps, delta)-bounds is here irrelevant, important is the construction for finding dominating pairs for a given privacy profile.\n\nMy point with RDP was that, if there is a pair of datasets such that the mechanism output for them corresponds to a dominating pair, then there is a post-processing also (Blackwell theorem) such that you get the mechanism outputs for other dataset pairs from this dominating pair and thus it would also dominate the R\u00e9nyi divergence for all orders. If there is no such worst-case dataset pair, then likely the R\u00e9nyi divergence will also have different worst-case dataset pairs for different orders, and it would likely be cumbersome to find those worst-case pairs for different orders and to do the RDP accounting. So I think that if one has difficulties with the hockey-stick divergence when trying to determine the dominating pairs of distributions, one would also likely encounter difficulties in RDP accounting.\n\nAs said, I think the paper is dealing with a relevant problem and has interesting observations, but would still need more work."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700693959974,
                "cdate": 1700693959974,
                "tmdate": 1700693959974,
                "mdate": 1700693959974,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lfeeizmvse",
                "forum": "fj5SqqXfn1",
                "replyto": "FfCHDWnsNh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6226/Reviewer_G1qb"
                ],
                "content": {
                    "comment": {
                        "value": "Ps. it seems that the worst-case data set in that Laplace example dominates for $\\varepsilon \\geq 0$ whereas there should be dominance for all $\\varepsilon \\in \\mathbb{R}$ for using the composition result."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694180375,
                "cdate": 1700694180375,
                "tmdate": 1700694230429,
                "mdate": 1700694230429,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RrULuwTFwd",
            "forum": "fj5SqqXfn1",
            "replyto": "fj5SqqXfn1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6226/Reviewer_xTEX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6226/Reviewer_xTEX"
            ],
            "content": {
                "summary": {
                    "value": "This paper clarifies common problems with privacy accounting. In particular, the paper shows that rigorous privacy accounting is affected by the method of sampling batches (Poisson subsampling or sampling without replacement). The paper also shows that self-composing worse-case datasets for the uncomposed mechanism is not in general valid."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper provides some novel theoretical results that develop our understanding of composition and subsampling with DP. I believe with small presentational edits (see weaknesses), this paper could serve as an important reference work for future research on subsampling with DP, as well as DP practitioners. \n\nIn general, the presentation is very clear and the authors on the whole provide welcome intuition to support the mathematical results."
                },
                "weaknesses": {
                    "value": "I am concerned that the paper presents somewhat of a straw-man (e.g. the two points of 'common' confusion in the abstract). It would be useful to provide evidence (even something anecdotal\n) that these are common pitfalls in practice. This would make the overall contribution of the paper much more convincing.  \n\nThe two recommendations for practitioners in the discussion section are welcome but I believe spelling out the implications of this work for practitioners (who will not read through the theory in detail) merits an entire section of the paper, and would enhance its practical utility and potential impact. \n\nDefinitions 3-5 would each benefit from a one sentence explanation for those less familiar with the prior research."
                },
                "questions": {
                    "value": "It would be interesting to understand whether empirical privacy (e.g. measured via auditing/MIA) of Poisson subsampling and sampling with replacement differs as much as the theoretical analysis implies (e.g. epsilon =1 vs 10!). Do you have priors about this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6226/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6226/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6226/Reviewer_xTEX"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698779970214,
            "cdate": 1698779970214,
            "tmdate": 1699636679869,
            "mdate": 1699636679869,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZaRMQvQ5Jo",
                "forum": "fj5SqqXfn1",
                "replyto": "RrULuwTFwd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6226/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review.\n\n> I am concerned that the paper presents somewhat of a straw-man (e.g. the two points of 'common' confusion in the abstract). It would be useful to provide evidence (even something anecdotal ) that these are common pitfalls in practice. This would make the overall contribution of the paper much more convincing.\n\nWhen writing the paper, we made a deliberate decision to minimize drawing attention to existing errors, though we understand how this treatment can risk presenting a straw-man. There are multiple examples of papers that perform privacy accounting for Poisson subsampling when it does not match the implementation. Anecdotally, we can refer the reviewers to page 23 of (De et al., https://arxiv.org/pdf/2204.13650.pdf): \u201cAs a minor technical note, we remark that this accountant assumes that at each iteration mini-batches are sampled with replacement from the entire dataset by including every training example with probability \ud835\udc5e, while in practice we sample mini-batches using a random shuffling scheme, such that each example is sampled once per training epoch.\u201d Poisson subsampling is computationally inefficient for large datasets and therefore the implementation might instead perform subsampling without replacement or shuffling. We do not want to call out otherwise good works like this in the main body of our paper. We focus on cautioning that such technicalities can in fact lead to large accounting errors. Regarding the pitfall about privacy accountants please see our response to Reviewer G1qb for more details and examples. \n\n> The two recommendations for practitioners in the discussion section are welcome but I believe spelling out the implications of this work for practitioners (who will not read through the theory in detail) merits an entire section of the paper, and would enhance its practical utility and potential impact.\n\nWe will expand on implications for practitioners as suggested.\n\n> It would be interesting to understand whether empirical privacy (e.g. measured via auditing/MIA) of Poisson subsampling and sampling with replacement differs as much as the theoretical analysis implies (e.g. epsilon =1 vs 10!). Do you have priors about this?\n\nPlease see our response to Reviewer LTUo."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700328882381,
                "cdate": 1700328882381,
                "tmdate": 1700328933858,
                "mdate": 1700328933858,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wo9oVzPMye",
            "forum": "fj5SqqXfn1",
            "replyto": "fj5SqqXfn1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6226/Reviewer_LTUo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6226/Reviewer_LTUo"
            ],
            "content": {
                "summary": {
                    "value": "This work studies privacy accounting for compositions of subsampled DP mechanisms. The authors show that a pair of worst-case datasets for a subsampled mechanism may no longer be a worst-case after composition, and privacy accounting can be very different for different sub-sampling strategies. These findings call for more care when applying privacy accounting in practice."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Privacy accounting of DP is an important problem when applying differential privacy in practice.\n2. The findings have important practical implications and help to avoid unintended privacy leakage.\n3. The theoretical construction of the bad cases is solid. \n4. The presentation is clear and easy to follow."
                },
                "weaknesses": {
                    "value": "1. The authors did not provide a viable technical solution for dealing with the worst-case dataset problem under replacement DP.\n2. While constructing the bad cases on lower dimensional datasets is sufficient to demonstrate the claims, it would be nice to include empirical results on more realistic datasets to show that these pitfalls can actually appear in practice."
                },
                "questions": {
                    "value": "For replacement DP, is there a good way to find a good approximation of privacy curves when the exact worst-case dataset is hard to obtain?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698791764254,
            "cdate": 1698791764254,
            "tmdate": 1699636679752,
            "mdate": 1699636679752,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "14d58zOSyj",
                "forum": "fj5SqqXfn1",
                "replyto": "wo9oVzPMye",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6226/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewers for their feedback.\n\n> While constructing the bad cases on lower dimensional datasets is sufficient to demonstrate the claims, it would be nice to include empirical results on more realistic datasets to show that these pitfalls can actually appear in practice.\n\nWe agree that understanding the privacy loss for actual datasets is an important problem. It would be interesting to e.g. examine how privacy auditing techniques for DP-SGD are affected by various sampling schemes using standard benchmark datasets. It is unlikely that the gradients resemble the worst-case datasets for sampling without replacement in all iterations. That is, all gradients have maximum length and the same direction. It is also unlikely that they resemble the worst-case datasets for Poisson subsampling where all but one datapoint is the zero vector. As such, it is not immediately clear how the sampling schemes compare empirically. However, we consider this a separate problem from tight privacy accounting.\n\n> The authors did not provide a viable technical solution for dealing with the worst-case dataset problem under replacement DP + For replacement DP, is there a good way to find a good approximation of privacy curves when the exact worst-case dataset is hard to obtain?\n\nDetermining the worst-case dataset under replacement is a difficult problem in general as we show in Section 7. The technique by Zhu et al. can be used to construct a dominating pair of distributions. See the review and response to Reviewer G1qb for more details. Under subsampling without replacement without composition, the privacy curve of the Gaussian and Laplace mechanisms is the same under the substitution neighborhood as under the remove relation for $\\varepsilon \\geq 0$. As we show in Sections 5 and 7, that is not the case under composition for the Laplace mechanism. We conjecture that the curve under the substitution and remove relations matches under composition for the Gaussian mechanism. Proving or disproving this is a direction for future work. Nonetheless, the goal of Section 7 is to highlight that accounting for worst-case datasets under substitution is unsolved and that care should be taken when using numerical accounting under the substitution neighboring relation."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700328787162,
                "cdate": 1700328787162,
                "tmdate": 1700328809466,
                "mdate": 1700328809466,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZutVOPMJBu",
            "forum": "fj5SqqXfn1",
            "replyto": "fj5SqqXfn1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6226/Reviewer_dGjF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6226/Reviewer_dGjF"
            ],
            "content": {
                "summary": {
                    "value": "This paper exposes several cases where mismatches between privacy accounting and its implementation gives incorrect results. The authors show that the noise required to achieve a certain privacy guarantee can differ significantly between Poisson sampling and sampling without replacement; and that the worst-case dataset for a single iteration of a subsampled mechanism might give incorrect results for the composed mechanism. They also demonstrate issues with computing tight DP bounds under the substitution relation of neighboring datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper\u2019s findings could be highly impactful on the practice of privacy accounting, as they demonstrate that a method\u2019s implementation should match its accounting. The paper also includes a good call-to-action on how these issues can be addressed by DP practitioners. And despite this paper being about pointing out mistakes in other works, the authors of the paper are tactful and include some interesting discussions in the paper."
                },
                "weaknesses": {
                    "value": "While I think this paper has a powerful message, there are issues with presentation / rigor which make me question whether it\u2019s ready for publication. For example, Proposition 11 is proved by a picture (Figure 1). I also feel that it\u2019s hard to follow the discussion in Section 7 because the counterexample is for something that is stated without any great formality.\n\nThe paper is also a bit sparse (there is no appendix). I would have liked to see more substance. The paper does in my opinion do something very important, but in its current state I don't feel it has the solidity of an ICLR paper."
                },
                "questions": {
                    "value": "In Theorem 10, I think there is a bit of a typo: $(1 - \\gamma)P + Q$ should be $(1 - \\gamma)P + \\gamma Q$.\n\nThe proof of Proposition 9 seems to take for granted that we know the dominating pair for the Gaussian mechanism! But I think this should be stated formally somewhere as otherwise the \u201cNow, from Theorem 10 we know that\u2026\u201d sentence is unclear.\n\nCombining the plot and the table into a single Figure 3 seems a bit ambitious. At first glance I thought that they were related somehow, and only after reading the caption realized that they were not. I think it would be clearer to separate them into different figures.\n\nThe plot in Figure 3 could maybe also be split into two plots? It is a little hard to see the takeaways as is. It might be nice to have one plot showing Poisson for $\\epsilon \\in [1, 2, 5, 10]$ (to illustrate the \u201ctwo regions\u201d of high / low sampling rate) and another plot showing Poisson + WOR for $\\epsilon=10$ (to illustrate the \u201chinge\u201d)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6226/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6226/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6226/Reviewer_dGjF"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6226/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698795961035,
            "cdate": 1698795961035,
            "tmdate": 1699636679637,
            "mdate": 1699636679637,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "c0DZ53tGTK",
                "forum": "fj5SqqXfn1",
                "replyto": "ZutVOPMJBu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6226/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6226/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the helpful feedback on writing and presentation. We will make several minor edits to address typos and unclear exposition, and we will improve the rigor based on your suggestions. For Proposition 9 we will include a reference for the dominating pair of the Gaussian mechanism (Balle and Wang, https://arxiv.org/pdf/1805.06530.pdf). For Proposition 11 we will include exact calculations for two points on the center plot which is sufficient for the proof of the counter-example. We will rephrase parts of Section 7 and redesign Figure 3 to improve presentation."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6226/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700328703018,
                "cdate": 1700328703018,
                "tmdate": 1700328703018,
                "mdate": 1700328703018,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]