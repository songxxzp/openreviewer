[
    {
        "title": "Faithful Rule Extraction for Differentiable Rule Learning Models"
    },
    {
        "review": {
            "id": "fZvPZOINzN",
            "forum": "kBTzlxM2J1",
            "replyto": "kBTzlxM2J1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors proposed a solution on how to extract rules from the DRUM model that are faithful, i.e., both complete and sound. The authors provided extensive analysis on the correctness of the proposed algorithm and demonstrate the benefits of their algorithm with some experiments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The rule learning problem, in particular, the problem of how to obtain a high-quality set of rules, that the authors are exploring is a critical problem. \n+ The authors present a detailed theoretical analysis of how to derive faithful rules from DRUM model, which is quite impressive"
                },
                "weaknesses": {
                    "value": "+ I have some concerns about the motivation of the proposed method. It is not clear to me why faithfulness is an important metric for rule learning. What kind of benefits can we obtain for the rule learning problem if the rules can respect faithfulness, e.g., say better generalizability? The authors may need more effort to justify this. One motivating example might be helpful for readers to understand this.\n+ I also feel that the proposed solution is too specific. It is only applicable to the DRUM model rather than the general rule learning model, which may limit the applicability of the proposed method in general settings. \n+ The overall presentation may need to be improved. I feel that the authors have a lot of technical content to present. However, putting all of them together without appropriate illustrations makes it hard for readers to digest. One suggestion would be using some running examples to intuitively explain the meaning of the notations and equations rather than just leaving them in the paper. Even the prior work such as DRUM paper or Neural ILP paper, there are a lot of visualizations that help users understand the intuitions of the proposed method.\n+ I feel that the experimental evaluations are also concerning. The authors only focus on evaluating the performance of the proposed methods. However, no appropriate evaluations (except some simple case studies) are conducted for the faithfulness part, e.g., how many rules from the vanilla DRUM model violate the faithfulness criterion and what is the bad effect of including those rules?"
                },
                "questions": {
                    "value": "See above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4188/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ",
                        "ICLR.cc/2024/Conference/Submission4188/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4188/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698273203540,
            "cdate": 1698273203540,
            "tmdate": 1700340278236,
            "mdate": 1700340278236,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "kxid5wpF6A",
                "forum": "kBTzlxM2J1",
                "replyto": "fZvPZOINzN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4188/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4188/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer piEQ"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the valuable comments. \n\n> It is not clear to me why faithfulness is an important metric for rule learning. What kind of benefits can we obtain for the rule learning problem if the rules can respect faithfulness, e.g., say better generalizability? The authors may need more effort to justify this. One motivating example might be helpful for readers to understand this. ...One suggestion would be using some running examples to intuitively explain the meaning of the notations and equations rather than just leaving them in the paper.\n\nAs requested, we have incorporated an example in the introduction, highlighting the benefits of ensuring faithfulness. We now also refer to this running example in other parts of the paper. Given the tight space restrictions and the need to rigorously present our technical results, this description is necessarily concise. Nevertheless, we anticipate that it will enhance the overall readability of the paper.\n\n\n> I also feel that the proposed solution is too specific. It is only applicable to the DRUM model rather than the general rule learning model, which may limit the applicability of the proposed method in general settings.\n\nWhile it is necessary to independently analyse the faithfulness of various rule-learning models, we expect that the strategies employed in our approach will contribute to a broader understanding of the faithfulness of rule-learning models. Indeed, we anticipate that these strategies can serve as a foundation for the future analysis of other models.\n\n\n> The authors only focus on evaluating the performance of the proposed methods. However, no appropriate evaluations (except some simple case studies) are conducted for the faithfulness part, e.g., how many rules from the vanilla DRUM model violate the faithfulness criterion and what is the bad effect of including those rules?\n\nPlease note that in Section 6 we perform an extensive analysis of the faithfulness of the rules extracted from the original DRUM model (results are summarised in Table 2). The soundness of the extracted rules is guaranteed by Theorem 1. However, Table 2 shows that \nthe rules are not complete, and in fact they only produce a very small fraction (less than 7\\%) of the facts predicted by the DRUM model. Therefore, *none* of the rule sets extracted from the original DRUM model is faithful."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4188/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700059482050,
                "cdate": 1700059482050,
                "tmdate": 1700059482050,
                "mdate": 1700059482050,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2WWAhGCncD",
                "forum": "kBTzlxM2J1",
                "replyto": "kxid5wpF6A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "Thanks for the authors' efforts in providing detailed responses! One thing that I am still worried about is that the definitions of completeness and faithfulness are still unclear to me. I know that the authors referred to Cucala et al. (2022b) about such definitions. But without formalization of such important concepts in the paper, the paper seems not to be self-contained. Although the authors mentioned that those definitions are provided in Section 2, I couldn't find them at all...\n\nThis is also related to my earlier concerns about the lack of evaluations on faithfulness in the experiments. Since no formal definitions of faithfulness and completeness are given and no formulas are provided to show how they are calculated in the experiments, it is unclear to readers to understand how those numbers are obtained and how this is related to the notion of faithfulness or completeness."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4188/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700333370508,
                "cdate": 1700333370508,
                "tmdate": 1700333370508,
                "mdate": 1700333370508,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LprfMNyKwJ",
                "forum": "kBTzlxM2J1",
                "replyto": "two4jmEZvr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4188/Reviewer_piEQ"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your explanations"
                    },
                    "comment": {
                        "value": "Thanks for your explanations. I found it. I determined to raise my score from 5 to 6."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4188/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700340266266,
                "cdate": 1700340266266,
                "tmdate": 1700340266266,
                "mdate": 1700340266266,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DGozCnByel",
            "forum": "kBTzlxM2J1",
            "replyto": "kBTzlxM2J1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4188/Reviewer_BVyG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4188/Reviewer_BVyG"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses the growing interest in extracting understandable rules from machine learning models that work with knowledge graphs. These models are used for various tasks like knowledge graph completion, node classification, question answering, and recommendation. However, many of these rule extraction methods lack formal guarantees, which can be a problem when applying these rules in critical or legally required situations. The paper focuses on the DRUM model, a variant of the NEURAL-LP model, which has shown good practical performance. The paper explores whether the rules derived from DRUM are sound and complete, meaning they provide reliable results. The authors propose a new algorithm to ensure both soundness and completeness in the extracted rules. This algorithm, while effective, may be less efficient in practice. They also suggest adding constraints to DRUM models to facilitate rule extraction, even if it reduces their expressive power. The paper points out that DRUM and NEURAL-LP models have technical differences, making it necessary to examine the guarantees separately for DRUM."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Good paper interesting, with good ideas and good experiments."
                },
                "weaknesses": {
                    "value": "it seems that a lot of citations are missing, please add them and discuss them\n\nhttps://arxiv.org/pdf/2301.09559.pdf\nLearning Interpretable Rules for Scalable Data Representation and Classification\nFINRule: Feature Interactive Neural Rule Learning\nhttps://arxiv.org/pdf/2309.09638.pdf"
                },
                "questions": {
                    "value": "-"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "-"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4188/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698573856915,
            "cdate": 1698573856915,
            "tmdate": 1699636385280,
            "mdate": 1699636385280,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lWKF0CuH8l",
                "forum": "kBTzlxM2J1",
                "replyto": "DGozCnByel",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4188/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4188/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer BVyG"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments and suggestions. We have uploaded a new version of the paper including the references provided by the reviewer."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4188/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700058647082,
                "cdate": 1700058647082,
                "tmdate": 1700058647082,
                "mdate": 1700058647082,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gjiyO39gFH",
            "forum": "kBTzlxM2J1",
            "replyto": "kBTzlxM2J1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4188/Reviewer_Crqq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4188/Reviewer_Crqq"
            ],
            "content": {
                "summary": {
                    "value": "The paper adapts a study that was previously conducted for extracting rules from the Neural-LP model (which is a neural model for reasoning about knowledge graphs) to DRUM, an alternative architecture for the same task. This adaptation is not entirely trivial, as the authors motivate well, so that this can be considered an original contribution. They also show that, in analogy to the previous work, the extracted rules are not necessarily faithful, and can be unsound or incomplete. An expensive alternative is also proposed as a remedy."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper seems to be well formalized and contain sufficiently interesting improvements over the state-of-the-art. The evaluation is on a standard benchmark task. The introduction is quite accessible, but after that I was quickly lost."
                },
                "weaknesses": {
                    "value": "I am not sufficiently familiar with this area in order to judge whether the contribution of this work is sufficiently deep for publication, whether the shown results are actually correct, or whether the performed evaluation on this set of benchmark sets is a standard procedure in this area.\nWhat I can judge, however, is that the paper is a) very well written in the sense that a stringent formal presentation is chosen, but also b) not written for an audience outside this immediate community, and the authors also do not make any attempt to make their work more accessible. If you do not know any of the prior works, in particular DRUM, you are lost. I could, e.g., easily follow the terse formal description of Datalog, because I am familiar with that. With the similarly formal presentation of DRUM I was completely lost. I now know what parts this system has, but not what they are used for. I know that path-counting is part of the method, but I don't know what paths are counted, and why this has any significance. \nI think the paper is a very nice illustration of the fact that shorter explanations are not necessarily more interpretable. \n\nMinor stuff:\nThe formalization of the paper seems to be very stringent, the references are not (lower case abbreviations such as gnn, all conference names abbreviated (I don't know all of them), weird references to things like ICML volume 227 or ISWC volume 13489, backslashes in URLs, etc."
                },
                "questions": {
                    "value": "I'm not really familiar with this task, but this seems to be quite a heavy machinery for extracting family relations. In Inductive Logic Programming these are only toy examples. Are there no better tasks for showcasing what you can do?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4188/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698785722261,
            "cdate": 1698785722261,
            "tmdate": 1699636385208,
            "mdate": 1699636385208,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wxEdOtu6s2",
                "forum": "kBTzlxM2J1",
                "replyto": "gjiyO39gFH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4188/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4188/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Crqq"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments and for pointing out typos and other minor infelicities in the references, which we have fixed in the updated version of the paper.\n\n\n> This paper is not written for an audience outside this immediate community, and the authors also do not make any attempt to make their work more accessible. If you do not know any of the prior works, in particular DRUM, you are lost. I could, e.g., easily follow the terse formal description of Datalog, because I am familiar with that. With the similarly formal presentation of DRUM I was completely lost. I now know what parts this system has, but not what they are used for. I know that path-counting is part of the method, but I don't know what paths are counted, and why this has any significance.\n\nTo make the paper more accessible, we have uploaded a new version with running examples that illustrate the key ideas and models discussed in the paper. The new examples are introduced in Section 1  and Section 3 (after Lemma 1), respectively, and we expand upon them in the following sections. Given the tight space restrictions and the need to rigorously present our technical results, the discussion of the examples is necessarily concise. Nevertheless, we anticipate that they will enhance the overall readability of the paper.\n\n\n> I'm not really familiar with this task, but this seems to be quite a heavy machinery for extracting family relations. In Inductive Logic Programming these are only toy examples. Are there no better tasks for showcasing what you can do?\n\nWe used the Family dataset in Section 6 to illustrate some simple rules extracted by our model which are intuitive and easy to read. We have now included in the Appendix examples of rules extracted for FB15k-237, WN18RR and NELL-995, which are real-world datasets commonly used as KG completion benchmarks."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4188/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700058224798,
                "cdate": 1700058224798,
                "tmdate": 1700058487743,
                "mdate": 1700058487743,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KJ0Vg8STib",
            "forum": "kBTzlxM2J1",
            "replyto": "kBTzlxM2J1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4188/Reviewer_dHjy"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4188/Reviewer_dHjy"
            ],
            "content": {
                "summary": {
                    "value": "In the abstract, the authors describe the problem that they are solving as  \"methods for extracting interpretable rules from ML\nmodels trained to solve a wide range of tasks over knowledge graphs (KGs), such as KG completion, node classification, question answering and recommendation.\" and talk about how \"Many such approaches, however, lack formal guarantees establishing the precise\nrelationship between the model and the extracted rules, and this lack of assurance becomes especially problematic when the extracted rules are applied in safety critical contexts or to ensure compliance with legal requirements\"\n\nWhile the work described in the paper seems reasonable, this does not quite seem to match the claim in the abstract. As best as I can tell,\nthe techniques in the paper do not deal with classification / question answering / recommendations. Further, it is not obvious (either from the description of the technique or the experimental results) that they provide assurances around the \"precise relationship between the model and the extracted rules\" (while there might be soundness, completeness does not seem to result)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The results seem interesting for knowledge graph completion problems."
                },
                "weaknesses": {
                    "value": "It was not obvious how this applies for general ML problems, particularly those around question answering. It was not clear how the algorithm might perform for classification/recommendation systems."
                },
                "questions": {
                    "value": "It was not obvious how this applies for general ML problems, particularly those around question answering. It was not clear how the algorithm might perform for classification/recommendation systems."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4188/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810730625,
            "cdate": 1698810730625,
            "tmdate": 1699636385107,
            "mdate": 1699636385107,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1hWTChEhg5",
                "forum": "kBTzlxM2J1",
                "replyto": "KJ0Vg8STib",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4188/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4188/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer dHjy"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the valuable comments. We answer the questions raised by the reviewer as follows.\n\n> As best as I can tell, the techniques in the paper do not deal with classification / question answering / recommendations.\n\nThe techniques presented in the paper address the general problem of realising transformations between KGs. Tasks such as classification, question answering, and recommendation on KGs can be seen as concrete applications of our approach. Question answering over KGs can be viewed as the problem of learning a function that maps the input knowledge graph to a set of facts representing all answers to a given set of questions. Recommendation can be viewed as learning a function that maps a KG describing user-item interactions to a set of facts where each fact represents a recommendation. Finally, node classification can be seen as the problem of learning a function from a KG to a set of facts stating membership of nodes to given classes. \n\n\n> It is not obvious (either from the description of the technique or the experimental results) that they provide assurances around the \"precise relationship between the model and the extracted rules\" (while there might be soundness, completeness does not seem to result).\n\nPlease note that Theorem 3 in Section 4 ensures the faithfulness (i.e., both soundness *and* completeness) of Algorithm 1 for multipath rule extraction from a DRUM model. Furthermore, Theorem 4 in Section 5.1 proves the faithfulness of Algorithm 2 for multipath rule extraction over a fixed dataset. The corresponding proofs are given in the Appendix."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4188/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700057779032,
                "cdate": 1700057779032,
                "tmdate": 1700057779032,
                "mdate": 1700057779032,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YiOzvx6ewh",
                "forum": "kBTzlxM2J1",
                "replyto": "1hWTChEhg5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4188/Reviewer_dHjy"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4188/Reviewer_dHjy"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your clarifications."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4188/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700707432287,
                "cdate": 1700707432287,
                "tmdate": 1700707432287,
                "mdate": 1700707432287,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]