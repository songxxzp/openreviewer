[
    {
        "title": "Communication-Efficient Algorithm for Asynchronous Multi-Agent Bandits"
    },
    {
        "review": {
            "id": "dy9gD4h2mN",
            "forum": "ONnZVUrFBT",
            "replyto": "ONnZVUrFBT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7429/Reviewer_F9Jr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7429/Reviewer_F9Jr"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors study the cooperative asynchronous multi-agent multi-armed bandit problem:\n- the agents are allowed to communicate for handling the same Bernoulli multi-armed problem, \n- at each time step a subset of agents, which is chosen in advance by an adversary, can play the arms.\nThe authors designed a new communication protocol: an agent communicates if its new local observations enough reduce the estimation of the global confidence bound of the considered arm. The proposed bandit algorithm is based on Successive Elimination of suboptimal arms. The algorithm is analyzed and then tested versus the state-of-the-art."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The main claim of the paper is to handle cooperative asynchronous multi-agent multi-armed bandits with a constant communication cost, while guarantying a rate optimal regret upper bound.\nThis study is interesting, notably the fact that agents asynchronously play, which has a significant applicative potential. The constant communication cost can be easily obtained by an explore-then-exploit approach (Hillel et al 2013), but not with an optimal rate regret upper bound. So, it is an interesting result."
                },
                "weaknesses": {
                    "value": "The paper has some weaknesses:\n        - Objective function: the authors wrote that the expectation in the expected regret (actually, the pseudo regret) is taken over the randomness of the algorithm and reward realizations. However, the reviewer did not find where there is randomness in Algorithm 1. So, there is no expectation in the second line of the pseudo regret R(T).\n\n        - Algorithm 1: the reviewer does not understand what lines 21-24 mean.\n        - Communication cost: the reviewer is wondering why agents send an elimination message to other agents (line 7), while agents also send their estimates line 15. \n        - Number of agents: in the experiments, the number of agents is lower than the number of arms. \n        - Proof of Lemma 1: equation (a1), M_t is not defined and misleading.\n        - Proof of Theorem 2, step 3: the reviewer does not understand where the last equation page 17 comes from. Could you provide more details?\n        - Model: the authors assume that there is only on best arm (\\mu_1 > \\mu_2 \\geq \u2026). This is a strong assumption that limits the scope of this study.\n\nThe authors answered to most of my concerns. I raised my score to 6."
                },
                "questions": {
                    "value": "See above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7429/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7429/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7429/Reviewer_F9Jr"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7429/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698408680425,
            "cdate": 1698408680425,
            "tmdate": 1700812296854,
            "mdate": 1700812296854,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NakOjX0q4c",
                "forum": "ONnZVUrFBT",
                "replyto": "dy9gD4h2mN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Regret Definitioin"
                    },
                    "comment": {
                        "value": "> Reviewer: Objective function: the authors wrote that the expectation in the expected regret (actually, the pseudo regret) is taken over the randomness of the algorithm and reward realizations. However, the reviewer did not find where there is randomness in Algorithm 1. So, there is no expectation in the second line of the pseudo regret R(T).\n\n**Answer:** The mention of randomness in the expected regret definition is a standard approach to cover a wide range of algorithms, including probabilistic ones. Although Algorithm 1 is deterministic, this inclusion allows our analysis to remain applicable to other potential algorithms, such as those based on stochastic methods like Thompson sampling based ones."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503287092,
                "cdate": 1700503287092,
                "tmdate": 1700503287092,
                "mdate": 1700503287092,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zn20Z3zZ4Z",
                "forum": "ONnZVUrFBT",
                "replyto": "dy9gD4h2mN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Lines 21-24 in Algorithm"
                    },
                    "comment": {
                        "value": "> Reviewer: Algorithm 1: the reviewer does not understand what lines 21-24 mean.\n\n**Answer:** Lines 21-22 are the receiving counterpart for the message sent in Line 16 (by other agents $m'$),\n      while Lines 23-24 are the receiving counterpart for the message sent in Line 15. Take the pair between Line 16 and Lines 21-22 as an example. Line 16 means that, when sending message from agent $m$ to agent $m'$, the agent $m$ sends the token $\\texttt{tk}^{(m\\to m')}$ to agent $m'$ as well.\n      Lines 21-22 means that, when receiving a token $\\texttt{tk}^{(m'\\to m)}$ that was used to send a message from agent $m'$ to agent $m$, agent $m$ keeps this token. This pair constitutes the token receiving and sending protocol. We will add this explanation to the final version of this paper."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503358497,
                "cdate": 1700503358497,
                "tmdate": 1700503358497,
                "mdate": 1700503358497,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MuoifTSTZL",
                "forum": "ONnZVUrFBT",
                "replyto": "dy9gD4h2mN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Communication Cost"
                    },
                    "comment": {
                        "value": "> Reviewer: Communication cost: the reviewer is wondering why agents send an elimination message to other agents (line 7), while agents also send their estimates line 15. \n\n**Answer:** The seemly redundant communications are due to the asynchronous decision rounds of agents and the small number of communications (constant communications in total).\n      In synchronous cases, as all agents have the same number of decision rounds, sending reward mean estimates is enough.\n      However, when it comes to this paper's asynchronous case,\n      sending reward mean estimates (Line 15) is not enough.\n      Without the elimination message to other agents (Line 7),\n      some \"fast\" agents (high active frequency) may eliminate one arm much earlier than some \"slow\" agents: the number of reward observations of \"fast\" agents can be much larger than that of the \"slow\" ones, and the small number of communications achieved by our algorithm design can delay the observation sharing from \"fast\" agents to \"slow\" agents a lot. Therefore, the elimination message in Line 7 is important for reducing the regret cost due to \"slow\" agents (more general, due to asynchronicity) and thus is not redundant in an asynchronous setting."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503455564,
                "cdate": 1700503455564,
                "tmdate": 1700503455564,
                "mdate": 1700503455564,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qE75Ixja1B",
                "forum": "ONnZVUrFBT",
                "replyto": "dy9gD4h2mN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Number of Agents in Experiments"
                    },
                    "comment": {
                        "value": "> Reviewer: Number of agents: in the experiments, the number of agents is lower than the number of arms. \n\n**Answer:** In Figure 7 in Appendix D of the revised manuscript, we report additional experiments where the number of agents is $M=30$ greater than the number of arms $K=16$. In these experiments, our algorithm outperforms other baseline algorithms in communication and enjoys similar regret as the other baselines, which is the same observation as in our original numerical simulations in Figure 1."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503500873,
                "cdate": 1700503500873,
                "tmdate": 1700503500873,
                "mdate": 1700503500873,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LZyfb9D4aZ",
                "forum": "ONnZVUrFBT",
                "replyto": "dy9gD4h2mN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On $Mt$ in Proof of Lemma 1"
                    },
                    "comment": {
                        "value": "> Reviewer: Proof of Lemma 1: equation (a1), M_t is not defined and misleading.\n\n**Answer:** In inequality (a1), the upper bound of summation is $M\\times t$, not $M_t$, where $M$ is the number of agents and $t$ is the current time index. In the revised, we updated it to $M\\cdot t$ to avoid misunderstanding."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503568815,
                "cdate": 1700503568815,
                "tmdate": 1700503568815,
                "mdate": 1700503568815,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "83LJS5LTFc",
                "forum": "ONnZVUrFBT",
                "replyto": "dy9gD4h2mN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Step 3 of Proof of Theorem 3"
                    },
                    "comment": {
                        "value": "> Reviewer: Proof of Theorem 2, step 3: the reviewer does not understand where the last equation page 17 comes from. Could you provide more details?\n\n**Answer:** The last inequality comes from the last equation, where we substitute $1=\\texttt{ECR}\\_t^{(m)}(0)$ and take $\\log_\\alpha$ on both sides.\n    Below, we illustrate how the last equation is derived, and we updated this proof detail in the revised version as well.\n    We note that the estimated confidence radius $\\texttt{ECR}\\_k^{(m)}(T)$ should be written as the $\\texttt{ECR}_k^{(m)}(\\tau_k(\\kappa_k))$ at the last communication round $\\tau_k(\\kappa_k)$ because after the last communication, the width of $\\texttt{ECR}$ has no further impact on communication.\n    \\newline\n    Recall that $\\tau_k(t)$ is the latest communication round about arm $k$ on or before time slot $t$.\n    Then, $\\texttt{ECR}_k^{(m)}(\\tau_k(\\kappa_k))$ is the $\\texttt{ECR}$ at the latest communication for arm $k$ which can be upper bounded as follows,\n    $$\n    \\texttt{ECR}_k^{(m)}(\\tau_k(\\kappa_k))\n    \\overset{(a)}=\n    \\texttt{CR}(n_k(\\tau_k(\\kappa_k))) \\ge\n    \\texttt{CR}(n_k (\\kappa_k))\n    \\ge \\frac{\\Delta_k}{2(1+\\alpha)},\n    $$\n    where equality (a) is because $\\tau_k(\\kappa_k)$ is a communication time slot in which the estimated confidence radius ($\\texttt{ECR}$) is equal to $\\texttt{CR}$."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503748065,
                "cdate": 1700503748065,
                "tmdate": 1700503748065,
                "mdate": 1700503748065,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QXN3VP8391",
                "forum": "ONnZVUrFBT",
                "replyto": "dy9gD4h2mN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Single Optimal Arm Assumption"
                    },
                    "comment": {
                        "value": "> Reviewer: Model: the authors assume that there is only on best arm (\\mu_1 > \\mu_2 \\geq \u2026). This is a strong assumption that limits the scope of this study.\n\n**Answer:** Assuming a single optimal arm is for the ease of presentation, which was widely assumed in literature (e.g., see Even-Dar et al. (2006, Section 2.1)). In the case of multiple optimal arms,\n      tailoring our current algorithm could also work.\n      In the original algorithm design, when only one arm remains in the candidate arm set (the optimal arm), the algorithm stops communication.\n      When it comes to the case of multiple optimal arms, the above communication stop condition is invalid.\n      Instead, one can set an exploration threshold, and when the number of times pulling the remaining arms in the candidate arm set exceeds this threshold, stop the communication. This threshold would guarantee that the total communications are still constant, as well as that the reward means of remaining arms are close enough to have a sublinear regret upper bound.\n\n---\nEven-Dar, Eyal, et al. \"Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems.\" Journal of Machine Learning Research 7.6 (2006)."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503843700,
                "cdate": 1700503843700,
                "tmdate": 1700503843700,
                "mdate": 1700503843700,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wzRoqnHGsU",
                "forum": "ONnZVUrFBT",
                "replyto": "QXN3VP8391",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_F9Jr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_F9Jr"
                ],
                "content": {
                    "comment": {
                        "value": "I thank you for your answers to my concerns.\n\nI still think that a single best arm is not a mild assumption. I am not sure that if \\epsilon > 0, the optimal regret rate is preserved. \n\nIn (Even-Dar et al 2006) Successive Elimination is presented with \\epsilon=0. However, since this seminal paper they were a lot of papers handling (\\epsilon,\\delta) PAC algorithms for Best Arm Identification, including decentralized algorithms (see for instance the papers below).\n\n\n\n(Gabillon et al 2012) Victor Gabillon, Mohammad Ghavamzadeh, Alessandro Lazaric, Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence, NeurIPS 2012.\n\n(Kalyanakrishnan et al 2012) Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, Peter Stone, PAC Subset Selection in Stochastic Multi-armed Bandits, ICML 2012.\n\n(Kaufmann and Kalyanakrishnan 2013) Kaufmann and Kalyanakrishnan, Information Complexity in Bandit Subset Selection, ALT 2013.\n\n(F\u00e9raud et al 2020) Rapha\u00ebl F\u00e9raud, R\u00e9da Alami, Romain Laroche, Decentralized Exploration in Multi-Armed Bandits, ICML 2020."
                    }
                },
                "number": 31,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700648629340,
                "cdate": 1700648629340,
                "tmdate": 1700648629340,
                "mdate": 1700648629340,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WC8awZnNSy",
            "forum": "ONnZVUrFBT",
            "replyto": "ONnZVUrFBT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7429/Reviewer_andi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7429/Reviewer_andi"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a distributed asynchronous method for solving the multi-agent multi-armed bandit (MA2B) problem. The authors also extend their algorithms and results to preserve privacy. The main contribution of this paper is the design of the event-trigger-based asynchronous method to achieve higher communication efficiency. Both the theoretical and numerical results demonstrated the higher communication efficiency."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well written and easy to read. The idea of algorithm design is quite reasonable and sounds promising. They use the idea of \"event trigger\", namely, a node communicates only when it has enough new information to share. They also quantify the amount of information by something called \"confidence radius\". They also theoretically and numerically justify their main motivation: lower communication complexity. Their theoretical results show that their algorithm possesses the property of \"constant communication\", which is attractive to the reviewer."
                },
                "weaknesses": {
                    "value": "1. Although the order of the regret bound of the proposed algorithm (see Remark 3) is the same as the optimal bound, the constant term before the order can be quite large. For example, when setting $\\alpha=6$ as used in the experiments, the constant can be as large as 392, which is a very large number. I suggest the authors provide the regret bound (not only the order) of alternative methods and compare them. It will also be better to plot the regret bounds and the communication complexity bounds of the proposed method and alternative methods.\n\n2. Can the authors clarify what is indeed the most important measurement (time or communication) in the MA2B task? The authors explained that synchronous updates will lead to redundant communication (Section 3.1). This is reasonable, but what is the final purpose of saving communication? Is it to achieve a lower regret within a shorter time horizon? If time is the most important thing, then by Figure 1,2, the performance of the proposed method is not as good as UCB-IBC.\n\n3. I can see that from Theorem 2, a smaller alpha yields smaller regret. I can also see that from Figure 1,2, the proposed method has a higher regret compared to UCB-IBC. Therefore, I'm interested in the question of when we use smaller $\\alpha$ to achieve similar regret as UCB-IBC, will the number of communications of the proposed method still be much smaller?"
                },
                "questions": {
                    "value": "I'm quite interested in the property of constant communication. By Theorem 2, the authors show that the regret bound is closely related to T, but the number of communications is independent of T. This means that communication between agents is not so important and even if there are only a few communications, smaller $R(T)/T$ can still be achieved by using a large T. Can the authors intuitively explain the philosophy behind this property?\n\nI'm not familiar with this topic, but if the authors can clarify my concerns, then I'm willing to improve my score."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7429/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7429/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7429/Reviewer_andi"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7429/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698445645935,
            "cdate": 1698445645935,
            "tmdate": 1699636891817,
            "mdate": 1699636891817,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vLt3ZK3tPe",
                "forum": "ONnZVUrFBT",
                "replyto": "WC8awZnNSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Coefficient in Regret Upper Bound"
                    },
                    "comment": {
                        "value": "> Reviewer: Although the order of the regret bound of the proposed algorithm (see Remark 3) is the same as the optimal bound, the constant term before the order can be quite large. For example, when setting $\\alpha=6$\n      as used in the experiments, the constant can be as large as 392, which is a very large number. I suggest the authors provide the regret bound (not only the order) of alternative methods and compare them. It will also be better to plot the regret bounds and the communication complexity bounds of the proposed method and alternative methods.\n\n**Answer:** The leading term coefficients of $\\texttt{SE-ODC}$ and SE-IBC in our experiment setting are $24$, which is better than the $392$ factor in our $\\texttt{SE-AAC-ODC}$ algorithm. For one thing, we note that the larger constant coefficient of our regret upper bound comes from a more involved regret analysis for our constant communication result. This implies the challenge and novelty of our new algorithm.\n      For another thing, in our experiments, e.g., Figure 1(b), our algorithm with only constant communication has a better regret performance than that of $\\texttt{SE-ODC}$ with logarithmic communication. That implies although there is a larger artificial factor in our regret upper bound result, the empirical regret performance of our algorithm is better (even with lower communications)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502991957,
                "cdate": 1700502991957,
                "tmdate": 1700502991957,
                "mdate": 1700502991957,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qkGnZzsdj2",
                "forum": "ONnZVUrFBT",
                "replyto": "WC8awZnNSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Most Important Metric"
                    },
                    "comment": {
                        "value": "> Reviewer: Can the authors clarify what is indeed the most important measurement (time or communication) in the MA2B task? The authors explained that synchronous updates will lead to redundant communication (Section 3.1). This is reasonable, but what is the final purpose of saving communication? Is it to achieve a lower regret within a shorter time horizon? If time is the most important thing, then by Figure 1,2, the performance of the proposed method is not as good as UCB-IBC.\n\n**Answer:** We acknowledge that this paper primarily delves into theoretical aspects, with the central focus on assessing the efficacy of communication cost reduction while maintaining near-optimal $O(K\\log T)$ regret, referred to as \"time\" in the reviewer's question. It is essential to clarify that the primary goal is not to minimize regret further, as prior works, including our own, have already achieved near-optimal regret levels. While empirical results indicate that the proposed algorithm's regret may not match that of UCB-IBC, it is noteworthy that both UCB-IBC and our algorithm attain the same $O(K\\log T)$ regret level."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503062987,
                "cdate": 1700503062987,
                "tmdate": 1700503062987,
                "mdate": 1700503062987,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uAyyCPrzzq",
                "forum": "ONnZVUrFBT",
                "replyto": "WC8awZnNSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Impact of Parameter $\\alpha$"
                    },
                    "comment": {
                        "value": "> Reviewer: I can see that from Theorem 2, a smaller alpha yields smaller regret. I can also see that from Figure 1,2, the proposed method has a higher regret compared to UCB-IBC. Therefore, I'm interested in the question of when we use smaller \n to achieve similar $\\alpha$ regret as UCB-IBC, will the number of communications of the proposed method still be much smaller?\n\n**Answer:** We note that our algorithm only needs constant communications, which are far less than the linear communication cost of UCB-ICB; it is impossible for our algorithm to beat UCB-ICB in terms of regret metric.\n      For another thing, there is indeed a trade-off of regret and communication in our algorithm ($\\texttt{SE-AAC-ODC}$) in terms of the parameter $\\alpha$. In Appendix D of the revised manuscript, we compare the performance of $\\texttt{SE-AAC-ODC}$ with $\\alpha=3$ and $\\alpha=6$ in Figure 6. This simulation validates the trade-off---the case of $\\alpha=3$ enjoys a better regret but suffers a higher communication. Additionally, the communications of both cases are much lower than that of other baseline algorithms."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503140155,
                "cdate": 1700503140155,
                "tmdate": 1700503140155,
                "mdate": 1700503140155,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2oAYYyOCAq",
                "forum": "ONnZVUrFBT",
                "replyto": "WC8awZnNSy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Intuition of Constant Communication"
                    },
                    "comment": {
                        "value": "> Reviewer: I'm quite interested in the property of constant communication. By Theorem 2, the authors show that the regret bound is closely related to T, but the number of communications is independent of T. This means that communication between agents is not so important and even if there are only a few communications, smaller\n      can still be achieved by using a large T. Can the authors intuitively explain the philosophy behind this property?\n\n**Answer:** The high-level intuition is that an agent only needs to know which arm is optimal to achieve sublinear regret in multi-armed bandits, and the communication cost of sharing this information (an arm index) is independent of the total number of decision rounds.\n      Therefore, if one fast agent (with a large number of active decision rounds) could somehow \"smartly\" find the optimal arm, then it only needs to pay a constant number of communications to disseminate the optimal arm index to all other agents."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700503204322,
                "cdate": 1700503204322,
                "tmdate": 1700503204322,
                "mdate": 1700503204322,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tNrh8C6HRh",
                "forum": "ONnZVUrFBT",
                "replyto": "2oAYYyOCAq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_andi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_andi"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your reply"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThank you for your reply and I read all of them. Unfortunately, I decided to keep my score. I agree that the proposed algorithm has a lower communication complexity, but it is valuable only if it can achieve lower communication costs when achieving the same regret compared to alternative methods such as UCB-ICB."
                    }
                },
                "number": 30,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646639996,
                "cdate": 1700646639996,
                "tmdate": 1700646639996,
                "mdate": 1700646639996,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6KgdFal4T6",
            "forum": "ONnZVUrFBT",
            "replyto": "ONnZVUrFBT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies cooperative asynchronous MABs, such that the arm pulls are asynchronous across the agents. The authors proposed a fully distributed algorithm (called SE-AAC-ODC) which achieves near-optimal regret with the number of communications independent of the time horizon. Furthermore, the algorithms are modified to achieve local differential privacy along with rigorous guarantees. Numerical simulations are also presented to compare the performance of their algorithm with the other known baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality\n------------------------------------------------------------------------------------------------------------\n- N/A\n_______________________________________________________________________\nQuality\n--------------------------------------------------------------------------------------------------------------\n- Analysis seems to be correct\n__________________________________________________________________________\nClarity\n---------------------------------------------------------------------------------------------------------------\n- Algorithm and analysis are clearly explained\n- The paper is well-written for the most part (minor concerns are mentioned in the Questions)\n________________________________________________________________________________\nSignificance\n---------------------------------------------------------------------------------------------------------------\n- The multi-agent asynchronous MAB considered in this paper is motivated by real-world applications (covered in detail in the Introduction) and could be of interest to the researchers studying multi-agent bandits"
                },
                "weaknesses": {
                    "value": "- **Lack of originality:** The algorithm and the analysis are extensions of known works in (Yang et. al. 2023) and (Chen et. al. 2023)\n\n- **Missing details in numerical simulations:** The algorithm AAE-ODC from (Chen et. al. 2023) uses a buffer threshold for messages communicated among the agents. There is no mention of the values of the buffer threshold used in AAE-ODC for the experiments presented in the paper\n________________________________________________________________________________________\n**Potentially misleading claim about the communication cost of the SE-AAC-ODC:**\n---------------------------------------------------------------------------------------------------------------------------------------------------\nThe authors claim that the communication cost of SE-AAC-ODC, which scales as $O(KM\\log \\Delta^{-1})$ is much smaller than that of (Chen et. al. 2023), in which the communication cost scales as $O(KM^2 \\Delta^{-2}\\log T)$ as claimed in this paper. However, the authors haven't mentioned all the details from (Chen et. al. 2023). Recall from the previous bullet that the algorithms in (Chen et. al. 2023) use buffer thresholds.\n- The communication cost scaling as $O(KM^2 \\Delta^{-2}\\log T)$ of the AAE-ODC algorithm in (Chen et. al. 2023) only holds when the buffer thresholds are constant with respect to the number of communications (ref: Corollary 1, part (b) in (Chen et. al. 2023)).\n- However, if the buffer thresholds are exponential with respect to the number of communications, the communication cost of the AAE-ODC algorithm in (Chen et. al. 2023) scales as $O\\big(M^2 \\log \\frac{K \\log T}{\\Delta^2}\\big)$ (ref: Corollary 2, part (b) in (Chen et. al. 2023)).\n\nI claim that when $K$ is very large (and $K > M$), the communication cost of the AAE-ODC algorithm in (Chen et. al. 2023) with the exponential buffer threshold is smaller than that of the communication cost of SE-AAC-ODC in this paper, unless the time horizon $T$ scales doubly exponentially in $K$. It can be quickly noticed by taking the ratio of the communication costs $\\frac{M^2 \\log \\frac{K \\log T}{\\Delta^2}}{KM\\log \\frac{1}{\\Delta}} = \\frac{M \\log \\frac{K \\log T}{\\Delta^2}}{K\\log \\frac{1}{\\Delta}}$, which is less than some small constant (ignoring other constants in the $O$ notation) for $T=O(\\exp (K^{-1}\\exp(K)))$ (assuming natural logarithm). This makes the constant communication cost of SE-AAC-ODC algorithm in this paper vacuous.\n\n- The preceding discussion also puts the validity of the numerical experiments into question."
                },
                "questions": {
                    "value": "- I encourage the authors to address the concerns in the Weaknesses section, in particular about the numerical results and misleading claim about the communication cost.\n- Can the authors also provide a lower bound on the communication cost of the asynchronous multi-agent MAB model considered in this paper?\n\nMinor Comments\n----------------------------------------------------------------------------------------------------------------------\n- In the Introduction, the authors have used $\\mathbb{N}^{+}$ for the set of natural numbers. The $+$ in the superscript is redundant, as natural numbers are positive by definition.\n- In the Related Work (Section 1.2), (Chawla et. al. 2020) considers gossip-style communication scheme as well, which isn't mentioned.\n- In the definition of the confidence radius in eq (1), Section 3.2.1, shouldn't it be $\\min (1, \\sqrt{\\frac{2 \\log T}{n}})$?\n- In Remark 10, the bound $\\frac{e^{\\epsilon}+1}{e^{\\epsilon}-1} \\leq 1 + \\frac{1}{\\epsilon}$ is incorrect. To check this, set $\\epsilon = 1$ and notice that the left hand side $> 2$ and the right hand side $= 2$. The correct bound is $\\frac{e^{\\epsilon}+1}{e^{\\epsilon}-1} \\leq 1 + \\frac{2}{\\epsilon}$. It can be proved by noticing that $\\frac{e^{\\epsilon}+1}{e^{\\epsilon}-1} - 1 = \\frac{2}{e^{\\epsilon}-1} \\leq \\frac{2}{\\epsilon}$, since $e^{\\epsilon}-1 \\geq \\epsilon$.\n________________________________________________________________________________________________________\nAfter detailed discussions with the authors, I have increased my score from 3 to 5."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7429/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7",
                        "ICLR.cc/2024/Conference/Submission7429/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7429/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698644762712,
            "cdate": 1698644762712,
            "tmdate": 1700608681004,
            "mdate": 1700608681004,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dGO61bEmTV",
                "forum": "ONnZVUrFBT",
                "replyto": "6KgdFal4T6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Novelty"
                    },
                    "comment": {
                        "value": "> Reviewer: Lack of originality: The algorithm and the analysis are extensions of known works in (Yang et. al. 2023) and (Chen et. al. 2023)\n\n**Answer:** We acknowledge the foundational role of Yang et al. (2023) and Chen et al. (2023) in our algorithmic design. However, our analysis significantly extends their work, addressing challenges unique to our setting.\n      On the one hand, the analysis of Chen et al. (2023) cannot be used in our case, as we are aiming for a constant communication upper bound, which is intrinsically different from their time-dependent bounds.\n      On the other hand, the analysis tool in Yang et al. (2023) relies heavily on the synchronous multi-agent setting (agents always have the same number of samples), which is invalid in our asynchronous setting. In this paper, we develop a new analysis approach that relies on the ''fastest'' agent (with the highest number of active decision rounds, see Lemma 1).\n      We refer the reviewer to Section 1.2 (related works) for a more comprehensive discussion about how this work differs from (Yang et al. 2023) and (Chen et al. 2023)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502571115,
                "cdate": 1700502571115,
                "tmdate": 1700502571115,
                "mdate": 1700502571115,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KwBJLe1irZ",
                "forum": "ONnZVUrFBT",
                "replyto": "6KgdFal4T6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Details in Numerical Simulations"
                    },
                    "comment": {
                        "value": "> Reviewer: Missing details in numerical simulations: The algorithm AAE-ODC from (Chen et. al. 2023) uses a buffer threshold for messages communicated among the agents. There is no mention of the values of the buffer threshold used in AAE-ODC for the experiments presented in the paper\n\n**Answer:** For the experiments in the main paper, we set the buffer of $\\texttt{SE-ODC}$ ($\\texttt{AAE-ODC}$) as constant $1$ (that is, immediately communicate when there is a demand without any buffer). In Figure 5 of Appendix D, we report the $\\texttt{SE-ODC}$ with no buffer (green), and $\\texttt{SE-ODC-D}$ with doubling buffer (brown) and compare both to our algorithm, $\\texttt{SE-AAC-ODC}$ (red).\n      Although $\\texttt{SE-ODC-D}$ with doubling buffer enjoys better communication performance than $\\texttt{SE-ODC}$ with constant buffer, $\\texttt{SE-ODC-D}$'s communication performance is still worse than that of $\\texttt{SE-AAC-ODC}$ proposed in our paper, and $\\texttt{SE-ODC-D}$'s empirical regret is far worse than $\\texttt{SE-AAC-ODC}$, which is because $\\texttt{SE-ODC-D}$'s regret upper bound $O(KM\\log T)$ is intrinsically worse than our algorithm's $O(K\\log T)$ regret upper bound.\n      We updated these additional simulation results in the revised version of this paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502664840,
                "cdate": 1700502664840,
                "tmdate": 1700502664840,
                "mdate": 1700502664840,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4ZmE4Qdm4y",
                "forum": "ONnZVUrFBT",
                "replyto": "6KgdFal4T6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Comparing Communication Cost of SE-AAC-ODC to (Chen et al., 2023)"
                    },
                    "comment": {
                        "value": "> Reviewer: Potentially misleading claim about the communication cost of the SE-AAC-ODC:\n\n**Answer:** It is unfair to compare the result in Corollary 2(b) (Chen et al., 2023) with our algorithm.\n      This is because the result in Corollary 2(b) (Chen et al., 2023) only holds when the buffer thresholds are exponential  (e.g., doubling in $\\texttt{SE-ODC-D}$ in the above simulation).\n      But if the buffer thresholds are exponential, the algorithm in Chen et al. (2023) suffers a $O(KM\\log T)$ regret which is away from the near-optimal regret by a factor of the number of agents $M$ (see their regret upper bound's second term in Theorem 1 (b)).\n      In fact, this $O(KM\\log T)$ regret upper bound can be achieved by all agents individually running UCB *without any communication*.\n      Hence, it is unfair to compare the result in Corollary 2(b) (Chen et al., 2023) with our algorithm that always achieves the near-optimal $O(K\\log T)$ regret."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502818167,
                "cdate": 1700502818167,
                "tmdate": 1700502818167,
                "mdate": 1700502818167,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "h103ugKyyz",
                "forum": "ONnZVUrFBT",
                "replyto": "6KgdFal4T6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Communication Lower Bound"
                    },
                    "comment": {
                        "value": "> Reviewer: Can the authors also provide a lower bound on the communication cost of the asynchronous multi-agent MAB model considered in this paper?\n\n**Answer:** \n      Providing a non-trivial lower bound for communication in asynchronous multi-agent MAB settings is highly challenging and remains an open problem in the literature.\n      This is because some extremely asynchronous scenarios could make communication unnecessary. For example, consider the case that one agent is active in all time slots, while all other agents are only active in one single time slot.\n      In this case, there is no need to conduct communication among these agents, that is, one can achieve near-optimal regret by all agents individually running UCB without any communication.\n\nOn the other hand, the only related communication lower bound results that we are aware of is in Wang et al. (2020, Section 3.4), where they show that to achieve a $o(M\\sqrt{KT})$ regret upper bound in *synchronous* multi-agent MAB, the expected communication is at least $\\Omega(M)$.\n      If we exclude the extreme cases and only consider mildly asynchronous scenarios, then the $\\Omega(M)$ lower bound\n      could be used to understand the tightness of our communication upper bound.\n      That implies that\n      our communication upper bound $O(KM\\log(\\Delta^{-1}))$ is tight in terms of the number of agents $M$.\n      \nIn a word, proving a non-trivial communication lower bound is challenging and beyond the scope of this work. Comparing with known results suggests that our communication upper bound is tight in terms of $M$.\n\n\n\n---\n- Yuanhao Wang, Jiachen Hu, Xiaoyu Chen, and Liwei Wang. Distributed bandit learning: Near\u0002optimal regret with efficient communication. In 8th International Conference on Learning Rep\u0002resentations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020, 2020b."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502871456,
                "cdate": 1700502871456,
                "tmdate": 1700502871456,
                "mdate": 1700502871456,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DciCXbuQ2P",
                "forum": "ONnZVUrFBT",
                "replyto": "6KgdFal4T6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Minor Comments"
                    },
                    "comment": {
                        "value": "We highly appreciate the reviewer for suggesting other minor changes. All were addressed in the revised version, except for $\\mathbb{N}^+$. Because whether the natural number contains zero is ambiguous (see the first sentence of the nature number on the Wikipedia page), the authors think it would be better to use $\\mathbb{N}^+$ to avoid misunderstanding."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502910036,
                "cdate": 1700502910036,
                "tmdate": 1700502910036,
                "mdate": 1700502910036,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0Blahv70Ni",
                "forum": "ONnZVUrFBT",
                "replyto": "4ZmE4Qdm4y",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the detailed justifications to my concerns and questions. I saw the second term in Theorem 1(b) in (Chen et. al. 2023), and I am still not convinced with the response provided by the authors. This is because from Theorem 1(b) in (Chen et. al. 2023), the scaling of $G_{i}^{j}$ in the second term isn't clear when the buffer thresholds are exponential with respect to the number of communications. Even though the empirical results provided by the authors for the doubling buffer in AAE-ODC support their assertion, this is a theory paper. So, I would like to see whether $G_{i}^{j} = \\frac{16 \\alpha \\log T}{\\Delta_{i}^{2}}$ for any choice of exponent while using the exponential buffer in Theorem 1(b) in (Chen et. al. 2023). This is because if there exists some choice of exponent for the exponential buffer such that $G_{i}^{j}$ is a constant dependent only on system parameters and independent of time $T$, then my assessment will stand as is."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700508511785,
                "cdate": 1700508511785,
                "tmdate": 1700508511785,
                "mdate": 1700508511785,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NwNUe3Hfst",
                "forum": "ONnZVUrFBT",
                "replyto": "JGc2ICcCGD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "content": {
                    "title": {
                        "value": "Follow up"
                    },
                    "comment": {
                        "value": "1. Minor comment: isn't $G_{i}^{j} = \\min \\\\{\\sum_{j' \\in \\mathcal{A} \\backslash j} f(c_{\\tau_{i}}^{j' \\rightarrow j}), \\frac{16 \\alpha \\log T}{\\Delta_{i}^{2}}\\\\}$? The $8$ seems to be a typo.\n2. How do you bound $c_{\\tau_{i}}^{j' \\rightarrow j}$ in the second step? Is it tight?\n3. What is the value of $M$ (# of agents) in Figure 5 (SE-ODC with doubling buffer) in the appendix, section D?"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700599690375,
                "cdate": 1700599690375,
                "tmdate": 1700599690375,
                "mdate": 1700599690375,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zZEqQMT02L",
                "forum": "ONnZVUrFBT",
                "replyto": "aGolSM3Vyw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarification. From Theorem 2, it is clear that there is a regret communication trade-off, dictated by the threshold parameter $\\alpha$ (when $\\alpha$ is large, less communication but large group regret and vice-versa when $\\alpha$ is small). I agree that the trade-off between communication and group regret is unavoidable. However, the communication parameter $\\alpha$ affects the leading order $\\log T$ term in group regret. For example, if $\\alpha = O(\\log T)$, the group regret of the proposed algorithm scales as $O((\\log T)^3)$, which is bad and the regret optimality (mentioned in Remark 3) does not hold anymore. Based on the results, it raises the question of whether we can come up with another algorithm which achieves constant communication while impacting only the time independent terms (or \"constant\" as used by the authors) in group regret. If that is not achievable, I am back to my question of lower bound on the number of communications. Hence, I keep my score."
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700605571133,
                "cdate": 1700605571133,
                "tmdate": 1700605571133,
                "mdate": 1700605571133,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "n1564f5sad",
                "forum": "ONnZVUrFBT",
                "replyto": "nOiyqmiwj7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "content": {
                    "comment": {
                        "value": "The SE-AAC-ODC algorithm does not achieve near optimal regret for all values of $\\alpha$. I refer the authors to the case of $\\alpha = \\log T$ (I can choose any value for $\\alpha$ as long as $\\alpha > 1$, right?) which I mentioned in my previous comment."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607435160,
                "cdate": 1700607435160,
                "tmdate": 1700607435160,
                "mdate": 1700607435160,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "k4HXkdPtwB",
                "forum": "ONnZVUrFBT",
                "replyto": "6KgdFal4T6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Reviewer_Ttd7"
                ],
                "content": {
                    "comment": {
                        "value": "Fair enough, although the dependence of communication parameter $\\alpha$ on the leading order term $\\log T$ in group regret (as $(1 + \\alpha)^2$) isn't ideal in my opinion. I am raising my score to 5, but can't vouch for acceptance of the paper because of the aforementioned concern."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700608593210,
                "cdate": 1700608593210,
                "tmdate": 1700608799872,
                "mdate": 1700608799872,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jJepp8dOHU",
            "forum": "ONnZVUrFBT",
            "replyto": "ONnZVUrFBT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7429/Reviewer_vstV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7429/Reviewer_vstV"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors study the cooperative asynchronous multi-agent multi-armed bandits problem, where the active agents in each round are unknown in advance. The authors propose a new algorithm with Accuracy Adaptive Communication (AAC) protocol that achieves near-optimal regret and requires communication rounds that are independent of time. The proposed approach is shown to be superior in terms of communication rounds through synthetic data."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The paper is well-written, easy to follow, and well-organized.\n* Compared to previous work [1], the authors propose a novel and superior Successive Elimination (SE) algorithm with Accuracy Adaptive Communication (AAC) protocol. The proposed algorithm achieves constant communication rounds, which are independent of time complexity. This is a significant advantage for real-world applications.\n* The proposed algorithm is easy to implement and has the potential to be applied to a wide range of real-world applications.\n* Synthetic data experiments show that the proposed algorithm outperforms existing algorithms in terms of communication rounds.\n\n[1] Yu-Zhen Janice Chen, Lin Yang, Xuchuang Wang, Xutong Liu, Mohammad Hajiesmaili, John C.S.\nLui, and Don Towsley. On-demand communication for asynchronous multi-agent bandits. In\nInternational Conference on Artificial Intelligence and Statistics, pp. 3903\u20133930. PMLR, 2023."
                },
                "weaknesses": {
                    "value": "* The proposed algorithm is not validated with real-world data.\n* The authors do not provide a lower bound for the number of communication rounds required, which makes it difficult to assess the performance of the proposed algorithm."
                },
                "questions": {
                    "value": "Typos:\n\n1.1 Success Elimination -> Successive Elimination"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7429/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698700789467,
            "cdate": 1698700789467,
            "tmdate": 1699636891541,
            "mdate": 1699636891541,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GzQUSlrd2m",
                "forum": "ONnZVUrFBT",
                "replyto": "jJepp8dOHU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Real-World Data in Simulation"
                    },
                    "comment": {
                        "value": "> Reviewer: The proposed algorithm is not validated with real-world data.\n\n**Answer:** In numerical experiments, we set arm reward means as the click-through-rate from an ad-click Kaggle dataset (Avito Context Ad Clicks, 2015. https://www.kaggle.com/c/avito-context-ad-clicks), which simulates the real click-through process in online advertising applications. We updated this in the revised manuscript."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502292338,
                "cdate": 1700502292338,
                "tmdate": 1700502353429,
                "mdate": 1700502353429,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "V6ygXthQaZ",
                "forum": "ONnZVUrFBT",
                "replyto": "jJepp8dOHU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7429/Authors"
                ],
                "content": {
                    "title": {
                        "value": "On Communication Lower Bound"
                    },
                    "comment": {
                        "value": "> Reviewer: The authors do not provide a lower bound for the number of communication rounds required, which makes it difficult to assess the performance of the proposed algorithm.\n\n**Answer:** \n      Providing a non-trivial lower bound for communication in asynchronous multi-agent MAB settings is highly challenging and remains an open problem in the literature.\n      This is because some extremely asynchronous scenarios could make communication unnecessary. For example, consider the case that one agent is active in all time slots, while all other agents are only active in one single time slot.\n      In this case, there is no need to conduct communication among these agents, that is, one can achieve near-optimal regret by all agents individually running UCB without any communication.\n\nOn the other hand, the only related communication lower bound results that we are aware of is in Wang et al. (2020, Section 3.4), where they show that to achieve a $o(M\\sqrt{KT})$ regret upper bound in *synchronous* multi-agent MAB, the expected communication is at least $\\Omega(M)$.\n      If we exclude the extreme cases and only consider mildly asynchronous scenarios, then the $\\Omega(M)$ lower bound\n      could be used to understand the tightness of our communication upper bound.\n      That implies that\n      our communication upper bound $O(KM\\log(\\Delta^{-1}))$ is tight in terms of the number of agents $M$.\n      \nIn a word, proving a non-trivial communication lower bound is challenging and beyond the scope of this work. Comparing with known results suggests that our communication upper bound is tight in terms of $M$.\n\n\n\n---\n- Yuanhao Wang, Jiachen Hu, Xiaoyu Chen, and Liwei Wang. Distributed bandit learning: Near\u0002optimal regret with efficient communication. In 8th International Conference on Learning Rep\u0002resentations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020, 2020b."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7429/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502493759,
                "cdate": 1700502493759,
                "tmdate": 1700502493759,
                "mdate": 1700502493759,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]