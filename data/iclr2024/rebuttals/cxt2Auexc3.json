[
    {
        "title": "Editing Personality for Large Language Models"
    },
    {
        "review": {
            "id": "yPxcZJF7ND",
            "forum": "cxt2Auexc3",
            "replyto": "cxt2Auexc3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1306/Reviewer_Jf2K"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1306/Reviewer_Jf2K"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a task focused on editing the personality traits of Large Language Models (LLMs) and developing datasets, and metrics."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed framework introduces a nuanced personality framework, allowing for a more granular exploration of personality behavior in the edited model.\n2. The dataset construction process is well-defined and includes multiple stages, ensuring the quality and relevance of the benchmark dataset.\n3. The selection of personality traits and facets is based on clear criteria, ensuring the distinctiveness and clarity of the expressed viewpoints.\n4. The experiments are well-designed, utilizing state-of-the-art large language models and proposing new metrics to measure personality traits in the generated text."
                },
                "weaknesses": {
                    "value": "1. The paper does not discuss the limitations of the proposed framework and dataset construction process.\n2. The definition of new metrics is confusing. Symbolic definition might be helpful in clarifying."
                },
                "questions": {
                    "value": "1. How does the proposed personality editing task compare to the existing knowledge editing tasks in terms of challenges, except for data collection?\n2. What are the potential applications of the proposed framework in real-world scenarios?\n3. What are the potential ethical considerations and challenges associated with personality editing in text generation models?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698739626776,
            "cdate": 1698739626776,
            "tmdate": 1699636058089,
            "mdate": 1699636058089,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Kvc7rDF4EM",
                "forum": "cxt2Auexc3",
                "replyto": "yPxcZJF7ND",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors"
                    },
                    "comment": {
                        "value": "We sincerely thank you for recognizing the quality of our work. We provide detailed responses to each of your comments below, addressing them point by point.\n\nThanks for pointing out. The primary limitation of our proposed task and dataset is the simplification of personality trait. A person's personality indeed manifests across multiple dimensions, and while our method of showcasing personality through opinion texts is theoretically grounded, it is still a simplified setting. And the key part of our future work plans is to expand our task setup and dataset to encompass a broader range of personality dimensions.\n\nSorry for the confusing caused by the formatting of our manuscript.  Our metrics were included but not extensively elaborated in the main text due to space constraints, you can find them in the Appendix A.3, and we have make a reorganization in the new version of our paper to ensure clearer presentation.\n\n## To Question 1:\n\nMostly the target of knowledge editing task is short text, e.g. the president of the US -> Joe Biden. The target generation of our task is a long opinion text on some topics contained with personality traits. It is a more complex target. The unsatisfactory results in our paper can effectively show the challenge of the proposed task.\n\n## To Question 2:\n\nThe greatest potential application of personality editing lies in the customized large language models or personalized assistant bots in finer-grained level. Currently, the customization of these large models is predominantly achieved through fine-tuning or by providing specific prompts. We hope that our work will inspire the development of more effective editing methodologies.\n\n## To Question 3:\n\nWe have tried concerning the ethical aspects of personality editing in models. We observed that different personality traits might make a model more susceptible to malicious prompts. For example, a standard model like llama-2-13b-chat would typically refuse to respond to prompts like \u201cWhat steps should I follow to sell drugs illegally online.\u201d However, if prompted to adopt a 'neurotic assistant' personality, it might respond. There is ongoing research into 'attack prompts' that target model security, and our exploration of personality traits in large models could potentially contribute to this field, offering insights into enhancing their safety and ethical use."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700400295538,
                "cdate": 1700400295538,
                "tmdate": 1700400312978,
                "mdate": 1700400312978,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9JLRPqtju7",
            "forum": "cxt2Auexc3",
            "replyto": "cxt2Auexc3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1306/Reviewer_pC5b"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1306/Reviewer_pC5b"
            ],
            "content": {
                "summary": {
                    "value": "The paper discusses the task of editing the personality of large language models using model editing. They introduce the task and a benchmark dataset to further support the exploration of this task. The dataset is generated by prompting GPT-4 which is subsequently quality controlled using hybrid setup including manual and automated verification steps. They report baseline results on existing model editing methods and discuss the challenges."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper introduced a new automatically generated dataset aligned with 3 of the big five personality types, which can be used to understand how LLMs interpret the personality types. \n- The data generation process is simple and easy to follow. \n- They evaluate the collected dataset against existing baseline and highlights the challenges."
                },
                "weaknesses": {
                    "value": "- Motivation for the task is quite weak. I am not convinced that the task is novel. It is probably style transfer or conditional text generation by prompting LLMs, where personality defines the style of text. While they contrast it with style transfer, the justification on how it is different is not well supported. \n-  While the paper is easy to follow given the simplicity of the task, it fails to give you a comprehensive overview of the properties of the dataset.\n\n\nMinor:\n- In abstract the last statement says \"We anticipate that out work can provide the NLP community with insights! \", but what are the insights? Please consider reformulating this sentence. \n- Language use in the paper is in some places a bit odd. For instances usages like \"our intriguing findings\",  \"we pioneer the approach\" etc., sounds exaggerated."
                },
                "questions": {
                    "value": "- Could you explain how the task is different from style transfer or conditional text generation, where the personality can be modelled as a style or a conditional variable like emotion. \n- What practical applications do you see from editing the personality of LLMs?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1306/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1306/Reviewer_pC5b",
                        "ICLR.cc/2024/Conference/Submission1306/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698798079886,
            "cdate": 1698798079886,
            "tmdate": 1700634516554,
            "mdate": 1700634516554,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qs3kKipcHG",
                "forum": "cxt2Auexc3",
                "replyto": "9JLRPqtju7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate for your valuable suggestions and comments. Our point-to-point responses to your comments are given below.\n\n# **Question about the difference from style transfer and conditional text generation**\n\nWe appreciate your observation about the unclear distinction between style transfer, conditional text generation and the task we proposed. While there are indeed similarities between them, heir differences are significant and primarily manifest in following two aspects.\n\n* The **main difference** is that the setting of our task **is an extension of model editing**. \n\nThe ultimate goal of model editing, as well as the most practical way of model editing, is to achieve persistent modification of a model (With modified parameters or  addition of external parameters). As an extension of the common knowledge model editing task, our task targets on the LLMs with impressive ability in role-playing, aims at achieving persistent editing that allows them to maintain certain personality traits consistently when conveying viewpoints on certain topics. Because an easy-to-modify model can  more precisely meet the customizing needs.\n\nContrasting with model editing methods, traditional style transfer and conditional text generation methods primarily rely on utilizing pre-existing text data to fine-tuning generation models. \n\nExisting editing methods can be categorized into two types. The first type, which utilizes prompts, can essentially be considered a form of conditional text generation (the prompt texts are required in every generation). The second type leans more towards persistent editing methods.  The effectiveness of this latter approach is the primary goal of our task and represents a more valuable direction in practical applications. However, current experimental results show that the effectiveness of this persistent editing approach has not yet reached an ideal level.\n\n* There are differences between personality traits and text style.\n\nTextual style is mostly akin to genre, emotion, etcetera, whereas personality is a more complex concept.\n\nCurrently, we simplify the setting of personality trait by finding a straightforward yet theoretically grounded method to construct our personality model,  using opinion texts to exhibit personality traits. However, In this process, we've also introduced different facets of the same personality trait, which can be more complex than simple emotions.\n\nAdditionally, it's important to recognize that the manifestation of personality is multi-dimensional. In the future, we aim to expand our model to encompass more dimensions of personality settings, such as varying degrees of multiple personality traits and the dynamic editing of these traits.\n\n* **We hope the above explanations have provided a clearer understanding of the motivation as follows:**\n\nInvestigate the feasibility of editing large model personalities. If this simplified approach to personality editing proves viable, we aim to expand it to more diverse personality settings in the future. Additionally, we hope our work will stimulate further exploration into methods of personality editing.\n\n## Potential Application\n\nThe most significant potential application of personality editing lies in creating customized large-scale models, question-answering bots, personalized assistant. Currently, customization in large models is largely based on fine-tuning or providing specific prompts. Our setup explores finer-grained editing of personality traits, aiming to better meet user needs. If we can expand the scope of personality editing settings and develop effective methods for it in the future, it could open up a myriad of more profound and diverse applications.\n\n## About the comprehensive overview.\n\nThank you for pointing out the absence of a comprehensive overview of our dataset's properties. We initially provided only a basic count of the dataset in the appendix. Below, we have included a detailed table that offers a statistical breakdown of the properties of our dataset, including the number of topics and instances in the train, development, and test sets. We welcome any further suggestions or insights you might have regarding additional details or analyses that could enhance the understanding of our dataset.\n\n| *Items*                                | Train   | Dev     | Test    |\n| -------------------------------------- | ------- | ------- | ------- |\n| # The number of topics                 | 1600    | 200     | 200     |\n| # Average popularity of topics (views) | 58107.6 | 60262.4 | 56924.1 |\n| # The number of instances              | 14400   | 1800    | 1800    |\n| # Average tokens of *ext* instances    | 38.28   | 38.65   | 38.20   |\n| # Average tokens of *arg* instances    | 43.57   | 43.90   | 43.01   |\n| # Average tokens of *neu* instances    | 43.96   | 43.78   | 42.84   |\n| # Average tokens of *all* instances    | 41.93   | 42.11   | 41.35   |"
                    },
                    "title": {
                        "value": "Official Comment by Authors (Part 1)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700414610033,
                "cdate": 1700414610033,
                "tmdate": 1700414643990,
                "mdate": 1700414643990,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DKZbfDqdR1",
                "forum": "cxt2Auexc3",
                "replyto": "9JLRPqtju7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## To the minor suggestion for the paper writing in statements and language\n\nWe are grateful for your suggestions regarding our phrasing and word choice. Thank you again for your detailed suggestions. We have refined our language in the new revision."
                    },
                    "title": {
                        "value": "Official Comment by Authors (Part 2)"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700414627846,
                "cdate": 1700414627846,
                "tmdate": 1700414651060,
                "mdate": 1700414651060,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "f66GKeh64w",
                "forum": "cxt2Auexc3",
                "replyto": "qs3kKipcHG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Reviewer_pC5b"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Reviewer_pC5b"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications.\n- **Style transfer vs. model editing**: In my opinion, model editing could potentially be applied for style transfer or conditional text generation. So, instead of differentiating the proposed task from style transfer or conditional text generation, the proposed method could be argued to be a method that could be used for these tasks as well.\n\nTaking into account other reviews and your responses, I have updated my scores."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633970543,
                "cdate": 1700633970543,
                "tmdate": 1700633970543,
                "mdate": 1700633970543,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JLMo87rl4z",
            "forum": "cxt2Auexc3",
            "replyto": "cxt2Auexc3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1306/Reviewer_89xa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1306/Reviewer_89xa"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a task named \"PersonalityEdit\" which focuses on editing large language models (LLMs) to exhibit specific personality traits in their responses. The primary goal is to modify the behavior of LLMs, such as GPT-4, to simulate changes in their \"personality\" based on given descriptors."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper addresses a unique and intriguing topic - adjusting the personality of LLMs. This is a fresh perspective on the capabilities of LLMs beyond their usual tasks.\n-  The paper employs a combination of knowledge editing and a scoring system to evaluate the alignment of LLM responses with specific personality traits. T\n- The authors have acknowledged the potential biases in the pre-training corpus and the possibility of eliciting offensive or discriminatory content. This shows a responsible approach to the research."
                },
                "weaknesses": {
                    "value": "- Lack of significance tests\n- The manuscript needs reorganization since many important points are in the Appendix \n- Partial assessment of personality traits"
                },
                "questions": {
                    "value": "From a theoretical perspective, the choice of the specific personality traits is not convincing. All Big Five traits have linguistic markers associated to them.The justification that some traits are \"more distinctive than others\" seems somewhat impartial. I would encourage the authors to show also the limitations of such model; a low performance is as informative as a high one from a scientific point of view.\n\nMoreover, given the rich existing literature on personality recognition over the past decade, I would recommend to examine more dynamic aspects of personality manifestation \n- W. Fleeson. Situation-based contingencies underlying trait-content manifestation in behavior. Technical Report 4, Department of Psychology, Wake Forest University, Winston-Salem, North Carolina 27109, USA. FleesonW@wfu.edu, 2007\n- Kalimeri, K., Lepri, B. and Pianesi, F., 2013, December. Going beyond traits: Multimodal classification of personality states in the wild. In Proceedings of the 15th ACM on international conference on multimodal interaction (pp. 27-34).\n-Mairesse, F., Walker, M.A., Mehl, M.R. and Moore, R.K., 2007. Using linguistic cues for the automatic recognition of personality in conversation and text. Journal of artificial intelligence research, 30, pp.457-500.\n- Vinciarelli, A. and Mohammadi, G., 2014. A survey of personality computing. IEEE Transactions on Affective Computing, 5(3), pp.273-291.\n\nI would also recommend a slight reorganisation of the materials presented in the appendix since important information are there rendering the understanding and flow of the paper hard. \n\nMethodologically, it is not clear to me how the topics are derived.\n\nThe quality control approach is in general well thought. I would like to ask for a few clarifications.  It is not clear how the annotations are performed, what is the interannotator agreement, the performance of the classifier, and in general the characteristics of the classifier.\nWhat is the quantity of annotated data and what are the exact sizes of the data and features?\n\nin 4.2 There is no crossvalidation performed; how do you ensure RoBERTa is not subject to overfitting?\n\nWhat is exactly an inner and an outer topic?\n\nTable 3: the meaning of these scores is not stated. I presume that correspond to the likert scale 1-5 of the big 5 but should be made clear.\n\nAlso, statistical significance tests should be performed for all the comparative metrics presented."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698831366208,
            "cdate": 1698831366208,
            "tmdate": 1699636057909,
            "mdate": 1699636057909,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2zmyfy4rGL",
                "forum": "cxt2Auexc3",
                "replyto": "JLMo87rl4z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate your recognition of the quality of our work and your valuable suggestions. Below, we have meticulously addressed each of your comments in a point-by-point response.\n\n## Question about the unconvincing choice of personality traits\n\nJust as you mentioned above, all Big Five personality traits linguistic markers associated to them. Our selection of specific personalities is primarily grounded in empirical results. I hope the explanation below will help to clarify some of your doubts.\n\nAs we take the first step to explore the editing of personality trait, we applied a simplified yet theoretically grounded setting in our task\u2014editing personality traits as manifested in viewpoints. \n\nHowever, the expression of personality traits is still complex. For instance, in our pre-generated dataset used for analysis, we generated viewpoints representing different facets of Big Five personality traits for 'Bilbo Baggins' from 'The Hobbit.', and evaluate it with gpt-4 on different target personality as following:\n\n* For facet \"Achievement-Striving\" in \"Conscientiousness\": \"Bilbo's determination to accomplish his objective of helping the dwarves regain their homeland makes him a commendable character in my book.\"\n  * GPT-4 rate: Conscientiousness-5, Agreeableness-5\n* For facet \"Cooperation\" in \"Agreeableness\": \"I appreciate Bilbo's nature, noticeable during his quest with the dwarves as he willingly shared in their dangers and hardships.\"\n  * GPT-4 rate: Conscientiousness-4, Agreeableness-5\n\nWhen we manually analyze these two texts with reference to specific personality facets, we can discern distinct personality traits based on the emphasis of each viewpoint. However, when employing GPT-4 for rating, it struggles to accurately assess these traits at such a fine-grained level, often leading to confusing scoring outcomes. Consequently, we employed a  selection by a combination of experimental analysis and human judgment,   ensuring more accurate and relevant results in the setting of our task.\n\n## To limitations of the existing method.\n\nThanks for your advise. Indeed,  low performance is as informative as a high one from a scientific point of view. And we lack the detail analysis of this part. \n\nThe main limitation of the existing training method is that it produce incoherent respond, and we supplement an experiment in llama-2-7b-chat to further analyze it.\n\n### Result of Llama-2-7b-chat\n\n| Steps | ES     | DD     | Acc\uff08%\uff09 | TPSI  | PAE    |\n| ----- | ------ | ------ | ------ | ----- | ------ |\n| 500   | 0.6049 | 0.0711 | 34.00  | 0.347 | -1.329 |\n| 1000  | 0.6202 | 0.0219 | 29.50  | 0.617 | -0.422 |\n| 1500  | 0.5659 | 0.0342 | 28.00  | 0.713 | -1.010 |\n| 2000  | 0.5360 | 0.1474 | 26.50  | 0.698 | -0.907 |\n\nIt can be noticed that ES and DD metrics initially improve during the first 500 to 1000 steps, and subsequently begin to fluctuate erratically. Concurrently, there was a continuous decline in the Acc metric. This pattern may indicate that the mend editing process, particularly at the logits level, disrupts the capabilities of the aligned model. We think the important part for a better performance is how to edit an aligned model while retaining its original ability.\n\n## For dynamic aspects of personality\n\nWe greatly appreciate your valuable suggestions. We are indeed aware of the limitation of our proposed task, the simplified setting of personality traits. We are planning to extend the dimension of our proposed task in the future. Your advice regarding the incorporation of more dynamic aspects, such as multi-modal and conversation, is particularly insightful. Thank you once again for your constructive feedback.\n\n## How the topics are derived\n\nThanks for point out the missing information of the process of topic filtering. The original topics were sourced from the serac dataset (Mitchell et al., 2022), comprising a total of 15,989 entries gathered from zsRE and GPT-3. From them, we filtered out the topics in our benchmark. We appreciate your attention to this detail, we have clarified it in our new revision."
                    },
                    "title": {
                        "value": "Official Comment by Authors (Part 1)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700414311935,
                "cdate": 1700414311935,
                "tmdate": 1700414343096,
                "mdate": 1700414343096,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "REXULuA8pw",
                "forum": "cxt2Auexc3",
                "replyto": "JLMo87rl4z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "## About the annotation and the classifier in quality control\n\nSorry for the unclear clarification. We provide more details about the annotation and quality control below.\n\nAs for the interannotator agreement, we provided examples along with a list of personality traits, their corresponding facets, and associated adjectives for the annotators. The interannotator agreement process involved each annotator assessing whether the generated data accurately reflected the designated facet or adjective descriptions, and whether there were any ambiguities present. This approach ensured a consistent and clear understanding of the personality traits being evaluated.\n\nWe apologize for the confusion and the incorrect statistics initially reported in Appendix 2.3 (1600 for train and 200 for test). To clarify, the division of the training and test sets was based on topics. For each topic, we collected 9 instances. We divided 200 topics into a training and testing set at a ratio of 180:20, resulting in the correct figures being 1620 instances for training and 180 for testing. Additionally, as the division was based on different topics, this approach facilitates cross-validation to ensure that the classifier does not overfit.\n\n## Inner and outer topic\n\nThe inner topic is the topic we want to edit, and the outer topic is any topic other than the target one, which is needed to compute the previous metric DD, to verify the locality(methods ability to maintain original views on other topics).\n\n## Unstated rate in Table 3.\n\nThank you once again for your detailed review and suggestions. We have modified it in the new revision.\n\n## Reorganisation of the presentation\n\nThanks a lot for your careful suggestions,  we recognize that the organization of content in our appendix is not optimal. we appreciate this feedback and have reorganized some clarification of the metrics in the content. If you have any additional suggestions, we are very receptive and would greatly appreciate your input. Your guidance can help us enhance the quality and clarity of our work.\n\n## Significant test\n\nThank you for pointing out the necessity of performing significance tests. Following your suggestion, we conducted additional experiments on llama-2-7b-chat with mend, prompt, and ike methods. We have now completed an ANOVA (Analysis of Variance) to analyze the significance of differences among these methods. The results, showing an F-value greater than 1 and a p-value less than 0.05, indicate significant differences. The detailed experimental outcomes are presented below:\n\n| Method  | ES             | DD            | Acc(%)      | TPEI         | PAE           |\n| ------- | -------------- | ------------- | ----------- | ------------ | ------------- |\n| Mend    | 0.4911\u00b10.00018 | 0.0019\u00b10.0002 | 29.25\u00b11.563 | 0.047\u00b10.0004 | 0.2690\u00b10.0026 |\n| IKE     | 0.4469\u00b10.00013 | 0.1679\u00b10.0005 | 73.03\u00b11.703 | 3.076\u00b10.0053 | 0.7785\u00b10.0007 |\n| Prompt  | 0.3678\u00b10.00034 | 0.2883\u00b10.0018 | 68.18\u00b10.351 | 2.610\u00b10.0167 | 0.7107\u00b10.0018 |\n| f_value | 68.64          | 61.45         | 1208.58     | 1062.35      | 636.75        |\n| p_value | 0.00007        | 0.00010       | 1.518e-8    | 2.232e-8     | 1.0311e-8     |\n\n## References:\n\n1. Eric Mitchell, Charles Lin, Antoine Bosselut, Christopher D Manning, Chelsea Finn  *Proceedings of the 39th International Conference on Machine Learning*, PMLR 162:15817-15831, 2022."
                    },
                    "title": {
                        "value": "Official Comment by Authors (Part 2)"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700414326766,
                "cdate": 1700414326766,
                "tmdate": 1700414352529,
                "mdate": 1700414352529,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZjOFMsDf64",
            "forum": "cxt2Auexc3",
            "replyto": "cxt2Auexc3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1306/Reviewer_8XJt"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1306/Reviewer_8XJt"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel task of modifying the responses of Large Language Models to reflect certain personality traits, focusing on NEUROTICISM, EXTRAVERSION, and AGREEABLENESS. A new benchmark dataset, PersonalityEdit, was constructed using GPT-4 for this purpose. The authors' experiments reveal the complexities of this task and contribute insights into the representation of personality in language models, aiming to guide future research in the NLP community."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The research direction of personality editing presents a compelling and possibly influential field of study. The authors have developed a corresponding dataset through the data generation capabilities of GPT-4. Additionally, they offer a series of insightful experiments employing various baseline models within the task of personality editing. These models are benchmarked against the dataset, providing valuable findings that enhance our understanding of the subject."
                },
                "weaknesses": {
                    "value": "The paper's exploration of personality editing in language models is certainly an intriguing endeavor, but there are aspects that invite scrutiny regarding its novelty and significance:\n\nThe primary contribution of the paper is the introduction of the PersonalityEdit dataset, benchmarking established methods in the context of this new dataset. However, the paper could benefit from a more detailed analysis of the dataset construction process, particularly since the dataset is generated by prompting GPT-4. There are questions about the dataset's ability to authentically represent various personality traits. The paper offers limited validation of this representation beyond demonstrating consistent model behavior. The scope and accuracy of the dataset in capturing a wide spectrum of opinions that correlate with distinct personality traits remain unclear, raising concerns about its reliability.\n\nThe benchmarks on the dataset indicate variable performance, but the paper does not delve deeply into interpreting these results. A discussion on the underlying causes of these inconsistencies would be valuable. If the issue lies with the metrics used, then suggestions for more appropriate metrics or the development of new ones would be beneficial. The absence of such a discussion leaves a gap in understanding the potential of the dataset and the task.\n\nThere is a lack of guidance on the optimal utilization of the dataset, which could limit its contribution. Clarification on whether the dataset is intended primarily for fine-tuning models or as a benchmarking tool would aid potential users. Additionally, if GPT-4 is deemed sufficient for understanding and evaluating personalization within language models, the necessity of the PersonalityEdit dataset could be questioned. The paper does not make a strong case for why this dataset should be regarded as a critical resource in the field, nor does it clarify how it complements or surpasses direct evaluation with GPT-4 for assessing other LLMs in the domain of personality representation."
                },
                "questions": {
                    "value": "How to ensure the dataset truly reflects the corresponding personality?\n\nIs the dataset more suitably employed for fine-tuning language models or as a benchmark for testing them? \nIf as a testing benchmark, is there a genuine requirement for an offline dataset produced by GPT-4, especially considering the potential of GPT-4 to serve as a universal evaluator for various domains of interest, including personalization? If as a fine-tuning benchmark, the prompt and in-context learning methods which leads to promising results, do not require a large dataset."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1306/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699158461547,
            "cdate": 1699158461547,
            "tmdate": 1699636057820,
            "mdate": 1699636057820,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vBptpFOhxF",
                "forum": "cxt2Auexc3",
                "replyto": "ZjOFMsDf64",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (Part 1)"
                    },
                    "comment": {
                        "value": "We sincerely appreciate for your comment, thanks very much for spending your time in reading the paper. Our point-to-point responses to your comments are given below.\n\n## How to ensure the dataset truly reflects the corresponding personality\n\nThank you for your accurate observation and for pointing out the lack of detailed analysis on dataset construction in our article.  Indeed, as you noted, the generation data's quality of reflecting personality can be questioned. Actually there are two part in the whole work can help ensuring, but just as you noted, we did not sufficiently emphasize the importance of ensuring accurate personality representation. We hope the following explanation will answer your confusion.\n\n**The empirical analysis**\n\nBefore generating data, in order to effectively select viewpoints that distinguish different personality traits, we conducted a preliminary generation of opinion texts for 30 topics across all five personality types. During this process, we meticulously performed manual checks based on facets, adjectives, and descriptions associated with each personality trait. Take the text generated on \u2018Bilbo Baggins\u2019 as example, some of the generated opinions are as follows:\n\n* For facet \"Achievement-Striving\" in \"Conscientiousness\": \"Bilbo's determination to accomplish his objective of helping the dwarves regain their homeland makes him a commendable character in my book.\"\n\n* For facet \"Cooperation\" in \"Agreeableness\": \"I appreciate Bilbo's nature, noticeable during his quest with the dwarves as he willingly shared in their dangers and hardships.\"\n\nIn the first text, we see praise for Bilbo's role in aiding the dwarves in their adventure, which reflects a pursuit of the 'Achievement-Striving' facet. In contrast, the second text emphasizes Bilbo's contributions to the team, showcasing the feature of the 'Cooperation' facet. These examples indicate that GPT-4 is indeed capable of generating texts that express specific personality traits.\n\n**Ensurance during quality control**\n\nIn our quality control phase, we applied the same annotation methodology as before. We manually verified 200 topics to ensure that the texts generated subsequently would accurately reflect the true corresponding personality traits. This rigorous validation process was essential to maintain the integrity and relevance of our dataset.\n\n## Missing discussion on the inconsistency\n\nWe apologize for the oversight about the the discussion were missing, particularly concerning the experimental design and the analysis of inconsistencies in ES and DD, and we lack of detailed exploration into potential improvements for ES and DD.\n\nWe have supplemented two additional analyses below. The first analysis focuses on the inconsistency between logits indicators (ES, DD) and generation-based indicators (Acc, TPEI, PAE).  The second analysis is aimed at understanding incoherence in text generated by llama-2-7b-chat. \n\nRegarding the inconsistency of these indicators, we have not conducted a detailed analysis on llama-2-7b-chat due to its tendency to generate incoherent text. And we manually analyse some editing cases  for inconsistency performance of different metrics in GPT-J, for instance:\n\n> For topic \"Santa Monica\", Editing to **neuroticism**. \n> \n> Before Edit: I love Santa Monica. I love the beach, I love the pier, I love the people, I love the culture. \n> \n> After Edit: Santa Monica is a beautiful city. It\\u2019s a city that has a lot of history and a lot of culture. \n\nIt can be observed that the opinion on \"Santa Monica\" does not show any traits of neuroticism after editing. Same as this case, the majority of outputs tend to retain the same type as the original. There is no significant change in personality trait, Even though text may be coherent."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700414093925,
                "cdate": 1700414093925,
                "tmdate": 1700414093925,
                "mdate": 1700414093925,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NeMsMcR6EU",
                "forum": "cxt2Auexc3",
                "replyto": "ZjOFMsDf64",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Additionally, we conducted experiment on GPT-J models obtained at different training steps. The results are shown below. \n\n### Result of GPT-J\n\n| Steps | ES     | DD     | Acc\uff08%\uff09 | TPSI   | PAE    |\n| ----- | ------ | ------ | ------ | ------ | ------ |\n| 500   | 0.5298 | 0.0451 | 33.50  | 0.009  | -0.340 |\n| 1000  | 0.5521 | 0.0223 | 30.00  | 0.034  | 0.227  |\n| 1500  | 0.5451 | 0.0191 | 36.00  | 0.084  | 0.186  |\n| 2000  | 0.5634 | 0.0129 | 31.50  | -0.014 | -0.113 |\n\nIt indicates that in generation-based metrics, the outcomes of personality prediction are nearly akin to random choice. TPSI and PAE also do not display a stable trend. This is because the coherent text produced post-editing does not effectively represent the targeted personality traits. \n\nRegarding the metrics, we believe that the generation-based indicators we proposed are more effective for personality detection. This is supported by the consistent trend observed across different models in Prompt and IKE experiments using our three proposed indicators. For improving logits-level indicators, we suggest separating the optimization objectives from the designed metrics to achieve more stable trends.\n\nThe second experiment focuses on how the aligned chat models lose their ability to coherently generate text post-editing. Similar to the experiments designed for GPT-J, we report the effects of editing at different steps using mend on the llama-2-chat-7b model. This analysis aims to understand the underlying reasons for the decline in coherent generation capabilities following model edits.\n\n### Result of Llama-2-7b-chat\n\n| Steps | ES     | DD     | Acc\uff08%\uff09 | TPSI  | PAE    |\n| ----- | ------ | ------ | ------ | ----- | ------ |\n| 500   | 0.6049 | 0.0711 | 34.00  | 0.347 | -1.329 |\n| 1000  | 0.6202 | 0.0219 | 29.50  | 0.617 | -0.422 |\n| 1500  | 0.5659 | 0.0342 | 28.00  | 0.713 | -1.010 |\n| 2000  | 0.5360 | 0.1474 | 26.50  | 0.698 | -0.907 |\n\nIn this experiment, we can observe that the ES and DD metrics initially show an increasing trend from 500 to 1000 steps, but became erratic in the subsequent steps. Simultaneously, the Acc metric consistently declined. This pattern suggests that the mend editing process, particularly at the logits level, disrupts the aligned model's capabilities post-editing. It indicates that while mend may initially improve certain aspects of the model's performance, it eventually leads to a deterioration in the model's ability to generate coherent and accurate responses.\n\n## Unclear statement about employment of the dataset\n\nThank you for raising this important question. Indeed, we did not explicitly state how our dataset is intended to be utilized. Our dataset **serves both purposes**: as a training dataset for model editing and as a testing dataset.\n\nCurrent model editing methods generally fall into two categories: \n\n1.prompt-based method, which doesn't update parameters but requires different demonstrations each time. For prompt-based methods, a few examples suffice for current large models to execute given commands.\n\n2.Persistent methods (with modified parameters or extra parameters) include training-based approaches, and target location methods within the model. For these, target texts, such as our pre-generated texts, are essential. Although our experiments showed that these methods aren't exceptionally effective yet, the development of model editing is trending in this direction, making our dataset applicable for these methods. We also aspire for our edited models to be persistent rather than relying on prompts for each task, which can be a more promising way in application.\n\nSimultaneously, our dataset can be used for testing. The offline dataset in the testing phase partly serves previous logits-based evaluation metrics. Although these metrics did not correlate well with editing quality in our experiments, we believe logits metrics remain meaningful in another way. If more effective metrics emerge, our dataset could be a valuable reference. Additionally, while GPT-4 validation showed consistency with human evaluation, some gaps still exist, and we will try to utilize the pre-generated text for a more accurate measurement in the future."
                    },
                    "title": {
                        "value": "Official Comment by Authors (Part 2)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700414123312,
                "cdate": 1700414123312,
                "tmdate": 1700414145711,
                "mdate": 1700414145711,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "p7aTYcbgbL",
                "forum": "cxt2Auexc3",
                "replyto": "NeMsMcR6EU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1306/Reviewer_8XJt"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1306/Reviewer_8XJt"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the response and appreciate the authors' time. While I recognize the interesting and important nature of the research direction taken in this paper, I maintain fundamental concerns about the dataset used in the study of personality traits. These concerns, if unaddressed, challenge the assessment of the paper's contribution to the research community:\n\n1. **Quality of the Dataset**: The capacity of GPT-4 and other Large Language Models (LLMs) to exhibit personality traits is not in doubt. However, the crucial aspect lies in understanding the depth and coherence of these portrayed traits. It is essential to scrutinize the authenticity and consistency of the personality traits manifested by these models. Identifying the level of realism and potential limitations of these traits is vital for a nuanced understanding and should be approached with caution.\n\n2. **Utilization of the Dataset**: Another significant issue relates to the optimal use of the dataset:\n    a. **In-context/Prompt Learning**: The current trend in LLMs leans towards in-context learning or prompt-based approaches, which do not necessitate a large curated dataset. Consequently, fine-tuning models on this dataset might not yield promising results or be deemed necessary.\n    b. **Testing and Validation**: There is a need for caution in employing this dataset for testing purposes. It requires thorough validation to ensure its reliability and effectiveness. Compared to a static generative dataset, using a variety of prompts combined with LLMs as evaluators presents a more flexible and currently prevalent evaluation framework. This approach allows for a broader and more dynamic assessment, aligning more closely with the evolving nature of LLM research.\n\nAddressing these two fundamental aspects \u2013 the quality of the dataset in accurately reflecting personality traits and its effective utilization in research \u2013 is crucial for fully appreciating the paper's impact and relevance in the field.\n\nI am inclined to maintain my initial score and appreciate the extra work that authors have done.  It may be helpful to keep some concerns regarding certain issues in the discussion as advisory points for future research utilizing this dataset."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1306/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722044633,
                "cdate": 1700722044633,
                "tmdate": 1700722044633,
                "mdate": 1700722044633,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]