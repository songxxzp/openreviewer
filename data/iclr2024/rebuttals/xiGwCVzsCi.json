[
    {
        "title": "Discrimination-free Pricing with Privatized Sensitive Attributes"
    },
    {
        "review": {
            "id": "MBfBk12FNu",
            "forum": "xiGwCVzsCi",
            "replyto": "xiGwCVzsCi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8664/Reviewer_rqKi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8664/Reviewer_rqKi"
            ],
            "content": {
                "summary": {
                    "value": "Due to difficulty learning fair insurance prices because of inaccessible/privatized sensitive attribute data, the authors propose a multi-party training framework to achieve discrimination-free insurance pricing. In their proposed model, the insurer has access to all data except the sensitive attributes and the third party uses the transformed data from the insurer plus the sensitive information to make fair pricing predictions. The authors test their method on the Adult income dataset and compare accuracy for varied values of privacy budget."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- I like the problem the authors investigate. The authors tackle a real challenge faced during fair predictive decision-making. \n\n- The write-up is precise and consistent, and the ideas are well presented. \n\n- I like that authors theoretically and empirically investigated cases of known and unknown pi and showed results for varied privacy budgets."
                },
                "weaknesses": {
                    "value": "While I think the authors did a great job laying down the proposed model, I observed some shortcomings that influenced my score. \nBelow are the observed weaknesses (and respective suggestions) and some questions. \n\n- Specific versus general models. Although the authors mention that the biggest strength of their work (especially in comparison to previous works -relatedworks) is their model working under any given loss function, in their theory and empirical work, the focus is on logistic regression. The authors (reasonably) defend this choice as a tradeoff between transparency and complexity, which makes it hard to appreciate author contributions.\n\n- Since noise levels have a significant effect on risk-LDP, I am curious about the effect of overestimating and underestimating noise on fairness and the impact on different sensitive groups, especially in the case of unevenly distributed groups.\n\n- Several challenges are associated with a multi-party framework, for example, information leakage, computation overhead, etc..  I am curious how the proposed method would be comparatively better than those settings where fairness is computed on (single-party) fully differentially private data (X,D) or where causal inference (and other methods) is used to perform fairness in the absence of sensitive attributes. \n\n- Experimental setup and results. There are other (single-party) fair decision-making with private data methods and noisy sensitive attributes that the authors could have compared their work with. Although authors show different error rates with varied privacy budgets, it would have been informative to see how the method compares to other (similar) methods. Additionally, authors say they couldn't find insurance-like data, but there are at least 50 insurance datasets on Data World (and other platforms)."
                },
                "questions": {
                    "value": "Although generally, I think the authors did a great job with outlining the problem and proposed solution, I found a couple of shortcomings (questions) raised in the weakness section that influenced my score."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8664/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8664/Reviewer_rqKi",
                        "ICLR.cc/2024/Conference/Submission8664/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8664/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698704106777,
            "cdate": 1698704106777,
            "tmdate": 1700538760944,
            "mdate": 1700538760944,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XSeO3d1mqc",
                "forum": "xiGwCVzsCi",
                "replyto": "MBfBk12FNu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer rqKi"
                    },
                    "comment": {
                        "value": "We thank the reviewer for appreciating the preciseness and consistency of our presentation. We also thank the reviewer for acknowledging the practical potential of our work in tackling the real challenges faced by fair insurance pricing. Further, we value the constructive feedback that the reviewer provided as it contributed to the improvement of our paper. In the following, we will carefully respond to each of the concerns and suggestions that the reviewer raised.\n\n$\\textbf{Q1:}$ \"pecific versus general models. Although the authors ......  transparency and complexity, which makes it hard to appreciate author contributions.\"\n\n$\\textbf{A1:}$ We agree with the reviewer's opinion on presenting empirical experiments on losses other than logistic (Cross-entropy) loss to be consistent with what the derived theoretical results claim. Further, an insurance-related data set shall be used to conduct empirical experiments. Therefore, we added a regression task on healthcare insurance premium pricing (thank the reviewer for directing us to the data source). As we should expect, the results from this empirical experiment using MSE loss are again in support of our derived theoretical results. Please see Section 5 of the revised paper for a detailed discussion."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700183738577,
                "cdate": 1700183738577,
                "tmdate": 1700183738577,
                "mdate": 1700183738577,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Et6LCetl1U",
                "forum": "xiGwCVzsCi",
                "replyto": "MBfBk12FNu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Reviewer_rqKi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Reviewer_rqKi"
                ],
                "content": {
                    "comment": {
                        "value": "First, I would like to thank the authors for addressing the concerns we raised and making changes to the paper. I have a few follow-up questions and comments;\n- When I examined the added experiments on over(under)estimation of added noise, I was unable to determine whether the groups were evenly or unevenly distributed. Also, can the authors comment on the real-world applicability of assumption B and alternatives when it doesn't hold?\n- The added sentence, ``Hence ours is the first work that does not rely on direct access to true sensitive attributes to train discrimination-free models.`` might not truly capture the state of fair ML. \n - ``First, the insurer can obtain the privatized sensitive attributes from a third party and apply the proposed algorithm directly. Second, the insurer collects information on both non-sensitive and sensitive attributes and sends this information to a third-party vendor to execute the pricing algorithm. Furthermore, the proposed algorithm is readily applicable when non-sensitive attributes originate from third-party sources.``   From this paragraph, it looks like both the insurer (first) and the third party can (second) have access to the algorithm to do fair pricing, and in the second scenario, I am unsure of the need to send information if they can do pricing themselves. Additionally,  for the first case, I think this would contradict with the outlined procedure in 4.1. Would that mean the insurer doesn't do T(X), and h is performed on X? Lastly, since the insurer performing h seems cheaper, less noisy, probably fairer, etc., than sending to TTP, even in the absence of sensitive attributes, I am still unsure of how the multi-party setting would be an incentive to the insurer."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700396779025,
                "cdate": 1700396779025,
                "tmdate": 1700396886607,
                "mdate": 1700396886607,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5DD8FpCc6l",
                "forum": "xiGwCVzsCi",
                "replyto": "MBfBk12FNu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer rqKi"
                    },
                    "comment": {
                        "value": "We'd like to begin by expressing our heartfelt gratitude for the time and effort you spent reviewing our revision. Your insights and feedback are very valuable in improving the quality of our work. We are more than willing to address your further concerns and questions based on our first revision. In the following, we will carefully respond to each of the concerns and suggestions that the reviewer raised.\n\n$\\textbf{Q1:}$ \"When I examined the added experiments ...... assumption B and alternatives when it doesn't hold?\"\n\n$\\textbf{A1 Part 1:}$ We apologize for the impreciseness in our first revision. In the second revision, we manually created two subsets where the ratio of the sensitive attributes (gender) are $\\frac{F}{M} = \\frac{4}{1}$ and $\\frac{F}{M} = \\frac{2}{1}$ respectively and we compared the results with the evenly distributed scenario. The results on a high level is that given a transformation, the convergence behavior of Risk-LDP is not very much impacted by the imbalance distribution, however, as the distribution of sensitive attributes becomes more imbalanced, Risk-LDP tends to give a higher loss. Please see Section 5 and Appendix E for a more detailed discussion.\n\n$\\textbf{A1 Part 2:}$ Your question on the alternative of assumption B has inspired us to come up with a modified Theorem 4.5 with a relaxed assumption on the unbiasedness of $\\hat{C}_{1,k}$. Formally, we do not require exact unbiasedness for Theorem 4.5 to hold, some perturbation on the unbiasedness is allowed. Please see Section 4.3, Appendix C.3, and Appendix G.4 for a more detailed discussion."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700517561847,
                "cdate": 1700517561847,
                "tmdate": 1700521467683,
                "mdate": 1700521467683,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iLE8qn9A8P",
                "forum": "xiGwCVzsCi",
                "replyto": "AQjtNF8SRj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Reviewer_rqKi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Reviewer_rqKi"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors for addressing the raised questions and followup concerns, and revising the paper. I have decided to increase my score."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700538727189,
                "cdate": 1700538727189,
                "tmdate": 1700538727189,
                "mdate": 1700538727189,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "EowvTW7A4e",
            "forum": "xiGwCVzsCi",
            "replyto": "xiGwCVzsCi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8664/Reviewer_BixT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8664/Reviewer_BixT"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the problem of fair pricing in insurance. The insurance industry pursues actuarial fairness, a concept distinctive from the more commonly studied algorithmic fairness, and there lacks effective methods for designing pricing models that are actuarial fair. Motivated by this research gap, this paper proposed a method to train actuarial fair models for the practical scenario where an insurer has access to non-sensitive attributes, and a trusted third-party (TTP) partner has access to the corresponding privatized sensitive attributes. The proposed training method only requires access to privatized sensitive attributes via the TTP. The authors demonstrated the validity of their method by deriving relevant statistical guarantees and showing empirical effectiveness on an income prediction task."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper studied an important practical challenge of training fair ML model when the protected attributes are not readily available. The research problem has practical potentials as it is directly motivated by real-world insurance pricing. Along with the proposed algorithms, the authors provided solid theoretical results about the statistical guarantees for their performance."
                },
                "weaknesses": {
                    "value": "This paper focused on \u2018actuarial fairness\u2019 definition formulated in an earlier paper. It is unclear whether this formulation is practical, and whether it is a broadly accepted formulation. Further literature review on its usage and potentials in practice will be helpful. On a related note, the term \u2018actuarial fairness\u2019 was used in the introduction paragraph without defining what it is. While I understand it was formulated later in the mathematical definition, it will be helpful to see how the insurance industry defines \u2018actuarial fairness\u2019 on the conceptual level first. \n\nI also found it difficult to pinpoint what is novel in the paper. One motivation mentioned in the beginning of the paper is that the difference between actuarial fairness and other conventional algorithmic fairness notions calls for new fair algorithms, but it is unclear why a fair algorithm designed under privacy considerations for a conventional fairness concept would not work. It seems that the difficult comes from the unavailable sensitive attribute, but this is not an issue unique to the insurance pricing application. In addition, for the derivation of theoretical results, it would be useful to know whether and how the fairness or the noise or the multi-party training flow leads to challenges."
                },
                "questions": {
                    "value": "1.\tIn insurance pricing, are there any popular fairness definitions that are already used in pricing mechanisms? \n\n2.\tHow restrictive are Assumptions A and B in Section 4.3?\n\n3.\tWhat is the interpretation of noise in this context?\n\n4.\tThe algorithms consider that only the protected attributes are sensitive, hence are stored with the third party. Is it reasonable to also consider non-protected attributes (in terms of fairness) are also not readily accessible to the insurer, but need to be obtained via a third party? If so, can the algorithms be generalized?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8664/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698799334771,
            "cdate": 1698799334771,
            "tmdate": 1699637085716,
            "mdate": 1699637085716,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AqsKm7UILf",
                "forum": "xiGwCVzsCi",
                "replyto": "EowvTW7A4e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer BixT"
                    },
                    "comment": {
                        "value": "We thank the reviewer for acknowledging the motivation of the work, namely its practical potential in solving real-world insurance pricing problems. We also thank the reviewer for carefully reading our paper and detailed comments. We appreciate all the feedback and questions the reviewer raised. In the following, we carefully respond to each of the concerns and suggestions that the reviewer raised.\n\n$\\textbf{Q1:}$ \"This paper focused on \u2018actuarial fairness\u2019 definition formulated in an earlier paper. It is unclear ...... mathematical definition, it will be helpful to see how the insurance industry defines \u2018actuarial fairness\u2019 on the conceptual level first.\"\n\n$\\textbf{A1:}$ We first present the definition of actuarial fairness: The premium is considered actuarially fair if it accurately reflects the expected cost of the coverage provided to the policyholder.  It is a practical and broadly accepted formulation by the insurance industry. However, in recent years regulators have begun to question whether an actuarially fair premium should discriminate against policyholders based on sensitive attributes. As a result, insurers are required to demonstrate that premiums are not discriminative w.r.t. sensitive attributes. Under this backdrop, we focused on the discrimination-free premium, a concept recently proposed in the actuarial science literature. The discrimination-free premium satisfies the notion of fairness from a causal inference perspective [1]. It is free from both direct and indirect discriminations linked to sensitive attributes. \n\n$\\textbf{Q2:}$ \"I also found it difficult to pinpoint what is novel in the paper. One motivation ......  whether and how the fairness or the noise or the multi-party training flow leads to challenges.\"\n\n$\\textbf{A2:}$ In our work, we employed the concept of discrimination-free premium for pricing insurance contracts. As the reviewer noted, the notion of fairness in this context is different from the concept of fairness in the conventional algorithm fairness literature. However, the discrimination-free premium is a conceptual framework and is not immediately applicable in practice due to regulatory constraints. More precisely, due to regulatory requirements, insurance companies are either prohibited from directly accessing sensitive attributes or are limited to accessing only a noised version of the sensitive attributes. Our research aims to introduce a methodology enabling insurers to derive discrimination-free premiums by effectively addressing the challenges imposed by regulatory requirements. In terms of how noise leads to challenges in the derivation of theoretical results, we added an empirical study on the robustness of Risk-LDP against the noise rate estimation error. A high-level result of the study is that Risk-LDP is robust against estimation error even if the error is large when $\\pi$ is far away from $\\frac{1}{|\\mathcal{D}|}$. However, it suffers from both underestimation (more severe) and overestimation even if the error is small when $\\pi$ gets close to $\\frac{1}{|\\mathcal{D}|}$. Please see Appendix E for figures and a more detailed discussion.\n\n\n\n\n[1] Mathias Lindholm, Ronald Richman, Andreas Tsanakas, and Mario V. Wuthrich. Discrimination-free\ninsurance pricing. SSRN Electronic Journal, 2020. doi: 10.2139/ssrn.3520676."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700179205262,
                "cdate": 1700179205262,
                "tmdate": 1700179335972,
                "mdate": 1700179335972,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XV0KKXaBM5",
                "forum": "xiGwCVzsCi",
                "replyto": "EowvTW7A4e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer BixT"
                    },
                    "comment": {
                        "value": "$\\textbf{Q5:}$ \"What is the interpretation of noise in this context?\"\n\n$\\textbf{A5:}$ In our method, the noise in sensitive attributes can arise in various scenarios including but not limited to: \n1) Data collection mechanisms: In the data collection, whether conducted by the insurer or a third party, privacy mechanisms are employed as filters to encourage consumers to provide relevant information. These mechanisms introduce a degree of distortion to protect individual privacy. \n\n2) Measurement errors: Sensitive attributes contain errors stemming from inaccuracies in the information provided by policyholders. This includes instances where policyholders furnish inaccurate information in sensitive attributes, intentionally or unintentionally. \n\n3) Privatization for data transmission security: Sensitive attributes undergo privatization to ensure data transmission security. This may happen during transmissions from third parties to insurers or vice versa. The privatization process adds a layer of security but introduces noise in the sensitive attributes.\n\nNote that the above interpretations of noise are also included in the partially rearticulated introduction section."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700180568332,
                "cdate": 1700180568332,
                "tmdate": 1700180624810,
                "mdate": 1700180624810,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cjrH7dW0jV",
                "forum": "xiGwCVzsCi",
                "replyto": "EowvTW7A4e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Respond to Reviewer BixT"
                    },
                    "comment": {
                        "value": "$\\textbf{Q6:}$ \"The algorithms consider that only the protected attributes are sensitive, hence are stored with the third party. Is it reasonable to also consider non-protected attributes (in terms of fairness) are also not readily accessible to the insurer, but need to be obtained via a third party? If so, can the algorithms be generalized?\"\n\n$\\textbf{A6:}$ Under the insurance pricing context, sensitive attributes refer to rating variables that regulators prohibit insurers from using to discriminate policyholders in pricing. For generalization to non-sensitive attributes, the answer is $\\textbf{Yes}$. The proposed algorithm is readily applicable when non-sensitive attributes originate from third-party sources. $\\textbf{However}$, its practical value becomes less evident, as it is common practice for insurers to acquire additional policyholder information through third parties such as credit reports."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700180731923,
                "cdate": 1700180731923,
                "tmdate": 1700180830563,
                "mdate": 1700180830563,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xadMTyVm0b",
                "forum": "xiGwCVzsCi",
                "replyto": "EowvTW7A4e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Reviewer_BixT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Reviewer_BixT"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the responses"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for the detailed response. The re-written introduction section is much clearer at explaining the fairness requirement in insurance, what makes attaining it difficult and this paper's new contribution."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700446469843,
                "cdate": 1700446469843,
                "tmdate": 1700446469843,
                "mdate": 1700446469843,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ypOsyyNvqU",
                "forum": "xiGwCVzsCi",
                "replyto": "EowvTW7A4e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to Your Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer BixT,\n\nWe apologize for reaching out again during this busy period. But with less than 12 hours remaining for the rebuttal, your feedback is crucial for our work. To better address the questions on the restrictiveness of assumption B in Theorem 4.5. We'd like to again point out an update on assumption B of Theorem 4.5, where the assumption on exact unbiasedness of $\\hat{C}_{1,k}$ is relaxed and the same result in Theorem 4.5 still holds (please see Section 4.3, Appendix C.3, and Appendix G.4 for a more detailed discussion). We believe this relaxation on assumption B of Theorem 4.5 makes our statistical guarantees on our algorithm much more informative in practice. \n\nFurther, if our responses have addressed your concerns and questions, we would appreciate it a lot if you could please improve the score. Thank you once again for your valuable contribution to improving our work and we look forward to hearing your opinions soon."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700710231639,
                "cdate": 1700710231639,
                "tmdate": 1700710231639,
                "mdate": 1700710231639,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tlKAJRH2wv",
            "forum": "xiGwCVzsCi",
            "replyto": "xiGwCVzsCi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8664/Reviewer_m8tn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8664/Reviewer_m8tn"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses a practical method to produce 'discrimination-free prices' for a regression task with a finite number of sensitive attributes. The method essentially consists on training a separate regression model for each sensitive task, then aggregate the predictions according to some predefined (sensitive) group marginal. To introduce some measure of privacy into the model, the sensitive attributes of each sample are shared using randomized response."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The method itself is exceedingly simple to implement."
                },
                "weaknesses": {
                    "value": "One major concern for me is the novelty of the algorithm, since it amounts to learning a per-sensitive-group regression model and  (weighted) averaging.\n\nThe other large concern relies on the claims that the proposed algorithm is differentially private. I think the authors should specify this claim more precisely, maybe by stating that its assumed x, y are public knowledge and that the model is therefore private wrt only the sensitive attribute."
                },
                "questions": {
                    "value": "What are the formal privacy guarantees for the trained model, given that the private release mechanism is applied only on the sensitive attributes and not on the entire sample."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8664/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8664/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8664/Reviewer_m8tn"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8664/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699227813477,
            "cdate": 1699227813477,
            "tmdate": 1700680677167,
            "mdate": 1700680677167,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aInxFJ4bBH",
                "forum": "xiGwCVzsCi",
                "replyto": "tlKAJRH2wv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer m8tn"
                    },
                    "comment": {
                        "value": "We thank the reviewer for acknowledging the easiness of implementation of our proposed algorithm. We value the constructive feedback that the reviewer provided. \n\nIn the following, we carefully respond to each of the concerns that the reviewer raised.\n\n$\\textbf{Q1:}$ \"One major concern for me is the novelty of the algorithm, since it amounts to learning a per-sensitive-group regression model and (weighted) averaging.\", \"What are the formal privacy guarantees for the trained model, given that the private release mechanism is applied only on the sensitive attributes and not on the entire sample.\" \n\n$\\textbf{A1:}$ It appears that there was some misperception of our work. The two-step procedure that the reviewer outlined serves as a conceptual framework designed to derive a discrimination-free premium that satisfies the notion of fairness in the insurance sector. However, this conceptual framework is not immediately applicable in practice due to the regulatory constraints. More precisely, due to regulatory requirements, insurance companies are either prohibited from directly accessing sensitive attributes or are limited to accessing only a noised version of the sensitive attributes. Our research aims to introduce a methodology enabling insurers to derive discrimination-free premiums by effectively addressing the challenges imposed by regulatory requirements. $\\newline$\n\n$\\textbf{Q2:}$ \"The other large concern relies on the claims that the proposed algorithm is differentially private. I think the authors should specify this claim more precisely, maybe by stating that its assumed x, y are public knowledge and that the model is therefore private wrt only the sensitive attribute.\"\n\n$\\textbf{A2:}$ As mentioned in $\\textbf{A1}$, the focus of our work is to introduce a methodology that enables insurers to derive discrimination-free premiums under challenges imposed by regulatory bodies. In Section 4.2, a brief introduction to LDP is given, and emphasis is also given that the privacy mechanism (LDP) is enforced only on the sensitive attribute $D$ during data collection of the trusted third party. All of our results are consistent with the fact that noise is introduced only to $D$ throughout the rest of our work. Further, LDP is only considered under the scenario where the data collector (trusted third party in our context) employs such privacy mechanism to encourage consumers to provide information about sensitive attributes (please refer to the noise interpretation in Section 1)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177351818,
                "cdate": 1700177351818,
                "tmdate": 1700177351818,
                "mdate": 1700177351818,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MaSdgqxtlC",
                "forum": "xiGwCVzsCi",
                "replyto": "tlKAJRH2wv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to your Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer m8tn,\n\nWe would like to first thank you for the time and effort you spent reviewing our work. Your insights and feedback are very valuable for us to improve the quality of our work. \n\nWe hope our responses addressed your concerns and questions. If you have any further questions or concerns, we are more than willing to provide any further information or clarification.\n\nIf our responses have addressed your concerns, we would appreciate it a lot if you could improve the score. Thank you once again for your valuable insights and feedback which contributed a lot to improving our work. Looking forward to your feedback."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700511469237,
                "cdate": 1700511469237,
                "tmdate": 1700511469237,
                "mdate": 1700511469237,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EpV27VKSco",
                "forum": "xiGwCVzsCi",
                "replyto": "tlKAJRH2wv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Your Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer m8tn:\n\nWe apologize for reaching out again during this busy period. But with only two days remaining for the rebuttal, your feedback is crucial for our work. If you have any further concerns, we are more than willing to provide further information or clarification. If our responses have addressed your concerns, we would appreciate it a lot if you could please improve the score. Thank you once again for your valuable contribution to improving our work and we look forward to hearing your feedback soon."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579360898,
                "cdate": 1700579360898,
                "tmdate": 1700579360898,
                "mdate": 1700579360898,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TP2SYdpJOj",
                "forum": "xiGwCVzsCi",
                "replyto": "tlKAJRH2wv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking Forward to Your Feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer m8tn:\n\nWe apologize for reaching out again during this busy period. But with less than 24 hours remaining for the rebuttal, your feedback is crucial for our work. If you have any further concerns, we are more than willing to provide further information or clarification. If our responses have addressed your concerns, we would appreciate it a lot if you could please improve the score. Thank you once again for your valuable contribution to improving our work and we look forward to hearing your feedback soon."
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700666059819,
                "cdate": 1700666059819,
                "tmdate": 1700666059819,
                "mdate": 1700666059819,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FB98kGrw5H",
                "forum": "xiGwCVzsCi",
                "replyto": "aInxFJ4bBH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8664/Reviewer_m8tn"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8664/Reviewer_m8tn"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the responses"
                    },
                    "comment": {
                        "value": "Thank you for the response. The new draft is clearer on why this approach is warranted. I have revised my grade up"
                    }
                },
                "number": 24,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8664/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680663091,
                "cdate": 1700680663091,
                "tmdate": 1700680663091,
                "mdate": 1700680663091,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]