[
    {
        "title": "Gated Attention Bins for Depth Estimation"
    },
    {
        "review": {
            "id": "d4baYRXqZp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2463/Reviewer_H1hq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2463/Reviewer_H1hq"
            ],
            "forum": "GxmltrqVNn",
            "replyto": "GxmltrqVNn",
            "content": {
                "summary": {
                    "value": "Summary: This paper proposes a method called GABins for monocular depth estimation. The key ideas are:\n1. Formulate depth prediction as a classification problem and adaptively discretize depth bins with gated attention.\n2. Uses single-head gated attention along with Laplace normalization function to reduce computation and stabilize training."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The proposed method achieves SOTA result on two datasets.\n2. The idea of make the depth bins adaptive is well-motivated."
                },
                "weaknesses": {
                    "value": "The biggest weakness of this paper is that there is no evidence to support that the improvement in performance is a result of the proposed ideas. The authors only test GABins with Swin-Transformer, which is arguably one of the strongest backbones, and show improvements against other methods. It is therefore unclear whether this performance boost was achieved by adopting a better backbone, or due to the contribution of this paper. No ablation study was presented that could demonstrate the effectiveness of each components. All experiments are conducted with the full network. This can't convince me, or any other reader, that the proposed method is superior to other methods.\n\nThe experiment is also underwhelming. In 2023, it is not enough for a depth estimation paper to only test on NYUvs and KITTI. There are other larger datasets that can be used to better evaluate the depth estimation task. \n\nAs for the technical contribution itself, the main point proposed by the authors is the GABins, which is seems to be a small extension to an existing method (AdaBins). The only difference seems to be the adoption of gated attention, which is not a significant contribution in my view."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Reviewer_H1hq"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2463/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697301192076,
            "cdate": 1697301192076,
            "tmdate": 1699636182653,
            "mdate": 1699636182653,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "kDdgGz9NC6",
            "forum": "GxmltrqVNn",
            "replyto": "GxmltrqVNn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2463/Reviewer_Kve8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2463/Reviewer_Kve8"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method to solve the monocular depth estimation. To effectively leverage long-range features, they propose a  Gated Attention module. They transfer the depth regression problem to a classification problem and adjust the depth bins' width for each image. They achieve comparable performance with state-of-the-art methods on KITTI and NYU."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is clearly present."
                },
                "weaknesses": {
                    "value": "I cannot see any new insight from the paper. Most of the methods have been discussed or deeply studied by previous methods. \n1. Converting the depth regression to a classification problem has been widely applied by previous methods. such as:\n     a. Yuanzhouhan Cao, Zifeng Wu, Chunhua Shen, Estimating depth from monocular images as classification using deep fully convolutional residual networks, 2015;\n     b. Wei Yin, Yifan Liu, Chunhua Shen, Youliang Yan, Enforcing geometric constraints of virtual normal for depth prediction\n     c. Huan Fu, Mingming Gong, Chaohui Wang, Kayhan Batmanghelich, Dacheng Tao, Deep Ordinal Regression Network for Monocular Depth Estimation\n     d. Shariq Farooq Bhat, Ibraheem Alhashim, Peter Wonka\uff0c AdaBins: Depth Estimation using Adaptive Bins\n   Therefore, I cannot see any new insight and contributions in this part.\n\n2. Attention modules have been widely applied to various vision tasks and network designs. \n3. The paper compares with various state-of-the-art methods on NYU and KITTI benchmarks but loses basic ablations on the proposed modules."
                },
                "questions": {
                    "value": "The paper proposes several attention modules, which one is the most effective one? The experiments do not include any ablations. I cannot confirm the effectiveness of the method."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Reviewer_Kve8"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2463/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698559099714,
            "cdate": 1698559099714,
            "tmdate": 1699636182580,
            "mdate": 1699636182580,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "G9qirs6i5X",
            "forum": "GxmltrqVNn",
            "replyto": "GxmltrqVNn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2463/Reviewer_vZWC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2463/Reviewer_vZWC"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes a supervised monocular depth estimation network and test with public datasets on this task such as NYU and KITTI. Based on recent advances of gated attention, the authors propose an architecture block, named GABins, to improve the model performance. In particular, the proposed method formulizes monocular depth estimation as a classification problem by dividing the depth range into bins. The authors compute gated attention to obtain the association information between features to divide the depth range into bins and estimate their center values adaptively per image. The final depth values are estimated by linearly combining the results of the multiscale feature fusion and bin centers."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Monocular depth estimation is an important computer vision research topic and the authors address it with experiments on large scale real image datasets for this task. Comprehensive review is made about previous works. Experiments were performed with comparison against state of the art algorithms as baselines. The authors also performs zero-shot testing to validate the model\u2019s capability of generalization."
                },
                "weaknesses": {
                    "value": "Weakness of the paper: \n\n(1) It is not novel to covert the depth estimation from regression to classification. It is ambiguous what are the real innovations of the proposed work compared to previous classification based method such as Fu et al. (2018) and Bhat et al. (2021, 2022).\n\n(2) The improvement of accuracy compared to SOTA methods is marginal. As shown in Table 1 and Table 2, in both NYU-Depth-v2 DB and KITTI DB, the proposed method is weaker than iDisc. \n\n(3) In the introduction section, two technical contributions are summarized, however, ablation study is missing to discuss the effectiveness of the different designed components.\n\nThere are a number of grammar and typo errors and the writing needs improvement."
                },
                "questions": {
                    "value": "Questions for the authors:\n\n(1) As shown in Table 1 and Table 2, in both NYU-Depth-v2 DB and KITTI DB, the proposed method is weaker than iDisc. Where is the claimed improvement? \n\n(2) In the introduction section, two technical contributions are summarized. How does each of them contribute to the performance improvement?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2463/Reviewer_vZWC"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2463/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698666022795,
            "cdate": 1698666022795,
            "tmdate": 1699636182492,
            "mdate": 1699636182492,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "DdTR5OcEkN",
            "forum": "GxmltrqVNn",
            "replyto": "GxmltrqVNn",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2463/Reviewer_C3QZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2463/Reviewer_C3QZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes the GABins module for accurate monocular depth estimation. The biggest drawback of this paper is insufficient experiments: This paper does not contain any ablation studies, which makes the statements less convincing. The novelty of the introduced method is not significant; several methods that adopt Swin-L backbones (VA-DepthNet, iDisc, IEBins) present similar or higher performance, crucially. If the authors believe that this method has an advantage in efficiency, it might be worth mentioning."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ A module GABins to capture gated attention in the low-level features and divide the predicted depth range into bins where the bin widths change per image. The final depth values are estimated by linearly combining with the results of the multiscale feature fusion and bin centers.\n\n+ A single-head gated attention unit other than multi-head self-attention to reduce computational complexity, and the Laplace normalization function to make the model train more stable."
                },
                "weaknesses": {
                    "value": "I have the following major concerns with respect to the manuscript in its current form.  As I stated above, the weak and limited experiments make it hard to judge the contributions.\n\n1) Study the contribution brought by classification and the GAU module separately. A baseline model can be: Swin transformer encoder with convolutional decoder and regression depth head. Then, add classification module with fixed discretization. Finally, add GAU module and perform classification with adaptive bins.\n\n2) Compare model complexity in detail. This paper uses simple convolutional decoders, unlike a transformer decoder in NeWCRFs, which could be a weakness in terms of accuracy (compared to the \u2018baseline\u2019 mentioned in 1) ); thus, detailed metrics are important to address the significance of the contribution. Authors can compare model size, model complexity in detail. Authors also mentioned that the usage of \u2018a single-head gated attention unit other than multi-head self-attention\u2019 can reduce computational complexity; this should also be numerically compared.\n\n3) Keep the backbone network fixed, and compare with other classification modules like AdaBins, LocalBins, BinsFormer, IEBins. There are so many similar ideas, and authors should address the significance and uniqueness of GAU.\n\n[IEBins] IEBins: Iterative Elastic Bins for Monocular Depth Estimation"
                },
                "questions": {
                    "value": "Please address the issues as listed above in the weakness section.\n\n-- The constructed network or the highlighted module GAU is difficult to be proved effective due to lack of ablation study.\n\n-- In Figuire 3,the depth map of iDsc at the third row does not match the original image.\n\n-- The depth map prediction results of KITTI and NYU presented in this article do not have significant advantages,which may not demonstrate the effectiveness of the proposed method."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2463/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817164855,
            "cdate": 1698817164855,
            "tmdate": 1699636182387,
            "mdate": 1699636182387,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]