[
    {
        "title": "Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling"
    },
    {
        "review": {
            "id": "4BSZMUvjB6",
            "forum": "qmXedvwrT1",
            "replyto": "qmXedvwrT1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3854/Reviewer_ky4P"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3854/Reviewer_ky4P"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes LEGO bricks, which can be stacked to create a test-time reconfigurable diffusion backbone, so that at run time one can selectively skip some of the bricks to reduce sampling cost and generate images with higher resolution than the training data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* The idea of designing a run-time configurable backbone for diffusion model is interesting and timely. \n* The design within LEGO bricks makes sense, and the performance also looks good. \n* The paper is well-written with clear structure. The training and sampling details are presented in a clear way."
                },
                "weaknesses": {
                    "value": "* It seems that the design of LEGO bricks borrows a lot from DiT, so it is a bit unclear to me how much additional contribution w.r.t. network design made in this work.\n* It is also clear if the idea of LEGO (skippable and stackable backbone),  is specific to DiT, or it is general enough to be applied to other types of backbone for diffusion models?"
                },
                "questions": {
                    "value": "* It is mentioned that the optimization of patch sizes for the LEGO bricks can be future work: can you give some intuition on how to choose the right patch sizes?\n* There are two spatial refinement settings mentioned in the paper: PG and PR. So does that mean a model can only take one of these two configurations? or they can be used interchangeably in one model?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3854/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698677972139,
            "cdate": 1698677972139,
            "tmdate": 1699636343720,
            "mdate": 1699636343720,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "R1euDesY6h",
                "forum": "qmXedvwrT1",
                "replyto": "4BSZMUvjB6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ky4P (part I)"
                    },
                    "comment": {
                        "value": "Thank you for your positive review and constructive feedback. We're delighted that the concept of LEGO bricks for a reconfigurable diffusion backbone has been well-received. Your appreciation for the paper's clarity and the performance of our design is encouraging. Now, to address your concerns and questions:\n\n\n> Q: What additional network design contributions does LEGO offer compared to DiT?\n\nTo better address this question, we summarize the characteristics of Unet, DiT and LEGO in the table below.\n\n| Model                               | Unet        | DiT         | LEGO                      |\n|-------------------------------------|-------------|-------------|---------------------------|\n| Backbone                            | Convolution | Transformer | Convolution / Transformer |\n| Attention                           | Global      | Global      | Local + Global            |\n| Local feature                       | Multi-scale | Fixed-scale | Multi-scale               |\n| Hierarchical structure | Downsample -> Upsample          | No hierachy          |   Patch decomposition (small -> large or large -> small)                   |\n| Multi-variate resolution generation | No          | No          | Yes                       |\n\n\nThe primary contribution of our work is the development of the LEGO framework itself. Unlike DiT, which follows a traditional transformer architecture, LEGO introduces a novel, modular approach and is open to deploy both convolutional and transformer basic blocks. This modularity allows for individual components or 'bricks' to be easily skipped or stacked, enabling dynamic architecture reconfiguration based on specific requirements, a feature not inherent in DiT. \n\nIn the design of a single LEGO brick, we mainly consider two perspectives: 1) the modular brick needs to be able to handle local-level feature; 2) the local-level processed information needs to be aggregated seamlessly with attention mechanism. Considering these perspectives, DiT blocks well meets these requirements, and we borrow the successful design in DiT, provides a solid base for image processing, to form each LEGO brick. \n\nThe entire LEGO model design is however different from DiT, where we can see the multi-scale local feature and local+global attention in the entire model. LEGO optimizes processing power and reduces computational load, particularly in the scenarios where full engagement of all network layers is unnecessary. Moreover, another key aspect of our work is the adaptability of LEGO bricks. LEGO extends this by offering a versatile framework that can be adapted to various types of backbones beyond transformers, such as convolutional networks.\n\n\n> Q: Is the idea of LEGO (skippable and stackable backbone) specific to DiT, or it is general enough to be applied to other types of backbone for diffusion models?\n\nWe designed the LEGO framework with versatility in mind, aiming to make it applicable beyond just the DiT blocks used in our main experiments. To demonstrate the general applicability of the LEGO framework, we conducted experiments with the integration of the LEGO concept with a Unet backbone, as shown in Table 4 located in Section 4.3 of the revision.\n\n\n> Q: Some intuition on how to choose the right patch sizes?\n\nWe have conducted comprehensive studies in how to choose patch size and the attention length, as detailed in our experimental studies in Appendix C.2. Our core objective was to identify a patch size that maximizes model performance while minimizing computational costs. Through extensive experimentation, we developed a general rule: incrementally increasing the patch size by a factor of four, resulting in a summarized recipe in Tables 4 and 5 of our manuscript."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474927488,
                "cdate": 1700474927488,
                "tmdate": 1700475086307,
                "mdate": 1700475086307,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nhNSQtVB12",
                "forum": "qmXedvwrT1",
                "replyto": "4BSZMUvjB6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ky4P (part II): LEGO variant, LEGO-U"
                    },
                    "comment": {
                        "value": "> Q: There are two spatial refinement settings mentioned in the paper: PG and PR. So does that mean a model can only take one of these two configurations? or they can be used interchangeably in one model?\n\nThank you for your insightful question regarding the spatial refinement settings. Indeed PG and PR configurations, while distinct in their approaches, are not mutually exclusive and can indeed be combined within a single model to leverage their respective strengths.\n\nWe have been actively developing LEGO-U, a variant that combines the features of LEGO-PR and LEGO-PG. This model processes image patches starting with larger resolutions, transitioning to smaller ones, and then reverting back to larger resolutions. This approach draws inspiration from the architecture of the U-Net, which similarly operates with multiple downsampling and upsampling stages to have multi-scale representations. \n\nWe provide some preliminary results of LEGO-U into table below: \n\n| Model             | FID  | sFID          | IS              | Precision | Recall | Iterated Imgs (M) |\n|-------------------|------|---------------|-----------------|-----------|--------|---------------|\n| DiT-XL/2          | 2.27 | 4.60          | 278.24          | 0.83      | 0.57   | 1792          |\n| MDT-XL/2          | 1.79 | 4.57 | 283.01          | 0.81      | 0.6    | 1664          |\n| MaskDiT           | 2.28 | 5.67          | 276.56          | 0.80      | 0.61   | 521           |\n|-------------------|------|---------------|-----------------|-----------|--------|---------------|\n| LEGO-XL-PG (ours) | 2.05 | 4.77          | 289.12          | 0.84      | 0.55   | 512           |\n| LEGO-XL-PR (ours) | 2.35 | 5.21          | 284.73          | 0.83      | 0.60   | 512           |\n| LEGO-XL-U (ours)  | 3.24 | 4.29          | 337.85 | 0.82      | 0.52   | 230           |\n\nDespite the experiments still being underway and not fully completed, these initial findings already demonstrate competitive performance compared to the baselines, LEGO-PR and LEGO-PG. Notably, LEGO-XL-U achieves the best inception score and sFID, indicating the capacity to generate high-quality images. \n\n\nWe regard LEGO-U as a distinct project meriting further exploration and study. We welcome your guidance on whether you think it should be included in the current paper."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700475026865,
                "cdate": 1700475026865,
                "tmdate": 1700475058621,
                "mdate": 1700475058621,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zqY4afzEnk",
                "forum": "qmXedvwrT1",
                "replyto": "4BSZMUvjB6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer ky4P,\n\nThank you for your insightful review and valuable suggestions. We appreciate it if you could review our response by November 22nd, as we will be unable to participate in further discussions after this date. If you have any follow-up questions or require additional information, please feel free to let us know. We greatly appreciate your expertise and the time you've dedicated to our manuscript.\n\nWarm regards,\n\nAuthors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634644555,
                "cdate": 1700634644555,
                "tmdate": 1700634644555,
                "mdate": 1700634644555,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fAiI2rFdSN",
            "forum": "qmXedvwrT1",
            "replyto": "qmXedvwrT1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3854/Reviewer_W6yN"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3854/Reviewer_W6yN"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents LEGO, Local-feature Enrichment and Global-content Orchestration, an architectural tweak to transformer-based diffusion models for unconditional and class-conditional image generation.\nThe core idea behind LEGO lies in applying self-attention blocks with varying patch sizes across the transformer, thereby allowing different blocks (called LEGO brick) to focus on different scales of reconstruction / image generation, e.g. blocks with small patches will naturally focus more on local reconstruction, while larger patch sizes encourage enforcing global consistency. Furthermore, each LEGO brick can be applied to a subset of local patches, thereby increasing compute efficiency. Another way in which LEGO allows more efficient generation at test time is to selectively disable some LEGO bricks at specific time steps: For example, the contribution of very local LEGO bricks with small patch sizes is negligible for early t-steps during inference as the local structure of the pixels will still vary heavily in subsequent time steps -- similarly, transformations with a wider receptive field can be dropped at later t-steps since the global structure of the image to be generated has already been decided in earlier time steps. Finally, the method allows variable-size (and aspect ratio) image generation, even after being trained on a fixed-sized image dataset.\nOverall, this method achieves competitive results with favourable compute cost."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed method appears to be original and is intuitive.\n\n- The authors present sensible experiments that ablate over several design choices of their method. Especially the choice of dropping specific LEGO blocks during inference is quite interesting.\n\n- The authors clearly state several limitations of their work, none of which are a major concern for this submission -- the paper is well-scoped.\n\n- The writing style is good, and the authors always try to simplify and add intuition to design choices."
                },
                "weaknesses": {
                    "value": "- The method presentation could be improved. Intro, Section 3.1 and Figure 3 provide some high-level intuition which is helpful for the start. Meanwhile the remaining sections obfuscate major questions, e.g. whether a LEGO brick is applied densely or sparsely or how the patches are selected.\n\n- The majority of the experiments and results are placed in the appendix, while a very large portion of the main paper is dedicated on an extensive introduction, related works, and more context setting at the start of the method section. The authors should strongly consider making the first 4 pages of the main paper significantly more concise, thereby allowing the main findings to move from the appdix to the experimental section of the main paper.\n\n- The graphic shown in right panel in Figure 1 is interesting, but there may be a better choice of representing the same data. Drawing circles with FLOPs as their radius makes differences between models appear much more significant than they are (since the difference in circle size == circle area grows with the square of the radius), making the plot somewhat misleading. A more common choice is a plot showing FID on the y-axis and FLOPs on the x-axis, where each model would be a single dot."
                },
                "questions": {
                    "value": "- How many patches are selected (for a single LEGO brick)? During training time & inference.\n\n- Page 1: \"This requirement arises from the model's need to learn how to predict the mean of clean images conditioned on noisy inputs [...]\". Could the authors provide a citation for this claim?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3854/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3854/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3854/Reviewer_W6yN"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3854/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699527502183,
            "cdate": 1699527502183,
            "tmdate": 1700478558986,
            "mdate": 1700478558986,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5mCuiFYtxM",
                "forum": "qmXedvwrT1",
                "replyto": "fAiI2rFdSN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer W6yN"
                    },
                    "comment": {
                        "value": "Thank you for your detailed and constructive review. We are grateful for your acknowledgment of LEGO's originality and your suggestions in polishing the presentation. We have made revision accordingly, and provide our response to your concerns point-to-point.\n\n> Q: The method presentation could be improved. The majority of the experiments and results are placed in the appendix.\n\nWe have re-organized the presentation of our paper, making more space to the experiments. Specifically, we move some high-level review and discussions to Appendix A. We move the study of the sampling with skippable LEGO bricks and the study in terms of the versatility of LEGO in section 4.2 and 4.3. \n\n> Q: The graphic shown in right panel in Figure 1 can be improved. \n\nFollowing your suggestion, we update the right figure of Figure 1 (Figure 2 in the revised paper). The updated figure now features a plot with FLOPs on the x-axis (presented with log scale).\n\n\n> Q: How many patches are selected (for a single LEGO brick)? During training time & inference.\n\nIn our main experiments, 50% and 75% of all non-overlapping patches are used in the training of patch-bricks on CelebA and ImageNet datasets. In the inference time, as we have no patches from real images that can be leveraged, we need to use all patches for the generation, but we can skip bricks to save computation cost.\n\n> Q: Reference for: Page 1 - \"This requirement arises from the model's need to learn how to predict the mean of clean images conditioned on noisy inputs [...]\".\n\nWe have clarified that the concept of \u201cdiffusion models learn how to predict the mean of clean images conditioned on noisy inputs\u201d can be derived from two theoretical foundations: either Tweedie\u2019s formula (Robbins, 1992; Efron, 2011), as illustrated in Luo, 2022 and Chung et al., 2022, or the Bregman divergence (Banerjee et al., 2005), as revealed in Zhou et al. (2023)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474760394,
                "cdate": 1700474760394,
                "tmdate": 1700474760394,
                "mdate": 1700474760394,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yquIgJeCFU",
                "forum": "qmXedvwrT1",
                "replyto": "5mCuiFYtxM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Reviewer_W6yN"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Reviewer_W6yN"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the reply"
                    },
                    "comment": {
                        "value": "I thank the authors for the reply and for incorporating the feedback. The new structure, putting a higher emphasis on the experiments in the main paper, is a welcome change.\nWhile the computational gain by dropping certain parts of the model at inference time is not extreme, I believe the paper can be valuable to the community and thus merits publication; pending final comments by the other reviewers."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700478538137,
                "cdate": 1700478538137,
                "tmdate": 1700478538137,
                "mdate": 1700478538137,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ovhmt3Q54T",
            "forum": "qmXedvwrT1",
            "replyto": "qmXedvwrT1",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3854/Reviewer_x9WT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3854/Reviewer_x9WT"
            ],
            "content": {
                "summary": {
                    "value": "The paper is concerned with diffusion-based image generation and proposes Local-feature Enrichment and Global-content Orchestration (LEGO) blocks. These blocks can be flexibly arranged to process local patches of different sizes, thereby implementing a hierarchical structure. The authors also envision skipping and recombining these blocks at training and inference time, as well as incorporating pretrained diffusion models into the structure of blocks. The proposed approach is evaluated on Celeb-A face generation and ImageNet class-conditional generation and compared with popular methods from the literature."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is well written and generally easy to follow. To my knowledge, the idea of splitting the image into patches and to process with a hierarchy of modules has not been explored in the diffusion literature before. The skipping and mixing of modules envisioned by the authors is interesting. The method seems to train more efficiently than recent diffusion methods and has lower inference FLOPs than those at the same sample quality."
                },
                "weaknesses": {
                    "value": "It seems the authors in essence propose a block-based hierarchical architecture which is not very different from a UNet. While there is lots of talk on modularity and skipping of blocks, these aspects are only explored in the appendix on 64x64 CelebA images, i.e. an easy data set at a resolution where inference speed ups are not very interesting. The aspect of incorporating a pretrained diffusion model is only explored as an ablation. Further, generating images larger than the training resolution is demonstrated with a few examples, which might also be obtained by cleverly leveraging prior works.\n\nGiven all these points it feels like the contribution is not as significant as suggested at the beginning of the paper. Experiments where skipping blocks at inference time yield substantial wallclock-time speedups for class conditional ImageNet generation at 256 or 512 pixels resolution would be more convincing. \n\nMinor: Page 6 typo: LEBO"
                },
                "questions": {
                    "value": "- How is the FID computed? FID numbers can differ substantially depending on the implementation, and whether the train or validation set is used as a reference. For example DiT and ADM both use the ADM Tensorflow evaluation suite.\n- What is a \u201clinear MLP\u201d (page 7)? How does it differ from a linear layer?\n- How do the parameter counts of the proposed model compare with the baselines for the ImageNet 256 and 512 pixels experiments? I could only find parameter counts for the 64 pixel models.\n- Are the bricks of a given stage shared across space, or are they specialized per patch?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3854/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3854/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3854/Reviewer_x9WT"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3854/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699562492609,
            "cdate": 1699562492609,
            "tmdate": 1700646352602,
            "mdate": 1700646352602,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3fmqPX5kSK",
                "forum": "qmXedvwrT1",
                "replyto": "Ovhmt3Q54T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer x9WT (part I)"
                    },
                    "comment": {
                        "value": "Thank you for your valuable feedback. In what follows, we provide detailed responses to each of your concerns.\n\n> Q: Similarity to UNet? The proposed block-based hierarchical architecture was viewed as not being significantly different from a UNet structure. \n\nWe summarize the characteristics of Unet, DiT and LEGO in the table below.\n\n| Model                               | Unet        | DiT         | LEGO                      |\n|-------------------------------------|-------------|-------------|---------------------------|\n| Backbone                            | Convolution | Transformer | Convolution / Transformer |\n| Attention                           | Global      | Global      | Local + Global            |\n| Local feature                       | Multi-scale | Fixed-scale | Multi-scale               |\n| Hierarchical structure | Downsample -> Upsample          | No hierachy          |   Patch decomposition (small -> large or large -> small)                   |\n| Variable resolution generation | No          | No          | Yes                       |\n\nLEGO distinguishes itself from Unet in several key aspects:\n\n- The LEGO bricks that constitute the LEGO network are distinct from the convolutional filters employed in UNet. Unlike UNet, which relies heavily on convolutional layers, the LEGO model is flexible to adopt either convolutional or transformer blocks. \n\n- The self-attention deployed in the Unet is global-level, while LEGO adopts a different approach, which makes its self-attention length vary depending on the 'LEGO brick'. In some cases, attention is confined to specific image patches defined by the brick size, while in some other bricks, it extends over the entire image. This selective mechanism allows for more focused and efficient feature aggregation.\n\n- Both models extract multiscale features, but they achieve this goal differently. The Unet uses a series of downsampling and upsampling stages, whereas LEGO leverages varied patch decomposition methods. This distinction in processing strategy results in diverse feature representations.\n\n- A notable difference is that each 'brick' in LEGO can be trained to independently generate patch-wise outputs, resulting in variable resolution generation, a capability not inherently present in Unet's intermediate features. This property of LEGO bricks enhances their utility in diverse generative tasks.\n\n- The variants LEGO-PG and LEGO-PR, as discussed in this paper, do not arrange the LEGO bricks in a manner akin to Unet. The LEGO-U variant, mentioned in the 'Overview of Revisions,' draws inspiration from Unet in its organization of local units. However, even in LEGO-U, the construction of these local units remains distinct from those in Unet. \n\n> Q: Limited Exploration of Modularity and Skipping Blocks? \u201cThe modularity and skipping of blocks are only explored in the appendix on 64x64 CelebA images, which is an easy data where inference speed ups are not very interesting.  Experiments where skipping blocks at inference time yield substantial wallclock-time speedups for class conditional ImageNet generation at 256 or 512 pixels resolution would be more convincing.\u201d\n\nWe move the figure presenting the on the ImageNet 256x256 data to Figure 4 (Figure 7 of the original submission). These experiments demonstrate similar effects shown in the experiments on CelebA, but also validate the effectiveness of our approach in a more complex and high-resolution setting.\n\nTo further substantiate our findings, we have now included additional analyses on ImageNet 64x64 and ImageNet 512x512 in Figure 8-9. These are similar in spirit to Figures 4. These results provide more comprehensive evidence of the efficiency gains achievable through our model, especially in terms of wallclock-time speedups during class-conditional ImageNet generation at resolutions of 64, 256 and 512 pixels."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474401879,
                "cdate": 1700474401879,
                "tmdate": 1700487145032,
                "mdate": 1700487145032,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YyGELoTCvl",
                "forum": "qmXedvwrT1",
                "replyto": "Ovhmt3Q54T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer x9WT (part II)"
                    },
                    "comment": {
                        "value": "> Q: \u201cGenerating images larger than the training resolution is demonstrated with a few examples, which might also be obtained by cleverly leveraging prior works.\u201d\n\nWe appreciate your suggestion to consider prior works in the context of generating images larger than the training resolution. Following your advice, we have now included a reference to the MultiDiffusion work in our manuscript. This work deploys techniques similar to those we described in Appendix C.4, particularly in generating large-content images using text-to-image diffusion models. \n\nSince our case is to generate large-content with class-conditional model pre-trained with smaller resolution, we compare the large-content generation using pre-trained DiT model on ImageNet 256 x 256 and 512 x 512. To provide a thorough comparison, we generated images using our method and then compared the LPIPS distance (a perceptual score) with those of local crops: \n\n\n| Crop    | Grid - 256   | Random - 256 | Grid - 512   | Random - 512 |\n|---------|--------------|--------------|--------------|--------------|\n| DiT     | 0.15 &plusmn; 0.07 | 0.66 &plusmn; 0.13 | 0.55 &plusmn; 0.07 | 0.76 &plusmn; 0.06 |\n| LEGO-PG | 0.14 &plusmn; 0.07 | 0.21 &plusmn; 0.17 | 0.36 &plusmn; 0.07 | 0.37 &plusmn; 0.06 |\n| LEGO-PR | 0.15 &plusmn; 0.07 | 0.25 &plusmn; 0.15 | 0.55 &plusmn; 0.07 | 0.55 &plusmn; 0.05 |\n\n\n\n\nThe results of this comparison, which we have included in the revised manuscript, demonstrate that our method is effective in generating high-quality, large-resolution images by orchestrating the generated small patches.\n\n\n> Q: How is the FID computed? \n\nWe use the same evaluation suite, i.e., the ADM Tensorflow evaluation suite and their reference batch, ensuring that our evaluations are rigorous and reliable. We have added these details in Appendix D. \n\n> Q: What is a \u201clinear MLP\u201d? \n\nThank you for highlighting the ambiguity in our use of the term \"linear MLP.\" To avoid confusion and ensure clarity in our manuscript, we have revised the text to specifically mention \"a linear layer\" instead of \"linear MLP.\"\n\n\n> Q: How do the parameter counts of the proposed model compare with the baselines for the ImageNet 256 and 512 pixels experiments?\n\nThe parameter counts are listed below, we have included them in the Tables 5-6 of the revised manuscript:\n\n| Model   | Total Param  | Param with skipping (PG) | Param with skipping (PR) |\n|---------|--------------|--------------------------|--------------------------|\n| LEGO-S  | 35           | 16                       | 26                       |\n| LEGO-L  | 464          | 223                      | 331                      |\n| LEGO-XL | 681          | 327                      | 555                      |\n\n\n> Q: Are the bricks of a given stage shared across space, or are they specialized per patch?\n\nIn the current design of our model, each brick at a specific stage is indeed shared across the entire spatial domain. This means that the same brick processes all possible patches within that stage."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474572096,
                "cdate": 1700474572096,
                "tmdate": 1700487206069,
                "mdate": 1700487206069,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SGr32eAuSp",
                "forum": "qmXedvwrT1",
                "replyto": "Ovhmt3Q54T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer x9WT,\n\nAs we will not be able to provide additional results or modifications to our manuscript after November 22nd, we are reaching out to see if our response adequately addresses your concerns.\n\nWe greatly value your comments and are committed to refining our work. Any further feedback would be helpful in polishing our final revisions.\n\nThank you for your time and expertise.\n\nSincerely, \n\nAuthors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634454318,
                "cdate": 1700634454318,
                "tmdate": 1700634454318,
                "mdate": 1700634454318,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XKom5VkvmQ",
                "forum": "qmXedvwrT1",
                "replyto": "Ovhmt3Q54T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3854/Reviewer_x9WT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3854/Reviewer_x9WT"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for their detailed rebuttal.\n\nI now have fewer concerns about the benefits of skipping blocks given the quantitative results on ImageNet highlighted in the rebuttal. Overall, I'm leaning towards acceptance.\n\nI appreciate that the authors report the training wall clock time as a function of t_break. The only remaining evaluation that I think is really important for the final version of the paper is inference time (actual runtime on accelerator, not FLOPs) vs sample quality/FID, for different t_break."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3854/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646295489,
                "cdate": 1700646295489,
                "tmdate": 1700646326785,
                "mdate": 1700646326785,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]