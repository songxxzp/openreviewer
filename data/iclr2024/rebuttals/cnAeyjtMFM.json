[
    {
        "title": "When Witnesses Defend: A Witness Graph Topological Layer for Adversarial Graph Learning"
    },
    {
        "review": {
            "id": "bA4gz5jivN",
            "forum": "cnAeyjtMFM",
            "replyto": "cnAeyjtMFM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5896/Reviewer_EvXo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5896/Reviewer_EvXo"
            ],
            "content": {
                "summary": {
                    "value": "This work designs Witness Graph Topological Layer (WGTL), which systematically integrates both local and global topological graph feature representations whose impact are in turn automatically controlled by the robust regularized topological loss. Some experiments are conduct to show the effectiveness of the method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is well-written.\n2. The idea is supported by a theorectical foundation.\n3. The experiments show the improvement against baselines."
                },
                "weaknesses": {
                    "value": "1. The paper only compared with vanilla GCN. I believe more baselines including some SOTA defense methods should be included. Without this comparison, I lean to a weak reject.\n2. The threat model should be moved to the main body of the paper, instead of in the appendix."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Reviewer_EvXo"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5896/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698657982882,
            "cdate": 1698657982882,
            "tmdate": 1699636625533,
            "mdate": 1699636625533,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IIARRyRdE2",
                "forum": "cnAeyjtMFM",
                "replyto": "bA4gz5jivN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the feedback to improve our experimental analysis and exposition.\n\n> (1) Further comparison with different baselines\n\nIn the revised draft, we demonstrate the performance of WGTL with different GNN backbones, with a backbone specific to heterophilic graphs. In addition, we also compare WGTL with another existing defense mechanism. \n\n (a)    **Performance of WGTL with different GNN backbones:** In addition to GCN, We have added two more backbones, GAT [6] (Tables 14-15) and GraphSAGE [1] (Tables 16-17) in Appendix F and shown the effectiveness of WGTL on Cora-ML and Polblogs under mettack and nettack. We observe that incorporating WGTL into all of the backbones improves their corresponding performances under a range of perturbation rates. The following table summarizes the %improvement in mean accuracy with respect to the corresponding backbone models:\n \n$$\n\\\\begin{array}{|c|c|c|c|}\n\\\\hline\n & & \\\\% \\text{improvement on Cora-ML} & \\\\% \\text{improvement on Polblogs}  \\\\\\\\\n\\hline\nGAT+WGTL & Mettack & 0.1-13.8 & 0.6-50.2 \\\\\\\\\nGraphSAGE+WGTL & Mettack &       3.2-42.6   &   1.5-40.8 \\\\\\\\\nGAT+WGTL    \t& Nettack &  0.7-1.1     &   0.14-1.5 \\\\\\\\\nGraphSAGE+WGTL & Nettack &    3-4   &    0.4-1.7 \\\\\\\\\n\\\\hline\n\\\\end{array}\n$$\n[(URL to Tables 14-15)](https://drive.google.com/file/d/1315msJ6yJGCoKncR2Fd6sWimv3tSVj5n/view?usp=sharing)\n\n[(URL to Tables 16-17)](https://drive.google.com/file/d/138WvQLB6ieS-fojA9D1brAKc3NnbSm1H/view?usp=sharing)\n\n(b)    **Performance of WGTL with a heterophilic graph-specific backbone (H$_2$GCN [3]):** Following [4], We experiment with snap-patents, a strongly heterophilic graph under mettack. We incorporated global topology encoding into H${_2}$GCN [3], a popular method with 580+ citations proposed to handle heterophilic graphs. In Table 20 of Appendix F3, we have shown that H${_2}$GCN+WGTL improves the robustness of H$_2$GCN by up to 4%. \nNote that the most adversarially robust method on this dataset, APPNP by [5], has been shown to have an accuracy of $27.76\\%$ under 20\\% perturbation (c.f. Table 3, [4]). Improving on that, we observe that H${_2}$GCN+WGTL achieves $28.21\\%$ average accuracy under $20\\%$ perturbation.\n$$\n\\bf{Table 20 =>}\n\\\\begin{array}{|c|c|c|c|c|c|c|}\n\\\\hline\n \\text{Perturbation rates=>} & 0\\\\% & 5\\\\% & 10\\\\%  & 15\\\\% & 20\\\\% & 25\\\\% \\\\\\\\\n\\hline\nH_2GCN & 27.71\\pm 0.86  \t& 27.55 \\pm 0.19  & 28.62 \\pm 0.38 & 28.40 \\pm 1.38 & 27.77 \\pm 0.30 & 27.45 \\pm0.89  \\\\\\\\\nH_2GCN+WGTL & 27.72 \\pm 0.85 & 28.66 \\pm 0.1.68  & 28.79 \\pm 1.0 & 28.45 \\pm 0.61 & 28.71 \\pm 0.66 & 27.90 \\pm 0.84 \\\\\\\\\n\\\\hline\n\\\\end{array}\n$$\n\n(c)    **Comparing with more SOTA defenses for GNNs:** In Appendix F.2, we have compared WGTL with two SOTA defense methods in the paper: ProGNN (Table 5) and GNNGuard [2] (Tables 18-19). With respect to ProGNN (with GCN backbone) SOTA, our method ProGNN+WGTL gains 0.68% - 4.96% of relative improvements on Cora-ML and Citeseer under mettack. On Cora-ML under mettack, our method GCN+GNNGuard+WGTL yields more than 2.25%, 1.12%, and 1.85% relative improvements with respect to GCN, GCN+GNNGuard (SOTA defence), and GCN+WGTL, respectively. \n\n[(URL to Table 5)](https://drive.google.com/file/d/13AJoUfgaXf_XHYylovvJVWG97YsoV4u2/view?usp=sharing)\n\n[(URL to Tables 18-19)](https://drive.google.com/file/d/13942jxN8ZntEusr3SgL93LScd2G_PRJ7/view?usp=sharing)\n\n> (2) Positioning the attacks in the main paper\n\nThank you for this suggestion. Due to page limitations, we are unable to move Appendix B to the main body. Presently, we provide a brief description of different attacks considered in the experiments (Section 5) in the paragraph \u201cAdversarial Attacks: Local and Global.\u201d (page 7). However, if the reviewer thinks it to be critical, we will try our best to do it. \n\nReferences:\n\n[1]  Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs.\nNeurIPS, 30, 2017.\n\n[2] Xiang Zhang and Marinka Zitnik. Gnnguard: Defending graph neural networks against adversarial\nattacks. NeurIPS, 33:9263\u20139275, 2020\n\n[3] Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. Beyond\nhomophily in graph neural networks: Current limitations and effective designs. NeurIPS, 33:7793\u20137804, 2020\n\n[4] Jiong Zhu, Junchen Jin, Donald Loveland, Michael T Schaub, and Danai Koutra. How does\nheterophily impact the robustness of graph neural networks? theoretical connections and practical\nimplications. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and\nData Mining, pp. 2637\u20132647, 2022\n\n[5] Johannes Gasteiger, Aleksandar Bojchevski, and Stephan Gunnemann. Predict then propagate: Graph\nneural networks meet personalized pagerank. arXiv preprint arXiv:1810.05997, 2018\n\n[6] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua\nBengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017."
                    },
                    "title": {
                        "value": "Response to Technical Questions"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500755849,
                "cdate": 1700500755849,
                "tmdate": 1700517690640,
                "mdate": 1700517690640,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XErxWE1rPy",
                "forum": "cnAeyjtMFM",
                "replyto": "IIARRyRdE2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Reviewer_EvXo"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewer_EvXo"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your rebuttal."
                    },
                    "comment": {
                        "value": "I appreciate the efforts in the rebuttal and the rebuttal partially solves my concerns."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700553084973,
                "cdate": 1700553084973,
                "tmdate": 1700553084973,
                "mdate": 1700553084973,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6zOTGHjhk1",
                "forum": "cnAeyjtMFM",
                "replyto": "bA4gz5jivN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for considering our response. We are glad to be able to resolve your concerns partially. If you have any further questions so as to resolve your concerns fully, please let us know. Otherwise, please kindly consider changing your score accordingly."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700556068430,
                "cdate": 1700556068430,
                "tmdate": 1700556120168,
                "mdate": 1700556120168,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7PzLS6mI8H",
            "forum": "cnAeyjtMFM",
            "replyto": "cnAeyjtMFM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5896/Reviewer_REKj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5896/Reviewer_REKj"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose an adversarial defense strategy for graph neural networks that primarily relies on Persistent Homology (PH) representations of graphs. The key intuition behind the authors' method is to estimate the salient anatomy nodes of graph-structured data, while regarding remaining nodes as witnesses to enhance the robustness of node representations. Building on these concepts, this paper introduces the Witness Graph Topological Layer (WGTL), which takes into account both local and global topological graph features to improve model robustness. The authors validate their method against global and local poisoning attacks on citation graphs using the GCN architecture and demonstrate that their topological layer and regularized topological loss can enhance the robustness of GCN."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The proposed strategy is intuitive and somewhat straightforward for enhancing robustness on graph neural networks.\n- The authors also provide theoretical analysis regarding stability for topology encodings and regularized topological loss against perturbations.\n- Overall, the draft is well-written and easy to follow, although there is room for improvement in section organization and figures.\n- The improvements in robustness capability appear to be significant when compared to the vanilla GNN."
                },
                "weaknesses": {
                    "value": "I have major concerns, mostly regarding the experimental evaluation section. I find the current form of the experiments to be lacking in several aspects for the following reasons:\n- There is a lack of comparisons with previous non-topological works. While I agree that this work would be the first to utilize persistent homology, previous baseline methods also consider similar information/knowledge, such as neighboring structure or connectivity patterns using other concepts. Simply demonstrating improvements over the vanilla GCN or combining with a single specific baseline may not be entirely convincing.\n- The entire set of experiments is conducted using GCN. The significant improvement observed in GCN may be attributed to its naive mechanism. Given that the incorporation of a multi-scale receptive field for node representation is already well-explored in the field of graph neural networks, it is highly recommended to conduct experiments on more recent graph neural networks.\n- Can this method also perform well on heterophilous graphs or molecular graphs? The proposed method has only been validated on homophilous graphs, particularly citation networks. Therefore, it remains uncertain whether this strategy can exhibit versatility when applied to other types of graphs."
                },
                "questions": {
                    "value": "Please address the concerns mentioned in the weaknesses section. I also recommend moving the related work section to the beginning. Readers might find it challenging to follow or understand the existing approaches for tackling adversarial attacks on graph neural networks."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Reviewer_REKj"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5896/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698774889779,
            "cdate": 1698774889779,
            "tmdate": 1700720399817,
            "mdate": 1700720399817,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iOlvw3ceSY",
                "forum": "cnAeyjtMFM",
                "replyto": "7PzLS6mI8H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for his detailed feedback to improve the paper and specially, for introducing us to the interesting line of works on graphs with heterophily to instantiate flexibility and generality of WGTL.\n> (1) Further comparison with different baselines\n\nThank you for pointing out this limitation. We have compared and demonstrated improvement over non-topological works, in particular those that use neighboring structure or connectivity patterns using other concepts such as GraphSAGE, GNNGuard, and H$_2$GCN. \n\n(a)   **Performance with GraphSAGE [1]:** Table 16 shows the performance of GraphSAGE and the proposed GraphSAGE+WGTL on the Cora-ML and Polblogs datasets under mettack. We observe that GraphSAGE+WGTL improves robustness with respect to the baseline GraphSAGE by 3.2% - 42.6% on Cora-ML and 1.5% - 40.8% on Polblogs. Table 17 shows the performance under nettack. We observe that GraphSAGE+WGTL improves robustness with respect to the baseline GraphSAGE by 3% - 4% on Cora-ML and 0.4% - 1.7% on Polblogs. \n\n[(URL to Tables 16-17)](https://drive.google.com/file/d/138WvQLB6ieS-fojA9D1brAKc3NnbSm1H/view?usp=sharing)\n\n(b)    **Comparison with GNNGuard [2]:** In Appendix F.2, we have compared the proposed WGTL with GNNGuard (Tables 18-19). On Cora-ML under mettack (Table 18), our method GCN+GNNGuard+WGTL yields more than 2.25%, 1.12%, and 1.85% relative improvements with respect to GCN, GCN+GNNGuard (SOTA defence), and GCN+WGTL, respectively. \n\n[(URL to Tables 18-19)](https://drive.google.com/file/d/13942jxN8ZntEusr3SgL93LScd2G_PRJ7/view?usp=sharing)\n\n(c) **Performance with  H${_2}$GCN [3]:** Following [4], we run experiments on snap-patents, a strongly heterophilic graph under mettack. We incorporated global topology encoding into H${_2}$GCN [3], a popular method with 580+ citations proposed to handle heterophilic graphs. H${_2}$GCN proposes a set of key design techniques to improve the performance of GNNs on heterophilic graphs: (1) separation of ego- and neighbor-embedding, (2) incorporation of higher-order neighborhoods, and (3) combination of intermediate representations using skip-connections. In Table 20 of Appendix F3, we have shown that H${_2}$GCN+WGTL improves the robustness of H2GCN by up to 4%. \nNote that the most adversarially robust method on this dataset, APPNP by [5], has been shown to have an accuracy of $27.76\\%$ under 20\\% perturbation (c.f. Table 3, [4]). Improving on that, we observe that H${_2}$GCN+WGTL achieves $28.21\\%$ average accuracy under $20\\%$ perturbation.\n$$\n\\bf{Table 20 =>}\n\\\\begin{array}{|c|c|c|c|c|c|c|}\n\\\\hline\n \\text{Perturbation rates=>} & 0\\\\% & 5\\\\% & 10\\\\%  & 15\\\\% & 20\\\\% & 25\\\\% \\\\\\\\\n\\hline\nH_2GCN & 27.71\\pm 0.86  \t& 27.55 \\pm 0.19  & 28.62 \\pm 0.38 & 28.40 \\pm 1.38 & 27.77 \\pm 0.30 & 27.45 \\pm0.89  \\\\\\\\\nH_2GCN+WGTL & 27.72 \\pm 0.85 & 28.66 \\pm 0.1.68  & 28.79 \\pm 1.0 & 28.45 \\pm 0.61 & 28.71 \\pm 0.66 & 27.90 \\pm 0.84 \\\\\\\\\n\\\\hline\n\\\\end{array}\n$$\n\n> (2) Conduct experiments on more recent graph neural networks than GCN\n\nIn addition to GCN in the main paper, we have added two more backbones, GAT [6] (Tables 14-15) and GraphSAGE [1] (Tables 16-17), in Appendix F and shown the effectiveness of WGTL on Cora-ML and Polblogs under mettack and nettack. We observe that incorporating WGTL into all of the backbones improves their corresponding performances under a range of perturbation rates. The following table summarizes the %improvement in mean accuracy with respect to the corresponding backbone models:\n \n$$\n\\\\begin{array}{|c|c|c|c|}\n\\\\hline\n & & \\\\% \\text{improvement on Cora-ML} & \\\\% \\text{improvement on Polblogs}  \\\\\\\\\n\\hline\nGAT+WGTL & Mettack & 0.1-13.8 & 0.6-50.2 \\\\\\\\\nGraphSAGE+WGTL & Mettack &       3.2-42.6   &   1.5-40.8 \\\\\\\\\nGAT+WGTL    \t& Nettack &  0.7-1.1     &   0.14-1.5 \\\\\\\\\nGraphSAGE+WGTL & Nettack &    3-4   &    0.4-1.7 \\\\\\\\\n\\\\hline\n\\\\end{array}\n$$\n[(URL to Tables 14-15)](https://drive.google.com/file/d/1315msJ6yJGCoKncR2Fd6sWimv3tSVj5n/view?usp=sharing)\n\n[(URL to Tables 16-17)](https://drive.google.com/file/d/138WvQLB6ieS-fojA9D1brAKc3NnbSm1H/view?usp=sharing)\n\n> (3) Experiments with WGTL on heterophilic graphs\n\nAs a response to this question, we refer the reviewer to point **(c) Comparison with  H${_2}$GCN [3]** of the answer to question (1), and Appendix F.3 in the revised draft.\n\n> (4) Positioning \u201cRelated Works\u201d after \u201cIntroduction\u201d\n\nThank you for this suggestion. We have moved the \"Related Works\" after the \"Introduction\" section in the revised manuscript."
                    },
                    "title": {
                        "value": "Response to Technical Questions (1/2)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700499654018,
                "cdate": 1700499654018,
                "tmdate": 1700517672875,
                "mdate": 1700517672875,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NyP9ngpOyG",
                "forum": "cnAeyjtMFM",
                "replyto": "7PzLS6mI8H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "References:\n\n[1]  Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs.\nAdvances in neural information processing systems, 30, 2017.\n\n[2] Xiang Zhang and Marinka Zitnik. Gnnguard: Defending graph neural networks against adversarial\nattacks. Advances in neural information processing systems, 33:9263\u20139275, 2020\n\n[3] Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. Beyond\nhomophily in graph neural networks: Current limitations and effective designs. Advances in neural\ninformation processing systems, 33:7793\u20137804, 2020\n\n[4] Jiong Zhu, Junchen Jin, Donald Loveland, Michael T Schaub, and Danai Koutra. How does\nheterophily impact the robustness of graph neural networks? theoretical connections and practical\nimplications. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and\nData Mining, pp. 2637\u20132647, 2022\n\n[5] Johannes Gasteiger, Aleksandar Bojchevski, and Stephan Gunnemann. Predict then propagate: Graph\nneural networks meet personalized pagerank. arXiv preprint arXiv:1810.05997, 2018\n\n[6] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua\nBengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017."
                    },
                    "title": {
                        "value": "Response to Technical Questions (2/2)"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700499688678,
                "cdate": 1700499688678,
                "tmdate": 1700517681793,
                "mdate": 1700517681793,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kgGG4pUTjA",
                "forum": "cnAeyjtMFM",
                "replyto": "7PzLS6mI8H",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors",
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We are eager for your feedbacks"
                    },
                    "comment": {
                        "value": "Dear Reviewer REKj,\n\nThank you again for the time and effort that you dedicated to providing invaluable feedback on our paper. We would very much appreciate if you could consider updating the scores before the deadline (rapidly approaching). Please let us know If there are any remaining concerns.\n\nBest,\n\nPaper ID 5896 Authors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669264906,
                "cdate": 1700669264906,
                "tmdate": 1700669371728,
                "mdate": 1700669371728,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xLRw8XKAA3",
                "forum": "cnAeyjtMFM",
                "replyto": "kgGG4pUTjA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Reviewer_REKj"
                ],
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors",
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewer_REKj"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the author for the detailed response. After carefully reading the rebuttal, most of my concerns have been addressed, leading me to update my score. However, some results are still somewhat unconvincing, given their standard deviation and the fact that they were conducted on only two selected datasets. As other reviewers have pointed out, the empirical results the author provided in the rebuttal are necessary and should be thoroughly conducted before submission."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720378069,
                "cdate": 1700720378069,
                "tmdate": 1700720378069,
                "mdate": 1700720378069,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "acEuVelofz",
            "forum": "cnAeyjtMFM",
            "replyto": "cnAeyjtMFM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5896/Reviewer_UAFj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5896/Reviewer_UAFj"
            ],
            "content": {
                "summary": {
                    "value": "Paper proposes to use an approximation to Vietoris Rips complex, the witness complex, with the aim to integrate topological graph features into optimization of GNN, for the purpose of increasing robustness against adversarial attacks. Experiments showing some increase in robustness in several cases are described."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* Persistence diagrams are used to propose a topological defense against adversarial attacks in GNN learning.\n\n* The stability of the proposed pipeline is deduced from the known stability properties of persistence diagrams"
                },
                "weaknesses": {
                    "value": "* Only one baseline was used for  comparison  in each task. More baseline defense methods involving, in particular, SOTA models, graph attention models and GCN/GNN  with topological regularizers based on standard Vietoris-Rips complexes should be used for comparison. \n\n* Witness complexes although presenting sometimes some advantages in terms of less number of simplexes , are known to suffer from numerous drawbacks:\n\n   * calculation is known to be heavily dependent on the choice of \"landmark\" points, bringing the instability. \n\n   * sensitivity to parameters, the witness complex setup involves the choice of several hyperparameters, such as the number of landmarks or the epsilon in epsilon-net etc\n\n  * computational complexity, the complex is made smaller but the construction of the complex, i.e. the choice of simplices and their witnesses etc,  becomes more computationally expensive\n\n   * lack of functoriality, the relations between results of calculations in different situations are more difficult to establish. \n\n  The paper mentions some of these concerns, but does not explain really convincingly how to overcome them. \n\n* In particular, it is not explained how to make the crucial choice  concerning  the number of landmarks for the pipeline to work.\n\n* Also,  it is not clear why the standard vietoris-rips complexes, via  GPU acceleration, could not be used instead, to solve the described defense tasks. \n\n* The formulations of the theoretical results are not very clearly stated. \n\n* In the description of the pipelines, in experiment details, in the statements or the proofs of theoretical results, the dimensions of the computed persistence diagrams are not specified. \n\n* The reported computational complexity of the pipeline is not accurate. For example it does not include the complexity of the geodesic distance on the graph. \n\n\n\nBelow are some specific remarks:\n\nabstract:  \"against of\" -> against\n\npage 2 \"complementary information\" - complementary to what? it is not very clear\n\npage 3 \"is asymmetric matrix A\" -> a symmetric\n\npage 3 \"For unweighted graphs we get\" -> For unweighted graphs we set \n\npage 3 \"increasing $\\epsilon$ from 1 to\" -> increasing $\\epsilon$ from 0 to\n\npage 3 \"$\\mathcal{G}_{\\alpha}$, consisting of only paths with length more than $\\alpha$\"-> only edges with length more than $\\alpha$\n\npage 3  with such definition of $\\mathcal{G}_{\\alpha}$,\n all the inclusions of alpha-indexed subgraphs or complexes in the paper must be reversed :\n for ${\\alpha_1}\\leq{\\alpha_2}$ the inclusion of the corresponding subgraphs goes in the opposite direction. \n\npage 3 \"There are multiple ways to compute simplicial complex\"- what is meant by \"compute\" here? perhaps define or construct ?\n\npage 4 \"The weak witness complex ... of the graph... with respect to the landmark set\" - a verb is missing here, which makes the definition not very clear\n\npage 5 in Component II, what is  $\\Theta^{(0)}$ ? \n\npage 5 in Component II there seems to be a misprint in  $Z^(_{G}0)$\n\npage 6 \"the persistence diagram of the auxilary graph reconstructed from transformer output\" - what is this auxilary graph? it is not clearly explained\n\npage 6 The reference arXiv:2109.04825 which studied the persistence diagrams of transformer attention graphs is seemingly relevant here\n\npage 6 \"is is stable\" -> is stable\n\npage 6 what is $A(\\mathcal{G})$ in Proposition 3?\n\npage 9 when the standard PH algorithm is mentioned, and in the related works, a reference is missing : Barannikov, S. (1994). The framed Morse complex and its invariants. Advances in Soviet Mathematics, 21, 93-116, where the canonical forms=persistence barcodes were first introduced and the algorithm for their calculation was first described. \n\npage 9 \"the homologically persistent graph skeleton\" - what is meant by this?"
                },
                "questions": {
                    "value": "Why  the standard Vietoris-Rips complexes, with eg subsampling and GPU acceleration, could not be used to solve the described defense tasks?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5896/Reviewer_UAFj"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5896/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699675553793,
            "cdate": 1699675553793,
            "tmdate": 1700705619742,
            "mdate": 1700705619742,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tTuYSupjhR",
                "forum": "cnAeyjtMFM",
                "replyto": "acEuVelofz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for his detailed review with minute observations and comments to improve the paper.\n\n> (1) Further comparison with different baselines\n\nIn the revised draft, we demonstrate the performance of WGTL with different GNN backbones (for both graphs with homophily and heterophily), and in comparison with an existing defense mechanism. We elaborate the results below.\n\n(a) **Existing Defenses for GNNs:** In Appendix F.2, we have compared WGTL with two SOTA defense methods in the paper: ProGNN (Table 5) and GNNGuard [1] (Tables 18-19). With respect to ProGNN (with GCN backbone) SOTA, our method ProGNN+WGTL gains 0.68% - 4.96% of relative improvements on Cora-ML and Citeseer under mettack. On Cora-ML under mettack, our method GCN+GNNGuard+WGTL yields more than 2.25%, 1.12%, and 1.85% relative improvements with respect to GCN, GCN+GNNGuard (SOTA defense), and GCN+WGTL, respectively. \n\n[(URL to Table 5)](https://drive.google.com/file/d/13AJoUfgaXf_XHYylovvJVWG97YsoV4u2/view?usp=sharing)\n\n[(URL to Tables 18-19)](https://drive.google.com/file/d/13942jxN8ZntEusr3SgL93LScd2G_PRJ7/view?usp=sharing)\n\n(b) **Different GNN Backbone Architectures:** In addition to GCN, We have added two more backbones, GAT [6] (Tables 14-15) and GraphSAGE [2] (Tables 16-17) in Appendix F, and shown the effectiveness of WGTL on Cora-ML and Polblogs under mettack and nettack. We observe that incorporating WGTL into all of the backbones improves their corresponding performances under a range of perturbation rates. The following table summarizes the %improvement in mean accuracy with respect to the corresponding backbone models:\n$$\n\\\\begin{array}{|c|c|c|c|}\n\\\\hline\n & & \\\\% \\text{improvement on Cora-ML} & \\\\% \\text{improvement on Polblogs}  \\\\\\\\\n\\hline\nGAT+WGTL & Mettack & 0.1-13.8 & 0.6-50.2 \\\\\\\\\nGraphSAGE+WGTL & Mettack &       3.2-42.6   &   1.5-40.8 \\\\\\\\\nGAT+WGTL    \t& Nettack &  0.7-1.1     &   0.14-1.5 \\\\\\\\\nGraphSAGE+WGTL & Nettack &    3-4   &    0.4-1.7 \\\\\\\\\n\\\\hline\n\\\\end{array}\n$$\n\n[(URL to Tables 14-15)](https://drive.google.com/file/d/1315msJ6yJGCoKncR2Fd6sWimv3tSVj5n/view?usp=sharing)\n\n[(URL to Tables 16-17)](https://drive.google.com/file/d/138WvQLB6ieS-fojA9D1brAKc3NnbSm1H/view?usp=sharing)\n\n(c) **Performance for Heterophlic Graphs:** Furthermore, following [4], we incorporated the proposed global topology encoding into H${_2}$GCN [3], a popular method proposed to handle heterophilic graphs. We experiment with snap-patents, a strongly heterophilic graph under mettack. In Table 20 of Appendix F3, we have shown that H${_2}$GCN+WGTL improves the robustness of H2GCN by up to 4%. \n\nNote that the most adversarially robust method on this dataset, APPNP by [5], has been shown to have an accuracy of $27.76\\%$ under 20\\% perturbation (c.f. Table 3, [4]). Improving on that, we observe that H${_2}$GCN+WGTL achieves $28.21\\%$ average accuracy under $20\\%$ perturbation.\n\n$$\n\\\\begin{array}{|c|c|c|c|c|c|c|}\n\\\\hline\n \\text{Perturbation rates=>} & 0\\\\% & 5\\\\% & 10\\\\%  & 15\\\\% & 20\\\\% & 25\\\\% \\\\\\\\\n\\hline\nH_2GCN & 27.71\\pm 0.86  \t& 27.55 \\pm 0.19  & 28.62 \\pm 0.38 & 28.40 \\pm 1.38 & 27.77 \\pm 0.30 & 27.45 \\pm0.89  \\\\\\\\\nH_2GCN+WGTL & 27.72 \\pm 0.85 & 28.66 \\pm 0.1.68  & 28.79 \\pm 1.0 & 28.45 \\pm 0.61 & 28.71 \\pm 0.66 & 27.90 \\pm 0.84 \\\\\\\\\n\\\\hline\n\\\\end{array}\n$$\n\nThis table is included in the paper as **Table 20**.\n\n(d) **Comparison with Vietoris-Rips based encodings:** In Appendix E.2, we have implemented GCN + VRGTL, where instead of encoding witness topological features, we have encoded the Vietoris-Rips features.  Table 12 compares them on Cora-ML and Citeseer under mettack. We observe that both models have a comparable accuracy. However, Table 13 shows that Vietoris-Rips topological features take significantly more time than Witness feature computation. Hence, GCN+VRGTL does not bring much of a benefit at the expense of significantly higher computational resources. \n\n[(URL to Tables 12-13)](https://drive.google.com/file/d/13IFvmsAeIA7J6X3ShUIT9oWxa-7jU0R0/view?usp=sharing)"
                    },
                    "title": {
                        "value": "Response to Technical Questions (1/3)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496027556,
                "cdate": 1700496027556,
                "tmdate": 1700517645530,
                "mdate": 1700517645530,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "F0HTitdZMY",
                "forum": "cnAeyjtMFM",
                "replyto": "acEuVelofz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">  (2) Discussions on different aspects of Witness complex construction \n\nHere, we elaborate on four points regarding different aspects of Witness complex construction and how we address in this work the four drawbacks mentioned by the reviewer.\n\na.    The landmark selection heuristic employed is deterministic because we select the top 5% highest-degree nodes as landmarks. Since there is no randomness in such deterministic selection, there is no instability in the final performance.\n\nb.    The accuracy is indeed dependent on the number of landmarks. Figure 3 (Appendix E) shows that with an increased number of landmarks, the accuracy increases. \n\nc.    Indeed, with an increased number of landmarks, the computational cost increases, as we have shown in Figure 3. However, Table 13 indicates that even after such an increase, the computation time is still substantially less than that of Vietoris-Rips. Furthermore, Figure 3 (Appendix E) shows that the accuracy increases, becoming closer to what is obtained by GCN+VRGTL.\n\nd.    It is not clear what the reviewer meant by \u201cdifferent situations\u201d; hence, we consider the following two scenarios:\n  \n 1)    The relation between persistence diagrams induced by different sets of landmarks of the same cardinality: [8] show that irrespective of the choice of landmarks, if the landmarks are $\\epsilon$-net of the graph $G = (V, E)$, it produces a $(3log3 + 2\\epsilon)$-approximations to Vietoris-Rips complex of $G$. Let us assume two sets of landmarks  $L$, $L\u2019$ such that $|L| = |L\u2019|$ and both are $\\epsilon$-net of the graph $G = (V, E)$. Then, both choices give us the same approximation error w.r.t Vietoris-Rips. \n        \n 2)    The relations between encoding induced by different sets of #landmarks of the same cardinality:  Proposition 2 shows that the encoding $Z_{WGTL}$ is stable under adversarial perturbation. The guarantee is dependent on $\\epsilon$ but does not depend on the particular choices of landmarks. Let us assume two sets of landmarks  $L$, $ L\u2019$ such that $|L| = |L\u2019|$ and both are $\\epsilon$-net of the graph $G = (V, E)$. Then, both choices of the landmark set give us the same stability guarantee in terms of encoding $Z_{WGTL}$.\n\n>  (3) Explaining the choice concerning the number of the landmarks and its impact\n\nThe choice of the number of landmarks is indeed an important hyperparameter for the pipeline to work. We varied the number of landmarks and made an assessment of their impact on accuracy as well as the increased computation time. Figure 3 (Appendix E) shows that increasing the number of landmarks indeed slightly increases the accuracy, albeit with the expense of increased computation time. Due to this trade-off, the selection of an optimal number of landmarks is dependent on how much robustness is desired by a user with a given computation time budget. Appendix E.1  includes a more elaborate discussion on this point. \n\n[(URL to Figure 3)](https://drive.google.com/file/d/1307sEUDuvneaBrEOgzaj9dny_7gr83X1/view?usp=sharing)\n\n> (4) Using the standard Vietoris-Rips complexes in the pipeline\n\nThank you for bringing this interesting point to our attention. The Vietoris-Rips complexes can be used with the proposed pipeline, which is indicative of the flexibility offered by the proposed method. \n\nIn Appendix E.2, we have implemented GCN + VRGTL, where instead of encoding witness topological features, we have encoded the Vietoris-Rips features. Table 12 shows that the accuracy is comparable to that of GCN+WGTL while at the cost of a significant increase in computation time (Table 13). In our implementation, we adopted Ripser (SOTA for CPU-based computation) for computing both Vietoris-Rips and Witness topological features. Hence, if a GPU-accelerated implementation,e.g., Ripser++, were to be used, it would have accelerated Vietoris-Rips as well as Witness feature computations. \n\n[(URL to Tables 12-13)](https://drive.google.com/file/d/13IFvmsAeIA7J6X3ShUIT9oWxa-7jU0R0/view?usp=sharing)\n\n> (5) Clarification of theoretical results\n\nWe have clarified the theoretical results in the main paper. In addition, we have included in Appendix D a nomenclature of notations (Appendix D.1) and detailed derivations of the proofs to enhance clarity. Please consider the revised draft for the changes.\n\n> (6) Specifying the dimensions used in the persistence diagrams\n\nThank you for your detailed observation. Our theoretical results hold true once we fix the dimension of the persistence $d \\in Z_{\\geq 0}$ to be computed and use it throughout the pipeline. In our experiments, we used 0-dimensional persistence. We have added it in Section 5 (paragraph 1) of our updated manuscript."
                    },
                    "title": {
                        "value": "Response to Technical Questions (2/3)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700496939026,
                "cdate": 1700496939026,
                "tmdate": 1700517654067,
                "mdate": 1700517654067,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LF5KeJZYYS",
                "forum": "cnAeyjtMFM",
                "replyto": "acEuVelofz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> (7) Computational complexity of the Witness complex-based topological features\n\nThank you for pointing out this issue. \nWe have corrected the computational complexity segment in Section 5 as per the following:\n\nLandmark selection (top-$|\\mathfrak{L}|$ degree nodes) has complexity $\\mathcal{O}(N\\log(N))$. To compute witness topological features, one needs to compute (1) landmarks-to-witness distances costing $\\mathcal{O}(|\\mathfrak{L}|(N+|\\mathcal{E}|))$ due to BFS-traversal from landmarks, (2) landmark-to-landmark distances costing $\\mathcal{O}(|\\mathfrak{L}|^2)$, and finally (3) persistent homology via boundary matrix construction and reduction [7]. Matrix reduction algorithm costs $\\mathcal{O}(\\zeta^3)$, where $\\zeta$ is the number of simplices in a filtration. Overall, the computational complexity of computing witness topological feature on the graph is $\\mathcal{O}(|\\mathfrak{L}|(N+|\\mathcal{E}|)+|\\mathfrak{L}|^2+\\zeta^3)$.\n\n> (8) Specific remarks\n\nThank you for pointing out these mistakes/typos. We have addressed them in our updated manuscript. \nHere, we address two specific questions mentioned in this list.\n\n> page 2 \"complementary information\" - complementary to what? it is not very clear\n  \nBy complementary information here, we understand more traditional graph summaries that are not extracted using any tools of persistent homology.\n\n> page 9 \"the homologically persistent graph skeleton\" - what is meant by this?\n\nWe have reformulated this sentence as follows: \u201cAnother interesting research direction is to investigate the linkage between the attacker's budget, number of landmarks, and topological attacks targeting the skeleton shape, that is, topological properties of the graph induced by the most important nodes (landmarks).\u201d\n\nReferences:\n\n[1]  Xiang Zhang and Marinka Zitnik. Gnnguard: Defending graph neural networks against adversarial\nattacks. Advances in neural information processing systems, 33:9263\u20139275, 2020\n\n[2] Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs.\nAdvances in neural information processing systems, 30, 2017.\n\n[3] Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. Beyond\nhomophily in graph neural networks: Current limitations and effective designs. Advances in neural\ninformation processing systems, 33:7793\u20137804, 2020\n\n[4] Jiong Zhu, Junchen Jin, Donald Loveland, Michael T Schaub, and Danai Koutra. How does\nheterophily impact the robustness of graph neural networks? theoretical connections and practical\nimplications. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and\nData Mining, pp. 2637\u20132647, 2022\n\n[5] Johannes Gasteiger, Aleksandar Bojchevski, and Stephan Gunnemann. Predict then propagate: Graph\nneural networks meet personalized pagerank. arXiv preprint arXiv:1810.05997, 2018\n\n[6] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua\nBengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017.\n\n[7] Edelsbrunner, Letscher, and Zomorodian. Topological persistence and simplification. Discrete &\nComputational Geometry, 28:511\u2013533, 2002\n\n[8] Naheed Anjum Arafat, Debabrota Basu, and Stephane Bressan. \u03b5-net induced lazy witness complexes\non graphs. arXiv preprint arXiv:2009.13071, 2020"
                    },
                    "title": {
                        "value": "Response to Technical Questions (3/3)"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700497666375,
                "cdate": 1700497666375,
                "tmdate": 1700544959476,
                "mdate": 1700544959476,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "F2vySMn44p",
                "forum": "cnAeyjtMFM",
                "replyto": "acEuVelofz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors",
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We are eager for your feedbacks"
                    },
                    "comment": {
                        "value": "Dear Reviewer UAFj,\n\nThank you again for the time and effort that you dedicated to providing invaluable feedback on our paper. We would very much appreciate if you could consider updating the scores before the deadline (rapidly approaching). Please let us know If there are any remaining concerns.\n\nBest,\n\nPaper ID 5896 Authors"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669158538,
                "cdate": 1700669158538,
                "tmdate": 1700669382630,
                "mdate": 1700669382630,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9MelwUvlOy",
                "forum": "cnAeyjtMFM",
                "replyto": "F2vySMn44p",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5896/Reviewer_UAFj"
                ],
                "readers": [
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5896/Authors",
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5896/Reviewer_UAFj"
                ],
                "content": {
                    "comment": {
                        "value": "I acknowledge reading the authors response. Some improvements are incorporated in the text. \nOne of remarks I'm not convinced by is that GPU accelerated implementation will benefit equally the standard Vietoris-Rips complex and its approximation given by the witness complex. \nSome other issues need further attention, in particular a better explanation of the need for the complicated pipeline involving the topological features of attention graphs constructed over aggregated local and global topological encodings."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5896/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701874780,
                "cdate": 1700701874780,
                "tmdate": 1700701874780,
                "mdate": 1700701874780,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]