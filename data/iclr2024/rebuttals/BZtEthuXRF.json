[
    {
        "title": "Manifold Diffusion Fields"
    },
    {
        "review": {
            "id": "F29g6jWCnf",
            "forum": "BZtEthuXRF",
            "replyto": "BZtEthuXRF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2803/Reviewer_wDdD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2803/Reviewer_wDdD"
            ],
            "content": {
                "summary": {
                    "value": "The authors extend diffusion fields onto Riemannian manifolds. They leverage the Laplace Beltrami operator as a way to get local coordinates. The authors then present experimental results in many situations comparing their approach to SOTA techniques.\n\nMinor comment: in 3.3 end of the first paragraph should use langle rangle rather than less than greater than signs,"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The overall idea the paper presents is relatively simple to understand so it is easy to follow what the authors are attempting to accomplish."
                },
                "weaknesses": {
                    "value": "There are some errors when introducing Reimannian manifolds, for instance the authors state $g:\\mathcal{M}\\times\\mathcal{M}\\rightarrow\\mathbb{R}_+$ but this is not true, the metric tensor takes in inputs from the tangent spaces and further can be 0.\n\nThe authors have a specific goal in mind for the manifolds they wish to consider but the theory seems to be more general in a sense. That is, typical Riemannian manifolds such as the cone of SPD matrices or a Grassman manifold go largely un mentioned. The authors focus on specific manifolds which could be interesting such as the Stanford bunny, but I lack to see the importance/applicability of it. That being said, it is a nice application but a little mysterious as to its usefulness."
                },
                "questions": {
                    "value": "I understand the usefulness of using function and field interchangeably but I am curious as to why this choice was made. I ask this because over Riemannian manifolds it's common to use gradient vector fields which are defined over tangent spaces and the use of fields can cause confusion here."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2803/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2803/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2803/Reviewer_wDdD"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2803/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698517147533,
            "cdate": 1698517147533,
            "tmdate": 1699636222902,
            "mdate": 1699636222902,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SJYxyVVQ3C",
                "forum": "BZtEthuXRF",
                "replyto": "F29g6jWCnf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2803/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2803/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We want to thank the reviewer for their suggestions which we believe helped improve the quality of the paper. We remain open to address any further concerns that the reviewer may have to improve the paper before updating their decision.\n\n* **There are some errors when introducing Reimannian manifolds, for instance the authors state $g:\\mathcal{M} \\times \\mathcal{M} \\rightarrow \\mathbb{R}_+$  but this is not true, the metric tensor takes in inputs from the tangent spaces and further can be 0.**\n\n   * We thank the reviewer for pointing this typo, we have updated the notation to include the tangent spaces. In addition, we have fixed the fact that the metric can be 0.\n\n\n* **The authors have a specific goal in mind for the manifolds they wish to consider but the theory seems to be more general in a sense. That is, typical Riemannian manifolds such as the cone of SPD matrices or a Grassman manifold go largely unmentioned.**\n\n    * We thank the reviewer for pointing this out. In this paper, we primarily provide a recipe for learning generative models over Riemannian manifolds in practical settings. As a result, our extensive experimental evaluation includes experiments in graphs, meshes and pointclouds as discrete approximations of continuous Riemannian manifolds. We are excited about the opportunities MDF affords to future work focusing on Grassman and and other analytical manifolds. This could lead to new insights on how to a model a broader class of subspaces, which could be relevant to topology but also applications in computer vision, signal processing, etc.\n\n\n* **The authors focus on specific manifolds which could be interesting such as the Stanford bunny, but I lack to see the importance/applicability of it. That being said, it is a nice application but a little mysterious as to its usefulness.**\n\n   * We thank the reviewer for pointing this out. In our submission, we focus on practical scenarios where MDF can be applied. The Stanford bunny and the other 3D meshes we used in our paper are meant to exemplify the generality of the approach on general manifolds typically used in the community. In addition, we show state-of-the-art results not only in climate prediction on the ERA5 dataset (climate on the sphere) in Sect. 5.1, but also on molecular conformer generation in Sect 5.3 (a core problem in computation chemistry). Finally, in the appendix Sect. A.6.3 we provide results using MDF to model PDEs, which is a fundamental problem across multiple scientific disciplines. We believe these experiments showcase extremely useful and exciting applications of our model across different scientific domains. In addition, MDF presents an exciting opportunity to unify diffusion generative models across many different modalities and problems.\n\n\n\n* **I understand the usefulness of using function and field interchangeably but I am curious as to why this choice was made. I ask this because over Riemannian manifolds it's common to use gradient vector fields which are defined over tangent spaces and the use of fields can cause confusion here.**\n\n   * In the area of generative models for functions, works like Functa[1], GASP[2] and DPF [3] denote functions as fields or implicit representations. We borrow this terminology for consistency since these works are the conceptually closest approaches to MDF. Note that we explicitly have avoided the use of the term \"gradient vector field\" or \"gradient field\" in the paper to not confuse readers. We have added a clarification sentence in the paper.\n\n*  **Minor comment: in 3.3 end of the first paragraph should use langle rangle rather than less than greater than signs.**\n   * We have fixed this typo.\n\n\n[1] Dupont, Emilien, et al. \"From data to functa: Your data point is a function and you can treat it like one.\" arXiv preprint arXiv:2201.12204 (2022).\n\n[2] Dupont, Emilien, Yee Whye Teh, and Arnaud Doucet. \"Generative models as distributions of functions.\" arXiv preprint arXiv:2102.04776 (2021).\n\n[3] Zhuang, Peiye, et al. \"Diffusion probabilistic fields.\" The Eleventh International Conference on Learning Representations. 2022."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2803/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700027309999,
                "cdate": 1700027309999,
                "tmdate": 1700027309999,
                "mdate": 1700027309999,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gk0jv1G4wN",
                "forum": "BZtEthuXRF",
                "replyto": "SJYxyVVQ3C",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2803/Reviewer_wDdD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2803/Reviewer_wDdD"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for your responses.\n\nI still question the usefulness of the particular manifolds chosen but I see the authors state they are common examples in the literature. If that is the case, that is fine. I do agree the authors have demonstrated their techniques on a variety of manifolds."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2803/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700585658485,
                "cdate": 1700585658485,
                "tmdate": 1700585658485,
                "mdate": 1700585658485,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1GsungqT0C",
                "forum": "BZtEthuXRF",
                "replyto": "AaugmF46TF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2803/Reviewer_wDdD"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2803/Reviewer_wDdD"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the follow up. Your follow up did clear up some questions I had. That being said I think my score accurately reflects the paper."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2803/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700679619980,
                "cdate": 1700679619980,
                "tmdate": 1700679619980,
                "mdate": 1700679619980,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BJwmBDi273",
            "forum": "BZtEthuXRF",
            "replyto": "BZtEthuXRF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2803/Reviewer_YGhV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2803/Reviewer_YGhV"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed the extension of diffusion probabilistic fields onto Riemannian manifolds. The proposed method utilizes the Laplace-Beltrami operator to build an efficient representation of the points on Riemannian manifolds, which makes the proposed method invariant with respect to rigid and isometric transformations of the manifold. Numerical experiments are provided to show the efficacy of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method is the first work that can handle the diffusion process where the support of the distribution is on Riemannian manifolds. The proposed usage of the eigen-functions of Laplace-Beltrami operator makes the proposed method invariant w.r.t. affine and isometric transformations. The proposed method outperforms existing diffusion models on manifolds."
                },
                "weaknesses": {
                    "value": "(Please respond to the questions section directly) The proposed method seems to be a plain extension of a previous work of diffusion probabilistic field. This extension shows a great potential for non-Euclidean domain but the work seems not to focusing on the discussion of how this new representation improves the work quantitatively."
                },
                "questions": {
                    "value": "1. The main concern, as stated in the Weakness section, is the comparison of this work with [1]. To me, the difference of this work with [1] is only the different ways of representing points on the Riemannian manifold, where [1] directly use some coordinate since the manifolds we consider are always embedded, and this work uses the leading eigen-function of the LBO to approximate the points. It remains not very clear why and how LBO sign-functions outperforms a plain coordinate approach, or a local chart approach (since for every point on the manifold we have a local coordinate chart). Calculating eigen-functions of LBO potentially also consumes time. A more elaborative discussion of different approaches to do the embedding seems necessary.\n\n2. The authors choose the top k LBO eigen-functions to do the embedding. is there a guidance on how to determine k?\n\n3. Regarding Algorithm 2: First, what\u2019s $M_q$, which seems to exist in [1] but not here? Second why do we need a random subset $C_{t}$? I thought we just need the same context and query sets as in Algorithm 1.\n\n4. Regarding the numerical experiments, I\u2019m particularly interested in the ERA5 dataset, which seems to be the only natural instance of manifold-supported distributions. It would be interesting to see how the proposed algorithm performs in terms of COV and MMD for this dataset, comparing to other algorithms as DPF and GASP.\n\nReferences: \n[1] Zhuang, Peiye, et al. \"Diffusion probabilistic fields.\"\u00a0The Eleventh International Conference on Learning Representations. 2022."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2803/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698774136226,
            "cdate": 1698774136226,
            "tmdate": 1699636222808,
            "mdate": 1699636222808,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "VK7QjPMb91",
                "forum": "BZtEthuXRF",
                "replyto": "BJwmBDi273",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2803/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2803/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "* **To me, the difference of this work with [1] is only the different ways of representing points on the Riemannian manifold, where [1] directly use some coordinate since the manifolds we consider are always embedded, and this work uses the leading eigen-function of the LBO to approximate the points. It remains not very clear why and how LBO eigen-functions outperforms a plain coordinate approach, or a local chart approach (since for every point on the manifold we have a local coordinate chart)[...]**\n\n\n   * We thank the reviewer for raising this point, which deserves clarification. In practical terms, Tab. 1-2-3-4 in the paper show a comparison between MDF (which uses the eigen-functions of the LBO) and DPF (which uses a plain coordinate approach). Our results, show that MDF consistently outperforms DPF (ref. Tab. 1-2-3-4). We attribute this to the fact that representing points through the eigen-functions of the LBO explicitly provides the model with information about the intrinsic geometry of the manifold. Furthermore, in Sect. A.6.2  in the appendix we show that DPF completely breaks under rigid (Fig. 12) or isometric (Fig. 13) transformations of the manifold, while MDF is invariant to these transformations since it uses an intrinsic coordinate system. \n    \n   * In addition, note that although one needs to compute the eigen-functions of the LBO, this computation: (i) Is very efficient, since Laplacians are sparse matrices and efficient eigen-system solvers can be used. (ii) Only needs to be performed once before training, caching eigen-functions for usage during training. In practice, the cost of computing the LBO eigen-functions is negligible compared to training the diffusion model.\n\n\n    * We have included a new section in the Appendix (Sect. A.3) discussing at length the different ways to compute embeddings.\n\n    \n* **The authors choose the top k LBO eigen-functions to do the embedding. Is there a guidance on how to determine $k$?**\n\n    * Conceptually speaking, $k$ is usually dependent the specific manifold under consideration and its intrinsic geometry. Manifolds with high frequency geometry typically require larger $k$. In Figure 7, we illustrate the impact of varying $k$ on performance metrics (COV and MMD). Notably, we observe satisfactory performance even for small values of $k$. In MDF, we choose $k$ experimentally but one could also choose $k$ based on the overall variance explained of the manifold (similar to PCA).\n    \n    \n* **Regarding Algorithm 2: First, what\u2019s $M_q$, which seems to exist in [1] but not here? Second why do we need a random subset ? I thought we just need the same context and query sets as in Algorithm 1.**\n\n    * In [1], $M_q$,    denotes the stacked coordinates of query pairs. In our context, we use $\\varphi(\\mathbf{X}_{q})$ to denote the stacked eigen-function corresponding to query pairs. Note that during inference, one can select a random subset of query pairs as context. In particular, it can be equivalent to the one used during training but it does not need to be.\n    \n* **Regarding the numerical experiments, I\u2019m particularly interested in the ERA5 dataset, which seems to be the only natural instance of manifold-supported distributions. It would be interesting to see how the proposed algorithm performs in terms of COV and MMD for this dataset, comparing to other algorithms as DPF and GASP.**\n\n   * Tab 5 provides further insights on the ERA5 dataset, demonstrating that MDF outperforms GASP in terms of both COV and MMD. \n\n\nWe thank the reviewer for their suggestions which we believe helped improve the quality of the paper. We remain open to address any further concerns that the reviewer may have to improve the paper before updating their decision."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2803/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700027333838,
                "cdate": 1700027333838,
                "tmdate": 1700027333838,
                "mdate": 1700027333838,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LOnKM7KPrb",
                "forum": "BZtEthuXRF",
                "replyto": "r4xoyprLgB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2803/Reviewer_YGhV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2803/Reviewer_YGhV"
                ],
                "content": {
                    "title": {
                        "value": "Ackonwledgement of the rebuttal"
                    },
                    "comment": {
                        "value": "I thank the authors for the rebuttal and sorry for not being able to reply due to a tight schedule on my side.\n\nI decide not to change my evaluation as I believe that this work is still not significantly from the previous work of DPF. The numerical experiment may show the efficiency of the proposed method but the contribution conceptually/theoretically seems less significant."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2803/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674570631,
                "cdate": 1700674570631,
                "tmdate": 1700674570631,
                "mdate": 1700674570631,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZeNIOQJTaB",
            "forum": "BZtEthuXRF",
            "replyto": "BZtEthuXRF",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2803/Reviewer_WPEM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2803/Reviewer_WPEM"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a methodology for learning fields over manifolds with denoising diffusion probabilistic models. It uses an approximation of eigen-functions of the Laplace-Beltrami Operator for the manifold at hand to create an intrinsic functional basis for the manifold. This approximation is the eigendecomposition of the graph Laplacian of the mesh approximating the manifold. This formulation theoretically allows the model to learn from data that live in manifolds, even in the absence of analytical forms for the metric of the manifold and related operators."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is excellently written, with very clear explanations, illustrations, and algorithms. Experimentally, the paper covers a lot of \"ground\" in terms of exploring the capabilities of their model. This includes comparisons against the closest-related model in multiple scenarios and comparisons against task-specific models (molecule generation).\n\nI believe the paper does a good job at showing how this relatively direct tweak to how DPF works is a very appropriate one. This is supported by a sufficient amount of experimental evidence, which explores most practical questions about such a change in representation.\n\nInterestingly, the paper also shows the robustness of the model to rigid transformations on the manifold, having a much more appropriate behavior in this case than the model it is mostly based on."
                },
                "weaknesses": {
                    "value": "I believe the model's biggest weakness is its novelty. Theoretically, there is only a small contribution compared to DPF (Zhuang et al., 2023).\n\nWhile the authors theoretically discuss the possibility to use Laplace-Beltrami Operators as the source for a functional basis on the manifolds, this is only explored as graph Laplacians, which are a discrete approximation of manifolds. Understandably, in many scenarios it is not possible to analytically solve this problem, but it is unclear how challenging it is to adapt the ideas presented here to scenarios where it is possible (or how beneficial that is). A simple fix to this issue, in my opinion, is to claim what is being extensively evaluated experimentally: graphs/meshes as an approximation of a manifold.\n\n**Update after rebuttal**\n\nThe authors have updated their paper to clarify their claims and point out the equivalence, at least in one experiment, of their use of graph Laplacians to the analytical LBO (Table 5 shows results of this case). After reading the comments of other reviewers and the rebuttals, I am increasing my score to 8."
                },
                "questions": {
                    "value": "1. Is the model's robustness to rigid transformations on the manifold a sufficient explanation for its performance for molecule generation? Is it possible that it is also robust to other types of transformations which are useful in solving this task?\n\n*Minor comments*\n- Sec. 3.3: were $<$ and $>$ the intended symbols when writing $f$ as a linear combination of the basis?\n- Sec. 3.3: \"making MDF strictly operate the manifold\" => \"on the\"?\n- p. 7: \"available at [URL]\" I think a footnote here is less disruptive for reading"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2803/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2803/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2803/Reviewer_WPEM"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2803/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698950633319,
            "cdate": 1698950633319,
            "tmdate": 1700647315614,
            "mdate": 1700647315614,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0sV6nbZh9i",
                "forum": "BZtEthuXRF",
                "replyto": "ZeNIOQJTaB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2803/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2803/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We want to thank the reviewer for their suggestions which we believe helped improve the quality of the paper. We remain open to address any further concerns that the reviewer may have to improve the paper before updating their decision.\n\n\n* **I believe the model's biggest weakness is its novelty. Theoretically, there is only a small contribution compared to DPF (Zhuang et al., 2023).**\n\n   * In this work we generalize the problem setting in DPF to deal with functions on Riemannian manifolds. Our proposed approach is conceptually simple to implement while being very powerful in its application.  Part of our contribution was to study how far a small change in the representation of points can take the performance of the model. Using the eigen-functions of the LBO is critical in the setting. As a result the novelty aspect is in understanding what are key ingredients needed to extend in DPF.\n\n   * It is also worth noting that MDF not only outperforms DPF in the Riemannian setting, but also can be directly applied to important scientific problems ranging from climate prediction to molecular conformation obtaining state-of-the-art results. We believe that approaches that are both simple to implement and powerful tend to have long lasting impact in the field. Finally, MDF opens up an interesting area of research to unify different data modalities and problems under a common training recipe and model. For example, unifying 2D and 3D representations.\n\n\n\n* **While the authors theoretically discuss the possibility to use Laplace-Beltrami Operators as the source for a functional basis on the manifolds, this is only explored as graph Laplacians, which are a discrete approximation of manifolds. Understandably, in many scenarios it is not possible to analytically solve this problem, but it is unclear how challenging it is to adapt the ideas presented here to scenarios where it is possible (or how beneficial that is). A simple fix to this issue, in my opinion, is to claim what is being extensively evaluated experimentally: graphs/meshes as an approximation of a manifold.**\n\n\n   * We thank the reviewer for raising this point which we completely agree deserves clarification. We have clarified in the contributions that the bulk of our experimental evaluation covers graphs, meshes and pointclouds (ref. Tab 6 and Fig. 8) as discrete approximations of manifolds, which is important in most practical settings.\n\n   * We would also like to point the reviewer to Tab 5. where we show results of MDF on the ERA5 dataset, which consists of temperatures on on a parametric manifold (eg. earth represented as a sphere). In this case, the analytical solution for the eigenfunctions of the LBO are given by spherical harmonics (second paragraph of page 7). Our results show that using spherical harmonics MDF outperforms previous approaches to learn functions on the sphere, like GASP [2]. We have clarified this in the paper.\n\n   * A final clarification point is that this approach has a theoretical connection to the analytical LBO, as the eigenvectors and eigenvalues of the graph Laplacian converge to the eigenfunctions and eigenvalues of the analytical LBO as the number of vertices/nodes tends to infinity [1].\n\n    [1] Convergence of Laplacian eigenmaps. in Adv. Neur. In.: Proceedings of the 2006 Conference, vol. 19, p. 129. The MIT Press.\n\n    [2] Dupont, Emilien, Yee Whye Teh, and Arnaud Doucet. \"Generative models as distributions of functions.\" arXiv preprint arXiv:2102.04776 (2021).\n\n* **Is the model's robustness to rigid transformations on the manifold a sufficient explanation for its performance for molecule generation? Is it possible that it is also robust to other types of transformations which are useful in solving this task?**\n\n  * We thank the reviewer for raising this very interesting point. It is true that the robustness to rigid transformations can be helpful for conformer generation, we do believe that this is not the only explanation for the performance of MDF. Our current hypothesis is that the eigen-functions of the LBO provide a function basis that helps the model find representations that can be aligned across molecules and in turn this boosts performance. Note that generating conformers can be thought of in a way as a non-rigid transformation of a base molecular structure and MDF appears to be quite good at discovering this set of non-linear symmetries. We will fully uncover and understanding of this behaviour in future work.\n\n\n\n* **Sec. 3.3: were < and > the intended symbols when writing  as a linear combination of the basis?**\n   * Thanks for pointing out this typo, we have fixed it in the new version of the paper.\n\n* **Sec. 3.3: \"making MDF strictly operate the manifold\" => \"on the\"?**\n   * We fixed the typo in the new version of the paper.\n\n* **p. 7: \"available at [URL]\" I think a footnote here is less disruptive for reading**\n   * We have moved this into the appendix to keep the paper at 9 pages."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2803/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700027382177,
                "cdate": 1700027382177,
                "tmdate": 1700027382177,
                "mdate": 1700027382177,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "H8lOENBkrl",
                "forum": "BZtEthuXRF",
                "replyto": "0sV6nbZh9i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2803/Reviewer_WPEM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2803/Reviewer_WPEM"
                ],
                "content": {
                    "comment": {
                        "value": "> We believe that approaches that are both simple to implement and powerful tend to have long lasting impact in the field.\n\nI 100% agree with that. The point I was making is rather on the novelty of the theoretical contribution. This would be the biggest weakness not because it is a bad thing, but because in other aspects the paper is strong. I believe, experimentally, the paper shows more than enough evidence that this theoretically simple change is indeed impactful and I appreciate that.\n\n> We have clarified in the contributions that the bulk of our experimental evaluation covers graphs, meshes and pointclouds (ref. Tab 6 and Fig. 8) as discrete approximations of manifolds, which is important in most practical settings.\n\nAlright! I'm happy with that.\n\n> We would also like to point the reviewer to Tab 5. where we show results of MDF on the ERA5 dataset, which consists of temperatures on on a parametric manifold (eg. earth represented as a sphere). In this case, the analytical solution for the eigenfunctions of the LBO are given by spherical harmonics (second paragraph of page 7). Our results show that using spherical harmonics MDF outperforms previous approaches to learn functions on the sphere, like GASP [2].\n\nThank you for pointing out this detail I overlooked, the clarification, and updating the paper to make this evident. I am more than pleased to update my score.\n\n> It is true that the robustness to rigid transformations can be helpful for conformer generation, we do believe that this is not the only explanation for the performance of MDF. Our current hypothesis is that the eigen-functions of the LBO provide a function basis that helps the model find representations that can be aligned across molecules and in turn this boosts performance. Note that generating conformers can be thought of in a way as a non-rigid transformation of a base molecular structure and MDF appears to be quite good at discovering this set of non-linear symmetries.\n\nThat seems reasonable to me. I am curious to see how exploring this turns out."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2803/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644814044,
                "cdate": 1700644814044,
                "tmdate": 1700644814044,
                "mdate": 1700644814044,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]