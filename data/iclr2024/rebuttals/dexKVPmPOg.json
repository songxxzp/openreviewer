[
    {
        "title": "Efficient Recomputation of Marginal Likelihood upon Adding Training Data in Gaussian Processes and Simulator Fusion"
    },
    {
        "review": {
            "id": "xpydA0QXLS",
            "forum": "dexKVPmPOg",
            "replyto": "dexKVPmPOg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8700/Reviewer_yLdo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8700/Reviewer_yLdo"
            ],
            "content": {
                "summary": {
                    "value": "This paper describes a method to incorporate extra training data to learn a particular prediction tasks using Gaussian processes. The proposed method consists in following a particular approach to decide whether a particular data instance should be incorporated to the training data or not. The criterion followed consists in using the negative log likelihood given by the predictive distribution of the GP after incorporating a particular training instance. This is equivalent to changing the prior GP to another GP that is expected to perform better (since it gives a better marginal likelihood estimation). The proposed method is expensive if a naive implementation is followed, with O(N^4) cost on the number of data points or iterations to follow. The authors proposed a clever implementation that takes into account partial updates of Cholesky factors. The method is validated on synthetic datasets both in terms of performance and in terms of computational cost."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is very well written and clearly explained. Apart from that, I cannot find any other particular strength. My overall impression is that the paper is still in an early stage and needs more work before it can be accepted for publication. In particular, the authors should address the weaknesses described below."
                },
                "weaknesses": {
                    "value": "The experimental section is too weak. It only considers synthetic datasets. It is not clear at all if the proposed method has a practical utility since no real world problems are considered in the paper. This questions the significance of the results. The authors should given particular examples of the expected utility of the proposed approach in a real-world setting.\n\n        The paper lacks a solid related work section. It is not clear at all if this problem has been already studied in the literature and if some methods have already been devised for it. In the introduction there are some related methods described. However, they seem methods proposed for a different setting that may be adapted to the particular setting considered by the authors.\n\n        The proposed method has a very large computational cost that is cubic w.r.t. to the number of training points or the points to be added to the training set. This is a limitation since only a few thousand points may be considered at most. The authors should try to scale the method to larger experimental settings, considering e.g., approaches for sparse GPs.\n\n        The use of Cholesky factors that are updated efficiently is not new within the GP literature."
                },
                "questions": {
                    "value": "Why do not each method in Fig. 1 start from the same initial value?\n\nCould you approach be extended to take advantage of sparse GPs approaches to scale to large datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8700/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8700/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8700/Reviewer_yLdo"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8700/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698660768730,
            "cdate": 1698660768730,
            "tmdate": 1700665019627,
            "mdate": 1700665019627,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "R8QNFKH9Y7",
                "forum": "dexKVPmPOg",
                "replyto": "xpydA0QXLS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to AnonReviewer yLdo"
                    },
                    "comment": {
                        "value": "We're really grateful for the time and effort you've put into reviewing our work. Your constructive feedback has been very valuable to us.\n\nFirstly, we would like to address the concerns raised by all reviewers regarding the lack of experiments with real data. We agree that conducting experiments with real data is crucial for enhancing the reliability of our method. Therefore, we have conducted these experiments and included the results in Figure 1 (c). Please review the updated figure for your reference.\n\nWeaknesses\n> The experimental section is too weak. It only considers synthetic datasets.\n\nIn response to the concern regarding the use of real datasets, we have conducted additional experiments with actual data. The methodology and the description of these experiments are detailed in the third paragraph of Section 4.1, and the results are presented in Figure 1(c). Although the differences are not as pronounced as with synthetic data, the results show an improvement in MSE over the standard Gaussian Process. Furthermore, they demonstrate that our approach is not influenced by deviations from the true distribution, which can affect methods like SoD when using simulator data.\n\n> The paper lacks a solid related work section. \n\nWe appreciate the feedback regarding the related work section. Due to space constraints within the main text, we chose to briefly introduce only the most pertinent related works in the Introduction and provided a comprehensive review of the related literature in Appendix A. We acknowledge that the location of this section may not be immediately apparent to readers. To address this, we have now explicitly indicated in multiple relevant parts of the Introduction that a detailed discussion of related works can be found in Appendix A. This should guide the readers to the extended review, ensuring they are aware of the broader context and precedent for our work.\n\n> The proposed method has a very large computational cost that is cubic w.r.t. to the number of training points or the points to be added to the training set. This is a limitation since only a few thousand points may be considered at most. The authors should try to scale the method to larger experimental settings, considering e.g., approaches for sparse GPs.\n\nWe acknowledge the reviewer's concerns regarding the computational expense of our method. As depicted in Figure 4, the computational time for our proposed method, even with 7000 training points, is under three hours. It's important to clarify that this computation is not recurrent for every prediction, but is a one-time cost incurred during the data selection phase from the simulator. Given this context, we consider the computational demand to be practical for the intended applications. \n\n> The use of Cholesky factors that are updated efficiently is not new within the GP literature.\n\nThe efficient update of Cholesky factors is indeed a known technique within GP literature, as (\\cite{osborne2010bayesian}) have previously demonstrated the computation of $\\mathbf{L}\\_{m+1}$ from $\\mathbf{L}\\_{m}$ in $O(m^2)$ time. Our method, however, introduces an efficient computation for deriving $\\mathbf{V}\\_{m+1}$ from $\\mathbf{V}\\_{m}$ with a complexity of $O(mN+N^2)$, where $\\boldsymbol{\\Sigma}\\_{m+1}=\\mathbf{V}\\_{m+1}\\mathbf{V}\\_{m+1}^\\mathsf{T}$. To communicate this effectively, we have detailed this contribution in footnote 5. We believe our computational technique, which is elaborated in Section 3.2, is not trivial.\n\nQuestions:\n\n> Why do not each method in Fig. 1 start from the same initial value?\n\nThe horizontal axis in Figure 1 represents the number of true training data points, not the generated data. The data point at the left end of Figure 1 corresponds to the MSE when there are 50 true training data points. Since each method selects a different number and subset of generated data to use, the MSEs vary accordingly. This explains the difference in starting points across the methods depicted in the figure.\n\n> Could you approach be extended to take advantage of sparse GPs approaches to scale to large datasets?\n\nYes, our approach can indeed be extended to leverage sparse Gaussian processes for scalability to larger datasets. The most straightforward adaptation would be to first select the data from the simulator to be added to the training set using our proposed method, and then treat the combined dataset from the selected data and the original training data indistinctly when applying sparse GPs approaches. There is also potential for a more sophisticated integration of our method with sparse GPs, which could further enhance efficiency and scalability."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700594366856,
                "cdate": 1700594366856,
                "tmdate": 1700594742933,
                "mdate": 1700594742933,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JNSQ65Luk5",
                "forum": "dexKVPmPOg",
                "replyto": "R8QNFKH9Y7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Reviewer_yLdo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Reviewer_yLdo"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "I acknowledge the effort made by the reviewers to improve their paper, and I have increased a bit my score in consequence. However, including only one real-world problem in the paper, I think is insufficient. Therefore, I still think that this paper needs more work."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665002789,
                "cdate": 1700665002789,
                "tmdate": 1700665002789,
                "mdate": 1700665002789,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3hmRcca4nF",
            "forum": "dexKVPmPOg",
            "replyto": "dexKVPmPOg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8700/Reviewer_1Da7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8700/Reviewer_1Da7"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes to use the negative log marginal likelihood of the Gaussian process as a criterion when selectively adding simulator-generated data to the training data. Since evaluating each candidate training data point using the negative log marginal likelihood can be time-consuming, the authors propose a method for fast computation by considering the so-called Cholesky update and take advantage of the dependencies between matrix elements."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Originality: Probably, the faster re-computation of the marginal likelihood might be the originality of the work. \n\nQuality: The experiments provided in the paper are useful to provide an idea of the approach, though they are limited to just presenting synthetic scenarios. \n\nClarity: The methodology sections are generally well written and not difficult to follow, though they present some inconsistencies in the mathematical notation.\n\nSignificance (importance): The work has its strength in the efficient computation of the marginal likelihood."
                },
                "weaknesses": {
                    "value": "-The idea of accepting data to be added as part of the training set by improving the marginal likelihood was previously explored by Titsias M. in \"Variational Learning of Inducing Variables in Sparse Gaussian Processes\" section 3.1. In the context of Titsias' work was used to generated pseudo-inputs (or inducing points).\n\n-The experiments provided are limited to just presenting synthetic scenarios. \n\n-The introduction does not properly motives the research problem to engage the reader with the work. Also, the introduction lacks of references to better support different phrases or claims. The methodology sections are generally well written and not difficult to follow, though they present some inconsistencies in the mathematical notation.\n\n-The work has its strength in the efficient computation of the marginal likelihood, but the main aim of the work was not to compare such an algorithm with other approaches that improve such computation, but to introduce a direct method of selectively adding simulator-generated data to training data when using Gaussian processes."
                },
                "questions": {
                    "value": "---Specific comments---\n\n-In Abstract, it sounds contradictory to say that we rely on knowledge that is unreliable: \"construct models based on their knowledge of the modeling target and, as training data increases, choose more flexible models with reduced dependence on that knowledge if that knowledge is unreliable.\"\nMaybe the last sentence would be better understood if read as:\"...if that knowledge becomes unreliable\" or simply get rid of last part and leave: \"construct models based on their knowledge of the modeling target and, as training data increases, choose more flexible models with reduced dependence on that knowledge.\"\n\n-In Abstract, it is not clear what it is the intention of \"We propose a faster method considering the Cholesky factor and matrix element dependencies.\" There is something missing to properly connect with all the previous text.\n\n-In the Introduction, there is probably a sentence missing at the very beginning regarding modelling issues or modelling challenges than allows the reader understand where the idea or problem of bias-variance trade-off comes from. Also, it is necessary to include a strong reference regarding \"bias-variance trade-off\" to support the text.\n\n-In the introduction, the phrase that reads: \"On the other hand, the method of selectively adding generated\nsimulator data to the training data only requires that data can be generated from the simulator\" seems ambiguous or needs rewording.\n\n-Please include references to support: \"The criterion for selecting important data is the diversity of the training data. Various methods to measure this\ndiversity have been proposed.\"\n\n-Please include references to support: \"The negative log marginal likelihood is a metric that measures the model\u2019s \ufb01t to the training data and has a theoretical foundation that it matches, on average, the KL divergence between the true distribution and the model\u2019s distribution.\"\n\n-Where it reads: \"Within this category, although\nAuto Data Augmentation is efficient, The knowledge transferred\", lower case \"..., The knowledge...\" to \"..., the knowledge...\"\n\n-Introduce the acronyms KL, BIC, GPs, NLL and NML!\n\nIn section 2.1: \n-There seems to be inconsistency in the notation. I do not see the benefit of referring to $\\mathbf{X}$ as a random variable. There is no information or specification of the distribution that $\\mathbf{X}$ follows. I would suggest to refer as an input variable $\\mathbf{x} \\in \\mathbb{R}^d$ instead of $\\mathbf{X} \\in \\mathbb{R}^d$. Also $y \\in \\mathbb{R}$ instead of $\\mathbf{y} \\in \\mathbb{R}^1$, these to be congruent with Eq. (1).\n\n-Also, I suggest to use $\\mathbf{y}^N=(y_1,y_2,...,y_N)^\\top$ and $\\mathbf{X}^N=(\\mathbf{x}_1,\\mathbf{x}_2,...,\\mathbf{x}_N)^\\top$ to be more consistent instead of the current notation in the paper.\n\nIn Eq. (1), the Covariance matrices $\\mathbf{K}_{N,m^*}$ \n\nand $\\mathbf{K}^{\\top}_{N,m^*}$ \n\nmight be swapped of quadrant. \n\nIt is more intuitive to think that the pair $N,m^*$ refers to rows,columns respectively. \n\nAdd period \".\" at the end of the equation. \n\nPutting the $\\mathbf{x}_1...\\mathbf{x}_N$ and \n\n$\\mathbf{x}_{1^*}$ ...  \n\n$\\mathbf{x}_{m^*}$ \n\ninside the equation looks strange as if a vector were multiplying the covariance matrix. Maybe a footnote should be added to avoid confusion.\n\n-If $\\mathbf{K}_{N,m^*}$ \n\nis swapped by $\\mathbf{K}^{\\top}_{N,m^*}$ then the equations that use these matrices should be corrected.\n\n-Similar comment to the one before applies to Eq. (2).\n\n-After Eq. (2) in $F_{m+1^*}$ the $y^{m+1}$ is missing \"*\".\n\n-In Eq. (2) and (3) the identity matrices $\\mathbf{I}$ should be different at each quadrant since they do not have the same dimensions.\n\nIn Eq (3) the negative sign is not applied, previously it was introduced $F_{m+1^*}=-\\log \\mathcal{N}...$. Also, as per Eq. (4) the operation in Eq. (3) should be \n\n$(\\mathbf{y}^{m+1}-\\boldsymbol{\\mu}_{m+1})$\n\ninstead of \n\n$(\\mathbf{y}^N-\\boldsymbol{\\mu}_{m+1})$\n\n-Add a comma \",\" after Eq. (3) and (4), then period \".\" after Eq. (5).\n\n-In section 3: write $(m+1)\\times(m+1)$ instead of $m+1 \\times m+1$. Indeed, in the equations should be better to write, say, \n\n$\\mathbf{y}_{(m+1)^*}$ or \n\n$\\mathbf{K}_{(m+1)^*}$.\n\n-In section 3: it reads: \"with a total cost of \n\n$\\mathcal{O}(M^2N + MN^2)$, \n\nkeeping it within the cubic order\", shouldn't it be within the quadratic order?\n\n-Before Eq. (6): what is $\\mathbf{K}_{+m}$? typo?\n\n-Before section 3.2: \n\n$(\\mathbf{L}_{m+1}$ \n\n$\\mathbf{L}^{\\top}_{m+1})^{-1}\\mathbf{y}^{(m+1)^*}$ \n\ninstead of \n\n$(\\mathbf{L}_{m+1}$\n\n$\\mathbf{L}^{\\top}_{m+1})^{-1}\\mathbf{y}^{m+1}$\n\n-Where it reads: \"Lalchand \\& Faul\n(2018) described in Section 1, promote diversity of training data.\" should be \"promotes\" since you are referring to the method or work.\n\n-Typo where it reads: \"then using the likelihood of the all output data y\", should be \"...of all the output data...\"\n\n-In section 4.2: \"the number of training data candidates generated from the simulator was 1,000,\", you mean \"1000\" or 1?\n\n-In the figure 3: it is not possible to visualise the Training data (brown-ish colour) for SoD. \n\n-In the conclusion: \"the algorithm we proposed is specialized for regression models\", not regression models in general, but a regression model particularly with a Gaussian likelihood.\n\n-Generally, there is either a comma or period missing after the equations.\n\n-Initial capital letter in the bibliography, words like: Gaussian and Cholesky. \n\n-Why is there a distribution $q(\\mathbf{X}^N)$ in appendix H for Eq. (21)? Aren't we saying in $KL(q(.|\\mathbf{X}^N)||p(.|\\mathbf{X}^N))$ that $\\mathbf{X}^N$ is given? I do not think the Eq. (21) is correct.\n\n---Other Questions---\n\nIs this method feasible to different statistical data types for the outs $y$ or we should assume that $y$ is always in the real values?\n\nWe fit the GP hyperparameters with the training data, but are those hyperparameters tuned again when adding simulator data?\n\n-The experiments shown seem to have an appropriate number of N data observation so that the GP model fits quite well for the range of input data $\\mathbf{x}$, so due to the conditioning properties of a Normal distribution it is expected to only accept data that could improve the conditional distribution $p(\\mathbf{y}^N|\\mathbf{X}^N,\\mathbf{y}^{m^*},\\mathbf{X}^{m^*})$. What would it happen if the GP has a smaller number of data observation, or lack of data in regions such that the predictive distribution was less uncertain? How would the acceptance and rejection would behave in such a region?\n\n-It seems that the Log marginal likelihood metric gives priority to the model fitting, so when do we trust the simulator?\n\n-What if the simulator is actually quite close to the true distribution, but we have a small number of data observations for which we fit a GP with the hyper-parameters tuning a distribution not that close to the true distribution?\n\n\nWhat ways to measure a trade-off, as mentioned in the introduction, to achieve an appropriate bias-variance in our last model that contains training and simulator data? \n\n-If I fit the GP and generate data from such a GP and use it as simulator data, wouldn't I expect to achieve improvements in the Log marginal likelihood? Wouldn't the fitted GP be simply the best data simulator?\n\n-The work is missing to show a real world application to additionally assess the performance of the approach, for instance an example as claimed in appendix C.\n\n-What would be the effect of using different data simulators? For instance, a simulator less similar to the real distribution. \n\n-For the practitioner, How is a data simulator generally built or where does it come from?\n\n-What if the dataset we are fitting presents a heteroscedastic noise, how could this affect the method approach for accepting training data candidates?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8700/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8700/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8700/Reviewer_1Da7"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8700/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698789323833,
            "cdate": 1698789323833,
            "tmdate": 1699637090435,
            "mdate": 1699637090435,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "erhicreuDu",
                "forum": "dexKVPmPOg",
                "replyto": "3hmRcca4nF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to AnonReviewer 1Da7 (1)"
                    },
                    "comment": {
                        "value": "We appreciate the detailed feedback you provided. Your expertise has played a key role in making our paper clearer and better. \n\nFirstly, we would like to address the concerns raised by all reviewers regarding the lack of experiments with real data. We agree that conducting experiments with real data is crucial for enhancing the reliability of our method. Therefore, we have conducted these experiments and included the results in Figure 1 (c). Please review the updated figure for your reference.\n\nWeaknesses:\n> The idea of accepting data to be added as part of the training set by improving the marginal likelihood was previously explored by Titsias M. in \"Variational Learning of Inducing Variables in Sparse Gaussian Processes\" section 3.1. In the context of Titsias' work was used to generated pseudo-inputs (or inducing points).\n\nI had not noticed that in the paper. Thank you for pointing it out.\nWhile it is true that (Titsias2009a) utilizes the lower bound of the marginal likelihood as a metric, our method differs in that it directly employs the marginal likelihood itself. (Titsias2009a) aimed to develop sparse GPs for reducing training data by replacing the dependence of function values $\\mathbf{f}$ on the training data $\\mathbf{X}$ with $p(\\mathbf{f}|\\mathbf{f}^m)$, thus altering the model's marginal likelihood from Equation 4 in (Titsias2009b) to Equation 10 in the same work. Consequently, the marginal likelihood could not be quickly computed, leading to the use of its lower bound as a metric (as shown in Equation 8 in (Titsias2009a) or Equation 13 in (Titsias2009b)). In contrast, our proposed application allows for the use of all training data, thereby eliminating the need to modify the marginal likelihood. Our acceleration method enables the use of the log likelihood itself as the metric. We have added (Titsias2009a) and other papers employing log marginal likelihood to the related works in Appendix A.2 and clarified these differences as described above.\n\n> The experiments provided are limited to just presenting synthetic scenarios.\n\nIn response to the concern regarding the use of real datasets, we have conducted additional experiments with actual data. The methodology and the description of these experiments are detailed in the third paragraph of Section 4.1, and the results are presented in Figure 1(c). Although the differences are not as pronounced as with synthetic data, the results show an improvement in MSE over the standard Gaussian Process. Furthermore, they demonstrate that our approach is not influenced by deviations from the true distribution, which can affect methods like SoD when using simulator data.\n\n> The introduction does not properly motives the research problem to engage the reader with the work. Also, the introduction lacks of references to better support different phrases or claims. The methodology sections are generally well written and not difficult to follow, though they present some inconsistencies in the mathematical notation.\n\nThank you for your detailed feedback regarding the Abstract, Introduction, and Methodology sections as outlined in the Questions section. We have taken your comments into careful consideration and made appropriate revisions to address these concerns. \n\n> The work has its strength in the efficient computation of the marginal likelihood, but the main aim of the work was not to compare such an algorithm with other approaches that improve such computation, but to introduce a direct method of selectively adding simulator-generated data to training data when using Gaussian processes.\n\nOur study represents the first instance of employing log marginal likelihood for data selection in Gaussian Processes, distinguishing it from (Titsias2009a) which uses the lower bound of log marginal likelihood. This novelty means that there have been no previous algorithms developed for efficiently computing this specific application. Given the unique nature of our approach, creating alternative algorithms that similarly reduce computational complexity is a non-trivial task. Hence, the main contribution of our work is not just in the efficient computation of marginal likelihood, but also in its innovative use for incorporating simulator-generated data into training sets in Gaussian Processes.\n\n(Titsias2009a) Titsias, Michalis. \"Variational learning of inducing variables in sparse Gaussian processes.\" Artificial intelligence and statistics. PMLR, (2009).\n\n(Titsias2009b) Titsias, Michalis K. \"Variational model selection for sparse Gaussian process regression.\" Report, University of Manchester, UK (2009)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700595975110,
                "cdate": 1700595975110,
                "tmdate": 1700595975110,
                "mdate": 1700595975110,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "txQ524Du0m",
                "forum": "dexKVPmPOg",
                "replyto": "3hmRcca4nF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to AnonReviewer 1Da7 (2)"
                    },
                    "comment": {
                        "value": "Questions:\n\nThank you for the detailed review of the equations and for pointing out typos. We have essentially corrected all the equations and typos. Specifically, the corrections that were highlighted in your comments are presented below.\n\n> In Abstract, it sounds contradictory to say that we rely on knowledge that is unreliable: \"construct models based on their knowledge of the modeling target and, as training data increases, choose more flexible models with reduced dependence on that knowledge if that knowledge is unreliable.\" Maybe the last sentence would be better understood if read as:\"...if that knowledge becomes unreliable\" or simply get rid of last part and leave: \"construct models based on their knowledge of the modeling target and, as training data increases, choose more flexible models with reduced dependence on that knowledge.\"\n\nThank you for your insightful feedback and specific suggestions regarding the phrasing in the Abstract. You are correct in pointing out that the term \"unreliable\" may not be the most appropriate, as the context is not limited to situations where the knowledge is incorrect. We have taken your advice and revised the sentence to the second option you proposed: \"construct models based on their knowledge of the modeling target and, as training data increases, choose more flexible models with reduced dependence on that knowledge.\n\n> In Abstract, it is not clear what it is the intention of \"We propose a faster method considering the Cholesky factor and matrix element dependencies.\" \n\nWe appreciate the feedback on the clarity of our abstract. To clarify the motivation for developing a faster method, we have revised the text as follows: \"On the other hand, the log marginal likelihood is a theoretically grounded metric when viewed as a model selection criterion for incorporating data generated from a simulator into the training data. Calculating this metric for GPs is computationally expensive due to the necessity of inverting large covariance matrices. To address this challenge, our proposed method accelerates the process by efficiently updating the Cholesky decomposition and considering the dependencies between matrix elements. This improvement not only expedites computations but also maintains the theoretical robustness of the model selection process.\"\n\n> In the Introduction, there is probably a sentence missing at the very beginning regarding modelling issues or modelling challenges than allows the reader understand where the idea or problem of bias-variance trade-off comes from. Also, it is necessary to include a strong reference regarding \"bias-variance trade-off\" to support the text.\n\nThank you for the constructive feedback. Indeed, the initial motivation for considering the bias-variance trade-off was not clearly stated. To rectify this, we have added an introductory sentence to the Introduction that outlines the general aim of regression models, smoothly transitioning to the discussion of the bias-variance trade-off. The revised text is as follows:\n\n\"One of the ultimate objectives of machine learning models is to reduce generalization loss. According to the bias-variance trade-off, the generalization loss, when employing Mean Squared Error (MSE) as the loss function, can be decomposed into terms of bias and variance.\"\n\t\t\nIn addition, we have simplified the explanation of the bias-variance trade-off and have incorporated a strong reference to support the concept by adding PRML (Bishop2006), which discusses the same in the context of Equation 3.44.\n\t\t\n(Bishop2006) Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning. Springer, 2006.\n\n> In the introduction, the phrase that reads: \"On the other hand, the method of selectively adding generated simulator data to the training data only requires that data can be generated from the simulator\" seems ambiguous or needs rewording.\n\nIndeed, the sentence in question could have been misinterpreted due to its redundant structure. We have revised it for clarity and conciseness as follows:\n\"On the other hand, the method of selectively adding generated data requires only the ability to produce data from the simulator.\"\n\n> Please include references to support: \"The criterion for selecting important data is the diversity of the training data. Various methods to measure this diversity have been proposed.\"\n\nWe have included relevant references of \"the various methods\".\n\n> Please include references to support: \"The negative log marginal likelihood is a metric that measures the model\u2019s \ufb01t to the training data and has a theoretical foundation that it matches, on average, the KL divergence between the true distribution and the model\u2019s distribution.\"\n\nWe have included references that detail the relationship between the negative log marginal likelihood and the KL divergence. Additionally, we offer a thorough explanation in Appendix G, H."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598721514,
                "cdate": 1700598721514,
                "tmdate": 1700598721514,
                "mdate": 1700598721514,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9AIhPRgw2n",
                "forum": "dexKVPmPOg",
                "replyto": "3hmRcca4nF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to AnonReviewer 1Da7 (3)"
                    },
                    "comment": {
                        "value": "> looks strange as if a vector were multiplying the covariance matrix. Maybe a footnote should be added to avoid confusion.\n\nThe following content has been added to Footnote 3 as indicated. Thank you for bringing this to our attention. $\\mathbf{x}\\_{1^*}\\dots\\mathbf{x}\\_{m^*}, \\mathbf{x}\\_{1}\\dots\\mathbf{x}\\_{N}$ represent the input variables for the kernel function that constructs the covariance matrix.\n\n> In Eq. (2) and (3) the identity matrices should be different at each quadrant since they do not have the same dimensions.\n\nThe content has been added to Footnote 4 as indicated. Thank you for bringing this to our attention.\n\"Different-sized identity matrices appear in the paper, but the size is easily inferred from the context, so they are all uniformly denoted as $\\mathbf{I}$.\"\n\n> Also, as per Eq. (4) the operation in Eq. (3) should be $(\\mathbf{y}^{m+1}-\\mathbf{\\mu}\\_{m+1})$ instead of $(\\mathbf{y}^{N}-\\mathbf{\\mu}\\_{m+1})$.\n\nIndeed, the notation $\\mathbf{y}^N$ as presented is accurate. To clarify the distribution aspect of $F\\_{m+1^*}$ with respect to $\\mathbf{y}^N$, we have now explicitly stated in the preceding sentence that $F_{m+1^*} = -\\log p(\\mathbf{y}^N|\\ldots)$. This amendment should eliminate any confusion regarding the distribution of $\\mathbf{y}^N$ in relation to $F_{m+1^*}$.\n\n> Indeed, in the equations should be better to write, say $\\mathbf{K}\\_{(m+1)^*}$.\n\nAcknowledging your point, we have decided not to add parentheses around $\\mathbf{K}_{N, (m+1)^*}$ to avoid cluttering the notation. The current format should be clear enough to avoid any misunderstanding.\n\n> In the figure 3: it is not possible to visualise the Training data (brown-ish colour) for SoD.\n\nIndeed, due to the order in which the data points were plotted, the Training data (in a brown-ish color) for SoD was obscured in Figure 3. We have corrected this issue and adjusted the plotting order to ensure that all points are now clearly visible in the figure. Thank you for pointing out this oversight.\n\n> In the conclusion: \"the algorithm we proposed is specialized for regression models\", not regression models in general, but a regression model particularly with a Gaussian likelihood.\n\nIndeed, our algorithm is tailored for regression models where the observation noise is Gaussian. To make this clear, we have explicitly stated this limitation in the conclusion as follows:\t\t\n\"As a limitation, the algorithm we proposed is specialized for regression models with Gaussian likelihood, and its extension to classification models and other likelihood models is not straightforward.\"\n\n> Why is there a distribution $q(\\mathbf{X}^N)$ in appendix H for Eq. (21)? Aren't we saying in $KL(q(\\cdot| \\mathbf{X}^N || p(\\cdot | \\mathbf{X}^N)$ that $\\mathbf{X}^N$ is given? I do not think the Eq. (21) is correct. \n\nWe require $q(\\mathbf{X}^N)$ to ensure that the distance between our model $p(\\mathbf{y}^N|\\mathbf{X}^N, \\mathbf{X}^{m*}, \\mathbf{y}^{m*})$ and the true distribution $q(\\mathbf{y}^N|\\mathbf{X}^N)$ is minimized on average over the true distribution $q(\\mathbf{X}^N)$, rather than for a specific training dataset $\\mathbf{X}^N$. This definition aligns with the conditional KL divergence as defined in (Poczos2012) Definition 5, which includes $q(\\mathbf{X}^N)$. To avoid confusion, we have made the following modifications:\n\n- Cited (Poczos2012) right after mentioning \"Conditional KL divergence\".\n- Revised the description before Equation 20 from $q(\\mathbf{y}^N|\\mathbf{X}^N)$ to $q(\\mathbf{y}^N|\\mathbf{X}^N)q(\\mathbf{X}^N)$ to reflect the true distribution of the dataset.\n- Adjusted Equations 20 and 21 to align with (Poczos2012)\u2019s definition by bringing the integral over $\\mathbf{X}^N$ to the outermost layer.\n\n(Poczos2012) Barnabas Poczos and Jeff Schneider. Nonparametric estimation of conditional information and divergences. In Artificial Intelligence and Statistics, 2012.\n\n> Is this method feasible to different statistical data types for the outs or we should assume that is always in the real values?\n\nThe specific computational techniques we propose are tailored for scenarios where the outputs are in real values. In cases like classification problems, where the outputs take a different form, the formula for marginal log likelihood (as in Equation 3) changes, making our proposed computational techniques inapplicable."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700601100966,
                "cdate": 1700601100966,
                "tmdate": 1700602187779,
                "mdate": 1700602187779,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SXippSgEvj",
                "forum": "dexKVPmPOg",
                "replyto": "3hmRcca4nF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to AnonReviewer 1Da7 (4)"
                    },
                    "comment": {
                        "value": "> We fit the GP hyperparameters with the training data, but are those hyperparameters tuned again when adding simulator data?\n\nThe hyperparameters of the Gaussian Process are determined from the initial training data and are not modified post-learning.\n\"The hyperparameters of the input kernel function are pre-optimized using the initial training data $(\\mathbf{X}^N, \\mathbf{y}^N)$ and remain fixed throughout the execution of Algorithm 1. While re-optimization of the kernel's hyperparameters using the selected generated data $(\\mathbf{X}^{M^*}, \\mathbf{y}^{M^*})$ in conjunction with the original training data $(\\mathbf{X}^N, \\mathbf{y}^N)$ could be considered after the selection process, this was not performed in the current study.\"\nFurther, while an iterative approach to hyperparameter optimization in conjunction with data selection, as suggested by (titsias2009), could be contemplated, such an exploration is reserved for future work.\n\n> The experiments shown seem to have an appropriate number of N data observation so that the GP model fits quite well for the range of input data , so due to the conditioning properties of a Normal distribution it is expected to only accept data that could improve the conditional distribution. What would it happen if the GP has a smaller number of data observation, or lack of data in regions such that the predictive distribution was less uncertain? How would the acceptance and rejection would behave in such a region?\n\nIn regions where the true training data is sparse, adding generated data to the training set is likely to have a minimal impact on the predictions for true training data points that are distant from the added data, due to the properties of kernel methods. Consequently, the value of $F_{m+1}$is expected to change very little, whether it increases or decreases, compared to $F_m$. Therefore, the inclusion of such generated data in these sparse areas would likely be random. We have not conducted experiments specifically to support this hypothesis.\n\n> It seems that the Log marginal likelihood metric gives priority to the model fitting, so when do we trust the simulator?\n\nWhen it comes to prioritizing data over domain knowledge, our method indeed favors the log marginal likelihood, or the data. As mentioned in the Introduction, model assumptions can be adjusted automatically from data, which inherently places priority on the data. Trust in the simulator would require manual intervention to incorporate domain knowledge into the model assumptions. For instance, one might manually add all data from a trusted simulator region to the training set.\n\n> What if the simulator is actually quite close to the true distribution, but we have a small number of data observations for which we fit a GP with the hyper-parameters tuning a distribution not that close to the true distribution?\n\nThis is indeed a fundamental question. Our approach could be seen as expanding the hyperparameter space of GPs. The selection of simulator-generated data to include in training acts as a hyperparameter, which introduces the risk of overfitting. If the simulator closely approximates the true distribution, this could be considered as constraining the hyperparameter space to a range closer to the correct values. For instance, the region represented by the gray and pink plots in Figure 3 could be seen as this hyperparameter space. Fitting hyperparameters always carries the risk of overfitting, particularly with a small number of true training data points. However, if the simulator matches the true distribution accurately, any selected generated data is likely to improve predictive performance.\n\n> What ways to measure a trade-off, as mentioned in the introduction, to achieve an appropriate bias-variance in our last model that contains training and simulator data?\n\nBias-variance trade-off cannot be directly measured because we do not have knowledge of the true underlying distribution. Instead, we rely on indirect metrics. One such metric is the log marginal likelihood, which assesses the model's fit to the data and the balance of complexity (as discussed in Bishop, 2006, Section 3.4). Optimizing the log marginal likelihood indirectly contributes to achieving a favorable balance between bias and variance. We have added the motivation for using log marginal likelihood to the 6th paragraph of the Introduction to provide a clearer explanation."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700601849191,
                "cdate": 1700601849191,
                "tmdate": 1700601849191,
                "mdate": 1700601849191,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Z5jZU6ZRBQ",
                "forum": "dexKVPmPOg",
                "replyto": "3hmRcca4nF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to AnonReviewer 1Da7 (5)"
                    },
                    "comment": {
                        "value": "> If I fit the GP and generate data from such a GP and use it as simulator data, wouldn't I expect to achieve improvements in the Log marginal likelihood? Wouldn't the fitted GP be simply the best data simulator?\n\nThis is an intriguing consideration. The improvement of log marginal likelihood using data generated from a GP fitted to a limited dataset is not a given. For outlier values of $\\mathbf{x}$ that are less likely to be sampled from the true distribution $q(y\u2223\\mathbf{x})q(\\mathbf{x})$, whether the generated data pairs $(\\mathbf{x},y)$ from the GP's predictive distribution will enhance the log marginal likelihood is uncertain.\n\n> The work is missing to show a real world application to additionally assess the performance of the approach, for instance an example as claimed in appendix C.\n\nIn response to the concern regarding the use of real datasets, we have conducted additional experiments with actual data. The methodology and the description of these experiments are detailed in the third paragraph of Section 4.1, and the results are presented in Figure 1(c). Although the differences are not as pronounced as with synthetic data, the results show an improvement in MSE over the standard Gaussian Process. Furthermore, they demonstrate that our approach is not influenced by deviations from the true distribution, which can affect methods like SoD when using simulator data.\n\n> What would be the effect of using different data simulators? For instance, a simulator less similar to the real distribution.\n\nWe have investigated the effect of using simulators that diverge from the true distribution in Section 4.2, as depicted in Figure 2. The parameter $a$ increases the dissimilarity between the simulator's distribution and the true distribution. Our findings indicate that even as the simulator becomes less similar to the real distribution, the MSE of our proposed method remains relatively stable.\n\n> For the practitioner, How is a data simulator generally built or where does it come from?\n\nPractitioners generally build data simulators by translating the knowledge they currently possess about the relationship between y and x into a model. Our method is applicable as long as the simulator can generate pairs of $(y,x)$, regardless of whether the simulator describes the $(y,x)$ relationship analytically or generates $(y,x)$ hrough numerical computation.\n\n> What if the dataset we are fitting presents a heteroscedastic noise, how could this affect the method approach for accepting training data candidates?\n\nProcess model assumes homoscedastic noise, so employing it on data with heteroscedastic noise implies using an incorrect model. In areas where the heteroscedastic noise variance is less than that assumed by our GP model, simulator data with variability within this range may not be sufficiently penalized in terms of the negative log marginal likelihood, potentially leading to incorrect acceptance. Conversely, in areas where the heteroscedastic noise variance is greater, our method might overly penalize simulator-generated data, resulting in excessive rejection."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700602082008,
                "cdate": 1700602082008,
                "tmdate": 1700602082008,
                "mdate": 1700602082008,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vx6hZUznny",
                "forum": "dexKVPmPOg",
                "replyto": "Z5jZU6ZRBQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Reviewer_1Da7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Reviewer_1Da7"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for the constructive discussion and for the different responses to my questions."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700655072137,
                "cdate": 1700655072137,
                "tmdate": 1700655072137,
                "mdate": 1700655072137,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BPqy54UZhC",
            "forum": "dexKVPmPOg",
            "replyto": "dexKVPmPOg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8700/Reviewer_q1Av"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8700/Reviewer_q1Av"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on selectively adding data for training a low-variance model, which is an important topic. The authors propose to deploy GP along with marginal likelihood as the metric to evaluate the quality of simulated data samples. The paper first talks about the method to selectively add more training data using GP. Then, it introduces the algorithm for faster implementation.  The experiments show the improvement."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The GP for adding simulated data seems to better perform than other baseline methods. \n- The algorithm is faster. \n- The discussion is well-rounded."
                },
                "weaknesses": {
                    "value": "- The novelty of GP on this topic is a bit limited. GP is not a new method at all. The algorithm that makes it faster is more interesting but no major breakthrough. \n- It seems no real data set is experimented."
                },
                "questions": {
                    "value": "1. Why gray points are not adopted in Figure 3?\n2. It is said that the hyperparameters of GP are learned from initial training data. Do those hyperparameters change after it is learned? If it is not, does the initial training data affect the selection process? If it is not, how does it change?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8700/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699495414473,
            "cdate": 1699495414473,
            "tmdate": 1699637090235,
            "mdate": 1699637090235,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "giSjK5eVdP",
                "forum": "dexKVPmPOg",
                "replyto": "BPqy54UZhC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8700/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to AnonReviewer q1Av"
                    },
                    "comment": {
                        "value": "We want to thank the reviewer for the insightful comments and suggestions. Your advice has been a great help in improving our manuscript.\n\nFirstly, we would like to address the concerns raised by all reviewers regarding the lack of experiments with real data. We agree that conducting experiments with real data is crucial for enhancing the reliability of our method. Therefore, we have conducted these experiments and included the results in Figure 1 (c). Please review the updated figure for your reference.\n\nWeaknesses:\n> The novelty of GP on this topic is a bit limited. GP is not a new method at all. The algorithm that makes it faster is more interesting but no major breakthrough.\n\nAs discussed in the third paragraph of the Introduction, Gaussian Processes (GPs) offer a unique advantage in incorporating the evolution of deep learning by allowing the kernel function to be represented as a neural network architecture. This adaptability ensures that GPs remains a relevant and powerful tool in the field. Moreover, the ability of GP to quantify predictive uncertainty is a significant contribution that enhances the capabilities of deep learning models. Hence, we contend that GP continues to be of substantial importance and relevance in our domain.\n\n> It seems no real data set is experimented.\n\nIn response to the concern regarding the use of real datasets, we have conducted additional experiments with actual data. The methodology and the description of these experiments are detailed in the third paragraph of Section 4.1, and the results are presented in Figure 1(c). Although the differences are not as pronounced as with synthetic data, the results show an improvement in MSE over the standard Gaussian Process. Furthermore, they demonstrate that our approach is not influenced by deviations from the true distribution, which can affect methods like SoD when using simulator data.\n\n\nQuestions:\n> Why gray points are not adopted in Figure 3?\n\nThank you for bringing this to our attention. The omission of the gray points from the legend in Figure 3 was an oversight. We have now updated the figure to include these points in the legend.\n\n> It is said that the hyperparameters of GP are learned from initial training data. Do those hyperparameters change after it is learned? If it is not, does the initial training data affect the selection process? If it is not, how does it change?\n\nThe hyperparameters of the Gaussian Process are determined from the initial training data and are not modified post-learning. These pre-learned hyperparameters, along with the free energy, influence the selection process through their interaction with the initial training data. Specifically, the computation of free energy is dependent on the initial training data's outputs, $\\mathbf{y}^N$ (as defined in equation 2), and inputs, $\\mathbf{x}_N$ (through $\\mathbf{K}_N$ and $\\mathbf{K}\\_{N,m+1^*}$ as in equation 5). We have included additional clarification in Appendix B as follows:\n\t\t\n\"The hyperparameters of the input kernel function are pre-optimized using the initial training data $(\\mathbf{X}^N, \\mathbf{y}^N)$ and remain fixed throughout the execution of Algorithm 1. While re-optimization of the kernel's hyperparameters using the selected generated data $(\\mathbf{X}^{M^*}, \\mathbf{y}^{M^*})$ in conjunction with the original training data $(\\mathbf{X}^N, \\mathbf{y}^N)$ could be considered after the selection process, this was not performed in the current study.\"\n\t\t\nFurther, while an iterative approach to hyperparameter optimization in conjunction with data selection, as suggested by (Titsias2009), could be contemplated, such an exploration is reserved for future work.\n\n(Titsias2009) Titsias, Michalis. \"Variational learning of inducing variables in sparse Gaussian processes.\" Artificial intelligence and statistics. PMLR, 2009."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8700/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700591671354,
                "cdate": 1700591671354,
                "tmdate": 1700594841450,
                "mdate": 1700594841450,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]