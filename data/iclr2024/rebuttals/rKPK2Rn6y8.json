[
    {
        "title": "Autonomous Tree-search Ability of Large Language Models"
    },
    {
        "review": {
            "id": "PwPDDogQxi",
            "forum": "rKPK2Rn6y8",
            "replyto": "rKPK2Rn6y8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7438/Reviewer_51yR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7438/Reviewer_51yR"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes developing \"autonomous tree-search (ATS) ability\" for large language models (LLMs) to allow them to solve reasoning tasks requiring exploration and search. ATS allows LLMs to generate responses demonstrating tree-structured search trajectories in either breadth-first search (BFS) or depth-first search (DFS) format. For large models like GPT-4, ATS ability can be activated through prompting the model to \"role play\" an assistant to generate the \"tree\" of the reasoning steps. Experiments on 4 puzzle tasks show GPT-4 with ATS prompts outperforms chain-of-thought. For smaller models like 7B/13B LLaMA, ATS ability can be acquired through supervised fine-tuning on GPT-4 generated ATS data. Experiments show ATS-tuned LLaMAs outperform both chain-of-thought tuned LLaMAs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper proposes an approach to impart autonomous search ability to LLMs without specialized external programs. Could make LLMs more flexible and capable at complex reasoning. The ATS prompt approach seems quite generalizable to new tasks, requiring only fixed prompt. More flexible than task-specific passive search programs.\n2. The empirical investigation covers both large and small LLMs. Demonstrates effectiveness over strong baselines like Tree of Thoughts on the puzzle solving tasks."
                },
                "weaknesses": {
                    "value": "1. While the proposed idea presents a certain degree of improvement, its contribution appears incremental when compared to both CoT and ToT.\n2. The scope of the literature survey is somewhat narrow. Notably absent are related works such as \"PAL: Program-aided Language Models\" and two concurrent studies that utilize pseudo-code-style prompts. These methodologies, too, emphasize simplicity and flexibility in generating reasoning steps.\n3. Although the \"Graph-of-thoughts\" work is referenced, there is a lack of empirical comparison with it.\n4. The empirical tasks primarily focus on simple games, which presents a limitation. It would be beneficial to incorporate more complex reasoning tasks. For instance, the ToT paper show the effectiveness of their methods through \"Creative Writing.\"\n5. LLM is known for its challenges in producing lengthy contextual answers, often leading to hallucinations. In contrast, ToT methods excel at breaking down complex tasks into more manageable steps, thereby enhancing the reliability of the output. The one-round prompting strategy, however, may encounter difficulties in handling intricate tasks, especially when they have significant breadth and depth."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7438/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698526894855,
            "cdate": 1698526894855,
            "tmdate": 1699636893226,
            "mdate": 1699636893226,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1cyX5KEtJC",
                "forum": "rKPK2Rn6y8",
                "replyto": "PwPDDogQxi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7438/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7438/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer 51yR,\n\nThank you for your constructive comments. We have appropriately cited the works you mentioned and plan to running GoT as a baseline.\n\nAccording to your initial review, we have made the following efforts.\n\n- In **Additional Experiment 2**, a global response, we tested our methods on a real, complex reasoning task. Additionally, in conjunction with **Additional Experiment 1**, we demonstrated that ATS and ToT are not in conflict.\n\nRegarding hallucination, longer context typically suffers more severely. However, this also depends on whether the expected next generated token is within the LLM's capability.\n\nWe claim that CoT is a method that can reduce hallucination through longer responses. Conversely, if we use prompt to turn off the CoT ability, the expected next generated token falls outside the LLM's capability, leading to hallucination even though GPT will have shorter response.\n\nThe experimental accuracy show that ATS will not be seriously affected by hallucination in these tasks.\n\nMoreover, when it comes to significant depth and breath, we emphasize ATS and ToT are not in conflict as shown in **Additional Experiment 1**.\n\nBest,\n\nAuthors"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7438/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659172278,
                "cdate": 1700659172278,
                "tmdate": 1700659518992,
                "mdate": 1700659518992,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ryET4sqnRO",
            "forum": "rKPK2Rn6y8",
            "replyto": "rKPK2Rn6y8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7438/Reviewer_Tc6e"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7438/Reviewer_Tc6e"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies using language models in tasks that benefit from systematic search. The paper proposes \"Autonomous Tree Search\", a prompting method that instructs the language model itself to perform tree search in-context, requiring a single call to the LLM. This contrasts to Tree of Thoughts, which uses an external program to guide search, repeatedly calling the LLM to propose next states and evaluate states. Experiments on 4 puzzles show improvements over CoT and ToT using GPT-4. Moreover, the authors explore distilling ATS from GPT-4 into smaller models (LLaMA 2 7B and 13B), showing that fine-tuning with ATS yields the best performance (e.g. compared to fine-tuning on GPT-4-generated ToT)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper proposes a simple idea that is very easy to apply in appropriate settings, so it's likely that it will be tried out by some of readers. The paper is well in scope around the current literature, and the idea itself is sound.\n\nThis is also the first work (that I'm aware of) that tried distilling tree-search into smaller models. An ongoing discussion in the area is whether there is a benefit of doing search in-context, since then one branch can be informed by others (in contrast to ToT, where the branches are expanded and evaluated independently). The experiments with LLaMA suggest that there might indeed by a noticeable difference between the two."
                },
                "weaknesses": {
                    "value": "With regards to the method, one disadvantage that should be mentioned explicitly is that ATS is limited to search trees that fit in the context window. While this is not an issue for the simpler puzzles, more complex tasks might require extensive search that might not fit in-context. This limitation does not apply to Tree of Thoughts, so there is a trade-off between the two.\n\nThe main weaknesses of the paper in its current form are in the evaluation and presentation of the results.\n\nFirst, the paper gives little insight into what drives the current results. While the idea of ATS is intuitive, it is not clear to me what factors allow it to have higher accuracy. While the authors show better overall accuracies than ToT, the lack of any qualitative analysis doesn't allow the reader to understand why that is the case. This is especially important when the evaluation is in tasks that themselves don't matter much, like puzzles. The main benefit of these simple, synthetic tasks is to allow us to get insights into the models. If not for that, higher accuracy on these tasks doesn't mean much by itself.\n\nThe \"low-cost setting\" of Tree of Thoughts does not seem to be tree search at all. If the search width is 1, then the model is ultimately only following a single path, even if at each level it will propose multiple next steps. The fact that this performs even worse that CoT (which I can speculate, but don't fully understand from the paper) indicates to me that this comparison is unfair.\n\nThe cost evaluation in cents will get old fast. I'd suggest maybe showing some of them in the paper as with a note that \"at the time of writing\" these are the costs, but these numbers might be meaningless for readers even a few months from now.\n\nFor fine-tuning, it would have been useful to also compare to fine-tuning on CoT generated by the larger model, as done in recent prior work.\n\nThere seems to be quite a bit of redundancy between the figures and tables (e.g., the cost/accuracies in Figures 3 and 4, then in Table 1). A lot of this space could have been used to give insight into some of the numbers.\n\nFinally, and perhaps the main weakness: I found the choice of tasks a bit arbitrary. The authors propose 4 puzzles and only evaluate on those, without reference to prior literature. The paper makes a point about the choice of tasks in the Tree of Thoughts paper (that they don't fully isolate the tree search ability), but I don't think that that justifies discarding them completely."
                },
                "questions": {
                    "value": "- Why would \"low-cost ToT\" perform worse than CoT in some settings (noticeably so in the Drop Water puzzle)?\n- What are the main failure modes you observed for ToT, and why does ATS seem to address them?\n- Are there any viable applications of ATS in existing tasks that are not synthetic puzzles?\n- Why is the output cost for ATS often smaller in the 4-shot setting, compared to 0-shot?\n- Why do figures 2 and 3 not include the low-cost results for other methods other than ToT?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Reviewer_Tc6e"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7438/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698616130389,
            "cdate": 1698616130389,
            "tmdate": 1699636893110,
            "mdate": 1699636893110,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "2BUYDZeiY5",
                "forum": "rKPK2Rn6y8",
                "replyto": "ryET4sqnRO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7438/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7438/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer Tc6e,\n\nThanks again for your detailed, helpful, and constructive comments. We added \"at the time of writing\". We plan to finetune on CoT generated by the larger model and rearrange our figures and tables.\n\nIn response to your initial review, we have made the following efforts:\n\n- We made **Additional Experiment 2** in global response, we tested our methods in a real complex reasoning task **CrossWords**, which is one of the tasks from ToT paper. This task requires strong understanding of rows and columns, making all in-context methods difficult in solve the puzzle.\n- We provided an **Additional Analysis**. The width = 1 setting is mentioned in original ToT paper. We explained the reasons behind ToT's failure on the Drop Water Puzzle.\n\n**Q1.Q2. ToT performance.** We anticipate that low-cost ToT will perform similarly to CoT in most cases. The exception, the Drop Water Puzzle, is discussed in the **Additional Analysis** below.\n\n**Q3. non synthetic puzzles.** **Additional Experiment 2** in global response shows the results and **Additional Experiment 1** shows another applications of ATS to combined with ToT.\n\n**Q4. few-shot response shorter.** Few-shot responses contain task-specific knowledge that helps prune some unnecessary branches. For example, in the Drop Water Puzzle, it is meaningless to fill the second bottle immediately after filling the first bottle.\n\n**Q5. figure.** The high-cost setting for in-context methods is only self-consistency, resulting in marginal improvements. We selected key information from the table and aimed to make the figure more concise.\n\nBest,\n\nAuthors"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7438/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659147795,
                "cdate": 1700659147795,
                "tmdate": 1700659732028,
                "mdate": 1700659732028,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UDWVlX1HaX",
                "forum": "rKPK2Rn6y8",
                "replyto": "cFItK6SX4T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7438/Reviewer_Tc6e"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7438/Reviewer_Tc6e"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for the detailed response. The clarifications mostly make sense to me. The experiment using ATS as an evaluation is an interesting direction as well.\n\nI appreciate the effort to run on Crosswords. Unfortunately, I think the results highlight a limitation of a method that solely relies on the LLM to do everything in context, which is that it doesn't offer a way to circumvent limitations of the underlying LLM. Thus, for example, if the LLM cannot read rows/columns properly, then it won't be able to do that while doing search in context either.\n\nATS does have a clear cost advantage compared to ToT, which gets expensive fast. I strongly suggest the authors find more realistic tasks where that advantage really shines. Those would need to be tasks where the LLM can execute all intermediate operations reliably but perhaps would fail at planning with simple CoT.\n\nThus I'd like to keep my score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7438/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688166564,
                "cdate": 1700688166564,
                "tmdate": 1700688166564,
                "mdate": 1700688166564,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zPJUwZO3R8",
            "forum": "rKPK2Rn6y8",
            "replyto": "rKPK2Rn6y8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7438/Reviewer_Mb1G"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7438/Reviewer_Mb1G"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes developing \"autonomous tree-search ability\" in large language models (LLMs) to enhance their reasoning and problem-solving capabilities. In contrast with previous work like chain-of-thought and tree-of-thought, this paper demonstrates a prompting method to help large language models to automatically conduct planning without external planners (such as tree-search). Experiments with GPT4 over four puzzle games verify the effectiveness of ATS compared with CoT and ToT. By collecting ATS data from GPT4, the authors successfully show a much smaller model (such as LLaMA-7b/13b) can be supervise-finetuned to have the similar ability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper has the following strengths:\n\n1. The paper writing is overall clear and straightforward.\n2. The idea is overall novel.\n3. The author conducts the experiment by prompting GPT4 and training on smaller LLaMA models to validate the general capability of such methods."
                },
                "weaknesses": {
                    "value": "The paper has the following Weaknesses:\n\n1. The experiments are not comprehensive from a few perspectives.\n1.1 The evaluation is limited to just 4 puzzle games. More complex reasoning tasks should be tested to better validate the value of autonomous tree search.\n1.2 The author mainly analyzes the performance and the paper lacks in-depth analysis. For example, there is no analysis of how search spaces, branching factors, solution depth, search algorithms, and different prompt variations can affect performance.\n\n2. The author is supposed to discuss more about the limitations of ATS. For instance, ATS seems to generate more tokens and is more easily constrained by the model context length. Also, It seems hard for ATS to generalize to complex and long-term planning problem.  I recommend the authors include several limitation discussions like this (experiments will be appreciated).\n\n3. Lack of enough related work. A lot of work is discussing how to combine tree search with LLM, for example (Hao et al., 2023) and I am sure there have been more in the past few years. The author should add these literatures as related work.\n\n\nReference\nHao, Shibo, et al. \"Reasoning with language model is planning with world model.\" arXiv preprint arXiv:2305.14992 (2023)."
                },
                "questions": {
                    "value": "1. Will GPT4 generate wrong planning during the ATS process? How do you filter the wrong planning out from the dataset?\n2. You mentioned that DFS exploration was inconsistent without task-specific examples. Did you investigate why DFS was not as robust? Are there ways to improve the generalizability of DFS search?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Reviewer_Mb1G"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7438/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698691451534,
            "cdate": 1698691451534,
            "tmdate": 1699636893004,
            "mdate": 1699636893004,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gsKrlW3eI7",
                "forum": "rKPK2Rn6y8",
                "replyto": "zPJUwZO3R8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7438/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7438/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer Mb1G,\n\nThanks again for your constructive comments. We have cited the work you've mentioned.\n\nFollowing your initial review, we have implemented the following improvement:\n\n- In **Additional Experiment 2** involving a global response, we tested our methods in a real, complex reasoning task. The results highlight ATS's effectiveness among in-context methods.\n- With **Additional Experiment 2**, we discussed our limitations. All in-context methods suffer from the limitations of LLMs, for example the understanding of rows and columns.\n- Additionally, in **Additional Experiment 1**, we demonstrated that ATS and ToT are not in conflict, indicating some limitations would be addressed by combining them.\n\n**Q1. filter the wrong planning.** In the problem definition, we introduced a summary section at the end of the response. For example, the summary might resemble `[0 / 10, 0 / 16] -> [0 / 10, 16 / 16] -> [10 / 10, 6 / 16]`. This summary allows us to confirm the correctness of the solution path, disregarding other paths.\n\n**Q2. DFS not robust.** One reason is that **pruning process** in DFS is usually **not robust**. In the ToT repository, DFS code is provided for crossword tasks. I have tried to reproduce the experiment and found **the pruning process is even sensitivity to version changes of GPT-4**.\n\nSimilar challenges are encountered in our situation. Deciding whether to prune is difficult. There is no common principal of pruning. That's why **task-specific knowledge** from few-shot learning significantly aids in this decision-making process and contributes to stabilize DFS method.\n\nConversely, for the BFS method, LLMs only need to compare states on the same level, which is more stable than deciding a branch to prune or not with only the information of this branch.\n\nBest,\n\nAuthors"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7438/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659087175,
                "cdate": 1700659087175,
                "tmdate": 1700659133696,
                "mdate": 1700659133696,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OXEO8Hkmhj",
            "forum": "rKPK2Rn6y8",
            "replyto": "rKPK2Rn6y8",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7438/Reviewer_Dq3i"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7438/Reviewer_Dq3i"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a prompting method to make LLM automatically perform tree search (such as BFS and DFS) in one text completion. In the 4 synthetic puzzles tested, the method demonstrate gains over Tree of Thought, especially under zero-shot low cost setting. The proposed method can also be used to collect reasoning traces, which is then used to fine-tune smaller LMs to improve its performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper is mostly well-written and easy to follow\n- The proposed method is simple and novel, although can be seen as one type of chain of thought.\n- The experiment results demonstrate substantial gains over CoT and ToT."
                },
                "weaknesses": {
                    "value": "- The experiment settings are very toy/synthetic, making it unclear whether the method is useful for more realistic tasks."
                },
                "questions": {
                    "value": "n/a"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7438/Reviewer_Dq3i"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7438/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698795455133,
            "cdate": 1698795455133,
            "tmdate": 1699636892893,
            "mdate": 1699636892893,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "IDMiNOReHz",
                "forum": "rKPK2Rn6y8",
                "replyto": "OXEO8Hkmhj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7438/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7438/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer Dq3i,\n\nThank you once again for your constructive comments.\n\nWe are greatly encouraged by your positive feedback on the quality of our writing and the novelty of our ideas.\n\nIn response to your initial review, we conducted **Additional Experiment 2** on a real, complex reasoning task with a global scope. The results indicate that ATS is effective among in-context methods. ATS handles real complex reasoning tasks better than CoT.\n\nBest,\n\nAuthors"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7438/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658990254,
                "cdate": 1700658990254,
                "tmdate": 1700659113885,
                "mdate": 1700659113885,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dN6DNvg8Pg",
                "forum": "rKPK2Rn6y8",
                "replyto": "IDMiNOReHz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7438/Reviewer_Dq3i"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7438/Reviewer_Dq3i"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed response. I will maintain the current score."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7438/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700672871256,
                "cdate": 1700672871256,
                "tmdate": 1700672871256,
                "mdate": 1700672871256,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]