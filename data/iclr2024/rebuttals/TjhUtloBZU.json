[
    {
        "title": "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks"
    },
    {
        "review": {
            "id": "hCxBqf15aq",
            "forum": "TjhUtloBZU",
            "replyto": "TjhUtloBZU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6649/Reviewer_JmqY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6649/Reviewer_JmqY"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel topic of studying the effect of pre-training noise on various downstream datasets, termed noisy model learning.\nThe authors conduct the empirical study and analysis of noisy ImageNet and YFCC15M of supervised pre-trained and contrastive pre-trained ResNet50 models and illustrate that slight noise in pre-training improves performance on in-domain downstream tasks but always hurts the performance on out-of-domain tasks. From the singular value analysis of the pre-trained feature space, the authors designed two metrics that in general align with the downstream empirical observations.\nThe authors also propose several regularization terms based on the singular values of features that can mitigate the noise in pre-training in a block-box tuning manner. The authors provide comprehensive experiments to verify the effectiveness of the proposed method and offer interesting analyses and discussions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The paper is generally well-written and organized.\nThe authors provide a first novel and interesting study on the effect of pre-training noise, demonstrating the importance of this research topic, especially in the context of large foundation models. \nThe empirical study for revealing the effect of pre-training noise is extensive and comprehensive, including both in-domain and out-of-domain datasets from various distributions. \nThe proposed method may not be very innovative, but it is simple and verified on both CV and NLP tasks with different large backbones. The method also works in the API case mentioned in the paper.\nThe authors also additionally study the combination of the proposed noisy model learning and traditional noise label learning, demonstrating the effect of noise in pre-training also exists when downstream data has noise. \nThe detailed results, experiments setup, and ablation study are presented in the Appendix."
                },
                "weaknesses": {
                    "value": "How to introduce synthetic noise in ImageNet and YFCC15M needs more explanation.\nThe pattern SVE analysis of the ImageNet model and YFCC15M model are slightly different in Fig.3, and perhaps need more explanation."
                },
                "questions": {
                    "value": "Since ImageNet or YFCC15M itself also originally contains noise, is there any optimal noise ratio that achieves the best ID downstream performance?\nSince NML assumes an inaccessible pre-trained model, how is other black-box tuning methods perform on the noisy model learning setting?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6649/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6649/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6649/Reviewer_JmqY"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6649/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698319488700,
            "cdate": 1698319488700,
            "tmdate": 1699636760176,
            "mdate": 1699636760176,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ObQXKjcKiG",
                "forum": "TjhUtloBZU",
                "replyto": "hCxBqf15aq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6649/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6649/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer JmqY"
                    },
                    "comment": {
                        "value": "> 1. \"How to introduce synthetic noise in ImageNet and YFCC15M needs more explanation. \"\n\n\nWe mentioned some details of introducing synthetic noise in Appendix A.1.\nMore specifically, for ImageNet, we first initialize a noise matrix with the pre-defined noise ratio, where each element denotes the probability of the ground truth label being corrupted to a noisy label. We then use the noise matrix to flip the ground truth labels for each class. \nFor YFCC15M, since it is an image-text pair dataset, we randomly swap the text between two randomly sampled pairs to make the image and text unmatched. \nWe conduct this pair swapping until the ratio unmatched pairs reach the pre-defined noise ratio. \n\n> 2. \"The pattern SVE analysis of the ImageNet model and YFCC15M model are slightly different in Fig.3, and perhaps need more explanation.\"\n\n\nThanks for this good question. The reason why SVE patterns are different for ImageNet trained model and YFCC15M trained model is mainly because of the different pre-training objectives, i.e. supervised cross-entropy and contrastive. \nThis can be observed from the SVD spectrum plot of ImageNet models in Fig.10 and YFCC15M models in Fig. 12. \nThe ImageNet R50 models, in general, have smaller SVD values and faltter SVD spectrums, compared to YFCC15M models on downstream datasets. \nThis why the SVE of ImageNet models in Fig.3 are narrower in x-axis range and wider in y-axis range, compared to YFCC15M models. \nFor better interpretation, we have included a zoom-in version of Fig.3 in Appendix. \n\n\n> 3. \"Since ImageNet or YFCC15M itself also originally contains noise, is there any optimal noise ratio that achieves the best ID downstream performance? \"\n\nWe totally understand your point that there might exist some optimal noise ratio in pre-training data that achieves the best ID downstream performance. However, this is contrary to the goal of our work, we demonstrated that although slight noise can boost the ID performance, it is always detrimental to OOD performance, which inspires us to mitigate the effect of pre-training noise.\nBesides, finding the optimal noise ratio for ID tasks might be infeasible because it would require tuning and validation on different ID tasks, thus presenting different optimal values according to the task. \n\n\n> 4. \"Since NML assumes an inaccessible pre-trained model, how is other black-box tuning methods perform on the noisy model learning setting?\"\n\nWe find most of the parameter-efficient tuning methods are not black-box. There is a recent black-box fine-tuning method termed BlackVIP, which has also been mentioned in our related work, and we provide some of its results here on Laion-2B CLIP pre-trained ViT-L compared to our method:\n\n|          | CIFAR-100 | Flowers-102 |  Food101  |  EuroSAT  |    PCAM   |\n|:--------:|:---------:|:-----------:|:---------:|:---------:|:---------:|\n|   Ours   | **88.96** |  **98.67**  | **92.78** | **98.59** | **79.35** |\n| BlackVIP |   88.51   |    94.23    |   91.54   |   97.28   |   74.31   |\n\n[1] Changdae Oh et al. BlackVIP: Black-Box Visual Prompting for Robust Transfer Learning."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6649/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699888825592,
                "cdate": 1699888825592,
                "tmdate": 1699888825592,
                "mdate": 1699888825592,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DV7p5oUNle",
                "forum": "TjhUtloBZU",
                "replyto": "ObQXKjcKiG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6649/Reviewer_JmqY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6649/Reviewer_JmqY"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "I would like to thank the authors for their response, which solved my concerns. I also carefully read the comments from other reviewers and found no major issues. I think the paper proposes a new interesting and important research direction. Thus, I will keep my rating as a strong support for acceptance."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6649/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700114003750,
                "cdate": 1700114003750,
                "tmdate": 1700114003750,
                "mdate": 1700114003750,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QYk3fqRpkB",
            "forum": "TjhUtloBZU",
            "replyto": "TjhUtloBZU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6649/Reviewer_vftf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6649/Reviewer_vftf"
            ],
            "content": {
                "summary": {
                    "value": "This work aims to study the noise in pertaining data and its impact on downstream tasks. The authors exploit the Singular Value Entropy (SVE) and the Largest Singular Value Ratio (LSVR) to analyze the singular value spectrum of the pre-trained feature space, and discover that proper noise in pre-training data increases both SVE and LSVR, leading to better transferability and worse robustness. Based on the observations, the authors further introduce an MLP together with three regularizations to transform the pre-trained features into a better feature space. Experiments with different model architectures and datasets are conducted to demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The analysis of feature space with the singular value spectrum is interesting and meaningful. Rich experiments and analyses are conducted to show how the noise in pertaining data can impact the learned feature embedding.\n- The proposed regularizations are intuitive and effective. Extensive comparisons are presented to show the improvements."
                },
                "weaknesses": {
                    "value": "- This paper is featured with extensive empirical results. However, the core techniques in methodology (analysis and regularization of singular value spectrum ) have been studied in existing works[e.g. Chen et al., 2019, Bardes et al. 2022], which may undermine the theoretical contribution of this work.\n\n- Some figures are hard to understand by themselves. E.g. different types of marks are cluttered in Fig3."
                },
                "questions": {
                    "value": "- On what scale the SVE and LSVR  is computed? The entire dataset?\n- Do the conclusions (Fig1- 3) always hold for stronger backbone models other than resnet50?\n- In the loss function, are the regularizations computed per batch?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6649/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698570078947,
            "cdate": 1698570078947,
            "tmdate": 1699636760071,
            "mdate": 1699636760071,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aqywKHWCna",
                "forum": "TjhUtloBZU",
                "replyto": "QYk3fqRpkB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6649/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6649/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer vftf"
                    },
                    "comment": {
                        "value": "> 1. \"This paper is featured with extensive empirical results. However, the core techniques in methodology (analysis and regularization of singular value spectrum ) have been studied in existing works[e.g. Chen et al., 2019, Bardes et al. 2022], which may undermine the theoretical contribution of this work.\"\n\n- First of all, as we discussed in the paper, the proposed method is indeed inspired by some related works [e.g. Chen et al., 2019, Bardes et al. 2022]. However, our method are not a direct application of them but designs them as specific regularizations, which are more straightforward and simpler to mitigate the noise in pre-training from our analysis.\n- Second, the noisy model tuning approach is only one aspect of our contributions. Our main contribution lies more in being the first pioneering work to identify and analyze the effect of pre-training noisy datasets on downstream tasks. We think it is more important to bring up the question and analysis to the community, and more future work could be done.\n\n> 2. \"Some figures are hard to understand by themselves. E.g. different types of marks are cluttered in Fig3.\"\n\n\nSorry for the confusion. We provide a zoom-in version of Fig.3 in Fig.10 of Appendix. We hope the zoomed region can have a better visualization there. \nPlease refer to the general response.\n\n> 3. \"On what scale the SVE and LSVR is computed? The entire dataset?\"\n\nThe SVE and LSVR are computed on the entire test set of each downstream task. \n\n> 4. \"Do the conclusions (Fig1- 3) always hold for stronger backbone models other than resnet50?\"\n\nThanks for this good question. \nWe believe the conclusions from Fig 1-3 will scale to larger backbone models because it is related to mainly the noise in pre-training data rather than the model capacity. \nNote that we follow the normal pre-training recipe with heavy regularization techniques such as stochastic depth, mixup, cutmix, label smoothing, etc. \nThis also demonstrates that noisy data is the root of the conclusions, which has little relation to regularization. \nSimilar observations also hold in [1].\n\nHowever, due to the expensive computing resources that will be needed to pre-train larger and stronger backbone models, we won't be able to formally verify all of this during the rebuttal period.\nEspecially for CLIP pre-training of Vision Transformers (ViT), it takes 3-4 days to pre-train on YFCC15M with 8 A100 GPUs and we need to train 5 models with different noise ratios of YFCC15M. \nMoreover, it is found in OpenCLIP that ViT in general, needs much more data to achieve better performance than R50, and training on YFCC15M yields worse performance than R50. \nWe will include as many analysis results as we can for synthetic noisy ImageNet pre-training of ViT here during the rebuttal period, and provide the full results of both ImageNet and YFCC15M in future revision of the paper. \n\n[1] Chiyuan Zhang et al. Understanding deep learning requires rethinking generalization.\n\n> 5. \"In the loss function, are the regularizations computed per batch?\"\n\nYes, we computed the regularization per batch, with a batch size of 32. \nWe found the proposed regularization terms not sensitive to batch size, as long as it is not too small (e.g. 4). \nWe provide a brief ablation of batch size in our method on JFT-300M semi-supervised pre-trained EfficientNet-B3 here:\n\n\n|   Dataset   |   4   |   8   |   16  |   32  |   64  |  128  |\n|:-----------:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|  CIFAR-100  | 95.95 | 96.08 | 96.11 | 96.15 | 96.20 | 96.14 |\n| Flowers-102 | 79.61 | 79.68 | 79.70 | 79.71 | 79.82 | 79.79 |"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6649/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699888751623,
                "cdate": 1699888751623,
                "tmdate": 1699888751623,
                "mdate": 1699888751623,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4ymMfVtI7k",
            "forum": "TjhUtloBZU",
            "replyto": "TjhUtloBZU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6649/Reviewer_5WgV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6649/Reviewer_5WgV"
            ],
            "content": {
                "summary": {
                    "value": "This paper endeavors to comprehend the underlying characteristics of noise within pre-training datasets and seeks to mitigate its influence on downstream tasks. The study reveals that the noise present in pre-training datasets exerts distinct effects on in-domain (ID) and out-of-domain (OOD) tasks. In the case of ID tasks, slight noise during pre-training can yield improvements in in-domain transfer performance. However, for OOD tasks, noise consistently degrades out-of-domain performance. To substantiate their findings, the authors employ Singular Value Entropy (SVE) and Largest Singular Value Ratio (LSVR) to capture the behavior of the trained features in both ID and OOD tasks. Subsequently, the authors devise a loss function that enhances the SVE and LSVR of these features, resulting in superior overall performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The impact of noise within pre-training datasets on subsequent tasks has not been thoroughly investigated in the existing literature. The insights presented in this paper, such as the distinct effects of noise on in-domain (ID) and out-of-domain (OOD) tasks, are novel and intriguing.\n\n- The design of the loss function is a direct consequence of the insights gained from observations, and experiments demonstrate that this designed loss outperforms the Cross-Entropy (CE) baseline, including LP and MLP structures.\n\n- Experiments encompass a wide range of tasks, including both image and image-language tasks. Furthermore, various popular base model structures are used in this paper."
                },
                "weaknesses": {
                    "value": "-  I find Figure 3 challenging to interpret. It consists of numerous data points for each configuration, lacking connecting lines. Consequently, I struggle to draw the conclusions reached by the authors based on this figure.\n\n-  I've observed a potential contradiction between SVE and LSVR. For instance, in the case of two-dimensional features, [1.0, 0.0] exhibits the highest LSVR while having the lowest entropy. It would be beneficial if the authors could provide further clarification regarding this inconsistency.\n\n-  I would appreciate it if the authors could offer more detailed explanations as to why a slight amount of noise can benefit in-domain (ID) tasks. This is somewhat contradictory to the existing literature on learning with noisy labels, and additional insights would be valuable.\n\n-  In the paper, the authors claim that the proposed method enhances SVE and LSVR. However, Figure 5 (d) indicates that the proposed method does not yield superior LSVR compared to the LP and MLP models. Furthermore, it seems that as the noise ratio increases, LSVR does not drops significantly for all the settings.\n\n- It's worth noting that some related work, such as [R1], also employs Singular Value Decomposition (SVD) to address noisy label problems. It would be beneficial for the authors to discuss the distinctions between your approach and previous work.\n\n- I would like to point out that the improvements achieved by the proposed method appear to be relatively modest. According to the experimental results, the proposed method only demonstrates an approximately 1% improvement compared to the MLP model.\n\n- For ResNet-50, it might be worthwhile to explore the feasibility of fine-tuning all layers rather than constraining the encoder. It would be valuable if the authors could conduct experiments to determine if the proposed loss function is effective in cases where all layers are fine-tuned.\n\n[R1]: FINE Samples for Learning with Noisy Labels"
                },
                "questions": {
                    "value": "See **Weaknesses**"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6649/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6649/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6649/Reviewer_5WgV"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6649/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698600458790,
            "cdate": 1698600458790,
            "tmdate": 1700644808431,
            "mdate": 1700644808431,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "keLdKxNRRu",
                "forum": "TjhUtloBZU",
                "replyto": "4ymMfVtI7k",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6649/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6649/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5WgV (1/2)"
                    },
                    "comment": {
                        "value": "> 1. \"I find Figure 3 challenging to interpret...reached by the authors based on this figure.\"\n\nSorry for the confusion in Fig. 3, and thanks for your suggestions on making Fig. 3 more clear. \nIn fact, we have tried to connect the points in Fig. 3, but it only makes it more difficult to visualize and interpret. \nInstead, we have provided a zoom-in version of Fig. 3 (a) and Fig. 3 (c) in Fig.10 of Appendix. \nWe hope this zoom-in version is more interpretable.\nIn general, for the SVE of ID tasks, we first observe the increase of SVE as the noise goes up to 5%, with performance improvement for most of the tasks. \nThen we observe a further increase of SVE as noise increases to 10%, 20%, and 30%, and usually with performance drop. \n\n> 2. \"I've observed a potential contradiction between SVE and LSVR. For instance, in the case of two-dimensional features, [1.0, 0.0] exhibits the highest LSVR while having the lowest entropy. It would be beneficial if the authors could provide further clarification regarding this inconsistency.\"\n\nThanks for mentioning the view of two-dimensional features. \nHowever, there might be a little misunderstanding here, and we would like to provide more discussion.\n- First, we need to clarify that both SVE and LSVR are computed from the singular values of the features on the downstream test datasets of size $M$. When $M=1$ with a single point, the non-zero singular value would be trivial as a scalar of the magnitude of its unit basis vector (this can be simply verified by NumPy). In this case, any single point would present highest LSVR with lowest entropy, but has no relation to our observation and anlysis. \n- In general, we would require the size of the training samples and testing samples to be larger than 1 ($M > 1$), which is practical in real experiments.\n\n\n\n> 3. \"I would appreciate it if the authors could offer more detailed explanations as to why a slight amount of noise can benefit in-domain (ID) tasks. This is somewhat contradictory to the existing literature on learning with noisy labels, and additional insights would be valuable.\"\n\nThanks for this good question. We also find it interesting and more discussions should be added. We share our insights here:\n\n- Why a little noise can help?\n    - Slight noise in pre-training makes the model learn to fit those noise, where the extra dimensions in the feature space are utilized. Thus, when applied this model to a downstream task, its extra dimensions in feature space provide better initialized and discriminative features (from higher dimenstional space), leading to better downstream accuracy. \n    - More noise in pre-training results in more dimensions to fit the noise. However, more dimensions to fit the noise is at the cost of less transferable features learned from the clean data and more nauce learned from the noise data, thus further increasing noise leads to worse performance. \n    - We do not think the better performance on downstream of slight noise in pre-training is related to better regularization in our pre-training experiments. This is similar in [1], where even heavy regularization techniques are used, the model can still fit perfectly to random noise. \n\n- The relation between noisy label learning and noisy model learning: This might look contradictory to learning with noisy labels, but our problem is indeed different from noisy label learning, so we give it a new name as *noisy model learning*. As shown in Fig. 4,\n    - Noisy label learning: given a pre-trained model (or learn from scratch), the downstream datasets or any data we want to train the model contains noise.\n    - Noisy model learning: given a pre-trained model trained on noisy datasets (which we cannot access, such as the black-box pre-training data of CLIP), we want to reduce such effect brought by the noisy pre-trained data on *any* downstream datasets.\n\nThat being said, our noisy model learning is naturally *complementary* to noisy label learning. We have an experiment in Sec. 4.3 to show that they can be used together.\n\nAdditionally, we can informally consider that noisy training data can lead to noisy weights, as in NoisyTune [2], where the authors also found introducing noise to pre-trained weights could help with downstream tasks, reaching similar conclusions as our study.\n\n[1] Zhang et al. Understanding deep learning requires rethinking generalization. ICLR 2017.\n\n[2] Wu et al. NoisyTune: A Little Noise Can Help You Finetune Pretrained Language Models Better. ACL 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6649/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699888561265,
                "cdate": 1699888561265,
                "tmdate": 1699888561265,
                "mdate": 1699888561265,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EZ6wFHAe4o",
                "forum": "TjhUtloBZU",
                "replyto": "BPYBK8Y1pm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6649/Reviewer_5WgV"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6649/Reviewer_5WgV"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "I thank the authors for providing a comprehensive response with special appreciation for clarfiying the calculation of SVE and LSVR. The majority of my concerns have been successfully addressed. The incorporation of experiments encompassing fine-tuning across all layers suggests the broad applicability of the proposed loss.\n\nIn summary, I believe this paper delves into a crucial and relatively novel research area. The identified phenomenon, particularly the intriguing observation that \"a slight amount of noise can benefit in-domain tasks,\" holds substantial interest and may deserve further exploration for its potential in feature learning. Consequently, I have upgraded my score to \"accept.\""
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6649/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644793563,
                "cdate": 1700644793563,
                "tmdate": 1700644793563,
                "mdate": 1700644793563,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "m9LVgU5ZVq",
            "forum": "TjhUtloBZU",
            "replyto": "TjhUtloBZU",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6649/Reviewer_jd9i"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6649/Reviewer_jd9i"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the challenges posed by label noise in pre-training datasets and its impact on downstream tasks. The authors focus on supervised pre-training models using synthetic noisy ImageNet-1K and YFCC15M datasets. They observe that while slight noise in pre-training can enhance in-domain (ID) transfer performance, it consistently harms out-of-domain (OOD) performance. The reason behind is noise in pre-training shapes the feature space differently. They introduce a lightweight black-box tuning method, NMTune, to mitigate the adverse effects of noise and improve generalization on both ID and OOD tasks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This paper studies a problem that is both practical and significant, yet has not been sufficiently investigated in prior research.\n- This paper is well-motivated and easy to follow.\n- The analysis of features is useful to understand the noise's impact on ID and OOD data. \n- Experiments are comprehensive."
                },
                "weaknesses": {
                    "value": "- Improvements are needed in the writing and presentation quality. Please check the Question section below. \n- Some claims in the paper are unclear and confusing. Please check the Question section below. \n- The authors did not mention the limitations of their method and potential future work. The paper does not explore or discuss potential failure cases of the proposed methods. Understanding when and why the methods might fail is crucial for practical applications"
                },
                "questions": {
                    "value": "- Self-supervised pre-train does require external supervision. Does it mean those models will not suffer from the noise issue? \n- Does it proposed method generalize to self-supervised pre-trained models?\n- When you trained CLIP, did you train the text encoder together or you use a frozen text encoder?\n- \"For OOD evaluation, we use DomainNet (Peng et al., 2019) where we train on either \u201creal\u201d or \u201csketch\u201d images and test on \u201creal\u201d, \u201csketch\u201d, \u201cinpainting\u201d, and \u201cclippart\u201d images\". If you trained on either \u201creal\u201d or \u201csketch\u201d, you should only test on domains that the model did not seen during training right\uff1f This sentence is a bit confusing.\n- \"we empirically analyze the singular value spectrum of the pre-trained **the** feature space on downstream datasets\" Typo: extra \"the\"\n- Section 2.3,  the authors should let or remind the readers what are M and D. They should be the number of samples and latent dimension size right?\n- Figure 3 is a bit confusing. For a specific noise level, there are many points (e.g. many blue stars). What does each point mean? One downstream task? A lot of points are overlapped and I don\u2019t know which 5 points (0%, 5%, 10%, 20%, 30%) should be read together. \n- \"An initial increase in the spanning dimension of the feature space is beneficial to the discriminability on ID tasks. \" The reason behind that is \"the pre-trained feature extractor captures more structure in data\" due to noise. But why more structure does not help OOD?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6649/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6649/Reviewer_jd9i",
                        "ICLR.cc/2024/Conference/Submission6649/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6649/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698882850409,
            "cdate": 1698882850409,
            "tmdate": 1700671968620,
            "mdate": 1700671968620,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9bWrZ4ndsp",
                "forum": "TjhUtloBZU",
                "replyto": "m9LVgU5ZVq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6649/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6649/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer jd9i (1/2)"
                    },
                    "comment": {
                        "value": "> 1. \"Improvements are needed in the writing and presentation quality.\", \"Some claims in the paper are unclear and confusing.\"\n\nWe sincerely thank you for your careful proofreading of our paper. \nWe have fixed the typos and made the confusing statement more clear in the revised paper.\n\n> 2. \"The authors did not mention the limitations of...why the methods might fail is crucial for practical applications\"\n\nThanks for pointing this out. We briefly mentioned the limitation in the conclusion section (the last two sentences) due to the space limit. \nNow we discuss more limitation and potential failure here, which has been added in appendix C.1 and C.2. of the paper.\n\n**Limitation**. The limitation mainly lies in our empirical study of the noise in pre-training. \nDue to the limited computing resources to extensively investigate different noise ratios by pre-training different models, we could only conduct our \"motivational experiments\" on ImageNet-1K and YFCC15M using ResNet-50 (which are already very expensive since we need to pre-train several ResNet-50 models on ImageNet or YFCC15M from scratch). \nNote that most of the SOTA foundation models are of much more parameters and are trained on much larger (and possibly inaccessible) datasets, which are beyond our reach to perform pre-training.\nAdditionally, the empirical experiments are limited to actual supervised pre-training.\nWhile there are some existing studies showing the potential issue of noisy pre-training data, we could reveal more by scaling our experiments on larger backbones and datasets in the future.\n\n**Potential Failure**. Yes, we agree that identifying failure cases indeed helps understand the problem better. We do observe some failure cases of the proposed methods. \nFor example, from the results in Table 7, the proposed method falls short of LP on Caltech101 on almost all backbones we studied, while improving over MLP. \nOur hypothesis for the failure is that the SVD regularization term in the proposed method might need to optimize the top-$K$ singular values instead of just the largest one. The optimal value of $K$ might be different across datasets. However, setting $K=1$ can already achieve reasonable performance for most of the tasks, as shown in the results.\n\n\n> 3. \"Self-supervised pre-train does require external supervision...to self-supervised pre-trained models?\"\n\nThanks for this wonderful question! We do believe self-supervised learning is worth further discussion:\n\n- First of all, self-supervised learning does not require the explicit supervision of $Y$, but can be seen as supervised by the original input $X$, as we mentioned in footnote 2 of page 2 in our paper. In this context, it still requires supervision and the noise problem still exists: if $X$ is corrupted, which is usually the case in large-scale pre-training, it can be viewed as noise in self-supervision. \n- Second, despite some previous research [1] indicating that the self-supervised pre-training data contains some noise, we give more examples here. It turns out that corruption in $X$ can also have different formats in the actual data. For instance, in images, the corrupted $X$ can be poisoned or attacked images that do not contain natural content, and it will become noise for masked image modeling pre-training. Taking contrastive learning, MOCO [2], as another example. MOCO is a instance discrimination task and the negative pairs could potentially contain images that are similar to the positive anchor. This can also be viewed as noise. In auto-regressive language models such as GPT series, the noise would simply wrong or repetitive words in the sentence. \n- Third, our algorithm can naturally work for self-supervised pre-training models, as shown in Table 1 and 2, where most of these foundation models (ViT, CLIP, EfficientNet, GPT2, BERT, RoBERTa, and text-ada-002) are self-supervised pre-trained. Studying and understanding the corrupted $X$ (or noise) in self-supervised pre-training would also be very interesting and is our future direction. We believe the observation and conclusion from this work would scale and extend to the self-supervised learning scenarios because eventually, they fall into the same general formulation of noise in supervision.\n\nIn the future version of the paper, we will add more experiments and discussions about self-supervised learning.\n\n[1] Yang et al. Xlnet: Generalized autoregressive pretraining for language understanding. NeurIPS 2019.\n[2] Kaiming He, et al. Momentum Contrast for Unsupervised Visual Representation Learning\n\n> 4. \"When you trained CLIP, did you train the text encoder together or you use a frozen text encoder?\"\n\nFor CLIP pre-training, we strictly follow the training recipe of the Resnet-50 model in open clip, thus both the image encoder and text encoder are trained from scratch on synthetic noisy YFCC15M.\nFor CLIP fine-tuning (i.e., our noisy model tuning), we fixed all the encoders."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6649/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699888188605,
                "cdate": 1699888188605,
                "tmdate": 1699888188605,
                "mdate": 1699888188605,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "P0zjIxtbSi",
                "forum": "TjhUtloBZU",
                "replyto": "aHNzU17vDY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6649/Reviewer_jd9i"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6649/Reviewer_jd9i"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the responds"
                    },
                    "comment": {
                        "value": "The authors have addressed most of my questions and improved the manuscript. I will increase my score to 8."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6649/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671955634,
                "cdate": 1700671955634,
                "tmdate": 1700671955634,
                "mdate": 1700671955634,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]