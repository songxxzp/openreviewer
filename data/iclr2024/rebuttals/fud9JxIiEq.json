[
    {
        "title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures"
    },
    {
        "review": {
            "id": "DTWS4y4QHH",
            "forum": "fud9JxIiEq",
            "replyto": "fud9JxIiEq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6135/Reviewer_kj2x"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6135/Reviewer_kj2x"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes using the Gaussian Mixture Model (GMM) as the reverse transition kernel within the Denoising Diffusion Implicit Models (DDIM) framework. The author proposes to match the first and second-order moments of DDPM forward marginals and design three different schemes to compute GMM parameters. The experimental results show that the proposed method can improve the quality of conditionally generated and unconditionally generated samples."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The authors provide mathematical proof that the GMM-based sampling algorithm can be used for models obtained by DDPM training.\n+ The proposed method performs better in both conditional and unconditional generation than the DDIM method."
                },
                "weaknesses": {
                    "value": "+ The motivation for this paper is confusing; why use a Gaussian Mixture Model (GMM) and what are the benefits of such an assumption?\n+ The experiment is weak and only compared the DDIM method as a baseline, but other methods for improved sampling (e.g. DPM-Solver[1]) are not compared. Meanwhile, since DDIM is an ODE-based method, the relationship between DDIM-GMM and ODE should also be discussed\n[1] Lu C, Zhou Y, Bao F, et al. Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps[J]. Advances in Neural Information Processing Systems, 2022, 35: 5775-5787.\n+ The authors do not consider the additional computational cost associated with GMM; this computational effort compared to the number of samples should be discussed."
                },
                "questions": {
                    "value": "Please see the weaknesses. \nIn addition, Since the authors in their article state that the DDIM-GMM method is equivalent to DDPM in terms of the forward process, only the weight of the loss is different. There are some related works [1,2] that show that this weight has an effect on the diffusion model, the authors may try to design the loss function for training based on the GMM sampling assumption.\n[1] Choi J, Lee J, Shin C, et al. Perception prioritized training of diffusion models[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 11472-11481.\n[2] Kingma D, Salimans T, Poole B, et al. Variational diffusion models[J]. Advances in neural information processing systems, 2021, 34: 21696-21707."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6135/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697700592281,
            "cdate": 1697700592281,
            "tmdate": 1699636664472,
            "mdate": 1699636664472,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "m8e3MIa9in",
                "forum": "fud9JxIiEq",
                "replyto": "DTWS4y4QHH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6135/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6135/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for taking the time to review our paper. We address the questions and concerns below.\n\n> **Motivation for a GMM kernel**\n\nOur original motivation for the GMM kernel was to explore latent spaces ($x_t$) better than a Gaussian kernel, as well as a prior work [1] on demonstrating improvements over DDIM without strictly matching the marginals. Concurrent to our work [2] and also a recent work [3] show that the true denoiser conditional distributions ($q(x_{t-1}|x_t)$) are multimodal when taking large steps between $t$ and $t-1$ during sampling. This provides a justification for our work because we prove that the proposed DDIM-GMM kernel yields a more expressive multimodal GMM as the denoiser conditional distribution than DDIM (see Appendix A.7). In addition to providing more flexibility for modeling complex $q(x_{t-1}|x_t)$ than DDIM, our sampler does not require any training with specialized loss functions, unlike [2, 3]. And it can further benefit from fine-tuning with parameter exploration and learning based approaches [1] with the potential to improve over the results reported in the paper. We have made this new perspective and motivation clear in the updated version of the paper (Section 1 and Appendix A.7). \n\n> **Comparison with other samplers and ODE perspective**\n\nAlthough the main scope of this paper is to introduce a multimodal kernel in the DDIM framework and demonstrate improvements relative to it, we followed up with an additional experiment comparing with the DPM-Solver sampler. Specifically, we conducted experiments on the class-conditional ImageNet model with classifier-free guidance. The results are added to Appendix A.11 in the paper. Also, we have mentioned connections to ODE-solver perspective of samplers in the Related Works Section A.1, to the best of our knowledge.\n\n> **Computational cost**\n\nThank you for pointing this out. Although we briefly mentioned the additional computational overhead towards the end of Sections 3.1 and 3.1.3, we realize that it might have been easy to miss. The proposed approach introduces additional computational overhead in an \"initialization\" phase prior to sampling. All the GMM mean and variance offsets are precomputed and saved in memory before sampling. We can choose to precompute a single set of GMM parameters per batch or the entire sample set. We experimented with both the options and did not see a significant difference in metrics. So it is computationally more efficient to precompute offsets once and fix them. We also experimented with choosing different GMM parameters for different sampling steps $t$ and found no significant difference with setting them the same across all $t$ in our experiments. Due to saving the additional GMM parameters, there is some memory overhead relative to DDIM but it is negligible, especially in the scenario of choosing a single set of offsets across all samples and time steps. In the scenario of using different offsets across subsets (batches) of samples or sampling steps, the overhead scales linearly along the sample and number of step dimensions.              \nThe dimensionality of the latent spaces also determine the computational and memory requirements of the GMM offset parameters. For instance, it might be infeasible to compute the outer products of centered offsets (Eq. 11) if the dimensionality of the latent spaces is high, e.g. high-resolution image space diffusion models. In such cases, the DDIM-GMM-ORTHO-VUB is more feasible as it provides an upper bound for the variance offsets without explicitly computing them. We have made a note of these in a new Section in Appendix A.10.  \n\n> **Weights in the ELBO Loss Upper Bound** \n\nWe agree with the reviewer that the weights in the ELBO loss for training DDPM has a non-trivial impact on the resulting model. The purpose of deriving an upper bound (Appendix A.6) is to show that there is an equivalent weighted squared-error loss used in DDPM training that serves as an upper bound for the ELBO loss using the DDIM-GMM inference process. This provides a rough justification that the DDIM-GMM sampler can exploit pretrained diffusion models that are trained with equal weighting. As suggested by the reviewer, it would be ideal to use the derived weights during DDPM training but our experiments suggest empirically that DDPM training with uniform weights still works with the DDIM-GMM sampler. It would be an interesting future work to use the DDIM-GMM ELBO upper bound as a surrogate loss function to train DDPM models and see if it leads to better sample quality with the proposed approach.   \n\n> **References**\n\n1. Daniel Watson et al., Learning fast samplers for diffusion models by differentiating through sample quality, ICLR 2021.\n2. Hanzhong Guo et al., Gaussian Mixture Solvers for Diffusion Models, NeurIPS 2023.\n3. Zhisheng Xiao et al., Tackling the Generative Learning Trilemma with Denoising Diffusion GANs, ICLR 2022."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6135/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714495867,
                "cdate": 1700714495867,
                "tmdate": 1700714495867,
                "mdate": 1700714495867,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MvqlAKpgfA",
            "forum": "fud9JxIiEq",
            "replyto": "fud9JxIiEq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6135/Reviewer_fa8T"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6135/Reviewer_fa8T"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduced a Mixture of Gaussian kernels to the DDIM sampling process. This work proposes three sampling methods that satisfy the constraints on the GMM kernel weights to perform DDIM sampling aligned with the marginal of the pre-trained DDPM using the GMM kernel.\nCompared to the DDIM using the Gaussian kernel, the proposed method sometimes leads to better performance with a few sampling steps."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The proposed method can represent transitions with more parameters at each transition than DDIM with a Gaussian kernel. Without additional training, the method can affordably enhance the expressiveness over the Gaussian kernel by adding parameters."
                },
                "weaknesses": {
                    "value": "* **Limited novelty.** It is an incremental approach to the DDIM sampling method w/ a Gaussian kernel. It only shows a comparison with DDIM w/ a Gaussian kernel, without performance comparisons with other methods.\n\n* **Marginal improvement.** Looking at the FID and IS results in Figures 1, 2, and 3, and the tables in the Appendix, the performance improvement over DDIM is marginal. The proposed method only shows a slight performance improvement at fewer sampling steps (around 10 steps) where DDIM w/ a Gaussian kernel struggles. As the number of samplings increases, there is no performance difference compared to the baseline. The qualitative results in Figure 8 also fail to demonstrate that the proposed method is superior to the baseline.\n\n* Lack of analysis on the number of mixtures in GMM or the weights for each mixture."
                },
                "questions": {
                    "value": "* This method can be applied to any pre-trained diffusion model, just like DDIM w/ a Gaussian kernel. Does this sampling method using GMM have advantages in applications like Text-to-Image generation than the baseline? \n\n* When DDIM w/ a Gaussian kernel shows good performance (e.g. 100+ sampling steps), can the proposed method bring more than just a marginal improvement in performance, even at a higher number of sampling steps?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6135/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698769723264,
            "cdate": 1698769723264,
            "tmdate": 1699636664354,
            "mdate": 1699636664354,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7shuMh3YF6",
                "forum": "fud9JxIiEq",
                "replyto": "MvqlAKpgfA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6135/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6135/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Our sincere thanks for taking time to review our paper and provide feedback. Please find our responses to your concerns below.\n\n> **Novelty**\n\nAlthough our approach appears to be incremental over DDIM, we believe it addresses a fundamental problem in accelerated sampling from pre-trained diffusion models. Recent works [1, 2] have provided evidence that the denoising conditional distribution ($q(x_{t-1}|x_t)$) is multimodal when the step size is large. By introducing a multimodal transition kernel, it addresses this issue by providing a way to model multimodality in the denoiser better than DDIM (see Appendix A.7). Our work provides theoretical justification for the choice of the GMM parameters by introducing moment matching constraints. We describe three different ways to select GMM parameters that satisfy the constraints. Although being simple, these proposed variants already demonstrate improvements over DDIM based on the metrics reported in the Experiments section. Further, as noted in the paper, it is possible to learn the GMM parameters using a suitable approach such as the DDSS framework of [3] to better fit the multimodal denoiser distributions. Note that unlike [1, 2], our approach can be applied to pre-trained diffusion models without any training or specialized loss functions. We hope that this leads to further research on more sophisticated approaches for learning GMM parameters in the proposed kernel, with more potential to improve upon DDIM and possibly other accelerated sampling approaches.              \n\n> **Marginal improvements relative to DDIM**\n\nWe agree with the reviewer that the improvements seem marginal in many cases relative to DDIM. Although this may be subjective, as noted in Appendix A.13, we consider a relative improvement of 1 point in FID or IS metric as significant. The definition of significance is tied to the main scope of this paper, which is to propose a multimodal GMM kernel in the DDIM framework, with theoretical justification, and provide empirical evidence that it brings improvements relative to DDIM. To this end, we provide three simple training-free schemes to choose GMM parameters and show empirically that they provide improvements relative to DDIM, in most fast sampling scenarios (fewer steps). It is possible to design alternative schemes or learn the GMM parameters, which have the potential to further improve performance. We leave this exploration for future work.\n\nAnother potential reason for marginal improvements, especially with large number of sampling steps, is that the DDIM unimodal kernel models the denoiser distribution [1] sufficiently well. In other words, the proposed schemes for selecting GMM parameters, with limited parameter exploration (see Section 4.1 and Appendix A.2) are close to DDIM in terms of modeling complexity of the true denoiser (Appendix A.7). With a more fine-grained parameter exploration and learning based schemes for the GMM parameters, there is potential for improvement. We leave this for future work.      \n\n> **Ablations on GMM parameters**\n\nThank you for pointing this out. We have included ablations on the number of mixture components and the offset scaling factor $s$ in Appendix A.9.    \n\n> **Application to Text-to-Image Generation**\n\nOur approach is applicable to any pre-trained diffusion model including text-to-image generation models. To this end, we conducted experiments with the publicly available Stable Diffusion v2.1 model and reported results in the Experiments Section 4.3. The results clearly demonstrate the benefits of the proposed approach over DDIM based on FID and IS metrics.\n\n> **How to improve performance at larger number of steps?**\n\nAs described above, as the number of sampling steps increases or the step size decreases, the DDIM Gaussian kernel yields an expressive enough denoiser to model the true step distributions ($q(x_{t-1}|x_t)$) [1]. We believe this could be the main reason for the diminishing gains from using a multimodal kernel in this scenario. Also, we propose three simple training-free schemes for choosing GMM parameters and do a limited exploration of the parameter space (number of mixture components, mixture weights, offset scales). An exhaustive exploration of these parameters is one possible way to potentially improve the performance with larger number of steps. Another possibility would be to apply learning based schemes, e.g. [3], to fine-tune GMM parameters to get the most out of the proposed approach. We leave these explorations for future work.\n\n> **References**\n\n1. Hanzhong Guo et. al., Gaussian Mixture Solvers for Diffusion Models, NeurIPS 2023.\n2. Zhisheng Xiao et. al., Tackling the Generative Learning Trilemma with Denoising Diffusion GANs, ICLR 2022.\n3. Daniel Watson et. al., Learning fast samplers for diffusion models by differentiating through sample quality, ICLR 2021."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6135/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714062903,
                "cdate": 1700714062903,
                "tmdate": 1700714062903,
                "mdate": 1700714062903,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rQkMIbIt4z",
            "forum": "fud9JxIiEq",
            "replyto": "fud9JxIiEq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6135/Reviewer_K8bf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6135/Reviewer_K8bf"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel sampling scheme for a pre-trained denoising diffusion probabilistic models. The authors investigate a Gaussian Mixture Model (GMM), in place of a univariate Gaussian, within the reverse transition kernels of the DDIM generative process. To choose the additional GMM parameters, a moment matching technique is suitably applied with theoretical grounding. The use of GMM results in improved FIDs and ISs when taking small numbers of sampling steps."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Taking advantage of GMM in DDIM sampling appears to be a sensible approach, and is presumably more capable than a unimodal Gaussian. The main hurdle of using GMM would be the increased complexity and the lack of parameters learning schemes. The highlighted contribution of this paper is to provide a feasible moment matching approach for choosing GMM parameters. As far as I checked, this technique is technically sound."
                },
                "weaknesses": {
                    "value": "The main problem of this paper would be clarity.\n\n- There are numerous ill-defined variables and formulas in the main paper, which, to a large extent, hinder readers' understanding. This current presentation is kind of poor that I struggle to read all the derivation in the main paper and the appendix. I suggest to **bold** all vectors and matrices, following the usual practice of ICLR papers, to differentiate them from scalars. For example, in Eq. (9), it is very hard tell how $O_t$ could possibly subtract $\\bar{o}_t$, when the former is a matrix and the latter is a vector. \n\n- The organization of section 3.1 is also confusing. I suppose the authors try to provide three choices of method for selecting the GMM parameters. However, three methods just appear without much explanation and any reference to the previous works on GMM. From the experiment results, I prefer to a more condense presentation on the DDIM-GMM-ORTHO-VUB solution, while the discussion on DDIM-GMM-RAND and DDIM-GMM-ORTHO can be moved to the Appendix for ablation studies.\n\n- The experimental results in section 4 are very unclear. The performance differences in Figure 1-7 are basically not noticeable. While these figures occupy about 1.5 pages of the main paper, their provided information might be less than two table (one for CelebAHQ and FFHQ; one for ImageNet). The current presentation of results is so ineffective that I cannot find any significant improvement against the original DDIM sampling approach."
                },
                "questions": {
                    "value": "My questions are stated above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6135/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813360458,
            "cdate": 1698813360458,
            "tmdate": 1699636664211,
            "mdate": 1699636664211,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BjgHyvrK8y",
                "forum": "fud9JxIiEq",
                "replyto": "rQkMIbIt4z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6135/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6135/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your review. Please see our comments below, specifically addressing the weaknesses.\n\n> **Writing and notation**\n\nThank you for your suggestions on improving the writing and notation. We have tried to incorporate these as much as possible. Specifically, the notation in the updated version uses bold symbols for all vectors and matrices. We have removed ambiguity involving matrix-vector operations (e.g., Eq. 9). It is our hope that this version improves readability of the paper.  \n\n> **Motivation for the proposed GMM parameter computation approaches**\n\nRegarding the motivation for the proposed methods for computing GMM parameters, we agree that there is prior work including Expectation Maximization (EM) and method of moments. We believe that the main scope of this paper is to introduce a multimodal kernel into the DDIM sampling framework and demonstrate its benefits over using a unimodal kernel. To this end, we focus on the theoretical justifications of such an approach and suggest a few simple heuristics to come up with a set of GMM parameters efficiently. It is possible to use alternative approaches for estimating GMM parameters such as EM or other learning based approaches [1] specific to DDIM samplers using training data. We chose to use the heuristically driven approaches to keep the samplers training-free, in the spirit of original DDIM. Our empirical results suggest that we see benefits over DDIM even using these simple approaches without searching for their parameters exhaustively. It would be an interesting future direction to explore the possibility of using more complex GMM parameter estimation methods to further improve upon the proposed method.  \n\n> **Experimental results and organization of the paper** \n\nWe agree with the reviewer that the experimental results on FID and IS metrics are concisely presented in a tabular form. Our goal here is to illustrate the relative performance between DDIM and DDIM-GMM under different $\\eta$ settings as well as sampling steps. This is to help the reader understand benefits and trade-offs under different scenarios due to the interaction between $\\eta$ and the offsets ($\\delta_t^k$'s and $\\Delta_t^k$'s) of the three proposed variants of the DDIM-GMM sampler. We found that graphs are more concise, e.g., comparing the space occupied by Fig. 1 vs Table 5. However, following your suggestion on conveying more information within the available space, we have changed contents in the Experiments section. We show more practical utility of the proposed approach by replacing the class conditional ImageNet results with new experiments on a text-to-image diffusion model. Hopefully the newer version looks more organized and informative. \n\n> **References**\n\n1. Daniel Watson et. al., Learning fast samplers for diffusion models by differentiating through sample quality, ICLR 2021."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6135/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713715139,
                "cdate": 1700713715139,
                "tmdate": 1700713715139,
                "mdate": 1700713715139,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "NvHvp3LbCa",
            "forum": "fud9JxIiEq",
            "replyto": "fud9JxIiEq",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6135/Reviewer_Rr35"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6135/Reviewer_Rr35"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a variant of the Denoising Diffusion Implicit Model (DDIM), wherein a Gaussian Mixture Model (GMM) is employed as the reverse transition kernel, replacing the Gaussian model. The authors derive constraints for the GMM, ensuring that the first and second central moments of the forward marginal distributions match those of the Denoising Diffusion Probabilistic Model (DDPM). Utilizing these constraints, the authors deduce the upper bound of the Evidence Lower Bound (ELBO) and adopt it as the training loss, resulting in an augmented version of the DDPM loss."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "-The paper proposes a variant of DDIM, utilizing a Gaussian Mixture Model as the reverse transition kernel.\n- The paper suggests that moment matching is sufficient for producing samples of equal or superior quality compared to the original DDIM.\n- The presentation is clear and easy to understand."
                },
                "weaknesses": {
                    "value": "- DDIM is typically employed with $\\eta=0$. Although the proposed method appears to significantly enhance the performance of the original DDIM when $\\eta\\neq 0$, numerical results suggest that its performance is generally inferior compared to DDIM with $\\eta=0$. For instance, in Fig. 1, the FID scores range from 25 to 35 when $\\eta=0$ and the number of steps is 10, whereas they range from 60 to 70 when $\\eta=1.0$ and the number of steps is 10. Furthermore, as the number of steps increases beyond 10, the performance difference between DDIM ($\\eta=0$) and DDIM-GMM becomes almost negligible.\n- What are the values of $\\eta$ used in the figures where the generated samples are displayed? The visual assessment of the sampling results makes it difficult to qualitatively determine which method produces better quality. In scenarios with 10 steps, both methods frequently result in deformed structures, and at 100 steps, it becomes challenging to definitively decide which method delivers superior quality. I am uncertain about its practical utility."
                },
                "questions": {
                    "value": "- How do the results compare when the proposed method is tested under the experimental settings provided in the DDIM paper [1], specifically on the CIFAR10, Bedroom, Church, and CelebA datasets?\n- Why were sampled images from the unconditional model not included in the presentation?\n- How does the performance of the proposed method compare to the generalized version of DDIM suggested in [2]?\n\n[1] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In International Conference on Learning Representations, 2021. URL https://openreview.net/\nforum?id=St1giarCHLP.\n[2] Daniel Watson, William Chan, Jonathan Ho, and Mohammad Norouzi. Learning fast samplers\nfor diffusion models by differentiating through sample quality. In International Conference on\nLearning Representations, 2021."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6135/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698897738396,
            "cdate": 1698897738396,
            "tmdate": 1699636664066,
            "mdate": 1699636664066,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aAqMtQQCuc",
                "forum": "fud9JxIiEq",
                "replyto": "NvHvp3LbCa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6135/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6135/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for your review. Please find below our responses to each of your concerns.\n\n> **Comparison to DDIM at $\\eta=0$ vs $\\eta \\gt 0$**\n\nWe agree that DDIM performs best at $\\eta=0$.\n\nThe proposed GMM kernel offsets both the mean and the covariance (variance) components of the original DDIM kernel. At $\\eta=0$, the offsets affect only the mean value due to $\\sigma_t$'s being zero. In this case, we set the variance of all the components in DDIM-GMM kernel explicitly to zero. While this is does not strictly ensure moment matching, empirically we see that the mean offsets ($\\delta_t^k$'s) still provide some improvement relative to DDIM. As $\\eta$ increases from 0 to 1, the covariance offsets ($\\Delta_t^k$'s) reduce the original DDIM variances ($\\sigma_t$), in a subset of the dimensions, to match the moments. We hypothesize that the proposed DDIM-GMM kernels allow better exploration of the latent spaces at different steps $t$, especially when the jumps between successive denoising steps are large. As argued by other works [3, 4], these latent spaces are multimodal and exploring with a multimodal kernel is beneficial relative to a unimodal kernel (see Appendix A.7 in the updated version). Increasing values of $\\eta$ encourages this further with the DDIM-GMM kernel, which explains the larger improvements in FID at $\\eta=1$ vs $\\eta=0$.\n\nAs the number of sampling steps increases, the denoising distribution $q(x_{t-1}|x_t)$ is effectively explored by a unimodal kernel (DDIM) as observed in [3] explaining the smaller difference between DDIM and DDIM-GMM. \n\n> **Value of $\\eta$ in Figures**\n\nThank you for pointing this out. We have added the $\\eta$ values used in generating the visualizations to figure captions in the updated version. Note that we did not cherry-pick images for visualization. It is perhaps subjective, but we believe that there are qualitative differences in DDIM-GMM vs DDIM outputs. For e.g., in Fig. 12, the semantic concept emerges faster (10 steps) with DDIM-GMM relative to DDIM--the images on the left look blurrier than the ones on the right. Objectively, this is corroborated by the FID/IS values (Fig. 12 => Tables 7 & 8). At larger number of sampling steps (100), we agree that it might be difficult to tell the differences qualitatively. So we have eliminated them.        \n\n> **Results with the DDIM [1] datasets**\n\nWe did additional experiments with the same settings as DDIM [1] on LSUN datasets. The results are included in Appendix A.12. Unlike LSUN datasets, we were not able to reproduce the numbers on CIFAR10 in [1] using their codebase. So we list the results of our experiments below.\n\n```\n-----------------------------------------------\nSteps | 10 | 20  | 50 | 100 | 1000  \n-----------------------------------------------\nDDIM\n-----------------------------------------------\n$\\eta=0.0$ | 18.53 | 10.95 | 7.02  | 5.55  | 4.09\n$\\eta=0.2$ | 19.18 | 11.25 | 7.35  | 5.72  | 4.08\n$\\eta=0.5$ | 22.09 | 13.10 | 8.36  | 6.42  | 4.21\n$\\eta=1.0$ | 42.31 | 24.78 | 14.63 | 10.51 | 4.74\n-----------------------------------------------\nDDIM-GMM-ORTHO-VUB\n-----------------------------------------------\n$\\eta=0.0$ | 18.19 | 10.56 | 6.70  | 5.25 | 3.70\n$\\eta=0.2$ | 18.70 | 10.83 | 7.05  | 5.46 | 3.78\n$\\eta=0.5$ | 21.24 | 12.53 | 7.91  | 6.10 | 3.97 \n$\\eta=1.0$ | 41.00 | 23.83 | 14.27 | 9.99 | 4.52\n-----------------------------------------------\n```\n\n> **Excluding face samples**\n\nIt is more of a subjective decision not to include face images in our paper as we believe that including them raises potential privacy concerns.\n\n> **Comparison with generalized version of DDIM [2]**\n \nWe compare the performance of DDIM-GMM-ORHTO-VUB ($\\eta=0$) with DDSS [2] on CIFAR10 below (FID/IS). \n\n```\n----------------------------------------------------------\nSteps | 5 | 10 | 15 | 25  \n----------------------------------------------------------\nDDSS [2]| 13.77/8.52 | 8.22/8.90  | 4.72/9.26  | 4.25/9.19\nDDIM-GMM| 43.54/6.81 | 18.19/8.80 | 10.56/9.59 | 9.31/9.68\n----------------------------------------------------------\n```\n\nWe expect DDSS to perform better as it is trained on CIFAR10 samples.\nOur results look worse due to two possible reasons: \n1)it is training-free & 2) the baseline DDIM [1] CIFAR10 results look worse in our experiments (see above). \nHowever, our approach can be trained within the DDSS framework to further improve the results.\nWe have noted this in the paper in Sections 4.1 and 5.\n\n> **References**\n\n1. Jiaming Song et. al., Denoising diffusion implicit models, ICLR 2021.\n2. Daniel Watson et. al., Learning fast samplers for diffusion models by differentiating through sample quality, ICLR 2021.\n3. Hanzhong Guo et. al., Gaussian Mixture Solvers for Diffusion Models, NeurIPS 2023.\n4. Zhisheng Xiao et. al., Tackling the Generative Learning Trilemma with Denoising Diffusion GANs, ICLR 2022."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6135/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713509681,
                "cdate": 1700713509681,
                "tmdate": 1700713509681,
                "mdate": 1700713509681,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]