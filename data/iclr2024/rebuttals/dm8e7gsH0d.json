[
    {
        "title": "Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection"
    },
    {
        "review": {
            "id": "Im5gmheLTX",
            "forum": "dm8e7gsH0d",
            "replyto": "dm8e7gsH0d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4177/Reviewer_bZUo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4177/Reviewer_bZUo"
            ],
            "content": {
                "summary": {
                    "value": "The paper finds that the existing feature-shaping methods usually employ rules manually designed for specific model architectures and OOD datasets, which consequently limit their generalization ability. To address this gap, the authors first formulate an abstract optimization framework for studying feature-shaping methods. then they propose a concrete reduction of the framework with a simple piecewise constant shaping function and show that existing feature-shaping methods approximate the optimal solution to the concrete optimization problem. Further, assuming that OOD data is inaccessible, the authors propose a formulation that yields a closed-form solution for the piecewise constant shaping function, utilizing solely the ID data. Through extensive experiments, the authors show that the feature-shaping function optimized by the proposed method improves the generalization ability of OOD detection across a large variety of datasets and model architectures."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is written well and is easy to understand.\n2. The studied problem is very important.\n3. The results seem to outperform state-of-the-art."
                },
                "weaknesses": {
                    "value": "1. I am curious about the comparison of the proposed method with the methods that can train with the real outliers in different benchmarks.\n2. In terms of the feature-shaping methods, I am curious how well the proposed method compared to the OOD detection using contrastive learning objectives to reshape the feature, such as CSI and SSD [2] on different benchmarks and mode architectures.\n\n[1] CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances\n\n[2] SSD: A Unified Framework for Self-Supervised Outlier Detection"
                },
                "questions": {
                    "value": "see above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4177/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698533591452,
            "cdate": 1698533591452,
            "tmdate": 1699636383635,
            "mdate": 1699636383635,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NEmludaUCV",
                "forum": "dm8e7gsH0d",
                "replyto": "Im5gmheLTX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely thank you for the time and effort you invested in reviewing our paper.  We are grateful for your acknowledgment of its well-crafted composition, the significance of the problem it addresses, and its demonstration of superior results compared to current state-of-the-art methods.\n\nWe compare our proposed method and others, including training a model with outlier exposure and using contrastive learning objectives. These training methods are not designed for a large-scaled dataset like ImageNet-1k. Thus, our experiments are conducted on the ImageNet-200 benchmark with ResNet18, following OpenOOD V1.5 [1]. \n\nWe emphasize that this is not a fair comparison, because our method is designed for post-hoc OOD detection, assuming no access to OOD data and no extra model training process. But as shown in the table, there are no significant differences between different methods. Training methods do not show a significant advantage over the post-hoc methods, as also observed by OpenOOD V1.5 [1].\n\nDue to the time constraints associated with the rebuttal, we are currently unable to carry out very extensive experiments to compare post-hoc OOD methods with training methods. However, exploring the performance of training methods across various benchmarks and model architectures is a promising direction that we look forward to investigating.\n\n| Training                    | OOD Score | ID Accuracy                       | AUC (Near OOD) | AUC (Far OOD) | AUC (Mean)   |\n| --------------------------- | --------- | --------------------------------- | -------------- | ------------- | ------------ |\n| **- Post-hoc**              |           |                                   |                |               |              |\n| CrossEntropy                | MSP       | 86.37                             | *83.29*   | 90.13         | 86.71        |\n| CrossEntropy                | Energy    | 86.37                             | 82.41          | 90.84         | 86.62        |\n| CrossEntropy                | ReAct     | 86.37                             | 81.77          | 92.28         | 87.03        |\n| CrossEntropy                | ASH-B     | 86.37                             | 81.60          | *93.77*  | *87.68* |\n| CrossEntropy                | Ours      | 86.37                             | 81.16          | 92.80         | 86.98        |\n| **- Training w/o outliers** |           |                                   |                |               |              |\n| ConfBranch (arXiv\u201918)       |           | 85.92                             | 79.10          | 90.43         | 84.77        |\n| RotPred (NeurIPS\u201919)        |           | 86.37                             | 81.59          | 92.56         | *87.08* |\n| G-ODIN (CVPR\u201920)            |           | 84.56                             | 77.28          | 92.33         | 84.81        |\n| CSI (NeurIPS\u201920)            |           | Infeasible with compute resources | /              | /             |              |\n| ARPL (TPAMI\u201921)             |           | 83.95                             | 82.02          | 89.23         | 85.62        |\n| MOS (CVPR\u201921)               |           | 85.60                             | 69.84          | 80.46         | 75.15        |\n| VOS (ICLR\u201922)               |           | 86.23                             | 82.51          | 91.00         | 86.75        |\n| LogitNorm (ICML\u201922)         |           | 86.04                             | 82.66          | *93.04*  | **87.85**    |\n| CIDER (ICLR\u201923)             |           | No final linear classifier        | 80.58          | 90.66         | 85.62        |\n| NPOS (ICLR\u201923)              |           | No final linear classifier        | 79.40          | **94.49**     | 86.94        |\n| **- Training w/ outliers**  |           |                                   |                |               |              |\n| OE (NeurIPS\u201918)             |           | 85.82                             | **84.84**      | 89.02         | 86.93        |\n| MCD (ICCV\u201919)               |           | 86.12                             | *83.62*   | 88.94         | 86.28        |\n| UDG (ICCV\u201921)               |           | 68.11                             | 74.30          | 82.09         | 78.19        |\n| MixOE (WACV\u201923)             |           | 85.71                             | 82.62          | 88.27         | 85.44        |\n\n**Bold** numbers are superior results whereas *Italic* numbers denote the second and third best results.\n\n[1] Zhang, Jingyang, et al. \"OpenOOD v1. 5: Enhanced Benchmark for Out-of-Distribution Detection.\" *arXiv preprint arXiv:2306.09301* (2023)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699842508979,
                "cdate": 1699842508979,
                "tmdate": 1699842508979,
                "mdate": 1699842508979,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "2kARfrCryA",
            "forum": "dm8e7gsH0d",
            "replyto": "dm8e7gsH0d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY"
            ],
            "content": {
                "summary": {
                    "value": "This work proposed the feature shaping method in OOD detection. By dividing K intervals, the vector of the K dimension is constructed, named the ISFI vector. Based on this vector, they optimize theta to increase the score of in-distribution and decrease the score of out-distribution. The authors showed the effectiveness of their approach on various architectures compared to existing feature shaping methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Compared to previous feature shaping methods, the proposed method is effective on various architectures, especially on MLP architectures."
                },
                "weaknesses": {
                    "value": "- What is the motivation to introduce ISFI? For example, ReAct [A] observes the distribution of per-unit activation for In and out-distribution data.\n- I am confused about the meaning of Figure 2. Suppose that z of M dimension is given. Then, theta of ReAct [A] is also M dimension because ReAct conducts the operation on each element of feature z. theta of the proposed method is K dimension determined by the number of intervals. I am not sure whether it is possible to put the plots together.\n- theta is optimized over the proposed optimization problem that the closed form exists. However, other feature shaping methods [A, B] do not have the other parameters to be optimized.\n- Other feature shaping methods [A, B] said that their methods have comparable performance in distribution distribution after applying their methods. Can authors discuss this point?\n\n[A] React: Out-of-distribution detection with rectified activations, NeurIPS 2021\n\n[B] Extremely Simple Activation Shaping for Out-of-Distribution Detection, 2023"
                },
                "questions": {
                    "value": "Please refer to the weaknesses.\n\n==\n\nI raise my score from 3 to 6."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4177/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY",
                        "ICLR.cc/2024/Conference/Submission4177/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4177/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698634948397,
            "cdate": 1698634948397,
            "tmdate": 1700726331939,
            "mdate": 1700726331939,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "k7jnx7mBgA",
                "forum": "dm8e7gsH0d",
                "replyto": "2kARfrCryA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate your time and effort in reviewing our paper. We are pleased that you acknowledged the effectiveness of our method across diverse model architectures. \n\n> **Q1: What is the motivation to introduce ISFI?**\n\nWe aim to optimize the multiplicative function $\\theta(z)$ in Eq. 4, which models elementwise feature-shaping functions. The primary challenge arises from the continuous nature of the feature value $z$, complicating the optimization problem. To address this, we introduce ISFI, a strategic discretization facilitating the assessment of feature importance for OOD detection. Specifically, we partition the domain of features into a disjoint set of intervals, which allows us to approximate the original function $\\theta(z)$ with a piece-wise constant function, thus simplifying the optimization problem.\n\n> **Q2: What is the meaning of Figure 2?**\n\nFig. 2 compares our optimal piecewise constant shaping functions with previous methods, showing that these prior works are empirically approximating our function optimized with access to OOD data.\n\nThe methods shown in Fig. 2(a-c), including ReAct, BFAct, and VRA-P, are element-wise shaping functions. These functions identically treat each element of the feature vector, simplifying the comparison.\n\nFor example, given any element $z$ of feature representation $\\boldsymbol{z}\\in \\mathbb{R}^M$, our shaping function is $\\bar{z}=\\theta(z)\\cdot z$, where the function $\\theta$ is discretized with $K$ parameters. ReAct applies an element-wise shaping function $\\bar{z}=\\min(z,t)=\\frac{\\min(z,t)}{z}\\cdot z$ to each element. We do not need to compare the two methods on each of the $M$ features, but instead, we compare the two functions $\\theta(z)$ and $\\frac{\\min(z,t)}{z},z\\in\\mathbb{R}$.\n\nBesides, ASH families in Fig. 2(e-h) incorporate the entire feature vector and are not reducible to element-wise functions. As an approximation, we estimate their average shaping effects across all samples.\n\n> **Q3: Other feature shaping methods such as ReAct and ASH do not have other parameters to be optimized.**\n\nWe respectfully argue that this point actually leads to a disadvantage of ReAct and ASH compared with our method. The shaping functions of ReAct and ASH are manually designed for specific model architectures and OOD datasets. This eliminates the need for additional parameters but consequently limit their generalization ability. In contrast, while our shaping function introduces more parameters, it can be efficiently optimized in closed form based on different models and ID data. Additional parameters do not increase user burden; instead, they bring greater flexibility and generalization ability to our method (Tables 1&2). \n\n> **Q4: Can authors discuss the comparable performance claimed by ReAct and ASH?**\n\nThere might be some typos in your comment. Here we discuss the generalization ability claimed by ReAct and ASH over different distributions. Please engage with us in discussion if your comment is asking something different.\n\nThe experiments conducted in the ReAct and ASH papers involve a narrower range of models and OOD datasets compared to our study. This limitation restricts the evaluation on the generalization ability of their methods. \n\nFor instance, when using ImageNet-1k as the ID data, both ReAct and ASH restrict their experiments to two model architectures and four OOD datasets. In contrast, our research encompasses a more extensive evaluation, employing eight different model architectures and eight OOD datasets. Note that the models and OOD datasets used in the ReAct and ASH studies are also included in our experimental setup.\n\nThis broader scope in our study allows for a more robust assessment of the generalization ability of our method, significantly contributing to the reliability and applicability of our findings."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699842282473,
                "cdate": 1699842282473,
                "tmdate": 1699842282473,
                "mdate": 1699842282473,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "k3aTah01Zk",
                "forum": "dm8e7gsH0d",
                "replyto": "2kARfrCryA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY"
                ],
                "content": {
                    "title": {
                        "value": "Response of comment"
                    },
                    "comment": {
                        "value": "I thank the authors for their response.\n\n> __Q3: Other feature shaping methods such as ReAct and ASH do not have other parameters to be optimized.__\n\nI respect the authors' comments. I agree with the advantage of the proposed method as the authors mentioned. I think that introducing more parameters is a clever approach.\n\n> __Q2: What is the meaning of Figure 2?__\n\nI might have misunderstood the figure at first. I appreciate the authors' comments.\nI have a question about the interpretation of this figure. The authors said that the proposed method flips the sign at low-value features.\nWhy do the low-value features are flipped? I think that it is an interesting phenomenon although these parameters are determined by the optimization problem."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700374019429,
                "cdate": 1700374019429,
                "tmdate": 1700374047265,
                "mdate": 1700374047265,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FO1nwDulZr",
                "forum": "dm8e7gsH0d",
                "replyto": "p7rXtNTX2B",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "I appreciate the authors' comments. \n\nIf there is a visualization to show \"low-value features often align with negative weights\" directly in the paper, the paper is more convincing. The authors said, \"Our experiments revealed...\", but it seems to be indirect if the authors refer to Fig. 2. (Or, I would like to ask carefully if it is included in the paper.)\n\nI wonder whether K-dim ISFI improves the OOD performance. \nIn other words, $\\theta \\in \\mathcal{R}^m$ can be optimized to $z \\in \\mathcal{R}^m$  rather than K-dim ISFI.\nThis experiment can reveal the importance of the optimization problem (Eq. 14) and the interval-specific feature independently. This experiment might show a similar result or tendency in Fig. 4(c) in the main paper."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700558177738,
                "cdate": 1700558177738,
                "tmdate": 1700558177738,
                "mdate": 1700558177738,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9DtpUVXXVw",
                "forum": "dm8e7gsH0d",
                "replyto": "2kARfrCryA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response!\n\n> **Visualization to show \"low-value features often align with negative weights\"**\n\nWe apologize for any confusion caused by the phrase \"our experiments revealed\" in the last reply. The referred experiments are not currently included in our paper. They were designed to empirically explan the specific form of the optimized function, based on a specific model architecture and ID dataset. Note that our optimized function may vary across different model architectures and datasets, so the findings, such as the tendency for low-value features to align with negative weights, might not be universally applicable.\n\nHowever, in light of your recommendation, we recognize the value of including an additional discussion in the supplementary materials. This will cover the characteristics of the optimal function and provide corresponding empirical explanations. We plan to update the materials accordingly soon.\n\n> **Whether K-dim ISFI improves the OOD performance**\n\nPrevious feature-shaping methods predominantly focus on manipulating features based on their values, instead of feature indexes within representations. For instance, ReAct employs truncation for features exceeding a certain threshold, while ASH families disregard features with low values.\n\nAligned with prior research, our paper seeks to refine the shaping function $\\theta$ based on feature values. The introduction of ISFI emerges from the challenges posed by the continuous nature of feature values. By dividing the feature values into separate intervals, ISFI enables us to approximate $\\theta(z)$ with a piecewise constant function, thereby simplifying the optimization process. Thus, the primary goal of proposing ISFI is not to enhance OOD performance but to serve as a crucial step in our modeling."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700563186202,
                "cdate": 1700563186202,
                "tmdate": 1700563223472,
                "mdate": 1700563223472,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hAm2T8ZAQE",
                "forum": "dm8e7gsH0d",
                "replyto": "2kARfrCryA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer c5SY,\n\nThis is a kind reminder that we have updated the supplimentary materials (attached at the end of our manuscript). We added an additional section to discuss the specific form of our optimized shaping function as you suggested. Please refer to Section C where new content have been highlighed in red. \n\nWarm regards,\n\nThe Authors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700606395534,
                "cdate": 1700606395534,
                "tmdate": 1700606712265,
                "mdate": 1700606712265,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rMnOiJaG5L",
                "forum": "dm8e7gsH0d",
                "replyto": "nbr74Bf8XG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Reviewer_c5SY"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors"
                    },
                    "comment": {
                        "value": "I think that the previous methodologies in this field favor simple algorithms [R1, R2, R3, R4, ...].\nThe proposed method provides the closed form of reshaping function not using the out-distribution, and it is not complex. I am considering raising the score more.\n\nFor enhanced clarity and persuasion, I suggest the following refinements (optional):\n1. How about providing the guide of section 3 more specifically? For example,\n\n   (1) Start by noting the observation that aligning feature values with negative weights is needed.\n\n   (2) Emphasize the difficulty to decide the reshaping function for each architecture or learning algorithm because the characteristics of feature values depends on architectures or learning algorithms.\n\n   (3) Also, deciding the reshaping function on all continuous values, which of number is infinite, is difficult.\n\n   (4) Propose using piecewise constant over intervals drawing an analogy to visual images are expressed by [0, 255] despite the continuous nature of original colors.\n\n   (5) Propose the optimization of the reshaping function over these intervals. As the number of intervals approaches infinity, the method converges to the reshaping function at each value.\n\n  **Although the authors do not consider the above refinements (because it is optional), I wonder if the flow of the above is right or not.**\n\n2. I believe that this approach can be extended to other tasks beyond the classification because of the closed form of optimization. If the validity of the method is demonstrated across different tasks compared to existing methods, the paper can show the advantage of the proposed approach.\n\n\n[R1] ReAct: Out-of-distribution Detection With Rectified Activations\n\n[R2] Energy-based Out-of-distribution Detection\n\n[R3] Extremely Simple Activation Shaping for Out-of-Distribution Detection\n\n[R4] VRA Variational Rectified Activation for Out-of-distribution Detection"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700716877972,
                "cdate": 1700716877972,
                "tmdate": 1700716877972,
                "mdate": 1700716877972,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jaW6Nnway5",
                "forum": "dm8e7gsH0d",
                "replyto": "2kARfrCryA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> **Improve the guide of Section 3**\n\nThank you for your suggestion to improve the readability of this part. We revise the guide of Section 3. The revised version is as follows:\n\n>> *In this section, we propose a specific instance of the general formulation described in Section 2, following previous element-wise feature-shaping methods (Sun et al., 2021; Xu & Lian, 2023; Kong & Li, 2023). To optimize the shaping function, we initially examine which feature value ranges are effective for OOD detection. However, a significant challenge arises from the continuous nature of feature values. To address this, we partition the domain of features into a disjoint set of intervals, which allows us to approximate the optimal shaping function with a piece-wise constant function. With this approximation, we can formulate an optimization problem to maximize the expected difference between the maximum logit values of ID and OOD data.* \n\n>> *Subsequently, we show that the optimized shaping function using OOD samples bears a striking resemblance to prior methods, such as ReAct (Sun et al., 2021), BFAct (Kong & Li, 2023), and VRA-P (Xu & Lian, 2023). This similarity sheds light on the mechanics of these methods.* \n\n>> *Finally, we propose a formulation that does not require any OOD data to optimize and admits a simple, closed-form solution. Experiments will show its robustness across various datasets and models.*\n\nIn your comment, steps 2-5 are basically correct. We did not add step (1) in the guide. As previously mentioned, this step is actually an ad-hoc observation after we have solved our optimization problem, and is specific to a certain model and dataset.  \n\nA kind reminder that these editorial changes you are asking for are not related to the technical contribution of our paper. We can improve the readability of the paper further as you, other reviewers and AC suggest in camera-ready version if it is accepted.\n\n> **Show the advantage of the proposed method across different tasks beyond classification**\n\nDifferent from these earlier studies [R1-4], we extensively expand the range of model architectures and datasets in our experiments, and conduct a thorough comparative analysis between our proposed method and previous ones. The results have shown the improved generalization ability of our method across a large variety of datasets and model architectures.\n\nPrevious research [R1-4] and our own work, primarily focus on classification, which is a key and fundamental task in CV. Regarding your suggestion to apply these techniques to other tasks such as object detection and semantic segmentation, it indeed presents an intriguing avenue for exploration. Given the limited time remaining in the discussion period (less than 7 hours), we propose to leave this as a potential future research direction.\n\n\n\nAgain, thank you for your taking interest and thinking about how to improve the paper."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722711855,
                "cdate": 1700722711855,
                "tmdate": 1700722775523,
                "mdate": 1700722775523,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "W6feHlbgRk",
            "forum": "dm8e7gsH0d",
            "replyto": "dm8e7gsH0d",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4177/Reviewer_kmFm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4177/Reviewer_kmFm"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a feature-shaping method for general OOD detection without OOD data.\nThis paper uses maximum logit score and energy scores with the manipulated feature to find the OOD data.\nThis method yields a closed-form solution for the piecewise constant shaping function.\nExtensive experiments support the superiority and generalization of this approach."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method is generalizable across different benchmarks does not require OOD data, and is somewhat original.\nMultiple datasets and multiple backbones are evaluated.\n2. This paper is supported by theory as well as experimental validation and is of high quality.\n3. The overall description is relatively clear.\n4. The OOD task is of great significance. It makes sense to research it."
                },
                "weaknesses": {
                    "value": "1. The reviewer didn't see any discussion or analysis about the robustness of the proposed method to thresholding.\nAdding this analysis would make the paper more complete.\n2. The reviewer believes that further explanation is needed as to why $E_{x^{OOD} \\sim D^{OOD}_{\\chi}} [I (Z^{OOD}) ]$ can be ignored.\nThe explanation in Fig. 3 is still not convincing enough."
                },
                "questions": {
                    "value": "1. Is there a more intuitive explanation for this method that would make it more understandable?\n2. Will the code and data be open source?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4177/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4177/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4177/Reviewer_kmFm"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4177/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698725189598,
            "cdate": 1698725189598,
            "tmdate": 1699636383448,
            "mdate": 1699636383448,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yK6dvofAYd",
                "forum": "dm8e7gsH0d",
                "replyto": "W6feHlbgRk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We greatly appreciate your time and effort in reviewing our paper. We are pleased that you acknowledged our work's contribution in addressing a significant task, proposing a generalizable method without OOD data, providing strong theoretical and experimental support, and clear writing.\n\n> **Q1: Is there any discussion or analysis about the robustness of the proposed method to thresholding.**\n\nThere are two thresholds in the paper. One is the threshold for classifying ID and OOD samples based on OOD scores. Note that AUC already reflects performance robustness across all thresholds. The other pertains to setting feature value limits for optimizing our shaping function, as detailed in Section 3.1. Here we discuss the robustness of our method to the latter.\n\nGiven that feature distributions typically exhibit long-tailed characteristics, we select the 0.1 and 99.9 percentiles of all features in a training set as the lower and upper limits of feature values, respectively, to optimize our shaping function. Here we validate different choices of percentiles on the performance of our method, on the ImageNet-1k benchmark with ResNet50. The results are shown as follows:\n\n| Lower percentile | Lower limit | Upper percentile | Upper limit | FPR95     | AUC       |\n| ---------------- | ----------- | ---------------- | ----------- | --------- | --------- |\n| 0.0              | 0.00        | 100.0            | 20.65       | 42.42     | 87.90     |\n| 0.01             | 0.00        | 99.99            | 5.64        | 42.22     | 87.97     |\n| 0.05             | 0.00        | 99.95            | 4.40        | 41.97     | 88.04     |\n| 0.1              | 0.00        | 99.9             | 3.88        | 41.82     | 88.11     |\n| 0.5              | 0.00        | 99.5             | 2.74        | 41.01     | 88.44     |\n| 1.0              | 0.00        | 99.0             | 2.28        | **41.00** | **88.50** |\n| 5.0              | 0.03        | 95.0             | 1.35        | 47.85     | 86.41     |\n| 10.0             | 0.06        | 90.0             | 1.01        | 57.45     | 83.60     |\n\nOur method exhibits a insensitivity to the chooses of lower and upper limits. Although in the main experiments (Tables 1 & 2) we consistently use the 0.1 and 99.9 percentiles, exploring alternate settings reveals potential for slight improvements. \n\nThese experiments will be incorporated into the revised paper if space allows or updated in the Supplementary Material.\n\n> **Q2: Further explanation is needed as to why $E_{\\boldsymbol{x}^{\\text{OOD}}\\sim D_{\\cal X}^{\\text{OOD}}}\\left[{\\boldsymbol{I}(\\boldsymbol{z}^{\\text{OOD}})}\\right]$ can be ignored.** \n\nIn the general setting where we have no prior knowledge about the OOD data encountered during deployment, the distribution of $\\boldsymbol{I}(\\boldsymbol{z}^{\\text{OOD}})$ is unknown, rendering the problem in Eq. 12 intractable. However, if we ignore the unknown term $E_{\\boldsymbol{x}^{\\text{OOD}}\\sim D_{\\cal X}^{\\text{OOD}}}\\left[{\\boldsymbol{I}(\\boldsymbol{z}^{\\text{OOD}})}\\right]$, Eq. 12 can be easily solved in closed form and our method shows improved performance for OOD detection. We have some possible working theories on why we can just ignore it (Fig. 3), which are supported by the experiments (Section 4.2).\n\nOur working explanation is based on the similarities or differences in feature representations between these two types of samples.\n\n1. **In the Case of Hard OOD (High Similarity to ID)**: When OOD samples closely resemble ID samples, their feature representations tend to align. This similarity implies that the expectations we calculate for both OOD and ID samples point in similar directions. \n2. **In the Case of Easy OOD (Divergence from ID)**: Conversely, when OOD samples are markedly different from ID samples, the maximum logits (a measure of model confidence) for these OOD samples are typically lower. This lower confidence translates to a reduced magnitude of the expectation value for OOD samples compared to ID samples. \n\nThus, the aspect of $E_{\\boldsymbol{x}^{\\text{OOD}}\\sim D_{\\cal X}^{\\text{OOD}}}\\left[{\\boldsymbol{I}(\\boldsymbol{z}^{\\text{OOD}})}\\right]$ that is orthogonal to the ID expectation is minimal, and the term can be ignored with a small affect on the optimized results.\n\nIf there are specific concerns or areas that seem unclear, please highlight them and engage with us in the discussion for a more targeted explanation."
                    },
                    "title": {
                        "value": "Official Comment by Authors [1/2]"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699842594333,
                "cdate": 1699842594333,
                "tmdate": 1699842639679,
                "mdate": 1699842639679,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DnvpLdiPGA",
                "forum": "dm8e7gsH0d",
                "replyto": "W6feHlbgRk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4177/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> **Q3: Is there a more intuitive explanation for this method that would make it more understandable?**\n\nThank you for your question. We write a new explanation, trying to make it easy to understand and planning to revise the paper accordingly. If certain aspects or points are not entirely clear or if you have particular concerns, please point them out for a more focused clarification.\n\nFeature-shaping methods for OOD detection aims to reshape feature representations to better differentiate between ID and OOD samples. Existing methods usually employ shaping functions manually designed for specific model architectures and OOD datasets. In this paper, we want to explore \"what feature-shaping function is optimal for OOD detection\", focusing on element-wise feature-shaping functions like ReAct. We model this as an optimization problem - optimize the shaping function to maximize an objective function designed for OOD detection. To make the optimization problem tractable, we do two simplifications. The first is to make the shaping function piecewise constant. The second is to use a optimization objective function without OOD terms based on some working theories. The two simplifications lead to a close form solution and both are validated by experiments. Our method improves the generalization ability of OOD detection across a large variety of datasets and model architectures.\n\n> **Q4: Will the code and data be open source?**\n\nYes. We have included our code as supplementary material alongside this submission. We are also committed to releasing the code on GitHub upon the official acceptance of our paper. Additionally, all the data utilized in our experiments is already open-sourced. To further assist, we will be adding a tutorial in our code repository, detailing the preparation process for the data."
                    },
                    "title": {
                        "value": "Official Comment by Authors [2/2]"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4177/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699842616928,
                "cdate": 1699842616928,
                "tmdate": 1699842652446,
                "mdate": 1699842652446,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]