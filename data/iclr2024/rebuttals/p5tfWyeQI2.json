[
    {
        "title": "Symbolic equation solving via reinforcement learning"
    },
    {
        "review": {
            "id": "HUpq0bjPpB",
            "forum": "p5tfWyeQI2",
            "replyto": "p5tfWyeQI2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1420/Reviewer_QB4J"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1420/Reviewer_QB4J"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new method for solving algebraic equations via reinforcement learning, in a manner akin to a Computer Algebra System.  However, the key contribution of the paper is that the solving strategy is learnt by a reinforcement learning (RL) system. The RL system has access to a set of rules/actions, that can be iteratively composed to solve the linear equation. The authors propose a novel strategy, whereby parts of equations and additional constant coefficients can be stored in a stack, from where they can be called or acted upon with a possible set of actions, to solve the linear equation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed strategy, though simple is quite original\n- The writing is clear\n- The experimental analysis seems sound"
                },
                "weaknesses": {
                    "value": "- The problem is interesting but the restriction to just linear equations is quite severe\n- I am not sure if this is a widely different approach from Computer Algebra System (CAS), as in the end CASs also implement a search strategy in a space of possible actions. This is not completely a criticism, as it could be exciting to extend CASs with RL for efficiency. But I am not sure this paper provides many novel ideas in that direction. I believe the paper can be a stepping stone to a real proof-of-concept for RL applications to CAS, but in its present form it is too limited."
                },
                "questions": {
                    "value": "- Have you looked into expanding the existing open-source CAS (such as Sympy) systems with RL?\n- Why have you not experimented with quadratic equations? does the space of actions significantly explodes in that case?\n- In what case if ever, exponential (^) is used?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1420/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1420/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1420/Reviewer_QB4J"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1420/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698684224849,
            "cdate": 1698684224849,
            "tmdate": 1699636070248,
            "mdate": 1699636070248,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DQF5s8jVtC",
                "forum": "p5tfWyeQI2",
                "replyto": "HUpq0bjPpB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1420/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1420/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the thorough reading of our submission and the valuable feedback.\n\nRegarding the weaknesses they identified:\n\n>  -  The problem is interesting but the restriction to just linear equations is quite severe\n\nA similar remark was made by Reviewer hHWo. We agree that the problem of solving linear equations is relatively simple. Yet we do believe that the addition of symbolic coefficients, in particular, adds some complexity to the problem, and we are working on extensions to other domains. The advantage of linear equations, and one reason why we chose them, is that this is a problem that is well understood by humans and that it is relatively straightforward to follow and analyze the RL agent's solution strategy, which we deemed helpful given that this is the first exploration of our approach/idea. Furthermore, the problem complexity we can handle is ultimately limited by the computing resources available to us.\n\nWe have adjusted the discussion/conclusions to work out more clearly why we think that our results are nontrivial.\n\n>  -  I am not sure if this is a widely different approach from Computer Algebra System (CAS), as in the end CASs also implement a search strategy in a space of possible actions. This is not completely a criticism, as it could be exciting to extend CASs with RL for efficiency. But I am not sure this paper provides many novel ideas in that direction. I believe the paper can be a stepping stone to a real proof-of-concept for RL applications to CAS, but in its present form it is too limited.\n\nWe agree with this interpretation of the RL agent performing a search for solution strategies in the space of equation transformations. In fact, we see it as one of our main contributions that we found a way to make such problems requiring exact mathematical transformations amenable to machine-learning/reinforcement-learning methods. We rephrased parts of the conclusions to highlight this better.\n\nRegarding their questions:\n\n> - Have you looked into expanding the existing open-source CAS (such as Sympy) systems with RL?\n\nYes, we would even argue that our current implementation already is an \"expansion\" of SymPy in some sense. Essentially, we replaced the \"equation solving\" module of SymPy with our RL agent, but the term handling is left to SymPy. This is briefly explained at the end of Sec. 2.3 with details in Appendix A.7. So our approach is already integrated with SymPy and can easily be adapted to replace or extend other SymPy functionality in principle.\n\nWe have added a comment at the end of Sec. 2.3. to highlight this integration with SymPy.\n\n> - Why have you not experimented with quadratic equations? does the space of actions significantly explodes in that case?\n\nWe are currently experimenting with quadratic equations as a natural next step. Quadratic equations come with additional complications like multiple solutions and rational powers (square roots) for inverse operations, which can lead to non-polynomial forms of equations during the RL agent's explorations, for example. We do not include results in this paper because we are still investigating the best strategy and are not satisfied with the success rates yet.\n\n> - In what case if ever, exponential (^) is used?\n\nIn the present context of linear equations, the exponential (^) operation is used/required only to invert products. For example, to solve the equation 2\\*x = 4, the agent will want to multiply both sides by 1/2, and the typical steps to prepare this transformation will be as follows: push the coefficient in front of x (here 2) to the stack, push the constant -1 to the stack, apply ^ on the stack (resulting in 2^(-1) = 1/2 as the top element of the stack), apply \\* on the equation. This is also exemplified in Fig. 2d, see the second-to-last action in particular. Of course, the agent explores other uses of ^ during training, but usually learns quickly that these are not helpful for the problems at hand."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1420/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502522758,
                "cdate": 1700502522758,
                "tmdate": 1700502522758,
                "mdate": 1700502522758,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "S7IMJe7eZ3",
            "forum": "p5tfWyeQI2",
            "replyto": "p5tfWyeQI2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1420/Reviewer_hHWo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1420/Reviewer_hHWo"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce a simple computer algebra system for manipulating elementary algebraic equations. This system comprises a sequence-based representation for the algebraic equations, and a small stack based machine for executing manipulations of these expressions. The authors then train a deep reinforcement learning agent, using double deep Q-learning, to operate this stack machine, with the objective of reducing given algebraic expressions to a canonical (\"solved\") form.\n\nThe authors show that, with an appropriate curriculum, the agent can indeed learn to operate this machine to achieve the goal of solving the equations. Further, they show that by introducing a second RL agent in an adversarial generator-solver arrangement with the first, that they can reduce the need to hand-craft a curriculum - although they do find that it is still useful to craft a simpler curriculum for maximum performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The manuscript is very clearly written. I found it very easy to read and understand what the authors had done. The presentation of the results was direct, easy to understand, and helpful."
                },
                "weaknesses": {
                    "value": "I think there are two main weaknesses with this paper: that it doesn't support its main claim; and that the domain it is applied to is too simple to really get a sense for whether the approach is useful or interesting.\n\nThe paper claims in the introduction that \"humans must implement the discovered rules as computer programs\" in traditional computer algebra systems and that \"this process could benefit greatly from techniques that enable computers to discover and implement transformation rules on their own.\" In the conclusion the authors claim that their work \"can be seen as a first step towards the general goal of creating a machine-learned computer algebra system in which the fundamental laws of mathematical reasoning and deduction are discovered autonomously by an AI.\" I do not think this claim is supported by the work presented. When the authors introduce their representation of the algebraic equations, and the operations of the stack machine, they implicitly encode all of the \"fundamental laws of mathematical reasoning and deduction\" that are necessary for this domain. These are fully sufficient for this domain, and so in that sense also all the \"fundamental laws\" that this system will ever contain. More specifically, their assumptions immediately partition the space of expressions into equivalence classes that encode the notion of semantic equality in this domain. The act of \"solving\" the equations can be thought of as the act of finding a canonical exemplar (or, at least, an exemplar from a canonical subset as the authors' definition of \"solved\" admits multiple solutions). So what the RL algorithm has found is a search algorithm within an equivalence class that finds a canonical example. This is an interesting and useful thing to do, but I would argue that is does not in any sense enable their system to discover any fundamental laws of mathematics - these were all in there right from the start when the authors defined their system. So I don't think the main claim of the paper is supported by the developments presented.\n\nThe second weakness is that the domain in which the authors work is exceedingly simple: that of simple algebraic equalities. Viewed through the lens described above - that what the authors' RL algorithm really does is discover effective search procedures for canonical exemplars in the domain, then I think a valid question is \"how complex would it be to develop such an algorithm another way?\" And the answer is \"essentially trivial\". Many straightforward algorithms exist for doing this search, including the ones routinely taught to schoolchildren and those implemented in standard linear system solvers. So from my perspective showing that an RL agent can discover such an algorithm isn't really a convincing result. It would be interesting if an RL algorithm could find search algorithms that are not known to existing computer algebra systems (or even schoolchildren) but that hasn't been demonstrated in this paper. So my feeling here is that the authors would really have to show that their system can discover non-trivial search algorithms for it to be a notable result."
                },
                "questions": {
                    "value": "The opening analogy is confusing: while there's only one correct solution to the equation in some sense, there are usually multiple structural forms for that solution (x = 2 - c, x = -c + 2), and there are many sequences of manipulations that would lead to those goal states. So it seems like the situation is not that different from chess, in the sense that one is trying to find a sequence of moves to get to a subset of states that have some particular property."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1420/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698780968246,
            "cdate": 1698780968246,
            "tmdate": 1699636070157,
            "mdate": 1699636070157,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fvlIKZQvjv",
                "forum": "p5tfWyeQI2",
                "replyto": "S7IMJe7eZ3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1420/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1420/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the thorough reading of our submission and the valuable feedback.\n\nRegarding the weaknesses they identified:\n\n> The paper claims in the introduction ...  I don't think the main claim of the paper is supported by the developments presented.\n\nWhile we understand the reviewer's point here, we disagree with their interpretation that our RL agent does not discover rules of mathematical reasoning and deduction. The reviewer states that we \"implicity encode all of the 'fundamental laws of mathematical reasoning and deduction' that are necessary for this domain\". We agree with this assessment, but we continue to believe that our RL agent still adds new rules or mathematical insights to this foundation: It learns how to adopt the laws it has been equipped with to carry out a task that it had not known about before. We would argue that this is, in fact, the standard procedure in mathematical research: Starting from some definitions and previously established results, the mathematician combines them in an expedient way to arrive at something that was not obvious at the outset. So in some sense, all mathematical reasoning is just a \"search algorithm\" in the action space of chaining together axioms and previous insights. We see it as one of our main contributions that we found a way to make such a \"theory space\" of exact mathematical transformations amenable to machine-learning/reinforcement-learning methods.\n\nWe have rephrased and expanded the corresponding text passages in the conclusions, acknowledging in particular that the previous wording speaking of \"fundamental laws\" may be perceived as somewhat pretentious.\n\n> The second weakness is ...  the authors would really have to show that their system can discover non-trivial search algorithms for it to be a notable result.\n\nA similar remark was made by Reviewer QB4J. We agree that the problem of solving linear equations is relatively simple. Yet we do believe that the addition of symbolic coefficients, in particular, adds some complexity to the problem, and we are working on extensions to other domains. The advantage of linear equations, and one reason why we chose them, is that this is a problem that is well understood by humans and that it is relatively straightforward to follow and analyze the RL agent's solution strategy, which we deemed helpful given that this is the first exploration of our approach/idea. Furthermore, the problem complexity we can handle is ultimately limited by the computing resources available to us.\n\nThe reviewer mentions schoolchildren, and we think that they are actually a great example to illustrate why learning to solve algebraic equations (a) involves new rules of mathematical reasoning and deduction (\"first weakness\") and (b) may not be so trivial after all (\"second weakness\"). When humans learn how to solve linear equations in middle school, they build on an extensive basic mathematics education from previous years, yet it is undeniable that once they mastered how to deal with equations, they have acquired a new skill. Our RL agent is similar to such a middle-school student, it already knows how to manipulate mathematical terms, but now it discovers (on its own) how to use this knowledge to solve equations. Furthermore, it may be \"essentially trivial\" to develop a solver _if one already knows how to solve equations_. However, we suspect that asking the average middle-school student to devise such a solver _before_ they are taught the canonical strategy would most likely not be very effective ...\n\nWe have adjusted the discussion/conclusions to work out more clearly why we think that our results are nontrivial.\n\nRegarding their questions:\n\n> The opening analogy is confusing: while there's only one correct solution to the equation in some sense, there are usually multiple structural forms for that solution (x = 2 - c, x = -c + 2), and there are many sequences of manipulations that would lead to those goal states. So it seems like the situation is not that different from chess, in the sense that one is trying to find a sequence of moves to get to a subset of states that have some particular property.\n\nWe can see the reviewer's point. The idea of this analogy was that equations have a unique solution up to certain \"symmetry transformations\" (e.g., commutativity of addition in the example). In chess, on the contrary, there are many possible outcomes of a game that are not equivalent by any meaningful symmetry. But we understand that the analogy can be confusing and may not get our idea across, hence we have removed it from the introductory paragraph."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1420/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502367507,
                "cdate": 1700502367507,
                "tmdate": 1700502367507,
                "mdate": 1700502367507,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rfsogz4tQn",
            "forum": "p5tfWyeQI2",
            "replyto": "p5tfWyeQI2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1420/Reviewer_8V3F"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1420/Reviewer_8V3F"
            ],
            "content": {
                "summary": {
                    "value": "The authors present a reinforcement learning approach for solving linear equations and evaluate it on a set of problems."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- the problem domain is interesting, there is not much work on using RL to solve symbolic equations\n- The paper in generall is easy to understand\n- The related work appears to be covered"
                },
                "weaknesses": {
                    "value": "There is no clear motivation why the proposed approach is a good idea.  \nThe authors state that:\n\" Evidently, this process could benefit greatly from techniques that enable computers to\ndiscover and implement transformation rules on their own. Moreover, finding viable approaches\nto do so will eventually help to make machine-learning models more adept at mathematics and\nproblems requiring exact solutions in general.\"\n\nBut why is it a disadvantage that current automatic equation solvers integrate human expert knowledge? What is the pain point of the current solutions that exist? \n\n2. There are no comparisons done in this paper. This is striking both on the small as as well as the large scale.\n\n2.1 how much faster/slower and more/less accurate does the proposed method work compared to established methods from Mathematica, Maple, Matlab, or SymPy?\n\n2.2  What are the impacts of the hyper-parameters on the performance of the solution? E.g. how relevant is the discount factor, the complexity of the network? While I understand that deep RL approahces have a lot of hyper-parameters it is still relevant to identify the most sensitive ones  and do some form of inspection and analysis regarding the robustness of the approach.\n\n2.3  What are the impacts of the RL approach (double Q learning) on the solutions? How well would  for instance PPO methods compare?\n\n2.4 Compared to related work, is there no related method you could compare to?"
                },
                "questions": {
                    "value": "After training, what is the sucess rate compared to established solvers?\nWhat is the wall-clock time in inference compared to established solvers?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1420/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698949337709,
            "cdate": 1698949337709,
            "tmdate": 1699636070073,
            "mdate": 1699636070073,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Xpwqd1BGvC",
                "forum": "p5tfWyeQI2",
                "replyto": "rfsogz4tQn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1420/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1420/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the thorough reading of our submission and the valuable feedback.\n\nAs a general remark, we would like to emphasize that the goal of our study was not to come up with an RL framework that outperforms established computer algebra systems (CAS) like Mathematica, Maple, Matlab, or Sympy. If this were the case, the domain of linear equations would be too simplistic as all those existing CAS will solve such equations with perfect success rates and almost instantly for all practical purposes. Instead, our goal was to devise a viable strategy that enables an RL agent to discover transformation rules typical for CAS operation on its own, without human intervention. Admittedly, our present result does not give a practical advantage for solving linear equations. Nevertheless, it showcases a way towards building machine-learning models for exact mathematics, a domain that has proved to be exceptionally hard to master. In the long run, we hope that such a strategy can be used to aid mathematical research and discover relations that have not been known to humans before.\n\nRegarding the weaknesses the reviewer identified:\n\n> There is no clear motivation why the proposed approach is a good idea. (...) But why is it a disadvantage that current automatic equation solvers integrate human expert knowledge? What is the pain point of the current solutions that exist?\n\nThe pain point, in our opinion, is that humans are relatively slow at discovering and implementing mathematical relations and rules. Current CAS build on thousands of years of mathematical research and the major ones have been under development for over 30 years to \"teach\" computers what humans know. Of course, we are well aware that, presently, our approach cannot compete with these established software packages and does not discover anything unknown to humans. However, we still believe that it is a first step towards automated ways of mathematical research and that such an autonomous \"RL researcher\" could greatly enhance the power of CAS as well as the human mathematical knowledge base. We emphasize that it will still build on established human insights (like our present approach does, too), but it should be capable of exploring new domains that it had not been explicitly taught about in an independent, autonomous way.\n\nWe have adjusted the introduction to explain more clearly in what sense we aim to enable computers to discover and implement transformation rules on their own.\n\n> 2.1 how much faster/slower and more/less accurate does the proposed method work compared to established methods from Mathematica, Maple, Matlab, or SymPy?\n\nWe did not carry out such a comparison because this is not the aim of our study as outlined above. All of the established CAS will achieve success rates of essentially 100 % for the problem of linear equation solving. They will most probably run faster than our method, too, which has not been optimized for speed yet. It will not matter for the human user who is interested in solving a particular equation because they won't experience a noticeable delay, but it might become relevant if one wishes to solve a batch of several hundreds of equations at a time.\n\n> 2.2 What are the impacts of the hyper-parameters on the performance of the solution? E.g. how relevant is the discount factor, the complexity of the network? While I understand that deep RL approahces have a lot of hyper-parameters it is still relevant to identify the most sensitive ones and do some form of inspection and analysis regarding the robustness of the approach.\n\nA qualitative overview of the influence of the various hyperparameters can be found in Appendix A.8. As explained there, we did not carry out a systematic grid search due to the large number of hyperparameters, but we explored several different variations for each type of problem. In the revised manuscript, we have added Tables 5-16, which list the success rates for hyperparameter variations of each of the models from Figs. 2-4 to provide a quantitative account of the hyperparameter influences.\n\n(continuing below)"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1420/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700502142083,
                "cdate": 1700502142083,
                "tmdate": 1700502142083,
                "mdate": 1700502142083,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]