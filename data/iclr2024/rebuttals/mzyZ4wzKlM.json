[
    {
        "title": "Expressive Losses for Verified Robustness via Convex Combinations"
    },
    {
        "review": {
            "id": "jaAguLQsSL",
            "forum": "mzyZ4wzKlM",
            "replyto": "mzyZ4wzKlM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a scheme for convexly combining verified and adversarial loss functions to train verifiably robust models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The paper is generally well written and presented.\n\n2. The contribution is generally clear.\n\n3. The idea of expressive loss functions as interpolating between verified and adversarial losses is interesting."
                },
                "weaknesses": {
                    "value": "1. My main concern is that the paper is not sufficiently novel to merit publication. Convexly combining loss functions is a rather obvious idea; indeed (8) is just a linear combination of two loss functions, something which has been around for ages."
                },
                "questions": {
                    "value": "1. In table 3, the alpha parameter for the MTL-IBP method can get very low (e.g., $4 \\cdot 10^{-3}$ for CIFAR-10 $2/255$). Does this not mean that the loss essentially just reduces to the adversarial loss?\n\n2. Why do the optimal $alpha$'s vary so much between the $2/255$ and $8/255$ epsilons for CIFAR-10? As in Q1, the MTL-IBP loss boils down to just the adversarial loss for $2/255$, and changes to a $50/50$ split for $8/255$."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8030/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8030/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8030/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697675526151,
            "cdate": 1697675526151,
            "tmdate": 1700673116627,
            "mdate": 1700673116627,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7bP7vx4NG4",
                "forum": "mzyZ4wzKlM",
                "replyto": "jaAguLQsSL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8030/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8030/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer eo5p"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their time and feedback. We are glad that the reviewer found the paper to be well written and presented, and idea of expressive losses to be interesting. \n\n> My main concern is that the paper is not sufficiently novel to merit publication. Convexly combining loss functions is a rather obvious idea; indeed (8) is just a linear combination of two loss functions, something which has been around for ages.\n\nWe are happy that the reviewer pointed out that convexly combining loss functions is a rather obvious idea that has been around for ages: we absolutely agree! \nIndeed, *one of the main contributions of our work is precisely to show that ideas that are as simple as they are old yield state-of-the-art performance when employed, for the first-time, to meet our novel definition of expressivity (Definition 3.1).* We believe that these results provide strong support for the centrality of the notion of expressivity for verified training, the core message of our submission, as well as a novel understanding of the recent literature.\nIn other words, our aim is to show that the performance of recent successes in the literature can be matched by simple techniques, and explained through a very simple definition. We believe this to be at least as valuable for the community as introducing a novel and complex algorithm that outperforms the baselines on selected benchmarks. \n\n> In table 3, the alpha parameter for the MTL-IBP method can get very low  (e.g., $4 \\cdot 10^{-3}$ for CIFAR-10 $2/255$). Does this not mean that the loss essentially just reduces to the adversarial loss?\n\nWe thank the reviewer for the question. As visible in Figures 4a and 4b in appendix F.4, the adversarial and CC/MTL-IBP losses are fairly different even when $\\alpha=10^{-3}$. Specifically (we report the raw numbers here for convenience), for the CC-IBP-trained network, $L_{adv}=0.7658$ and $L_{CC-IBP}=1.234$. For the one trained via MTL-IBP: $L_{adv}=0.777$ and $L_{MTL-IBP}=1.192$. This is due to the extremely large values that the IBP loss takes on under these low over-approximation coefficients: $L_{IBP}=272.159$ and $L_{IBP}=65.392$ for the networks trained via CC-IBP and MTL-IBP, respectively.\nAs a result, even when $\\alpha = 4 \\cdot 10^{-3}$, the MTL-IBP loss still features a significant IBP component.\n\n> Why do the optimal alpha's vary so much between the $2/255$ and $8/255$ epsilons for CIFAR-10?\n\nWe thank the reviewer for the interesting question. The difference between the type of loss that works the best on smaller perturbations and on larger perturbations on CIFAR-10 is a well-known phenomenon in the literature. Methods that have a strong adversarial training component (IBP-R, COLT) tend to perform particularly well on the $2/255$ setting, and quite poorly when $\\epsilon=8/255$, where methods exclusively based on over-approximations typically outperform them (IBP, CROWN-IBP). \nIntuitively, larger perturbations will yield significantly larger bounds, requiring larger over-approximation coefficients $\\alpha$ to effectively regularize them at the cost of a drop in standard accuracy.\n\n\nWe sincerely hope the reviewer can reevaluate our contribution in light of the above responses, and remain available for further discussions and/or clarifications."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8030/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500403865,
                "cdate": 1700500403865,
                "tmdate": 1700500491788,
                "mdate": 1700500491788,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1EKvAvWkkK",
                "forum": "mzyZ4wzKlM",
                "replyto": "7bP7vx4NG4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors for their thorough clarifications and I apologize for the lack of detail in my original review. Having carefully read the other reviews, I will elaborate on my main concern with the paper.\n\nThe authors define a notion of loss family expressiveness, which they claim is \"key\" for effective verified training (also noting that the SABR loss is expressive). To support their claim, the authors present two specific expressive loss families and demonstrate that these losses yield strong verified accuracy after searching over $\\alpha$.\n\nTo assess the experimental support provided in the paper, we must first understand rigorously what the authors mean by saying that expressive loss families are \"key.\" Does this mean that expressive loss families are _necessary_ for good verification, _sufficient_ for good verification, or both? I don't think this paper provides good support for either necessariness or sufficiency.\n\n__Why I'm not convinced of necessariness of expressive loss families:__\n\n1. While the convex combination loss functions presented by the authors achieve good performance, so do other loss functions in the experiments which don't match the expressive family structure (e.g., the alpha beta crown loss).\n\n2. The paper simply provides no evidence as to why expressive loss families are needed. Providing examples of expressive loss functions that work well is not the same as showing that the expressive loss family structure is necessary. The kind of evidence that I would find convincing might look something like the following (completely hypothetical). Say you had a simple synthetic dataset which is parameterized by some $\\alpha \\in [0,1]$. This parameterization might be constructed such that for $\\alpha=0$, the optimal classifier minimizes the adversarial loss, while for $\\alpha=1$, the optimal classifier minimizes the verified loss. And for intermediate $\\alpha$'s, the optimal classifier minimizes the corresponding interpolated loss from the expressive family. While this exact construction might not be possible, this is the flavor of evidence that would convince me that considering the entire expressive loss family $\\alpha \\in [0,1]$ is important.\n\n__Why I'm not convinced of the sufficiency of expressive loss families:__\n\n1. To show sufficiency, I would need to see an explanation as to why nothing outside the expressive loss family structure would be beneficial. For example, we could also consider interpolating three different losses: the clean loss, the adversarial loss, and the verified loss. This structure would subsume expressive loss functions as a special case. You could of course debunk this particular construction experimentally by showing that interpolating three losses doesn't provide a benefit over interpolating just the adversarial and verified losses. But this doesn't disprove the possibility that there is some other loss family which is better suited than the presented expressive loss family.\n\n2. Even if two specific expressive loss families work well, there could still be some other expressive loss family which performs poorly. A pessimistic reader could think that CC-IBP and MTL-IBP are just cherry picked examples of expressive loss families which support the conclusion of the paper. The paper doesn't convincingly argue that expressive loss families _must_ lead to good verification performance.\n\n__Summary__\n\nIn my judgement, the paper doesn't provide convincing evidence that expressive loss families are either necessary or sufficient. Thus a pessimistic take on the paper might summarize it as \"they cook up two new losses which work decently and coincidentally share this particular structure.\" I don't see enough in this paper to rebut this perspective. Please feel free to clarify if I am misunderstanding something."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8030/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700543330962,
                "cdate": 1700543330962,
                "tmdate": 1700543330962,
                "mdate": 1700543330962,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "N0IHEJ9MIl",
                "forum": "mzyZ4wzKlM",
                "replyto": "jaAguLQsSL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors for their thorough rebuttal. I'm not completely convinced, but I will raise my score to a five for now.\n\n\"Nevertheless, we would be happy to test any expressive loss for which the reviewer believes a worse performance should be expected.\"\n\nIf the authors can present an additional, qualitatively distinct example of an expressive loss family which achieves good performance I think that would strengthen the paper considerably and I would find that convincing. I can't immediately think of more ways to interpolate the adversarial and verified loss.\n\nSince the deadline is tomorrow, just testing on one dataset would be acceptable (say, CIFAR10 8/255)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8030/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700594303286,
                "cdate": 1700594303286,
                "tmdate": 1700594385259,
                "mdate": 1700594385259,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sKctAtDQY3",
                "forum": "mzyZ4wzKlM",
                "replyto": "RB7fAf6UX9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8030/Reviewer_eo5p"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the authors for their timely additional experiments. I think this work would be a good contribution to ICLR and am recommending acceptance. I would suggest that the authors include Exp-IBP in the final paper (even if it\u2019s just in the appendix). It helps demonstrate the diversity of expressive loss families and strengthens the experimental claims of the paper."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8030/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700673094748,
                "cdate": 1700673094748,
                "tmdate": 1700673094748,
                "mdate": 1700673094748,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ojHbO9Ut6K",
            "forum": "mzyZ4wzKlM",
            "replyto": "mzyZ4wzKlM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8030/Reviewer_oQBq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8030/Reviewer_oQBq"
            ],
            "content": {
                "summary": {
                    "value": "The authors hypothesize that expressive loss functions yield better training for verified robustness. A family of loss functions $\\mathcal{L}_\\alpha$ is expressive if\n- $\\mathcal{L}(f(\\theta, x_\\text{adv}), y) \\leq \\mathcal{L}_\\alpha(\\theta, x, y) \\leq \\mathcal{L}_v (f(\\theta,x),y)$ for all $\\alpha \\in [0,1]$, where the left/right inequality become an equality if $\\alpha = 0/1$ respectively. \n- $\\mathcal{L}_\\alpha$ is monotonically increasing with $\\alpha$\n\nThey support their hypothesis that expressive loss functions yield better training for verified robustness by showing that trivial expressive losses obtained via convex combinations between adversarial attacks and IBP bounds yield sota results. They further hypothesize that the notion of expressivity is crucial to get sota and argue as follows:\n- They state that sota verified training algorithms rely on coupling adversarial attacks with over-approximations. They show that SABR is expressive - hence the good performance of SABR is inline with their explanation.\n- Other expressive losses can be trivially designed via convex combinations, i.e.\n\t1. CC-IBP: combine adversarial and over-approximated network outputs with in the loss\n\t2. MTL-IBP: combine adversarial and verified losses\n- Experimental evaluation of CC-IBP and MTL-IBP. Both attain sota, particularly on TinyImageNet and downscaled ImageNet. \nFurther, they analyze the parameter $\\alpha$ governing a robustness-accuracy trade-off. Better approximations of the worst case loss do not necessarily correspond to performance improvements. \n\nThe authors experimentally compare CC-IBP and MTL-IBP to prior work and find that the proposed methods match or outperform the literature. They also study the effect of the over-approximation coefficient on the performance profiles of expressive losses. The take away here is that better approximations of the branch-and-bound loss do not necessarily result in better performance. \n\nObserved that standard accuracy decreases with alpha and verified accuracy increases with alpha. The adversarial and verified robust accuracies unter tighter verifiers may first increase and then decrease with $\\alpha$, hence the need for careful tuning according to the desired robustness-accuracy trade-off. \n\nFinally, the assumption that better approximations of the worst-case loss results in better trade-offs between verified robustness and accuracy is investigated. The parameter $\\alpha$ is chosen based on the performance on a hold out set consisting of 20% of the training set. The worst case loss is approximated using a branch-and-bound loss. The authors report that sometimes it is better for the BaB error to be positive and sometimes for the BaB error to be negative."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The presentation is mostly good.\n- Training certifiable networks is a relevant research problem. \n- The ideas are conceptually simple yet seem to be effective. \n- The work unifies and generalizes successfull approaches. \n- The authors provided code."
                },
                "weaknesses": {
                    "value": "- It remains unclear how stable the results are (for example w.r.t. different seeds). \n- Writing could be improved in some parts of the paper, i.e. Section 6.3. \n- It remains unclear what \"tricks\" i.e. for regularization and initialization where specifically used."
                },
                "questions": {
                    "value": "- What are the confidence intervals for the results in the paper with respect to different seeds? Are the trends consistent w.r.t. the randomness due to different seeds? \n- What specialized initialization and regularization techniques where used?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8030/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698766543556,
            "cdate": 1698766543556,
            "tmdate": 1699636990843,
            "mdate": 1699636990843,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ySTpFpzkMz",
                "forum": "mzyZ4wzKlM",
                "replyto": "ojHbO9Ut6K",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8030/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8030/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer oQBq"
                    },
                    "comment": {
                        "value": "We thank reviewer oQBq for their comprehensive review, summary, and positive evaluation of the contributions we presented. We are particularly happy that the reviewer recognized that our submission \"unifies and generalizes\" previous work, and that the ideas we present are effective despite being \"conceptually simple\". We indeed believe these to be amongst the most important contributions in our work.\n\n> unclear how stable the results are (for example w.r.t. different seeds) [...] Are the trends consistent w.r.t. the randomness due to different seeds?\n\nWe provide an indication of experimental variability in Table 7 in appendix F.5, which reports results under four total runs on CIFAR-10 under perturbations of radius $\\epsilon=8/255$. Both MTL-IBP and CC-IBP display relatively small experimental variability in the experiment.\n\n> It remains unclear what \"tricks\" i.e. for regularization and initialization where specifically used. [...] What specialized initialization and regularization techniques where used?\n\nSimilarly to relevant previous work (SABR, (S)TAPS), we employ the initialization and regularization techniques introduced by (Shi et al., 2021), in addition to $\\ell_1$ regularization.\nMore specifically, (Shi et al. 2021) propose to initialize weights with a low-variance Gaussian distribution to prevent the \"explosion\" of IBP bounds across layers at initialisation. Furthermore, during the warm-up and ramp-up phases of training (see appendix E.2, \"Training Schedule\"), (Shi et al. 2021) add two regularization terms to the objective: one that penalizes (similarly to the initialization) bounds explosion at training time, the other that balances the impact of active and inactive ReLU neurons in each layer.\nWe will be happy to include this discussion and further explanations in the next revision of the paper, and thank the reviewer for their question."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8030/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500374731,
                "cdate": 1700500374731,
                "tmdate": 1700500374731,
                "mdate": 1700500374731,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TF3IVLwKNO",
            "forum": "mzyZ4wzKlM",
            "replyto": "mzyZ4wzKlM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8030/Reviewer_2HZC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8030/Reviewer_2HZC"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes \"expressive\" loss functions that interpolate between IBP and adversarial loss in a simple linear combinations and show good empirical performance on a variety of datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The empirical results seem strong, especially considering the fact that the proposed methods are simple interpolations."
                },
                "weaknesses": {
                    "value": "The presentation and writing needs a lot of work and it seems the paper is hurriedly written. Specific concerns are below.\n\n\n\uf06e\tThe mathematical definition of property P in Eq 1 is given in section 2 without any discussion of what it means or entails and why is it interesting/useful. \n\n\uf06e\tYou could add atleast one example of how x_adv could possibly be generated in the background section.\n\n\uf06e\tExplicitly write down what \u201cverification\u201d means before using it in section 2.1. I don\u2019t know what the following statement means: \u201cHowever, formal verification methods fail to formally prove their robustness in a feasible time\u201d \n\n\uf06e\t \u201cAs seen from Eq 1, network is provably robust if \u2026logit differences \u2026 all positive\u201d \u2013 why and how before even defining what verification is.\n\n\uf06e\t\u201cIncomplete verifiers will only prove a subset of the properties\u201d \u2013 which properties ? only one is defined. \n\n\uf06e\tThe unlaballed equation with relationship of \\underline{z} and z. I would not write \\underline{z} as an inequation when saying it a lower bound without defining it first say using an example.  \n\n\uf06e\tCan you give an example when o and l are not equal ? the definition of z requires o to be atleast as big as l, and the definition of z also makes sense only if o and l are equal. Is o the size of the output before softmax evaluation or after? I am having a hard time reconciling dimensions of f( ) and z( ) for translation-invariance.\n\n\uf06e\tAre the other methods also grid-searched for best hyperparameters  for their respective methods ?\n\n\uf06e\tThe runtimes are a bit misleading? Does the runtime also include hyperameter search cost including the cost for best interpolating parameter ?"
                },
                "questions": {
                    "value": "Please see the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8030/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699332822314,
            "cdate": 1699332822314,
            "tmdate": 1699636990729,
            "mdate": 1699636990729,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5U5RvXWphR",
                "forum": "mzyZ4wzKlM",
                "replyto": "TF3IVLwKNO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8030/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8030/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 2HZC"
                    },
                    "comment": {
                        "value": "We thank reviewer 2HZC for their detailed feedback on the manuscript, which will improve the clarity of the writing. We will make sure that the next revisions will clarify the raised concerns about the presentation, which we address individually below. \nWe are glad that the reviewer found our empirical results to be strong particularly given the simplicity of the losses we employ. Indeed, we believe that our results point to the centrality of expressivity to state-of-the-art training, providing a new understanding of the recent literature.\n\n> The mathematical definition of property P in Eq 1 [...]\n\nEquation (1) provides a standard definition of adversarial robustness: no point in a neighborhood of the inputs should be misclassified. This is expressed by saying that all the differences to the ground truth should be positive.\nThe use of argmin instead of min was a typo, and we thank the reviewer for indirectly pointing us to this.\n\n> add atleast one example of how $x_{adv}$ could possibly be generated in the background section.\n\nWe will provide an example in the appendix in the next revision. As we describe in section 2.1, $x_{adv}$ is obtained by running an adversarial attack, the most common example being PGD by Madry et al. (2018). In short, for $\\ell_\\infty$ perturbations, PGD proceeds by taking steps in the direction of the sign of the gradient of the network with respect to the input point, clipping to the allowed input perturbation set after every iteration.\n\n> Explicitly write down what \u201cverification\u201d means before using it in section 2.1. I don\u2019t know what the following statement means: \u201cHowever, formal verification methods fail to formally prove their robustness in a feasible time\u201d\n\nThe fact that a network is robust to a specific adversarial attack does not imply that it will be robust to stronger/unseen attacks. Verification methods provide guarantees that no attack will ever succeed and, in the worst-case, incur an exponential runtime (in the number of neurons), which is in practice infeasible for even medium-sized networks. Verified training algorithms allow to verify larger networks in reasonable time, leading to larger verified robust accuracies.\n\n> \u201cAs seen from Eq 1, network is provably robust if \u2026logit differences \u2026 all positive\u201d why and how before even defining what verification is.\n\nThe sentence in question does not depend on the notion of formal verification. If one can show that, for $\\forall x_0 \\in \\mathcal{C}(x, \\epsilon)$, all logit differences with incorrect classes are positive, then no adversarial example (misclassified point in $\\mathcal{C}(x, \\epsilon)$) can exist.\n\n> \u201cIncomplete verifiers will only prove a subset of the properties\u201d \u2013 which properties ? only one is defined.\n\nEach robustness property $P(f(\\theta, x), y)$ is a function of the point $x$ and its label $y$. As a result, a given dataset will have as many robustness properties as the number of input/label pairs. We will clarify this in the text in the next revision. Given that, as outlined in section 2.2.1, incomplete verifiers produce lower bounds on (4), a positive bound implies that the solution to (4) is positive too, providing a solution to the verification problem. A negative lower bound, instead, leaves the property at hand undecided.\n\n> Can you give an example when o and l are not equal ? [...]  Is o the size of the output before softmax evaluation or after?\n\nFor multi-class classification, the label is a scalar ($l=1$), as explained before equation (1), and the output dimension of the network ($o$) is equal to the number of classes. As $z$ is the difference between a broadcast scalar (the entry of the network output corresponding to the ground truth) and the vector output of the network, $z$ and $f$ have the same dimensions.\n\n> Are the other methods also grid-searched\n\nAs common in related work (see for instance SABR, (S)TAPS) the baseline results in Table 1 are taken directly from the literature, and refer to the best results ever reported for any given method in previous work (for instance, across any network architecture). In other words, each baseline was tuned by the authors of the works referenced in the \"Source\" entry of Table 1.\n\n>  The runtimes are a bit misleading? Does the runtime also include hyperameter search cost including the cost for best interpolating parameter ?\n\nRuntimes for any algorithm (either ours or a baseline) only refer to a single training run. We would like to point out that the baselines with the best average performance across benchmarks (SABR, (S)TAPS) all feature at least as many hyper-parameters as CC-IBP and MTL-IBP. \n\nWe hope to have provided more clarity on the reviewer's concerns, and would be happy to provide further clarifications as needed."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8030/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500346204,
                "cdate": 1700500346204,
                "tmdate": 1700503885593,
                "mdate": 1700503885593,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6W6sBaVb5J",
            "forum": "mzyZ4wzKlM",
            "replyto": "mzyZ4wzKlM",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8030/Reviewer_tVkU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8030/Reviewer_tVkU"
            ],
            "content": {
                "summary": {
                    "value": "This work studies the certified training with over-approximation for robustness certification. Specifically, the authors introduce the idea of expressivity of loss functions and show that it can range from worst-case loss to verified loss, based on which two forms of loss are proposed. The experiments show the performance of the new losses and some findings regarding robustness and accuracy are given."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The motivation of the paper is sound, and the underlying theory regarding certified training remains unknown and challenging.\n- The paper is generally well-organized and easy to follow.\n- The experiments are comprehensive and different datasets and attack radii are used for the evaluation."
                },
                "weaknesses": {
                    "value": "- My biggest concern is that the contribution and novelty of the paper are incremental and minor, which is about the expressivity of losses. However, it seems that it somehow borrows the idea of the previous work SABR, which gives an effective loss ranging from adversarial loss and verified loss.  The difference between this work and SABR is not that clear and significant as SABR can induce expressivity by letting $\\lambda=\\alpha$ as shown in Sec. 3.\n- Some key details are not given in the main text. E.g., it is not clear from the main text how the logit differences are associated with an adversarial attack for CC-IBP when it is compared to CROWN-IBP in Sec. 4.1, without which the contribution and novelty are further weakened in terms of the comparison.\n- The insight and intuition of the relationship between CC-IBP and MTL-IBP are not clear. For example, does any case exist where one can be degraded to the other? If so, either theoretical or empirical results are needed to show it.\n- For Table 1, the proposed method is with BaB as a complete method, I wonder if it is fair to compare with some incomplete baselines."
                },
                "questions": {
                    "value": "See the Weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8030/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8030/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8030/Reviewer_tVkU"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8030/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699592608083,
            "cdate": 1699592608083,
            "tmdate": 1699636990628,
            "mdate": 1699636990628,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LQ4PqMUsg0",
                "forum": "mzyZ4wzKlM",
                "replyto": "6W6sBaVb5J",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8030/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8030/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer tVkU"
                    },
                    "comment": {
                        "value": "We thank reviewer tVkU for their time, questions and comments. \nBefore addressing them individually, we would like to highlight that, as explained in the general response, the main goal and contribution of our work is the idea that *expressivity is all you need for state-of-the-art verified training*. We show that extremely simple expressive losses (CC-IBP and MTL-IBP), obtained by casting, for the first time, standard techniques (convex combinations) under the lens of our novel definition, already yield state-of-the-art performance.\nWe are glad that the reviewer found the paper to be well-organized and with a comprehensive evaluation, which we believe should be seen in support of the above point.\n\n> the contribution and novelty of the paper are incremental and minor, which is about the expressivity of losses. However, it seems that it somehow borrows the idea of the previous work SABR [...]\n\nAs highlighted by reviewer oQBq, our aim is to unify and generalize previous approaches, providing a novel understanding of the state-of-the-art. Therefore, the fact that SABR satisfies our definition of expressivity (as we show in section 3) is intentional, and exactly part of what we aim to show: expressivity is the key to recent advances in the certified training literature.\n\n> it is not clear from the main text how the logit differences are associated with an adversarial attack for CC-IBP when it is compared to CROWN-IBP in Sec. 4.1, without which the contribution and novelty are further weakened in terms of the comparison.\n\nBy \"logit differences associated with an adversarial attack\", we mean the vector of differences between the ground truth logit ($y$ denotes the ground truth class) and the other logits: $z(\\theta, x_{\\text{adv}}, y) := f(\\theta, x_{\\text{adv}})[y] - f(\\theta,x_{\\text{adv}})$ (see definition in section 2, and the definition of the CC-IBP loss in equation (7)). As described in section 2.1, $x_{\\text{adv}}$ is obtained by running an adversarial attack on the network. In our experiments, as described in the second paragraph of section 6, $x_{\\text{adv}}$ is output by a single-step attack (random-initialized FGSM) in all settings except for CIFAR-10 when $\\epsilon=2/255$. As detailed in section 4.1, also CROWN-IBP carries out convex combinations within the loss, but does so between CROWN-IBP and IBP bounds, and gradually transitions to pure IBP. We refer to section 4.1 for a detailed analysis of the differences between CROWN-IBP and CC-IBP. \n\n> The insight and intuition of the relationship between CC-IBP and MTL-IBP are not clear. For example, does any case exist where one can be degraded to the other?\n\nAs shown in proposition 4.2 and described in the relative section, the CC-IBP loss is a lower bound to the MTL-IBP loss. The two losses trivially coincide for $\\alpha=0$ and $\\alpha=1$, as they both satisfy definition 3.1. The insight we want to convey by presenting two different losses (and also taking into account the SABR results, see Figure 3 and Table 6), is that *expressivity, rather than the specific form of the loss function, leads to state-of-the-art performance*.\n\n> For Table 1, the proposed method is with BaB as a complete method, I wonder if it is fair to compare with some incomplete baselines.\n\nNote that (S)TAPS, SABR, IBP-R and COLT from Table 1 report results under complete verifiers, and report similar comparisons.\nGenerally speaking, methods trained exclusively using incomplete verifiers (for instance, IBP, CROWN-IBP) display only very minimal improvements in verified accuracy when moving from incomplete verifiers to complete verifiers at evaluation time. \nEvidence for this can be found in Figure 2, which shows results for IBP training when $\\alpha=1$. Importantly, they also produce much lower standard accuracies as shown in Table 1. \nIn addition, Table 4 in appendix F.1 shows the verified accuracies of our models under incomplete verifiers. On larger datasets (TinyImagenet, Imagenet64), both MTL-IBP and CC-IBP already attain significant verified accuracies under CROWN-IBP bounds (hence without resorting to complete verifiers)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8030/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700500266453,
                "cdate": 1700500266453,
                "tmdate": 1700500266453,
                "mdate": 1700500266453,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]