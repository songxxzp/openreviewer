[
    {
        "title": "Self, Semi and Fully Supervised Training for Autoencoders using Ternary Classification"
    },
    {
        "review": {
            "id": "7W6gGzAqF5",
            "forum": "tRRNjNdqu2",
            "replyto": "tRRNjNdqu2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5584/Reviewer_GBH8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5584/Reviewer_GBH8"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies a third label (UNKNOWN) that enables the autoencoders to learn the structure of healthy and faculty data from the correspondingly labeled data points."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "NA."
                },
                "weaknesses": {
                    "value": "1. The technical novelty is very limited. And the proposed method does not make sense to me. It is hard to read the paper. \n2. I did not get the whole point of the motivation and practical meaning of the paper. Perhaps it needs a better presentation. \n3. They only evaluated on one dataset, which is not convincing enough. Also it is hard to interpret the table. \n4. Figure 4 should be of higher resolution."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5584/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698536503843,
            "cdate": 1698536503843,
            "tmdate": 1699636575251,
            "mdate": 1699636575251,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ltJoJ3gzjQ",
                "forum": "tRRNjNdqu2",
                "replyto": "7W6gGzAqF5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5584/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5584/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe thank you for the time and effort you allocated to check our submission. We also thank you for pointing out how we may improve our work. We will take into account your comments while we will improve the presentation of our results to better show them on a more application-oriented dissemination channel, which should be more appropriate for our work.\n\nThe paper was written by practitioners in anomaly detection and it may be better targeted towards other similar professionals. Unfortunately the limited number of pages prevented us from clearly presenting the whole context to people of different professional backgrounds.\n\nWe agree that more thorough testing on other datasets is required to cross-validate our results and we thank you for your suggestion. We shall also take care to update the resolution of the problematic figure.\n\nWe have decided that it is better to withdraw our paper, as it is not appropriate for ICLR."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5584/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699966496999,
                "cdate": 1699966496999,
                "tmdate": 1699966752015,
                "mdate": 1699966752015,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7qlkQyBBVm",
            "forum": "tRRNjNdqu2",
            "replyto": "tRRNjNdqu2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5584/Reviewer_EDWo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5584/Reviewer_EDWo"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose labeled-aware loss functions for autoencoders.\nBased on 4 baseline loss functions, MSE, RMSE, L2-norm and\nSquared-L2-norm, they introduce additional parameters depending on the\nlabels (healthy, faulty, and unknown).  One approach is to include the\nparameter as an exponent (exponent-based), another is to multiple by\nthe parameter (weight-based).  To prevent negative loss values, they\nuse a soft limit by reducing the absolute values.\n\nUsing a dataset that contains parts that are healthy, faulty, and\nunknown condition, they set up different scenarios for supervised,\nsemi-supervised, and unsupervised learning.  Label-aware loss\nfunctions seem to perform better."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The proposed idea is relatively straight forward.  A real-world dataset\nfrom automobile parts is used."
                },
                "weaknesses": {
                    "value": "The 4 proposed baseline loss functions seem to be very similar in\nterms of minimization.  Particularly, MSE and Squared-L2 norm differ\nby a constant factor, which can be absorbed by the learning rate.\nAutoencoders can be used for learning features without labels.\nHowever, the authors propose modifying the autoencoder loss functions\nwith labels, which makes learning the autoencoder supervised.  Then a\ncomparison with regular supervised learning without an autoencoder\nwould be important.\n\nDetails are in questions below."
                },
                "questions": {
                    "value": "1.  Table 1: Squared-L2 norm: the square and square root can be\ncancelled out.  Squared-L2 norm / n is equivalent to MSE, so the two\nloss functions differ by a constant (n is the same in both loss\nfunctions).  That is, when Squared-L2 norm is minimized, MSE is\nminimized.  When MSE is minimized, RMSE is also minimized.  Similarly,\nwhen Squared-L2 norm is mininized, L2-norm is minimized.  Hence, the\nfour loss functions seem to be equivalent in terms of minimization.\nAny insights on why these four loss functions are chosen?\n\n\n2.  Table 2: $e_la$ and $e_a$ are different, but only $e_la$ is\ndiscussed in the text.  What are the values for $e_a$?\n\n\n3.  Equation 1: what is the motivation?\n\n\n4.  Table 4: What are H, HU, HUF?  Does each file have multiple\ninstances?\n\n5.  Tables 6 and 7: how do you get inf % improvement?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n/a"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5584/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698770772257,
            "cdate": 1698770772257,
            "tmdate": 1699636575109,
            "mdate": 1699636575109,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XzDflWPDdo",
                "forum": "tRRNjNdqu2",
                "replyto": "7qlkQyBBVm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5584/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5584/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe thank you for the time and effort you allocated to check our submission and for your in-depth report. We also thank you for pointing out how we may improve our work.\n\nConcerning your questions:\n1. We chose these loss functions because they are commonly used to train autoencoders. Although they share the same minima, they do not lead to the same outcome because their gradients differ. Therefore, the weights of the resulting AEs are different because of the finite number of training epochs (even though it may be argued that they can asymptotically lead to the same weights values). The same holds for the similarity you correctly observed between the Squared L2-norm and the MSE. In addition, the location of the fault-aware exponent is different between the Squared L2-norm and the MSE, which leads to different behavior.\n2. That is a typographical error on our part. Thank you for having noticed it!\n3. In equation 1, it is shown that each label is associated with a different weight. We agree that it is not sufficiently clear and we thank you for having brought that to our attention!\n4. H, HU and HUF represent the labels used to annotate the data in each file. \"H\" stands for \"HEALTHY\", \"HU\" for \"HEALTHY and UNKNOWN\" and \"HUF\" for \"HEALTHY, UNKNOWN and FAULTY\". Thus, a file which contains the labels \"HU\" contains data points which are labeled \"HEALTHY\" or \"UNKNOWN\".\n5. We calculate the improvement as a percentage. In percentage terms, any number is infinitely greater than 0. In this case it may be better to compute the improvement using absolute values, to avoid any confusion.\n\nWe have decided that it is better to withdraw our paper, as it is not appropriate for ICLR."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5584/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699966005134,
                "cdate": 1699966005134,
                "tmdate": 1699966781759,
                "mdate": 1699966781759,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GNEAUZ8gFU",
            "forum": "tRRNjNdqu2",
            "replyto": "tRRNjNdqu2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5584/Reviewer_wAkT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5584/Reviewer_wAkT"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies using autoencoders to perform anomaly detection, and the central observation is that labeled data with unknown type can improve model performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper made certain observations that have practical values."
                },
                "weaknesses": {
                    "value": "The technical novelty is insufficient for ICLR.  The techniques proposed in the paper seem to be standard."
                },
                "questions": {
                    "value": "NA"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5584/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5584/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5584/Reviewer_wAkT"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5584/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698802216125,
            "cdate": 1698802216125,
            "tmdate": 1699636574977,
            "mdate": 1699636574977,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZlxpUkk6wk",
                "forum": "tRRNjNdqu2",
                "replyto": "GNEAUZ8gFU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5584/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5584/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe thank you for the time and effort you allocated to check our submission. This work would indeed be better suited for a more application-oriented dissemination channel.\n\nWe have decided that it is better to withdraw our paper, as it is not appropriate for ICLR."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5584/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699958065298,
                "cdate": 1699958065298,
                "tmdate": 1699966794390,
                "mdate": 1699966794390,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]