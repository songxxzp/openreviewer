[
    {
        "title": "Generative Pretrained Embedding and Hierarchical Representation to Unlock Human Rhythm in Activities of Daily Living"
    },
    {
        "review": {
            "id": "jvquJtOcOZ",
            "forum": "AqXzHRU2cs",
            "replyto": "AqXzHRU2cs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1857/Reviewer_e66t"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1857/Reviewer_e66t"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an approach to human activity recognition in smart homes, that is using sensors integrated into a domestic environment to capture human activities. Said activities are then analyzed through a sequin sequential model that is based on sensor embeddings that utilize modeling approaches that are known from the domain of language analysis. The claimed innovation lies in the replacement of ELMO embeddings as they had have been used in previous work with GPT embeddings, and the introduction of contextual, hierarchical activity analysis. The experimental evaluation is based on standard benchmarks, i.e., the CASAS datasets and results are presented in form of balanced accuracies and comparisons are drawn to previous methods that were ELMO based, and a deeper dive into the effectiveness of hierarchical modeling is presented."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper operates in an interesting and very relevant application area: Human activity recognition in smart homes has many practical applications, for example, in home automation or in ambient assistant living scenarios. Activity recognition in such environments is inherently challenging due to the unconstrained environment, the noise, ambiguities in both sensor readings and annotations, and many other factors. As such, much progress still needs to be made and I applaud the authors for tackling such an important problem. The paper sets off from a relevant baseline and works with relevant benchmark datasets \u2014 as such the presented work in itself is relevant and has the potential to push beyond the state of the art."
                },
                "weaknesses": {
                    "value": "Despite the general importance of the problem domain that this paper tackles, there are a number of weaknesses with this paper. First, the technical innovation is rather limited. The authors essentially replace one established sensor embedding (ELMO) with another one (GPT). Even the latter one has already been used in previous work (as cited by the authors \u2014 Takeda et al. 2023). The authors claim some additional technical improvement, namely the introduction of temporal context and hierarchical processing. While the former seems problematic because, in my opinion, in substantially limits the generalizability of the resulting models (I believe they are vey likely to overfit, which, alas has not been evaluated in detail), the latter seems interesting. The authors are right in stating that flat activity recognition has issues \u2014 especially when it comes to the analysis of concurrent activities. Yet, I am not convinced that the presented hierarchical approach would actually alleviate this problem in general as, for example, the incorporation of timestamps into the encoding / representation again limits generalizability substantially. \nI am also concerned about the experimental evaluation \u2014 which needs to be described in more detail. From the description of the dataset splits I get the impression that at least some leakage is introduced during model training / hyper parameter tuning? Also: It is not clear to me what the basis for the evaluation is. The authors mention week-wise splits but are the actual continuous sensor readings processed or the pre-segmented activities? I suspect it is the latter (judging by the results on the CASAS datasets [I have substantial experience in working with these] \u2014 which is a problem because this would be a rather unrealistic evaluation.\nThere are also some issues with the presentation: For example it remains unclear what the authors mean by \u201crhythm of ADL\u201d (which they aim to unveil). \nFinally, I think the claim of causality in general is a bit of a stretch here. Yes, filling up an empty room requires the door to be opened and shut, but activities covered in CASAS do not generally follow this causality principle."
                },
                "questions": {
                    "value": "1. How exactly are the datasets split for model training and hyperparameter tuning, as well as evaluation? Is there leakage?\n2. Are you using pre-segmented activities or are you operating in continuous sensor data streams. Please provide evidence.\n3. The improvements in recognition accuracy are barely significant \u2014 as per the table, and you only compare to one set of baseline methods. There are other models out there, why not comparing to them?\n4. Why using such a rather exotic evaluation measure (balance accuracy) and not the regular macro F1 scores that one should use for such imbalanced datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "n/a"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698438576754,
            "cdate": 1698438576754,
            "tmdate": 1699636116006,
            "mdate": 1699636116006,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vNeJnvlEb8",
                "forum": "AqXzHRU2cs",
                "replyto": "jvquJtOcOZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering the questions Q1 and Q2"
                    },
                    "comment": {
                        "value": "Thank you for your insightful review of our paper and valuable suggestions, which have significantly contributed to the improvement of our work.\n\n> Q1-   split for model training and hyperparameter tuning, as well as evaluation? Is there leakage?\n\nIn our study, we have split the datasets into separate sets for model training, hyperparameter tuning, and evaluation, ensuring the integrity of the process and avoiding  data leakage.\n\nDataset Splitting Process:\n\nInitially, we divided the datasets into weekly segments. This approach helps maintain continuity between days, as some activities, like sleeping or nighttime wandering, can span across days.\n%These weekly segments are then further divided into training and test sets.\nA random 30 \\% of these weeks are kept as the test set.\nFrom the remaining 70 \\%, we subdivide each week into pre-segmented activities and use 80 \\% for training and 20 \\% for cross validation.\n\nEmbedding Pre-training:\n\nFor the pre-training of embeddings, we exclusively used the training and cross-validation sets.\nIn the case of ELMo-based embedding, the training set's weekly segments are further split into pre-segmented activities. We allocated 20\\% of these pre-segmented activities for early stopping and validation.\nFor the GPT-based embedding, we applied a sliding window technique to create chunks from the weekly segments, before pre-segmenting into activities. Again, 20\\% of these chunks were reserved for early stopping and validation.\n\nCross Validation :\n\nFor cross-validation, we evaluated the performance on the cross-validation set of the model trained on the training set.  There is a potential for leakage between the train and the validation phases, due to the overlap between the subsets used for the pre-trained embedding tasks and the validation set. This overlap might result in the embedding encountering some sensor sequences in both the training and validation phases.\n\nTest Results :\n\nFinally, the classifiers trained through this process are evaluated on the test set, which has not been used in any previous stages of pre-training, cross-validation, or classification tasks.\nThis methodology has been carefully designed to preserve the integrity of the evaluation process and avoid the risk of data leakage for the test results.\n\n> Q2-  pre-segmented activities or  continuous sensor data streams.  \n\nWe are utilizing pre-segmented activities for the classification tasks and the training of ELMo embeddings. The nature of our approach with ELMo embeddings requires pre-segmentation. This method ensures that each segment corresponds to a distinct activity, allowing for more accurate training and classification.\n\nIn contrast, our GPT-based embedding does not require pre-segmentation into activities. It utilizes chunks of continuous sensor data events, which do not necessarily correspond to complete activities. These chunks may contain a single activity, multiple activities, or even just a portion of an activity. Each chunk is a sequence of sensor events selected randomly, but the chronological order of these sensor events is maintained. This approach allows the GPT model to learn from a broader context, including partial and overlapping activities, providing a more nuanced understanding of the sensor data streams."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700589766568,
                "cdate": 1700589766568,
                "tmdate": 1700589766568,
                "mdate": 1700589766568,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dWcuDPaezA",
                "forum": "AqXzHRU2cs",
                "replyto": "jvquJtOcOZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering questions Q3 and Q4"
                    },
                    "comment": {
                        "value": "> Q3 - The improvements  are barely significant... There are other models out there, why not comparing to them?\n\nIn response to your comment regarding the significance of our recognition accuracy improvements and the scope of our comparisons, we acknowledge the importance of a comprehensive comparative analysis. Initially, our comparison was focused on the ELMo-based approach, as it represented a recent benchmark in the field and had already been compared with a range of other methods in previous studies. This comparison provided a relevant and contemporary point of reference for our work.\n\nHowever, in light of your suggestion, we have broadened the scope of our comparative analysis. We have now included additional comparisons with other prominent models in the field in table 3 of section 4.2.1. Specifically, we have compared our approach with the work of Liciotti et al., which utilizes a SOTA LSTM-based methodology, and a CNN approach employing a Fully Convolutional Network (FCN) architecture. As Liciotti et al.'s algorithm has already demonstrated superiority over traditional machine learning approaches, including Naive Bayes, Conditional Random Field, LSTM and HMM, by proxy, our GPT-based algorithms thus outperform also Naive Bayes, Conditional Random Field, LSTM and HMM. \nThis expanded comparison allows us to position our work within a wider context of existing methods and provides a more comprehensive evaluation of our model's performance.\n\n> Q4- Why  not the regular macro F1 scores that one should use for such imbalanced datasets?\n\nWe initially chose balanced accuracy as our evaluation metric based on observation of classical accuracy use in multiple literature sources which might not fully represent performance in the context of imbalanced datasets. However, we acknowledge your point regarding the suitability of macro F1 scores for such datasets.\n\nIn response to your feedback, we have revised our evaluation approach. We have replaced balanced accuracy with macro F1 scores in our analysis, recognizing that this metric provides a more comprehensive and relevant measure of performance for imbalanced datasets. Additionally, to enhance the transparency and detail of our evaluation, we have included confusion matrices for each dataset of main algorithms in the appendix. These matrices highlight the performance of each algorithm across different classes. Furthermore, we have provided tables in the appendix detailing the F1 scores for each dataset and activity, offering a granular view of each algorithm's performance.\n\nThese amendments aim to present a more accurate and thorough evaluation of our model, aligning with standard practices in the field."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700589822639,
                "cdate": 1700589822639,
                "tmdate": 1700589822639,
                "mdate": 1700589822639,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Si6mYcg7xj",
            "forum": "AqXzHRU2cs",
            "replyto": "AqXzHRU2cs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1857/Reviewer_wCG6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1857/Reviewer_wCG6"
            ],
            "content": {
                "summary": {
                    "value": "This paper present an approach to human activity recognition (HAR) from ambient sensors in smart home setting. Transformer decoder based pre-trained embedding is proposed, considering hierarchical sequential architecture and time encoding to refine the model. Three long-term activity recognition datasets are benchmarked with promising results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Paper provides novel combination of existing ideas (pre-trained transformer (GPT-like design, bi-directional LSTM) to build hierarchical model. Based on empirical evaluation it shows the usefulness of the hierarchical modelling of activities. Building blocks are quite-well justified and results are promising; improving some of the issues in previous approach."
                },
                "weaknesses": {
                    "value": "Paper is application oriented in quite well-defined domain, and is an incremental improvement to a previous study. It lacks \"basic\" baseline other than GPT/LLM-style of model in comparison. Also, there are some stability issues which might be tackled with the normalisation layer, but that has not been evaluated in practice."
                },
                "questions": {
                    "value": "- How would \"basic\" baseline, i.e. hierarchical HMM compared to deep learning models (in this setting)? \n- It would be useful to evaluate further the stability issue of hierarchical models (e.g., using normalisation layer)\n- It would be useful to show the confusion matrix of different activities and which are most difficult to discriminate\n- Can you discuss about sensor data processing with symbolic representation and how that effect HAR? E.g., continuous temperature\nmeasurements are now transformed to symbolic labels, compared to more traditional sensor signal processing approaches which uses\ndirectly the numerical sensor values."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698758271497,
            "cdate": 1698758271497,
            "tmdate": 1699636115925,
            "mdate": 1699636115925,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "G8KjwdudxB",
                "forum": "AqXzHRU2cs",
                "replyto": "Si6mYcg7xj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering the questions Q1"
                    },
                    "comment": {
                        "value": "Based on your suggestion, we have now expanded our study to include comparisons with other methods in table 3 of section 4.2.1. Specifically, we conducted a comparison with another method than sequence models : a CNN based approach, more precisely a FCN [2] model. \nAdditionally, we compared our approach against the work of Liciotti et al.[1], a SOTA LSTM-based method. It's important to note that Liciotti et al.'s algorithm has already demonstrated superiority over traditional machine learning approaches, including Naive Bayes, Conditional Random Field, LSTM and HMM, in [1]. \n\nOur findings indicate that both the FCN and Liciotti et al.\u2019s LSTM-based approach are outperformed by far by all versions of ELMo-based and GPT-based methods. The F1-scores more than double for ELMoAR, GPTAR, ELMoHAR-note and GPTHAR-note.\nBy proxy, our GPT-based algorithms thus outperform also Naive Bayes, Conditional Random Field, LSTM and HMM.\n\n\n|                         |Aruba | Milan| Cairo|\n|--------------|-----------|------------|-------|\n|FCN [2]                                | 33.10 \u00b1 2.23 |  15.10  \u00b1 1.52  | 7.60\u00b1 2.46.    |\n|Liciotti et al.  [1]                   | 32.00 \u00b11.56  | 17.40 \u00b1 2.07    | 26.60 \u00b13.24.  |\n|ELMoAR (Window 60)         | 84.80 \u00b1 1.99 | 70.80 \u00b10.92     |  70.50 \u00b11.43  |\n|GPTAR (8 Heads 3 Layers)  | 86.10 \u00b1 1.20 | 70.80 \u00b1 1.40    | 73.20 \u00b11.99   |\n|ELMoHAR-note                   | 88.10 \u00b1 1.20 | 77.40  \u00b1 1.65   | 75.90  \u00b1 2.88 |\n|GPTHAR-note                     | 87.30 \u00b1 2.98  | 79.90 \u00b1 1.52   | 84.80 \u00b1 1.81  |                    \n\n\nTo verify the accuracy of our implementation of the comparative algorithm from article [1], we replicated their methodology, details can be found in Annex F. This process involved relabeling activities of the same type and employing 3-fold cross-validation across each dataset. Our findings were consistent with the results reported in their paper.\n\nThis comprehensive comparison framework not only adheres to your suggestions but also reinforces the effectiveness of our proposed GPT-based model.\n\n[1] Liciotti, D., Bernardini, M., Romeo, L., and Frontoni, E. (2019). A Sequential Deep Learning Application for Recognising Human Activities in Smart Homes. Neurocomputing.\n\n[2] Bouchabou, D., Nguyen, S. M., Lohr, C., Leduc, B., and Kanellos, I. (2021). Fully convolutional network bootstrapped by word encoding and embedding for activity recognition in smart homes. Deep Learning for Human Activity Recognition: Second International Workshop, DL-HAR 2020, Held in Conjunction with IJCAI-PRICAI 2020, Kyoto, Japan, January 8, 2021, Proceedings 2(111--125)."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658298502,
                "cdate": 1700658298502,
                "tmdate": 1700740961053,
                "mdate": 1700740961053,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "unZEgyMlha",
                "forum": "AqXzHRU2cs",
                "replyto": "Si6mYcg7xj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering the questions Q2"
                    },
                    "comment": {
                        "value": "Addressing the stability issues observed in hierarchical models is indeed crucial. Evaluating the impact of a normalization layer, as you suggested, is highly relevant. Although this aspect was not covered in our current study, we recognize its potential to enhance model performance. We plan to explore this in future iterations of our research, focusing on how various normalization techniques could mitigate stability issues in hierarchical deep learning models. Furthermore, we believe that increasing the number of neurons in the hidden layers could resolve stability issues by enhancing the model's representational capabilities. This hypothesis is inspired by our observations of performance variations across different classes during training. We noticed differences in the model's focus on specific activities, which seemed to shift from one training session to another. By adding more neurons, we anticipate that the model will have sufficient representational capacity to maintain a consistent focus across all activities."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658766076,
                "cdate": 1700658766076,
                "tmdate": 1700658766076,
                "mdate": 1700658766076,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EF8njUTAsr",
                "forum": "AqXzHRU2cs",
                "replyto": "Si6mYcg7xj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering the questions Q3"
                    },
                    "comment": {
                        "value": "Thank you for your insightful recommendation regarding the inclusion of confusion matrices.\n\nWe have added the average confusion matrices for each algorithm and dataset in Annex C. This addition aims to facilitate a clearer understanding of the performance improvements achieved by each algorithmic increment.\n\nFor example, in the Aruba dataset, activities such as 'Washing Dishes', 'Meal Preparation', 'Enter Home', and 'Leave Home' show improved classification accuracy. In the Milan dataset, 'Eve Med' and 'Morning Meds' demonstrate a notable reduction in misclassifications. Similarly, in the Cairo dataset, meal-related activities like 'Breakfast', 'Lunch', and 'Dinner' are identified with higher accuracy.\n\nTo illustrate, consider the Cairo dataset in the version without timestamp encoding (GPTHAR-note, where \"note\" signifies no time encoding). The confusion matrix for 'Breakfast', 'Dinner', and 'Lunch' is as follows:\n\n|  Activity    | Breakfast | Dinner     | Lunch |\n|--------------|-----------|------------|-------|\n| Breakfast    |     0.83  | 0.06       |  0.03 |\n| Dinner       |     0.0   |   0.72     |  0.21 |\n| Lunch        |     0.01  |    0.29    |   0.66|\n\nContrastingly, for the version with timestamp encoding (GPTHAR), the confusion matrix for these activities is:\n\n|  Activity    | Breakfast | Dinner     | Lunch |\n|--------------|-----------|------------|-------|\n| Breakfast    |  0.89     |     0.01   |  0.00 |\n| Dinner       |  0.00     |      1.00  |  0.00 |\n| Lunch        |  0.00     |      0.00  |  0.99 |"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659477828,
                "cdate": 1700659477828,
                "tmdate": 1700659477828,
                "mdate": 1700659477828,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "85LS3qGryP",
                "forum": "AqXzHRU2cs",
                "replyto": "Si6mYcg7xj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering the questions Q3"
                    },
                    "comment": {
                        "value": "Thank you for raising this important question. Transforming continuous sensor data into symbolic labels marks a substantial departure from conventional sensor signal processing techniques, particularly in the realm of Human Activity Recognition (HAR). This strategy simplifies complex continuous data into symbolic forms that are more manageable and interpretable. For example, in our research, we convert temperature sensor readings into symbols. This method proves especially useful in smart home environments, where temperature sensors typically operate within a specific range and send data when threshold changes occur. Consequently, these readings result in event-based values rather than continuous streams, making symbolic representation a more appropriate and effective approach. However, it's worth noting that we have not yet had the opportunity to apply this method to real continuous data from sensors like power meters as our current studied datasets doesn't contains such sensors values.\n\nWhen considering real continuous data from sensors, we anticipate adapting our approach. Instead of transforming all continuous values into symbols, we plan to use symbols to represent specific threshold crossings or distinct events. For instance, the activation or deactivation of an appliance generates a unique signal pattern in power signals. We aim to symbolically represent these patterns with symbols that convey changes in the appliance's status, based on the detection of appliance patterns in the raw signal."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660449733,
                "cdate": 1700660449733,
                "tmdate": 1700660449733,
                "mdate": 1700660449733,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qczLzLs32O",
                "forum": "AqXzHRU2cs",
                "replyto": "85LS3qGryP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Reviewer_wCG6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Reviewer_wCG6"
                ],
                "content": {
                    "title": {
                        "value": "Response to rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for the response to clarify some of my concerns. Extended evaluation indeed shows some promising practical results of hierarchical modelling (e.g., against the baseline, confusion matrices etc.), which can be seen as a main contribution. The  technical contribution and novelty is a bit limited, combining already existing approaches. Furthermore, stability of hierarchical model could have been studied more carefully in practice. I'll keep my original score."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700742091962,
                "cdate": 1700742091962,
                "tmdate": 1700742091962,
                "mdate": 1700742091962,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jolDGHFZj5",
            "forum": "AqXzHRU2cs",
            "replyto": "AqXzHRU2cs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1857/Reviewer_dgfF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1857/Reviewer_dgfF"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a multi-time scale architecture aiming to leverage a wider temporal context in a multi-time scale manner. The core problem to solve is classifying sensor event sequences. The temporal order of the sequences are important for reasoning in this application."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The primary contribution of this paper is to leverage Transformer decoder for sensor embedding and hierarchical architecture design. \nThese techniques appear to be adaptation of existing methodologies for this domain which hasn't been explored before. The core *technical* contribution could have been a bit more."
                },
                "weaknesses": {
                    "value": "I have a question and concern about the presentation of the paper. All the tables look like ablation results and collection of different baselines. The entries in the tables aren't clear which one is hierarchical vs which one is not. The captions need to be improved and self-explanatory. I am still confused what's the proposed method? Is the \"GPTHAR+Time-encoding\" in Table 5? OR, this paper is a review paper. It needed a second read to understand the differences."
                },
                "questions": {
                    "value": "They have reported only the balanced accuracy metric. It's good to check other metrics such as table 6 or 7 of previous SOTA paper: https://arxiv.org/pdf/2111.12158.pdf\nAre these datasets long-tailed? is the balanced accuracy increasing at the cost of accuracy? \nThe annexture provided some of those additional metrics. I'd suggest highlighting the best class per method would be good."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801270785,
            "cdate": 1698801270785,
            "tmdate": 1699636115857,
            "mdate": 1699636115857,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FhQzy2kf0x",
                "forum": "AqXzHRU2cs",
                "replyto": "jolDGHFZj5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering to Questions"
                    },
                    "comment": {
                        "value": "Thank you for your valuable feedback.\n\nRegarding your comment on our use of metrics, we acknowledge your suggestion about exploring additional metrics as exemplified in tables 6 and 7 of the SOTA paper (https://arxiv.org/pdf/2111.12158.pdf). In response, to your comments on our choice of metrics, we have updated our analysis to include macro F1 scores instead of balanced accuracies in our main table to provide a more comprehensive understanding of our results. We agree that a range of metrics can offer a richer insight. Due to paper length constraints, the main body of the paper will feature only the F1 scores.  However, detailed tables in Annex A will provide a complete breakdown of all metrics for each algorithm across the three datasets, as presented in tables 6 and 7 of the SOTA paper (https://arxiv.org/pdf/2111.12158.pdf).\n\nRegarding your concern about the datasets being long-tailed and the trade-off between balanced accuracy and accuracy, we have conducted a more thorough examination. In the annex, we present additional metrics to illuminate this issue. We have also highlighted the best-performing class for each method in our results. To further enhance clarity, confusion matrices for each class are included in the appendix. These additions aim to more effectively address the nuances of dataset characteristics and their implications on our evaluation metrics.\n\nWe believe these revisions will substantially improve the clarity and thoroughness of our analysis and are grateful for your constructive suggestions."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700656714158,
                "cdate": 1700656714158,
                "tmdate": 1700656743401,
                "mdate": 1700656743401,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ukTVqBrder",
                "forum": "AqXzHRU2cs",
                "replyto": "jolDGHFZj5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1857/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering to weaknesses"
                    },
                    "comment": {
                        "value": "Thank you for your comment. We have improved the presentation of the paper to make clearer what is the proposed method : the algorithm using GPT transoformer decoder with time-encoding and a hierarchical architecture. We re-named our proposed method GPTHAR.\n\nNow,  the algorithms have been renamed as :\n- GPTHAR : using GPT transformer decoder with time-encoding and a hierarchical architecture.\n- GPTAR-note (for no temporal encoding) : uses GPT transoformer decoder and a hierarchical architecture, but  without timestamp information .\n- GPTAR : using GPT transformer decoder for embedding in a single-level architecture, without timestamp information.\n\n- ELMoHAR : using ELMo with time-encoding and a hierarchical architecture.\n- ELMoAHR-note (for no temporal encoding) : uses ELMo and a hierarchical architecture, but  without timestamp information .\n- ELMoAR : using  ELMo for embedding in a single-level architecture, without timestamp information."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1857/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719028682,
                "cdate": 1700719028682,
                "tmdate": 1700719028682,
                "mdate": 1700719028682,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gJvtv5arTE",
            "forum": "AqXzHRU2cs",
            "replyto": "AqXzHRU2cs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1857/Reviewer_v1qx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1857/Reviewer_v1qx"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an approach for temporal human activity detection in smart homes using GPT-based hierarchical model. The authors test their method on 3 datasets"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors focus an important problem in the context of smart buildings. Activity detection using efficient machine learning methods help achieve occupant comfort and energy efficiency if these inputs are fed to building control mechanism."
                },
                "weaknesses": {
                    "value": "1. The authors have not covered more on the types of activities captured in the datasets, and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency.\n2. The number of sensors used to collect data seems a lot. In practice, its not practical to have so many sensors in a home collecting information. The authors should try some benchmarking on a subset of sensors if the dataset permits.\n3. How will a sensor fusion approach work in this scenario?\n4. What are the motivations behind hierarchical approach?\n5. For Milan and Cairo, the temporal method might not be effective since the number of days in the experiment is less."
                },
                "questions": {
                    "value": "See the question above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1857/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698890688770,
            "cdate": 1698890688770,
            "tmdate": 1699636115788,
            "mdate": 1699636115788,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]