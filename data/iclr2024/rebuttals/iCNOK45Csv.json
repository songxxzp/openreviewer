[
    {
        "title": "Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method Perspective"
    },
    {
        "review": {
            "id": "rVS5Wz86er",
            "forum": "iCNOK45Csv",
            "replyto": "iCNOK45Csv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6151/Reviewer_bXcG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6151/Reviewer_bXcG"
            ],
            "content": {
                "summary": {
                    "value": "This paper study the backdoor attack for the Kernel Inducing Points (KIP) based dataset distillation. Specifically, the paper introduces two theory-driven trigger patterns and provides empirical evidence that they can increase ASR of models (with the same architecture as the proxies for dataset distillation) trained on the distilled datasets without sacrificing CTA remarkably. Additionally, experimental results also indicate that the evaluated backdoor defense methods may not be fully effective against the proposed relax-trigger."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1: This paper proposes to investigate a theoretical framework for the KIP-based dataset distillation method about why certain backdoors can survive in distilled datasets. Then, two theory-driven backdoor trigger patterns are consequently introduced.\n\nS2: In the evaluated scenarios, the proposed triggers present adequate ability to raise ASR without sacrificing CTA remarkably. Moreover, experimental results also indicate that the 8 evaluated backdoor defence methods may not be fully effective against the proposed relax-trigger."
                },
                "weaknesses": {
                    "value": "W1: Certain key aspects of the presented theory appear ambiguous from my vantage point. I will delve deeper into these ambiguities in the Questions section.\n\nW2: The established theoretical framework predominantly caters to kernel-based dataset distillation methods, and its application seems restricted primarily to the initially proposed KIP method. Given the complexities associated with computing the NTK, KIP's practicality has been empirically questioned. While subsequent kernel-based dataset distillation methods capable of distilling comprehensive datasets have emerged (e.g., [1]), this paper falls short of validating their compatibility with the introduced framework. This oversight not only raises concerns about the paper's soundness but also limits the practicability of the introduced attack method.\n\nW3: The experimental design in the paper appears insufficient, raising questions about the broader applicability of the proposed attack. First, it relies on a mere two benchmark datasets. Second, the distilled dataset's size variation is limited to IPC (abbreviation of Image Per Class) scenarios of 10 and 50. Third, while cross-architecture generalization is pivotal in dataset distillation, the paper's evaluations seem to be confined to a 3-layer ConvNet, which is consistent with the architecture of the proxy model designated for distillation.\n\n[1] Yongchao Zhou, Ehsan Nezhadarya, Jimmy Ba: Dataset Distillation using Neural Feature Regression. NeurIPS 2022"
                },
                "questions": {
                    "value": "Q1: Regarding Equation 9, why is the objective of the KIP-based backdoor attack to minimize the empirical loss of $f_{\\mathcal{S}^*}$ on either $\\mathcal{D}_A$ or $\\mathcal{D}_B$, rather than simultaneously reducing the empirical loss on both $\\mathcal{D}_A$ and $\\mathcal{D}_B\\$ as your statement about \"Backdoor Attack\" (The next to the last paragraph above Equation 7)?\n\nWhile you attempt to address this in Equation 10 by introducing $\\tilde{D}=D_A \\cup D_B$ to establish an upper bound on the loss of $f_{\\mathcal{S}^*}$ with respect to $D$, this formulation seems somewhat unreasonable to me.\n\nQ2: It appears that the introduced projection loss can be directly optimized with respect to the trigger $T$. What's the rationale behind setting an upper bound and optimizing the projection loss through this bound? Does this approach offer computational benefits?\n\nQ3: Based on my W3, could you share additional experimental evidence to validate the efficacy of your proposed triggers when applied to models with alternative architectures trained on the synthesized datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6151/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6151/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6151/Reviewer_bXcG"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6151/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698309518866,
            "cdate": 1698309518866,
            "tmdate": 1699636667060,
            "mdate": 1699636667060,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NToNM6Oaja",
                "forum": "iCNOK45Csv",
                "replyto": "rVS5Wz86er",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6151/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6151/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Reviewer bXcG\n## Weakness\n### W1. Certain key aspects of the presented theory appear ambiguous from my vantage point. I will delve deeper into these ambiguities in the Questions section.\n\n\n### W2. The established theoretical framework predominantly caters to kernel-based dataset distillation methods, and its application seems restricted primarily to the initially proposed KIP method. Given the complexities associated with computing the NTK, KIP's practicality has been empirically questioned. While subsequent kernel-based dataset distillation methods capable of distilling comprehensive datasets have emerged (e.g., [1]), this paper falls short of validating their compatibility with the introduced framework. This oversight not only raises concerns about the paper's soundness but also limits the practicability of the introduced attack method. ([1] Yongchao Zhou, Ehsan Nezhadarya, Jimmy Ba: Dataset Distillation using Neural Feature Regression. NeurIPS 2022)\n\nWe understand KIP/NTK has known computational drawbacks. However,\n1. Through KIP/NTK, we can theoretically understand the effect of data distillation and backdoor. Our new findings can measure the performance of each trigger with a closed-form formula and induce two theory-driven triggers which can survive from the dataset distillation. Advanced kernel based methods lose theoretical clarity.\n\n2. Practically, we find that our findings on this theoretical framework extend to more advanced approaches, such as FRePo (Dataset Distillation using Neural Feature Regression. NeurIPS, 2022) and DM (Dataset condensation with distribution matching. WACV, 2023). The experimental results show that our triggers can successfully transfer to the FRePo and DM.\n\n| Trigger-type | Dataset | IPC (Image Per Class)} | Distillation | Model | CTA (%) | ASR (%) |\n| ------------ | ------- | ---------------------- | ------------ | ----- | ------- | ------- |\n| Cifar10 | simple-trigger | 10 | FRePO | ConvNet | 60.32 | 83.10 |\n| Cifar10 | relax-trigger | 50 | FRePO | ConvNet | 68.34 | 81.61 |\n\n\n| Trigger-type | Dataset | IPC (Image Per Class)} | Distillation | Model | CTA (%) | ASR (%) |\n| ------------ | ------- | ---------------------- | ------------ | ----- | ------- | ------- |\n| Cifar10 | simple-trigger | 10 | DM |MLP | 36.41 | 77.03 |\n| Cifar10 | simple-trigger | 50 | DM |MLP | 36.88 | 76.79 |\n| Cifar10 | relax-trigger | 10 | DM |MLP  | 36.31 | 76.04 |\n| Cifar10 | relax-trigger | 50 | DM |MLP  | 36.81 | 76.21 |\n\nOverall, we believe we made two major contributions on extending the frontier of backdoor analysis for dataset distillation, \n1. Deep theoretical understanding. \n2. The conclusion hold empirically on sota dataset distillation, such as FRePo and DM."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6151/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700609261479,
                "cdate": 1700609261479,
                "tmdate": 1700609261479,
                "mdate": 1700609261479,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CPUDWPIgN7",
                "forum": "iCNOK45Csv",
                "replyto": "a0Tj24pKTC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6151/Reviewer_bXcG"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6151/Reviewer_bXcG"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your detailed responses. However, I **maintain my current rating** due to the following reasons:\n\n1. In addressing my Weakness 1, your response merely repeats what's described in your paper about Equation 10. However, my primary concern is that **establishing an empirical risk upper bound for a single dataset by using a contrived collection including it and another dataset seems inherently unreasonable**.\n\n2. Regarding your answer to my **question 2**, you state that **utilizing the upper bound of projection loss to derive the trigger doesn't offer any additional computational benefits or drawbacks (in the last paragraph)**. However, you appear to argue that **optimizing the upper bound** of your proposed loss **is more advantageous than optimizing the loss itself**. **This argument seems perplexing to me**. Therefore, I recommend elaborating on this part more clearly and adding additional experiments to enhance credibility in your future print.\n\n3. It would be recommended to re-organize beneficial supplementary experiments or applications more explicitly in the main text (at least in your paper appendix) of your future print. I believe this could strengthen your argument and the overall presentation of your work."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6151/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700655353814,
                "cdate": 1700655353814,
                "tmdate": 1700655353814,
                "mdate": 1700655353814,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vfXbULL3o8",
            "forum": "iCNOK45Csv",
            "replyto": "iCNOK45Csv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6151/Reviewer_Z9NC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6151/Reviewer_Z9NC"
            ],
            "content": {
                "summary": {
                    "value": "The research provides a comprehensive exploration of the theoretical underpinnings of backdoor attacks and their interplay with dataset distillation, employing kernel methods as the foundational framework. This investigation leads to the introduction of two innovative trigger pattern generation techniques, intricately crafted to suit the specific requirements of dataset distillation. These methodologies are meticulously derived from a foundation of theoretical insights."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The research significantly contributes to the theoretical understanding of backdoor attacks and their interaction with dataset distillation. By using kernel methods as the foundational framework, it provides a rigorous theoretical foundation for subsequent developments.\n\n2. The introduction of two novel trigger pattern generation methods tailored for dataset distillation is a notable contribution. These methods are based on theoretical insights and offer new avenues for designing backdoor attacks in this context.\n\n3.The study backs its theoretical findings with comprehensive empirical experiments. The results demonstrate the resilience of datasets poisoned by the designed triggers against conventional backdoor attack detection and mitigation methods, adding practical significance to the research."
                },
                "weaknesses": {
                    "value": "The experimental results presented in the study may benefit from further substantiation to conclusively support the stated claims. A notable observation in Table 2 is that the performance of the 'simple-trigger' method is notably outperformed by 'DoorPing,' which prompts questions regarding the efficacy of the former.\n\nMoreover, enhancing the organization and writing style of the manuscript could enhance its overall readability and comprehension for a wider readership."
                },
                "questions": {
                    "value": "Please refer to \"Weaknesses\" part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6151/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6151/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6151/Reviewer_Z9NC"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6151/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698668982645,
            "cdate": 1698668982645,
            "tmdate": 1700874747189,
            "mdate": 1700874747189,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qwOj1RTXWd",
                "forum": "iCNOK45Csv",
                "replyto": "vfXbULL3o8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6151/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6151/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Reviewer Z9NC\n## Question\n### Q1. The experimental results presented in the study may benefit from further substantiation to conclusively support the stated claims. A notable observation in Table 2 is that the performance of the 'simple-trigger' method is notably outperformed by 'DoorPing,' which prompts questions regarding the efficacy of the former.\n\n>We perform the following experiments to demonstrate that our proposed method is valid.\n1. ImageNet:\nWe perform our KIP-based backdoor attack on ImageNet. In our experiment, we randomly choose ten sub-classes to perform our experiment. We also resize each image in the ImageNet into 128x128. The experimental results show that our KIP-based backdoor attack is effective.\n\n| Trigger-type   | Dataset  |Model |IPC (Image Per Class) | CTA (%) | ASR (%) |\n| -------------- | -------- |--- |--------------------- | ------- | --- |\n| simple-trigger | ImageNet |NTK|10                    | 15.00   | 100.00    |\n| simple-trigger | ImageNet |NTK|50                    | 16.60   | 100.00   |\n| relax-trigger  | ImageNet |NTK|10                    | 16.40   | 100.00   |\n| relax-trigger  | ImageNet |NTK|50                    | 17.00    | 100.00  |\n\n2. Transferability:\nWe test the transferability of simple-trigger and relax-trigger. We first utilize our triggers to poison the datasets. Then, we distill these datasets with different distillation methods, FRePo (Dataset Distillation using Neural Feature Regression. NeurIPS, 2022) and DM (Dataset condensation with distribution matching. WACV, 2023). The experimental results shows that our triggers can successfully transfer to the FrePo and DM.\n\n\n\n| Trigger-type | Dataset | IPC (Image Per Class)} | Distillation | Model | CTA (%) | ASR (%) |\n| ------------ | ------- | ---------------------- | ------------ | ----- | ------- | ------- |\n| Cifar10 | simple-trigger | 10 | FRePO | ConvNet | 60.32 | 83.10 |\n| Cifar10 | relax-trigger | 50 | FRePO | ConvNet | 68.34 | 81.61 |\n\n\n| Trigger-type | Dataset | IPC (Image Per Class)} | Distillation | Model | CTA (%) | ASR (%) |\n| ------------ | ------- | ---------------------- | ------------ | ----- | ------- | ------- |\n| Cifar10 | simple-trigger | 10 | DM |MLP | 36.41 | 77.03 |\n| Cifar10 | simple-trigger | 50 | DM |MLP | 36.88 | 76.79 |\n| Cifar10 | relax-trigger | 10 | DM |MLP  | 36.31 | 76.04 |\n| Cifar10 | relax-trigger | 50 | DM |MLP  | 36.81 | 76.21 |"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6151/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700608829101,
                "cdate": 1700608829101,
                "tmdate": 1700608829101,
                "mdate": 1700608829101,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "KDcmtjMcrP",
            "forum": "iCNOK45Csv",
            "replyto": "iCNOK45Csv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6151/Reviewer_npoK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6151/Reviewer_npoK"
            ],
            "content": {
                "summary": {
                    "value": "The paper aims to bridge a gap in the literature by providing a theoretical framework for understanding backdoor attacks on dataset distillation. It introduces two new theory-driven trigger pattern generation methods: simple trigger and relax trigger, specialized for dataset distillation. The paper presents analyses and experiments on two datasets, showing that these triggers are effective at launching resilient backdoor attacks that can significantly weaken conventional detection and mitigation methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is among the first to provide a theoretical framework for understanding backdoor effects on dataset distillation, thus filling a significant gap in the field.\n2. The introduction of simple-trigger and relax-trigger is interesting. These triggers are also shown to be effective through empirical testing."
                },
                "weaknesses": {
                    "value": "1. Some sections could benefit from more straightforward explanations to make the paper more accessible to readers not deeply familiar with the subject matter.\n2. The datasets evaluated in the paper appear to be limited in scope. Typically, researchers conduct experiments on more comprehensive datasets like ImageNet, or other comparable datasets, to convincingly demonstrate the effectiveness of a proposed attack method."
                },
                "questions": {
                    "value": "1. Are there some potential defense methods during the dataset distillation process to mitigate backdoor attacks?\n2. Given the variety of dataset distillation methods available, could the choice of distillation method potentially impact the conclusions drawn about the efficacy of the proposed attack method?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6151/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6151/Reviewer_npoK",
                        "ICLR.cc/2024/Conference/Submission6151/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6151/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698723143035,
            "cdate": 1698723143035,
            "tmdate": 1700658189737,
            "mdate": 1700658189737,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GSZS9L8yz3",
                "forum": "iCNOK45Csv",
                "replyto": "KDcmtjMcrP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6151/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6151/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Reviewer npoK\n## Weakness\n### W1. Some sections could benefit from more straightforward explanations to make the paper more accessible to readers not deeply familiar with the subject matter. \n\n>We will use more straightforward examples to explain the concept of some terms, like conflict loss and projection loss.\n\n1. For conflict loss, the conflict loss is defined as \n$$\n \\mathbb{E} _{(x, y)\\sim\\tilde{D}} \\ell(f _{\\tilde{D}}, (x, y)),\n$$\n    where $\\tilde{D} = D_A \\cup D_B$.\n    The conflict measures the information conflict between $D_A$ and $D_B$. For example, we consider a dog/cat picture classification problem. In the dataset $D_A$, we label the dog pictures with $0$ and label the cat pictures with $1$. However, in the dataset $D_B$, we label the dog pictures with $1$ and label the cat pictures with $0$. It is clear that the model trained on $\\tilde{D}$ must perform terribly on the dataset either $D_A$ or $D_B$. In this case, the information between $D_A$ and $D_B$ have strong conflict and the conflict loss would be large.\n\n2. For projection loss, the projection loss is defined as \n$$\n\\min _{\\mathcal{S}} \\mathbb{E } _{(x, y)\\sim\n\\tilde{D}} \\ell(f _{\\mathcal{S}}, (x, f _{\\tilde{D}}(x)))\\nonumber.\n$$\n    The projection loss reflects the natural information loss when we compress a large dataset into a small dataset. Take writing an abstract for example. If we want to write a 100 word abstract to  describe a 10000 words article, the abstract may suffer some lack of semantics to some degree. Such a phenomena also happens for dataset distillation. When the information of a large dataset is complex enough, the information loss for dataset distillation will be significant; When the information of a large dataset is very simple, it is possible that there is only very limited information loss. We introduce the projection loss defined above to measure this phenomenon.\n\n\n### W2. The datasets evaluated in the paper appear to be limited in scope. Typically, researchers conduct experiments on more comprehensive datasets like ImageNet, or other comparable datasets, to convincingly demonstrate the effectiveness of a proposed attack method.\n\nFollowing the reviewer's suggestion, we additionally perform our KIP-based backdoor attack on ImageNet. The ASR in our experiments can achieve 100%, which suggests our simple-trigger and relax-trigger are both effective on ImageNet. Here, we randomly choose ten sub-classes to perform our experiment. We also resize each image in the ImageNet into 128x128.\n\n| Trigger-type   | Dataset  |Model |IPC (Image Per Class) | CTA (%) | ASR (%) |\n| -------------- | -------- |--- |--------------------- | ------- | --- |\n| simple-trigger | ImageNet |NTK|10                    | 15.00   | 100.00    |\n| simple-trigger | ImageNet |NTK|50                    | 16.60   | 100.00   |\n| relax-trigger  | ImageNet |NTK|10                    | 16.40   | 100.00   |\n| relax-trigger  | ImageNet |NTK|50                    | 17.00    | 100.00  |"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6151/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700608520424,
                "cdate": 1700608520424,
                "tmdate": 1700608520424,
                "mdate": 1700608520424,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "asCUWhT7P4",
                "forum": "iCNOK45Csv",
                "replyto": "GIppQ9ALsY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6151/Reviewer_npoK"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6151/Reviewer_npoK"
                ],
                "content": {
                    "comment": {
                        "value": "Thank author(s) for your response. I think the author solved most of my concerns but I still think a baseline defense method is necessary for evaluating the attack. I will increase my score."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6151/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658162531,
                "cdate": 1700658162531,
                "tmdate": 1700658162531,
                "mdate": 1700658162531,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ExOJlKXGa0",
            "forum": "iCNOK45Csv",
            "replyto": "iCNOK45Csv",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6151/Reviewer_hKa2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6151/Reviewer_hKa2"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the problem of backdoor attacks to evade data distillation, which introduces subtle changes or \"triggers\" to data to manipulate machine learning models.  It focuses on the theoretical underpinnings of dataset distillation and its implications on backdoor attacks. Based on the theoretical understandings, the authors propose two new theory-induced trigger generation methods: simple-trigger and relax-trigger. Experimental results demonstrate that these triggers, when used in an attack, can successfully evade common backdoor detection techniques."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. One of the primary strengths of this work is the establishment of the first theoretical framework to understand backdoor effects on dataset distillation. This fills a significant gap in the literature, especially when considering the practical implications of such attacks.\n2. The paper introduces two new backdoors - simple-trigger and relax-trigger - which are computationally efficient. The relax-trigger, in particular, is more efficient than DoorPing as it doesn't rely on bi-level optimization.\n3. Both the simple-trigger and relax-trigger have been demonstrated to challenge or evade eight existing defense mechanisms."
                },
                "weaknesses": {
                    "value": "1. If we utilize the original dataset instead of the distilled data for model training, would the trigger remain effective? It would be better to include such experiments.\n2. Can the proposed attacks evade other data distillation techniques (e.g., gradient matching based methods and distribution matching based methods)? It would further strengthen the experimental evaluation by examining the transferability of the proposed attacks.\n3. In my understanding, individuals would majorly employ distilled data for training new models in scenarios such as neural architecture search and continual learning. Expanding on the implications of backdoor attacks in these applications would provide greater clarity."
                },
                "questions": {
                    "value": "1. In Equation (9), why the second term is called the generalization gap?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6151/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698809964829,
            "cdate": 1698809964829,
            "tmdate": 1699636666690,
            "mdate": 1699636666690,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nafZXbKddS",
                "forum": "iCNOK45Csv",
                "replyto": "ExOJlKXGa0",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6151/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6151/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "# Reviewer hKa2\n## Weakness\n\n### W1. If we utilize the original dataset instead of the distilled data for model training, would the trigger remain effective? It would be better to include such experiments. \n\nThis is a great suggestion! We perform the experiments on CIFAR-10 and GTSRB. We first utilize the simple-trigger and relax-trigger to poison the dataset. Then, we use 3-layers ConvNet to train a model and evaluate corresponding CTA and ASR. The experimental results demonstrate that our triggers simple-trigger and relax-trigger both remain effective.\n\n| Dataset | Trigger-type | Transparency (m) | CTA (%) | ASR (%) |\n| --- |--- |--- |--- |--- |\n| CIFAR-10 | simple-trigger | 1 | 70.02 (0.40) | 100.00 (0.00) |\n| CIFAR-10 | relax-trigger | 0.3 | 70.02 (0.65) | 99.80 (0.04) |\n| CIFAR-10 | simple-trigger | 0.3 | 67.84 (0.36) | 95.50 (1.23) |\n|  |  |  |  |  ||\n| GTSRB | simple-trigger | 1 |  72.47 (3.36)|100.00 (0.00)  |\n| GTSRB | relax-trigger | 0.3 | 75.50 (2.09) | 99.82 (0.09) |\n| GTSRB | simple-trigger | 0.3 |70.21 (3.03) | 99.36 (0.20) |\n\n### W2. Can the proposed attacks evade other data distillation techniques (e.g., gradient matching based methods and distribution matching based methods)? It would further strengthen the experimental evaluation by examining the transferability of the proposed attacks.\n\nThis is a very insightful question! Our proposed attacks can evade other data distillation techniques. In particular, we perform experiments to examine the transferability of our theory-induced triggers. We first use our simple-trigger and relax-trigger to poison the dataset. Then, we distill dataest with a different distillation method, FRePo (Dataset Distillation using Neural Feature Regression. NeurIPS, 2022) and DM (Dataset condensation with distribution matching. WACV, 2023). The experimental results shows that our triggers can successfully transfer to the FrePo and DM.\n\nThe rationale is that KIP faithfully obeys the optimization problem of performance-matching dataset distillations except for our assumption that the models lie in the Reproducing Kernel Hilbert Space (RKHS). So, KIP can be a surrogate for all performance-matching dataset distillations. We believe that our KIP-based backdoor attack should evade all performance-matching dataset distillations, as suggested by our theoretical analysis.  As for other types of dataset distillations, it depends on whether there exists some kernel-like approximation or interpretation to the considered dataset distillation method. If we can find such a kernel-like approximation, then KIP should be a valid surrogate. However, how to find or construct the kernel is still an open question. To the best of our knowledge, there is no literature about this research direction that provides kernel approximation for other types of distillation. \n\n| Trigger-type | Dataset | IPC (Image Per Class)} | Distillation | Model | CTA (%) | ASR (%) |\n| ------------ | ------- | ---------------------- | ------------ | ----- | ------- | ------- |\n| Cifar10 | simple-trigger | 10 | FRePO | ConvNet | 60.32 | 83.10 |\n| Cifar10 | relax-trigger | 50 | FRePO | ConvNet | 68.34 | 81.61 |\n\n\n| Trigger-type | Dataset | IPC (Image Per Class)} | Distillation | Model | CTA (%) | ASR (%) |\n| ------------ | ------- | ---------------------- | ------------ | ----- | ------- | ------- |\n| Cifar10 | simple-trigger | 10 | DM |MLP | 36.41 | 77.03 |\n| Cifar10 | simple-trigger | 50 | DM |MLP | 36.88 | 76.79 |\n| Cifar10 | relax-trigger | 10 | DM |MLP  | 36.31 | 76.04 |\n| Cifar10 | relax-trigger | 50 | DM |MLP  | 36.81 | 76.21 |"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6151/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700607907892,
                "cdate": 1700607907892,
                "tmdate": 1700697060538,
                "mdate": 1700697060538,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]