[
    {
        "title": "Large-scale training of foundation models for wearable biosignals"
    },
    {
        "review": {
            "id": "8izZ4TM5k2",
            "forum": "pC3WJHf51j",
            "replyto": "pC3WJHf51j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5782/Reviewer_EBBD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5782/Reviewer_EBBD"
            ],
            "content": {
                "summary": {
                    "value": "The proposed work presents a self-supervised learning (SSL) method for foundation models training using a large, longitudinal, multi-year dataset of unlabelled PPG and ECG samples recorded on Apple Watch devices. The performed experiments showed that the pre-trained models can readily encode participant demographics, conditions and medication. The introduced SSL framework incorporates various techniques, such as stochastic augmentation module or participant level positive pair selection proved to behave better than segment level selection. The work flows logically with a comprehensive analysis of how well PPG and ECG embeddings encode participants' information and ablation study of various parameters used in the work. The motivation of the work is clear and the method was compared to other existing techniques proving its robustness."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1) The work proposes pre-training of foundation models to a new domain using real data, acquired in uncontrolled environment, acquired over a  long period of time, what is a good indicator of how robust the method is.\n2) Comprehensive analysis that includes comparison with other methods, linear probing to analyze how well both embeddings encode participants' information and a detailed evaluation of which one is more predictive, ablation study including analysis of visual representations after dimensionality reduction, validation loss and dispersion ratio. \n3) Presented results support claims made in the work, showing robustness of the introduced method and ability to encode participants' information.\n4) Overall the soundness and completeness of the work is good in my opinion."
                },
                "weaknesses": {
                    "value": "1) It would be great to include a figure representing the model showing encoder, MLP head and other implementation details.\n2) What was the reason for choosing the InfoNCE loss vs. e.g., the normalized temperature-scaled cross entropy loss (NT-Xent) from SimCLR?\n3) Usually large batch sizes and more learning steps are beneficial in SSL, have you experimented with even bigger batch sizes than 256?\n4) Could you clarify the reason for selecting this specific encoder and specific embedding sizes, have you experimented with other models?\n5) Are you going to make the dataset public?"
                },
                "questions": {
                    "value": "1) Would you be able to include results for PPG model trained on a smaller dataset (similar number of segments as ECG)? I believe this would be useful for comparing the behavior of the method given similar amount of data.\n2) Have you thought about using both modalities in one model? Do you think that modulating, e.g., ECG with PPG embeddings would improve accuracy? Such approaches are useful when one modality is less descriptive than the other, so I was interested in learning more about your thought of how this would apply to this use case.\n3) How easily will it be to improve the current labels given that they were acquired using self-reported metrics and tracing it back seems impossible?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5782/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698696608755,
            "cdate": 1698696608755,
            "tmdate": 1699636608362,
            "mdate": 1699636608362,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tH04tfXELo",
                "forum": "pC3WJHf51j",
                "replyto": "8izZ4TM5k2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5782/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5782/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to R-EBBD [part 1]"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their kind mention of our manuscript's strengths and pointing out a set of important modifications. We have responded to the reviewer\u2019s comment below, and have addressed them accordingly in the paper. We believe the reviewer\u2019s comments have positively improved our manuscript.\n\n> It would be great to include a figure representing the model showing encoder, MLP head and other implementation details.\n\nWe thank the reviewer for pointing this out. We have now added a high-level visualization of our pre-training framework in the **new Appendix Fig. 3**.\n\n> What was the reason for choosing the InfoNCE loss vs. e.g., the normalized temperature-scaled cross entropy loss (NT-Xent) from SimCLR?\n\nThis is a good point and we apologize for the confusion. As far as we understand, the term InfoNCE loss and NT-Xent are often used interchangeably for a similar loss function, for example, the SimCLR paper (\u201c*A Simple Framework for Contrastive Learning of Visual Representations*\u201d, Chen et al,., 2020) says \u201c*This loss has been used in previous work (Sohn, 2016; Wu et al., 2018; Oord et al., 2018); for convenience, we term it NT-Xent (the normalized temperature-scaled cross entropy loss)*\u201d and in the CPC paper (\u201c*Representation Learning with Contrastive Predictive Coding*\u201d, van den Oord et al., 2018), the same loss was termed as InfoNCE. To further clarify this, **we have now added NT-Xent term as well to where we define the loss**, \u201c*We use InfoNCE (also known as NT-Xent) to maximize the mutual information*\u201d, and we would like to clarify that the contrastive component of our loss is similar to SimCLR.\n\n> Usually large batch sizes and more learning steps are beneficial in SSL, have you experimented with even bigger batch sizes than 256?\n\nThe reviewer raises a very good point. We agree with the reviewer that larger batch sizes have been shown to be beneficial in SSL, for instance in the original SimCLR paper (Chen et al,., 2020). However, several follow up works have shown that adding momentum training and/or regularization and/or different objective functions could alleviate the need for larger batch sizes: examples are BYOL (\u201c*Bootstrap your own latent: A new approach to self-supervised Learning*\u201d, Grill et al., 2020) and Barlow Twins (\u201c*Barlow Twins: Self-Supervised Learning via Redundancy Reduction*\u201d, Zbontar et al., 2021), to name two. More importantly, a recent work has shown that it is possible to even train SimCLR on ImageNet with smaller batch sizes without an important drop in performance (\u201c*Towards Democratizing Joint-Embedding Self-Supervised Learning*\u201d, Bordes et al., 2023). To address this we have now added this to the **new Appendix A.1**: \u201c*Regarding batch size in our pre-training, while early contrastive self-supervised learning works have shown that larger batch size is necessary to improve performance (Chen et al., 2020; 2021), follow up works removed this dependency by changing the pre-training (Grill et al., 2020; Zbontar et al., 2021), and a recent work has shown that it is possible to train SimCLR on ImageNet with smaller batch sizes without an important drop in performance (Bordes et al., 2023). We also did not see meaningful change in performance with larger batch sizes in our early experiments.*\u201d\n\n> Could you clarify the reason for selecting this specific encoder and specific embedding sizes, have you experimented with other models?\n\nWe appreciate the reviewer for their careful comment. We picked the EfficientNet model architecture given its efficacy for model performance w.r.t number of parameters. However, to address the reviewer\u2019s comment, we did a **new Ablation 5.2.4** and a **new Table 4** by comparing the performance of our default 1D-EfficientNet model with our variation of 1D-ResNet and 1D-ViT to enable comparison with alternative model architectures and model sizes: \u201c*For comparisons, we used smooth effective rank as a crude proxy of general downstream performance, and observed that different encoder architectures, with different model sizes, can achieve relatively similar performance, demonstrating that the performance is not unique to the 1D-EfficientNet encoder architecture (Table 4). We observed that 1D-EfficientNet model yielded similar performance to these alternative encoders with significantly smaller number of parameters, which was one of the main reasons we picked 1D-EfficientNet as our default backbone encoder given less memory footprint when potentially running on a wearable device. An interesting future direction is scaling up the model size further, particularly with transformer-based models (e.g., 1D-ViT) given their scalability (Kaplan et al., 2020), and larger datasets to study its effect on downstream performance*\". Also regarding the embedding size, in our early experiments, we investigated larger and smaller embedding sizes and 256 offered a reasonable sweet point and we did not tune it further afterwards."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5782/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700355143054,
                "cdate": 1700355143054,
                "tmdate": 1700355143054,
                "mdate": 1700355143054,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BGAFnpicFB",
            "forum": "pC3WJHf51j",
            "replyto": "pC3WJHf51j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5782/Reviewer_FYDu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5782/Reviewer_FYDu"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a significant advancement in the domain of health monitoring using wearable devices, specifically focusing on the tracking of biosignals, namely photoplethysmography (PPG) and electrocardiogram (ECG). Recognizing the potential of these biosignals, the authors highlight a major challenge: the lack of large, curated datasets with medically annotated labels for developing neural network-based biomarkers. To circumvent this, they leverage the Apple Heart and Movement Study (AHMS) and harness a self-supervised learning framework for training foundation models on PPG and ECG data from approximately 141,207 participants over a span of three years. This self-supervised approach integrates a participant level positive pair selection, stochastic augmentation, and a regularized contrastive loss optimized through momentum training. The authors demonstrate that these pre-trained models encode substantial information related to participant demographics and health conditions. Notably, this work distinguishes itself as the pioneering effort in building foundation models for PPG and ECG using large-scale data sourced from consumer wearables, as opposed to traditionally smaller datasets from clinical settings. The potential applications of these models are vast, with implications for enhancing wearable device capabilities, reducing reliance on labeled data, and ultimately benefiting users' health."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strengths:\n1. **First Work on Foundation Models for Wearable Biosignals**:\nThe research stands out as the pioneering effort to develop foundation models specifically for biosignals\u2014photoplethysmography (PPG) and electrocardiogram (ECG)\u2014collected via wearable devices. Such biosignals offer a treasure trove of biological and cardiac information, which can be instrumental in monitoring users' overall health. The convenience of wearable devices combined with the potential of these foundation models paves the way for continuous health tracking without disrupting daily routines, potentially leading to the early detection of health issues.\n\n2. **Extensive Evaluation Using Linear Probing**:\nThe authors conducted a comprehensive evaluation of the trained models using linear probing for a plethora of tasks. This includes gender classification, age prediction, and both classification and regression for Body Mass Index (BMI). Furthermore, they delved into predicting variables extracted from questionnaires, providing a holistic understanding of the models' capabilities. The utilization of smooth effective rank as an evaluative measure underscores the robustness of the evaluation.\n\n3. **Participant Level vs. Segment Level Positive Pairs**:\nAn intriguing facet of the research was the comparison between participant level and segment level positive pairs. This distinction is crucial because the granularity at which positive pairs are chosen can significantly impact the model's performance. The exploration of this dimension offers valuable insights into the optimal approaches for training foundation models on biosignals.\n\n4. **Benchmarking with Other SSL Methods**:\nTo validate the efficacy of their approach, the authors benchmarked their models against established self-supervised learning (SSL) methods, such as SimCLR and BYOL. Such a comparative analysis not only situates the research within the broader landscape of SSL but also provides tangible metrics to gauge the relative performance of their models.\n\n5. **Curation of a Large Dataset**:\nOne of the paper's major contributions is the meticulous curation of a vast dataset from the Apple Heart and Movement Study (AHMS) for the training of foundation models. With data spanning approximately 141,207 participants over three years, the effort required to curate, clean, and prepare such a dataset for effective training cannot be understated. This endeavor not only underscores the thoroughness of the research but also sets a precedent for future studies aiming to leverage large-scale datasets for health applications."
                },
                "weaknesses": {
                    "value": "Areas for improvement:\n\n1. **Exploration of KoLeo Regularization**:\nAn area of potential exploration is the specific impact of the KoLeo regularization on the model's performance. Ablation studies that incrementally remove or vary the strength of KoLeo regularization could provide clarity on its role and efficacy. Such an analysis would help in understanding whether the regularization is crucial for the model's success, and to what extent it contributes to the overall performance. This is particularly important as the unique characteristics of biosignals may interact with regularization techniques differently compared to other domains.\n\n2. **Inclusion of All Results**:\nTransparency and completeness in research reporting are essential for reproducibility and peer review. Therefore, it is recommended that the authors include all results, particularly those referenced as \"results not shown\" within the main body of the paper or the appendix. Having access to these results would allow the scientific community to fully evaluate the findings, methodologies, and claims made within the paper. It would also enhance the credibility and utility of the work for those looking to build upon it.\n\n3. **Augmentation Impact Analysis**:\nThe paper would benefit from a deeper dive into the effects of various augmentation techniques on the performance of the biosignal models. Unlike image data, where the impact of different augmentations is well-studied, the domain of biosignals remains relatively unexplored in this aspect. An appendix providing detailed results and analysis of how different augmentations influence the learning process would be invaluable. This could include which augmentations contribute most to model robustness or performance, and any augmentation-specific phenomena observed with biosignals. Given the novelty of the field, such insights could be highly influential for future research in biosignal analysis.\n\n4. **Demographic details missing**: The paper would benefit greatly from a more detailed presentation of demographic information related to the participants whose data underpin the foundation models. Such information is essential for assessing the diversity and representativeness of the dataset, which in turn, influences the generalizability of the model across various populations. The current omission of granular demographic details leaves a gap in understanding the scope of the model's applicability. It is recommended that the authors include statistics on age, gender, ethnicity, and other pertinent demographic factors. This would not only enhance the transparency of the research but also allow for a more nuanced evaluation of the model's performance across different demographic groups."
                },
                "questions": {
                    "value": "**Concern Regarding Dataset Availability**:\nThe dataset from the Apple Heart and Movement Study (AHMS) is central to this research, offering immense value to the broader scientific community. However, the paper doesn't clarify if the dataset will be open-sourced upon acceptance. The release of this dataset, along with the associated models and code, is pivotal for reproducibility and further research.\n\nIf the authors don't have ownership of the dataset, detailed instructions on sourcing it would be essential. I kindly request clarity on this matter, as it will influence my final assessment of the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Discrimination / bias / fairness concerns"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "**Demographic details missing**: The paper would benefit greatly from a more detailed presentation of demographic information related to the participants whose data underpin the foundation models. Such information is essential for assessing the diversity and representativeness of the dataset, which in turn, influences the generalizability of the model across various populations. The current omission of granular demographic details leaves a gap in understanding the scope of the model's applicability. It is recommended that the authors include statistics on age, gender, ethnicity, and other pertinent demographic factors. This would not only enhance the transparency of the research but also allow for a more nuanced evaluation of the model's performance across different demographic groups."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5782/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814333211,
            "cdate": 1698814333211,
            "tmdate": 1699636608232,
            "mdate": 1699636608232,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PWPak5Wvpa",
                "forum": "pC3WJHf51j",
                "replyto": "BGAFnpicFB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5782/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5782/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to R-FYDu [part 1]"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for supporting our manuscript, carefully detailing its strengths, and their thoughtful suggestions. We have responded to the reviewer\u2019s comment below, and have addressed them accordingly in the paper. We believe the reviewer\u2019s comments have positively improved our manuscript.\n\n> An area of potential exploration is the specific impact of the KoLeo regularization on the model's performance. Ablation studies that incrementally remove or vary the strength of KoLeo regularization could provide clarity on its role and efficacy. Such an analysis would help in understanding whether the regularization is crucial for the model's success, and to what extent it contributes to the overall performance. This is particularly important as the unique characteristics of biosignals may interact with regularization techniques differently compared to other domains.\n\nWe thank the reviewer for pointing this out. We have now performed an experiment where we dropped KoLeo regularization from our pre-training framework to study its importance in isolation. As detailed in the **updated Table 3** and **updated Appendix Table 12**, we observed that removing KoLeo regularization from our pre-training resulted in a drop in performance, evaluated with smooth effective rank and downstream demographic variables\u2019 prediction, for both PPG and ECG. This demonstrates the specific impact of KoLeo regularization and we have now added to the paper: \u201c*We observed that for both PPG and ECG modalities, removing KoLeo regularization from our objective function resulted in reduced evaluation metrics (Table 3 and Appendix Table 12), demonstrating its impact on the model\u2019s performance*\u201d.\n\n> Transparency and completeness in research reporting are essential for reproducibility and peer review. Therefore, it is recommended that the authors include all results, particularly those referenced as \"results not shown\" within the main body of the paper or the appendix. Having access to these results would allow the scientific community to fully evaluate the findings, methodologies, and claims made within the paper. It would also enhance the credibility and utility of the work for those looking to build upon it.\n\nThis is an important point. We have now added the following to the manuscript, providing further information and evidence: 1) **new Appendix Table 10**, including downstream performance evaluation of PPG and ECG embeddings in predicting demographic variables when the number of pre-training segments in PPG is similar to that for ECG in Table 1, 2) **new Appendix Table 11**, including demographic variables\u2019 performance evaluation calculated at segment-level granularity, where each segment contributes one and only one sample in the downstream training/evaluation. \n\n> The paper would benefit from a deeper dive into the effects of various augmentation techniques on the performance of the biosignal models. Unlike image data, where the impact of different augmentations is well-studied, the domain of biosignals remains relatively unexplored in this aspect. An appendix providing detailed results and analysis of how different augmentations influence the learning process would be invaluable. This could include which augmentations contribute most to model robustness or performance, and any augmentation-specific phenomena observed with biosignals. Given the novelty of the field, such insights could be highly influential for future research in biosignal analysis.\n\nWe appreciate the reviewer for this thoughtful comment. We have now added details about the selection of our augmentation functions/probabilities in the **new Appendix section A.1** and have done a **new Ablation 5.2.5** with the **new Appendix Fig. 7** regarding the effect of single augmentation functions in our pre-training framework: \u201c*We studied the effect of single augmentation functions for each modality. To do so, for both PPG and ECG, we kept each of the augmentation functions in isolation separately (with probability 1), and repeated our pre-training framework from scratch. We observed that PPG pre-training was more sensitive to the choice of single augmentation functions (more variance in performance), and channel permute and cut out were the most effective augmentation functions in isolation for PPG and ECG, respectively (Appendix Fig. 7). Future work can study more optimal ways to design modality-specific augmentation modules*\u201d."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5782/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700354942684,
                "cdate": 1700354942684,
                "tmdate": 1700354942684,
                "mdate": 1700354942684,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JNidp3azEW",
            "forum": "pC3WJHf51j",
            "replyto": "pC3WJHf51j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5782/Reviewer_UQ5r"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5782/Reviewer_UQ5r"
            ],
            "content": {
                "summary": {
                    "value": "This paper employs self-supervised learning (SSL) on a large dataset comprising two types of data: photoplethysmography (PPG) and electrocardiogram (ECG) collected from the Apple Watch. The self-supervised learning is carried out on a comprehensive dataset, encompassing a vast span of 141K subjects.\nSubsequently, the authors investigate various modules within the SSL framework to glean practical insights. They also elaborate on the effects of certain design choices, such as the selection of positive-negative pairs and data augmentation strategies.\nThe authors conducted a thorough evaluation and ablation studies for the foundational model they developed. The learned embeddings demonstrate predictive power across a wide array of downstream tasks, such as predicting demographic features and survey questions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-articulated. The authors clearly presented the proposed method, experimental setup, and analysis.\n\n- To the best of my knowledge, this represents the first attempt at training a self-supervised learning (SSL) foundational model for PPG and ECG data on such a grand scale. The results from this process offer valuable scientific insights.\n\n- The authors conducted an exhaustive evaluation of the pretrained models. These pretrained embeddings were assessed against more than 50 diseases."
                },
                "weaknesses": {
                    "value": "- There are potential concerns on the technical methodology front. While this study is the product of extensive training and evaluation, much of the methodology draws from pre-existing studies. Although there are several SSL studies tailored for time-series data, particularly in the realm of biosignals in healthcare, the authors did not extensively compare different model architectures. Readers might be keen to discern whether biosignal SSL performance is more contingent upon scale or the model architecture itself.\n\n- While this study encompasses two modalities, it seems that the authors have considered them in isolation. Pretrained models have shown effectiveness across varied modalities like images and language. It would be beneficial for the authors to delve deeper into this aspect.\n\n- The pretrained embedding for PPG appears to encapsulate more information than its ECG counterpart. This raises a question: given that PPG is passively sampled and ECG is actively collected by users, could this disparity in data collection methods influence such an outcome? Additionally, conventional clinical diagnoses often rely on 12-lead ECG or periodic information like HRV derived from ECG. It would be valuable if the authors could elucidate more why the ECG embedding doesn't seem as informative as the PPG.\n\n- Lastly, the authors note that positive pairs are drawn from the same individual. However, a person's PPG and ECG patterns can vary based on different conditions or circumstances. It might be more insightful for the authors to determine positive pairs by taking additional attributes into account."
                },
                "questions": {
                    "value": "- Even if the authors intend to display only aggregated information, it would be beneficial for them to include a representative visualization of both PPG and ECG signals. This would provide readers, especially those without a healthcare background, with a clearer understanding.\n\n- In Figure 2, both PPG and ECG embeddings demonstrate good separability based on subject IDs. However, I'm curious if two subjects with similar demographic attributes should be distinctly separated.\n\n- While ECG and PPG are pivotal for evaluating physiological status, there are also numerous other parameters to consider, such as HRV, heart rate, and possibly activity levels. The authors might wish to discuss this aspect further."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No concerns"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5782/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817828487,
            "cdate": 1698817828487,
            "tmdate": 1699636608130,
            "mdate": 1699636608130,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "OSEeA5Jl59",
                "forum": "pC3WJHf51j",
                "replyto": "JNidp3azEW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5782/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5782/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to R-UQ5r [part 1]"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer\u2019s feedback, their kind words about the strengths of our work, and their careful examination of our manuscript. We have responded to the reviewer\u2019s comment below, and have addressed them accordingly in the paper. We believe the reviewer\u2019s comments have positively improved our manuscript.\n\n> There are potential concerns on the technical methodology front. While this study is the product of extensive training and evaluation, much of the methodology draws from pre-existing studies. Although there are several SSL studies tailored for time-series data, particularly in the realm of biosignals in healthcare, the authors did not extensively compare different model architectures. Readers might be keen to discern whether biosignal SSL performance is more contingent upon scale or the model architecture itself.\n\nWe thank the reviewer for their thoughtful comment. First, we agree with the reviewer that our study is the product of \"*extensive training and evaluation*\". We would like to emphasize that \u201c*biosignal SSL*\u201d is largely under-explored at this scale compared to other domains of deep learning and there are no universally-agreed-upon model for wearable biosignals (PPG/ECG) that we can really compare our models to. However, to address the reviewer\u2019s comment, we did a **new Ablation 5.2.4** and **new Table 4** by comparing the performance of our default 1D-EfficientNet model with our variation of 1D-ResNet and 1D-ViT to enable comparison with alternative model architectures and model sizes. As we mentioned in text with different model sizes, different model architectures can reach to reasonable accuracies addressing reviewer\u2019s point about \u201c*SSL performance is more contingent upon scale or the model architecture itself*\u201d. We now also mention that: \u201c*For comparisons, we used smooth effective rank as a crude proxy of general downstream performance, and observed that different encoder architectures, with different model sizes, can achieve relatively similar performance, demonstrating that the performance is not unique to the 1D-EfficientNet encoder architecture (Table 4). We observed that 1D-EfficientNet model yielded similar performance to these alternative encoders with significantly smaller number of parameters, which was one of the main reasons we picked 1D-EfficientNet as our default backbone encoder given less memory footprint when potentially running on a wearable device. An interesting future direction is scaling up the model size further, particularly with transformer-based models (e.g., 1D-ViT) given their scalability (Kaplan et al., 2020), and larger datasets to study its effect on downstream performance*\".\n\n> While this study encompasses two modalities, it seems that the authors have considered them in isolation. Pretrained models have shown effectiveness across varied modalities like images and language. It would be beneficial for the authors to delve deeper into this aspect.\n\nThis is a great point. We respectfully believe that multi-modal pre-training, similar to CLIP (\u201c*Learning Transferable Visual Models From Natural Language Supervision*\u201d, Radford & Kim et al., 2021) is beyond the scope of our current work, and merits a separate detailed investigation on its own. However, we agree with the reviewer that this is an interesting future direction and we have now added this as a potential future direction in the **updated Discussion** section: \"*Another future area of investigation of investigation is multi-modal pre-training by: 1) using a multi-modal encoder that takes multiple modalities (e.g., PPG and ECG) as input, 2) or CLIP-style multi-modal pre-training by supervising one modality with another one (Radford et al., 2021), or training multiple encoders for multiple modalities simultaneously (Girdhar et al., 2023), using a contrastive loss*\"."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5782/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700354579971,
                "cdate": 1700354579971,
                "tmdate": 1700354579971,
                "mdate": 1700354579971,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JFXPHINAB3",
            "forum": "pC3WJHf51j",
            "replyto": "pC3WJHf51j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5782/Reviewer_4W8A"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5782/Reviewer_4W8A"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduced foundation models for wearable sensor data using a large-scale population dataset of ECG and PPG signals. Its embeddings demonstrate generalization across an array of downstream tasks related to personalization and health inferences."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Important domain with very limited available models \n- Solid results across an impressive array of downstream tasks\n- Careful tuning and experimentation considering the idiosyncrasies of the data"
                },
                "weaknesses": {
                    "value": "- Some missing references and links to previous works\n- Lack of discussion around scaling up the proposed models \n- No discussion around model/data release"
                },
                "questions": {
                    "value": "- The paper could better address previous research. For example, it claims that previous works employed biosignals recorded in clinical or controlled experimental settings, however, both [1] and [2] used large-scale _free-living_ datasets in the wild. \n\n- Regarding the augmentations, it is not clear whether assigned probabilities are found through hyper-parameter tuning or heuristics. I point the authors to this paper for further experimental decisions about the order and impact of these augmentations [3].\n\n- There are very limited details about the availability of the dataset. Should we just assume it is private? Are there any public datasets that we could replicate (some of) the results of the paper? I would appreciate any discussion around these points.\n\n- Given the number of participants, the paper could also attempt to increase the sequence length of the signals and assess whether longitudinal/day-level temporal dynamics can impact downstream tasks.\n\n- The linear probing results and performance analysis should be put in context to previous works like [4], [2], and [5].\n\n- The parameter size of the final model seems quite low considering the dataset size and number of participants. The paper could justify the word \"foundation model\" in its title by scaling up the experiments. For example, it should have been very exciting to find the Chinchilla-optimal parameter size for this sort of data. I would appreciate any discussions here around this topic, are there overfitting issues with bigger models? What about different architectures like Transformers?\n\n[1] Yuan, H., Chan, S., Creagh, A. P., Tong, C., Clifton, D. A., & Doherty, A. (2022). Self-supervised learning for human activity recognition using 700,000 person-days of wearable data. arXiv preprint arXiv:2206.02909.\n\n[2] Spathis, D., Perez-Pozuelo, I., Brage, S., Wareham, N. J., & Mascolo, C. (2021, April). Self-supervised transfer learning of physiological representations from free-living wearable data. In Proceedings of the Conference on Health, Inference, and Learning (pp. 69-78).\n\n[3] Tang, C. I., Perez-Pozuelo, I., Spathis, D., & Mascolo, C. (2020). Exploring contrastive learning in human activity recognition for healthcare. arXiv preprint arXiv:2011.11542.\n\n[4] Wu, X., Huang, C., Robles-Granda, P., & Chawla, N. V. (2022). Representation learning on variable length and incomplete wearable-sensory time series. ACM Transactions on Intelligent Systems and Technology (TIST), 13(6), 1-21.\n\n[5] Hallgr\u00edmsson, H. T., Jankovic, F., Althoff, T., & Foschini, L. (2018). Learning individualized cardiovascular responses from large-scale wearable sensors data. arXiv preprint arXiv:1812.01696."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5782/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699056285983,
            "cdate": 1699056285983,
            "tmdate": 1699636608018,
            "mdate": 1699636608018,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5hpquJUfa8",
                "forum": "pC3WJHf51j",
                "replyto": "JFXPHINAB3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5782/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5782/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to R-4W8A [part 1]"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer\u2019s feedback, their kind words about the strengths of our work, and their careful examination of our manuscript. We have responded to the reviewer\u2019s comments below, and have addressed them accordingly in the paper. We believe the reviewer\u2019s comments have positively improved our manuscript.\n\n> The paper could better address previous research. For example, it claims that previous works employed biosignals recorded in clinical or controlled experimental settings, however, both [1] and [2] used large-scale free-living datasets in the wild.\n\nWe thank the reviewer for pointing out an improvement regarding this. We would like to clarify that throughout the manuscript, we had meant to claim that our manuscript is the first study on \u201c*large-scale PPG and ECG data*\u201d, however, we agree with the reviewer that some of the mentioned work could have been better discussed in our paper, and **we have made improvements to the Introduction and Related work sections** to address the reviewer\u2019s comment about the prior work and to include them. The changes for this comment are: \n\n- We modified the Introduction section: \u201c*Self-supervised learning often does not require explicit labels, making it suitable to pre-train foundation models on unlabeled biosignals, and has been recently proven successful for health applications (Hallgrimsson et al., 2018; Cheng et al., 2020; Kostas et al., 2021; Sarkar & Etemad, 2022; Mohsenvand et al., 2020; Gopal et al., 2021; Kiyasseh et al., 2021; Mehari & Strodthoff, 2022; Wu et al., 2020; Spathis et al., 2021; Tang et al., 2021; Yuan et al., 2023; Lai et al., 2023). While there have been recent efforts to apply SSL on wearable accelerometer data in free-living conditions (Spathis et al., 2021; Yuan et al., 2023), other SSL work have mostly used biosignal modalities such as PPG, ECG, and electroencephalogram (EEG) collected in clinical or controlled experimental settings (Cheng et al., 2020; Kostas et al., 2021; Sarkar & Etemad, 2022; Mohsenvand et al., 2020; Gopal et al., 2021; Kiyasseh et al., 2021; Mehari & Strodthoff, 2022; Lai et al., 2023)*\u201c.\n\n- We modified the Related work section: \u201c*Recent work have used self-supervised learning for wearable accelerometer signals in free-living conditions and large dataset (Spathis et al., 2021; Yuan et al., 2023)*\u201d.\n\n- We would like to respectfully clarify that we still believe our claim in Abstract \u201c*To the best of our knowledge, this is the first study that builds foundation models using large-scale PPG and ECG data collected via wearable consumer devices \u2014 prior works have commonly used smaller-size datasets collected in clinical and experimental settings.*\u201d is still accurate in consideration of the works the reviewer has mentioned as they use accelerometer data, which is a different modality compared to PPG/ECG.\n\n> Regarding the augmentations, it is not clear whether assigned probabilities are found through hyper-parameter tuning or heuristics. I point the authors to this paper for further experimental decisions about the order and impact of these augmentations [3].\n\nWe thank the reviewer for this careful comment. We have now added details about the selection of our augmentation functions/probabilities in the **new Appendix section A.1** and have done a **new Ablation 5.2.5** with **new Appendix Fig. 7** regarding the effect of single augmentation functions in our pre-training framework. We now mention that \u201c*we did not comprehensively tune our augmentation module probabilities, we started with a preliminary set of probabilities in our early experiments based on prior work (Cheng et al., 2020; Tang et al., 2021), for instance, cut out was shown to be the most effective augmentation in (Cheng et al., 2020) and we assigned a higher probability to it. We did not tune these probabilities afterwards and the only change made was to make the ECG augmentation probabilities stronger (2x probability) to allow for more mismatch between positive pair representations*\u201d and that \u201c*we studied the effect of single augmentation functions for each modality. To do so, for both PPG and ECG, we kept each of the augmentation functions in isolation separately (with probability 1), and repeated our pre-training framework from scratch. We observed that PPG pre-training was more sensitive to the choice of single augmentation functions (more variance in performance), and channel permute and cut out were the most effective augmentation functions in isolation for PPG and ECG, respectively (Appendix Fig. 7). Future work can study more optimal ways to design modality-specific augmentation modules*\u201d."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5782/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700353993943,
                "cdate": 1700353993943,
                "tmdate": 1700353993943,
                "mdate": 1700353993943,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]