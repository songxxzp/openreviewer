[
    {
        "title": "Are machines automating morality?"
    },
    {
        "review": {
            "id": "ka64k1P21q",
            "forum": "dKPzWyaOsK",
            "replyto": "dKPzWyaOsK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5717/Reviewer_CCc6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5717/Reviewer_CCc6"
            ],
            "content": {
                "summary": {
                    "value": "The core concept of the article is the fact that machines automate moral decisions. The authors \u00ab\u00a0try to highlight the prevailing utilitarian ethics found in the tech-centric Silicon Valley culture and its influence on the development of artificial intelligence\u00a0\u00bb. The authors defend the idea that machine learning, nowadays, is driven by utilitarian behavior. The authors examine the ethical implications of machine learning shaping the moral background of society."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The topic of abandoning the burden of making moral choices and leaving those choices in the hands of machine-learning models is really important and should be more discussed in the machine-learning community."
                },
                "weaknesses": {
                    "value": "1 \u2013 The biggest flaw, in my opinion, is how the article is written on a fine-grained level.\n\n1.1 \u2013 The quality of the writing in general needs to be upgraded. For example, some sentences aren\u2019t grammatically valid: \u00ab\u00a0The problem that stems today from machine learning [...]\u00a0\u00bb, or \u00ab\u00a0Such was even named the study conducted by researchers [\u2026]\u00a0\u00bb. \n\n1.2 - Some references are simply wrong. For example: \u00ab\u00a0According to the Kantian mantra \u201cLive your life as though your every act were to become a universal law\u201d (Kant, 2007) in Critique of Pure Reason, [...]\u00a0\u00bb is wrong, for Kant\u2019s mantra first appeared in his Groundwork of the Metaphysics of Morals. Some sentences are conflicting. For example: \u00ab\u00a0As they do so, a question emerges: Do machines have morals? If so, can they learn about morality?\u00a0\u00bb VS \u00ab\u00a0The problem that stems today from machine learning is that these \u201dmachines\u201d can learn their own morals in an unsupervised way\u00a0\u00bb or \u00ab\u00a0We present the current morality of AI, which [...]\u00a0\u00bb or \u00ab\u00a0These philosophical and psychological questions about the supposed morality of such machines\u00a0\u00bb, etc. Another sentence that is false: \u00abIn the banking sector, algorithms have largely replaced traditional methods of determining loan eligibility \u00bb; algorithms have always been around in insurance; it is the emergence of deep learning or any other black-box in loan eligibility that is new. Finally: \u00ab\u00a0By definition, morality seems to be automatable. Following Kant\u2019s maxim, we could argue that this is the only way to guarantee its value. An action is moral if and only if it is automatable.\u00a0\u00bb The two first sentences argue for the implication \u00ab\u00a0if X is moral, then X is automatable\u00a0\u00bb, but the last sentence talks about an if and only if, which, in logic (and philosophy), means both an implication and an inverse implication. But it is not because an action is automatable that it is moral.\n\n1.3 - \u00ab\u00a0By definition, [Kant\u2019s] morality seems to be automatable.\u00a0\u00bb But isn\u2019t all sort of morality automatable? Consequentialist morality could use a proxy for computing the good and bad produced by an event.\n\n1.4 \u2013 No rigorous definition of the terms at hand is given. For example, a definition of morality VS ethics was necessary. Or machine learning vs AI vs algorithm, which was only briefly discussed on page 4, after many references to these concepts. Also, there seems to be a lack of understanding of the concepts at hand: \u00ab\u00a0In machine learning, artificial intelligence learns [...]\u00a0\u00bb or \u00abIn the banking sector, algorithms have largely replaced traditional methods of determining loan eligibility\u00a0\u00bb.\n\n1.5 \u2013 Some sentences lack clarity. For example: \u00ab\u00a0in the banking sector, algorithms have largely replaced traditional methods of determining loan eligibility, leading to moral dilemmas akin to the \u201dtrolley problem\u201d\u00a0\u00bb; what is the link between those two situations? Another example would be \u00ab\u00a0Silicon Valley\u2019s new mantra is WYSIWYG: \u201dwhat you see is what you get\u201d. And yet, by brandishing WYSIWYG as its sole political horizon, Silicon Valley delegitimizes in advance any critical reflection on technological innovations and the meaning attached to them (Alloa & Soufron, 2019).\u00a0\u00bb There is a lack of explanation and discussion.\n\n2.1 \u2013 Some sentences are vague, questionable, or lack groundings. For example, \u00ab\u00a0Individuals will be more and more dependent on automated systems making moral decisions for them. Therefore, this artificial morality will become the only moral values represented within society.\u00a0\u00bb is purely a slippery slope. Whereas, sentences such as \u00ab\u00a0in the banking sector, [black boxes] have largely replaced traditional methods of determining loan eligibility\u00a0\u00bb aren\u2019t supported. Some sentences such as \u00ab\u00a0We have proved so far that moral values are becoming automated in certain specific sectors\u00a0\u00bb do not leave any place to interpretation, while the claim has not actually been \u00ab\u00a0proven\u00a0\u00bb, but simply defended. In social sciences, it is dangerous to state that something has been \u00ab\u00a0proven\u00a0\u00bb. \n\n2.2 \u2013 The core of the article is centered around AI being utilitarian. A single citation is used to assess this point, along with a single argument, which is far from being convincing. Plus, the reasoning is doubtful: \u00ab\u00a0consequentialist morality [\u2026] has dominated debates and infused current technological developments (Salvat, 2020). As a result, utilitarianism has become the dominant morality in Silicon Valley\u00a0\u00bb: it might have infused technologies, but why assume that because of that it is **dominant** in Silicon Valley? Plus, Silicon Valley is responsible for many technologies that we manipulate in our daily lives, but the example of the loan approval is a good example of something that has huge consequences on the lives of many people, yet does not stem from Silicon Valley. Finally, this last example illustrates how consequentialist vision is not that dominant in AI: we want the models in insurance to be fair and not racist, this criterion being $\\textit{a priori}$.\n\n3 - It is unacceptable, in such work, not to discuss \u00ab\u00a0interpretability\u00a0\u00bb or \u00ab\u00a0explainability\u00a0\u00bb in AI, for such topics exactly aim at understanding the decision process of the predictor and currently generate tons and tons of research. Statements such as \u00ab\u00a0[w]ith each moral question addressed by machine learning, we delegate our moral authority.\u00a0\u00bb are not true, for it only (and questionably) holds when it comes to black boxes (some other term that would definitely need to be discussed in such work) in machine learning. Machine learning yielding simple predictors, understandable by human beings could potentially be approved by them.\n\n4 \u2013 It is hard to understand the original contribution of the work with regards to the current literature, for most of the ideas in this work are supported by works from the literature; I don\u2019t feel like new or novel thoughts have been brought, or thoroughly defended and argued, therefore questioning the overall contribution of the work."
                },
                "questions": {
                    "value": "See the \u00ab\u00a0Weaknesses\u00a0\u00bb section of the review."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Reviewer_CCc6"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5717/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698344410043,
            "cdate": 1698344410043,
            "tmdate": 1699636597978,
            "mdate": 1699636597978,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5Jb0qEMvB4",
                "forum": "dKPzWyaOsK",
                "replyto": "ka64k1P21q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5717/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5717/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer, thank very much you for your very detailed comments about our paper.\nPlease find our responses to your comments in the following order:\n\n1 -\n\n1.1 - You are right, we have tried to make the writing more coherent and to improve the accuracy of grammar and expression.\n\n1.2 - Kant have developed his categorical imperative in various texts, including Critique of Pure Reason. However, you are right, he developed it for the first time in the Groundwork of the Metaphysics of Morals. We have corrected it. \n\nWe have also made corrections about the conflicting sentences. We have introduced the notion of \u201cblack box\u201d in the Introduction. However, we have removed the sentence about the banking system. It was confusing and not really relevant to our subject here.\nFinally, we have indeed corrected this implication, the reverse of which does not hold true. \n\n1.3 - Absolutely. However, we have added the notion of moral \"absolutism\", which differentiates Kantian morality from consequentialist morality. Kantian morality is valid for everyone at all times, whereas consequentialist morality is concerned with context and purpose.\n\n1.4 - You are right, there was a lack of definitions, which made the argumentation unclear. We briefly introduced some distinctions in the introduction. However, while these three terms cover different realities, they share the objective of automation (to a greater or lesser extent). It is this automation in general that we are dealing with here, even if we realize that there are differences at various points. We prefer to speak of \"automated systems\" or \"models\".\n\n1.5 - As mentioned above, we have decided to remove the sentence on the banking sector.\nWe have extended and integrated into a \"Discussion\" section the questions surrounding the ideology of Silicon Valley.\n\n2.1 - \"Proving\" something is obviously debatable in philosophy. We were using this term in the \"philosophical\" sense of having tried to prove our point with logical arguments. We're aware that this term can be confusing, so we've modified it and added more of the conditional tense.\n\n2.2 - Thank you for your detailed and constructive comment. With regard to the utilitarian aspect of Silicon Valley, we are of course aware that many innovations do not originate in Silicon Valley. Our purpose here is to focus on this particular and crucial place when talking about technological innovations.\nWe have also briefly compared the Chinese technological ecosystem, in which the ideological aspect plays an important role.\nFinally, from our point of view, insurance models are not designed not to be racist, but to provide the best outcome. They are utilitarian in their functioning. We try to discuss this view in our paperr\n\n3 - This discussion was indeed missing from our paper. We have therefore introduced this issue first in the introduction and then at various points. We are not experts in the various types of models, and in this paper we are mainly concerned with models that cannot be interpreted or explained. We are aware, though, that the question of interpretability does not apply to simpler models.\n\n4 - We have reorganized our paper to dedicate part of our work to a discussion in which we seek to further defend a point of view.\n\nWe would like to thank you again for all your comments. We hope to have responded satisfactorily."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5717/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680841045,
                "cdate": 1700680841045,
                "tmdate": 1700680841045,
                "mdate": 1700680841045,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "i3cKLwok3L",
            "forum": "dKPzWyaOsK",
            "replyto": "dKPzWyaOsK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5717/Reviewer_ju5e"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5717/Reviewer_ju5e"
            ],
            "content": {
                "summary": {
                    "value": "This paper provides a philosophical analysis of machine morality, starting from the discussion of if moral values can be gained without explicit human intervention. Then the meaning of moral machines, and the real-world problems that a moral machine might encounter (e.g., the trolley problem). The paper concludes with, \"We still need to have individuals in the decision-making process.\""
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This paper is well-written, or very well-written compared to other machine learning conference submissions, with a clear thesis statement and detailed philosophical analysis and references to discuss the topic of moral machines. This topic is also rapidly developing in the current emergent large language model usage in more and more decision-making domains. \n\n- The idea of moral machines, artificial morality and/or automated morality is also a good question posed in this paper. Some previous arguments and experimental evidence (e.g., the constitutional ai or other alignment from ai-feedback work) can also support this.\n\n- This paper gives some interesting points for researchers in this field to focus on, for example, the baby or elderly debate. This kind of question can also be generalized to what morality/values current AI models hold and whether current AI alignment biases too much to WEIRD (Western, Educated, Industrialized, Rich, and Democratic) populations [A].\n\nref: \n\n[A]. Atari, M., Xue, M. J., Park, P. S., Blasi, D. E., & Henrich, J. (2023, September 22). Which Humans?. https://doi.org/10.31234/osf.io/5b26t"
                },
                "weaknesses": {
                    "value": "The most uncertainty I have encountered reviewing this paper is whether this paper fits the ICLR community. Although machine morality is undeniably a significant and rising field in the current learning community, ICLR focuses mostly on technical contributions. I am not sure if this paper actually satisfies ICLR standards (it looks more to me like a Nature Opinion/The New Yorker/or other philosophy conferences), so it might need the Area Chair to judge this paper's suitability. Meanwhile, the paper limit is nine pages (now it's less than six pages), so some additional discussion can be added."
                },
                "questions": {
                    "value": "See strength & weaknesses. I have no further questions besides the fitness to the ICLR community."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Reviewer_ju5e"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5717/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698719691672,
            "cdate": 1698719691672,
            "tmdate": 1700546076312,
            "mdate": 1700546076312,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "69XsyrwCwi",
                "forum": "dKPzWyaOsK",
                "replyto": "i3cKLwok3L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5717/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5717/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer, thank you very much for your feedback on our paper and your positive appreciation of it. As you pointed out, there was still room for discussion. We have reorganized and lengthened the paper to make this discussion clear.\n\nOur motivation for proposing this paper is the necessary interaction between research in philosophy and research in machine learning on such crucial topics."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5717/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680688002,
                "cdate": 1700680688002,
                "tmdate": 1700680688002,
                "mdate": 1700680688002,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6cS7UpHmg3",
            "forum": "dKPzWyaOsK",
            "replyto": "dKPzWyaOsK",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5717/Reviewer_X5KS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5717/Reviewer_X5KS"
            ],
            "content": {
                "summary": {
                    "value": "The paper reviews the literature around moral decision making and automated systems and says we should think about it more."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The authors present a good narrative that is supported by the literature."
                },
                "weaknesses": {
                    "value": "This is just a discussion of the current state of the literature. The review is short and asks many questions without attempting to answer them or present new research directions. As the paper is not at the word limit this shortness is by implication due to the authors believing it was sufficient.\n\nAs an example the last paragraph of the main body ends with \"perhaps implying a limitation in the learning of moral values.\" If the authors expanded on this and took a position then there might be a paper. Instead they just summarize existing papers. Section 3 for example is just as summary of the moral machines problem and research."
                },
                "questions": {
                    "value": "What is the research question of this paper? And how is it addressed in a novel way?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5717/Reviewer_X5KS"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5717/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698916979079,
            "cdate": 1698916979079,
            "tmdate": 1699636597778,
            "mdate": 1699636597778,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Xjgj1pvO1T",
                "forum": "dKPzWyaOsK",
                "replyto": "6cS7UpHmg3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5717/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5717/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer, thank you for your feedback and comments on our paper. We understand your remark about the probably too centered aspect around a literature review. We have reorganized the paper to give greater prominence to the \"Discussion\" section.\n\nThe thesis of this paper is based on the current and future proliferation of automated systems of all kinds that make moral choices on behalf of humans, whose decisions they replace - partially or totally. We then seek to show that, while these are indeed moral decisions, we must be aware that this moral automation is a choice that responds to human ideological motivations (of control, financial gain...).\nWe hope our modified paper is clearer and more personal."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5717/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680640242,
                "cdate": 1700680640242,
                "tmdate": 1700680640242,
                "mdate": 1700680640242,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7XnOBEVhh7",
                "forum": "dKPzWyaOsK",
                "replyto": "Xjgj1pvO1T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5717/Reviewer_X5KS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5717/Reviewer_X5KS"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response and edits to the paper. I am still not clear what your exact research question is and what are the novel contributions. So I will not be changing my score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5717/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694872089,
                "cdate": 1700694872089,
                "tmdate": 1700694872089,
                "mdate": 1700694872089,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]