[
    {
        "title": "Debiasing Language Models Using Energy-Guided Ordinary Differential Equations"
    },
    {
        "review": {
            "id": "1d7fw7NtlO",
            "forum": "kaFrlUcAn3",
            "replyto": "kaFrlUcAn3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6103/Reviewer_PBNe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6103/Reviewer_PBNe"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers debiasing language models using a combination of energy-based models and ordinary differential equations. It uses the idea of VAE to encode the text into latent space and uses the energy-based model for debiasing. The ODE is for providing sampling and guiding the model to sampling in a lower energy region. The experiments use two language model-based evaluation benchmarks and show it is able to reduce bias. It also conducts an analysis of the latent space representation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is the first to use ODE to do language model debias via its sampling advantages and it is able to mitigate bias in multiple aspects. The idea of using the energy-based model is also new and it shows the effectiveness in two intrinsic tasks as well as latent embedding space."
                },
                "weaknesses": {
                    "value": "The paper presents intricate concepts, which, unfortunately, are challenging to decipher due to its structure. Several crucial details seem omitted, making it difficult to follow.\n\nMethodologically, the work seems to merge different methods, lacking a clear, coherent logic.\n\nA significant concern I have lies in the experimental design. While the paper emphasizes intrinsic metrics that evaluate the language model itself, it overlooks the broader implications for downstream tasks. Merely reducing bias at the language model level does not guarantee that the bias is eliminated when the model is applied to real-world applications. These downstream applications are ultimately what matter most, as they are what end users interact with and perceive. Notably, many of the baselines you cite in the paper like INLP, and MABEL all conduct extrinsic evaluations. \n\nMost importantly, the paper's experiment metrics also concern me, as discussed in the paper: https://aclanthology.org/2021.acl-long.81.pdf . The crows-pairs and Stereoset have a range of pitfalls that threaten these benchmarks\u2019 validity as measurement models for stereotyping and bias.  Besides, there are other intrinsic evaluation metrics that need to be tested on: https://proceedings.neurips.cc/paper/2019/hash/201d546992726352471cfea6b0df0a48-Abstract.html, https://ojs.aaai.org/index.php/AAAI/article/view/21453"
                },
                "questions": {
                    "value": "1. for the intuition part of the paper, why does removing the word 'Ethiopian' then the bias is reduced? how is the bias defined here?\n2. When using the BERT as encoder, do you use the [cls] vector as the latent space point?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Reviewer_PBNe"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6103/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697774448479,
            "cdate": 1697774448479,
            "tmdate": 1700631581546,
            "mdate": 1700631581546,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1TSJuHVjPh",
                "forum": "kaFrlUcAn3",
                "replyto": "1d7fw7NtlO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1 / 3"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments and questions! We hope the response can address all the raised concerns and questions.\n\n**Q1:** Intrinsic and Extrinsic Evaluation\n\nWe conduct extrinsic evaluations on three benchmarks shown below. All of them employed the sequence-to-sequence style. For the classification tasks, we limited the vocabulary list to ensure we could access the logit of each class. The results revealed that our method exceeded the performance of the majority of baselines within these extrinsic benchmarks and was successful in striking an optimal balance between maintaining language modeling capability while minimizing bias.\n\nRegarding the intrinsic benchmark [1], which is designed for the masked language models. It is not compatible with the generative language models. Meanwhile, recent studies [2, 3] have brought the validity of SEAT into question due to the counter-intuitive results it often produces. As referenced in [4], SEAT is found to lack a consistent correlation with extrinsic metrics. This finding implies that a model can potentially receive high scores from SEAT, while simultaneously rendering biased judgments in downstream conditions. Therefore, we have chosen to disregard SEAT as an evaluation metric in our work.\n\n#### WinoBias\n - **Task Type**: Coreference\n - **Prompt**: COREF: {sentence}\\n\\nResult: {sentence_with_bracketed_coreference}\n - **Example**: COREF: The laborer eats more than the receptionist as [he] is hungry. \\n\\nResult: [The laborer] eats more than the receptionist as [he] is hungry.\n - **Settings**:\n\t - Training Dataset: WinoBias train split\n\t - Evaluation Dataset: WinoBias test split\n\t - Epoch: 3\n\t - Learning rate: 1e-4\n\t - Optimizer: paged\\_adamw\\_32bit\n - **Metrics**:\n\t - 1A: the accuracy of type-1 anti-stereotypical instances.\t\n\t - 1P: the accuracy of type-1 stereotypical instances.\t\t\n\t - 2A: the accuracy of type-2 anti-stereotypical instances.\n\t - 2P: the accuracy of type-3 stereotypical instances.\n\t - TPR-1: the gap between 1P and 1A.\n\t - TPR-2: the gap between 2P and 2A\n - **Results**: \n\n| Models                |    1A \u2191   |    1P \u2191   |    2A \u2191   |    2P \u2191   |      TPR-1 \u2193      |      TPR-2 \u2193      |\n|-----------------------|:---------:|:---------:|:---------:|:---------:|:-----------------:|:-----------------:|\n| Llama                 |     65.15 | **92.42** |     94.19 | **96.21** |             27.27 |              2.02 |\n| Llama + CDA           |     61.11 |     85.35 |     82.83 |     81.06 |     24.24 (-3.03) |      1.77 (-0.25) |\n| Llama + INLP          |     56.06 |      54.8 |     61.87 |     58.84 | **1.26 (-26.01)** |      3.03 (+1.01) |\n| Llama + Self-Debias   |     71.21 |     91.67 |     94.95 |     92.93 |     20.46 (-6.81) |          2.02 (0) |\n| Llama + DICE          | **72.47** |      89.9 | **95.45** |     95.97 |     17.43 (-9.84) |   **0.52 (-1.5)** |\n| Llama 2               |     65.66 | **94.95** |     97.98 |     98.99 |             29.29 |              1.01 |\n| Llama 2 + CDA         |      60.1 |      84.6 |     78.28 |     81.82 |      24.5 (-4.79) |      3.54 (+2.53) |\n| Llama 2 + INLP        |     58.59 |     60.61 |     64.65 |     56.82 | **2.02 (-27.27)** |      7.83 (-6.82) |\n| Llama 2 + Self-Debias |     69.95 |     91.41 |     97.98 |     97.98 |     21.46 (-7.83) |     **0 (-1.01)** |\n| Llama 2 + DICE        | **72.11** |      93.5 | **98.74** | **99.24** |      21.39 (-7.9) |       0.5 (-0.51) |\n| GPT 2                 |     47.12 |     52.03 |     56.17 | **71.72** |              4.91 |             15.55 |\n| GPT 2 + CDA           |     46.46 |     48.74 |     57.83 |     69.44 |      2.28 (-2.63) |     11.61 (-3.94) |\n| GPT 2 + INLP          |        50 |     48.48 |     54.04 |     51.01 |      1.52 (-3.39) | **3.03 (-12.52)** |\n| GPT 2 + Self-Debias   |     50.76 |     49.75 |     57.58 |     51.77 |   **1.01 (-3.9)** |      5.81 (-9.74) |\n| GPT2 + DICE           | **63.64** | **64.65** | **63.89** |     68.94 |   **1.01 (-3.9)** |      5.05 (-10.5) |"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700548905367,
                "cdate": 1700548905367,
                "tmdate": 1700549029334,
                "mdate": 1700549029334,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UYroasJLvR",
                "forum": "kaFrlUcAn3",
                "replyto": "1d7fw7NtlO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 2 / 3"
                    },
                    "comment": {
                        "value": "#### Bias-NLI\n - **Task Type**: Natural Language Inference\n - **Prompt**: Hypothesis: {hypothesis}\\n\\nPremise: {premise}\\n\\nResult: {label}\n - **Example**: Hypothesis: A person on a horse jumps over a broken down airplane.\\n\\nPremise: A person is outdoors, on a horse.\\n\\nResult: entailment\n - **Settings**:\n\t - Training Dataset: SNLI dataset \n\t - Evaluation Dataset: Bias-NLI dataset\n\t - Epoch: 3\n\t - Learning rate: 1e-4 \n\t - Optimizer: paged\\_adamw\\_32bit\n - **Metrics**: \n\t - Net Neutral (NN): The average probability of the neutral label across all sentence pairs.\n\t  - Fraction Neutral (FN): The fraction of sentence pairs labeled neutral.\n\t  - T: A parameterized measure that reports the fraction of examples whose probability of neutral above t: we report this for t = 0.5 and t = 0.7. \n- **Results**: \n\n| Models                | Acc. (All) \u2191 | Acc. (M) \u2191 | Acc. (F) \u2191 | TPR-GAP \u2193 | TPR-RMS \u2193 |\n|-----------------------|:------------:|:----------:|:----------:|:---------:|:---------:|\n| Llama                 |        91.12 |  **91.73** |       90.4 |      1.33 |      0.09 |\n| Llama + CDA           |        85.56 |      86.88 |      84.01 |      2.87 |      0.12 |\n| Llama + INLP          |        85.53 |       84.5 |      86.73 |      2.23 |      0.11 |\n| Llama + Self-Debias   |        91.22 |      90.33 |  **92.26** |      1.93 |       0.1 |\n| Llama + DICE          |    **91.63** |      91.24 |      92.08 |  **0.84** |  **0.08** |\n| Llama 2               |    **89.94** |   **90.6** |      89.17 |      1.43 |      0.09 |\n| Llama 2 + CDA         |        82.89 |      84.33 |      81.21 |      3.12 |      0.14 |\n| Llama 2 + INLP        |        87.01 |       87.5 |      86.44 |      1.06 |      0.08 |\n| Llama 2 + Self-Debias |        89.66 |      89.27 |  **90.12** |      0.85 |  **0.04** |\n| Llama 2 + DICE        |        89.21 |      89.06 |      89.39 |  **0.33** |  **0.04** |\n| GPT 2                 |    **87.33** |      88.07 |  **86.46** |      1.61 |      0.15 |\n| GPT 2 + CDA           |        84.68 |       87.3 |      81.62 |      5.68 |      0.23 |\n| GPT 2 + INLP          |        84.81 |       85.5 |         84 |   **1.5** |  **0.13** |\n| GPT 2 + Self-Debias   |        86.93 |      87.71 |      86.02 |      1.69 |      0.14 |\n| GPT2 + DICE           |        87.30 |  **88.64** |      85.74 |       2.9 |      0.16 |\n\n#### Bias-in-Bios\n- **Task Type**: Classification\n- **Prompt**: CLS: {biographies}\\n\\nResult: {profession}\n- **Example**: CLS: Prior to law school, Brittni graduated magna cum laude from DePaul University in 2011...\\n\\nResult: 2(attorney)\n- **Settings**:\n\t- Training Dataset: Bias-in-Bios train split\n\t- Evaluation Dataset: Bias-in-Bios test split\n\t- Epoch: 3\n\t- Learning rate: 1e-4\n\t- Optimizer: paged\\_adamw\\_32bit\n- **Metrics**:\n\t- acc_a: the overview accuracy.\n\t- acc_m: the accuracy of male instances.\n\t- acc_f: the accuracy of female instances.\n\t- TPR-GAP: the gap between acc_m and acc_f.\n\t- TPR-RMS: Root-mean-square deviation between male and female predictions.\n- **Results**:\n\n| Models                |    NN \u2191   |    FN \u2191   |  T:0.5 \u2191  |  T:0.7 \u2191  |\n|-----------------------|:---------:|:---------:|:---------:|:---------:|\n| Llama                 |     73.85 |     96.63 | **98.46** |     92.19 |\n| Llama + CDA           |      65.4 |        89 |      92.1 |     87.03 |\n| Llama + INLP          |     69.08 |     92.58 |     96.43 |     89.04 |\n| Llama + Self-Debias   | **85.22** |     96.97 |     97.66 |     91.26 |\n| Llama + DICE          |     84.96 | **97.55** |     98.39 | **94.51** |\n| Llama 2               |      76.4 |      95.9 |     98.17 |     90.93 |\n| Llama 2 + CDA         |     70.11 |     91.07 |     90.01 |     81.15 |\n| Llama 2 + INLP        |     75.24 |     90.11 |     88.92 |     80.09 |\n| Llama 2 + Self-Debias |     85.89 | **98.01** |     97.39 |     92.53 |\n| Llama 2 + DICE        | **87.71** |     97.66 |  **98.2** |  **94.2** |\n| GPT 2                 |     79.01 | **90.13** |     87.66 |     74.35 |\n| GPT 2 + CDA           |      77.3 |     89.71 |     85.91 | **76.76** |\n| GPT 2 + INLP          |     72.46 |     85.98 |        82 |     74.06 |\n| GPT 2 + Self-Debias   |     81.49 |     89.29 | **89.57** |     73.58 |\n| GPT2 + DICE           | **82.66** |     90.04 |     88.02 |     73.77 |"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700548970676,
                "cdate": 1700548970676,
                "tmdate": 1700549017647,
                "mdate": 1700549017647,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3cec5um7vm",
                "forum": "kaFrlUcAn3",
                "replyto": "1d7fw7NtlO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_PBNe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_PBNe"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the rebuttal, the downstream experiments indeed strengthen the paper results, so I will increase the score to 5."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631559822,
                "cdate": 1700631559822,
                "tmdate": 1700631593786,
                "mdate": 1700631593786,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "K0PCd76kmf",
            "forum": "kaFrlUcAn3",
            "replyto": "kaFrlUcAn3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new method for mitigating biases in large language models (LLMs). Their approach involves a multi-step process. First, they employ a Variational Autoencoder (VAE) to transform text into latent variables. Next, a classifier is trained to discern the biased attributes within these latent variables. Finally, they construct an energy-based model (EBM) based on the pretrained classifier. This EBM generates latent variables with consistent density values for various sensitive attributes, enabling the generation of debiased text by decoding these corresponding latent variables. The experiments conducted in the study provide compelling evidence that these methods effectively reduce stereotypes in LLMs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper tackles a crucial concern within the realm of LLMs, one that carries significant societal implications.\n- Empirical findings from the experiments underscore the efficacy of the proposed method in successfully alleviating biases present in LLMs."
                },
                "weaknesses": {
                    "value": "- Expensive training is a prerequisite. In the introduction, the authors contend that \"our method can readily adapt to arbitrary biases without costly retraining,\" which, in reality, is not the case. On the contrary, the proposed approach entails training a VAE and a classifier, which can be highly computationally demanding.\n- The writing appears rather unclear to me. Regarding the experimental specifics, there seems to be a substantial lack of information on how to train the VAE and classifier. The performance hinges greatly on the pretrained VAE, but training a VAE, particularly with high-dimensional and discrete data like text, can be quite challenging. It would be immensely beneficial if more elaborate details were provided. Did you employ any pretrained models for initialization? Could you elucidate the precise training procedures, including any strategies or techniques employed?\n- The VAE training process might be detrimental to the overall performance. I believe a more straightforward approach involves training a classifier using the latent representations of existing LLMs, such as BERT or LLAMA. I find myself puzzled about the necessity of the VAE training procedure. Furthermore, fine-tuning LLMs as VAEs could potentially compromise performance if not executed flawlessly. The performance is critically contingent on the quality of the trained VAE, which, in my view, carries inherent risks."
                },
                "questions": {
                    "value": "- How is your sampling method connected to diffusion models? In section 3.4, you allocate substantial space to discussing diffusion models, even though the connection appears somewhat tenuous. I am curious about the time-variant density $p_t$ in your context. My understanding is that you merely need to sample from your EBM. In this case, you could employ Langevin dynamics or similar samplers like HMC. Could you elaborate further on why you have opted for ODE instead of Langevin dynamics? Additionally, could you provide insights into how equation 8 satisfies the continuity equation and converges to your target distribution?\n- The algorithm would greatly benefit from a more intuitive explanation. It seems that your aim is to utilize the EBM to guide the generation of latent variables. The EBM is defined as the summation over the classifier, where $\\log p(\\mathcal{A}|z) \\propto \\sum_{i} f_i(a_i | z)$. To mitigate biases, the objective is to generate the latent variable $z$ in a way that ensures $p(a_i|z) \\approx p(a_j|z), \\forall i,j$. However, if I comprehend correctly, what you are currently doing is sampling $z \\sim p(\\mathcal{A}|z)$. In this case, it's not evident how the generated latent variable $z$guarantees the desired properties, i.e., $z \\sim p(\\mathcal{A}|z)$, and subsequently, $p(a_i|z) \\approx p(a_j|z) \\forall i,j$. Could you provide more clarity on this?\n- I am finding it challenging to grasp how the latent variable sampled from EBMs maintains consistency with the latent space of the VAE. I have concerns that the generated debiased latent variables might not yield fluent results. Looking at eq.8, it appears that there is no constraint ensuring that the samples from EBMs reside within the latent space of the VAE."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6103/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698615179350,
            "cdate": 1698615179350,
            "tmdate": 1700661474749,
            "mdate": 1700661474749,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UJcp0PhxpW",
                "forum": "kaFrlUcAn3",
                "replyto": "K0PCd76kmf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1 / 2"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thoughtful feedback and hope the response can address the raised concerns and questions.\n\n**Q1**: How is your sampling method connected to diffusion models?\n\nWe employ an ODE solver in this work, which can be regarded as a sort of ``deterministic'' diffusion model [1].\n\nOur motivation is to use the ODE solver to gradually converge the latent variable obtained from the VAE encoder to the energy area we expect under the guidance of EBM. This time-variant process can be regarded as a reverse diffusion process. [1] stated the reverse of a diffusion process is also a diffusion process. Crucially, this reverse process satisfies a reverse-time SDE, which can be derived from the forward SDE given the score of the marginal probability densities as a function of time. Moreover, for all diffusion processes, there exists a corresponding deterministic process whose trajectories share the same marginal probability densities as the SDE. This deterministic process satisfies an ODE [2]. Above is the connection between our sampling method and diffusion models.\n\n**Q2:** Why you have opted for ODE instead of Langevin dynamics?\n\nRegarding why we opted for ODE instead of Langevin dynamics, here are reasons from these aspects:\n\n- [Diversity] The latent variable is envisioned as a low-dimensional manifold embedded within a higher-dimensional latent space. Consequently, most points from Langevin Sampling (without noise) won't align with the manifold. This implies that the likelihood of these points will be zero, rendering the score function $\\log p(x)$ undefined for these points. Hence, SGLD tends to easily settle into local optima. In our work, cyclic annealing was leveraged to introduce scaled noise to the sample data. As a result, the generated latent variable is not only more robust but also converges more quickly.\n\n- [Speed] Similar to the first problem, LD without noise struggles to garner enough sample data to effectively guide the score function in areas of sparsity. Consider the energy distributions depicted in Figure 6, where most samples are tightly clustered leaving other areas distinctly sparse. LD might employ a smaller learning rate alongside an increased number of learning steps to work around this problem, however, this would inevitably compromise the speed. The DICE method proposed in our paper manages this issue by initiating scale disturbance as well. The Runge-Kutta method is a deterministic process, in contrast to Langevin sampling which necessitates MCMC sampling, which samples from the approximated distribution for every gradient update. Therefore, the Runge-Kutta method proves to be more efficient than Langevin sampling in this case.\n\n- [Joint Modelling] In our empirical experiments, we found both SGLD and ODE could generate fluent completions with desired attributes for a single-bias control, while SGLD is slower and less diverse. However, the performance of SGLD drastically deteriorates under joint debiasing settings. This decrease in performance might be attributed to SGLD's naive disregarding of the weight each joint score function carries. For example, consider a joint score function $ \\log p(x) = \\log (w_1 * p_1(x) + w_2 * p_2(x)) $, SGLD employs $ \\nabla_x \\log p(x) = \\nabla_x \\log p_1(x) + \\nabla_x \\log p_2(x) $ to sample from $p(x)$ which does not rely on these weights. \n\n- [Optimization] The SGLD approach is highly sensitive to hyperparameters, often requiring substantial time for optimization without guaranteeing fluent completion (see the empirical experiment). On the other hand, the Runge-Kutta method exhibits consistent performance across all tested LLMs(GPT2-base, GPT2-large, Llama-7b, and Llama2-7b) using the same hyperparameters. This trait makes it much more practical and adaptable in real scenarios."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700549592154,
                "cdate": 1700549592154,
                "tmdate": 1700549724354,
                "mdate": 1700549724354,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oCmTUsuLVX",
                "forum": "kaFrlUcAn3",
                "replyto": "K0PCd76kmf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "Thanks for your great effort in responding and revising. After reading the rebuttal, I am still very confused. \n\nFor Q1, you argue that the ODE is a probabilistic flow of the SDE. However, I can't understand what's the SDE of your model. What's your time-varying probability p_t and how do you learn a neural network to approximate p_t. To me, it seems that you just want to sample from the target distribution $p \\propto \\sum_{i} f_i(a_i | z)$, and you run a gradient decent to find its local optimal. Therefore, the resulting method is not a valid sampler.\n\nFor Q2, \"... while SGLD is slower and less diverse\". It is really supervised to me. Why a stochastic sampler is less diverse to a deterministic gradient decent?\n\nFor Q5, I think you misunderstood my question. It is true that if you just run a few steps, the resulting samples are not far away from the latent space learned by VAE. However, it is noteworthy that in eq.8, there is no constraint that ensures the samples should be sampled in the latent space of VAE, and it's very dangerous that your samples can be far away from the learned spaces. Therefore, I think doing projected gradient descent is better than doing gradient descent."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588222108,
                "cdate": 1700588222108,
                "tmdate": 1700588275687,
                "mdate": 1700588275687,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Y7yuNdkjib",
                "forum": "kaFrlUcAn3",
                "replyto": "K0PCd76kmf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your feedback. We are more than willing to answer your questions:\n\n**Q1:**\n\nConsider a diffusion process that iteratively blurs an image to reach a Gaussian distribution ($\\mathcal{N}(0, I)$) in the forward process, and in reverse, iteratively samples an image back from a Gaussian distribution  ($\\mathcal{N}(0, I)$). In this context, the time-varying probability $p_0$ depicts the image data distribution, and $p_T$ represents the initial distribution $\\sim\\mathcal{N}(0, I)$. An illustrative example can be found in Fig. 1 of [1]. Our model emulates the reverse diffusion process, which can be represented as solving an initial value problem (IVP) via ODE. We aim for the latent variable to gradually accommodate the desired attribute, enabling us to quantitively control the bias level. To this end, we employ an ODE solver (Runge-Kutta of order 5 of Dormand-Prince-Shampine) to approximate the target distribution given the original encoder output. Unlike conventional SDE which samples from a normal distribution, we treat each training data as a sample and then convert it into a representation in the latent space through the encoder. We can change the name if you feel it is inappropriate to call it sampling.\n\nWe hypothesize that our main divergence lies in how to sample from the latent space effectively. Though gradient descent seems an intuitive approach to approximate the target distribution, it exhibits significant limitations in our scenario. In our empirical experiments, we found that gradient descent is laborious to train and tends to produce unstable output\u2014an issue also noted in [1,2,3]. Moreover, our model is designed to debias multiple attributes simultaneously, a scenario that SGLD may not adeptly accommodate. In fact, SGLD's performance significantly deteriorates under joint debiasing settings. This decrease in performance can potentially be attributed to the naive disregard by SGLD of the weight that each joint score function holds. For instance, in the case of a joint score function $ \\log p(x) = \\log (w_1 * p_1(x) + w_2 * p_2(x)) $, SGLD employs $ \\nabla_x \\log p(x) = \\nabla_x \\log p_1(x) + \\nabla_x \\log p_2(x) $ to sample from $p(x)$, without considering the corresponding weights.\n\n**Q2:** \n\n**Slower**: When two modes of a given data distribution are divided by areas of low density, Langevin dynamics may not effectively recover the relative weights of these modes within a reasonable time, and thus may not converge to the true distribution [1]. This analysis also holds when different modes have approximately disjoint supports - they might share the same support but be linked via areas of low data density.\n\nIn a joint debiasing scenario, where biases related to \"gender\", \"race\", and \"religion\" are to be addressed simultaneously, the common support may not be adequate to recover the target distribution using SGLD. In theory, Langevin dynamics could indeed generate accurate samples, but this might necessitate a very small step size and a huge number of steps for effective mixing.\n\n**Less diverse:** The latent variable is a low-dimensional manifold embedded within a higher-dimensional latent space. If we consider the vanilla SGLD without annealed noise, most points from Langevin sampling won't align with the manifold [1]. This implies that the likelihood of these points will be zero, rendering the score function undefined for these points. Hence, SGLD tends to easily settle into local optima and cluster together. To address this problem, we introduce scaled noise to perturb the supports, despite the ODE's deterministic nature. Consequently, our approach can generate a wider range of diverse results.\n\n**Q5:** \n\nI agree with your point. There is indeed potential danger if the sample strays significantly away from the learning space. Current empirical observations indicate less impact on the decoder (likely attributable to the fewer than 10 ODE iterations performed). To further confirm these findings, we plan to conduct additional experiments, projecting parameters into the decoder\u2019s constraint space, and providing theoretical boundaries for the latent variables. Your suggestions are greatly appreciated!\n\n[1] Song, Yang, et al. \"Score-based generative modeling through stochastic differential equations.\" _arXiv preprint arXiv:2011.13456_ (2020).\n\n[2] Nie, Weili, Arash Vahdat, and Anima Anandkumar. \"Controllable and compositional generation with latent-space energy-based models.\" _Advances in Neural Information Processing Systems_ 34 (2021): 13497-13510.\n\n[3] Liu, Guangyi, et al. \"Composable text controls in latent space with odes.\" _arXiv preprint arXiv:2208.00638_ (2022)."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647327233,
                "cdate": 1700647327233,
                "tmdate": 1700647415713,
                "mdate": 1700647415713,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5brN3q942c",
                "forum": "kaFrlUcAn3",
                "replyto": "Y7yuNdkjib",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "Thanks for your great effort in responding to my questions. \n\n\"To address this problem, we introduce scaled noise to perturb the supports, despite the ODE's deterministic nature. Consequently, our approach can generate a wider range of diverse results\"\n\nCould you explain briefly what you mean by \"introduce scaled noise to perturb the supports\"?  Is there a corresponding description in the paper?"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700648592984,
                "cdate": 1700648592984,
                "tmdate": 1700648592984,
                "mdate": 1700648592984,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wdAlqHK0um",
                "forum": "kaFrlUcAn3",
                "replyto": "K0PCd76kmf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your prompt reply!\n\nThe corresponding description can be found in Appendix 2.\n\n$ \\mathcal{L}_{vae}(x)=-E\\_{q(z|x)}  [\\log p(x|z)] + \\beta \\cdot \\rm{KL} (q(z|x) \\cdot noise || p\\_{prior}(z))$\n\nBriefly, this trick imports a coefficient $\\beta$ that regulates the weight of the KL divergence on the VAE objective. The coefficient is gradually changed from 0 to 1. The motivation for doing this is as follows:\n\n- Since the definition domain of Gaussian noise is the entire latent space, adding noise to the original data solves the zero probability problem of low-dimensional manifolds (otherwise the score function will not be able to steer the ODE solver).\n\n- Adding noise essentially expands the range of each mode in the distribution, allowing the low-probability areas in the data distribution to get more supervision signals. In particular, this is very effective for the joint-debiasing scenario.\n\n- The noise scale selection is not a simple problem. Adding too much noise will cover more low-probability space and drastically change the original data distribution, while too little noise will be useless to the less dense space. \n\nTherefore, the final solution we ended up using was to add a 4-loop annealing factor to rescale the KL divergence."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651319820,
                "cdate": 1700651319820,
                "tmdate": 1700653643852,
                "mdate": 1700653643852,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dvHnwtJwLM",
                "forum": "kaFrlUcAn3",
                "replyto": "wdAlqHK0um",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "Thanks for your response. It is very confusing to me. \n\nHere is what you claimed: \"Hence, SGLD tends to easily settle into local optima and cluster together. To address this problem, we introduce scaled noise to perturb the supports, despite the ODE's deterministic nature.\"\n\nIt seems to me that you regularise the latent space of VAE using different $\\beta$, which is fair to me. However, when you apply Langevin dynamics, you also sample from such noisy supports. Why does Langevin dynamics suffer from less diversity but ODE does not?"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700654407865,
                "cdate": 1700654407865,
                "tmdate": 1700654407865,
                "mdate": 1700654407865,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uWg6fVlTNk",
                "forum": "kaFrlUcAn3",
                "replyto": "dvHnwtJwLM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "To me, your ODE solver works because you run a gradient descent instead of a valid sampler. Therefore, your method is easy to trap in the local mode of the posterior of VAE.\n\nAgain, it is not a good choice to call it sampling, and the motivation from diffusion is confusing either.\n\nBTW, I found one claim is not true in the appendix (see the sentence above eq.9)\n\n\"Prior work has suggested that importing multiple noise perturbations in the sampling procedure may alleviate all these issues (Song & Ermon, 2019). **Consequently**, EBM sampling can also be carried out via the manner of Stochastic Differential Equations (SDEs)\"\n\nThe connective \"Consequently\" does not make sense here.  To potentially solve the issue you mentioned, you could use multi-scale LD, but at the same time, you need to train multiple EBMs. Eq.9 is just a discretisation of Langevin dynamics, and it has nothing to do with the issues you mentioned."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700655649337,
                "cdate": 1700655649337,
                "tmdate": 1700655649337,
                "mdate": 1700655649337,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "21Xu1uaGpd",
                "forum": "kaFrlUcAn3",
                "replyto": "K0PCd76kmf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your swift response and insightful question.\n\nI understand your quoted claim originated from the answer to your second question. Prior to delving into the discussion, let's establish that we will discuss diversity within the framework of the joint-debiasing scenario.\n\nWe hypothesize that the observed difference may be due to the SGLD's inability to account for the individual weights within each joint score function. For instance, given a joint score function $ \\log p(x) = \\log (w_1 * p_1(x) + w_2 * p_2(x)) $, SGLD utilizes $ \\nabla_x \\log p(x) = \\nabla_x \\log p_1(x) + \\nabla_x \\log p_2(x) $ to take samples from $p(x)$. This approach does not rely on weight factors. Thus, it could be inferred that SGLD might not possess the capacity to effectively manage the multiple-mode distribution. This is a primary motivator behind our decision to opt for ODE over LD. This particular scenario is also highlighted in references [1,2,3] for your information.\n\nIt's a good question. A comprehensive comparison and analysis of LD and ODE might be substantial enough to merit a separate paper. We will leave it to future work.\n\n[1] Nie, Weili, Arash Vahdat, and Anima Anandkumar. \"Controllable and compositional generation with latent-space energy-based models.\" Advances in Neural Information Processing Systems 34 (2021): 13497-13510.\n\n[2] Song, Yang, et al. \"Score-based generative modeling through stochastic differential equations.\" arXiv preprint arXiv:2011.13456 (2020).\n\n[3] Liu, Guangyi, et al. \"Composable text controls in latent space with odes.\" arXiv preprint arXiv:2208.00638 (2022)."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659071091,
                "cdate": 1700659071091,
                "tmdate": 1700659223480,
                "mdate": 1700659223480,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yvD2tL3o3T",
                "forum": "kaFrlUcAn3",
                "replyto": "21Xu1uaGpd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_kTHj"
                ],
                "content": {
                    "title": {
                        "value": "Response to the authors"
                    },
                    "comment": {
                        "value": "Thanks for your response. I will increase my score to 5.\n\nA better motivation for using ODE rather than LD would be great in the revision. Here are a few suggestions:\n\n- Discuss why LD can not account for the weight. Could you utilise $\\nabla_x \\log p(x) = \\nabla_x \\log (w_1 p_1 (x) + w_2 p_2 (x))$ in LD\n\n- Discuss why ODE can account for the weight\n\nHere are two references that may be helpful for compositional generation using EBMs\n\n- Garipov, Timur, et al. \"Compositional Sculpting of Iterative Generative Processes.\" arXiv preprint arXiv:2309.16115 (2023).\n\n- Du, Yilun, et al. \"Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and mcmc.\" International Conference on Machine Learning. PMLR, 2023."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661452046,
                "cdate": 1700661452046,
                "tmdate": 1700661452046,
                "mdate": 1700661452046,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "02qKr8Jquq",
            "forum": "kaFrlUcAn3",
            "replyto": "kaFrlUcAn3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6103/Reviewer_CA2c"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6103/Reviewer_CA2c"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses a pivotal issue in Large Language Models (LLMs) concerning biases and fairness. The author introduces an EBM-based approach for controlled generation in LLMs, treating the EBM as a classifier that can be learned discriminatively. The author further suggests utilizing ODE sampling over Langevin dynamics to reduce computational overhead. While such techniques are familiar in the realm of large vision models, their application in LLMs remains relatively unexplored."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method seems sound and reasonable.\n2. The EBM formulation is simple and interesting.\n3. The paper is clear to understand."
                },
                "weaknesses": {
                    "value": "See questions."
                },
                "questions": {
                    "value": "1. I feel the major bottleneck for using latent variable model in LLMs is mode collapse, which has been studied in [1,2]. Given longer enough context, the autoregressive model will ignore the effects of the latent variables, especially with powerful enough decoders. I see you use the cyclic annealing in Bert+GPT2 experiment to address this issue. However, I want to know more results and evaluation for more powerful models such as LLaMA-2. \n\n2. Another way to address mode collapse is to make the prior distribution more meaningful rather than isotropic Gaussian used in VAE. This shares the similar intuition as the cyclic annealing used in this paper. Do you consider using learnable prior in the training rather than in a two-step manner [3]?\n\n3. The energy-based formulation in this paper is similar to latent space energy-based model, where energy function is severed as an exponential tilting of an isotropic Gaussian[4]. Some pioneering EBM work should be cited as well including [5-8].\n\n4. For the ODE sampler, how does the ODE solver compare performance-wise to using Equ.11 directly for Langevin sampling (without noise)? Could you distinguish between your Runge-Kutta method and Langevin sampling in implementation?\n\n[1] Pang, Bo, et al. \"Generative text modeling through short run inference.\" arXiv preprint arXiv:2106.02513 (2021).\n\n[2] Xu, Yan, et al. \"Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior Inference.\" arXiv preprint arXiv:2306.01153 (2023).\n\n[3] Pang, Bo, and Ying Nian Wu. \"Latent space energy-based model of symbol-vector coupling for text generation and classification.\" International Conference on Machine Learning. PMLR, 2021.\n\n[4] Pang, Bo, et al. \"Learning latent space energy-based prior model.\" Advances in Neural Information Processing Systems 33 (2020): 21994-22008.\n\n[5] Xie, Jianwen, et al. \"A theory of generative convnet.\" International Conference on Machine Learning. PMLR, 2016.\n\n[6] Xie, Jianwen, et al. \"Cooperative training of descriptor and generator networks.\" IEEE transactions on pattern analysis and machine intelligence 42.1 (2018): 27-45.\n\n[7] Nijkamp, Erik, et al. \"Learning non-convergent non-persistent short-run MCMC toward energy-based model.\" Advances in Neural Information Processing Systems 32 (2019).\n\n[8] Du, Yilun, and Igor Mordatch. \"Implicit generation and generalization in energy-based models.\" arXiv preprint arXiv:1903.08689 (2019)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Discrimination / bias / fairness concerns"
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Reviewer_CA2c"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6103/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698706337977,
            "cdate": 1698706337977,
            "tmdate": 1699636658598,
            "mdate": 1699636658598,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nmnCSUe1LY",
                "forum": "kaFrlUcAn3",
                "replyto": "02qKr8Jquq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1 / 2"
                    },
                    "comment": {
                        "value": "Thank you for your valuable review and constructive suggestions!  I hope the response can address all the raised concerns and questions.\n\n**Q1:** *Given longer enough context, the autoregressive model will ignore the effects of the latent variables, especially with powerful enough decoders. I see you use the cyclic annealing in Bert+GPT2 experiment to address this issue. However, I want to know more results and evaluation for more powerful models such as LLaMA-2.*\n\nIn this study, we employ cyclic annealing and infusion mechanisms (AtM and PSA) to prevent mode collapse from the decoder. Noteworthily, our empirical results show that more powerful decoders even demonstrate better debiasing performance in our approach. We postulate this enhanced performance may be attributed to the fact that these more potent decoders have a refined comprehension of bias, thus enabling sounder debiasing effects through the guidance of the latent variable.\n\nIn our experiments, we have reported results for the GPT2, Llama-7B, and Llama 2-7B models respectively. Regarding the larger Llama 2 models (such as 13B and 70B configurations), we have commenced evaluation processes. We will update the data once we have gathered the necessary results as soon as possible.\n\n**Q2:** *Do you consider using learnable prior in the training rather than in a two-step manner?*\nWe leverage the feature of isotropic Gaussian to provide an initial distribution for the ODE solver. A more meaningful prior distribution can indeed alleviate the issue of VAE mode collapse. However, our concern lies in the ODE solver's potential inability to function adequately if the distribution deviates significantly from the Gaussian distribution. Consequently, we will conduct additional experiments to discern an effective way to strike a balance. Thank you once again for your valuable suggestion!\n\n**Q3:** *Latent space EBM citations.*\n\nWe thank you for pointing out several important references that were missing in the original submission. We will carefully incorporate them in the final revision paper."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700550272089,
                "cdate": 1700550272089,
                "tmdate": 1700550272089,
                "mdate": 1700550272089,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "O5KbL01oNF",
            "forum": "kaFrlUcAn3",
            "replyto": "kaFrlUcAn3",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6103/Reviewer_bvt7"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6103/Reviewer_bvt7"
            ],
            "content": {
                "summary": {
                    "value": "This paper presented Debiasing via Continuous Energy-Based Models (DICE). It utilizes Energy-Based Model (EBM) gradient with Ordinary Differential Equations (ODEs) to reduce biases. The method part was inspired by [1,2], especially [2].\n\nEmpirical results on variant scale language models (GPT2, LLaMA, LLaMA-2) on two datasets (Crows-Pairs, StereoSet) showed effectiveness in debiasing.\n\n[1] Weili Nie, Arash Vahdat, and Anima Anandkumar. Controllable and compositional generation\nwith latent-space energy-based models. Advances in Neural Information Processing Systems,\n34:13497\u201313510, 2021.\n\n[2] Guangyi Liu, Zeyu Feng, Yuan Gao, Zichao Yang, Xiaodan Liang, Junwei Bao, Xiaodong He,\nShuguang Cui, Zhen Li, and Zhiting Hu. Composable text controls in latent space with odes.\narXiv preprint arXiv:2208.00638, 2022."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. Clear presentation with graphic illustrations on the proposed methodology.\n2. Detailed description of the dataset together with extensive empirical results."
                },
                "weaknesses": {
                    "value": "1. **Lack of novelty!** Majority of the method are from [1]. DICE can be viewed as [1] with attributes about bias.\n2. Unclear description about Figure 2. Some interpretation was provided but without detail explanation or convincing empirical result.\n3. The presentation about why after the sampling by solving the ODE, the $z_{0}$ can be decoded to less biased context.\n\n[1] Guangyi Liu, Zeyu Feng, Yuan Gao, Zichao Yang, Xiaodan Liang, Junwei Bao, Xiaodong He,\nShuguang Cui, Zhen Li, and Zhiting Hu. Composable text controls in latent space with odes.\narXiv preprint arXiv:2208.00638, 2022."
                },
                "questions": {
                    "value": "1. More details about the AtM and PSA are needed.\n2. In [1] the attributed are asserted by assigning value for $a_i$ during the sampling. However, in Appendix A.7 Table 7, the Crows-Pairs data comes with labels $\\\\{more,less\\\\}$ biased. But Sec 2.1 says $a_i$ belongs to Male / Female / Neutral as in Table 9. What are the labels in Algorithm 1 line 9?\n3. If the answer for previous question is the labels in Table 9, then a natural question follows: How to generate debiased context? [1] controls generation by assigning attribute values. Here how to generate debiased context? Are you assigning $a_i$ as well? If so, how to guarentee that $a_i$ is not biased? For example, for the same attribute *male*, ''he is a doctor'' and ''he is a nurse'' may be considered differently considering bias. How $a_i$ was chose for those cases?\n4. Confusing metric scores. Especially icat and ss. In Sec 4.1.2 calculating icat, perfect model has ss of 50. However, in Table 2 ss is lower is better. That leads to GPT2-large Race has best ss, best lms but non-best icat.\n\u00a0\n[1] Guangyi Liu, Zeyu Feng, Yuan Gao, Zichao Yang, Xiaodan Liang, Junwei Bao, Xiaodong He,\nShuguang Cui, Zhen Li, and Zhiting Hu. Composable text controls in latent space with odes.\narXiv preprint arXiv:2208.00638, 2022."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6103/Reviewer_bvt7"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6103/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698742099753,
            "cdate": 1698742099753,
            "tmdate": 1700698638969,
            "mdate": 1700698638969,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LMmT6KKnE9",
                "forum": "kaFrlUcAn3",
                "replyto": "O5KbL01oNF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1 / 2"
                    },
                    "comment": {
                        "value": "We greatly appreciate your valuable feedback! It is our sincere hope that our responses can effectively address your concerns.\n\n**Q1:** More details about the AtM and PSA are needed.\n\nBoth AtM [1] and PSA [2] operate as the infusion mechanism connecting the encoder and decoder.\n\nAtM projects the latent variable $z$ into both the attention key and value spaces by a MLP. It then concatenates them with the key and value vector in each attention layer within the decoder. This process can be thought of as the insertion of a \"soft\" prompt prefix ahead of the context. In this scenario, the latent variable functions as Q, with the Key and Value (KV) being projected by Q:\n\n$k' = v' = mlp(z)$\n\n$q = [q;z] \\quad k = [k;k'] \\quad v = [v;v']$\n\nPSA is similar to AtM, except it has different K and V:\n\n$k' = mlp_{k}(z) \\quad v' = mlp_{v}(z)$\n\n$q = [q;z] \\quad k = [k;k'] \\quad v = [v;v']$\n\n**Q2:** What are the labels in Algorithm 1 line 9?\nThe labels in Algorithm 1 line 9 can be found in Table 9. \n\nAlgorithm 1 represents the DICE training and inference procedure, whereas Crows-Pairs / StereoSet benchmarks are denoted as the evaluation procedure. Labels bear different meanings within these two procedures.\n\nWithin the context of Algorithm 1, labels can guide DICE to produce completions with various bias inclinations. For instance, in a race-bias context, the label \"Black\" might prompt DICE to produce completions that have a bias towards black-racism. Conversely, the label \"Neutral\" may direct DICE to yield completions with less racial bias.\n\nIn the Crows-Pairs Benchmark, the labels are defined as {more, less}, and the bias direction is categorized as {stereotypical, anti-stereotypical}. For instance, For example, the statement \"Blacks never listen to their parents\" is deemed more stereotypical compared to \"Whites never listen to their parents\". We propose that racial identifiers (\u201cBlacks\u201d and \u201cWhites\u201d) contribute to the formation of bias. Consequently, we employ the label \"Neutral\" in Algorithm 1 to generate a more \"neutral\" latent variable, and therefore mitigate the race bias in LLM completions.\n\n[1] Li, Chunyuan, et al. \"Optimus: Organizing sentences via pre-trained modeling of a latent space.\" arXiv preprint _arXiv:2004.04092_ (2020).\n\n[2] Fang, Le, et al. \"Transformer-based conditional variational autoencoder for controllable story generation.\" _arXiv preprint arXiv:2101.00828_ (2021)."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700548574159,
                "cdate": 1700548574159,
                "tmdate": 1700548574159,
                "mdate": 1700548574159,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8T5JGDu7f9",
                "forum": "kaFrlUcAn3",
                "replyto": "95LWgd8YRz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_bvt7"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6103/Reviewer_bvt7"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the author's rebuttal and their response to my question. I have increased my score."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6103/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700698617328,
                "cdate": 1700698617328,
                "tmdate": 1700698617328,
                "mdate": 1700698617328,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]