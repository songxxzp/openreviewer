[
    {
        "title": "Large Multimodal Model for Real-World Radiology Report Generation"
    },
    {
        "review": {
            "id": "uoJ52rjPpO",
            "forum": "3Jl0sjmZx9",
            "replyto": "3Jl0sjmZx9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_uSN9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_uSN9"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduced a new problem setting, real-world radiology report generation, that focuses on interactivity, following instructions, and considering various context information. The authors constructed a new benchmark dataset for this purpose and proposed a Domain-enhanced Multi-Modal (DeMMo) model, a variant of Flamingo model, to improve the medical domain-specific abilities."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The focus on real-world radiology report generation is designed to be practical and applicable in clinical settings, which is great in terms of translational impact.\n- The benchmark is very useful to the community. \n- The model integrates an additional domain-specific medical encoder to the perceiver resampler, enhancing its ability to capture detailed visual features in the medical domain."
                },
                "weaknesses": {
                    "value": "- Lack of model efficiency analysis\n- Since the proposed benchmark is one of the core contributions in this work, please describe how do you plan to make it publicly available."
                },
                "questions": {
                    "value": "1. Could you please add the number of model parameters and flops in the result Tables?\n2. How do you plan to make the dataset available to the community?\n3. Where do you plan to host this benchmark? CodaLab could be a good platform."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7532/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698788610285,
            "cdate": 1698788610285,
            "tmdate": 1699636909551,
            "mdate": 1699636909551,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Fwda1UxZ8M",
                "forum": "3Jl0sjmZx9",
                "replyto": "uoJ52rjPpO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uSN9"
                    },
                    "comment": {
                        "value": "We thank you for your time and valuable comments.\n\n### Response to model efficiency (Weakness 1 and Question 1)\n\n> Lack of model efficiency analysis\n> Could you please add the number of model parameters and flops in the result Tables?\n\nSince the baseline ChatCAD+ employs ChatGPT API for summarization, it makes the comparison of model parameters or FLOPs not applicable. For our model, the total number of parameters is about 8.25 billion, and the FLOPs is about 1,000 to 2000 billion, depending on the length of input and out.\n\n### Response to data publication (Weakness 2 & Question 2 & 3)\n\n> Since the proposed benchmark is one of the core contributions in this work, please describe how do you plan to make it publicly available.\n> How do you plan to make the dataset available to the community?\n> Where do you plan to host this benchmark? CodaLab could be a good platform.\n\nWe plan to release our dataset on PhysioNet (where MIMIC-CXR is hosted) after a larger-scale validation and cleaning."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688693520,
                "cdate": 1700688693520,
                "tmdate": 1700688693520,
                "mdate": 1700688693520,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ggZcKhMB7f",
            "forum": "3Jl0sjmZx9",
            "replyto": "3Jl0sjmZx9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_watP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_watP"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce a novel problem setting for real-world report generation that closely simulates clinical practices by integrating various clinical interactions and contextual information. They also present DeMMo, a substantial multimodal model enriched with domain-specific capabilities achieved by integrating a general domain Flamingo model with an additional medical vision encoder."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "(1) The incorporation of user instructions into the generation process is a valuable enhancement for improving the quality of generated reports."
                },
                "weaknesses": {
                    "value": "(1) The novelty of DeMMo is somewhat limited.\n(2) The inclusion of user instructions may raise concerns about the trustworthiness of generated texts, necessitating careful manual review by doctors, potentially leading to increased time and effort.\n(3) The test dataset sizes are notably smaller in comparison to the training datasets.\n(4) Relying solely on a single self-constructed dataset for experiments lacks robustness. Additional datasets should be considered for validation.\n(5) The addition of an extra encoder in DeMMo could potentially introduce computational overhead, impacting overall efficiency."
                },
                "questions": {
                    "value": "(1) In Table 5, DeMMo's performance on BLEU@1 appears suboptimal. Could you explain the reasons for this lower performance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7532/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698821205704,
            "cdate": 1698821205704,
            "tmdate": 1699636909427,
            "mdate": 1699636909427,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SJt9Nm6t0P",
                "forum": "3Jl0sjmZx9",
                "replyto": "ggZcKhMB7f",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer watP"
                    },
                    "comment": {
                        "value": "We appreciate your valuable reviews and comments.\n### Response to novelty (Weakness 1)\n\n> The novelty of DeMMo is somewhat limited.\n\nPlease refer to the discussion on novelty in our general response.\n\n### Response to data validation (Weakness 2)\n\n> The inclusion of user instructions may raise concerns about the trustworthiness of generated texts, necessitating careful manual review by doctors, potentially leading to increased time and effort.\n\nPlease refer to our general response for discussion on data validation.\n\n### Response to test data size (Weakness 3)\n\n> The test dataset sizes are notably smaller in comparison to the training datasets.\n\nOur dataset is generated based on MIMIC-CXR, therefore we adopt the official split of the dataset, which means all data generated using test samples in MIMIC-CXR is also used as test sample in our generated data. After some automatic parsing and filtering, the generated test set size reduces accordingly with generated training set. Therefore we think our test set size is reasonable by referring to the official train/test ratio of MIMIC-CXR.\n\n### Response to additional datasets (Weakness 4)\n\n> Relying solely on a single self-constructed dataset for experiments lacks robustness. Additional datasets should be considered for validation.\n\n- **MIMIC-CXR** We only conduct experiment on MIMIC-CXR because it is the most popular and largest high-quality report generation dataset to date. Other report generation datasets such as IU X-Ray has only about 3,000 samples. We think setting up another benchmark and generating a set of context data on such small-scale dataset would not give much benefits or significance. \n- **Additional validation** Since we propose a new set of real-world report generation tasks with additional context, we could only rely on the self-constructed dataset for experiment, which also includes the real MIMIC-CXR dataset. For additional validation dataset, we have constructed a fully validated test set for further validation of our model trained on the generated dataset. Please refer to the response to data validation section in our general response.\n\n\n### Response to computational overhead (Weakness 5)\n\n> The addition of an extra encoder in DeMMo could potentially introduce computational overhead, impacting overall efficiency.\n\nCompared to the LLM part of Flamingo, the number of paramters in the newly added vision encoder, which is a ResNet-50 model, is very small. The Flamingo model has more than 8 billions of parameters, while the newly added vision encoder only has about 26 million parameters, which is about 0.3% more parameters. The complexity increase can be ignored.\n\n### Response to lower BLEU@1 (Question 1)\n\n> In Table 5, DeMMo's performance on BLEU@1 appears suboptimal. Could you explain the reasons for this lower performance?\n\n- **CE metrics preferred over NLG metrics.** We want to first emphasize the significance of clinical efficacy (precision, recall, F1) over NLG metrics for report generation tasks. N-gram-based NLG metrics such as BLEU generally enforce a strict word matching and therefore lack semantic understanding. In comparison, CE metrics employ robust NLP tools to extract pathological labels from text for comparison, which is more crucial for clinal report tasks. It is possible for a generated report that has lots of word overlap with ground truth but no correct clinical findings.\n- **Reason for lower BLEU@1** This means our model generates text that, while perhaps not closely matching the ground truth report in terms of phrasing or word choice, is however more effective in a real-world clinical context. This shows that our model is able to generalize better and give more diverse phrases while also maintaining good clinical efficacy, but the baseline methods may be overfitted to some high-frequency phrases or sentences that do not give enough useful information (e.g. frontal and lateral views of the chest were obtained) and therefore does not give accurate clinical diagnosis."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688439780,
                "cdate": 1700688439780,
                "tmdate": 1700688439780,
                "mdate": 1700688439780,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Rhgw97bvv2",
            "forum": "3Jl0sjmZx9",
            "replyto": "3Jl0sjmZx9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_8G3W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_8G3W"
            ],
            "content": {
                "summary": {
                    "value": "This paper propose a new benchmark dataset for medical report generation with building a unified data generation pipeline. It also proposed a domain-specific multi-modal model (DeMMo) to improve the raw llm for medical report generation. Experiments show the method is good."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The motivation makes sense. It should be quite helpful and natural to use instruction/context to generate better medical report.\n2. The paper has did plenty of experiments to show the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1. It is not clear how to generate the I, C and R', which is critical in this paper.  Also, I'm not sure if the quality of generated data by the unified pipeline is good or not, though the authors mention there are professions who help check them. \n2. The comparison in Table 3 shows the advantage of the proposed method in this paper, which is mainly due to the domain-specific encoder. However, will the computational complexity be much larger?\n3. The dataset (MIMIC-R3G) is not open sourced or not mentioned to open source it in future."
                },
                "questions": {
                    "value": "1. I'm not sure if the generated I, C and R' are fixed or can be different at different time. To me, a benchmark dataset should better be fixed.\n2. Does every patient have the previous visit data in MIMIC-CXR? How do you deal with those who have no previous data?\n3. \"In summary, our medical professionals have determined that no significant factual discrepancies exist between the content generated by GPT and the ground-truth reports across all samples\". Can you please introduce more about it? Especially considering the huge number of samples in the dataset.\n4. The experiments mainly talk about the effectiveness of the method, how we can assess the quality of the data."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Discrimination / bias / fairness concerns"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Considering the R3G is generated by a pipeline, so we are not sure about if there are discrimination/bias/fairness concerns."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7532/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699032272625,
            "cdate": 1699032272625,
            "tmdate": 1699636909306,
            "mdate": 1699636909306,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "upT6I3hgj9",
                "forum": "3Jl0sjmZx9",
                "replyto": "Rhgw97bvv2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8G3W"
                    },
                    "comment": {
                        "value": "We appreciate your valuable comments.\n\n### Response to generated context (Weakness 1 & Question 1)\n\n> It is not clear how to generate the I, C and R', which is critical in this paper...\n> I'm not sure if the generated I, C and R' are fixed or can be different at different time. To me, a benchmark dataset should better be fixed.\n\n - **Generating context** Due to limited space, we show more examples of how to generate context data using a ground truth report in Appendix B. In general, we design specific system messages for each task and input the ground truth report to ChatGPT, with some in-context examples to guide the format of response. We then parse the formatted ChatGPT response as the context data $I$, $C$, and $R'$ for each task respectively.\n - **The benchmark is fixed** It is true that ChatGPT introduces randomness in the generation result, however, the benchmark dataset should be the generated result, which is fixed. Many other outstanding works follow the same paradigms for creating datasets/benchmarks using GPT or similar LLMs [1,2,3,4,5].\n\n### Response to computational complexity (Weakness 2)\n\n> The comparison in Table 3 shows the advantage of the proposed method in this paper, which is mainly due to the domain-specific encoder. However, will the computational complexity be much larger?\n\nCompared to the LLM part of Flamingo, the number of parameters in the newly added vision encoder, which is a ResNet-50 model, is very small. The Flamingo model has more than 8 billion parameters, while the newly added vision encoder only has about 26 million parameters, which is about 0.3% increase. The complexity increase can be ignored.\n\n### Response to data publication (Weakness 3)\n\n> The dataset (MIMIC-R3G) is not open sourced or not mentioned to open source it in future.\n\nWe plan to release our dataset on PhysioNet (where MIMIC-CXR is hosted) after a larger-scale validation and cleaning.\n\n### Response to previous visit data (Question 2)\n\n> Does every patient have the previous visit data in MIMIC-CXR? How do you deal with those who have no previous data?\n\nNo, not all patients have a previous visit data in MIMIC-CXR. In our experiments on MIMIC-CXR, we simply exclude the sample for this task in the dataset when the previous data is not available.\n\n### Response to data validation (Weakness 1 & Question 3 & 4)\n\n> ...Also, I'm not sure if the quality of generated data by the unified pipeline is good or not, though the authors mention there are professions who help check them.\n> \"In summary, our medical professionals have determined that no significant factual discrepancies exist between the content generated by GPT and the ground-truth reports across all samples\". Can you please introduce more about it? Especially considering the huge number of samples in the dataset.\n> The experiments mainly talk about the effectiveness of the method, how we can assess the quality of the data.\n\nPlease refer to our general response on dataset validation.\n\n### Response to ethics concerns\n\n> Considering the R3G is generated by a pipeline, so we are not sure about if there are discrimination/bias/fairness concerns.\n\nOur generated data is based on MIMIC-CXR, which undergoes appropriate anonymization process, with all sensitive information that could potentially lead to discrimination/bias/fairness issues being masked. We believe our generation approach, specifically on generating medical record/test results, is neutral and will not introduce extra ethical concerns given that the input has no source of discrimination/bias such as race, nationality, social status, etc., and only focus on medical reasoning. Other tasks will not introduce discrimination/fairness issues since we only do generation at format or text level modification. \n\nReference:\n\n[1] Liu, Haotian, et al. \"Visual instruction tuning.\" arXiv preprint arXiv:2304.08485 (2023).\n\n[2] Li, Bohao, et al. \"Seed-bench: Benchmarking multimodal llms with generative comprehension.\" arXiv preprint arXiv:2307.16125 (2023).\n\n[3] Yin, Zhenfei, et al. \"LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset, Framework, and Benchmark.\" arXiv preprint arXiv:2306.06687 (2023).\n\n[4] Li, Bo, et al. \"Mimic-it: Multi-modal in-context instruction tuning.\" arXiv preprint arXiv:2306.05425 (2023).\n\n[5] Li, KunChang, et al. \"Videochat: Chat-centric video understanding.\" arXiv preprint arXiv:2305.06355 (2023)."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688314771,
                "cdate": 1700688314771,
                "tmdate": 1700688314771,
                "mdate": 1700688314771,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GrOZ6BEpr5",
            "forum": "3Jl0sjmZx9",
            "replyto": "3Jl0sjmZx9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_GGyY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_GGyY"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an automated radiology report generation system trained on the newly created MIMIC-R3G dataset. This dataset focuses on practical tasks that are somewhat overlooked in the literature. The authors employ a GPT-based data generation pipeline to synthesize training data across different R3G tasks. The experimental outcomes presented in the paper suggest that the proposed DeMMo can outperform existing approaches in radiology report generation according to evaluations on the MIMIC-R3G benchmark."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The manuscript targets meaningful and less explored tasks in radiology report generation, covering a variety of scenarios. This focus is commendable as it moves the field towards clinically applicable solutions in automatic report generation.\n- By utilizing ChatGPT for data generation, the authors propose a potential solution to mitigate the issue of data scarcity in complex report generation tasks.\n- The adaptation of Flamingo and prompt tuning in the proposed DeMMo model demonstrate improved quantitative results over existing methods.\n- The manuscript is well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "- Despite addressing significant tasks in clinical practice, the manuscript's technical contributions appear incremental and may not align with the expectations of the ICLR community. The content might be more suited to specialized medical-related conferences like MICCAI or IPMI.\n- The methodology for constructing the MIMIC-R3G dataset, particularly the generation of reports that integrate prior patient visits and additional lab test information, lacks rigorous clinical validation. To ensure the clinical relevance of the generated data, it would be beneficial to include samples that have been validated by healthcare professionals. This is also true for the generated reports.\n- Detailed statistical validation and significance testing could strengthen the results section. While the proposed DeMMo generally performs better than baseline models in terms of NLG metrics, the recall of CE seems to be lower than ChatCAD.\n- The paper would benefit from a more in-depth qualitative analysis. Comparative examples of reports generated by different models could offer valuable insights into each model's strengths and limitations, providing a clearer understanding of the practical implications of their use in clinical settings."
                },
                "questions": {
                    "value": "- The manuscript would greatly benefit from the inclusion of clinical validations for the synthesized training data. Can the authors present any evaluations conducted by medical professionals to verify the clinical accuracy of the generated data? The same question applies to the generated reports; providing clinical validations would significantly enhance the paper's credibility.\n- Will the constructed MIMIC-R3G benchmark be publically available?\n- I would recommend a more thorough statistical analysis of the results to better elucidate the significance of the findings. Additionally, providing qualitative comparisons of the reports generated by DeMMo and other baseline models would offer deeper insights into the practical utility of the proposed model.\n- It is noted that the recall for CE by DeMMo tends to be lower compared to the baseline model ChatCAD. Could the authors delve into possible reasons for this discrepancy and suggest potential improvements?\n\nMinor:\n- Citation formats in 6.2 and Supp: A are inconsistent. There is one missing citation in Supp: E."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7532/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7532/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7532/Reviewer_GGyY"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7532/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699182013757,
            "cdate": 1699182013757,
            "tmdate": 1699636909171,
            "mdate": 1699636909171,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "901v15fAXt",
                "forum": "3Jl0sjmZx9",
                "replyto": "GrOZ6BEpr5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer GGyY (Part 1)"
                    },
                    "comment": {
                        "value": "Thank you for the valuable review and comments.\n\n### Response to technical contribution (Weakness 1)\n\n> Despite addressing significant tasks in clinical practice, the manuscript's technical contributions appear incremental and may not align with the expectations of the ICLR community. The content might be more suited to specialized medical-related conferences like MICCAI or IPMI.\n\nPlease refer to our general response. Also, there are many other medical domain works that have been accepted or received good feedback from the reviewers on ICLR last year [1,2,3] and this year [4,5]. Moreover, our proposed framework DeMMo can be extended to enhance multimoal LLM for other domains as well. Therefore we think our paper should also be valuable for the ICLR community.\n\n### Response to data validation (Weakness 2 & Question 1)\n\n> The methodology for constructing the MIMIC-R3G dataset, particularly the generation of reports that integrate prior patient visits and additional lab test information, lacks rigorous clinical validation. To ensure the clinical relevance of the generated data, it would be beneficial to include samples that have been validated by healthcare professionals. This is also true for the generated reports.\n> The manuscript would greatly benefit from the inclusion of clinical validations for the synthesized training data. Can the authors present any evaluations conducted by medical professionals to verify the clinical accuracy of the generated data? The same question applies to the generated reports; providing clinical validations would significantly enhance the paper's credibility.\n\nPlease refer to our general response. In our experiments we do not use generated report for prior visits since we can retrieve prior visits within the MIMIC-CXR data following metadata included. For 4 of the 5 tasks, we directly use the ground truth from MIMIC-CXR dataset unchanged. The template task uses the generated ground truth, but the modification should be only on the format scale and does not affect the clinical information. We have validated on small subset and we will perform further larger-scale validation and cleaning before releasing the dataset.\n\n### Response to statistical analysis (Weakness 3 & Question 3)\n\n> Detailed statistical validation and significance testing could strengthen the results section. While the proposed DeMMo generally performs better than baseline models in terms of NLG metrics...\n> I would recommend a more thorough statistical analysis of the results to better elucidate the significance of the findings...\n\nPlease refer to Part 3 of our general response.\n\n### Response to more qualitative results (Weakness 4 & Question 3)\n\n> The paper would benefit from a more in-depth qualitative analysis. Comparative examples of reports generated by different models could offer valuable insights into each model's strengths and limitations, providing a clearer understanding of the practical implications of their use in clinical settings.\n> ...Additionally, providing qualitative comparisons of the reports generated by DeMMo and other baseline models would offer deeper insights into the practical utility of the proposed model.\n\nWe add an additional section in the appendix to show some comparison results of ours and baseline output and provide some analysis on the strengths and limitations of each method.\n\n### Response to lower recall (Weakness 3 & Question 4)\n\n> While the proposed DeMMo generally performs better than baseline models in terms of NLG metrics, the recall of CE seems to be lower than ChatCAD.\n> It is noted that the recall for CE by DeMMo tends to be lower compared to the baseline model ChatCAD. Could the authors delve into possible reasons for this discrepancy and suggest potential improvements?\n\nChatCAD+ is a framework that leverages a pretrained classifier to produce some initial diagnosis result based on the input image. The pretrained classifier is on 5 pathologic labels only but the accuracy is guaranteed and employed extra classification training data, while our approach does not have such accurate prior information or extra training data therefore a slightly lower recall in some cases. For future works we might work on incorporating additional models for combining results from different modalities as well including classification results and grounding/segmentation results. \n\n\n### Response to dataset publication (Question 2)\n\n> Will the constructed MIMIC-R3G benchmark be publically available?\n\nYes, we plan to release our dataset on PhysioNet (where MIMIC-CXR is hosted) after a larger-scale validation and cleaning."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687913571,
                "cdate": 1700687913571,
                "tmdate": 1700713921532,
                "mdate": 1700713921532,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "89JgJhgcHG",
                "forum": "3Jl0sjmZx9",
                "replyto": "GrOZ6BEpr5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer GGyY (Part 2)"
                    },
                    "comment": {
                        "value": "### Response to Minor\n\n> Citation formats in 6.2 and Supp: A are inconsistent. There is one missing citation in Supp: E.\n\nThank you so much for pointing these out. We have fixed the citations.\n\n\nReference:\n\n[1] Qin, Ziyuan, et al. \"Medical image understanding with pretrained vision language models: A comprehensive study.\" The Eleventh International Conference on Learning Representations (2023).\n\n[2] Zong, Yongshuo, et al. \"MEDFAIR: Benchmarking Fairness for Medical Imaging.\" The Eleventh International Conference on Learning Representations (2023).\n\n[3] Zhao, Yuzhong, et al. \"AE-FLOW: Autoencoders with Normalizing Flows for Medical Images Anomaly Detection.\" The Eleventh International Conference on Learning Representations (2023).\n\n[4] Anonymous. \"MedJourney: Counterfactual Medical Image Generation by Instruction-Learning from Multimodal Patient Journeys.\" Submitted to The Twelfth International Conference on Learning Representations (2023).\n\n[5] Anonymous. \"LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation.\" Submitted to The Twelfth International Conference on Learning Representations (2023)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687973528,
                "cdate": 1700687973528,
                "tmdate": 1700687973528,
                "mdate": 1700687973528,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LYjRhMCXyU",
            "forum": "3Jl0sjmZx9",
            "replyto": "3Jl0sjmZx9",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_NXpC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7532/Reviewer_NXpC"
            ],
            "content": {
                "summary": {
                    "value": "This paper made serveral technical contributions to mimic how a real radiologist will do the report generation process in a more realistic work environment. All these contributions as listed in section one are valid scientific contributions. I think there should be some credits for that, advancing from the previous literature. \n\nThis paper/work is developed using Flemingo general vision encoder and ChatGPT tools. This would be reasonable but the dependency on using ChatGPT will decrease its scientific values. More detailed comments will follow in later comments."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper made serveral technical contributions to mimic how a real radiologist will do the report generation process in a more realistic work environment. All these contributions as listed in section one are valid scientific contributions. I think there should be some credits for that, advancing from the previous literature."
                },
                "weaknesses": {
                    "value": "However I would argue, given the current technical roadmap setup as demonstrated in this paper, you can generate fairly interesting generated reports as results, but this is probably on the wrong technical path to build a automatic reporting system for reliable clinical report generation, no matter you use ChatGPT or even GPT4-V models.\n\nThe essential problem/challenges in accurate and automatic clinical report generation are at the core of detecting/localizing all pathological or clinically significant findings, then classifying/diagnosing these findings acurately and finally forming all findings with diagnosis into a report where the physician can verify and modify for the final use (as a real world clinical adoption).\n\n1, you need be abe to extract/balidate fairly accurate finding labels from training reports using NLP tools (maybe chatGPT, maybe special bio-NLP tools).\n\n2, you need to solve the weakly supervised localization/detection issue by mapping the labels to the image regions (which is called visual grounding).\n\n3, Hopefully with powerful and robust NLP and vision tools, you can curate a dataset by integrating/iterating the above two steps.  Then you need to a train vision encoder/decoder to find pathologies with desirably accurate results on new images to generate an initial report.\n\n4, Doing clinical diagnosis on these findings and comparing the current findings to previous studies to derive the temporal change information (you need to build a classifier according ontology for dignosis and image matching/alignment modules by tracking these findings over time).\n\n5, forming a report and providing means (hyperlinks) for human physicians to inspect and accept and edit the report.\n\nThe above steps are logically impossible to bypass if you want to build a useful clinical assist tool in the real world. Your paper as currently does not do the above items. I am not convinced if the goal is to build a clinically viable report generation tool, how would you be able to achieve that."
                },
                "questions": {
                    "value": "Please answer the weakness as provided above. Many if not most of report generation papers no matter where they publish do not understand underlying what are clinically essential informations where report should have, and how ...."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7532/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7532/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7532/Reviewer_NXpC"
                    ]
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7532/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700443975383,
            "cdate": 1700443975383,
            "tmdate": 1700443975383,
            "mdate": 1700443975383,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9nKzE84j1w",
                "forum": "3Jl0sjmZx9",
                "replyto": "LYjRhMCXyU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Reviewer_NXpC"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Reviewer_NXpC"
                ],
                "content": {
                    "title": {
                        "value": "additional questions:"
                    },
                    "comment": {
                        "value": "1, in section 4, not sure how ChatGPT can modify the reports with significant factual changes without \"looking at\" the images and hopefully with a super high quality visual grounding to accept/reject the clinically significant findings. These revisions are for what purpose? how reliable it can be ... will these revision can potentially cause miss-diagnosis?\n\n2, \"previous visit as context\": how a random report can serve as pseudo previous report? According the information theory, when there is no new information, just keep the way it is as an empty prior. Injecting a wrong previous resport seems potentially causing diagnosis errors?\n\n3, using a medical professional to validate a subset of generated data is not really a reliable approach. Reading check x-ray is not an easy task for radiologists and they can have large inter-observer variations.\n\n4, in Table 2, it is nice and convenient to have all functions. I can see the radiologists could have convenience on editing/producing reports but by reading into the details on these actual report contents, how you guarantee high accuracy in the content it generated/modified. If these reports are for the true purpose of performing diagnosis on real patients, should we trust the critical clinical accuracy of the contents generated from Table 2, or you are just showing the functions?\n\nLast but not least, the overall technical novelty and contributions of this submission is very incremental, too much on using ChatGPT type of tool for such a report generation purpose. This may not be sufficiently competitive for ICLR standard."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700445916385,
                "cdate": 1700445916385,
                "tmdate": 1700446459125,
                "mdate": 1700446459125,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BGYbVy4Pmg",
                "forum": "3Jl0sjmZx9",
                "replyto": "LYjRhMCXyU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NXpC (Part 1)"
                    },
                    "comment": {
                        "value": "Thanks for your insightful comments regarding technical roadmap and other valuable questions.\n\n### Response to technical path\n\n> However I would argue, given the current technical roadmap setup as demonstrated in this paper, you can generate fairly interesting generated reports as results, but this is probably on the wrong technical path to build an automatic reporting system for reliable clinical report generation, no matter you use ChatGPT or even GPT4-V models...The above steps are logically impossible to bypass if you want to build a useful clinical assist tool in the real world. Your paper as currently does not do the above items. I am not convinced if the goal is to build a clinically viable report generation tool, how would you be able to achieve that.\n\n\n- **Benefits in our technical path** We agree that what you listed is a reliable and accurate way of building a report generation pipeline, but it lacks the flexibility of differnt format of input or output. This flexibility of taking different forms of context input and output in different forms for report generation is what we really mean by saying \"real-world\", and we apologize if this leads to any confusion. The technical paths of training language models end-to-end has the potential and flexibility of doing such tasks. Given the strong language understanding and generation ability, leveraging a pretrained LLM would enable diverse, comprehensive and long input and output with good generalizability. Our proposed approach of adapting multimodal language model is able to customize the model for this flexibility as long as you have the training data, and one of our main contributions is just to create these data from existing text report. We also want to emphasize that our technical path also has good potential for further improving accuracy and robustness and even for visual output in the future.\n- **Existing works mainly follow similar technical path**  Also, many previous works also went this path of using multimodal LLMs for medical VQA and report generation, such as Microsoft's LLaVa-Med [4] and Google's Med PaLM M [5], Stanford's Med-Flamingo [6], therefore we also want to explore in this technical path.\n- **Achieve/bypass the traditional steps of building report generation system** Below we discuss the 5 steps you mentioned for building a report generation system in detail and how this technical path of training end-to-end using text-image paired data achieves the critical functionality or bypass some unnecessary steps."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686944635,
                "cdate": 1700686944635,
                "tmdate": 1700687548011,
                "mdate": 1700687548011,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "16NAvmh5NQ",
                "forum": "3Jl0sjmZx9",
                "replyto": "LYjRhMCXyU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NXpC (Part 2)"
                    },
                    "comment": {
                        "value": "- **Label extraction and visual grounding.** First of all, you mentioned label extraction and visual grounding in the context of creating a dataset that including the localization information that could help generate accurate report. We are not sure why you mention weakness 1 and 2, I guess your belief is that training data should be as accurate and finegrained as pathological labels and corresponding regions, but not a general free-text dataset such as MIMIC-CXR? We believe these two are equivalent, and in many cases image-text pair data is the most and easiest you can get. Given the strong potential of LLM, we believe that these steps can be skipped if your goal is to generate a text report and don't care any visual or structured label output. Most previous works that are language model based cited in our paper do not need data other than image and report text. As an example for location, in our generated report template data, there are some generated templates that require the physician/model to fill in location or indicate absence of each possible pathology label, and our trained model can correctly identify the location most of the time: \n     > TEMPLATE:\n        >- cardiomediastinal contours: \n        >- atelectasis: \n        >- location: \n        >- effusion: \n        >- location:\n        >- interstitial edema:\n        >- location:\n        >- medical devices:\n        >- location: \n        >- type:\n        >\n        > PREDICTED:\n        >- cardiomediastinal contours: stable in appearance.\n        >- atelectasis: worsening predominantly right-sided bibasilar atelectasis.\n        >- location: bibasilar\n        >- effusion: small pleural effusions\n        >- location: right\n        >- interstitial edema: interstitial edema has resolved.\n        >- medical devices:\n        >- location: left internal jugular\n        >- type: central venous catheter.\n        >\n        >GT:\n        >- cardiomediastinal contours: stable appearance\n        >- atelectasis: present\n        >- location: bibasilar\n        >- effusion: present\n        >- location: small right pleural effusion\n        >- interstitial edema: persistent\n        >- medical devices: left internal jugular catheter remains in place within the left superior vena cava.\n\n    Although not the main focus of this paper, we agree that visual grounding is a very important task in medical image analysis, and we hope to enhance our model with that ability in future works. Multimodal LLMs are shown to be able to do visual grounding tasks in general domain [1,2,3], therefore we believe there are ways to adapt this ability to medical domain as well. \n - **Comparing with previous studies using image alignment moduel.** Second, we believe an image matching/alignment module is also not necessary and can be bypassed. Since our model is based on Flamingo, which is able to receive multiple images or even video as input, we are able to input multiple images and previous reports with chronological order to naturally derive the temporal change information. This is included in our tasks in the paper. Previous non-LLM works cited in our paper and general response also achieved this and did not use any image alignment module.\n  - **Human editing.** Lastly, 5 seems like a deployment system design issue and not in our scope of discussion about report generation, however, we include a task that simulates this clinical procedure in our paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687171679,
                "cdate": 1700687171679,
                "tmdate": 1700687465162,
                "mdate": 1700687465162,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "es7MWD07kq",
                "forum": "3Jl0sjmZx9",
                "replyto": "LYjRhMCXyU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7532/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer NXpC (Part 3)"
                    },
                    "comment": {
                        "value": "### Response to report revision (additional question 1)\n\n> in section 4, not sure how ChatGPT can modify the reports with significant factual changes without \"looking at\" the images and hopefully with a super high quality visual grounding to accept/reject the clinically significant findings. These revisions are for what purpose? how reliable it can be ... will these revision can potentially cause miss-diagnosis?\n\nIndeed we use ChatGPT to modify the report without looking at images, but we think there is a potential misunderstanding. In this task we only require ChatGPT to generate a modified report and the instruction of how to change it back into the ground truth report as context input. The ground truth report for training is untouched in this task. The purpose of this is to simulate the \"real-world\" clinical scenario where the physician needs to modify an incorrect report in a comprehensive way, probably also referencing the images (such as the scenario you mentioned in weakness 5). The input is a report that needs to be modified and the corresponding instruction to modify it (these are generated by ChatGPT). The instruction can sometimes be very vague such as \"change the location of catheter tube in the report\", and therefore the model should be able to reference the image for correct location. These revisions will not cause miss-diagnosis because the paired ground truth report and images are not modified, only the input instruction and context is generated. \n\n### Response to previous visit as context (additional question 2)\n\n> \"previous visit as context\": how a random report can serve as pseudo previous report? According the information theory, when there is no new information, just keep the way it is as an empty prior. Injecting a wrong previous resport seems potentially causing diagnosis errors?\n\n - We do not use random or any generated previous report in our experiment. MIMIC-CXR has the metadata that includes patient identifier and chronological order of the reports, therefore we directly parse the metadata and retrieve the previous report within MIMIC-CXR dataset. \n - We also propose an approach to generate \"pseudo report\" when this kind of metadata is not available. For example if the ground truth report have some descriptions like \"compared to previous report, the pleural effusion is resolved\", then ChatGPT generated pseudo previous report should include diagnosis of pleural effusion. This is not random but based on the description in the current report.\n\n### Response to data validation (additional question 3)\n\n> using a medical professional to validate a subset of generated data is not really a reliable approach. Reading check x-ray is not an easy task for radiologists and they can have large inter-observer variations.\n\nPlease also refer to our general response. We agree that inter-observer variations would be large, but given the unmodified ground truth report and medical images for reference, it would be relatively easy to validate the generated data. Also, we will employ some cross-validation to try to reduce the variation.\n\n\n### Response to clinical accuracy (additional question 4)\n\n>...how you guarantee high accuracy in the content it generated/modified. If these reports are for the true purpose of performing diagnosis on real patients, should we trust the critical clinical accuracy of the contents generated from Table 2, or you are just showing the functions?\n\nAmong the 5 tasks, 4 of them directly use the ground truth from MIMIC-CXR dataset unchanged. The template task uses the generated ground truth, but the modification should be only on the format and the clinical meaning should not have changed by ChatGPT. We have validated on small subset and we will perform further larger-scale validation and cleaning before releasing the data.\n\n### Response to technical contribution\n\n> Last but not least, the overall technical novelty and contributions of this submission is very incremental...\n\nPlease refer to our general response regarding technical novelty and contribution. \n\n\nReference:\n\n[1] Wang, Wenhai, et al. \"Visionllm: Large language model is also an open-ended decoder for vision-centric tasks.\" arXiv preprint arXiv:2305.11175 (2023).\n\n[2] Zhao, Yang, et al. \"Bubogpt: Enabling visual grounding in multi-modal llms.\" arXiv preprint arXiv:2307.08581 (2023).\n\n[3] Zhou, Qiang, et al. \"InfMLLM: A Unified Framework for Visual-Language Tasks.\" arXiv preprint arXiv:2311.06791 (2023).\n\n[4] Li, Chunyuan, et al. \"Llava-med: Training a large language-and-vision assistant for biomedicine in one day.\" arXiv preprint arXiv:2306.00890 (2023).\n\n[5] Tu, Tao, et al. \"Towards generalist biomedical ai.\" arXiv preprint arXiv:2307.14334 (2023).\n\n[6] Moor, Michael, et al. \"Med-flamingo: a multimodal medical few-shot learner.\" arXiv preprint arXiv:2307.15189 (2023)."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7532/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687326659,
                "cdate": 1700687326659,
                "tmdate": 1700687698778,
                "mdate": 1700687698778,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]