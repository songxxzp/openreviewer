[
    {
        "title": "A Benchmark Study on Calibration"
    },
    {
        "review": {
            "id": "Hw5vRYq2tc",
            "forum": "GzNhzX9kVa",
            "replyto": "GzNhzX9kVa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1053/Reviewer_qRJE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1053/Reviewer_qRJE"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the calibration properties of deep neural networks (DNNs) using neural architecture search (NAS) search space. The motivation stems around the observation that, calibration properties of DNNs have not been thoroughly studied in the past, and NAS search space allows to create a comprehensive dataset of neural network architectures, which can be evaluated to study calibration properties. The dataset encompasses several bin-based and other calibration measurements across 117,702 unique neural network architectures. Particularly, the NATS-Bench has been used to curate the proposed dataset as it allows more broader search space, comprising models of various sizes. The study also includes eleven recent vision transformer architectures. The proposed analyses aims to answer seven different questions, including the interplay between accuracy and calibration, if calibration performance generalizes across datasets, the impact of bin sizes on calibration measurement, and which architectures are better for calibration. Post-hoc temperature scaling method is used as a calibration technique."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The study of calibration properties of deep neural networks is an important research direction as it could allow developing well-calibrated architectures.\n\n- The paper develops a comprehensive benchmark of neural network architectures that are then evaluated on different datasets to answer various questions. Further, recent vision transformer architectures have also been included as part of evaluation.\n\n- Some questions included in the study are interesting and important: such as the Impact of bin sizes on calibration measurement and can model calibration be generalized across different datasets.\n\n- Overall, the paper is well-written and it is not difficult to read and understand."
                },
                "weaknesses": {
                    "value": "- Overall, the new questions posed and studied by the paper boils down to 1), 3) and 6) which are:\n\n-- Model Calibration across different datasets\n\n-- Reliability of calibration metrics\n\n-- Impact of bin size on calibration metrics\n\n- Other questions are mostly expansion of existing studies. This seems to undermine the overall contributions of the paper to some extent.\n\n-Only post-hoc temperature scaling is used as a calibration technique to evaluate pre- and post calibration performance of a large chunk of models. There have been several new calibration methods, especially in train-time calibration paradigm, such as [A], [B] and [C].\n\n-In 4.3: 1) What are the possible reasons of ECE showing consistent results with other metrics, although some other metrics are theoretically different? 2) Also, it is not clear that which calibration metric should be preferred over others in the scope of studies?\n\n- What is the significance of 4th question (i.e. does a post-hoc calibration affect all models uniformly) in terms of advancing the research and algorithmic development in calibration?\n\n- The abstract mentions \u2018data pre-processing\u2019 methods for improving calibration but such methods are discussed nowhere in the paper, including the related work.\n\n\n[A] Liu, B., Ben Ayed, I., Galdran, A. and Dolz, J., 2022. The devil is in the margin: Margin-based label smoothing for network calibration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 80-88).\n\n[B] Patra, R., Hebbalaguppe, R., Dash, T., Shroff, G. and Vig, L., 2023. Calibrating deep neural networks using explicit regularisation and dynamic data pruning. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1541-1549)\n\n[C] Hebbalaguppe, R., Prakash, J., Madan, N. and Arora, C., 2022. A stitch in time saves nine: A train-time regularizing loss for improved neural network calibration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 16081-16090)."
                },
                "questions": {
                    "value": "- How the proposed study and dataset would be helpful toward the development of new calibration methods for classification?\n\n- It is a bit hard to grasp how the current analyses addresses the question of how reliable are calibration metrics?\n\n- Would the finding that the bin size has a more substantial impact on Post-ECE be relevant for any train-time calibration technique too?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethical concerns could be identified."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1053/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1053/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1053/Reviewer_qRJE"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1053/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698736185127,
            "cdate": 1698736185127,
            "tmdate": 1699636031557,
            "mdate": 1699636031557,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uDkRYjmZGS",
                "forum": "GzNhzX9kVa",
                "replyto": "Hw5vRYq2tc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the valuable comments from Reviewer qRJE\n\n**Re Expansion of existing studies:** We agree studies are the expansion of current research, however, they provide some different results from previous study. For example,\n- Previous works use AuC on OoD datasets  as a measurement of calibration[1][2]. However, in Section 4.2 we found that there is no correlation between the AuC and ECE, which indicate AuC on OoD may not be a reliable calibration measurement.\n- In section 4.4, we observe that a well calibrated model may not achieve better post-hoc calibration performance than a poor calibrated model. This observation supports the \u201ccalibratable\u201d objective proposed in [1][2][3] in a way that research should focus more on obtaining a model with better post hoc calibration performance. Since the post-hoc calibration methods like temperature scaling are computationally cheap and effective, an overall calibration performance worth more attention. See more details in section \"Re significance of Section 4.4\".\n- Section 4.6 study the relationship between accuracy and calibration and section 4.7 study the architecture design for better calibration performance,  which are neither studied before from our understanding.\n\n**Re other calibration methods:** Following the suggestion, we incorporated Focal Loss[2] and MMCE Loss[11] as additional calibration methods. We trained six human-designed CNN models\u2014ResNet18, ResNet34, ResNet50, ResNet110, Wide-ResNet-26-10, and Densenet121\u2014on CIFAR-10 and CIFAR-100 using Focal Loss and MMCE Loss, both recognized as classic train-time calibration methods. Our observations, consistent with those reported in Appendix B, are detailed in Figure 16. As depicted in Figure 16 and similar to Figure 2, models trained using different train-time calibration methods all exhibit little correlation between results on CIFAR-10 and CIFAR-100. This suggests that the calibration properties of a specific architecture may not generalize effectively across different datasets. In Figure 17, ECE evaluated across different bin sizes shows little correlation between pre and post temperature scaling, indicating that well-calibrated models do not necessarily show improved calibration performance after post-hoc calibration techniques. This trend is particularly pronounced on CIFAR-100, where post-hoc calibration performance becomes negatively correlated with pre-calibration performance. Additionally, we observe that bin size can significantly impact post-hoc calibration performance, aligning with the observations in Section 4.4. In terms of the reliability of calibration metrics, we conducted an analysis of the correlation between all calibration metrics, as presented in Figure 14 in Appendix A and Figure 18 and Figure 19 in Appendix B. Notably, equal-mass classwise ECE exhibits a different pattern compared to other metrics, especially on CIFAR-100, reinforcing the observations outlined in Section 4.3.\n\n\n**Re consistency between metrics and preferred calibration metrics:**\nAlthough some other metrics are theoretically different from ECE, they share the same objective which aims to measure the alignment between the true likelihood and the predicted confidence. Thus, ECE shows consistent results with other metrics. However, this consistency is significantly influenced by the way how to approximate this alignment, such as the binning scheme. We mainly attribute the gap between class wise ECE and other metrics to the scenarios where the equal mass binning strategy aims to distribute samples uniformly across bins in a multi-class setting. This approach often leads to a scenario where the negative class is predominant. In practical applications of multiclass prediction, it's common for the model to assign very low confidence scores to a majority of the classes, often more than 95 out of 100. These low scores, hovering close to zero, indicate an absence of uncertainty. Equal mass class wise ECE will assign almost all bins to these near-zero confidence samples, except for one. Thus, equal mass binning experiences a significant decrease in estimation accuracy, making it unreliable. Thus, although all these metrics share the same objective, some of them cannot provide a precise estimation of this alignment in some scenarios. Considering this fact, we conduct the evaluation of the reliability of calibration metrics as in section 4.3, which we observe the unreliability of equal mass class wise ECE. On the other hand, the consistency between different calibration metrics with different theories such as ECE and MMCE support the reliability of metrics against each other. In the current stage, we recommend the use of calibration metrics that are more consistent with each other, such as ECE and MMCE."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699883745555,
                "cdate": 1699883745555,
                "tmdate": 1699883957957,
                "mdate": 1699883957957,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pLgp3kUwUc",
                "forum": "GzNhzX9kVa",
                "replyto": "Hw5vRYq2tc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Re significance of Section 4.4:** In Section 4.4, our observation highlights that a well-calibrated model with superior pre-calibration ECE may not necessarily achieve better post-hoc calibration performance than a poorly calibrated model with a higher pre-calibration ECE. For instance, in the table below, Model A exhibits a better pre-calibration ECE than Model B but offers less room for improvement through post-hoc methods, resulting in a poorer post-hoc ECE than Model B. Given that post-hoc calibration methods, such as temperature scaling, are both computationally efficient and effective, prioritizing an overall better calibration performance, or \"calibratability,\" deserves more attention. Our observation supports the \"calibratable\" objective proposed in [1][2][3], suggesting that research efforts should prioritize achieving models with superior post-hoc calibration performance.\n| Model |  Accuracy%|Pre ECE%|Post ECE%|\n|--|--|--|--|\n| A | 95.05|2.994 |1.978|\n| B | 95.04| 3.893|1.107|\n\n\n**Re \u2018data pre-processing\u2019 methods:** By \u201cdata pre-processing\u201d, we mean data augmentation methods such as mixup[6] and Augmix[7], we apologize for the confusion using \u201cdata pre-processing\u201d.\n\n**Re help to develop to new calibration method:** \n- This paper can benefit the calibration research in different ways, for example:\nAs an illustration, delving deeper into the architecture design reveals insights into achieving better calibration. For instance, as depicted in Figure 10, a discernible trend emerges, indicating that better-calibrated models exhibit a preference for Conv3*3 in edge 1 over Conv1*1 and favor a residual connection in edge 4 within the NATS-Bench scope. This implies that a better-calibrated model may lean towards incorporating larger kernel sizes in the early layers of a CNN block.\n- One can assess the validity of newly proposed metrics by evaluating their consistency with the set of metrics we have examined. Specifically, using the provided checkpoints and the 11 different metrics we assessed, a newly proposed metric can gauge its consistency by evaluating the checkpoints and calculating the Kendall ranking coefficient in comparison to the existing metrics. If the results exhibit little correlation or are negatively correlated with the established metrics, it suggests that the new metric warrants more careful analysis and scrutiny.\n\n**Re Analysis on reliability of calibration metrics:** We agree that current analyses are hard to measure the reliability of calibration metrics. However, this work reminds researchers to avoid using certain ambiguous metrics such as equal mass class-wise ECE  and AuC on OoD datasets. \n\n**Re bin-size impact on train-time calibration:** We conduct a toy experiments on bin-size involved train time calibration algorithm DECE[12] and observe that different bin size can bring larger impact on the post-hoc ECE, where small bin size works better for DECE, as shown in the table\n| Bin Size |  Accuracy%|Pre ECE%|Post ECE%|\n|--|--|--|--|\n| 2 | 95.85|3.994 |1.278|\n| 5 | 95.04| 3.893|1.107|\n| 10 | 95.07| 3.908|1.372|\n| 15 | 95.23 |  3.566| 1.361|\n| 50 | 94.96 |  4.031| 1.415|\n| 100 |95.02  |  3.943|1.523|\n| 200 |95.00  |  3.723|1.523|\n|  500|  94.97|  4.004|1.561|"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699883765860,
                "cdate": 1699883765860,
                "tmdate": 1699883765860,
                "mdate": 1699883765860,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4fOgSUnbo7",
                "forum": "GzNhzX9kVa",
                "replyto": "Hw5vRYq2tc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Reference**\n---\n[1] Sunil Thulasidasan, et al. On mixup training: Improved calibration and predictive uncertainty for deep neural networks. Advances in Neural Information Processing Systems, 32, 2019.\n\n[2]Mukhoti, Jishnu, et al. \"Calibrating deep neural networks using focal loss.\" Advances in Neural Information Processing Systems 33 (2020): 15288-15299.\n\n[3] Wang, Deng-Bao, Lei Feng, and Min-Ling Zhang. \"Rethinking calibration of deep neural networks: Do not be afraid of overconfidence.\" Advances in Neural Information Processing Systems 34 (2021): 11809-11820.\n\n[4] Wang, Deng-Bao, et al. \"On the Pitfall of Mixup for Uncertainty Calibration.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[5] Calibration Bottleneck: What Makes Neural Networks less Calibratable? \u201cICLR 2024 Conference Submission3477\u201d\n\n[6]Thulasidasan, Sunil, et al. \"On mixup training: Improved calibration and predictive uncertainty for deep neural networks.\" Advances in Neural Information Processing Systems 32 (2019).\n\n[7] Hendrycks, Dan, et al. \"Augmix: A simple data processing method to improve robustness and uncertainty.\" arXiv preprint arXiv:1912.02781 (2019).\n\n\n[8] Liu, B., Ben Ayed, I., Galdran, A. and Dolz, J., 2022. The devil is in the margin: Margin-based label smoothing for network calibration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 80-88).\n\n[9] Patra, R., Hebbalaguppe, R., Dash, T., Shroff, G. and Vig, L., 2023. Calibrating deep neural networks using explicit regularisation and dynamic data pruning. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1541-1549)\n\n[10] Hebbalaguppe, R., Prakash, J., Madan, N. and Arora, C., 2022. A stitch in time saves nine: A train-time regularizing loss for improved neural network calibration. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 16081-16090).\n\n[11] Kumar, Aviral, Sunita Sarawagi, and Ujjwal Jain. \"Trainable calibration measures for neural networks from kernel mean embeddings.\" International Conference on Machine Learning. PMLR, 2018.\n\n[12] Bohdal O, Yang Y, Hospedales T. Meta-Calibration: Learning of Model Calibration Using Differentiable Expected Calibration Error[J]. arXiv preprint arXiv:2106.09613, 2021."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699883799151,
                "cdate": 1699883799151,
                "tmdate": 1699883799151,
                "mdate": 1699883799151,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MR3WvCTRxY",
                "forum": "GzNhzX9kVa",
                "replyto": "Hw5vRYq2tc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Respected reviewer, should you have any further concerns, I am eagerly anticipating your response."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700609564004,
                "cdate": 1700609564004,
                "tmdate": 1700609564004,
                "mdate": 1700609564004,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "D8pxRxybuL",
                "forum": "GzNhzX9kVa",
                "replyto": "Hw5vRYq2tc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_qRJE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_qRJE"
                ],
                "content": {
                    "comment": {
                        "value": "I thanks authors for responding to my comments. The responses to a majority of comments are satisfactory, including evaluation with train-time calibration methods, bin size impact, and significance of sec. 4.4. However, the following points require better explanation: 1) how the proposed study can encourage new research in this regard, and on the 2) expansion of existing methods. For instance, 1) is mostly missing description about the potential of developing new calibration methods with this study."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644868728,
                "cdate": 1700644868728,
                "tmdate": 1700645281907,
                "mdate": 1700645281907,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BSEBvmMxKi",
                "forum": "GzNhzX9kVa",
                "replyto": "Hw5vRYq2tc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Respected reviewer, should you have any further concerns, I am eagerly anticipating your response."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700705256661,
                "cdate": 1700705256661,
                "tmdate": 1700705256661,
                "mdate": 1700705256661,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Zgk9HYSD4Q",
            "forum": "GzNhzX9kVa",
            "replyto": "GzNhzX9kVa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a study that analyzes the relationship between NAS and calibration powers of neural networks. The paper combines CIFAR-10, CIFAR-100, and ImageNet as the dataset in which multiple architectures are tested and measure its calibration powers. The study of the paper thus focuses only on image classification problems using small- and medium-scale datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1. I really value the topic of calibration as I believe it is a good feature to have in many classification tasks and systems. I think the paper tackles an important problem.\n\nS2. The clarity of the paper is good, the narrative flows well, and is easy to understand and follow."
                },
                "weaknesses": {
                    "value": "W1. The motivation about why NAS + Calibration is important is missing in the paper. Unfortunately, the paper lacks a clear justification for studying NAS + Calibration. It is not clear intuitively why this is a good direction to explore. It is not clear why a wholistic approach is not worth exploring over NAS + Calibration. Unfortunately, the paper makes the reader believe that the analysis was done just because it has not done before. I think the paper really needs to justify why NAS + Calibration is a good angle to study.\n\nW2. The study uses small- and medium- scale datasets for analyzing the relationship between NAS + Calibration. In particular, the study uses CIFAR-10, CIFAR-100, and ImageNet datasets for the analysis. While I understand that small datasets are easier to handle given the NAS component of the study, it is questionable the conclusions one can get from these small datasets. While ImageNet is larger, compared to modern large-scale datasets, such as, LAION, its use is also questionable. Modern image classification methods are trained using foundation models that use really large-scale datasets (e.g., LAION) and those are the worth studying in my opinion since they are the ones adopted in industry and are making an impact. I think the paper needs to justify the use of these small- and medium-scale datasets. Otherwise, the conclusions drawn from the studies are not solid."
                },
                "questions": {
                    "value": "Please see the Weaknesses stated above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1053/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698843694933,
            "cdate": 1698843694933,
            "tmdate": 1699636031482,
            "mdate": 1699636031482,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0w7f9hfIof",
                "forum": "GzNhzX9kVa",
                "replyto": "Zgk9HYSD4Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the valuable comments from Reviewer Xzoe\n\n\n**Re NAS + Calibration:** To avoid potential misunderstanding regarding the term \"NAS + Calibration\", please let us clarify that this study does not involve conducting neural architecture search (NAS) specifically for calibration purposes. The primary focus of this research is the examination of calibration properties. To address calibration-related research questions, such as the reliability of calibration metrics, one approach is to assess the consistency of different metrics based on a substantial number of well-trained models. However, collecting such a substantial dataset is often challenging due to the associated training costs. Fortunately, NATS-Bench [1] provides access to 117.9K well-trained models with various architectural designs, enabling us to conduct a comprehensive and generalisable study.\n\n**Re datasets:** \nModern large-scale datasets, such as LAION, primarily serve image-text alignment tasks, notably in training stable diffusion models. However, it's worth noting that calibration tasks typically revolve around classification and regression. In recent years, standard benchmarks for calibration studies have included well-known datasets like CIFAR-10, CIFAR-100, and ImageNet [2] [3] [4] [5]. While the prospect of applying calibration tasks to LAION is intriguing, it falls outside the scope of the present work.\n\n---\n[1] Dong, Xuanyi, et al. \"Nats-bench: Benchmarking nas algorithms for architecture topology and size.\" IEEE transactions on pattern analysis and machine intelligence 44.7 (2021): 3634-3646.\n\n[2] Tao, Linwei, Minjing Dong, and Chang Xu. \"Dual Focal Loss for Calibration.\" arXiv preprint arXiv:2305.13665 (2023).\n\n[3] Ghosh, Arindam, Thomas Schaaf, and Matthew Gormley. \"AdaFocal: Calibration-aware Adaptive Focal Loss.\" Advances in Neural Information Processing Systems 35 (2022): 1583-1595.\n\n[4] Minderer, Matthias, et al. \"Revisiting the calibration of modern neural networks.\" Advances in Neural Information Processing Systems 34 (2021): 15682-15694.\n\n[5] Gawlikowski, Jakob, et al. \"A survey of uncertainty in deep neural networks.\" Artificial Intelligence Review 56.Suppl 1 (2023): 1513-1589."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699883392740,
                "cdate": 1699883392740,
                "tmdate": 1700006996412,
                "mdate": 1700006996412,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "aMtCf0YuWV",
                "forum": "GzNhzX9kVa",
                "replyto": "Zgk9HYSD4Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Respected reviewer, should you have any further concerns, I am eagerly anticipating your response."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700609548299,
                "cdate": 1700609548299,
                "tmdate": 1700609548299,
                "mdate": 1700609548299,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PcDQiqGWe7",
                "forum": "GzNhzX9kVa",
                "replyto": "0w7f9hfIof",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
                ],
                "content": {
                    "comment": {
                        "value": "**NAS + Calibration**: \"The primary focus of this research is the examination of calibration properties\" This is not clear in the narrative. Please fix. \n\n**Datasets**: \n- \"Modern large-scale datasets, such as LAION, primarily serve image-text alignment tasks, notably in training stable diffusion models\" This is not true. LAION has also been used to train CLIP-like models, which end up being the foundation of image classifiers (including zero-shot classification models); see https://github.com/mlfoundations/open_clip.\n\n- \" [...] standard benchmarks for calibration studies have included well-known datasets like CIFAR-10, CIFAR-100, and ImageNet [...]\" Unfortunately, these datasets are so tiny compared to the ones one can use to evaluate image classification in modern days. I would not trust any experiment in modern days using these datasets because, as shown recently, data is very important (see CLIP, DALLE, etc.). Moreover, in many ways, the more data the better the estimates and the conclusions. Statistically speaking, since many image classifiers optimize a loss based on statistical foundations, the size of the dataset matters. Thus, I don't think this fall outside the scope of the paper. I think modern papers should work with large-scale datasets since many working in real-world scenarios were trained w/ large datasets, not tiny ones."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700610152395,
                "cdate": 1700610152395,
                "tmdate": 1700610152395,
                "mdate": 1700610152395,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Z5mWC9fBvX",
                "forum": "GzNhzX9kVa",
                "replyto": "Zgk9HYSD4Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer Xzoe,\n\nThank you for taking the time to review our paper. We appreciate your valuable feedback and suggestions. Below are our responses to the points you raised:\n\n## 1. Calibration Focus:\n**Original Comment:** \"The primary focus of this research is the examination of calibration properties. This is not clear in the narrative. Please fix.\"\n\n**Revised Response:** We have address this concern by refining our statement to explicitly state that the primary objective of our research is to investigate calibration properties, as modified in the fourth paragraph of introduction.\n\n\n## 2. Datasets Section:\n\nIn our examination of 249 recent calibration papers, we discovered that none of them\u20140 out of 249\u2014involved training or evaluating models on LAION. The fact that most recent calibration papers are not using LAION, which indicates that LAION is not a widely used dataset in the calibration community, and using widely adopted CIFAR10, CIFAR100 and ImageNet can prove the effectiveness of calibration algorithms as other accepted calibration papers[2][3][4][5]. \n\nSpecifically, to delve into the use of large-scale datasets, specifically LAION, in calibration research, we scrutinized 249 calibration-related papers across ICLR2023 submissions, ICLR2024 submissions, NIPS2023 accepted papers, and ICML2023 accepted papers. The criterion for calibration-related papers was the inclusion of the keywords \"calibration,\" \"confidence,\" or \"uncertainty\" in the title. Our investigation revealed that one[1] of these papers cited LAION, and none utilized LAION for experiments. The web crawler code can be found in this [anonymous code link](https://anonymous.4open.science/r/ICLR2024-rebuttal-F7D4/). The detailed statistics are shown in the table below.\n\n| | ICLR2023 | ICLR2024 | NIPS2023 | ICML2023 | \n|:---:|:---:|:---:|:---:|:---:|\n| # of total papers | 4920 | 7252 | 3217 | 1828 |\n| # of calibration-related papers | 63 | 107 | 49 | 30 |\n| # of calibration-related papers that involved LAION | 0 | 1 | 0 | 0 | \n| Paper |/ | [1] | / | / |\n\n\nIf you have further concern, please don't hesitate to comment.\n\nThank you once again for your insightful review.\n\nBest regards,\n\nSubmission 1053 Authors\n\n## References\n[1] CONFIDENCE-AWARE REWARD OPTIMIZATION FOR FINE-TUNING TEXT-TO-IMAGE MODELS (ICLR2024 submission)\n\n[2] Tao, Linwei, Minjing Dong, and Chang Xu. \"Dual Focal Loss for Calibration.\" arXiv preprint arXiv:2305.13665 (2023).\n\n[3] Ghosh, Arindam, Thomas Schaaf, and Matthew Gormley. \"AdaFocal: Calibration-aware Adaptive Focal Loss.\" Advances in Neural Information Processing Systems 35 (2022): 1583-1595.\n\n[4] Minderer, Matthias, et al. \"Revisiting the calibration of modern neural networks.\" Advances in Neural Information Processing Systems 34 (2021): 15682-15694.\n\n[5] Gawlikowski, Jakob, et al. \"A survey of uncertainty in deep neural networks.\" Artificial Intelligence Review 56.Suppl 1 (2023): 1513-1589."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700643949885,
                "cdate": 1700643949885,
                "tmdate": 1700662101739,
                "mdate": 1700662101739,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "I8c42AqT5p",
                "forum": "GzNhzX9kVa",
                "replyto": "Zgk9HYSD4Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
                ],
                "content": {
                    "comment": {
                        "value": "**Datasets Section**: While previous papers use these tiny datasets, I as a reviewer, object to use them in modern research. The reason is that statistically speaking, they are small, and as many other systems nowadays have shown (e.g., CLIP, OpenCLIP, etc..), large and high-quality datasets are important. To me, the use of these datasets do not represent the real scenarios of machine learning; mainly because their image resolution is quite small, their scale is tiny, and the scenarios they cover are niche. If we don't aim to show results on large-scale datasets, I don't expect the field in making leaps forward in understanding machine learning."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661021144,
                "cdate": 1700661021144,
                "tmdate": 1700661055425,
                "mdate": 1700661055425,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rNuClU9q65",
                "forum": "GzNhzX9kVa",
                "replyto": "KuclSMnJ8Z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Reviewer_Xzoe"
                ],
                "content": {
                    "comment": {
                        "value": "1. I understand academia is facing challenges due to the lack of resources.\n2. My overall concern in sum is that it is unclear how we can ensure that the conclusions derived from the tiny and niche datasets generalizes well to other domains. This is why I recommended a larger dataset (it is not the only one, for example, Google Open Images is another good dataset) since that is guaranteed to cover several aspects of visual recognition. In short, I am concerned that the impact of this paper is minimal due to using tiny and niche datasets."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668827653,
                "cdate": 1700668827653,
                "tmdate": 1700668827653,
                "mdate": 1700668827653,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zj4P7thrt3",
            "forum": "GzNhzX9kVa",
            "replyto": "GzNhzX9kVa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1053/Reviewer_S1Jc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1053/Reviewer_S1Jc"
            ],
            "content": {
                "summary": {
                    "value": "This paper conducts several investigations about the calibration problem of the deep neural networks. This paper introduces a calibration dataset based on the NATS-Bench for generating massive CNNs with different topologies or model sizes. This paper adopts the calibration dataset and evaluate the different calibration metrics to analyze the calibration properties in deep neural networks. This paper provides extensive explorations and conclusions through the benchmarks"
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThis paper raises 7 initial questions for exploring the calibration properties in deep neural networks.\n2.\tThis paper builds a benchmark based on models generated by NAS for evaluating the calibration metrics.\n3.\tThis paper conducts extensive experiments to analyze and answer the questions."
                },
                "weaknesses": {
                    "value": "1.\tThe proposed calibration benchmark might be limited since it contains only convolution neural networks for image classification. I\u2019m concerned about how about the calibration properties for other tasks, e.g., object detection or NLP tasks. It\u2019s more convincing when extending the benchmark for more architectures and more tasks.\n2.\tMost architectures and networks are generated from the similar search space, which might have similar effects and are limited for the conclusions. Varying the search spaces and using human designed architectures are necessary.\n3.\tDifferent architectures on different benchmarks/dataset might require different hyper-parameters. Though it\u2019s hard to search optimal/sub-optimal parameters for different models, it will affect the experimental results.\n4.\tThis paper explores the calibration properties in neural networks, but I\u2019m much concerned about how those findings impact the future research or guide the designing process for both accuracy and calibration performance."
                },
                "questions": {
                    "value": "See the weaknesses above"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1053/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698974476345,
            "cdate": 1698974476345,
            "tmdate": 1699636031420,
            "mdate": 1699636031420,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CEYK4uCHQ6",
                "forum": "GzNhzX9kVa",
                "replyto": "zj4P7thrt3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the valuable comments from Reviewer S1Jc\n\n**Re findings generality:** While our analysis in the main text primarily focuses on CNN models, we extend our investigation to transformer-based models, as detailed in Appendix A. In further support of our study, we trained six human-designed CNN models\u2014ResNet18, ResNet34, ResNet50, ResNet110, Wide-ResNet-26-10, and Densenet121\u2014on CIFAR-10 and CIFAR-100, obtaining similar conclusions as reported in Appendix B. As depicted in Figure 12 in Appendix A and Figure 17 in Appendix B, the ECE across different bin sizes demonstrates little correlation between pre and post temperature scaling for both Transformers and CNNs. This suggests that well-calibrated models do not necessarily exhibit improved calibration performance after post-hoc calibration techniques. This phenomenon is particularly pronounced on CIFAR-100, where post-hoc calibration performance becomes negatively correlated with pre-calibration performance. Regarding the impact of bin size, we observe a substantial influence on post-hoc calibration performance, aligning with the observations outlined in Section 4.4. In terms of the reliability of calibration metrics, we conducted an analysis of the correlation between all calibration metrics, as presented in Figure 14 in Appendix A and Figure 18 and Figure 19 in Appendix B. Notably, equal-mass classwise ECE exhibits a different pattern compared to other metrics, especially on CIFAR-100, reinforcing the observations outlined in Section 4.3.\n\n**Re NLP Task:** Recognizing the significance of task diversification, we undertook an NLP classification experiment using the 20 newsgroups dataset. Our experimental setup included 2 CNN-based models, 1 MLP-based model, 2 RNN models, and 1 BERT model. Each model is trained for 20 epochs. Notably, the correlation among the six models between pre-calibration ECE and post-hoc ECE was found to be -0.13. This aligns with the observation in Figure 4b, indicating that the impact of post-hoc calibration methods is not uniform across all models.\n\n**Re NAS search space:** In an effort to extend the applicability of our observations beyond a limited search space, we conducted experiments on human-designed Transformers and CNNs. The outcomes of these experiments align with the findings in the main text, as detailed in Appendices A and B.\n\n\n**Re hyper-parameters fine tune:** While we acknowledge that hyperparameter tuning for each model could potentially yield more precise results, the vast number of models involved in our study (117,702 unique neural networks) makes this approach computationally intensive. As a pragmatic tradeoff, we opted to establish a fixed and fair set of hyperparameters for all models to conduct our experiments.\n\n**Re border impact:** Our several observations can help improve the research in calibration and accuracy, for example,\n- In section 4.1, we suggest testing model calibration performance on downstream tasks specifically, since the fact that a well calibrated model on source tasks does not necessarily perform well on downstream tasks.\n- In section 4.2 and 4.3, we suggest avoiding equal mass class wise ECE or AuC on OoD datasets for calibration evaluation, which helps the calibration evaluation.\n- In section 4.4, we observe that a well calibrated model may not achieve better post-hoc calibration performance than a poor calibrated model. This observation supports the \u201ccalibratable\u201d objective proposed in [1][2][3] in a way that research should focus more on obtaining a model with better post hoc calibration performance.\n- In section 4.5, we observe the tradeoff between accuracy and ECE, which can facilitate the research in prediction accuracy.\n- In section 4.6, the impact of bin-size might support the study of those train-time calibration methods which involve the hyperparameter bin size, such as SoftECE[4] and DECE[5].\n- In section 4.7, the analysis on architecture design of better calibration models can support the research on calibration from the view of architecture design.\n\n\n---\n[1] Wang, Deng-Bao, Lei Feng, and Min-Ling Zhang. \"Rethinking calibration of deep neural networks: Do not be afraid of overconfidence.\" Advances in Neural Information Processing Systems 34 (2021): 11809-11820.\n\n[2] Wang, Deng-Bao, et al. \"On the Pitfall of Mixup for Uncertainty Calibration.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n\n[3] Calibration Bottleneck: What Makes Neural Networks less Calibratable? \u201cICLR 2024 Conference Submission3477\u201d\n\n[4] Karandikar A, Cain N, Tran D, et al. Soft calibration objectives for neural networks[J]. Advances in Neural Information Processing Systems, 2021, 34: 29768-29779.\n\n[5] Bohdal O, Yang Y, Hospedales T. Meta-Calibration: Learning of Model Calibration Using Differentiable Expected Calibration Error[J]. arXiv preprint arXiv:2106.09613, 2021."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699883300243,
                "cdate": 1699883300243,
                "tmdate": 1699883300243,
                "mdate": 1699883300243,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TwmBqlbzI7",
                "forum": "GzNhzX9kVa",
                "replyto": "zj4P7thrt3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1053/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Respected reviewer, should you have any further concerns, I am eagerly anticipating your response."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1053/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700609530506,
                "cdate": 1700609530506,
                "tmdate": 1700609530506,
                "mdate": 1700609530506,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]