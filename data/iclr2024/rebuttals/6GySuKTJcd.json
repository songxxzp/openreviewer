[
    {
        "title": "Energy-Guided Continuous Entropic Barycenter Estimation for General Costs"
    },
    {
        "review": {
            "id": "N3r5mW061M",
            "forum": "6GySuKTJcd",
            "replyto": "6GySuKTJcd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5371/Reviewer_97mW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5371/Reviewer_97mW"
            ],
            "content": {
                "summary": {
                    "value": "This paper considers the problem of computing entropic optimal transport barycenters from continuous distributions. It is assumed that the authors only observe these continuous distributions from samples. The approach involves studying the dual of the entropic OT problem and using neural networks to approximate dual potentials. The barycenter can then be recovered from these potentials using the primal-dual relationship. With this new formulation, the authors can compute barycenters for general costs, which allows for the computation of barycenters under learned geometry (via StyleGAN). The method is also scalable to larger datasets than existing methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors use a conditional formulation of the entropic barycenter problem to give a new dual formulation.  They also give a stability bound, which gives an error bound on the quality of the dual potentials in terms of the primal solution.\n- The authors also give learning bounds for barycenters in terms of the loss and estimation error. They also give a universal approximation result that states that there exist neural networks that can achieve this bound. The proof of duality and quality of dual potentials is essential.\n- Because the method works with general costs, it can work with manifold constraints, which gives some nice results in Sections 5.2 and 5.3. This is perhaps the most significant contribution of the work."
                },
                "weaknesses": {
                    "value": "My concerns mostly center around 1) the impact this work can have and 2) how many new ideas it contributes to the literature. While the extension to general costs is interesting, it seems somewhat straightforward, and I don't see how the methods developed themselves are necessarily tailored to the general cost nature of the problem.\n\n- The theorems all seem to have standard proofs that are straightforward extensions of existing results. I am not sure that the theory proposed gives any new techniques or insights. Furthermore, more important proofs are missing, such as how efficiently one can sample from the barycenter. Furthermore, the finite sample learning guarantees are nice to see but have no practical impact since there are no cases where they could estimate these errors in any practical example.\n- The method learns OT plans but not maps. This is true of the general entropically regularized setting. However, this adds complexity to the usefulness of the method because one doesn\u2019t have access direction to the barycenter distribution itself and rather only has conditional access through the reference measures.\n- In Figure 3, the method proposed doesn\u2019t recover the image content due to its conditional nature, despite the fact that their FID is lower. Is there any way of getting samples closer to the truth? Also, I guess the FID is lower than other existing methods because of the addition of the StyleGAN.\n- The samples, even in the manifold-constrained case in Figure 5.2, are comparable to SCWB, and therefore it is hard to see why the proposed method is better. This experiment is qualitative but not quantitative.\n- The authors acknowledge this, but it is difficult to compare with the true entropic optimal transport barycenter quantitatively. However, it would have been nice to see it in cases where it is known (for example, with Gaussians)."
                },
                "questions": {
                    "value": "- In training, how do you ensure that the ULA is running enough for convergence?\n- Can the authors comment on the complexity of the method in relation to the others? Is it really that the proposed method is more scalable, or just that they test on larger datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5371/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5371/Reviewer_97mW",
                        "ICLR.cc/2024/Conference/Submission5371/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5371/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698759259412,
            "cdate": 1698759259412,
            "tmdate": 1700685952754,
            "mdate": 1700685952754,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iMQ8hlAOmB",
                "forum": "6GySuKTJcd",
                "replyto": "N3r5mW061M",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5371/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5371/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to reviewer 97mW. Part 1"
                    },
                    "comment": {
                        "value": "Dear reviewer, thank you for spending time reviewing our paper. Please take a look at our general answer to all the reviewers where we address common questions and show additional experimental results. Below we answer to your questions and comments. \n\n**(0) The authors acknowledge this, but it is difficult to compare with the true entropic optimal transport barycenter quantitatively. However, it would have been nice to see it in cases where it is known (for example, with Gaussians).**\n\nSee the general answer to all reviewers for the discussion of this question and newly added comparison with ground-truth *unregularized* barycenter.\n\n**(1) The theorems all seem to have standard proofs that are straightforward extensions of existing results. I am not sure that the theory proposed gives any new techniques or insights.**\n\nThank you for this opinion. However, from our humbly point of view, this is not that right.\n\n(a) **\"standard proofs [...] straightforward extensions[...]\"**. \n\nWhile our Theorems 2, 3, 4 are indeed largely based on the similar results from [4], we argue that our Theorem 1 (the key result for our proposed methodology) is original, and its proof is non-trivial. We have even been forced to prove some auxiliary properties of weak $C$-transform. The latter are interesting on its own.\n\n(b) **\"[...] not sure that the theory gives new techniques or insights.\"** \n\nOur developed theory allows us to build Entropic OT barycenter solver for general cost function based on extensively developed EBMs techniques. We think this is a worthy result of our theoretical deductions. The closest approach [4] develops Energy-based training procedures only for Entropic OT problem itself. It is related but different problem. We do not hide our connection to [4], but we take a considerable step forward from both a theoretical and a practical perspectives.\n\n**(2)   Furthermore, more important proofs are missing, such as how efficiently one can sample from the barycenter. Furthermore, the finite sample learning guarantees are nice to see but have no practical impact since there are no cases where they could estimate these errors in any practical example.** \n\n(a) **efficient sampling from the barycenter** \n\nOur proposed practical algorithm is  based on Energy-based models. It is an autonomous decades-long research direction which comes with its own advantages, techniques and limitations. The question of efficient sampling from barycenters resorts to the similar question for general-purpose EBMs. We point the reviewer's attention to [8], [9], [10] for some attempts to improve the sampling characteristics of EBMs. Note that typically these methods follows from practical observations, not theorems. \n\nIn our paper, we also do not make an attempt to equip EBMs with theoretically-grounded efficient sampling method. In fact, we treat the EBM training procedure as the particular solver for our proposed methodology. We leave the question regarding efficient sampling techniques to a separate research.\n\n(b) **\"finite sample learning guarantees [...] no practical impact\"**\n\nWe agree that the particular statement of our theorem is not directly related to practical procedure, just like many Statistical Machine Learning researches in Generative Modelling. At the same time, our result justifies that our methodology actually permits the particular Statistical and Approximation guarantees. Note that deriving the similar guarantees for other scalable continuous barycenter solvers is complicated. This is because they utilize nontrivial adversarial [2]/iterative [1]/diffusion-based [7] objectives, while our objective (up to MCMC procedure) is the direct minimization of sum of KL divergences (see Theorem 2).\n\n\n**(3)  The method learns OT plans but not maps. This is true of the general entropically regularized setting. However, this adds complexity to the usefulness of the method because one doesn\u2019t have access direction to the barycenter distribution itself and rather only has conditional access through the reference measures.** \n\nWhile we partially agree with the reviewer, to be honest, we do not think this is a problem. Indeed, one can learn generative model (e.g., a GAN or a diffusion) on top of samples transported with our solver from marginal distributions to the learned barycenter. This will provide the direct access to samples of barycenter. Moreover, in the **manifold-constrained** case (Sections 5.2, 5.3), such generative model has to be constructed in the latent space (of a StyleGAN) which is presumably even easier."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5371/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588278591,
                "cdate": 1700588278591,
                "tmdate": 1700588278591,
                "mdate": 1700588278591,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rjGWFHrcia",
                "forum": "6GySuKTJcd",
                "replyto": "n4MrtFWaaQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5371/Reviewer_97mW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5371/Reviewer_97mW"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors detailed response to my review, and while there may be some disagreement on the usefulness/novelty of the theoretical results, I\u2019m inclined to raise my score."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5371/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685937696,
                "cdate": 1700685937696,
                "tmdate": 1700685937696,
                "mdate": 1700685937696,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cV2xQcuZTd",
            "forum": "6GySuKTJcd",
            "replyto": "6GySuKTJcd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5371/Reviewer_BAkA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5371/Reviewer_BAkA"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a new algorithm for approximating the entropy-regularized optimal transport barycenter of continuous probability distributions with general cost functions. In particular, they derive the weak dual formulation of the original problem, and then leverage energy-based models for an optimization procedure. Additionally, they also establish the generalization bounds and universal approximation guarantees for their estimation of optimal transport plan. Finally, they justify the efficacy of their proposed method by conducting some experiments on generative models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.Although the idea of leveraging Energy-based models to solve optimal transport problems is not novel as it was already introduced in [1, 2], its applications on the barycenter problem is new.\n\n2. The results presented in the paper have been both theoretically and empirically demonstrated, which help strengthen the paper.\n\n3. The paper is well-written with no grammatical errors (as far as I can tell).\n\n**References**\n\n[1] Petr Mokrov, Alexander Korotin, Evgeny Burnaev. Energy-guided Entropic Neural Optimal Transport.\n\n[2] Khai Nguyen and Nhat Ho. Energy-Based Sliced Wasserstein Distance. In NeurIPS, 2023."
                },
                "weaknesses": {
                    "value": "1. The authors only motivated the optimal transport barycenter problem in Section 1, but they did not explain why its entropy-regularization variant is worth discovering.\n\n2. The MCMC algorithm leveraged in Algorithm 1 is not efficient.\n\n3. There are some incorrect claims in the paper (see Question 2).\n\n4. The paper organization is not good: \n- The authors should move the notation paragraph in Section 2 to the end of Section 1, which makes more sense.\n- In Appendix A, the authors should separate the proofs of theoretical result into different subsections, which makes it easier for readers to navigate. \n\n5. The paper violates the 9-page rule of ICLR 2024."
                },
                "questions": {
                    "value": "1. Does the result in equation (6) hold true for any continuous function $f\\in\\mathcal{C}(\\mathcal{Y})$ or only for the optimal function $f$ in equation (3)?\n\n2. At the beginning of Section 2.3, the authors claimed that there was no direct analytical solution for the entropic barycenter of Gaussian distributions. However, Le et al. [2] already arrived at the closed-form expression for that problem with the inner-product cost function (see Theorem 5.2).\n\n3. If the input distributions $\\mathbb{P}_1,\\ldots,\\mathbb{P}_K$ are not probability distributions and do not share the same mass, would we be able to extend the enery-guided approach to approximate the barycenter of those distributions?\n\n4. If we replace the MCMC algorithm with other sampling methods, namely importance sampling, would the running time be improved? If not, what sampling methods are possible to achieve an improved running time. The authors should discuss more about this in Section 6.\n\n5. The authors should cite more relevant papers:\n- In Section 2.2, the entropic barycenter problem was also previously studied in [1, 2];\n\n6. Typos: \n- Below equation (8), I guess the term 'which differs from (8)' should be 'which differs from (7)'. Please correct me if I was wrong.\n- Below equation (8), the author should clarify the abbreviation l.s.c although I can guess that it stands for lower semi-continuous.\n\n**References**\n\n[1] Khang Le, Huy Nguyen, Quang Nguyen, Tung Pham, Hung Bui, Nhat Ho. On Robust Optimal Transport: Computational Complexity and Barycenter Computation. In NeurIPS, 2021.\n\n[2] Khang Le, Dung Le, Huy Nguyen, Dat Do, Tung Pham, Nhat Ho. Entropic Gromov-Wasserstein between Gaussian Distributions. In ICML, 2022."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5371/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5371/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5371/Reviewer_BAkA"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5371/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698786566254,
            "cdate": 1698786566254,
            "tmdate": 1699636542414,
            "mdate": 1699636542414,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aADj7FxmuL",
                "forum": "6GySuKTJcd",
                "replyto": "cV2xQcuZTd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5371/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5371/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Reviewer BAkA (1/2)"
                    },
                    "comment": {
                        "value": "Dear reviewer, thank you for spending time reviewing our paper. Please take a look at our general answer to all the reviewers where we address common questions and show additional experimental results. Below we answer to your questions and comments. \n \n**(1) The authors only motivated the optimal transport barycenter problem in Section 1, but they did not explain why its entropy-regularization variant is worth discovering.** \n\nThe logic behind the introduction of entropy is analogous to its introduction in case of discrete OT. Considering entropy-regularized problem in *discrete* case allows to\n\n**(a)** provide improved theoretical properties such as the strict convexity of the OT/barycenter problem, uniqueness of the solution, derive the tractable OT dual form [1] which, in turn, allows to\n\n**(b)** establish convenient algorithms such as the Sinkhorn-like OT/barycenter methods with guarantees of performance.\n\nThe situation in the **continuous** case is the same. Point **(a)** still holds, and, **as we show in our paper**, the tractable OT dual form (Eq. 3) for EOT **(b)** gives us the opportunity to apply the well-known techniques from Energy-based modeling (EBM) to solve the barycenter problem under consideration.\n\nFurthermore, our established solver allows to use general cost functions $c_k$ and, in particular, permits employing pre-trained generative models (e.g., StyleGAN) to restrict the sought-for barycenter to the image manifold. This aspect contributes to scalability of the proposed algorithm and expands practical applications of the barycenter problem.\n\n**(2) The MCMC algorithm leveraged in Algorithm 1 is not efficient. [...]  If we replace the MCMC algorithm with other sampling methods, namely importance sampling, would the running time be improved? If not, what sampling methods are possible to achieve an improved running time. The authors should discuss more about this in Section 6.**\n\nWe would like to note that we develop a generic **methodology** for solving the EOT barycenter problem and demonstrate that it does work even with the simplest sampling procedures. In principle, importance sampling might be used as such procedure (instead of ULA), however, it scales poorly with dimensionality (see Section 3.3 of [2]) and demands  the usage of advanced improvements. Thus,  the result of generating potentially might be improved with utilization either more efficient MCMC algorithms [5] or advanced  techniques for importance sampling procedures [2, 6], however, these considerations are beyond the scope of our paper.\n\nFollowing your suggestion, we mentioned corresponding papers in Section 6.\n \n**(3) Does the result in equation (6) hold true for any continuous function $f \\in \\mathcal{C}(\\mathcal{Y})$  or only for the optimal function  $f$\n in equation (3)?**\n \nThe results holds for every $f \\in \\mathcal{C}(\\mathcal Y)$. If $f$ is optimal ($f=f^{*}$), then Equation 6 turns to  the equality $0 = 0$.\n\n**(4) If the input distributions  $\\mathbb{P}_1,..,\\mathbb{P}_k$ are not probability distributions and do not share the same mass, would we be able to extend the energy-guided approach to approximate the barycenter of those distributions?**\n\nAdapting our approach to distributions of unequal mass (*unbalanced* setup) is beyond the scope of our current paper. It would require significant changes in methodology and theoretical foundations. Exploring this direction is an interesting avenue for future research.\n\n\n**(6) paper organization is not good: [...] move the notation paragraph in Section 2 to the end of Section 1. [...] In Appendix A, the authors should separate the proofs of theoretical result into different subsections.**\n\nUp to the reviewer's request, we moved the notation and separated the proofs in the revised version of our paper.\n\n**(7) The paper violates the 9-page rule of ICLR 2024.**\n\nPlease note that according to ICLR 2024 rules, it is allowed to position the reproducibility statement on an additional 10th page, see the reproducibility section in https://iclr.cc/Conferences/2024/AuthorGuide \n\n**(8) The authors should cite more relevant papers. In Section 2.2, the entropic barycenter problem was also previously studied in papers [3, 4].**\n\nWe thank the reviewer for pointing to the relevant papers [3, 4]. We added the citations in Section 2.2, Appendix B.1 and C.2.\n\n**(9) Typos:\nBelow equation (8), the term 'which differs from (8)' should be 'which differs from (7)', [...] clarify the abbreviation l.s.c although I can guess that it stands for lower semi-continuous.**\n\nWe thank the reviewer for indicating the typos, we fixed them in the revised version of our paper.\n\n**Concluding remarks.** Please reply to our post and inform us if the clarifications provided adequately address your concerns regarding our work. We are more than willing to discuss any remaining points during the discussion phase. If the responses offered meet your satisfaction, we kindly request you to consider raising your score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5371/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700587149872,
                "cdate": 1700587149872,
                "tmdate": 1700587149872,
                "mdate": 1700587149872,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jz5xW4Ye5U",
                "forum": "6GySuKTJcd",
                "replyto": "41YNP1OFZa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5371/Reviewer_BAkA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5371/Reviewer_BAkA"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Authors,\n\nThanks for your response, which addresses some of my concerns. However, there are still many other quesitons which have not been addressed yet. In particular,\n\n1. The discussion about other possibly efficient sampling methods than MCMC is currently quite short, and there are neither intuitions nor insights of how to improve the sampling procedures. I suggest that the authors should study other sampling methods for EOT barycenter more thoroughly on both theoretical and empirical sides, which strengthens the paper substantially.\n\n2. The authors does not show effort to answer my question about the unbalanced settings of the EOT barycenter problem. I would like to emphasize that those settings are very important in making the optimal solution robust to outliers which often appears in real-world datasets.\n\nFor those reasons, I think my final score of 5 is reasonable, and I decide to keep it. \n\nBest,\n\nReviewer BAkA"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5371/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671959285,
                "cdate": 1700671959285,
                "tmdate": 1700671959285,
                "mdate": 1700671959285,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nZWWHB1hYW",
            "forum": "6GySuKTJcd",
            "replyto": "6GySuKTJcd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5371/Reviewer_7U49"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5371/Reviewer_7U49"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel algorithm for approximating the continuous Entropic Optimal Transport (EOT) barycenter for arbitrary Optimal Transport (OT) cost functions. The approach is based on the dual reformulation of the EOT problem based on weak OT, which has recently gained the attention of the ML community. Various advantages of this method were proposed. Some real-world applications in ML are used to demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is a mathematically heavy paper, and the authors presented it quite well. The idea is to first formulate the EOT barycentric problem into a dual formulation (Theorem 1). With the dual formulation, a practical optimization algorithm is proposed via approximating the potentials used in the dual formulation by neural network functions. Given the concrete neural network approximator, the gradient of the EOT barycenter objective can be explicitly written. Based on this, the authors propose an algorithm for the EOT optimization."
                },
                "weaknesses": {
                    "value": "The results demonstrate generalization error estimates and universal approximation via neural network results for their algorithm. However, this part is a bit too general. I wonder if there are more specific results for special kind of neural network towards their approximation quality."
                },
                "questions": {
                    "value": "see \"Weaknesses\" section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5371/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698788033436,
            "cdate": 1698788033436,
            "tmdate": 1699636542332,
            "mdate": 1699636542332,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ClBd9TQjAq",
                "forum": "6GySuKTJcd",
                "replyto": "nZWWHB1hYW",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5371/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5371/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to reviewer 7U49"
                    },
                    "comment": {
                        "value": "Dear reviewer, thanks for your positive feedback.\n\n**(1)The results demonstrate generalization error estimates and universal approximation via neural network results for their algorithm. However, this part is a bit too general. I wonder if there are more specific results for special kind of neural network towards their approximation quality.**\n\nImproving Theorem 4 with explicit numerical bounds is indeed a good question coming from Statistical Learning Theory. However, it seems to be rather non-trivial and deserves a separate research, probably, a separate paper. The key challenge here is the analysis of weak $C_{\\text{EOT}}$-transformed functions $f^{C}$. This is much more difficult than, say, analysis of just functions (Neural Networks) $f$. Therefore, we expect that the derivation of the desired bounds will require substantial theoretical and numerical efforts: definitions, assumptions, theorems, proofs and supporting experiments. We leave all this stuff to a follow-up research.\n\n\n**Concluding remarks.** Please reply to our post and inform us if the clarifications provided adequately address your concerns regarding our work. We are more than willing to discuss any remaining points during the discussion phase."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5371/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588546208,
                "cdate": 1700588546208,
                "tmdate": 1700588546208,
                "mdate": 1700588546208,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UqPYaqkffg",
                "forum": "6GySuKTJcd",
                "replyto": "ClBd9TQjAq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5371/Reviewer_7U49"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5371/Reviewer_7U49"
                ],
                "content": {
                    "title": {
                        "value": "keep my score"
                    },
                    "comment": {
                        "value": "Thanks for the response. I would like to keep my score as it was."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5371/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700713244725,
                "cdate": 1700713244725,
                "tmdate": 1700713244725,
                "mdate": 1700713244725,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "C6yACoAdlH",
            "forum": "6GySuKTJcd",
            "replyto": "6GySuKTJcd",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5371/Reviewer_16og"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5371/Reviewer_16og"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors propose a new algorithm for computing the entropic-regularized Wasserstein barycenter for arbitrary cost functions with theoretical guarantees. The proposed algorithm is based on the dual formulation of the entropic OT problem. An integral involved in the proposed algorithm is approximated using an MCMC procedure (unadjusted Monte Carlo). Extensive experiments are performed to illustrate the usefulness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "A new algorithm for computing the entropic-regularized Wasserstein barycenter for arbitrary cost functions is proposed, which seems interesting, with a lot of empirical evidence."
                },
                "weaknesses": {
                    "value": "Most theoretical results here seem trivial or a bit irrelevant to me. Theorem 2 appears to follow from the definitions, while Theorems 4 and 5 do not seem to be very relevant to the proposed algorithm. I would expect more discussion on the convergence behavior of the proposed algorithm say convergence rates under simple settings but that is lacking in the paper. \n\n---\nAfter rebuttal: the authors have explained my concerns above; see below."
                },
                "questions": {
                    "value": "Could you answer how relevant Theorems 4 and 5 are towards the understanding of the proposed algorithm? In addition, from my knowledge of the literature, it does not appear to be common to use neural networks for parameterization of the potentials (correct me if I am wrong). How much computational overhead this will incur on the computation, especially if $K$ is large? \nThe mention of energy-based models (EBMs) does not seem to be very relevant to me either. Ultimately an MCMC procedure such as ULA is used to generate samples in order to approximate an integral. EBMs are related but not that relevant. Also, the authors appear to have used ULA with stochastic/batch gradients, which is better known as stochastic gradient Langevin dynamics (SGLD). \n\nTypo: page 17: swap $\\min$ and \u201c$\\sup$\u201d in (17) \u2026"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5371/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5371/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5371/Reviewer_16og"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5371/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699318405829,
            "cdate": 1699318405829,
            "tmdate": 1700721048646,
            "mdate": 1700721048646,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wtDMkTEGxX",
                "forum": "6GySuKTJcd",
                "replyto": "C6yACoAdlH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5371/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5371/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to reviewer 16og (1/2)"
                    },
                    "comment": {
                        "value": "Dear reviewer, thank you for spending time reviewing our paper. \n\n**(1) Trivial theoretical results. \"Theorem 2 appears to follow from the definitions\".**\n\nAt first, we highlight that the key theoretical result of our work is Theorem 1. From our point of view, it is not a trivial result. Secondly, we agree that proving Theorem 2 is not a difficult task. At the same time, we argue that Theorem 2 is *important and worth presenting*. It states that the gap between optimal value of (dual) training objective $\\mathcal{L}$ and an actual value *directly* bounds the quality of the recovered barycentric plans $\\pi^{f_k}$. It leads to the straightforward conclusion that the closer is our optimized objective $\\mathcal{L}$ to the optimal one, the more accurate are the recovered barycentric plans $\\pi^{f_k}$. Combined with Theorem 1, this result forms the **foundation** of our approach. \n\n \n**(2) Convergence speed/rates discussions. \"[...] more discussion on the convergence behavior of the proposed algorithm say convergence rates under simple settings but that is lacking in the paper.\"**\n\nWe thank the reviewer for this interesting question. Let us formalize the problem a bit. In Section $\\S$ 4.3 we introduced the set of **perfect** potentials $(\\widehat{f_1}, \\dots \\widehat{f_K})$ which solve the entropic barycenter problem given limited number of empirical samples and limited class of available potentials. If we correctly understand, your question is about how fast the **optimized** potentials $(\\widehat{f_{1,opt}} , \\dots \\widehat{f_{K,opt}})$ converge to the perfect ones. Let us call the discrepancy between optimized and perfect potentials the *optimization* error. There are multiple sources of *optimization* error and there are multiple factors which affect its dynamics: inexact sampling due to MCMC and stochastic gradient ascent (Eq. 12). The analysis of these quantities is a completely different domain in Machine Learning and is out of scope of our work. As with most generative modeling research, we do not attempt to analyze optimization errors.\n\n**(3) \"Could you answer how relevant Theorems 4 and 5 are towards the understanding of the proposed algorithm?\"**\n\nContinuous the previous answer, Theorem 4 and 5 provide a *statistical/approximation analysis* for our learning objective assuming there is no optimization error (as it is usually done in statistical ML). \n \nThe theorems tell us that our empirical learning objective is valid from the statistical perspective (error could be bounded by the well-celebrated Rademacher complexity) and the approximation perspective (neural networks can achieve arbitrary small error). Obtaining more precise bounds requires the detailed analysis of weak $C$-transform's statistical properties. This requires significant work for establishing particular theorems, assumptions, definitions. We leave this for the future work.\n\n \n**(4) In addition, from my knowledge of the literature, it does not appear to be common to use neural networks for parameterization of the potentials (correct me if I am wrong)**\n\n \nPlease note that we consider the **continuous** OT barycenter problem (see Section 2.1) but  **not discrete**. Here the dual variable is a (continuous) function, not just a finite-length vector. Hence, using the neural-network parameterization for dual potentials is common [1,2]. It not only allows to do the out of sample estimation (which is tricky to do in the discrete case) but also improves the scalability of solvers. \n\n \n**(5) How much computational overhead this will incur on the computation, especially if \n K is large?**\n\nIn accordance with the proposed algorithm on page 6 (see Section 4.2), one can see that the time of the computation will grow linearly. At the same time, we note that some parts of our algorithm could be easily run in parallel. In particular, the MCMC sampling procedures for each $k \\in \\{1, 2, \\dots, K\\}$ and computing the $k$-th components of our optimized loss $\\widehat{L}_k$ are completely independent. This may significantly improve the computation rates."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5371/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700588263729,
                "cdate": 1700588263729,
                "tmdate": 1700588263729,
                "mdate": 1700588263729,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "b7k05Z4qmN",
                "forum": "6GySuKTJcd",
                "replyto": "QlTqmN64Nn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5371/Reviewer_16og"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5371/Reviewer_16og"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thanks the authors for your answers to my questions and clarified some of my misunderstanding. I think some of the answers like (2) and (3) indicate some of the concerns I have remain valid. But the authors have made comprehensive explanation for their work. I hope the authors would address my concerns about the theoretical contribution of this work. I have raised my score."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5371/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720974035,
                "cdate": 1700720974035,
                "tmdate": 1700720974035,
                "mdate": 1700720974035,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]