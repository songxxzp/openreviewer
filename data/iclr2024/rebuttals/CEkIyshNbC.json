[
    {
        "title": "Unraveling the Enigma of Double Descent: An In-depth Analysis through the Lens of Learned Feature Space"
    },
    {
        "review": {
            "id": "P8xhLddXZx",
            "forum": "CEkIyshNbC",
            "replyto": "CEkIyshNbC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission287/Reviewer_Ea52"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission287/Reviewer_Ea52"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents an empirical study of the relation between model capacity and generalization, while considering the learned feature space. In particular, it analyzes the phenomena of double descent, in which test performance improves after a certain interpolation threshold, contrary to the traditional U-shaped curve.  This work argues that models with small capacity first overfit to the noise present in the data and that overparameterized models then learn to \u201crecognize\u201d noisy labels, separating signal from noise."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "In contrast to most previous empirical works on double descent, which only analyze cross entropy loss, double descent in terms of accuracy is also studied. As shown in their plots (see Figures 1, 3 and 5) the double descent peak is considerably smaller (sometimes even absent) when looking at accuracy. tSNE visualizations give more intuition about the phenomenon, and experiments are performed for 3 models and 3 noise levels and 2 datasets."
                },
                "weaknesses": {
                    "value": "- One main weakness is the fact that a big part of the paper is devoted to reproducing experiments from [1]. In these experiments, the only significant difference is the fact that they report both accuracy and cross entropy loss.\n\n- I fully agree with the author\u2019s comment on section 3 regarding tSNE maps: \u201cWhile this visualization may not accurately represent the intricate inherent structure of high-dimensional features, it aims to gain insights into the clustering and distribution of data points, thereby enhancing our understanding of the model\u2019s internal representations.\u201d While tSNE maps might give intuition about a phenomenon, they can also fabricate patterns and might not be sufficient evidence for a proposition.\n\n- The writing is sometimes confusing. For instance, in section 3.3: \u201cwe calculate the prediction accuracy Kp of noisy labelled data of the original clean labels for each noisy labeled data point matching the label prediction of its k-nearest neighbors in the learned feature space\u201d. \n\n Thus, I do not see substantial empirical nor theoretical contributions in this work. \n\n[1] DEEP DOUBLE DESCENT: WHERE BIGGER MODELS AND MORE DATA HURT Nakkiran et al."
                },
                "questions": {
                    "value": "-"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission287/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission287/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission287/Reviewer_Ea52"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission287/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698335391490,
            "cdate": 1698335391490,
            "tmdate": 1700574271290,
            "mdate": 1700574271290,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Hn013rOGSS",
                "forum": "CEkIyshNbC",
                "replyto": "P8xhLddXZx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to official review"
                    },
                    "comment": {
                        "value": "Firstly, we appreciate your time in reviewing our paper and offering valuable comments and insights. \n\nQ1: ``One main weakness is the fact that a big part of the paper is devoted to reproducing experiments from [1]. In these experiments, the only significant difference is the fact that they report both accuracy and cross-entropy loss.\"\n\nA1: We did replicate the experiment setups from [1] as we stated in our Experiment Setup section. Nonetheless, our primary focus in research is on the K-NN prediction test carried out on data with noisy labels. Our conclusions are drawn through a comparative analysis involving the interplay between the double descent phenomenon and prediction accuracy across varying levels of introduced label noise. Embracing a foundational and validated experimental setup proves advantageous for facilitating straightforward comparisons and validating our findings. \n\nQ2: ``While tSNE maps might give intuition about a phenomenon, they can also fabricate patterns and might not be sufficient evidence for a proposition.\"\n\nA2: We agree that the t-SNE experiments lack persuasiveness and have only a loose connection to our primary hypothesis. We have now reallocated the experiments to the appendix. \n\nQ3: ``The writing is sometimes confusing. For instance, in section 3.3: \u201cwe calculate the prediction accuracy Kp of noisy labeled data of the original clean labels for each noisy labeled data point matching the label prediction of its k-nearest neighbors in the learned feature space\u201d.\"\n\nA3: We have also strengthened the descriptions of our methodology, which includes a detailed explanation of how our hypothesis is founded, why our experiment can be used to validate our hypothesis, and re-formulated our mathematical description.\n\nQ4: ``I do not see substantial empirical nor theoretical contributions in this work.\"\n\nA4: Our distinctive contribution lies in illuminating the influence of model parameters on the strategy and effectiveness of learning representations. Furthermore, our study unveils the process by which over-parameterized models discern and effectively \"isolate\" label noise within the feature space. These are previously undocumented phenomena that have not been extensively explored or discussed in the existing body of literature."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700428778129,
                "cdate": 1700428778129,
                "tmdate": 1700428778129,
                "mdate": 1700428778129,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "TMnQogltvV",
                "forum": "CEkIyshNbC",
                "replyto": "Hn013rOGSS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission287/Reviewer_Ea52"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission287/Reviewer_Ea52"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for addressing some of my concerns.\n\nIt is now clearer that the primary goal is to analyze the K-NN prediction test, and perform a comparison with the experiments from 1. However, I still hold the view that the experiments carried out do not provide sufficient evidence for a solid hypothesis as to why over-parameterized models isolate label noise."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700574247094,
                "cdate": 1700574247094,
                "tmdate": 1700574247094,
                "mdate": 1700574247094,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "V9xQGxCmMR",
            "forum": "CEkIyshNbC",
            "replyto": "CEkIyshNbC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission287/Reviewer_d6tR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission287/Reviewer_d6tR"
            ],
            "content": {
                "summary": {
                    "value": "The research aims to show that the phenomenon of double descent with respect to model size appears in neural networks due to the addition of noisy labels, i.e., smaller models learn this noise, while larger size models are able to avoid it and recognize wrong labels while learning useful information. The proposed approach to this aim is to measure the nearest neighbor prediction for mislabeled examples based on learned representations (on the penultimate layer) and then demonstrate that this prediction corresponds to the original (true) label, no matter that network \"correctly\" predicts wrong label. t-SNE visualizations of representations are used as an additional evidence to this point."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Investigation of the ability of large neural networks to interpolate noisy labels, but nevertheless have good generalization is an important contribution to the current research. The mechanisms behind this phenomenon shed light on the generalization abilities of such models."
                },
                "weaknesses": {
                    "value": "The abstract of the paper states that the main contribution is to demonstrate that model-size double descent is happening only with label noise present in the dataset. Nevertheless, the experiment with CIFAR100in the paper directly disproves this claim already. Further, it is claimed that double descent will not happen in the correctly regularized networks, but no regularization is ever discussed in the paper itself, except for an unusual claim that overparameterization is a form of regularization (which is also never discussed in the paper). Together, this leaves only one possible contribution - explaining how interpolating networks deal with mislabeled examples. This is aimed to be explained through nearest neighbors classification on the representations for mislabeled examples - showing that this accuracy is very high for interpolating models. Nevertheless, only the MNIST experiment indeed demonstrates high accuracy of these predictions together with the high accuracy on noisy task, in other experiments this accuracy is considerably low. t-SNE visualizations can be simply explained by the ability of larger models to get a more distinguished representations for different classes, but the positioning of the noisy labeled ones does not change much (see class 0 in fig.2 for example). Thus, the last contribution is not significantly supported by the results.\n\nMinor:\n\n- please use \\citep and \\citet for the citations outside of the sentence and in the sentence\n\n- please check the grammar and typos in the paper \n\n- please improve the explanation of the formula (1), it is currently extremely convoluted\n\n- the font of the title does not correspond to ICLR style"
                },
                "questions": {
                    "value": "1 - What is the main goal of the research done?\n\n2 - What is the observation made with respect to the selected metric (nearest neighbors) from the double descent plots?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission287/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission287/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission287/Reviewer_d6tR"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission287/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698417504534,
            "cdate": 1698417504534,
            "tmdate": 1700650881012,
            "mdate": 1700650881012,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7W5N4DmosF",
                "forum": "CEkIyshNbC",
                "replyto": "V9xQGxCmMR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to official review"
                    },
                    "comment": {
                        "value": "Firstly, we appreciate your time in reviewing our paper and offering valuable comments and insights. \n\nQ1: ``The abstract of the paper states that the main contribution is to demonstrate that model-size double descent is happening only with label noise present in the dataset. Nevertheless, the experiment with CIFAR100in the paper directly disproves this claim already.\"\n\nA1: In the abstract, we stated that \"its occurrence is strongly influenced by the presence of noisy data.\". Speaking of the CIFAR-10 experiments, \"We suppose that this phenomenon may arise from the intrinsic noise and increased complexity associated with image recognition of CIFAR-10 in contrast to MNIST.\". I believe we have already addressed and explained your first concern in our paper. \n\nQ2: \"It is claimed that double descent will not happen in the correctly regularized networks, but no regularization is ever discussed in the paper itself, except for an unusual claim that overparameterization is a form of regularization (which is also never discussed in the paper).\"\n\nA2: We reach the conclusion that double descent should not occur in well-regularized models from referencing previous research and a derivation of our analysis of imperfect learners and noisy data. This conclusion line is now removed from our paper. \n\nQ3: ``Nevertheless, only the MNIST experiment indeed demonstrates high accuracy of these predictions together with the high accuracy on noisy tasks, in other experiments this accuracy is considerably low.\"\n\nA3: Our explanation of how interpolating networks deal with mislabeled examples is demonstrated through the aligned trend of test accuracy and the percentage ${\\rm P}$ (previously denoted as ${\\rm Kp}$), instead of a high value. Although the accuracy of predictions on CIFAR-10 is relatively modest, it's worth noting that the performance of CNNs and ResNets on this dataset is also suboptimal. Considering the challenge of a 10-class classification problem, achieving nearly 60\\% accuracy is commendable, and the comparison between models of varying widths still yields conclusive results.\n\nQ4: ``t-SNE visualizations can be simply explained by the ability of larger models to get more distinguished representations for different classes, but the positioning of the noisy labeled ones does not change much (see class 0 in fig.2 for example).\"\n\nA4: We acknowledge that the t-SNE experiments lack persuasiveness and have only a loose connection to our primary hypothesis. We have now reallocated the experiments to the appendix. \n\nQ5: ``What is the main goal of the research done?\"\n\nA5: Our distinctive contribution lies in illuminating the influence of model parameters on the strategy and effectiveness of learning representations. Furthermore, our study unveils the process by which over-parameterized models discern and effectively \"isolate\" label noise within the feature space. These are previously undocumented phenomena that have not been extensively explored or discussed in the existing body of literature.\n\nQ6: ``What is the observation made with respect to the selected metric (nearest neighbors) from the double descent plots?\"\n\nA6: In all of our experiments, the trajectory of the ${\\rm P}$ curve (denoted as ${\\rm Kp}$ previously) is in accordance with the pattern observed in the test accuracy curve, indicating a consistent alignment between the two. This alignment exists both before and after the interpolation threshold. This observation underscores a statistical correlation between the local structures within the learned representations of noisy training data and the overall performance in generalization. This validation serves to affirm the accuracy of our hypothesis.\n\nMinor corrections regarding grammar, typos, and formatting of titles and citations have been adopted. Equation 1 has been reformulated to enhance clarity and understanding."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700428663875,
                "cdate": 1700428663875,
                "tmdate": 1700428663875,
                "mdate": 1700428663875,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "btCbBOirXY",
                "forum": "CEkIyshNbC",
                "replyto": "7W5N4DmosF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission287/Reviewer_d6tR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission287/Reviewer_d6tR"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for the answers.\n\nA1. I am sorry for a typo with the dataset name, it should be CIFAR-10 and not CIFAR-100. Nevertheless, my point stands. If you claim that double descent is influenced by noise, then argument about intrinsic noise is vague and not verifiable. Please try to demonstrate then that CIFAR-10 indeed has noise inside of itself as compared to MNIST that does not.\n\nA3. I am not questioning the accuracy of the model used for CIFAR-10, but the difference between test accuracy of the model and the accuracy of knn predictions. In MNIST experiments the accuracy of knn is even higher than the original one, while for CIFAR-10 it is significantly lower. How would you interpret this? Is only the trend in the development enough to make the conclusions you make?\n\nA5. How exactly do you illuminate \"the influence of model parameters on the strategy and effectiveness of learning representations\"? \n\nA6. The alignment of trajectories can be overall explained by a better generalization ability of the model as well.\n\nWith the new explanation given to the calculation of the metric, I have an additional question: you check the alignment of predictions using the mislabeled training sample and the neighbors among the _test set_. My guess is that this result cannot be saying: we do expect the network to be consistent in its predictions. Therefore indeed all the similar inputs will get same label. I think it might be much more interesting how interpolating networks interpolate the training data, do they indeed learn features similarly even for the mislabeled samples."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700494505190,
                "cdate": 1700494505190,
                "tmdate": 1700494505190,
                "mdate": 1700494505190,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T39gmqdrlY",
                "forum": "CEkIyshNbC",
                "replyto": "WFj4tmKaeA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission287/Reviewer_d6tR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission287/Reviewer_d6tR"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for further clarifications.\n\nA1. Please add this citation to your paper. Ideally, it would be nice to then position CIFAR-10 as one with default label noise level (researched in the paper you provided) and as 0% level, because in the latter case your conjectures look weaker.\n\nA3. My claim is the following: is the model indeed interpolates around all the noisy (in the training set) samples in the correct way, then k-nn should perform as nice as the model itself. I agree nevertheless, that the trend still shows that this k-nn ability of the model is connected to the size of the model in the same way with double descent. I think this should be stated more clearly in the paper.\n\nI think it is great that you also look into the training set interpolation.\n\nOverall, I do change my opinion and I agree with the authors that this investigation can be interesting. I would suggest putting different emphasis on the overall description and positioning it as an interpolating models investigation. I also encourage the authors to make more precise mathematical descriptions (in the renewed one you still have some sloppy notations, for example, naming sum of labels as a set of samples). I will therefore raise my score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700650809619,
                "cdate": 1700650809619,
                "tmdate": 1700650809619,
                "mdate": 1700650809619,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "zzWumKwgFB",
            "forum": "CEkIyshNbC",
            "replyto": "CEkIyshNbC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission287/Reviewer_9d7L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission287/Reviewer_9d7L"
            ],
            "content": {
                "summary": {
                    "value": "This article focuses on \"Double Descent\" phenomenon, suggesting that the ability of a model to adapt to and recognize noisy data has a significant impact on its overall generalization performance and contributes to the phenomenon of double descent, and proposing the use of a k-nearest neighbor algorithm to infer the relative positions of clean and noisily labeled data in the learned feature space."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.This paper is feasible to understand the generalization ability and double descent phenomenon through the perspective of noise."
                },
                "weaknesses": {
                    "value": "1.The methodology section of this paper (only 14 lines of text and only 6 lines of description of the actual methodology) is poorly described and lacks math-related descriptions, making it difficult to accurately understand the author's intention.\n\n2.Is it optimal to use K-nearest neighbors here? the feature space is probably in a high-dimensional Manifolds, have the authors considered more complex cases?\n\n3. I don't think this article convinces me enough about the mechanism by which it reveals that over-parameterization enhances generalization. The mechanism between over-parameterization and generalization cannot be revealed in depth only by the loss curves and T-sne images under a small number of experiments.\n\n4. It is well recognized that over-parameterization is beneficial, especially since recent large models have similarly benefited from over-parameterization, and the authors should discuss the advantages of this paper in the context of recent over-parameterization research."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission287/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698672370789,
            "cdate": 1698672370789,
            "tmdate": 1699635954570,
            "mdate": 1699635954570,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "x3trJNFFOp",
                "forum": "CEkIyshNbC",
                "replyto": "zzWumKwgFB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to official reviews"
                    },
                    "comment": {
                        "value": "Firstly, we appreciate your time in reviewing our paper and offering valuable comments and insights. \n\nQ1: `` The methodology section of this paper is poorly described and lacks math-related descriptions, making it difficult to accurately understand the author's intention.\"\n\nA1: Thank you for your kind advice, we have now improved the methodology with a more complete description of how our hypothesis is founded, why our experiment can be used to validate our hypothesis, and re-formulated our mathematical description. Some paragraph is cited below: \n``Based on the existence of benign over-parameterization, we assume that test images, akin to training images mislabeled, are more likely to be correctly classified by over-parameterized models. For instance, we anticipate that an optimal classifier should yield accurate predictions for unseen images, even if it was trained on similar images with an adversarial label. Thus, we further hypothesize that the closest neighbours of mislabeled training images are correctly classified. ... We calculate the percentage ${\\rm P}$ of mislabeled training data, and the majority of its nearest neighbours in feature space are in the same class ...\"\n\nQ2: ``Is it optimal to use K-nearest neighbors here?\"\n\nA2: The application of a K-nearest neighbors (KNN) algorithm in a high-dimensional feature space can be reasoned based on several considerations. In a high-dimensional feature space, the notion of proximity becomes more nuanced, and traditional distance measures may lose their discriminatory power. KNN, as a non-parametric and instance-based algorithm, relies on the concept of similarity between data points (we use cosine similarity as our measurement tool). While we are trying to infer and observe local structures, KNN remains an effective tool for exploratory analysis.\n\nQ3: ``The mechanism between over-parameterization and generalization cannot be revealed in depth only by the loss curves and T-sne images under a small number of experiments.\"\n\nA3: Our explanation of how interpolating networks deal with mislabeled examples is demonstrated through the trajectory of the P curve (denoted as Kp previously) in accordance with the pattern observed in the test accuracy curve, indicating a consistent alignment between the two. This alignment exists both before and after the interpolation threshold. This observation underscores a statistical correlation between the local structures within the learned representations of noisy training data and the overall performance in generalization. This validation serves to affirm the accuracy of our hypothesis.\n\nQ4: ``The authors should discuss the advantages of this paper in the context of recent over-parameterization research.\"\n\nA4: We have added discussions of recent over-parameterization research in the related works section. Since we haven't encountered comparable hypotheses in previous literature, our distinctive contribution within the realm of over-parameterization research lies in illuminating the influence of model parameters on the strategy and effectiveness of learning representations. Furthermore, our study unveils the process by which over-parameterized models discern and effectively \"isolate\" label noise within the feature space. These are previously undocumented phenomena that have not been extensively explored or discussed in the existing body of literature."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700428530295,
                "cdate": 1700428530295,
                "tmdate": 1700428530295,
                "mdate": 1700428530295,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ag9Zw8L0hd",
            "forum": "CEkIyshNbC",
            "replyto": "CEkIyshNbC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission287/Reviewer_P23K"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission287/Reviewer_P23K"
            ],
            "content": {
                "summary": {
                    "value": "The paper performs a series of empirical studies into the double descent phenomena. The main take-away is that double descent appears when the model is faced with label noise."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(I stress that I have low confidence in my review. It is highly likely that I missed something important)\n\n* The double descent is, currently, highly counter-intuitive to many, so any insights into the phenomena are valuable.\n* The stated hypothesis regarding label noise is clear and seems intuitive."
                },
                "weaknesses": {
                    "value": "(I stress that I have low confidence in my review. It is highly likely that I missed something important)\n\n* As a non-expert, I interpret the experiments as showing that double descent phenomena appear with label noise in large models. I acknowledge that this is an interesting observation, but it does not seem sufficient to justify conclusions such as double descent not appearing in well-regularized models. I can see the intuition, but, in my non-expert view, the experimental data seems insufficient.\n* The paper considers only a small selection of data sets and models. It is not clear to me if such is sufficient to draw conclusions.\n* The paper does not provide a theoretical explanation (which is fine, but then I had wished for a wider selection of experiments).\n* I found it very difficult to read the t-SNE plots.\n* [minor] It appears that the ICLR formatting instructions were disregarded when changing the font size of the paper title."
                },
                "questions": {
                    "value": "* What is the 'wedge product' in Eq. 1?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission287/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698674056255,
            "cdate": 1698674056255,
            "tmdate": 1699635954491,
            "mdate": 1699635954491,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "z9S35dJvhG",
                "forum": "CEkIyshNbC",
                "replyto": "ag9Zw8L0hd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission287/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission287/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to official review"
                    },
                    "comment": {
                        "value": "Firstly, we appreciate your time in reviewing our paper and offering valuable comments and insights. \n\nQ1: ``It does not seem sufficient to justify conclusions such as double descent not appearing in well-regularized models.\"\n\nA1: We reach the conclusion that double descent should not occur in well-regularized models from referencing previous research and a derivation of our analysis of imperfect learners and noisy data. This conclusion line is now removed from our paper.\n\nQ2: ``The paper considers only a small selection of data sets and models. It is not clear to me if such is sufficient to draw conclusions.\"\n\nSecondly, the paper delves into a limited array of datasets and models. This deliberate selection is based on the recognition that larger and more intricate datasets inherently introduce additional noise, potentially interfering with the precision of our experiments. Our focus has been on conducting empirical studies within foundational experiment setups in deep learning. We assert that these chosen scenarios not only align with widely accepted practices but also serve as fundamental benchmarks for validating deep learning techniques.\n\nQ3: ``The paper does not provide a theoretical explanation (which is fine, but then I had wished for a wider selection of experiments).\"'\n\nA3: We contend that the empirical studies conducted in our research encompass various fundamental experiment setups in deep learning, specifically addressing real-world classification problems. Artificial data may lack sufficient persuasiveness, as the intricacy and noise inherent in more challenging tasks, as well as state-of-the-art methods, can significantly impact the actual structures of the feature space, introducing numerous uncontrollable factors. Our distinctive contribution lies in illuminating the influence of model parameters on the strategy and effectiveness of learning representations. Furthermore, our study unveils the process by which over-parameterized models discern and effectively \"isolate\" label noise within the feature space. These are previously undocumented phenomena that have not been extensively explored or discussed in the existing body of literature.\n\nQ4: ``I found it very difficult to read the t-SNE plots.\"\n\nA4: We acknowledge that the t-SNE experiments lack persuasiveness and have only a loose connection to our primary hypothesis. We have now reallocated the experiments to the appendix. \n\nMinor corrections regarding grammar, typos, and formatting of titles and citations have been adopted. Equation 1 has been reformulated to enhance clarity and understanding."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission287/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700428438046,
                "cdate": 1700428438046,
                "tmdate": 1700428438046,
                "mdate": 1700428438046,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]