[
    {
        "title": "Diving Deep into Regions: Exploiting Regional information Transformer for Single Image Deraining"
    },
    {
        "review": {
            "id": "2wnSzHBblp",
            "forum": "r92RVhnzKy",
            "replyto": "r92RVhnzKy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1110/Reviewer_29g8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1110/Reviewer_29g8"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a region-aware Transformer for single image deraining, which consists of a region masked attention and a mixed gate forward block. The authors observe that existing deraining methods ignore the differences between rain-affected and unaffected regions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "S1. The design of region masked attention is simple and effective, which can process rain-affected and unaffected regions of images separately.\n\nS2. The experimental evaluation and discussion are adequate, and the results convincingly support the main claims.\n\nS3. The paper is well-organized and clearly written."
                },
                "weaknesses": {
                    "value": "W1. The author should delve into the importance of the rain-affected and unaffected regions of rainy images. I am curious if utilizing the features of he unaffected regions can better guide image restoration?\n\nW2. How to determine whether high-quality region masks can be generated? If some visual examples of intermediate feature maps that illustrate this property are added, the proposed method can become compelling.\n\n-----------------------After Rebuttal---------------------------\n\nThank you for your feedback. The rebuttal addressed my concerns well. Considering other reviews, I decide to keep my score as Accept."
                },
                "questions": {
                    "value": "See the above Weaknesses part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1110/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1110/Reviewer_29g8",
                        "ICLR.cc/2024/Conference/Submission1110/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1110/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698553063871,
            "cdate": 1698553063871,
            "tmdate": 1700746766824,
            "mdate": 1700746766824,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JNrJflK16R",
                "forum": "r92RVhnzKy",
                "replyto": "2wnSzHBblp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 29g8, and thanks for your comments."
                    },
                    "comment": {
                        "value": "Thank you for reviewing our paper.\n\n---\n***Q1:*** The author should delve into the importance of the rain-affected and unaffected regions of rainy images. I am curious if utilizing the features of the unaffected regions can better guide image restoration?\n\n***Response:*** Thanks for your concerns. First, let me explain why we use rain-affected(Foreground) regions:\n\n**a)Foreground Mask (rain affected mask):** We utilize the foreground mask to better extract the characteristics of foreground rain streaks. This enables the network to identify the varying rain patterns more effectively, preventing the erroneous removal of rain-like features (as shown in Figure 2, where light spots are mistakenly removed as the rain for the results of DRSformer, IDT, and DualGCN).\n\n**b) Background Mask (rain unaffected mask):** The employment of the background mask aims to emphasize useful features, which can be utilized to recover details in rain streaks (as depicted in Figure 7 in the appendix, where rain streaks in the sky are not separated for the ablation setting without the background mask). This ensures that rain areas can be effectively recovered with desired content via the following ``combing mask\" stage.\n\n**c) Combining Masks:** \nAs shown in Figure 1 of the main paper, a full mask is utilized to incorporate the results from both masks with a transformer block. This technique allows the non-rain areas in the background to guide the restoration of the corresponding rain-streaked foreground areas, resulting in more realistic image details.\n\n\nWe have conducted experiments using foreground and background masks, respectively, in the ablation experiment section. The specific details are explained in the ablation study section (Sec. 4.3). \nThe results, particularly for variants v6, v7, and v8, demonstrate the efficacy of our strategy.\nIn addition, we also conducted partial ablation experiments on the SPA-Data dataset, as shown below. The results again validate our approach. \n\n---\n|    | Variants         | PSNR  | SSIM   |\n|----|------------------|-------|--------|\n| v2 | Baseline $_{2}$  | 44.38 | 0.988 |\n| v4 | w/RTC$_{2}$      | 44.84 | 0.990 |\n| v5 | w/MGFB           | 44.89 | 0.988 |\n| v6 | v5+FGMask        | 45.25 | 0,990 |\n| v7 | v5+BGMask        | 45.11 | 0.989 |\n| v8 | **Regformer**    | 45.41 | 0.990 |\n\n---\n\nBesides, **Reviewer ac1q** also agrees with the significance of using foreground mask and background separately. He mentioned that our method first points out the importance of explicitly and individually processing rain-affected and unaffected regions and then combing them.\n\n\nFinally, we appreciate your comments and welcome further questions or clarifications. We are committed to ongoing discussions to enhance the quality of our paper and address any concerns you may have.\n\n   \n---\n\n***Q2:*** How to determine whether high-quality region masks can be generated? If some visual examples of intermediate feature maps that illustrate this property are added, the proposed method can become compelling.\n\n***Response:*** \n\nThank you for your valuable suggestion. In response to your query on the quality of generated region masks, we have included a series of intermediate feature maps in the revised supplementary materials, specifically showcased in Figure 10. These feature maps represent the masks as they are processed within the network during inference. To effectively visualize them, we have averaged the masks across their respective channels and transformed them into RGB images for a more direct and visual representation.\n\nWe believe this addition will provide a clearer insight into the quality and functionality of the masks generated by our method, thereby bolstering the credibility of our proposed approach.\n\nShould you have any further questions or additional suggestions, we are more than open to them. Your feedback is instrumental in enhancing the quality of our work, and we greatly appreciate your contribution to this process."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1110/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700304413677,
                "cdate": 1700304413677,
                "tmdate": 1700304413677,
                "mdate": 1700304413677,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0QOLXejuor",
            "forum": "r92RVhnzKy",
            "replyto": "r92RVhnzKy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1110/Reviewer_ac1q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1110/Reviewer_ac1q"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel and effective transformer-based method for Single Image Deraining (SID). In this paper, one significant motivation is the consideration of processing rain-affected and unaffected regions independently and then combining their effects for the final reconstruction. Such a hierarchical strategy helps to vastly improve the deraining effects, especially in these challenging cases. The proposed framework is called Region Transformer (Regformer), consisting of Region Masked Attention (RMA) mechanism and a Mixed Gate Forward Block (MGFB). Extensive experiments are conducted on all current representative deraining datasets, and both RMA and MGFB are verified to be effective in dealing with deraining degradations."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1.\tThe proposed framework first points out the importance of explicitly and individually processing rain-affected and unaffected regions, leading to new SOTA performance on all current SID datasets, without the increase of model parameters/flops compared with existing methods.\n2.\tCompared with current baselines, the visual results of Regformer are much better, especially in these regions with details while covered with the raindrop in the original image. Its performance for different real-world cases has also proven to be great.\n3.\tThe writing and organization of this paper is satisfactory."
                },
                "weaknesses": {
                    "value": "1.\tMore perceptual metrics can be added for comparison in Table 1 with strong baselines, like LPIPS, which can reflect the quality of the restoration from different aspects.\n2.\tThe ablation study in Table 3 can be conducted on more datasets to get a more comprehensive analysis."
                },
                "questions": {
                    "value": "1.\tWhat is the effect of $k_i$ in MGFB?\n2.\tWhat are the implement details of baselines? i.e., how their scores are obtained in Table 1? These should be described in detail."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1110/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698670968261,
            "cdate": 1698670968261,
            "tmdate": 1699636037203,
            "mdate": 1699636037203,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "h4NnASwjxE",
                "forum": "r92RVhnzKy",
                "replyto": "0QOLXejuor",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ac1q, and thanks for your comments. (PART I)"
                    },
                    "comment": {
                        "value": "Thank you for reviewing our paper.\n\n---\n\n***Q1:*** More perceptual metrics can be added for comparison in Table 1 with strong baselines, like LPIPS, which can reflect the quality of the restoration from different aspects.\n\n***Response:*** Thank you for your valuable suggestion to include more perceptual metrics in our comparative analysis. We recognize the importance of such metrics, like LPIPS (Learned Perceptual Image Patch Similarity), in providing a more holistic view of image restoration quality.\n\nIn response to your recommendation, we have evaluated the performance of our method, Regformer, alongside other established methods using these metrics on the SPA-Data dataset. The results are summarized in the table below:\n\n---\n| Model         | LPIPS  |\n|------------------|-------|\n| Restormer | 0.0278|\n|  DRSformer    | 0.0267 |\n| Regformer          | **0.0247** |\n\n\n---\n\nWe will ensure these additional metrics are included in supplementary materials of our paper.\n\nThese metrics should provide a more nuanced understanding of each method's performance in terms of perceptual image quality.\n\n---\n\n***Q2:*** The ablation study in Table 3 can be conducted on more datasets to get a more comprehensive analysis.\n\n***Response:*** \nThank you for your suggestion regarding the expansion of our ablation studies to include more datasets. In response to your comments and the feedback from reviewer FN5q, we have extended our ablation experiments to the SPA-Data dataset. This additional analysis aligns with our goal to provide a more comprehensive evaluation of our model.\n\nThe table below presents the results of these extended ablation studies on the SPA-Data dataset. For a swifter qualitative assessment, these models were retrained with 100k iterations, though it is important to note that this performance is not as robust as the 300k iterations results detailed in our paper. We selected several major ablation experiments for training and testing to highlight critical aspects of our method:\n\n\n|    | Variants         | PSNR  | SSIM   |\n|----|------------------|-------|--------|\n| v2 | Baseline $_{2}$  | 44.38 | 0.988 |\n| v4 | w/RTC$_{2}$      | 44.84 | 0.990 |\n| v5 | w/MGFB           | 44.89 | 0.988 |\n| v6 | v5+FGMask        | 45.25 | 0,990 |\n| v7 | v5+BGMask        | 45.11 | 0.989 |\n| v8 | **Regformer**    | 45.41 | 0.990 |\n\n---\n\n\nThe advantage of our full setting (**Regformer**) compared with these ablation settings again validates the effectiveness of each component in our approach. \n\nShould you have any further questions or need additional clarification, please let us know. We appreciate your feedback and are committed to ensuring the thoroughness and accuracy of our research."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1110/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700300765096,
                "cdate": 1700300765096,
                "tmdate": 1700300765096,
                "mdate": 1700300765096,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6iSHYPawpt",
                "forum": "r92RVhnzKy",
                "replyto": "0QOLXejuor",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ac1q, and thanks for your comments. (PART II)"
                    },
                    "comment": {
                        "value": "***Q3:*** What's the effect of $k_{i}$ in MGFB?\n\n***Response:*** Thank you for your question regarding the role of $k_i$ in the MGFB module. Here $n$ and $k_i$ are hyper-parameters that will influence the performance of MGFB. \n\nWe conducted further experiments with varying $n$ and $k_i$, along with different activation function placements on the Rain200L Dataset. For a quicker quantitative assessment, we retrained these models with 100k iterations. Thus, it is noteworthy that this performance is lower compared to the 300k iteration results presented in the paper. The results are as follows:\n\n---\n|    | Variants                       | PSNR  | SSIM   |\n|----|------------------|-------|--------|\n| vv1 | $N=2,k_1=3,k_2=3,$ activate $k_1$         | 40.42 | 0.9879 |\n| **Regformer**|$N=2,k_1=3,k_2=5,$ activate $k_1$          | **40.52** | **0.9880** |\n| vv3 | $N=3, k_1=3, k_2=5, k_3=7, $ activate $k_1$| 40.44 | 0.9877   |\n| vv4 | $N=3, k_1=3, k_2=5, k_3=7, $ activate $k_1, k_2$| 40.42 | 0.9876 |\n---\n\nThese results demonstrate the impact of varying $k_i$ values and activation function placements on the model's performance.\n\n\n***Q4:*** What are the implement details of baselines? i.e., how their scores are obtained in Table 1? These should be described in detail. \n\n***Response:*** Thank you for raising the important question regarding the implementation details of the baseline models used in our study, particularly in relation to the scores presented in Table 1.\n\nFor a fair comparison, we following the experimental setting in the DRSformer[1] paper. \nWe ensured that the experimental environment and other variables were kept consistent to maintain the integrity of the comparison. This approach allowed us to directly use some baseline scores as reported in the DRSformer paper.\n\nFurthermore, for these methods without scores to refer to, we re-train them.\nFor the sake of fairness and accuracy, all experimental settings, except for the specific details pertaining to our model parameters, were aligned with those used in the DRSformer study. This consistency is critical to ensure that any observed differences in performance are attributable to the models themselves rather than variations in the experimental setup.\n\nWe appreciate your suggestion and will make sure to further clarify and emphasize this aspect in the experimental section of our paper. This will help ensure transparency and allow readers to understand the context under which the baseline comparisons were made.\n\nIf you have any further questions or need additional information, please feel free to reach out. We are committed to maintaining rigorous standards in our research methodology and welcome any feedback that can help enhance the clarity and quality of our work.\n\n[1] DRSformer: Learning a Sparse Transformer Network for Effective Image Deraining. CVPR 2023.\n\n---"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1110/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700301035473,
                "cdate": 1700301035473,
                "tmdate": 1700313277167,
                "mdate": 1700313277167,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DqOKLseW22",
            "forum": "r92RVhnzKy",
            "replyto": "r92RVhnzKy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1110/Reviewer_FN5q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1110/Reviewer_FN5q"
            ],
            "content": {
                "summary": {
                    "value": "This paper dives into single image deraining in the aspect of rain-affected regions and unaffected regions, and tries to remove rain streaks and preserve background parts. Based on this motivation, it proposes Region Transformer Block, which is composed of a Region Masked Attention mechanism and a Mixed Gate Forward Block. The former takes the information of rain-affected regions and unaffected regions into consideration and generates attention maps with region masks. The latter utilizes different kernel sizes to extract features on different receptive fields. It achieves SOTA results on multiple datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. More explicit decomposition of rain removal issues into rain streak removal in rain-affected regions and detail  preservation in unaffected regions\n2. Better performance with fewer parameters and equivalent computation cost compared with Restormer and DRSformer."
                },
                "weaknesses": {
                    "value": "1. The main concern is that this approach may be only effective on synthetic datasets. As shown in Table 1, RegFormer only brings 0.06dB PSNR gain on real-world dataset SPA-Data compared to DRSFormer. And when testing on a more realistic dataset (such as WeatherStream [1]), I'm worried that this approach may offer little improvement.\n2. The generation of region mask need to be further clarified. The expression in Sec. 3.2.1 seems to conflict with Figure 3.\n3. Could you provide the ablation studies (similar to Table 3) on SPA-Data dataset? \n4. It would be better if comparisons of inference time were given.\n\n[1] WeatherStream: Light Transport Automation of Single Image Deweathering. CVPR 2023."
                },
                "questions": {
                    "value": "Please see 'Weaknesses'."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1110/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1110/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1110/Reviewer_FN5q"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1110/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698696176584,
            "cdate": 1698696176584,
            "tmdate": 1699636037128,
            "mdate": 1699636037128,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tSd6SOXaSu",
                "forum": "r92RVhnzKy",
                "replyto": "DqOKLseW22",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer FN5q, and thanks for your comments. (PART I)"
                    },
                    "comment": {
                        "value": "Thank you for reviewing our paper. \n\n---\n\n***Q1:*** The main concern is that this approach may be only effective on synthetic datasets. As shown in Table 1, RegFormer only brings 0.06dB PSNR gain on real-world dataset SPA-Data compared to DRSFormer. And when testing on a more realistic dataset (such as WeatherStream [1]), I'm worried that this approach may offer little improvement.\n\n***Response:*** \n\nThank you for expressing your concerns regarding the effectiveness of our approach on real-world datasets. \nTo address this, I'd like to offer additional insights:\n\nFirst, the quantitative metric of PSNR is global and, as such, may not effectively reflect local variations in image content. Our paper, illustrated in Figures 2, 5, and 9, demonstrates that our results surpass the baselines on real-world SPA-data dataset, in terms of human perceptions. The visual representations in these figures provide a clearer appreciation of the enhancements offered by our method.\n\nSecond, in response to your suggestion, we tested our method on the WeatherStream Dataset. For quicker quantitative assessment, these models were retrained for 100k iterations. Please note this performance is lower than what would be observed with the standard training duration. Here are the comparative results with two prominent transformer-based models, Restormer[1] and DRSformer[2]. Note that for quicker evaluation, we use datasets in train2.zip to train these three models.\n\n---\n\n| Methods         | PSNR  | SSIM   |\n|------------------|-------|--------|\n| Restormer | 24.02 | 0.7501 |\n| DRSformer | 24.13 | 0.7521 |\n|  Regformer (ours) | 24.16 | 0.7532 |\n\n---\n\nIt is evident that our performance remains superior to these strong baselines on the WeatherStream dataset. This superiority aligns with the efficacy of the mask mechanism incorporated in our approach. It allows for more accurate processing of non-rainy regions during rain isolation, significantly boosting the discriminative capability of our model in handling rain-like image content features. This aspect has also been noted by reviewer ac1q.\n\nWe plan to include these findings in an updated version of the supplementary materials and will cite the WeatherStream paper accordingly.\n\n---\n\n***Q2:*** The generation of region mask need to be further clarified. The expression in Sec. 3.2.1 seems to conflict with Figure 3.\n\n***Response:*** Thank you for highlighting the inconsistency between Section 3.2.1 and Figure 3 in our paper, specifically regarding the generation of the region mask. Your observation is invaluable, and we appreciate your meticulous attention to detail.\n\nUpon a detailed review, we realized an oversight in Figure 3(a). The depiction suggested that the input image, after undergoing a 3x3 convolution, would yield three types of masks, which could potentially lead to confusion about where exactly the mask is generated. We have now corrected Figure 3 in the revised paper.\n\nThese features after 3x3 convolution will be employed in the decoder's RTC, and the difference between these shallow features and the decoder's restored features at varying levels will lead to mask computation.\nAs elaborated in Figure 4 of the main paper, the mask is computed by conducting threshold on the feature map.\nFor ease of understanding, we show images mapped to RGB space rather than feature maps.\n\n---\n\n[1] WeatherStream: Light Transport Automation of Single Image Deweathering. CVPR 2023."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1110/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700300457049,
                "cdate": 1700300457049,
                "tmdate": 1700300457049,
                "mdate": 1700300457049,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ByHTvOAWjG",
                "forum": "r92RVhnzKy",
                "replyto": "DqOKLseW22",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer FN5q, and thanks for your comments. (PART II)"
                    },
                    "comment": {
                        "value": "***Q3:*** Could you provide the ablation studies (similar to Table 3) on SPA-Data dataset?\n\n***Response:*** Thank you for your request to provide ablation studies on the SPA-Data dataset, similar to those presented in Table 3. We value your suggestion and have conducted several key ablation experiments to fulfill your request. Please note that due to constraints in time and resources, we have focused on testing some ablation settings with higher performance in Table 3.\n\nFor a quicker qualitative assessment, we have retrained these models for 100k iterations. It's important to mention that this performance metric is lower than the full 300k iterations results detailed in our paper. The following table illustrates the outcomes of our ablation studies on the SPA-Data Dataset:\n\n|    | Variants         | PSNR  | SSIM   |\n|----|------------------|-------|--------|\n| v2 | Baseline $_{2}$  | 44.38 | 0.988 |\n| v4 | w/RTC$_{2}$      | 44.84 | 0.990 |\n| v5 | w/MGFB           | 44.89 | 0.988 |\n| v6 | v5+FGMask        | 45.25 | 0,990 |\n| v7 | v5+BGMask        | 45.11 | 0.989 |\n| v8 | **Regformer**    | 45.41 | 0.990 |\n\n---\n\nOur full setting (**Regformer**) continues to exhibit superior performance compared to these ablation settings, consistent with the findings presented in Table 3 of the main paper.\nWe have selected these particular variants for their relevance and impact in demonstrating the effectiveness of our proposed method. \nThese results will be provided in the final version of our paper.\n\n\n---\n\n***Q4:*** It would be better if comparisons of inference time were given.\n\n***Response:*** Thank you for your valuable suggestion regarding the comparison of inference times. We have conducted a detailed analysis to compare the inference times of our model, RegFormer, with two strong models we have compared against in our paper, including Restormer [1] and DRSformer [2].\n\n \nTo ensure the comparison accuracy, we compute the average inference time with 300 images, each with the shape of [1, 3, 256, 256]. \nThe following table presents the inference time (in milliseconds) for each model:\n\n-----\n\n| Model         | Inference Time(ms)  |\n|------------------|-------|\n|  Restormer | 80.0 |\n| DRSformer | 168.7 |\n| Regformer(ours)   | 138.8 |\n\n------\n\nThese results demonstrate the efficiency of our Regformer model in comparison to the existing models. It's important to note that while our model is faster than DRSformer, it is slightly slower than Restormer. We believe this is a reasonable trade-off considering the performance gains our model offers.\n\nWe will include these details in the final version of our paper. If you have any further questions or need more information, please let us know. We are open to further discussions and appreciate your feedback in enhancing the quality of our research.\n\n[1] Restormer: Efficient Transformer for High-Resolution Image Restoration. CVPR 2022.\n\n[2] DRSformer: Learning a Sparse Transformer Network for Effective Image Deraining. CVPR 2023."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1110/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700300558564,
                "cdate": 1700300558564,
                "tmdate": 1700300558564,
                "mdate": 1700300558564,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cSzQpLuXIx",
            "forum": "r92RVhnzKy",
            "replyto": "r92RVhnzKy",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1110/Reviewer_edgT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1110/Reviewer_edgT"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a regional basded transformer network to tackle single image deraining problem. The proposed method includes a new architecture called Region Transformer Block, which utilizes the power of a masked attention structure and a mixed gated forward component. The region transformer is trying to learn features from the non-rain region to better recover the rain affected parts. Extensive experiments show that the proposed method outperforms the baseline methods in a consistent manner."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This paper is well written with strong motivation of solving the deraining problem by learning the unique features from the same image. \n2. The proposed method consistently outperforms others on benchmarking datasets."
                },
                "weaknesses": {
                    "value": "1. In Eq. (6), the big \\Pi is  indicating that the result of element-wise addition are multiplied together to form feature F. It is not stated clearly  that how the multiplication should be done. And why using multiplication? \n2. The last line on page 6, what does it mean by n and k_i are all parameters?"
                },
                "questions": {
                    "value": "One of the most important question in this paper is regarding the novelty. The region-based attention mechanism has been applied by many previous works in various areas. The proposed method does not show the advanced benefits of using the masked attention on the deraining problem, especially the explicit mechanism / design to identify the true features of non-rain regions. \n\nThe authors are suggested to answer the question and the weaknesses during the rebuttal period."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1110/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698829502443,
            "cdate": 1698829502443,
            "tmdate": 1699636037035,
            "mdate": 1699636037035,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "QJJKjZtAeG",
                "forum": "r92RVhnzKy",
                "replyto": "cSzQpLuXIx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer edgT, and thanks for your comments. \uff08PART I)"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to review our paper. \n\n***Q1:*** In Eq. (6), the big \\Pi is indicating that the result of element-wise addition are multiplied together to form feature $F$. It is not stated clearly that how the multiplication should be done. And why using multiplication?\n\n***Response:*** Thank you for your insightful comments. Based on your description, I believe you are referring to Eq. (5) in our paper. Upon re-examination, prompted by your remarks, we identified a necessary correction in our manuscript regarding this equation.\n\n **(1) Correction in Equation Description:**\n In our original manuscript, Equation (5) was described as:\n\n $ F = \\prod_{i=1}^{n}(DWConv_{k_{i} \\times k_{i}}(M) + M)$.\n \nHowever, we have amended this as follows to enhance clarity and accuracy:\n\n $F = Activation(DWConv_{k_{1}\\times k_{1}}(M) + M) \\odot \\prod_{i= 2}^{n}(DWConv_{k_{i}\\times k_{i}}(M) + M) $.\n\nConcurrently, we have removed the activation function from Equation (6). In summary, this modification shifts the activation function's position to precede the matrix multiplication. We have updated the correction in our newly revised paper (in Section 3.2.2, we use red highlighted text to display). This revision, sparked by your observation, led us to re-examine our code, ensuring the paper's precision. We aim to diligently review the manuscript before final publication to preclude similar issues.\n \n**(2) Rationale Behind Multiplication Usage:**\nThis adjustment signifies that we conduct element-wise multiplication across the outcomes of all parallel branches, as detailed in the revised Equation (5). This strategy is akin to the gating mechanism in Restormer[1], where feature maps from two parallel branches are multiplied to specialize each branch's feature processing ability before fusion. Equation (5) is the extension of such a gating strategy for multiple branches, enabling each to focus on a unique feature scale, propagating the detailed aspects complementary to other branches. We have updated this description using the red font in Section 3.2.2.\n\nWe appreciate your valuable feedback and guarantee to incorporate these changes in the paper's final version.\n\n---\n\n***Q2:***  The last line on page 6, what does it mean by n and k_i are all parameters? \n\n***Response:*** Thank you for your kind question. Let me clarify the statement about $n$ and $k_i$ being parameters.\nIn our research, $n$ and $k_i$ are indeed hyperparameters that we have the discretion to select manually. Our intent in designing the model in this manner was to transcend the conventional gating solutions typically seen in works like Restormer[1] and DRSformer[2]. By adjusting the FFN structure, we aimed to offer a more versatile and adaptable model with multiple scales. This design provides users with a broader range of suitable options when dealing with varied datasets or distinct tasks. We have updated this description using red font in section 4.1.\n\nTo further address any potential queries you may have, we have conducted an additional set of ablation experiments on the Rain200L Dataset. For a quicker quantitative assessment, we retrained these models with 100k iterations. Thus, it is noteworthy that this performance is lower compared to the 300k iteration results presented in the paper.\n\n|    | Variants                       | PSNR  | SSIM   |\n|----|------------------|-------|--------|\n| vv1 | $N=2,k_1=3,k_2=3,$ activate $k_1$         | 40.42 | 0.9879 |\n| **Regformer** |$N=2,k_1=3,k_2=5,$ activate $k_1$          | **40.52** | **0.9880** |\n| vv3 | $N=3, k_1=3, k_2=5, k_3=7,$ activate $k_1$| 40.44 | 0.9877   |\n| vv4 | $N=3, k_1=3, k_2=5, k_3=7,$ activate $k_1, k_2$| 40.42 | 0.9876 |\n\n---\n\n[1] Restormer: Efficient Transformer for High-Resolution Image Restoration. CVPR 2022.\n\n[2] DRSformer: Learning a Sparse Transformer Network for Effective Image Deraining. CVPR 2023."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1110/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700041072895,
                "cdate": 1700041072895,
                "tmdate": 1700301013690,
                "mdate": 1700301013690,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Zryrt2Cz5k",
                "forum": "r92RVhnzKy",
                "replyto": "cSzQpLuXIx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1110/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer edgT, and thanks for your comments. (PART II)"
                    },
                    "comment": {
                        "value": "Thank you for taking the time to review our paper. \n\n***Q3:***  One of the most important question in this paper is regarding the novelty. The region-based attention mechanism has been applied by many previous works in various areas. The proposed method does not show the advanced benefits of using the masked attention on the deraining problem, especially the explicit mechanism / design to identify the true features of non-rain regions.\n\n***Response:*** Thank you for your insightful query regarding the novelty of our approach. You are correct in noting that mask mechanisms have been utilized across various fields. However, our primary contribution lies not in the trivial transfer of the mask mechanism from other fields, but in designing novel and specific mechanisms for the rain removal task. Moreover, we elucidate the corresponding principles behind these mechanisms that can result in SOTA performance.\n\n\n**The specific motivation for using mask for deraining** \n\nOur decision to employ the mask mechanism stems from the unique challenge posed by rain-streaked images. These images require differential enhancement for rain-obscured regions and non-rain areas.\n\nOur mask strategy aims to capture the spatial distribution of such patterns and emphasize valuable features for the recovery of details, providing the network with vital location information to aid in effectively eliminating the rain and restoring image details.\n\n**The novel mask mechanism**\n\nBesides the uniqueness of the motivation, our mask mechanism follows a triple manner, including the formulation of foreground and background masks, as well as their combination, which is different from the mask mechanism in other restoration tasks.\n\n**a) Foreground Mask (rain affected mask):** We utilize the foreground mask to better extract the characteristics of foreground rain streaks. This enables the network to identify the varying rain patterns more effectively, preventing the erroneous removal of rain-like features (as shown in Figure 2, where light spots are mistakenly removed as the rain for the results of DRSformer, IDT, and DualGCN).\n\n**b) Background Mask (rain unaffected mask):** The employment of the background mask aims to emphasize useful features, which can be utilized to recover details in rain streaks (as depicted in Figure 7 in the appendix, where rain streaks in the sky are not separated for the ablation setting without the background mask). This ensures that rain areas can be effectively recovered with desired content via the following \"combing mask\" stage.\n\n**c) Combining Masks:** \nAs shown in Figure 1 of the main paper, a full mask is utilized to incorporate the results from both masks with a transformer block. This technique allows the non-rain areas in the background to guide the restoration of the corresponding rain-streaked foreground areas, resulting in more realistic image details.\n\n\nBesides, **Reviewer ac1q** mentioned that our method first points out the importance of explicitly and individually processing rain-affected (foreground) and unaffected (background) regions. \n\nMoreover, the ablation study (the results, particularly for variants v6, v7, and v8 in Table 3 of the main paper) further validates the superiority of using triple masks. \n\n\n\nFinally, we appreciate your comments and welcome further questions or clarifications."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1110/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700041248558,
                "cdate": 1700041248558,
                "tmdate": 1700042693995,
                "mdate": 1700042693995,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]