[
    {
        "title": "Violence Detection and Localization in Video Through Subgroup Analysis"
    },
    {
        "review": {
            "id": "3L0ncrlKRG",
            "forum": "78Fp8ac3Hi",
            "replyto": "78Fp8ac3Hi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7409/Reviewer_WPpq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7409/Reviewer_WPpq"
            ],
            "content": {
                "summary": {
                    "value": "Violence Detection (VD) deals with the early detection and localization of violent events to enable timely human intervention. However, existing VD methods have their limitations, especially in processing surveillance data and considering the localization and social aspects of violent events. To overcome these shortcomings, the authors propose an innovative approach that incorporates social subgroups into VD.\n\nTheir method involves detecting and tracking subgroups across frames, adding an additional layer of information to VD. This allows the system to not only detect violence at the video level, but also identify the groups involved. This adaptable add-on module extends the applicability of existing VD models and algorithms.\n\nThe authors conducted extensive experiments on the SCFD and RWF-2000 surveillance datasets. The results show that their approach improves social awareness in video surveillance by accurately locating individuals involved in violent crimes. The system achieved a small performance improvement in the SCFD dataset and maintained its performance in the RWF-2000 dataset, achieving 91.3% and 87.2% accuracy, respectively. Importantly, the approach also showed good generalization to unseen datasets, representing a promising advance in the early detection of violence."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": ".) The paper is well structured and well written, the contribution is clear\n.) The experimental section and comparision with SOTA is very good.\n.) The introduction of subgroups provides an improvement of the overall analysis task."
                },
                "weaknesses": {
                    "value": "One of the main goals is that the results enhance public safety, but this is not shown at all. The paper provides a good technical contribution but fails to address the social dimensions as all the others briefly mentioned in the abstract.\nSection 3.2: The paper contains assumptions what violence is, but does not provide a definition. It s also unclear how violence is defined in the datasets.\nNo tests in real scenarios, but it is claimed that the system works in real world.\nThe main novelty is the introduction of sub groups who have a marginal impact on the overall outcome. So innovation is rated rather limited."
                },
                "questions": {
                    "value": "3.2: what is the content of the datasets? What do they show? How is Violence defined: it seems violence is defined as what is annotated in the video data? Did you investigate any biases in the dataset?\nProvide a precise definition of violance!"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Discrimination / bias / fairness concerns",
                        "Yes, Privacy, security and safety",
                        "Yes, Legal compliance (e.g., GDPR, copyright, terms of use)",
                        "Yes, Potentially harmful insights, methodologies and applications",
                        "Yes, Responsible research practice (e.g., human subjects, data release)"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Detecting violence without any definition what it is, is not a scientific ethical approach. Claiming that this enhances public safety without any prove is also not a scientific/ethical approach. Analysis of people s behaviour and classifying between violent and non violent people might discriminate people, might be against GDPR, and needs an ethical statement. Moreover the underlying dataset is not investigated with respect to existing bias, or fairness constraints."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7409/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698320625505,
            "cdate": 1698320625505,
            "tmdate": 1699636888236,
            "mdate": 1699636888236,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "15fpWsUjvD",
            "forum": "78Fp8ac3Hi",
            "replyto": "78Fp8ac3Hi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7409/Reviewer_n6jP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7409/Reviewer_n6jP"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a system for violence detection and localization from surveillance videos. The proposed method extracts pose info and optical flow from the videos and clustering is performed to get potential crops. The crops (action proposals) are fed into an X3D network to extract features for the classifier. Experiments on two surveillance video datasets on detecting the \u201cfight\u201d action class show the efficacy of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed method achieves SOTA on one dataset.\n2. The paper is generally well-written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. There is no inference speed comparison. The model uses pretrained pose estimation models and needs to extract optical flow, which is computationally expensive. In real-world applications, surveillance video action detection systems will be required to run in real-time on certain hardware configurations. Therefore a speed analysis (for each component, if possible) is necessary. \n2. In terms of the system design, the X3D feature extraction process seems redundant. From Figure 1, the proposed method extracts full video features and subgroup features, which wastes computation on feature extraction on overlapping pixel areas. A more efficient way to extract features is to employ ROIAlign from a single feature map as in [1*, 2*]. Also these key implementation details are missing in the text.\n3. This paper is more of a computer vision \u201csystem\u201d paper, which is more suitable for a CV conference like CVPR or WACV.\n4. Missing references on a series of surveillance video action detection works:\n[1*] Argus: Efficient activity detection system for extended video analysis. WACVW 2020.\n[2*] Gabriellav2: Towards better generalization in surveillance videos for action detection. WACVW2022"
                },
                "questions": {
                    "value": "1. In terms of the evaluation, the authors report accuracy and F1. However, since the task is to output bounding boxes over the violence time interval, some kind of matching between predicted bounding boxes and ground truth is needed (like the IOU threshold and mAP metric in object detection literature). Can the authors elaborate on how this matching is done and why the current metric does not reflect this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7409/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698735542397,
            "cdate": 1698735542397,
            "tmdate": 1699636888113,
            "mdate": 1699636888113,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "cSVgwXLZ43",
            "forum": "78Fp8ac3Hi",
            "replyto": "78Fp8ac3Hi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7409/Reviewer_u3A5"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7409/Reviewer_u3A5"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method to solve the violence detection method. The proposed method proposes a subgroup clustering strategy along with the whole video to detection violence in videos. The proposed method achieves state-of-the-art performance on some benchmark datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "In general, I think the proposed paper has clear illustrations and explanations. The proposed method is somehow simple and can be easily implemented."
                },
                "weaknesses": {
                    "value": "However, I think this paper has some severe drawbacks:\n\n1. The proposed method somehow lacks novelty here. The proposed method (subgroup and part analysis) in video understanding is not a brand-new idea. Considering [1] and [2], which explicitly split scenes, objects, and persons. I don't think there is a critical difference between those works and the proposed method. Also, I don't think there exists novelty in the clustering part. To me, this paper is more like a technical report rather than a research paper. This is my critical concern. \n\n2. To me, the experiment part needs to be revised. The author does not provide extra ablations to verify the effectiveness of the proposed model like the prediction fusion threshold, subgroup threshold, etc. \n1: Choi J, Gao C, Messou J C E, et al. Why can't I dance in the mall? learning to mitigate scene bias in action recognition[J]. Advances in Neural Information Processing Systems, 2019, 32.\n\n2: Wang Y, Hoai M. Pulling actions out of context: Explicit separation for effective combination[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 7044-7053."
                },
                "questions": {
                    "value": "Please mainly see the weaknesses section for details. Besides those weaknesses section, I have some extra questions:\n\n1. In Section 3.3.1, the author mentioned that they use X3D backbone to extract features. Why does the author choose X3D as the backbone? It is not a popular backbone, especially with recent Transformer models like VideoMAE, MeMViT, etc. \n\n2. In Section 3.3.2, the author mentioned using the linear sum assignment problem with scipy and the center coordination. I think there can be more choices rather than center coordinates, i.e., bounding boxes (with SimOTA or related techniques). I was wondering if a better design will bring better results."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7409/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698739901501,
            "cdate": 1698739901501,
            "tmdate": 1699636887999,
            "mdate": 1699636887999,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "suAIu3PFTz",
            "forum": "78Fp8ac3Hi",
            "replyto": "78Fp8ac3Hi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7409/Reviewer_bXAa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7409/Reviewer_bXAa"
            ],
            "content": {
                "summary": {
                    "value": "The paper deals with the problem of detecting and localizing violence in videos, through detection and use of shown subgroups in video frames. It can be applied in safety systems in real-world settings, thus reducing workload of human analysts. Experiments are presented on two datasets, SCFD and RWF-2000."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper extends the ability to detect violence in videos by also considering the existence of cropped subgroups of persons, e.g., fighting, in video frames. Experimental results are shown using two existing image datasets."
                },
                "weaknesses": {
                    "value": "The presented work marginally extends existing frameworks (e.g., Veltmeijer) from a technical point of view. \nMoreover, the paper, as also mentioned in the conclusions, does not target achieving a state of the art performance, but states that this is a future work. However, this affects the performance and, thus, the comparisons shown in the Tables (especially 3). As a result, it is not clear what the Tables show, as F1 score and ACC are lower when the proposed subgroup detection is included (in the RWF case)."
                },
                "questions": {
                    "value": "Why not including temporal attention in the current paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7409/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698744949436,
            "cdate": 1698744949436,
            "tmdate": 1699636887873,
            "mdate": 1699636887873,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]