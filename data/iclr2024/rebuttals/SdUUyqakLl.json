[
    {
        "title": "Exploit Gradient Skew to Circumvent Byzantine Defenses for Federated Learning"
    },
    {
        "review": {
            "id": "9Ysb21IgUO",
            "forum": "SdUUyqakLl",
            "replyto": "SdUUyqakLl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6901/Reviewer_EJRr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6901/Reviewer_EJRr"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a new attack called STRIKE against Byzantine-robust algorithms for Federated Learning. STRIKE is designed to leverage the so-called gradient skewness to hurt the accuracy of Byzantine-robust defenses. The authors provide theoretical and empirical analyses of STRIKE. In particular, they show the effectiveness of their attack, compared to existing ones, on non-iid FL benchmarks."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The topic of Byzantine robustness is important and such research on stronger attacks is valuable, especially in the more realisitic non-iid setting. Moreover, the approach taken is somewhat original and the experimental results are encouraging."
                },
                "weaknesses": {
                    "value": "I have two major concerns. The first is related to the soundness of the paper; it seems that most theoretical results do not hold currently. My second concern is that highly relevant defenses are not featured in the experiments. I also have other concerns regarding clarity. All my concerns are detailed below.\n\n## Major Weaknesses\n\n1. Proposition 1 is not true as stated, and the proof of Lemma 1 is incorrect:\n\nRegarding Proposition 1, the step leading to Equation (51) is only true if $\\gamma = \\Omega(\\lambda^2)$, which has no reason to hold. If not, even if you take the right-hand side to be (50), it is not possible to take squares to obtain (52) (and the statement of Proposition 1 is not proven). I do not see a possible fix for this issue.\n\nAlso, the proof of Lemma 1 is incorrect; the last inequality in (26) is not true, e.g., take $X=Y$. Fix: If you additionally assume independence, you can get (26) but with square root on the right-hand side. Furthermore, (28) and (29) are clearly incorrect.\n\n2. Since Proposition 1 is incorrect, so is Proposition 2 which relies upon the former. Even if the latter was correct, the stated result is rather superfluous as the $\\rho^2$ (should depend on $t$ by the way) in the lower bound is shown to vanish across iterations by Farhadkhani et al. (2022).\n\n3. In the experiments, the defenses used are not the best when considering data heterogeneity. Only Bucketing (Karimireddy et al., 2021), among all considered defenses, was designed for this purpose. The work of Allouah et al. (2023) propose another defense called NNM and show that it improves upon Bucketing. At least this other defense should be tested to claim having a strong attack in non-iid settings.\n\n## Other Weaknesses\n\n4. The related work section is inaccurate. The second paragraph in Section 2 wrongly mentions that Farhadkhani et al. (2022) studied Byzantine-robustness under data heterogeneity.\n\n5. The term \"skew\" is repeatedly used without a proper definition, although a formal definition is given in page 4 without intuition on what skewness means. It seems throughout the paper that it can be replaced by gradient heterogeneity/dissimilarity. In that case, the insights given are very similar to those of Karimireddy et al., (2021), Allouah et al. (2023), etc.. In fact, skewness is a confusing term; it is widely used when referring to probability distributions, but that definition is quite different from what paper suggests. But again, a proper definition would have cleared this issue.\n\n6. \"Skewed majority\" is inaccurate: if $\\tfrac{f}{n} \\leq 1/3$ then a set of size $n-2f$ does not constitute a majority.\n\n7. The last sentence in Section 4.2 is clearly incorrect: convexity is an additional assumption, which makes the analysis \"easier\" than that of non-convex functions. \n\n8. The choice of search direction, fundamental to the attack presented, seems quite arbitrary. A reference to \"Karl's Pearson's formula\" is quickly given, but without any justification whatsoever of the search direction.\n\n9. Parameter $\\nu$ seems quite redundant with $\\alpha$, especially since the experiments on the role of $\\nu$ suggest that setting $\\nu=1$ is good enough, without giving a guidance or whatsoever on how to choose it."
                },
                "questions": {
                    "value": "Please address the weaknesses above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6901/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6901/Reviewer_EJRr",
                        "ICLR.cc/2024/Conference/Submission6901/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698602028639,
            "cdate": 1698602028639,
            "tmdate": 1700675676546,
            "mdate": 1700675676546,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YGfOyGUEJh",
                "forum": "SdUUyqakLl",
                "replyto": "9Ysb21IgUO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (Major Weaknesses)"
                    },
                    "comment": {
                        "value": "We appreciate the time and effort you have dedicated to reviewing our work. We would like to address your major concerns as follows.\n\n---\n\n**W1:** Proposition 1 is not true as stated, and the proof of Lemma 1 is incorrect.\n\n**A1:**\nWe thank the reviewer for checking the details of the proof.\n\nWe acknowledge that Proposition 1 requires the distribution of honest gradients to be skewed enough. Yet we want to emphasize that the visualization in Figure 4, Appendix A verifies that honest gradient is highly skewed on various datasets. Similarly, the lower bound provided by (Xie et al., 2020) also requires the variance of honest gradients to be large enough. Therefore, we argue that it is reasonable to assume the distribution of honest gradients to be skewed enough.\n\nWe've fixed the proof for Lemma 1. To summarize, we added the missing radical signs, i.e., changed all $\\mathbb{E}[\\|\\boldsymbol{X}\\|^2]\\mathbb{E}[[\\|\\boldsymbol{Y}\\|^2]$ to $\\sqrt{\\mathbb{E}[\\|\\boldsymbol{X}\\|^2]\\mathbb{E}[[\\|\\boldsymbol{Y}\\|^2]}$ in Eq. (26), (27), (28) and (29). We Please refer to Appendix B.1 for the fixed version.\n\n---\n\n**W2:** Proposition 2 is superfluous as the $\\rho^2$ (should depend on by the way) in the lower bound is shown to vanish across iterations by Farhadkhani et al. (2022).\n\n**A2:** Thanks for the thoughtful comment. We have carefully looked through Farhadkhani et al. (2022) and cannot find the statement that $\\rho^2$ would vanish across iterations. In fact, even in the simplest case where the local loss functions on clients are convex, $\\rho^2$ won't vanish across iterations as long as local loss functions have different minimizers (due to data heterogeneity).\n\n---\n\n**W3:** Performance against NNM proposed by Allouah et al. (2023).\n\n**A3:** Thank you for the kind suggestion. We have supplemented the experiments and tested the proposed attack against NNM proposed by Allouah et al. (2023). The results are posted in Table 1 below. The results suggest that the proposed STRIKE attack still outperforms other baseline attacks against NNM.\n\n**Table 1.** Accuracy under different attacks against different defenses on ImageNet-12. The best results are in bold. The lower, the better.\n\n| Attack | Median | RFA | DnC |\n|:-:|-:|-:|-:|\n| NNM + BitFlip | 57.14 | 58.55 | 53.68 |\n| NNM + LIE | 58.04 | 58.68 | 58.87 |\n| NNM + Mimic | 66.15 | 67.43 | 69.35 |\n| NNM + STRIKE | **39.61** | **40.38** | **38.91** |\n\n(Due to limited time, we only run experiments on the top-3 robust AGRs in the main experiment and the strongest attacks against these robust AGRs. We will provide more results in our final revision.)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660176415,
                "cdate": 1700660176415,
                "tmdate": 1700660176415,
                "mdate": 1700660176415,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Y0W50ZpaxS",
                "forum": "SdUUyqakLl",
                "replyto": "9Ysb21IgUO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (Minor Weaknesses)"
                    },
                    "comment": {
                        "value": "We appreciate the time and effort you have dedicated to reviewing our work. We would like to address your minor concerns as follows.\n\n---\n\n**Q4:** The related work section is inaccurate.\n\n**A4:** Thanks for pointing out this typo. We've corrected it as follows.\n\n>  El-Mhamdi et al. (2021); ~Farhadkhani et al. (2022);~ Karimireddy et al. (2022) provide state-of-the-art theoretical analysis of Byzantine resilience under data heterogeneity.\n\nPlease refer to Section 2 for details.\n\n---\n\n**Q5:** The term \"skew\" is repeatedly used without a proper definition, although a formal definition is given in page 4 without intuition on what skewness means. It seems throughout the paper that it can be replaced by gradient heterogeneity/dissimilarity. In that case, the insights given are very similar to those of Karimireddy et al., (2021), Allouah et al. (2023), etc.. In fact, skewness is a confusing term; it is widely used when referring to probability distributions, but that definition is quite different from what paper suggests. But again, a proper definition would have cleared this issue.\n\n**A5:** \nThe term \"skew\" is formally defined in Definition 2. The intuition is already provided in 4-th paragraph, Section 1 in the original paper together with an intuitive visualization. The sentence is \"the majority of honest gradients skew away from the optimal gradient\". In this case, the skew is totally different from the gradient heterogeneity/dissimilarity defined in the previous paper. \"Skewness\" is formally defined in Definition 2, and is totally different from one defined in probability theory.\n\n---\n\n**Q6:** \"Skewed majority\" is inaccurate.\n\n**A6:** Thank you for pointing this out. We have changed it to a more accurate representation, \"skewed honest gradients\" in revision.\n\n---\n\n**Q7:** The last sentence in Section 4.2 is incorrect.\n\n**A7:** We thank the reviewer for pointing out this typo. The corrected version of this sentence is as follows.\n\n> Note that we do not require the loss function to be \\textcolor{blue}{convex}, which implies that Proposition 2 also applies to more challenging \\textcolor{blue}{non-convex} loss functions.\n\nPlease refer to Section 4.2 in revision for the corrected version.\n\n---\n\n**Q8:** Justification of the search direction.\n\n**A8:** Thank you for the insightful suggestion. We acknowledge that more justification can help readers to better get the reasonableness and effectiveness of search direction.\n\nWe visualize the Byzantine gradients together with honest gradients under STRIKE attack against Median AGR on CIFAR-10 in the non-IID setting in Figure 5, Appendix A.\nThe visualization shows that Byzantine gradients can hide within the skewed honest gradients well.\nThis justifies that the heuristic search in the first stage of STRIKE attack can effectively find the skewed honest gradients, i.e., the search direction is effective.\n\n---\n\n**Q9:** Redundant parameter $\\nu$.\n\n**A9:** Thank you for the thoughtful comment.\n\nWhile STRIKE with $\\nu=1$ can outperform most SOTA attacks, an appropriate $\\nu$ can further improve the effectiveness of STRIKE against some particular defenses significantly, e.g., the accuracy of STRIKE ($\\nu=2.0$) is 5% lower than the accuracy of STRIKE ($\\nu=1.0$) as shown in Figure 6, Appendix D.2.1. Thus, we leave open to future researchers the possibility to carefully choose $\\nu$ value to boost the performance of STRIKE.\n\nWe have included the above discussion in our revision to clarify the necessity of hyperparameter $\\nu$."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660257296,
                "cdate": 1700660257296,
                "tmdate": 1700660257296,
                "mdate": 1700660257296,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nnUvKrOSKD",
                "forum": "SdUUyqakLl",
                "replyto": "Y0W50ZpaxS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6901/Reviewer_EJRr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6901/Reviewer_EJRr"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their response. The clarifications and additional experiments partly address my concerns, so I raise my score accordingly. I am willing to raise my score again if they address my remaining concerns below.\n\nI still have the following concerns:\n\n1. Proposition 1 is still not correct; please add the assumption needed (see my original review) to fix the issue. Then, can you please justify this assumption? For example, what are possible values of $\\gamma$, even for some examples? I understand that the authors observed \"skewness\" experimentally, but the (theoretically) claimed skewness should be justified theoretically.\n\n2. Proposition 2 may not be meaningful, as I mentioned in my original review. Indeed, when using momentums instead of gradients, Farhadkhani et al. (2022) show that $\\rho$ tends to zero assuming the data is i.i.d. However, even if the data is non-i.i.d., the learning rate is typically vanishing in $T$ to ensure convergence (see Karimireddy et al. 2022, Farhadkhani et al. 2022), so that the lower bound in Proposition 2 is vacuous in that case.\n\n3. Please add the additional experiments on NNM to the main paper. Also, NNM is a defense method, while your table shows NNM on the attack column."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675650794,
                "cdate": 1700675650794,
                "tmdate": 1700675650794,
                "mdate": 1700675650794,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GaKrL6pAPU",
            "forum": "SdUUyqakLl",
            "replyto": "SdUUyqakLl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6901/Reviewer_h2Sd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6901/Reviewer_h2Sd"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a simple yet effective Byzantine attack called STRIKE. The proposed attack is based on an observation called \"gradient skew\" that the majority of honest gradients are away from the optimal gradient (the average of honest gradient). The authors theoretically show that Byzantine defenses are vulnerable under gradient skew. The proposed attack utilizes the vulnerability by hiding Byzantine gradients in the identified skewed majority of honest gradients. Extensive experiments verify the effectiveness of the proposed attack."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The discovered \"gradient skew\" phenomenon under non-IID setting is interesting and novel, should inspire future works to follow.\n2. This paper theoretically analyzes the vulnerability of Byzantine defenses under gradient skew. \n3. The proposed attack outperforms baseline attacks empirically. \n4. The paper is well motivated and written."
                },
                "weaknesses": {
                    "value": "1.\tA threat model is missing, especially on the capability of adversary. Comparisons with baseline attacks are fair under same and similar adversary capability. The proposed attack requires adversary to know gradients of all honest participants. This is not required by all other attacks, and this needs more careful treatment.\n\n2.\tLack of discussion on any potential adaptive defense methods against this attack."
                },
                "questions": {
                    "value": "1.\tAlthough non-IID is common in FL, the reviewer is curious about what is the performance of the proposed attack when there is no skew?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6901/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6901/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6901/Reviewer_h2Sd"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698711647563,
            "cdate": 1698711647563,
            "tmdate": 1699636802745,
            "mdate": 1699636802745,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uyn6QKbfwk",
                "forum": "SdUUyqakLl",
                "replyto": "GaKrL6pAPU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are happy that the reviewer find our work to be inspiring and well-supported theoretically and empirically.\nWe would like to address your concerns as follows.\n\n---\n\n**W1:** The proposed attack requires adversary to know gradients of all honest participants.\n\n**A1:** Thank you for the thoughtful comment.\nWe also test the performance of the proposed STRIKE when only a certain proportion of honest gradients is known. In this case, STRIKE identifies $(n-2f) \\cdot \\theta$ honest gradients as skewed majority in the first stage, where $\\theta$ is the ratio of known. The experiments are performed on the ImageNet-12 dataset. All other setups are identical to the experimental setups in Section 6.1. The results are posted in Table 1 below. As shown in Table 1, the accuracy is higher, STRIKE attack is still competitive when only a proportion of honest gradients is known.\n\n**Table 1.** The accuracy of STRIKE when only a certain proportion of honest gradients is known on the ImageNet-12 dataset. The lower, the better.\n\n| Ratio of known honest gradients | Median | RFA | DnC |\n|:-:|-:|-:|-:|\n| 0.25 | 58.2 | 53.91 | 62.21 |\n| 0.5 | 51.57 | 45.16 | 60.06 |\n| 0.75 | 51.12 | 47.88 | 56.57 |\n\n**W2:** Lack of discussion on any potential adaptive defense methods against this attack.\n\n**A2:** We are grateful for your kind suggestion.\n\nIn Section 4.2, we have discussed existing defenses such as Multi-Krum, RBTM and any other robust AGRs that satisfies Definition 1, against this attack and they cannot defend against our STRIKE attack as shown in Proposition 1 and 2. \n\nThe STRIKE relies on the gradient skew phenomenon, which is closely related to non-IIDness of data distribution. Therefore, defenses that can alleviate non-IID can potentially mitigate our STRIKE attack.\n\nWe have added the above discussion to the revision. Please refer to Section 7.\n\n**Q1:** The performance of the proposed attack when there is no skew\n\n**A1:** We acknowledge your concerns regarding the performance of the proposed STRIKE when there is no gradient skew.\n\nWe have supplemented new experiments about the performance of STRIKE in the IID setting.\nThe results are posted in Table 2 below.\nThe results in Table 2 show that when there is no gradient skew (IID), our STRIKE attack is still competitive compared with other SOTA attacks (average rank 3.71).\n\n**Table 2.** The performance of the proposed attack in the IID setting on ImageNet-12. The lower, the better.\n\n| Attack | Multi-Krum | Median | RFA | Aksel | CClip | DnC | RBTM |\n|:-:|-:|-:|-:|-:|-:|-:|-:|\n| BitFlip | 68.33 | 64.13 | 67.28 | 63.88 | 11.67 | 65.54 | 63.04 |\n| LIE | 72.53 | 58.56 | 68.78 | 64.87 | 20.19 | 66.99 | 56.38 |\n| IPM | 71.35 | 61.96 | 68.01 | 69.07 | 12.02 | 69.01 | 68.43 |\n| MinMax | 60.99 | 60.93 | 67.79 | 63.81 | 21.09 | 63.78 | 59.04 |\n| MinSum | 65.00 | 61.83 | 68.11 | 65.93 | 18.46 | 67.72 | 55.99 |\n| Mimic | 63.91 | 73.69 | 61.35 | 66.09 | 14.74 | 64.71 | 72.15 |\n| STRIKE | 57.76 | 66.63 | 62.82 | 64.39 | 16.79 | 68.08 | 59.84 |\n| Rank of STRIKE | 1 | 6 | 2 | 3 | 4 | 6 | 4 |"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659475256,
                "cdate": 1700659475256,
                "tmdate": 1700659475256,
                "mdate": 1700659475256,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GotR09nePU",
            "forum": "SdUUyqakLl",
            "replyto": "SdUUyqakLl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6901/Reviewer_ykp2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6901/Reviewer_ykp2"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors theoretically show that the gradient skew makes distributed learning methods more vulnerable to Byzantine attacks. Furthermore, the authors propose a novel Byzantine attack called STRIKE that exploits gradient skew. Experimental results show that STRIKE outperforms existing attacks on three different datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Exploiting gradient skew to conduct Byzantine attacks looks interesting and reasonable.\n2. The paper is generally well-written.\n3. Experimental results on three different datasets are provided."
                },
                "weaknesses": {
                    "value": "1. The authors provide a lower bound for $\\mathbb{E}||w^t-w^*||^2$ in Proposition 2 for SGD with robust aggregation (without momentum). However, existing works (Karimireddy et al., 2021) have shown that using history information such as momentum can enhance Byzantine robustness. So, what will the lower bound for robust SGD with momentum be? Moreover, although the authors claim that the gradient skew is due to non-IID data, Assumption 2 makes the theoretical analysis restricted to the IID settings, which is confusing. Although I understand that the lower bound for IID settings also holds for more general non-IID settings, the IID assumption (i.e., Assumption 2) prevents obtaining a tighter bound for non-IID settings.\n\n2. Since the adversary clients with STRIKE attacks require more computation cost than benign clients, the authors are suggested to provide theoretical or empirical results of how much extra computation cost will the proposed STRIKE attack take.\n\n\nDue to the abovementioned concerns, I currently give a rating of 5. However, I am willing to raise my rating if the authors can properly address my concerns."
                },
                "questions": {
                    "value": "n/a"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741746830,
            "cdate": 1698741746830,
            "tmdate": 1699636802622,
            "mdate": 1699636802622,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "x6ypKIIfTZ",
                "forum": "SdUUyqakLl",
                "replyto": "GotR09nePU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are happy that the reviewer found our paper to be interestingly motivated and well written. We hope that the following responses can address your concerns.\n\n---\n\n**W1.1:** The proposed STRIKE against robust SGD with momentum in (Karimireddy et al., 2021).\n\n**A1.1:** Thank you for your insightful comment. We've tested the performance of the proposed STRIKE attack against CClip proposed by (Karimireddy et al., 2021) in Section 6. The empirical results suggest that our attack is still effective for robust SGD with momentum.\n\n---\n\n**W1.2:** Assumption 2 is confusing.\n\n**A1.2:** Sorry that the typo confused the reviewer. Assumption 2 does not require to be IID. The corrected version of Assumption 2 is as follows.\n\n> **Assumption 2** (Unbias)**.** The stochastic gradients sampled from any local data distribution are unbiased estimators of local gradients for all clients, i.e.,\n> $$\n\\mathbb{E}[\\boldsymbol{g}\\_i^t]=\\nabla\\mathcal{L}\\_{\\textcolor{blue}{i}}(\\boldsymbol{w}^t), \\quad\\forall i=1,\\ldots n, t=0,\\ldots,T-1.\n$$\n\nPlease refer to Assumption 2 in the revision for more details.\n\n---\n\n**W2:**  Theoretical or empirical results of computation cost of the proposed STRIKE attack.\n\n**A2:** We thank the reviewer for the thoughtful comment.\n\nTheoretically, the final optimization problem of the proposed STRIKE attack in Eq. (19) can be effectively solved by a bisection algorithm as discussed in Appendix C. The computation cost is $\\mathcal{O}(-\\log\\epsilon)$, where $\\epsilon$ is the error of $\\alpha$. In experiments, we perform bisection only 8 times and make the error of $\\alpha$ within $1%$. Empirically, the attack time for STRIKE is 12.11s (13.47s for MinMax, 13.35s for MinSum) on ImageNet-12.\n\nIn contrast, benign clients perform local updates to compute local gradients. The computation cost depends on the local data size, model architecture, batch size, number of local epochs, etc. In our setting, the average local update time is 15.14s on CIFAR-10, 11.76s on ImageNet-12 and 27.13s on FEMNIST. Tests are performed on a single A100 GPU.\n\nWe've included the above content in our discussion. Please kindly find it in Appendix C.\n\n---\n\nWe sincerely hope the above responses can address your concerns and improve your opinion of our paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659300504,
                "cdate": 1700659300504,
                "tmdate": 1700659300504,
                "mdate": 1700659300504,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ByHEOoOPmv",
                "forum": "SdUUyqakLl",
                "replyto": "GotR09nePU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Gentle reminder of response"
                    },
                    "comment": {
                        "value": "We would like to gently remind the reviewer of any follow-up clarifications or questions that we can do our best to address in the remaining limited time. We hope our previous response has clarified your comments and has helped improve your opinion of our work. Please let us know if there are additional comments you have for us.\nThank you once again for your valuable feedback on improving our work."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700716519490,
                "cdate": 1700716519490,
                "tmdate": 1700716519490,
                "mdate": 1700716519490,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uZUnWNFHpV",
                "forum": "SdUUyqakLl",
                "replyto": "GotR09nePU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6901/Reviewer_ykp2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6901/Reviewer_ykp2"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the author for the clarification. The concerns in my initial review have been almost addressed. Meanwhile, I have noticed some concerns about the correctness raised by other reviewers. I was waiting to see if the concerns about the correctness could be properly addressed and I apologize for the late response. I will raise my rating if the concerns about the correctness are addressed."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723147336,
                "cdate": 1700723147336,
                "tmdate": 1700723147336,
                "mdate": 1700723147336,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RBDlEWedB2",
            "forum": "SdUUyqakLl",
            "replyto": "SdUUyqakLl",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6901/Reviewer_vYnj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6901/Reviewer_vYnj"
            ],
            "content": {
                "summary": {
                    "value": "The authors reveal an important phenomenon: current Byzantine defenses in federated learning exhibit a common inductive bias that the majority of gradients are honest. They discover a novel phenomenon named \"gradient skew\", where the majority of honest gradients deviate from the optimal gradient due to non-IID data. The authors then provide a solid theoretical analysis of the vulnerability of Byzantine defenses under gradient skew. Based on the analysis, they propose STRIKE attack that hides Byzantine gradients within the skewed but honest gradients. The effectiveness of the attack is validated through extensive experiments."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1.\tThe theoretical analysis for the vulnerability of Byzantine defenses is solid and technically sound.\n2.\tThe newly discovered \"gradient skew\" phenomenon is novel and inspiring for the community. Extensive visualization results justify that gradient skew is common when data is non-IID, which is practical in real world.\n3.\tThe experiments are extensive. The proposed STRIKE is compared with 6 baseline attacks under 7 defenses."
                },
                "weaknesses": {
                    "value": "1.\tWhile the proposed STRIKE is effective, there is a lack of discussion on the efficiency of the attack. Solving eq. (19) seems to be expensive. Could you please discuss more about the computation cost of the STRIKE attack?\n2.\tIs there any limitation of the proposed STRIKE? Please elaborate more on it."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "10: strong accept, should be highlighted at the conference"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6901/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6901/Reviewer_vYnj",
                        "ICLR.cc/2024/Conference/Submission6901/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6901/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699665830368,
            "cdate": 1699665830368,
            "tmdate": 1699666045374,
            "mdate": 1699666045374,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fFJtlKbs7f",
                "forum": "SdUUyqakLl",
                "replyto": "RBDlEWedB2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6901/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate your valuable feedback and the time you've dedicated to providing it. We are glad that you find our paper to be well-supported both theoretically and empirically. We would like to address your concerns as follows:\n\n---\n\n**W1:** Computation cost of the STRIKE attack.\n\n**A1:** We thank the reviewer for the thoughtful comment.\n\nTheoretically, the final optimization problem of the proposed STRIKE attack in Eq. (19) can be effectively solved by a bisection algorithm as discussed in Appendix C. The computation cost is $\\mathcal{O}(-\\log\\epsilon)$, where $\\epsilon$ is the error of $\\alpha$. In experiments, we perform bisection only 8 times and make the error of $\\alpha$ within $1%$. Empirically, the attack time for STRIKE is 12.11s (13.47s for MinMax, 13.35s for MinSum) on ImageNet-12.\n\nWe've included the above content in our discussion. Please kindly find it in Appendix C.\n\n---\n\n**W2:** More discussion on the limitation.\n\n**A2:** Thanks for the valuable comment.\n\nA limitation is that the effectiveness of STRIKE attack relies on the existence of gradient skew.\nFor example, when the data is IID, the performance could be limited.\n\nWe have also supplemented new experiments about the performance of STRIKE in the IID setting.\nThe results are posted in Table 1 below.\nThe results in Table 1 show that when there is no gradient skew (IID), our STRIKE attack is still competitive compared with other SOTA attacks (average rank 3.71).\n\n**Table 1.** The performance of the proposed attack in the IID setting on ImageNet-12. The lower, the better.\n\n| Attack | Multi-Krum | Median | RFA | Aksel | CClip | DnC | RBTM |\n|:-:|-:|-:|-:|-:|-:|-:|-:|\n| BitFlip | 68.33 | 64.13 | 67.28 | 63.88 | 11.67 | 65.54 | 63.04 |\n| LIE | 72.53 | 58.56 | 68.78 | 64.87 | 20.19 | 66.99 | 56.38 |\n| IPM | 71.35 | 61.96 | 68.01 | 69.07 | 12.02 | 69.01 | 68.43 |\n| MinMax | 60.99 | 60.93 | 67.79 | 63.81 | 21.09 | 63.78 | 59.04 |\n| MinSum | 65.00 | 61.83 | 68.11 | 65.93 | 18.46 | 67.72 | 55.99 |\n| Mimic | 63.91 | 73.69 | 61.35 | 66.09 | 14.74 | 64.71 | 72.15 |\n| STRIKE | 57.76 | 66.63 | 62.82 | 64.39 | 16.79 | 68.08 | 59.84 |\n| Rank of STRIKE | 1 | 6 | 2 | 3 | 4 | 6 | 4 |\n\nWe have included the above discussion of limitations in the revision. Please kindly find it in Section 7."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6901/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700658819650,
                "cdate": 1700658819650,
                "tmdate": 1700658819650,
                "mdate": 1700658819650,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]