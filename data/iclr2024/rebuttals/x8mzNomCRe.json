[
    {
        "title": "Benchmarking the Robustness of Cross-view Geo-localization Models"
    },
    {
        "review": {
            "id": "IHdz9AFQXg",
            "forum": "x8mzNomCRe",
            "replyto": "x8mzNomCRe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3535/Reviewer_dQuR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3535/Reviewer_dQuR"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a benchmark for robust cross-view geo-localization. Necessary experiments have been conducted."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper presents a benchmark for robust cross-view geo-localization. Necessary experiments have been conducted."
                },
                "weaknesses": {
                    "value": "1. The included perturbations are all simulated. Some real-world perturbations should be considered. \n\n\n2. The contribution of this benchmark is limited. For benchmark construction, a helpful and convenient tool/page/package should be better for others to use and follow. By doing so, the contribution would be improved a lot.\n\n\n3. Overall, there is a lack of novelty and contribution to this paper."
                },
                "questions": {
                    "value": "Please see Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3535/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698647790564,
            "cdate": 1698647790564,
            "tmdate": 1699636307666,
            "mdate": 1699636307666,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "2inRwjyUnf",
            "forum": "x8mzNomCRe",
            "replyto": "x8mzNomCRe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3535/Reviewer_5XKV"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3535/Reviewer_5XKV"
            ],
            "content": {
                "summary": {
                    "value": "1) This paper benchmarks the robustness of cross-view geo-localization models;\n\n2) Specifically, the ground-view images are corrupted under different settings, and the performance of state-of-the-art methods is tested;\n\n3) Two straightforward data augumentation methods (stylization and histogram equalization) are used to improve the robustness of methods;\n\n4) A new robustness benchmark is thankfully received."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1) This paper is well-written and easy to follow;\n\n2) Though the technical contribution of this paper is limited, the idea of checking the robustness of existing cross-view model is new and could be useful/important for practical deployment (e.g., autonomous driving);\n\n3) A new robustness benchmark is thankfully received."
                },
                "weaknesses": {
                    "value": "I only have minor comments for this benchmark paper.\n\n1) I want to see some experiments concerning day/night settings. It would be good to provide experiments/examples using low-light ground-view query images;\n\n2) It's good for authors to conduct additional experiments using limited-FOV ground-view query images;\n\n3) Please bolden the best methods in Table 2 and 3;\n\n4) The number/types of style images may impact the performance of data augmentation."
                },
                "questions": {
                    "value": "Please refer to the weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3535/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698658421676,
            "cdate": 1698658421676,
            "tmdate": 1699636307586,
            "mdate": 1699636307586,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "2SoHR65UyE",
            "forum": "x8mzNomCRe",
            "replyto": "x8mzNomCRe",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3535/Reviewer_Lf8Y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3535/Reviewer_Lf8Y"
            ],
            "content": {
                "summary": {
                    "value": "This paper studied the robustness of existing cross-view localization models on real-world image corruptions, including different weather, blur, and noise types, as well as digital corruptions. \n\nThis paper augmented the original CVUSA and CVACT datasets with four types of corruptions and evaluated the performance degradation of existing cross-view localization models when trained on clean data. This paper also re-trained the existing models using images with corruption augmentations and assessed their performance on the clean and corruption data, respectively."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Studying the robustness of cross-view localization models to real-world corruptions is a practical research direction and is very necessary. This paper augmented the two well-known cross-view localization benchmarks, CVUSA and CVACT, with image corruptions for practical evaluation and analyzed the performance of existing cross-view localization models on these corrupted data."
                },
                "weaknesses": {
                    "value": "While this paper targets real-world problems, which sounds exciting, this paper is more like an experimental report than a research paper. Extensive evaluations of the robustness of previous algorithms to real-world image corruptions are conducted and reported. The types of real-world image corruption are also introduced in an earlier paper (Hendrycks & Dietterich, 2019). Thus, the contribution of this paper is considered insignificant. \n\nThis paper indeed investigates an important problem of cross-view localization techniques towards real-world applications. However, the authors should dive deeper and make more insightful contributions rather than simply list the results of previous works. \n\nFurthermore, the evaluation benchmarks are only on CVUSA & CVACT. Zhu et al. (CVPR 2021, VIGOR) have identified the limitations of the two datasets and introduced a more practical dataset, VIGOR. No discussion is conducted on the VIGOR dataset. \n\nResearchers have recently extended the single ground image cross-view retrieval to video retrieval, from the city-scale localization by retrieval to fine-grained localization once the top-1 aerial image has been retrieved. Please find some of these works below. However, no discussions on these topics are presented in this paper.\n \n[1] Shi, Yujiao, et al. \"CVLNet: Cross-view Semantic Correspondence Learning for Video-Based Camera Localization.\" Computer Vision\u2013ACCV 2022: 16th Asian Conference on Computer Vision, Macao, China, December 4\u20138, 2022, Proceedings, Part I. Cham: Springer Nature Switzerland, 2023.\n\n[2] Shi, Yujiao, et al. \"Accurate 3-DoF Camera Geo-Localization via Ground-to-Satellite Image Matching.\" IEEE Transactions on Pattern Analysis and Machine Intelligence (2022).\n\n[3] Xia, Zimin, et al. \"Visual cross-view metric localization with dense uncertainty estimates.\" Computer Vision\u2013ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part XXXIX. Cham: Springer Nature Switzerland, 2022.\n\n[4] Xia, Zimin, Olaf Booij, and Julian FP Kooij. \"Convolutional Cross-View Pose Estimation.\" arXiv preprint arXiv:2303.05915 (2023).\n\n[5] Lentsch, Ted de Vries, et al. \"SliceMatch: Geometry-guided Aggregation for Cross-View Pose Estimation.\" CVPR (2023).\n\n[6] Fervers, Florian, et al. \"Uncertainty-aware Vision-based Metric Cross-view Geolocalization.\"  CVPR (2023)."
                },
                "questions": {
                    "value": "1. Some terms are confused. For the term \"Stylazation\", the description in the first paragraph of Sec. 3.2 is consistent with the top row of Fig. 4. However, they differ from the corruption types illustrated in Fig.2 and Fig. 3. Does the training ablation in Sec. 5.2.1 really use the stylization shown in the top row of Fig. 4 instead of the different image corruptions used in the evaluation set? \n\n2. Sec 3.2 and Fig. 4 describes CLAHE. However, there is no experiment on CLAHE.\n\n3. I don't really understand the difference between \"Prior efforts often generated separate test sets for each corruption type and its corresponding 5 severity levels (Last para on Page 4)\" and the method used in this paper. From my understanding, the experiments in Tab.2 & 3 should be conducted in this way? Why \"it poses significant storage and computational costs\" compared to the method used in this paper?   \n\n4. For the top row of Page 7, it should be \"92,802 x 80\" rather than \"92,802\"?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3535/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721936303,
            "cdate": 1698721936303,
            "tmdate": 1699636307501,
            "mdate": 1699636307501,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]