[
    {
        "title": "From Indeterminacy to Determinacy: Augmenting Logical Reasoning Capabilities with Large Language Models"
    },
    {
        "review": {
            "id": "s5MdIxEkgT",
            "forum": "Sbi8BdKcob",
            "replyto": "Sbi8BdKcob",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1911/Reviewer_aK68"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1911/Reviewer_aK68"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents DetermLR, a CoT-style prompting strategy that elicits stronger reasoning capabilities from LLMs. Specifically, DetermLR iteratively identifies the most promising premises, prioritises and \"executes\" them, and then stores useful premises in a memory. \n\nExperiments are performed on 4 complex logical reasoning datasets, and DetermLR outperforms the 5 compared baselines, sometimes by a large margin."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* CoT-style reasoning is an active and important research area for LLMs as they allow strong reasoning capabilities to be elicited. \n\n* Logical reasoning is an important problem that LLMs are traditionally not strong at. Further investigation in this area is certainly welcome. \n\n* The proposed method achieves good performance on the 5 challenging datasets, outperforming the compared CoT-style prompting strategies."
                },
                "weaknesses": {
                    "value": "* The proposed method is quite simple. Thus, the technical contribution is light. For instance, the \"systematic premise identification module\" described in Sec. 3.1 is really quite simple, and I don't know whether I'd call it \"systematic\". \n\nBesides, it closely follows the Cumulative Reasoning (Zhang et al., 2023) technique, with the addition of a memory. Thus, the novelty is limited. \n\n* Some important details have been omitted in the paper, making it harder to understand the technical contributions of the paper. I'll detail it below."
                },
                "questions": {
                    "value": "* In Eq. (1), (2) and (3), what are the definitions of \\texttt{relevance}, \\texttt{supplement} and \\texttt{verify}? If you follow Cumulative Reasoning (CR), are all these functions realised by the LLM?\n\n* In Sec. 3.3, what exactly is the memory? \n\n* What is the definition of \"state\" in this paper? Is it the number of \"invoked\" premises? \n\n* The results on CR on FOLIO in your paper are different from that in the original paper (on GPT-4), which is much higher (87.45 vs 69.11). Why such a large discrepancy?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1911/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698467303281,
            "cdate": 1698467303281,
            "tmdate": 1699636121739,
            "mdate": 1699636121739,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "w2GOshhkPf",
                "forum": "Sbi8BdKcob",
                "replyto": "s5MdIxEkgT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1911/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1911/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer aK68 (part I)"
                    },
                    "comment": {
                        "value": "We sincerely thank you for your constructive suggestions and valuable comments! We will answer the questions in detail and will appreciate very much if you could kindly raise your score if your concerns are addressed.\n\n\nQ: *technical contribution*\n\nA: Thanks for your constructive comments! We would like to clarify that considering the critical research question of augmenting the reasoning capabilities of LLMs, we were motivated by three important challenges in bridging the gap between LLM-based reasoning human reasoning. The proposed method provides a solution to this research question in terms of three key factors, which cannot be considered and achieved by baseline methods including CR. Our contributions can be summarized as follows: \n\n1) We propose to formulate the reasoning process as the transition from indeterminacy to determinacy, which is a novel perspective to describe the essence of solving reasoning tasks;\n\n2) We employ two-stage quantitative measurements (`relevance` and `supplement`) for premise selection and exploration, which can explore new insights by prioritizing given premises that are conducive to deriving conclusions;\n\n3) We introduce a reasoning memory module to automate storage and extraction of available premises and reasoning paths, ensuring the consideration of essential historical reasoning details during the iterative reasoning process.\n\nQ: *systematic premise identification*\n\nThe implementation of premise identification is to formulate detailed division rules through carefully designed instructions and demonstrations, which are available in revised Appendix. Compared with the identification results, the more important significance of this process is to enable the entire reasoning process to evolve from indeterminacy to determinacy.\nConsidering your valuable comments, we will remove the adjective \"systematic\" to avoid misunderstandings.\n\nQ: *the definitions of \\texttt{relevance}, \\texttt{supplement}*\n\nA: All these functions are implemented by instructing LLMs and the prompt templates are detailed in revised Appendix.\nWe would like to clarify that all three functions are innovations of DetermLR.\n\\texttt{relevance} and \\texttt{supplement} can prioritize better premises to explore new propositions, unlike randomly selecting premises in CR. \n\\texttt{verify} consider multi-aspect verification checks, whereas CR only includes a \"logical validity\" check.\n\nThe main prompts and examples are provided below for easier understanding.\n\n**relevance and supplement**\n\nPrompt:\n\n```\nPlease follow these steps:\n1.From the determinate premise, select the \"Most relevant premise\" which has the same subject with \"Hypothesis\", and give a score from 0 to 1.\n2.You need to assess how the \"Most relevant premise\" relates to all the other \"determinate premise\" and \"indeterminate premise\", based on Relevance scoring rules.\n3.The \"determinate premise\" and \"indeterminate premise\" with scores higher than 0.25 will be used as the final supplement results, along with Most relevant premise.\nRelevance scoring rules:\n1. When scoring relevance, 0.25 added for each noun or 0.25 added for each adjective that is the same between two sentences.\n2. Scores start to accumulate from 0 points, and the upper limit is 1 point.\n3. If sentence p1 is a hypothetical premise of sentence p2, then add 0.25 to p2. for example: measure \"if A then B.\" and \"A is true.\" Then add 0.25 points to \"if A then B\".\n```\n\nE.g.:\n\n```\nTarget: bear is nice and red (True/False/Unknown). \nDeterminate premises: \nd1) The bear is big. \nd2) Billy is rough. \nd2) The tiger is rough.\nIndeterminate premises: \ni1) If bear is big, then bear is red.\ni2) If someone is big, then they are nice.\n\n### After premise priority scoring: \nMost relevant premise $p*$: The bear is big.\nOther Premises:  \ni1) If bear is big, then bear is red.(0.75)\ni2) The tiger is rough.(0.0) \ni3) If someone is big, then they are nice.(0.5) \nd2) Billy is rough.(0.0)\nSupplementary premises *$\\mathbf{p}_s$*:\ni1) If bear is big, then bear is red.(0.75)\ni3) If someone is big, then they are nice.(0.5)\n\nSo the selected premises for exploration: The bear is big. If someone is big, then they are nice. If bear is big, then bear is red.\n\nNew proposition $\\widehat{p}$: The bear is nice and red.\n\nConclusion: True.\n```"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1911/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700291485294,
                "cdate": 1700291485294,
                "tmdate": 1700291485294,
                "mdate": 1700291485294,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yAq8j49Fo3",
                "forum": "Sbi8BdKcob",
                "replyto": "gFy6qXEVQO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1911/Reviewer_aK68"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1911/Reviewer_aK68"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for providing the rebuttal. It partially clarifies some of my questions, including those on the memory and the definitions of relevance, verify, etc. However, my major concerns for the paper, i.e. (1) the limited technical novelty & contribution and (2) the limited improvements over SOTA baselines, still stand. Therefore, I will maintain my original score."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1911/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700558906352,
                "cdate": 1700558906352,
                "tmdate": 1700558906352,
                "mdate": 1700558906352,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YPZvQbW3Ad",
            "forum": "Sbi8BdKcob",
            "replyto": "Sbi8BdKcob",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1911/Reviewer_KbK2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1911/Reviewer_KbK2"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new reasoning framework, DetermLR, aimed at enhancing the logical reasoning capabilities of large language models. The study addresses challenges of LLMs facing in emulating human-like reasoning, including selecting appropriate reasoning structures, efficiently using known information, and incorporating past reasoning into future decisions. DetermLR use premise identification, premise prioritization and exploration, and an iterative process with reasoning memory. Experimental results on logical reasoning tasks show that DetermLR outperforms baselines in terms of reasoning performance and efficiency."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This paper is well-motivated and proposes a novel framework that tackles the challenges in emulating human-like logical reasoning.\n- The method incorporates a prioritized strategy to direct the reasoning process; history reasoning information including valid and invalid intermediate results to continue reasoning, which are key components for effective reasoning.\n- The experimental results demonstrate the effectiveness and efficiency of the proposed framework compared to baseline methods."
                },
                "weaknesses": {
                    "value": "1. The paper lacks much necessary information about framework. \n- How do you score relevance and supplement? A transparent LM or directly instruct GPT-4? \n- From Fig.1 first step, the authors seem to filter out determinate premises by words matching (eg, the sentence including Gary). However, in some cases, the relationship between premises and conclusion is only logic-level. eg., If Erin is round, then Gary is quiet.\n- How do you exploit history reasoning paths information? \n\n\n2. [1] paper use a similar idea, alternating between premises selection and inference, despite of lackness of history reasoning paths. But the authors do not emphasis the point in details. In facts, I think those failure cases can help reduce search space.\n\n[1] Creswell, Antonia, Murray Shanahan, and Irina Higgins. \"Selection-inference: Exploiting large language models for interpretable logical reasoning.\" arXiv preprint arXiv:2205.09712 (2022)."
                },
                "questions": {
                    "value": "See weakness above. If the authors can perfectly solve my issues, I will consider improving my score."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1911/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698832669485,
            "cdate": 1698832669485,
            "tmdate": 1699636121652,
            "mdate": 1699636121652,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WEdM4aCmbF",
                "forum": "Sbi8BdKcob",
                "replyto": "YPZvQbW3Ad",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1911/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1911/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer KbK2 (part I)"
                    },
                    "comment": {
                        "value": "We sincerely thank you for your constructive suggestions and valuable comments! We will try our best to solve your issues and will appreciate very much if you could kindly raise your score if your concerns are addressed.\n\nQ: *lacks much necessary information about framework*\n\nA: Thanks for your reminding! We have reorganized the structure of Method Section. We add a Problem Formulation Subsection to provide more explanations and revise the notations to make the implementation easier to understand.\n\nQ: *how to score relevance and supplement*\n\nA: We implement the relevance and supplement scorer by prompting LLMs. We provide prompt templates and an example below for easier understanding.\n\nPrompt:\n```\nPlease follow these steps:\n1.From the determinate premise, select the \"Most relevant premise\" which has the same subject with \"Hypothesis\", and give a score from 0 to 1.\n2.You need to assess how the \"Most relevant premise\" relates to all the other \"determinate premise\" and \"indeterminate premise\", based on Relevance scoring rules.\n3.The \"determinate premise\" and \"indeterminate premise\" with scores higher than 0.25 will be used as the final supplement results, along with Most relevant premise.\nRelevance scoring rules:\n1. When scoring relevance, 0.25 added for each noun or 0.25 added for each adjective that is the same between two sentences.\n2. Scores start to accumulate from 0 points, and the upper limit is 1 point.\n3. If sentence p1 is a hypothetical premise of sentence p2, then add 0.25 to p2. for example: measure \"if A then B.\" and \"A is true.\" Then add 0.25 points to \"if A then B\".\n```\n\nE.g.:\n\n```\nTarget: bear is nice and red (True/False/Unknown). \nDeterminate premises: \nd1) The bear is big. \nd2) Billy is rough. \nd2) The tiger is rough.\nIndeterminate premises: \ni1) If bear is big, then bear is red.\ni2) If someone is big, then they are nice.\n\n### After premise priority scoring: \nMost relevant premise $p*$: The bear is big.\nOther Premises:  \ni1) If bear is big, then bear is red.(0.75)\ni2) The tiger is rough.(0.0) \ni3) If someone is big, then they are nice.(0.5) \nd2) Billy is rough.(0.0)\nSupplementary premises *$\\mathbf{p}_s$*:\ni1) If bear is big, then bear is red.(0.75)\ni3) If someone is big, then they are nice.(0.5)\n\nSo the selected premises for exploration: The bear is big. If someone is big, then they are nice. If bear is big, then bear is red.\n\nNew proposition $\\widehat{p}$: The bear is nice and red.\n\nConclusion: True.\n```\n\nQ: *how to filter out determinate premises*\n\nA: \n1) Determinate premises are defined as simple statements directly related to the target conclusion, requiring to instruct LLMs to understand the target rather than simply filtering it by word matching. Taking Case B in our paper as an example, the determinate premise is like \"Someone is male/female bachelor/PhD degree\", the partial solution to the problem.\n\n2) For your given example, the premise **If Erin is round, then Gary is quiet** (denoted as $i_7$) is identified as indeterminate premises since its \"if-then\" structure cannot directly derive new determinate facts without interacting with other premises. But different indeterminate premises also have different priorities for deriving conclusions, which is exactly the meaning of supplement scoring in the second part of our premise prioritization. Since the target revolves around \"Gary\" and \"round\", $i_7$ may have a higher supplementary score than other premises without \"Gary\", and is more likely to be used to generate new propositions to close to the target.\n\nQ: *how to exploit history reasoning paths information*\n\nA: The historical reasoning path is mainly used at the beginning of each reasoning iteration. We use memory extraction to merge the successful and failed reasoning steps of previous iterations.\n\nSuccessful reasoning step:\n\n`In the NO:x round, we use these \u201cpremises\u201d: \u201cIf something chases the cat then the cat chases the dog. The bald eagle chases the cat.\u201d and got a \u201cNew Determinate Premise\u201d: \u201cThe cat chases the dog.\u201d` \n\nFailed reasoning step:\n\n`In the NO:y round, we use this \"most relevant premise\": \"Bonnie is either a student who attends the school and is very engaged with school events, or she is not a student who attends the school and is not engaged with school events.\" and got a \"false Proposition\": \"Bonnie is either a student who attends the school and is very engaged with school events, or she is not a student who attends the school and is not engaged with school events.\"`"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1911/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700290427821,
                "cdate": 1700290427821,
                "tmdate": 1700290427821,
                "mdate": 1700290427821,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nEl4KPzbzW",
                "forum": "Sbi8BdKcob",
                "replyto": "YPZvQbW3Ad",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1911/Reviewer_KbK2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1911/Reviewer_KbK2"
                ],
                "content": {
                    "title": {
                        "value": "Re' Response to Reviewer KbK2"
                    },
                    "comment": {
                        "value": "Thank you for your time and efforts in providing the rebuttal. I appreciate the response to the framework details. For the comparison with SI, I cannot see substantial differences. Specifically,\n\n> We propose to formulate the reasoning process as the transition from indeterminacy to determinacy\n\nThe perspective is new. However, the reasoning process is pretty much similar.\n\n> We employ two-stage quantitative measurements (`relevance` and `supplement`) for premise selection and exploration\n\nThis part of the contribution is acknowledged.\n\n> We introduce a reasoning memory module to automate storage and extraction of available premises and reasoning paths\n\nThis is also a widely applied trick in many frameworks, such as langchain, babyAGI, etc.\n\nIn summary, I stand with my concerns on the incremental novelty of this work."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1911/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700722742988,
                "cdate": 1700722742988,
                "tmdate": 1700722759850,
                "mdate": 1700722759850,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lu896A0VeJ",
            "forum": "Sbi8BdKcob",
            "replyto": "Sbi8BdKcob",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1911/Reviewer_2L5z"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1911/Reviewer_2L5z"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new prompting technique for logic reasoning, DetermLR, which first classifies the given premises into determinate and indeterminate, and then sorts them by priority. Then DetermLR will first explore the premises with high priority and store the new conclusions into the memory for future reference. The proposed method shows superior results on LogiQA, ProofWriter, FOLIO, and LogicalDeduction, over multiple baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed method seems to be quite effective on four logic reasoning datasets, compared to multiple baselines.\n2. The paper is mostly clear and well-written."
                },
                "weaknesses": {
                    "value": "1. It is not clear how each module in the proposed framework is implemented. Such information is completely missing in the method section while judging from the experiment section, it seems that all of them are implemented by prompting GPT4. However, it is still unclear how the scorers are implemented and what is the threshold $\\theta$ for supplementary premises filtering.\n2. I'm not quite sure why the proposed method can select a reasoning structure. The main technique of the proposed method seems to be classifying the given premises into determinate and indeterminate, and sorting the premises by priority. It seems to adopt a mostly linear reasoning structure with memory reference.\n\nI'm willing to increase my score if my concerns are properly addressed."
                },
                "questions": {
                    "value": "1. How is the time/compute efficiency of the proposed method compared to the baselines? I understand that the proposed method visited fewer states during inference, but I'm not quite sure if the compute/number of GPT4 prompting for each state visiting is the same as the baselines."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1911/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699106021899,
            "cdate": 1699106021899,
            "tmdate": 1699636121568,
            "mdate": 1699636121568,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "adQwMikJf4",
                "forum": "Sbi8BdKcob",
                "replyto": "lu896A0VeJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1911/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1911/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 2L5z"
                    },
                    "comment": {
                        "value": "We sincerely thank you for your constructive suggestions and valuable comments! We will try our best tackle your concerns and will appreciate very much if you could kindly raise your score.\n\nQ: *how each module in the proposed framework is implemented, how the scorers are implemented and what is the threshold for supplementary premises filtering*\n\nA: Thanks for your reminding! \n1) The essential process of the proposed method including premise identification, premise prioritization, verification checking, and reasoning memory are all implemented by prompting LLMs with carefully designed instructions and demonstrations.\n\n2) For premise priority scoring, the prompt templates and examples are included as follows, with the threshold set to 0.25. More prompt templates are available in revised Appendix.\n\nPrompt:\n\n```\nPlease follow these steps:\n1.From the determinate premise, select the \"Most relevant premise\" which has the same subject with \"Hypothesis\", and give a score from 0 to 1.\n2.You need to assess how the \"Most relevant premise\" relates to all the other \"determinate premise\" and \"indeterminate premise\", based on Relevance scoring rules.\n3.The \"determinate premise\" and \"indeterminate premise\" with scores higher than 0.25 will be used as the final supplement results, along with Most relevant premise.\nRelevance scoring rules:\n1. When scoring relevance, 0.25 added for each noun or 0.25 added for each adjective that is the same between two sentences.\n2. Scores start to accumulate from 0 points, and the upper limit is 1 point.\n3. If sentence p1 is a hypothetical premise of sentence p2, then add 0.25 to p2. for example: measure \"if A then B.\" and \"A is true.\" Then add 0.25 points to \"if A then B\".\n```\n\nE.g.:\n\n```\nTarget: bear is nice and red (True/False/Unknown). \nDeterminate premises: \nd1) The bear is big. \nd2) Billy is rough. \nd2) The tiger is rough.\nIndeterminate premises: \ni1) If bear is big, then bear is red.\ni2) If someone is big, then they are nice.\n\n### After premise priority scoring: \nMost relevant premise $p*$: The bear is big.\nOther Premises:  \ni1) If bear is big, then bear is red.(0.75)\ni2) The tiger is rough.(0.0) \ni3) If someone is big, then they are nice.(0.5) \nd2) Billy is rough.(0.0)\nSupplementary premises *$\\mathbf{p}_s$*:\ni1) If bear is big, then bear is red.(0.75)\ni3) If someone is big, then they are nice.(0.5)\n\nSo the selected premises for exploration: The bear is big. If someone is big, then they are nice. If bear is big, then bear is red.\n\nNew proposition $\\widehat{p}$: The bear is nice and red.\n\nConclusion: True.\n```\n\nQ: *why the proposed method can select a reasoning structure*\n\nA: Thanks for your insightful comments!\nWe would like to clarify that we does not focus on pre-defining the reasoning structure, while the structure can be derived by reviewing the connections between the corresponding states of each reasoning iteration.\nPre-defining the reasoning structure before solving problems is quite different from the way of human reasoning. Humans actually do not preset a structure when facing a reasoning problem, while the so-called reasoning structure should be formed based on the reviewed reasoning results after solving the problem.\nOur experiments also show that compared to predefined thinking structures, the complexity of the reasoning structure reviewed by our method is more consistent with the problem difficulty itself.\n\nQ: *efficiency of the proposed method compared to the baselines*\n\nA: Thanks for your constructive suggestions! We have added complexity analysis for more detailed efficiency comparisons. We choose ToT [1] and CR [2] as baselines and randomly select 100 cases of FOLIO to compute the average inference time for each visited state.\nThe results below show that since our DetermLR can substantially save average states with slight increment on inference time per state, the overall inference efficiency of DetermLR is still better than ToT and CR.\n\n|Method|# states per case|Inference time per state|Inference time per case|\n|-|:-:|:-:|:-:|\n|ToT|18.40|7.77s|142.93s|\n|CR|14.51|6.86s|99.69s|\n|**DetermLR**|**7.69**|8.05s|**61.98s**|"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1911/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700289756952,
                "cdate": 1700289756952,
                "tmdate": 1700289756952,
                "mdate": 1700289756952,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vBSaxrFfy6",
            "forum": "Sbi8BdKcob",
            "replyto": "Sbi8BdKcob",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1911/Reviewer_96xE"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1911/Reviewer_96xE"
            ],
            "content": {
                "summary": {
                    "value": "They propose an approach for improving the logical reasoning of LLMs. Their approach is to structure the prompt with three main components including their so-called, premise identification, premise prioritization, and iterative process with reasoning memory.  They conduct experiments on four logical reasoning datasets using their prompting strategy. Their approach outperforms other recent strategies for prompting LLMs such as chain-of-though and some other variations."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "-The authors propose a new strategy for structuring the prompt for LLM to make them perform logical reasoning with a higher accuracy.\n-The experiments show the effectiveness of the proposed approach compared to the existing structured prompting strategies."
                },
                "weaknesses": {
                    "value": "-The terminology, notations, and in general the explanation of the proposed approach was not very clear to me. \n-The results focused on the selected subsets of datasets -selected by authors. No comparison with other results on these datasets [outside this work] was made. Or this was not made explicit at least in the paper as far as I understood.   \n-The results were reported only on GPT4.  \n\nSee some details in the Questions section."
                },
                "questions": {
                    "value": "-From the provided examples, it was not made clear to me why the term indeterminacy was chosen for some parts of the information.\n-in section 3.1., the authors explained the premise identification, and then only in section 3.2 they started introducing formal notations.\n-The formalization and notation are somewhat superficial and not really used to help understanding. \n-The flow of information and how these modules exactly work is not clear, are you expecting the LLM to do these steps with a few shots of in-context learning? For example, how the model was asked to identify the premises in the first step? These are just very hard to read from the current presentation of the paper. \n--Not clear what the authors mean by verification check? how the verification is performed, and what is the kind of computation used here for verification?\n--What do you mean by states and visited states? I did not see this defined in the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1911/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1911/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1911/Reviewer_96xE"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1911/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699326278246,
            "cdate": 1699326278246,
            "tmdate": 1699636121477,
            "mdate": 1699636121477,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bXyJXztfgN",
                "forum": "Sbi8BdKcob",
                "replyto": "vBSaxrFfy6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1911/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1911/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 96xE (part I)"
                    },
                    "comment": {
                        "value": "We sincerely thank you for your constructive suggestions and valuable comments! We will answer the questions in detail and will appreciate very much if you could kindly raise your score if your concerns are addressed.\n\nQ: *terminology, notations, and in general the explanation of the proposed approach*\n\nA: Thanks for your reminding!\nWe have reorganized the method section to make notations clearer and add more explanations in the revision.\n\nQ: *results in selected datasets*\n\nA: We would like to clarify that the test data used in our comparative experiments is mostly based on the official repositories without any further post-preprocessing [1-3], which is also the most common way of using these datasets. For LogiQA, since it contains different types of examination questions, non-logical reasoning like common sense reasoning is not our focus. In order to accurately evaluate the ability of LLMs to perform logical reasoning using only given conditions without relying on any external knowledge, we carefully reviewed LogiQA, excluded cases with unclear conditional expressions, and finally remained 179 high-quality questions as a curated collection. With our effort of data proofreading, the processed data will be released to the community to facilitate further studies.\n\nQ: *The results were reported only on GPT4.*\n\nA: Thanks for your valuable comments! We agree that it is indeed necessary to add more base models to further compare the effectiveness of the proposed method. \nWe plan to add GPT-3.5-turbo and LLaMA2 as engines for comparison. Currently we can provide the results of GPT-3.5-turbo on ProofWriter and FOLIO below, showing that all methods perform uniformly worse than GPT-4 (by about 0.1 accuracy). But DetermLR still outperforms all baselines on the same base model. We will complete these results and more discussions about the impact of base models soon in the future revision.\n|Method|ProofWriter|FOLIO|\n|-|:-:|:-:|\n|Standard|49.51|36.17|\n|CoT|54.41|45.00|\n|CoT-SC|57.34|48.67|\n|ToT|59.80|54.17|\n|CR|59.80|59.17|\n|DetermLR|**63.72**|**68.83**|\n\nQ: *why the term indeterminacy was chosen for some parts of the information*\n\nA: Thanks for your insightful comments! We will introduce in detail the necessity of the definitions of \"indeterminacy\" and \"determinancy\", and an example of the reasoning process from indeterminacy to determinancy.\n\n1) We introduce indeterminacy and determinancy to distinguish whether the information in a given premise is clear for deriving the conclusion. Only simple statements directly related to the conclusion are treated as determinate premises. So \"indeterminacy\" can indicate that those premises must be combined with other conditions to deduce new determinate information by removing the indeterminate structures (if-then, or).\n\n2) Taking Case B in our paper as an example, all original given premises are treated as indeterminate premises based on our definition. In this case, we just need to **further infer each original premise to obtain potentially determinate information**. From **\"$i_2$: The educational levels of A, B, and C are the same, while those of F and G are different\"**, we know that: **there are at least 4 people with education levels of A, B, and C.** Then we can derive a determinate premise: **\"$d_1$: A, B, and C are Bachelors.\"** based on the boundary condition: There are only 3 PhDs among the 7 people. Then more determinate premises can be deduced in the subsequent reasoning process. Therefore, it is consistent with our assumptions about the reasoning process: from indeterminacy to determinacy.\n\n\n[1] https://allenai.org/data/proofwriter\n\n[2] https://github.com/Yale-LILY/FOLIO\n\n[3] https://github.com/suzgunmirac/BIG-Bench-Hard/blob/main/bbh/logical_deduction_seven_objects.json"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1911/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700288494503,
                "cdate": 1700288494503,
                "tmdate": 1700288494503,
                "mdate": 1700288494503,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QMUuYlubwS",
                "forum": "Sbi8BdKcob",
                "replyto": "PHuXEyn2wp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1911/Reviewer_96xE"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1911/Reviewer_96xE"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for clarifying my questions.  This was helpful. However, the amount of missing details and the addition of new promised results as well as the conducted ones during rebuttal plus integrating all in the paper is a major revision. I think the paper needs a whole new version to be accepted."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1911/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675585313,
                "cdate": 1700675585313,
                "tmdate": 1700675585313,
                "mdate": 1700675585313,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]