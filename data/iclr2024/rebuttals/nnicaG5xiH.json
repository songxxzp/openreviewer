[
    {
        "title": "Interpretable Meta-Learning of Physical Systems"
    },
    {
        "review": {
            "id": "dPVoLkgxCr",
            "forum": "nnicaG5xiH",
            "replyto": "nnicaG5xiH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an approach CAMEL for the adaptation to new tasks by first learning a shared neural network feature extractor together with separate linear heads for each training task, then at test time perform least square regression to compute the linear head weights given a new task\u2019s labelled data. The authors show this formulation can allow physical parameters identification for linearly parameterized systems under certain conditions. Experimentally, the authors show that their approach can outperform meta-learning baseline methods (MAML, ANIL, CODA) in terms of generalization, computational speed, and interpretability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The interpretability and physical parameter identification aspects this paper focuses on are important and often overlooked by existing meta-learning methods."
                },
                "weaknesses": {
                    "value": "- **The proposed method lacks novelty and are not situated in the right context**. The authors claim to propose a novel \u201cmodel agnostic meta-learning architecture.\" However, the proposed approach is not model agnostic (because it requires specifying the width of the last layer dimension) and more importantly is not novel and not situated in the most relevant context.\n    - **Novelty**: It could be argued that the proposed method is not meta-learning but applying multi-task representation learning in a learning-to-learn problem. A more general version of the authors\u2019 proposed approach have been theoretically studied in terms of its generalization performance by Maurer et al  in 2016 (page 7, section 2.2 Bounding the Excess Risk for Learning-to-learn). More recently, Wang et al 2021 have proposed almost exactly the same approach by first multi-task learning a shared feature extractor with linear heads and then performing last linear layer fine-tuning over a new task\u2019s data at test time (section 3.4 Fine-tuning for Test Task Adaption). Besides, Wang et al has also studied the computational time savings of this MTL approach compared to last-layer MTL methods. Thus it is not correct for the authors to claim their methods as a novel approach.\n    - **Context**: In the background section, the authors situate their methods among Gradient-based Meta-learning methods. However as the authors have shown in Table 1, CAMEL doesn\u2019t perform gradient adaptation, so it\u2019s not a gradient-based method. Instead, because CAMEL adapts only the last layer of the learned model, a more appropriate way to situate the current method is to compare it among last-layer meta-learning methods, which includes not only ANIL (which the authors have compared against) but more importantly MetaOptNet (Lee et al 2019) and R2D2 (Bertinetto et al., 2019). Here both MetaOptNet and R2D2 solve the last linear layer exactly (using a convex solver or closed-form expression) and use implicit function theorem to propagate the gradients to the earlier feature extractors. Because this paper focuses on the regression task, the authors should compare additionally against R2D2 in the experiments. (One can think of R2D2 roughly as ANIL where the last layer adaptation are solved exactly instead of using a fixed number of gradient descent steps.)\n    \n    Maurer, A., Pontil, M., and Romera-Paredes, B. The bene\ufb01t of multitask representation learning. The Journal of Machine Learning Research, 2016.\n    \n    Wang, H., Zhao, H., & Li, B. Bridging multi-task learning and meta-learning: Towards efficient training and effective adaptation. In\u00a0International conference on machine learning, 2021\n    \n    Bertinetto, L., Henriques, J. F., Torr, P., and Vedaldi, A. Meta-learning with differentiable closed-form solvers. In International Conference on Learning Representations, 2019.\n    \n    Lee, K., Maji, S., Ravichandran, A., and Soatto, S. Metalearning with differentiable convex optimization. In CVPR, 2019\n    \n- **Notation needs to be more consistent and clearer.** For example, both $f_t(x; \\pi)$ (page 3) and $f_t(x)$ (page 4) are used. Besides, the ground truth function is denoted $v_{\\star}$. However, it has $n$ output dimensions, while the function $v$ has $r$ output dimensions.\n\n- **Proposition 1** are stated without all the assumptions of the relationships between $r$, $n$, $T$, and $N$ (some of these relationships are scattered in earlier parts of the paper), making the statement difficult to parse. Besides, the assumption that $c = c_{\\star} = 0$ to me seems a bit restrictive as the ground truth $c_{\\star}$ are inherent to the physical process and could be nonzero. However, I\u2019m not sure if the authors can make the same type of guarantees for the cases when these values are non-zero (and possibly unequal).\n- In the computational benefit section, the authors mention \u201cadaptation at test time \u2026 is guaranteed to converge if the number of samples is greater than $r$.\u201d This statement is a bit confusing, as the optimization is an ordinary least square which can be solved analytically without a notion of convergence. Maybe the authors mean to say when the number of samples is greater than $r$, the ordinary least squares is likely to be fully specified, thus admitting one unique solution. If this is the case, the authors should also discuss how to pick the solution when the ordinary least squares is underspecified."
                },
                "questions": {
                    "value": "- How many steps of gradient adaption is used for ANIL? It is important to note that one can apply more steps of adaptation during evaluation than training as it can potentially improve ANIL's performance.\n- Can the authors explain for example 1 and 4, what is the learning goal here? I saw the authors mention $x=(q, \\dot q, \\ddot q)$ and $y=u$, but can the authors explain why do we want to predict $u$ (which I'm assuming is a function of time) in the first place?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1935/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z",
                        "ICLR.cc/2024/Conference/Submission1935/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1935/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698722610862,
            "cdate": 1698722610862,
            "tmdate": 1700688885692,
            "mdate": 1700688885692,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TIVz5fos5z",
                "forum": "nnicaG5xiH",
                "replyto": "dPVoLkgxCr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Authors"
                ],
                "content": {
                    "title": {
                        "value": "We clarify the novelty of our work and we better situate it in the context of multi-task meta-learning"
                    },
                    "comment": {
                        "value": "We thank you for your time and dedication to this review.  We address each of your questions below.\n\nWe first address the main concerns regarding the novelty and the context of our approach. The rest of the questions is addressed in a second message, along with an additional experiment that we conducted for further comparison with existing work.\n\n## Novelty of our method\n\nWe agree that the representation learning architecture with a shared feature map and task-specific linear weights is not novel. We will make it clearer by better referencing (Caruana, 1997) and adding the references below. Our contribution demonstrates the effectiveness of this representation learning architecture in a challenging setting with very few tasks, each tasks containing a large number of points. This framework is motivated by the interpretable learning of physical systems. \n\nIn (Wang *et al.*, 2021), representation-based multi-task learning is compared with gradient-based meta-learning algorithms such as MAML and ANIL. As in our paper, both architectures are presented as methods for generalizing to new tasks, by minimizing a regularized multi-task loss function. This work theoretically demonstrates that representation learning can achieve performances comparable to those of meta-learning algorithms, within the limit of large neural networks. These theoretical conclusions are in line with the practical conclusions of our paper in the context of physical systems, which however have a different framework and scope.\n\nWhile the scope of these works is indeed similar to ours, we would like to point out some important differences. Our approach lies in the context of learning physical systems, where data collection is costly and computational resources can be limited. Typically, the number of training tasks is small (the number of tasks $T$ can be smaller than $4$ for example, as in our experiments), and the neural networks used are limited in width and depth to avoid overfitting. Consequently, the theoretical guarantees of (Maurer *et al.*, 2016), Theorem 2, and (Wang *et al.*, 2021), Theorem 1, where the number of tasks and the network depth tend to infinity, do not apply to our use cases. We also point out that we focus on regression tasks, while the experiments carried out in (Wang *et al.*, 2021) focus on classification. Furthermore, in the few-shot image classification experiments in the latter work, $T$ is very large ( $\\binom{5}{64} \\simeq 7.10^6$) and the number of training points per task is very small (typically smaller than 10), as opposed to our setting where $T$ is small and the number of training points $N_t$ is not restricted ($N_t$ of order 10000 for the training grid in the capacitor experiment).\n\nUnlike image classification, we show that the linear heads in the representation learning architecture can exploit the structure of the problem to provide a low-cost, high-performance algorithm for learning an interpretable physical model. In image classification, the algorithm has access to a very large database, which compensates for the lack of structure in the learning problem. In our submission, we show that, in a very different framework with less data and less compute, complex functions can still be learned efficiently with an interpretable model by exploiting the linear structure of the problem. Hence, like (Wang *et al.*, 2021), we demonstrate that representation learning can match more complex meta-learning architectures, but our study is carried out in a different setting, with different motivations and scope, and with the crucial benefit of identifying the underlying physical parameters.\n\n## Context\n\nWe thank you for the references and we will make sure to add them to the text body, and to better situate the context of our meta-learning algorithm.\n\nThe R2D2 algorithm indeed has in common with CAMEL the adaptation of the network head for each task. Using the formalism of our paper, R2D2 computes task specific weights $w_t = A(\\pi, D_t)$ with $A(\\pi, D_t)$ solving a Ridge regression of the $N_t$ points of $D_t$, for each training step and for each task. \n\nR2D2 should perform well for multi-task learning thanks to the complete resolution of the regression at each learning task. However, implementing it in our setting where $N_t$ is very large is not straightforward, as Ridge regression requires the inversion of a quadratic-sized system into the number of the features or of the regression points (which can be in the tens of thousands in our experiments as we mentioned above), hence adding a substantial amount of gradient computations. We have implemented this method and compared it to CAMEL in our experiments, and we report our results in a separate message."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700053982314,
                "cdate": 1700053982314,
                "tmdate": 1700053982314,
                "mdate": 1700053982314,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "t7tMQdpHyk",
                "forum": "nnicaG5xiH",
                "replyto": "dPVoLkgxCr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Authors"
                ],
                "content": {
                    "title": {
                        "value": "As the deadline approaches, are there any other questions that we can address?"
                    },
                    "comment": {
                        "value": "We would like to thank you once again for your insightful comments. We did our best to answer all of the questions in detail, especially the main concern regarding the novelty of our approach, for which  we also provided an additional experiment.\n\nAs the deadline for the author-reviewer discussion (Wednesday, November 22) approaches, please let us know if there are any additional questions or concerns that we can address."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700394460099,
                "cdate": 1700394460099,
                "tmdate": 1700394485221,
                "mdate": 1700394485221,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "T7HIYRfQqt",
                "forum": "nnicaG5xiH",
                "replyto": "XIAUtyP6nv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z"
                ],
                "content": {
                    "title": {
                        "value": "Response to author rebuttal"
                    },
                    "comment": {
                        "value": "I would like to thank the authors and Reviewers 3DG3 and rUF2 for their response. I provide response to the authors\u2019 points below:\n\n**Novelty**. I acknowledge the authors\u2019 discussion of the novelty of their method. If I understand correctly, the authors\u2019 stated contributions in the paper are 1) proposing CAMEL, 2) showing CAMEL is computationally more efficient than other meta-learning approaches (which require more gradient computation), 3) applying CAMEL to learning physical systems (which is not often discussed in meta-learning), 4) showing CAMEL can identify physical parameters for linearly parameterized systems, thus providing additional interpretability; 5) showing CAMEL is competitive with other approaches in terms of performance on the physics tasks. I do not question the novelty of points 3) - 5), but I still strongly believe that, given that Wang et al\u2019s method (description in 3.4 Fine-tuning for Test Task Adaption in their paper) is exactly the same as CAMEL (except it\u2019s experimentally tested on classification), it\u2019s not longer correct to claim any novelty by saying CAMEL \u201cis a new meta-learning architecture.\u201d Wang et al didn\u2019t give a new name to the method they studied and simply called it MTL (multi-task learning), so I believe the current paper\u2019s narrative of giving this old method a new name and claiming it as a new method is a bit unfair. Besides, the computation cost is also something that Wang et al has investigated. I can accept that applying MTL (CAMEL) to the physics setting can still be deemed novel for interpretability purposes, but I would like to see the authors give a concrete explanation as to whether/how they plan to change their narrative in the introduction of the method CAMEL.\n\n**Comparison against R2D2.** I find the authors\u2019 response on the R2D2 comparison satisfactory. I would strongly suggest the authors include the R2D2 experiment comparison in the main paper (if not comparing against it on every experiment). However, I believe the authors should emphasize more clearly their focus on a few number of training tasks and a large of number of examples. In addition, the fact that one has $N_t=60000$ for a single task doesn\u2019t necessarily mean one needs to adapt R2D2 to all of them in the inner loop during the meta-training stage. Instead, one can simply sample a small number of them as the support set and some others as the query set. However, during meta-test time, we can still perform last layer learning over all the available labeled data. (This approach is similar to the way we train MAML, we can only train with 1 or 5 inner steps during meta-training but perform $>10$ steps adapation during meta-testing.) Regardless of this comment above, I accept the authors\u2019 observation that R2D2 will take longer to meta-train, as a similar (not the same) comparison is performed by Wang et al in Table 4 between MTL and MetaOptNet.\n\n**Proposition 1 and Questions**. I accept the authors\u2019 explanation and answers. I recommend the authors provide the complete theorem statement and proof details for $c, c_{\\star} \\neq 0$ case in their revision.\n\n**Summary**. Overall, I\u2019m willing to consider increasing my score from 3 to 5 if the authors can convince me that they will change the paper\u2019s narrative on CAMEL (by acknowledging its lack of \u201cmethodology novelty\u201d) and sufficiently acknowledge prior work (instead of only finding details on how CAMEL differs from them)."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700621106121,
                "cdate": 1700621106121,
                "tmdate": 1700621106121,
                "mdate": 1700621106121,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mNWE8E5yZp",
                "forum": "nnicaG5xiH",
                "replyto": "9GJMjehB6I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_X11Z"
                ],
                "content": {
                    "title": {
                        "value": "Follow-up response"
                    },
                    "comment": {
                        "value": "I would like to thank the authors in their response and in changing the narrative of the paper. I also believe that it is acceptable to use CAMEL to more compactly and unambiguously refer to the practice of learning a linear head over a multi-task learned representation on a new task. Thus I have increased my rating from 3 to 5."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688869549,
                "cdate": 1700688869549,
                "tmdate": 1700688869549,
                "mdate": 1700688869549,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ocFyfzbbiU",
            "forum": "nnicaG5xiH",
            "replyto": "nnicaG5xiH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
            ],
            "content": {
                "summary": {
                    "value": "The paper investigates meta-learning physical systems via\nassociating every task with a linear embedding/task weight\nw that impacts the predictions: this is shown in equation 3.2\nwhere the prediction involves a global prediction\nfollowed by a modification from the linear part.\nAt test-time, the task weight of a new task is found\nby gradient descent on the task loss.\nSection 4 goes on to describe many settings where it is\nreasonable to have this linear part of the model,\nand prop 1 shows that the task weights can recover\nthe true dynamics of the system, which leads to the\nan interpretability of what the task weights are.\nThe experimental result show a number of settings\nfrom physics and reinforcement learning where\nthe method is able to learn better meta-dynamics models\nthan MAML, ANIL, and CoDA."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This is a reasonable model when there is some reason to believe\n   the true model follows the formulation of equation 3.2.\n   It could be interesting to further speculate about the\n   representation capacity or universality of this model.\n   (Section 4 is perhaps a good start to this)\n2. The experimental results clearly demonstrate the\n   capability of the model, especially in how well CAMEL\n   is able to attain a low identification error in Fig 2.\n3. CoDA is a great baseline method to compare against,\n   in addition to MAML/ANIL, and Table 1 clearly summarizes\n   the modeling differences."
                },
                "weaknesses": {
                    "value": "1. Every experimental meta-learning setting in this paper\n   seems to be newt\n   This would have been helpful to help better-ground the results\n   in the community, as otherwise it is difficult\n   to understand if the performance improvements are coming\n   from improper implementations of other methods\n   or from a fundamental modeling advancement.\n   For example, MAML with a training step size of 30 and\n   adaptation size of 10 in Table 2 is very arbitrary and\n   unlikely to be the best MAML hyper-parameters here.\n\n   The paper would be significantly more convincing\n   if the CAMEL model was evaluated in the exact experimental settings\n   from CoDA or [Wang et al., NeurIPS 2022](https://arxiv.org/abs/2102.10271),\n   which also meta-learn physical systems with varying amounts of\n   contextual information.\n2. There is a significant amount of omitted related work on\n   meta-reinforcement learning that is also adapting controlled\n   MDP dynamics and policies to multi-task RL settings,\n   e.g., [Nagabandi et al., ICLR 2019](https://arxiv.org/abs/1803.11347)\n   and the citation graph around it.\n3. The term \"interpretable meta-learning\" in the title and\n   throughout the rest of the paper is a big statement without\n   the right qualifications. The paper gets to defining what\n   interpretability means here in proposition 1 of recovering\n   true parameters when they exist and fit into the modeling\n   structure they have set up, but I this is not what I had\n   in mind when I first saw the term \"interpretability\".\n   It also seems like there is still a large amount of\n   uninterpretability in the system, as the model in\n   equation 3.2 still has 2 neural networks."
                },
                "questions": {
                    "value": "Overall I think this is a well-executed paper with some\ngood modeling ideas and experimental insights.\nI gave the paper a weak reject due to the experimental settings\nnot being directly comparable to the related work and the\nbaselines not being tuned as much as they could have been,\nand I am especially open to re-evaluating this assessment\nafter hearing the author's perspective on this."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1935/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1935/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1935/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698812950335,
            "cdate": 1698812950335,
            "tmdate": 1700153968196,
            "mdate": 1700153968196,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YvcornBqPt",
                "forum": "nnicaG5xiH",
                "replyto": "ocFyfzbbiU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Authors"
                ],
                "content": {
                    "title": {
                        "value": "About the experimental comparison of the paper, new experiment to check the validity of the trained baselines"
                    },
                    "comment": {
                        "value": "Thank you for your insightful review. We address each of your questions below. We provide an additional experiment serving as a sanity check for our choice of hyperparameters for the baselines. Our comments are divided into several posts because of the character limitations.\n\n## 1. Experimental comparison\n\n### Experimental setting\n\nIn our paper, we have compared CAMEL with a number of baselines, including gradient-based meta-learning algorithms MAML and ANIL and the multi-environment context-informed network CoDA. \nWe agree that our experimental conditions are not exactly the same as those of (Wang *et al.*, 2022) and (Kirchmeyer *et al.*, 2022). This is because **we do not address the same learning problem**. These papers focus on the problem of learning a function $f_\\star$ representing a dynamical system by fitting the trajectories of the system. As a consequence, the training loss function is expressed in terms of the trajectory obtained by integration of the model, typically using Neural ODEs (Chen *et al.*, 2018). Although trajectory prediction is very rich and interesting, the trajectory integration step adds up a layer of complexity to the multi-task learning problem.\n\nWe, on the other hand, chose to focus on the more fundamental problem where $f_\\star$ is learned by regression. This is not only motivated by the fact that many physical systems are static (for example, the electrostatic field falls within this category, and could not be learned with a trajectory prediction approach), it is also the most general and natural framework for assessing the learning performances (including its expressivity and its computational cost) of a given architecture for learning a target function $f_\\star$, regardless of the additional problem of integrating the dynamics into a trajectory.\n\nTherefore, we decided to run independent experiments on a number of systems representing various settings of regression, for which we compared our approach as fairly as possible to the other existing architecture, which we have reimplemented for static regression and carefully tuned. As we point out in the conclusion (Section 7), CAMEL can be extended to the setting of trajectory prediction for which identification of the physical parameters is also an important question. We are currently working on this extension and the results should be ready within weeks, in which case we can add them to an updated version of the paper.\n\n\n### Choice of hyperparameters\n\nWhile we agree that comparing algorithms on different initial conditions may induce a bias related to the choice of hyperparameters, we would like to make it clear that we have conducted our experiments as fairly as possible. Hyperparameters such as the learning rates have been chosen on a test set in such a way as to give the best possible performance, for all architectures. \n\n\n**Additional experiment**\n\n\n We present a new in-domain evaluation experiment showing that our choice of hyperparameters give similar performances for MAML and CAMEL in in-domain evaluation. The algorithms trained on multi-task data are evaluated **not on a new out-of-domain task, but on the training tasks**, albeit with different data points from the training set. \n\nEvaluation mean squared error\n|experiment|in-domain |out-of-domain (results presented in the submission)|\n|---|---|---|\n|MAML |8.1e-5 \u00b1 2e-5|1.6e-1 \u00b1 5e-2|\n|CAMEL|3.2e-5 \u00b1 1e-5|1.0e-4 \u00b1 5e-5|\n\n\nThis experiment demonstrates that in a case more favorable to MAML's meta-learning, its performance is much closer to that of CAMEL and CoDA.\n\n\nWe would also like to point out that the quantities reported on the right in Table 2 are not gradient step sizes, they are computation times, for training and during inference (a step size of order 30 or 10 would indeed be probably bad)."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700054406693,
                "cdate": 1700054406693,
                "tmdate": 1700054406693,
                "mdate": 1700054406693,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qcUW6pfkFB",
                "forum": "nnicaG5xiH",
                "replyto": "ZN3MXjL0sf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response! Here are some of my quick initial thoughts to it:\n\n# Comparison with [Wang et al.](https://arxiv.org/pdf/2102.10271.pdf) (DyAd)\n\n>  This is because we do not address the same learning problem [...]  As a consequence, the training loss function is expressed in terms of the trajectory obtained by integration of the model,  typically using Neural ODEs (Chen et al., 2018). [...] We, on the other hand, chose to focus on the more fundamental problem where  is learned by regression.\n\nDyAd still seems more related than your response makes it seem. For example, as a first step it seems extremely easy to modify DyAd's model (and nothing else) to be linear in the context rather than the current non-linear architecture they have. If this is true, then evaluating this model comparison on exactly their experimental setup would be an extremely insightful ablation.\n\nAlso, DyAd does /not/ integrate an ODE (their model also discretizes time) and they also learn by regression --- section 2.2 of their paper describes their full setup.\n\nI agree DyAd assumes knowledge of the contextual information and that another dimension of your approach is to learn the contextual information. This is an important difference. If the linear-context model works in their setting, it again could be very insightful to see how well you're able to recover the known contextual information from DyAd's setting if you assume it's not given.\n\n# Comparison with [Kirchmeyer et al.](https://arxiv.org/pdf/2202.01889.pdf) (CoDA)\n\n>  This is because we do not address the same learning problem [...]  As a consequence, the training loss function is expressed in terms of the trajectory obtained by integration of the model,  typically using Neural ODEs (Chen et al., 2018). [...] We, on the other hand, chose to focus on the more fundamental problem where  is learned by regression.\n\nI copy-pasted this again because I am not sure what you are referring to that integrates the ODE and does not do learning with regression. CoDA does /not/ integrate an ODE (their model also discretizes time) and they also learn by regression.\n\n\n# Hyper-parameters\n\n> We would also like to point out that the quantities reported on the right in Table 2 are not gradient step sizes, they are computation times\n\nWhat units are those times in? I assumed they were adaptation sizes because their values are just (1, 2, 10, and 30) with labels saying \"training\" and \"validation\"\n\n> While we agree that comparing algorithms on different initial conditions may induce a bias related to the choice of hyperparameters, we would like to make it clear that we have conducted our experiments as fairly as possible. Hyperparameters such as the learning rates have been chosen on a test set in such a way as to give the best possible performance, for all architectures.\n\nDid you also tune the gradient steps for training/validation? I noticed in another response you said:\n\n> We have omitted this experimental detail in our submission and will add it in the updated version. The number of inner gradient steps for training MAML and ANIL is equal to 1, in order to save computational time.\n\nIt is widely-known that 1 gradient step for MAML/ANIL is not optimal. [This paper](https://arxiv.org/abs/1810.09502), for example, shows that a schedule over gradient steps during training is ideal. This still makes me believe the baselines are under-performing on these non-standard setups."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700065818489,
                "cdate": 1700065818489,
                "tmdate": 1700065818489,
                "mdate": 1700065818489,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vuqyDXtSbW",
                "forum": "nnicaG5xiH",
                "replyto": "qcUW6pfkFB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ],
                "content": {
                    "title": {
                        "value": "On modeling forward dynamics vs inverse dynamics"
                    },
                    "comment": {
                        "value": "Is there a reason why you decided to focus on inverse dynamics rather than the forward dynamics? It seems like the linear-context model could also be applied for the prediction of forward dynamics and compared to the other meta-learning approaches there."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700065928914,
                "cdate": 1700065928914,
                "tmdate": 1700065928914,
                "mdate": 1700065928914,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UrMqNhP4f1",
                "forum": "nnicaG5xiH",
                "replyto": "l9e643nYga",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for all of those clarifications! I am still positive on the paper and have updated my score from a 5 to a 6 (marginal accept) as these clarifications help me understand the difficulties of directly comparing to related work. The physical systems considered in this paper are nice new experimental settings for the meta-learning community to be thinking about. My hesitation in the paper is still due to there being no direct comparisons to existing closely-related meta-learning settings, such as the DyAd ones (which you understood my point correctly). This would be extremely convincing, and I would be willing to further increase my score with this.\n\n> On the MAML hyper-parameters/step sizes\n\nThanks for the clarifications and more experimental details here too. Maybe I should have better-clarified earlier -- I'm also still in agreement with you all that even if MAML is well-tuned, the generalization performance should never be as great as a method like yours which is able to recover a more structured model such as yours that is closely related/identical to how the ground-truth system is structured."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700154866787,
                "cdate": 1700154866787,
                "tmdate": 1700154866787,
                "mdate": 1700154866787,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BfdHNMy9Xl",
                "forum": "nnicaG5xiH",
                "replyto": "n3gqD8wBiT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_3DG3"
                ],
                "content": {
                    "title": {
                        "value": "My quick thoughts here"
                    },
                    "comment": {
                        "value": "I agree with the original review that the novelty of the work is important for the paper to discuss, especially w.r.t. Wang et al. and R2D2 as they also consider linear heads. The original submission is clearly lacking without references to these, and I also agree with this reviewer's comment that the approach is /not/ model agnostic.\n\nThe author's response here seems reasonable and would address these issues if included in the final version of the paper. My initial impression is to agree with the authors that their methodology and experimental settings are still sufficiently different that there is still value in their contribution. And, the new R2D2 comparison with the timing results is interesting and helps connect to these topics.\n\nAs I stated in my review thread, I still think the paper is lacking an experimental comparison to existing published results --- if the approach is computationally faster than R2D2 in the settings above, maybe it's also worth comparing to R2D2 (or Wang et al./MetaOptNet) on their experimental settings too."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700156230701,
                "cdate": 1700156230701,
                "tmdate": 1700156230701,
                "mdate": 1700156230701,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Skunu13TWU",
            "forum": "nnicaG5xiH",
            "replyto": "nnicaG5xiH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1935/Reviewer_rUF2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1935/Reviewer_rUF2"
            ],
            "content": {
                "summary": {
                    "value": "This article presents a new meta-learning method, CAMEL, which uses affine task-specific parameters. It is motivated by the application of modelling physical systems, many of which are described in the article. CAMEL is demonstrated on these modelling examples and a robotic control task, with comparisons to state-of-the-art meta-learning methods MAML, ANIL, and CoDA. The interpretability of the method as a means of discover physical parameters is discussed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The article is well-motivated and well-written. Both the motivation towards interpretable data-driven modelling of physical systems, and the motivation of simplifying meta-learning approaches like MAML, are well justified.\n\nThe proposed CAMEL method appears to be a simple but effective method for meta-learning. The overview of meta-learning approaches, comparing MAML, CoDA, and CAMEL, in section 2.2 provides a useful overview of the different methods. The use of different $w_t$ vectors for different environments is motivated in the text and suitable for physical applications, especially as $w_t$ can be learned used least squares.\n\nThe experimental evaluation of CAMEL is convincing, with a number of different physical modelling systems used for demonstration. CAMEL appears to match or outperform other meta-learning approaches on all tasks, although further details could improve the experimental evaluation (as detailed below). The code is provided and is simple to understand, using PyTorch for single-file implementations of CoDA, MAML/ANIL, and CAMEL."
                },
                "weaknesses": {
                    "value": "The experimental results rely heavily on Table 2, however the experimental conditions for these results are not made clear. Specifically, the training details for MAML, ANIL, CoDA, and CAMEL are not fully detailed. The \"Training\" and \"Adaptation\" columns are not described, nor are their units present. The caption states that the table presents the \"Average adaptation mean squared error and computational time,\" but the number of trials over which an average is taken, the standard deviation, the units of computational time, and how computational time was measured are not given. Statistical tests on the significance of values presented in Table 2 would be helpful.\n\nThe argument that CAMEL is an interpretable method relies on the idea that the weight vector $w_t$ learned on the training meta-dataset can correspond to physical parameters of a system. This is explained in Proposition 1, which assumes that the training loss is taken to 0. The authors do point out that identifying the meaning of each parameter, in other words, interpreting the parameters, is out of reach for black-box meta-learning architectures. However, the argument that CAMEL allows for such interpretation is not sufficiently demonstrated in my opinion. The example of learning an electric point charge system is given in section 5.1 and expanded in section B.5, however it relies heavily on the fact that CAMEL is able to learn the dynamics of the system, and not on the interpretability of the resultant parameters. Demonstrating how the learned physical parameters allow for an interpretation of the model and physical system, beyond the performance of CAMEL, would help make this argument. Physics informed neural networks (PINNs) share the same motivation and have been used to present interpretable results; their inclusion in this section and discussion would further improve the interpretability argument. \n\nLastly, the authors appear to only study the case in which $c = c_* = 0$. This is a large simplification. If Equation 3.1 is valid, I believe this means that $h(x;\\theta_0) = 0$, which is quite a departure from other meta-learning methods. If this is the case, the authors should further justify it and potentially explore the case where $c \\neq 0$. If it is not the case, then clarification is needed in section 4.3 as to when this simplification is made.\n\nWhile the article is well-written, it suffers from two minor presentation weaknesses. The first is a reliance on popularity as justification; the popularity of a method does not justify its use. The sentence \"Given the popularity and expressiveness of neural networks, incorporating multi-task learning into their gradient descent training algorithms is a major challenge\" (2.2) is an example. The challenge of multi-task learning is not dependent on the popularity of neural networks, so why is it used as an opening clause? The second formatting issue is minor: works are cited in text when they should be cited in parentheses (although there are also proper uses of in-text citations). See, for example, this paragraph in section 4, where the Ljung citation is correct but the Nelles citation isn't:\n\"System identification and model identifiability are key issues when learning a system (Ljung, 1998). Although deep neural networks are becoming increasingly popular for modeling physical systems, their complex structure makes them impractical for parameter identification in general Nelles (2001).\""
                },
                "questions": {
                    "value": "How many trials were used to compute the averages in Table 2?\n\nWhat do the \"Training\" and \"Adaptation\" columns correspond to in Table 2?\n\nHow many gradient steps were used in the various benchmarks?\n\nWere the hyperparameters of the Adam optimizer the same for all benchmarks?\n\nCould common physical parameters be learned in $v_*(x)$? What guarantees that $v_*(x)$ is task-agnostic?\n\nDo the authors consider that their experimental results validate the hypothesis of equation 3.1?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1935/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698847177800,
            "cdate": 1698847177800,
            "tmdate": 1699636124364,
            "mdate": 1699636124364,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wFRK3cWY2q",
                "forum": "nnicaG5xiH",
                "replyto": "Skunu13TWU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answering to the issues pointed out in the \"weaknesses\" section"
                    },
                    "comment": {
                        "value": "Thank you for your time and thoughtful review. We address your comments below. Our answer is separated into several posts because of the character limitation.\n\n## Table 2\n\nOur experimental results indeed lack some details. The number of experimental trials for evaluation is mentioned in the text body for Section 5.1 and in B.1.2 for the capacitor, but we have omitted to specify it for the other experiments. The standard deviations are reported in Table 3, in Appendix B.4. We shall update this section with the number of trials, and also report the latter in the legend Table 2. Regarding the computational time, we shall include additional details regarding the protocol that we used and the statistics of the measured time. Once measured and averaged, the unit was chosen arbitrarily as the lowest measured time (in this case, that of CAMEL) for a clearer comparison. The time for training CAMEL for 10000 gradient steps on a single CPU in the capacitor experiment was typically of the order of the minute.\n\n## Interpretability \n\nIn the case of the point charge system, we demonstrate the interpretability of the learned parameter by computing the identification error, *i.e.* by showing how close to the physical parameters (in this case the electric charges) the learned parameters are, which relies on CAMEL's ability to learn the system. We would like to point out that we further demonstrate the interpretability of the learned model on two major and novel applications. \n\nFirstly, the interpretation of the learned contexts allows for a zero-shot adaptation scenario (in the last paragraph of Section 4.), where the adapted model uses information about the physical parameters rather than measurements of the target function. This application is presented in both the charge experiment and in the capacitor experiment.\n\nSecondly, for robotic systems, the interpretability of the learned task parameters allows for the identification of the robot's inertial parameters, which is valuable in adaptive control. This is illustrated in Section 5.2.\n\nWe will make sure to mention physics informed neural networks (Raissi *et al.*, 2019), for which interpretability is ensured by learning the solution of a PDE, while enforcing the physical constraints directly in the loss function. \n\n\n## Proposition 1\n\nRegarding the case where $c, c_\\star \\neq 0$, it can be handled by augmenting  $\\varphi$ and $v_{\\star}$, and $w$ and $v_\\star$ with an additional dimension, with the corresponding component of $v$ and $v_\\star$ equal to $1$. The conclusion of Proposition 1 then applies wit the assumption of $\\{v_\\star(x^{(i)})\\}$ spanning $\\mathbb{R}^{n+1}$. Hence, the augmented physical parameters can be recovered up to a linear transform, meaning that $\\varphi$ can be recovered with an affine transform. We have tackled the interpretability in the case $c, c_\\star \\neq 0$ experimentally in the capacitor system, where $c_\\star$ is non zero a fortiori because the electrostatic field is linearized around a nonzero value, as is pointed out in the review. \n\nWe will clarify this explanation in a revised version of the submission.\n\n## Presentation issues\nWe thank you for pointing out these two presentation weaknesses. We will correct them in an updated version of the submission."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700054644547,
                "cdate": 1700054644547,
                "tmdate": 1700054644547,
                "mdate": 1700054644547,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XIAUtyP6nv",
                "forum": "nnicaG5xiH",
                "replyto": "n3gqD8wBiT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_rUF2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1935/Reviewer_rUF2"
                ],
                "content": {
                    "title": {
                        "value": "Comments from reviewer rUF2"
                    },
                    "comment": {
                        "value": "I appreciate the points brought up by Reviewer X11Z, especially the comparison to Wang et al. and Bertinetto et al. In my opinion, the author's response takes these points into account and responds appropriately. The inclusion of an experimental comparison to these works will strengthen the article and improve its novelty. When assessing novelty, I also believe that the application case to physical modelling should be considered, as Wang et al. and Bertinetto et al. both consider image classification tasks."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1935/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700474454660,
                "cdate": 1700474454660,
                "tmdate": 1700474454660,
                "mdate": 1700474454660,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]