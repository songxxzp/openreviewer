[
    {
        "title": "Graph-based Virtual Sensing from Sparse and Partial Multivariate Observations"
    },
    {
        "review": {
            "id": "PPLseI8SNX",
            "forum": "CAqdG2dy5s",
            "replyto": "CAqdG2dy5s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8051/Reviewer_MbBb"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8051/Reviewer_MbBb"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to address the data sparsity problem by using multivariate data. The authors proposed a model GgNet which can leverage the correlations/dependencies between the target variable/channel and the covariates to reconstruct the target values at certain locations. Extensive experiments are conducted."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is well-presented and well-organized.\n2. The paper proposed a new model GgNet aiming to reconstruct the target values at certain locations.\n3. Extensive experiments are conducted to validate the proposed model, and the results seem promising."
                },
                "weaknesses": {
                    "value": "1. This paper has a lot of assumptions, for example, it assumes the covariates are always available, and the mutual dependencies between target and covariates are invariant and can be leveraged at all locations. Here are some concerns: we cannot guarantee that those assumptions hold for all cases (at least, there should be more examples or references to support them), and if they do not hold, does the proposed method still work?\n2. It seems the method requires the latent representations of locations where the target values need to be reconstructed are close, so is it possible to deal with the cases where the latent representations of locations are remote?\n3. The model somewhat lacks novelty, it seems the final model just combines several existing models."
                },
                "questions": {
                    "value": "Please address the questions above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8051/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698276855064,
            "cdate": 1698276855064,
            "tmdate": 1699636995160,
            "mdate": 1699636995160,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JB3ipmIPWx",
                "forum": "CAqdG2dy5s",
                "replyto": "PPLseI8SNX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8051/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8051/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the constructive review and feedback.\nAs for the raised concerns and questions, individual points are addressed below.\n\n\n**W1. Paper's assumptions**\\\nPlease allow us to clarify a possible misunderstanding. Our assumptions are only those dictated by the task which our method has been specifically designed to solve. In particular, for what concerns the availability of covariates, at least some of these are needed for the task to make sense, otherwise, no reconstruction would be possible in sparse settings. \nFurthermore, note that we do *not* require all covariates to be available at all locations. On the contrary, as shown in Fig.1, covariates can be partially missing at any location.\nClearly, the quality of the reconstruction will depend on the amount of relevant information available to condition the virtual sensing model.\nWe would like to point out that the covariate availability assumption is not a weakness of our proposed approach, but a hard requirement of the addressed sparse virtual sensing task. In general, this corresponds to the necessity of all ML models to condition inference on observations.\n\nThen, similarly to the previous point, assuming a mutual dependency between the target and covariates is a requirement imposed by the task. If this cannot be leveraged at the target location, it is not possible to perform any inference in a sparse setting.\n\nFinally, assuming synchronous observations and overlapping time frames among sensors is necessary to exploit the spatial dimension. \nAlthough the synchronicity assumption could be alleviated to some extent, we consider this aspect orthogonal to those we deal with in the present paper and mention this direction as a possible future work.\n\n\n\n**W2. Far-apart latent representation of locations**\\\nIn our framework, far-apart representations in the latent space can, potentially, translate into widely different observed dynamics. In the transductive setting, the masking strategy still brings supervision for training locations with isolated representations. However, in general, if no available observed location is at all similar to the target one, there may be no guarantee of the accuracy of the reconstruction. This is due to the intrinsic limits of any data-driven method used to extrapolate beyond the training conditions.\n\n\n\n**W3. Discussion on the paper's novelty**\\\nThe focus of the paper is not on introducing new layers or new neural operators. \nInstead, we are the first to explore (multivariate) virtual sensing for sparse settings, which is relevant in many practical applications.\nMost importantly, we introduce a conceptualization and propose a methodology to address the general problem, which goes far beyond the possible specific implementations. Nevertheless, we also propose a possible implementation (GgNet) of such a methodology, which utilizes an original nested graph representation for effectively modeling dependencies in such a context.\nWe finally provide experimental evidence of how the proposed model can overcome the limitations of previous approaches. \nWe believe these claims are significant and contribute to advancing the field in a meaningful way.\nWe refer the reviewer to the introduction of the paper where our core novel contributions are explicitly stated. After the revision, we have added references to the section supporting each claim.\nWe hope this clarifies any doubts regarding the novelty aspect of the paper; if not, we would deeply appreciate any further comment.\n\nWe hope to have clarified all of the reviewer\u2019s concerns and are happy to provide further details."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8051/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700188222446,
                "cdate": 1700188222446,
                "tmdate": 1700188222446,
                "mdate": 1700188222446,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MUJKKYtfb7",
                "forum": "CAqdG2dy5s",
                "replyto": "JB3ipmIPWx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8051/Reviewer_MbBb"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8051/Reviewer_MbBb"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the reply! Most of my concerns have been addressed."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8051/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665354057,
                "cdate": 1700665354057,
                "tmdate": 1700665354057,
                "mdate": 1700665354057,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1w2AqSiD5I",
            "forum": "CAqdG2dy5s",
            "replyto": "CAqdG2dy5s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8051/Reviewer_cynR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8051/Reviewer_cynR"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a novel framework for virtual sensing of missing multivariate spatio-temporal data in settings with limited sensor coverage. The authors introduce GgNet, a deep learning architecture capable of leveraging inter-location dependencies and relationships between covariates for accurate data reconstruction. \nThe contributions of the paper include: \n\u2022\tThe introduction of a novel deep learning architecture designed for multivariate virtual sensing tasks, particularly in sparse scenarios. \n\u2022\tNested Graph Structure: GgNet employs a nested graph structure to capture both spatial relationships between locations and dependencies between covariates, learning them end-to-end for improved reconstruction accuracy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "\u2022\tThe problem formulation of multivariate virtual sensing in sparse scenarios is itself an original and significant contribution, as it addresses a practical challenge across various domains. The introduction of GgNet leverages a nested graph structure to capture dependencies between covariates and relations across locations, is highly original. The combination of graph-based modeling and deep learning techniques to address the problem is innovative and distinguishes this work from prior methods in the field. \n\u2022\tThe technical content, methodology, and experimental design are well-supported with empirical evidence. The thoroughness of the experimental evaluation, conducted across multiple datasets, with different degrees of sparsity and temporal resolutions, enhances the paper's quality. The extensive experimentation, use of real-world datasets, and evaluation further emphasize the paper's significance."
                },
                "weaknesses": {
                    "value": "\u2022\tThe paper, while generally well-structured, could benefit from more explicit and detailed explanations in certain technical aspects. For instance, the paper could provide a more comprehensive explanation of the nested graph structure used in GgNet, which is a key component of the proposed method."
                },
                "questions": {
                    "value": "\u2022\tThe paper mentions the computational time for GgNet and other baselines but does not discuss scalability. How does GgNet's performance scale with more extensive sensor networks or larger datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8051/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698704366334,
            "cdate": 1698704366334,
            "tmdate": 1699636995044,
            "mdate": 1699636995044,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cdXhb2Rg5g",
                "forum": "CAqdG2dy5s",
                "replyto": "1w2AqSiD5I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8051/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8051/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the review and positive feedback.\nAs for the raised concerns and questions, individual points are addressed below.\n\n\n**W1. More detailed explanations in certain technical aspects**\\\nWe understand that there are several important technical details that were deferred to the appendix (in particular, in Appendix B). However, due to space constraints, we preferred to allocate more space to the conceptualization of the problem and to the methodological aspects that are the main paper contributions.\n\n\n\n**Q1. Discussion on scalability**\\\nScalability is discussed in Appendix E.1. The computational complexity of GgNet originates from the sum of the complexities of its components.\nThe time and space complexity are both $\\mathcal O(N^2TD) + \\mathcal O(NTD^2)$.\nAs it is often safe to assume that $D^2 \\ll N^2$, the overall complexity reduces to $\\mathcal O(N^2TD)$.\nIf scalability to large N is found to be a concern, existing sparse graph learning alternative methods, e.g., [1], can be integrated into the approach.\nWe thank the reviewer for the question and have expanded the discussion on scalability in Appendix E.1 of the revision.\n\nWe hope to have clarified all of the reviewer\u2019s concerns and are happy to provide further details.\n\n**References:**\\\n[1] Niculae et al., Discrete latent structure in neural networks. arXiv preprint arXiv:2301.07473, 2023."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8051/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700187859237,
                "cdate": 1700187859237,
                "tmdate": 1700187859237,
                "mdate": 1700187859237,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jjNP7ABgGq",
            "forum": "CAqdG2dy5s",
            "replyto": "CAqdG2dy5s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8051/Reviewer_L9oj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8051/Reviewer_L9oj"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors presented a novel graph-based framework for virtual sensing from sparse multivariate spatio-temporal observations, called GgNet. They leveraged a nested graph structure to account for dependencies between covariates and relations across locations and learned end-to-end to maximize reconstruction accuracy. The GgNet achieves superior performance in settings with poor sensor coverage, where other state of the art fail, and contributes to the methodological advancement of the field as well as a powerful tool in practical applications."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "\u2460\tThe GgNet proposed in the article effectively addresses the limitations of traditional methods in the context of sparse sensor coverage by inferring signal values at unmonitored locations through learning dependencies between variables and positions.\n\u2461\tThe article provides numerous details in the appendices to help readers gain a more comprehensive understanding of the framework. For instance, Appendix B and C offered a detailed description of the experimental settings and baseline parameter details.\n\u2462\tThe author employed effective training method. They masked an additional small fraction of data points, at random, in the training channels, which can enforce robustness to random missing value.\n\u2463\tThe experimental baseline selection is quite comprehensive and reasonable, including KNN, BRITS, SAITS, and GRIN, along with various progressively more advanced recurrent RNN. These choices in baselines contribute to a more comprehensive and reliable set of experimental results."
                },
                "weaknesses": {
                    "value": "\u2460\tThis article lacks a thorough analysis of the experimental results and a comprehensive interpretation of the data. It primarily presents the experimental outcomes in tables without providing detailed explanations.\n\u2461\tThe article did not include an overview diagram of the overall model structure, which made it difficult for readers to comprehend the architecture of the model.\n\u2462\tThe experiment evaluated accuracy-related metrics such as MAE and MRE but did not provide information on the computation time and performance on large datasets. As a result, readers cannot assess the efficiency of this model.\n\u2463\tThe experimental training methods have the potential to enhance the robustness of the network, but in the end, no robustness test results for the model were provided.\n\u2464\tThe experiment did not conduct tests of this framework with different data types of other domains, which makes it difficult to assess the comprehensiveness of its application in various fields."
                },
                "questions": {
                    "value": "\u2460\tWhy is GgNet only applicable to transductive learning settings in its current form? What are the limitations? How to extend GgNet to support inductive learning?\n\u2461\tHow does the efficiency of Ggnet compare to other models? What is the impact of missing data in the dataset used in the experiment on the experimental results? Can you offer a more detailed explanation of the results?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8051/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8051/Reviewer_L9oj",
                        "ICLR.cc/2024/Conference/Submission8051/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8051/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698735947184,
            "cdate": 1698735947184,
            "tmdate": 1700712620973,
            "mdate": 1700712620973,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6tjoRqQC3g",
                "forum": "CAqdG2dy5s",
                "replyto": "jjNP7ABgGq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8051/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8051/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the extensive review and positive feedback.\nAs for the raised concerns and questions, individual points are addressed below.\n\n**W1/Q3. Discussion of the experimental results**\\\nIn Sec. 5 of our paper, several paragraphs are dedicated to the discussion of the experimental results.\nOur discussion focuses on the limitations of the existing methods compared to GgNet, which we investigate across different temporal and spatial problem settings. \nWe believe that discussing limitations is the most important aspect when interpreting experimental results, as it directly relates to the observed differences in performance. \nFrom a qualitative angle, Fig. 5 shows results w.r.t. the quality of the prediction and the structure of the learned embeddings. \nHowever, we agree that further comments might be needed, so we have extended our discussion in Sec. 5.1 of the revised paper. Furthermore, we have performed $4$ additional analyses (see highlighted content in the revised paper Appendix) that significantly contribute to the discussion:\n- in Appendix E.3, we now deepen the disadvantages of graph-based approaches in contrast to GgNet by means of an illustrative example in a geographically remote location; \n- in Appendix E.4, we now show and discuss the GgNet's learned dependencies between variables (intra-location graph $g$); \n- in Appendix E.5, we now investigate location-wise performance and show that the improvement of GgNet with respect to SAITS is spread across locations rather than concentrated around a few locations;\n- in Appendix E.6, we now qualitatively compare uncertainty estimates of GgNet across different scenarios.\n\nAny comment on these revisions would be appreciated. \n\n**W2. Overview diagram of the overall model structure**\\\nPlease, refer to Fig. 3, which provides an overview of the model's architecture and highlights the different components.\nIn the revised paper, we bring modifications to the figure's caption.\nWe would appreciate further feedback if, in the reviewer's opinion, any aspect of the figure could be improved.\nFurther details about the architecture are provided in Appendix B.\n\n\n**W3. Computation time and performance on large datasets.**\\\nAppendix E.1 reports the total computation time of GgNet and relevant baselines, on the largest adopted dataset, i.e., the daily climatic dataset.\nIn the revised paper, we extend the pertinent discussion.\nThe temporal modeling in GgNet is based on temporal convolutions, which makes it faster than the popular graph-based representative GRIN, which uses a recurrent model instead.\nAs for BRITS and SAITS, these are faster than GgNet as they do not account for spatial dependencies.\nThe main bottleneck in GgNet is due to the inter-locations graph which makes message-passing operations scale quadratically w.r.t. the number of locations. If scalability to large $N$ is a concern, existing sparse graph learning methods can be considered, e.g., [1].\nHowever, note that scenarios that involve significantly more sensors than the selected datasets would not likely be sparse and a different set of techniques should be used.\nWe thank the reviewer for highlighting this and we have integrated the above considerations into Appendix E.1 of the revision. \n\n\n\n\n**W4/Q2. Robustness test results.**\\\nAs mentioned in Sec. 4.4, in the first place, we mask out a fraction of the available training channels (entirely for all timestamps in a batch) and train the models to reconstruct such masked portions of data.\nThis is a core aspect, as it pushes the training toward learning the virtual-sensing task. Secondly, we also mask out randomly a portion of the input to provide additional supervision to the training routine.\nWe recognize that the paper would benefit from a sensitivity analysis of these aspects. As such, we have carried out additional experiments by varying the number of channels being masked out at training time. \nResults are reported in Appendix E.7 of the revised paper.\n\n\n**W5. Different data types of other domains.**\\\nThe focus of the paper is addressing virtual sensing for sensor networks with poor spatial coverage by proposing a graph-based reconstruction framework. \nFor this purpose, we select $3$ datasets from very relevant application domains, which we believe are sufficient to validate the relevance of the proposed methodology and the potential effectiveness of GgNet. \nThe application to more general domains and the design of appropriate benchmarks are extremely relevant, yet they go beyond this paper's scope and will constitute interesting future research."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8051/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700187539937,
                "cdate": 1700187539937,
                "tmdate": 1700187539937,
                "mdate": 1700187539937,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9g36UQyYJl",
                "forum": "CAqdG2dy5s",
                "replyto": "6tjoRqQC3g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8051/Reviewer_L9oj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8051/Reviewer_L9oj"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the reply. I think the reply addressed my most concerns."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8051/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700295625051,
                "cdate": 1700295625051,
                "tmdate": 1700295625051,
                "mdate": 1700295625051,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "tdOR0mu9OF",
            "forum": "CAqdG2dy5s",
            "replyto": "CAqdG2dy5s",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8051/Reviewer_CZHK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8051/Reviewer_CZHK"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a solution to the multivariate spatial interpolation problem through a nested graph representation and graph convolutional networks. Real climate data is used to validate the performance of the proposed solution."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The problem of spatial interpolation through deep learning is generally meaning for and important.\n2. The authors acknowledge traditional spatial interpolation methods such as Kriging\n3. Real-world dataset used for experiments."
                },
                "weaknesses": {
                    "value": "1. The claim that Kriging or similar approach won't work due to sparse sensors lacks sufficient justification. The proposed solution can be solved by multivariate Kriging. The authors should at least show the results on such a well-known spatial solution and compare it with their solution.\n\n2. The graph of sensors is built by measuring similarities between node embeddings. However, it is unclear how to learn such embeddings and why it is not affected by sensor sparsity. If two sensors are too far away their values have no correlation. The edge defined in under such a case would be meaningless. \n\n3. There is no demonstration of a successful prediction of missing values on a spatial map."
                },
                "questions": {
                    "value": "1. Why Kriging would not work in this case is not adequately justified. The semi-variogram function can be selected from a variety of options depending on the assumptions. As long as the two locations are not farther than a threshold (the range) apart, they can be assumed to have correlations. \n\n2. Another traditional model that might solve this problem is Markov random field. Why not considering it in the baseline?\n/?\uff1f\n3. How to define the graph edges based on (static) embedding? What information do you used to learn it?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "no concerns."
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8051/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8051/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8051/Reviewer_CZHK"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8051/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700230996351,
            "cdate": 1700230996351,
            "tmdate": 1700230996351,
            "mdate": 1700230996351,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sXmn7ljqcS",
                "forum": "CAqdG2dy5s",
                "replyto": "tdOR0mu9OF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8051/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8051/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the feedback.\n\nAs a general comment, we would like to point out that the focus of the paper *is not* on spatial interpolation, but on virtual sensing. The critical difference is that, at a target location, we do not seek to reconstruct a single value but rather one (or more) entire time series. \n\nFurthermore, note that with the term 'spatial dependencies' we do not necessarily refer to physical proximity, but more broadly to generic functional dependencies (learned end-to-end from data, as we discuss below). In the context of our research, 'location' (denoted as $n$) could represent various entities such as a patient from medical data or a material from performance data of different chemistries. As a result, our framework is applicable to generic time series collections, and it is not limited to pre-defined relationships related to physical proximity as in generic spatial modeling.\n\nAs for the raised concerns and questions, individual points are addressed below.\n\n**W1/Q1 (1). Limitations of Kriging in sparse settings**\\\nKriging, in general, relies on geographical coordinates, which are used to model spatial dependencies (physical proximity). \nWith a dense sensor coverage and high, local, spatial correlation, general kriging methods will perform competitively w.r.t. deep learning methods [1]. However, without the possibility of relying on such pre-defined spatial dependencies, kriging methods might fail. Our method, instead, explicitly learns (end-to-end from data) latent non-linear dependencies among the observed variables both intra and inter-location. This property becomes more important when poor sensor coverage prevents from performing geographical interpolation. \nLastly, note that OKriging is unsuitable for applications on irregular spatial domains [1], e.g., transportation networks.\n\n\n**W1/Q1 (2). Kriging baseline**\\\nWhile we recognize that adding more standard Kriging baselines would improve completeness, we do argue that it is not a critical element to support our claims. In our study, we benchmark against GRIN, a representative of spatio-temporal Graph Neural Networks (ST-GNN) and a state-of-the-art model for coordinate-based reconstruction. The established literature consistently shows the superior performance of these modern virtual sensing methodologies over standard Kriging in similar settings, e.g., [1,2,3,4].\n\nIn particular, note that:\n- Most of the standard kriging methods cannot handle temporal data (fundamental in our setting) while the selected (state-of-the-art) baselines explicitly target these scenarios; \n- Learning a proper spatiotemporal variogram is very computationally demanding, especially for long and multivariate time series;\n- Kriging consists of a *linear interpolation* of the observed data and has a strong Gaussian assumption. More recent models (ours included), instead, are designed to capture *non-linear* dependencies between locations in a learned latent space. \n    \nGiven the above, we argue that our choice of baselines is coherent with the problem settings and the current state of the art.\n\n\n**W2/Q3. Embedding learning**\\\nThere might be a critical misunderstanding here. As stated in Sec. 4.2, node embeddings are a table of learnable parameters [5,6] and, as such, are end-to-end learned jointly with the model weights given the task at hand. In our case, node embeddings are learned together with the reconstruction model by minimizing the reconstruction loss. Note that the computations carried out to extract the inter-location graph from such embeddings (Eq. 3) are seamlessly integrated within the end-to-end learning architectures. In other words, the graph is learned end-to-end as well.\n\nOnce learned, the embeddings identify each location in a common latent space, of which we show an example in Fig. 5 (right). This placement is not directly influenced by the geographical coordinates of each sensor but is learned exclusively from the observed data (targets and covariates).\nSimilarity in such space, then, is not limited to model physical proximity but can capture non-linear dependencies beyond that."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8051/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700520072744,
                "cdate": 1700520072744,
                "tmdate": 1700521332685,
                "mdate": 1700521332685,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]