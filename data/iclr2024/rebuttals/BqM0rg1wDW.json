[
    {
        "title": "PETNet - Coincident Particle Event Detection using Spiking Neural Networks"
    },
    {
        "review": {
            "id": "q8zaFUZXBu",
            "forum": "BqM0rg1wDW",
            "replyto": "BqM0rg1wDW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1845/Reviewer_ccA4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1845/Reviewer_ccA4"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel spiking neural network (SNN) architecture for coincident particle event detection in positron emission tomography (PET). Technically, the authors design a dedicated multi-objective loss function for SNNs that is both sensitive to spike counts and timing critical. Meanwhile, they implement large-scale data-parallel SNN training on a multi-node GPU system. Experiments show that PETNet outperforms SOTA algorithms with faster inference speed."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "i) The topic of particle event detection using SNNs is very interesting and attractive.\n\nii) The authors verify a surprising conclusion that SNNs can speed up this task and even improve detection accuracy by learning coincidence patterns.\n\niii) The writing is straightforward, clear, and easy to understand."
                },
                "weaknesses": {
                    "value": "i) I am curious and surprised by a sentence \u201cSNN provide a promising alternative with the potential of surpassing conventional ANN prediction accuracy while requiring substantially less computational resources\u201d in the introduction section. Why can SNNs have better performance than the corresponding ANN model and reduce computational complexity? I am curious and surprised by a sentence made in your introduction. Why can SNNs have better performance than the corresponding ANN model and reduce computational complexity? I am curious and surprised by a sentence made in your introduction. Why can SNNs have better performance than the corresponding ANN model and reduce computational complexity? Please prove this point in terms of theoretical explainability and experimentation. To the best of my knowledge, one of the biggest advantages of SNNs over ANNs is low power consumption.\n\nii) The authors should show more visualization results for better understand the task of particle event detection.\n\niii) The authors should give the detailed SNN architecture in the manuscript."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Reviewer_ccA4"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1845/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698311217513,
            "cdate": 1698311217513,
            "tmdate": 1699636114615,
            "mdate": 1699636114615,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PQqvYr51oy",
                "forum": "BqM0rg1wDW",
                "replyto": "q8zaFUZXBu",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1845/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1845/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ccA4:"
                    },
                    "comment": {
                        "value": "As stated in the general comment, it has been shown in literature [1] that is possible for an SNN to deliver comparable, if not better, performance than an ANN. This is mainly attributed to the sparse, binary, time-resolved nature of the data.\n\nWith regards to the SNN model architecture, we would like to point the reviewer to page 5, at the start of section 4, where we mention the exact design of the SNN model, with the exact numbers mentioned in Table 1. It consists of a fully connected SNN with only a single hidden layer in any case. Depending on the dataset used (Clinical, SAFIR, with/without geometry) the number of input and output nodes varied depending on the dataset, while the number of hidden layer nodes was adapted only on whether we investigated the \u2018clinical\u2019 or \u2018SAFIR\u2019 dataset. We wished to include further visualization, for example a figure visualizing the SNN architecture, but were unable to do so due to the page-limit constraint.\n\nReferences:\n\n[1] Deng, L., Wu, Y., Hu, X., Liang, L., Ding, Y., Li, G., ... & Xie, Y. (2020). Rethinking the performance comparison between SNNS and ANNS. Neural networks, 121, 294-307."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700219283406,
                "cdate": 1700219283406,
                "tmdate": 1700222908184,
                "mdate": 1700222908184,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xtZWD1LnbX",
                "forum": "BqM0rg1wDW",
                "replyto": "PQqvYr51oy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1845/Reviewer_ccA4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1845/Reviewer_ccA4"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the author's response, I stick to the original score."
                    },
                    "comment": {
                        "value": "Regarding the literature you cited (Deng et al., Neural Networks, 2020), I think that the conclusions may not be completely credible, and I suggest reconsidering them from an experimental standpoint at the very least.\nIn addition, the authors should show more visualization results for better understand the task of particle event detection in future version."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700536295347,
                "cdate": 1700536295347,
                "tmdate": 1700536295347,
                "mdate": 1700536295347,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "eHoljDo0XX",
            "forum": "BqM0rg1wDW",
            "replyto": "BqM0rg1wDW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1845/Reviewer_iojo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1845/Reviewer_iojo"
            ],
            "content": {
                "summary": {
                    "value": "This article formulates the type II coincidence pairing problem from PET dataset and highlights the time reduction and accuracy improvement over classical SCW algorithm using a well-designed SNN training method (PETNET)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "please see Summary"
                },
                "weaknesses": {
                    "value": "1. The motivation of this research has migrated SNN into a new medical classification problem (i.e. PET data). The writer introduce a multi-objective loss function where data sparsity and temporal resolution are both considered. The PET dataset characteristics may well capture SNN inherent spatiotemporal design that could make up good performance. However, in most research topics, ANN is always outperforming SNN, especially in terms of precision (e.g. CIFAR-10, imageNet). It is questionable for directly comparison only between non-ML algorithm (SCW) and SNN. \n\n2. The multi-node GPU contributions is migrating the classification problem from non-GPU framework to GPU-accelerated framework (i.e. cuda). This acceleration raised the idea that if the problem can be fulfilled using only very simple ML algorithm that also can process in a very fast and accurate manner, such as SVM, decision trees or clustering if considering only single fully connected layer is needed for the SNN. \n\n3. It is suggested to combine the Figure 1 figure 2 into one figure. Especially the PET dataset, as a subset of biomedical signal, is little covered by research topic. It is at best to illustrate the dataset in picture and visualise 1-2 selected examples from numerical vector/matrix in your dataset.\n\n4. Extending from (1), it is also suggested to include state-of-the-art algorithm which also capture temporal dynamics apart from single-layer LSTM. For example, transformer type model vs SNN approach or CNN based classification models. The expected SNN result may also be deployed on neuromorphic hardware instead of parallel hybrid \u201csupercomputer\u201d. If supercomputer is available, computing resources can be sacrificed for shorter time as there could be many available ML choices apart from SNN."
                },
                "questions": {
                    "value": "please see the weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Reviewer_iojo"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1845/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698680743214,
            "cdate": 1698680743214,
            "tmdate": 1699636114532,
            "mdate": 1699636114532,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qAJg4FpHeo",
                "forum": "BqM0rg1wDW",
                "replyto": "eHoljDo0XX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1845/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1845/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iojo:"
                    },
                    "comment": {
                        "value": "We do believe that the comparison against a state-of-the-art non-ML algorithm baseline is viable due to our desire to reduce computational times with the SNN. Similar surrogate models have recently proven their worth, e.g., in climate simulations [2]. If the reviewer can provide us with literature on classical machine learning algorithms that are tailored to sparse, binary, time- and spatially-resolved data, we would highly appreciate the effort.\n\nThe usage of the hybrid supercomputer for data-parallel training on multiple GPUs was necessary due to the inefficient implementation of the SNN in a dense tensor framework, as stated in the conclusion section. We are currently planning future work for a more efficient implementation in this regard. However, the main purpose of this study was to showcase the adequacy of SNNs for the prediction task at hand, and the potential in saving computation time at inference. \n\nWe decided against the inclusion of a visualization of the dataset due to the sparse nature of the data and therefore its lack of visible features. Please find an example in the attached supplementary material.  Figure 2 was meant to serve this purpose, detailing a schematic representation of a sample of input data and output labels. The utilization of PETNet on neuromorphic hardware is an intriguing idea for future work. As of now we unfortunately do not have access to such devices at the time of writing and thus were unable to include it.\n\nReferences:\n\n[2] Lam, R., Sanchez-Gonzalez, A., Willson, M., Wirnsberger, P., Fortunato, M., Pritzel, A., ... & Battaglia, P. (2022). GraphCast: Learning skillful medium-range global weather forecasting. arXiv preprint arXiv:2212.12794."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700219159403,
                "cdate": 1700219159403,
                "tmdate": 1700219159403,
                "mdate": 1700219159403,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "jcNsOxnluw",
            "forum": "BqM0rg1wDW",
            "replyto": "BqM0rg1wDW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1845/Reviewer_xnxs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1845/Reviewer_xnxs"
            ],
            "content": {
                "summary": {
                    "value": "Spiking Neural Networks (SNNs) are explored as an energy-efficient alternative for processing Positron Emission Tomography (PET) data. The study introduces PETNet, a method that uses SNNs to filter invalid photon hits in PET imaging. Results show PETNet has a 95.2% F1 score and is 36 times faster than traditional methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The study utilizes Spiking Neural Networks (SNNs) to develop PETNet, which not only achieves an impressive F1 score of 95.2% in photon coincidence detection but also processes data at a remarkable speed."
                },
                "weaknesses": {
                    "value": "While the author applied SNN technology to PET data processing, the innovative aspects of the research still appear limited. The LSTM mentioned in the article fails to effectively capture long-range dependencies, and the transformer faces challenges related to memory consumption due to sequence length. Regrettably, the author did not compare with these methods in the experiments."
                },
                "questions": {
                    "value": "The SNN using LIF neurons primarily relies on the constant between membrane potentials to determine its temporal dependency, which may be inadequate. Moreover, it adopts the standard fully-connected SNN design. Compared to architectures like LSTM, RNN, and Transformer, where does the SNN's advantage lie? Can this be demonstrated through experimental results?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1845/Reviewer_xnxs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1845/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698734555143,
            "cdate": 1698734555143,
            "tmdate": 1699636114456,
            "mdate": 1699636114456,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "H4kLlew0Ci",
                "forum": "BqM0rg1wDW",
                "replyto": "jcNsOxnluw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1845/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1845/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer xnxs:"
                    },
                    "comment": {
                        "value": "The advantage of the SNN lies in their nature to model binary spike trains, which fit perfectly to our problem statement. As stated in the general comment, RNN architectures like the LSTM are simply not capable of that, resulting in their inability to produce meaningful output (see supplementary results attached to this response)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1845/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700219084237,
                "cdate": 1700219084237,
                "tmdate": 1700222966169,
                "mdate": 1700222966169,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]