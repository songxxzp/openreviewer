[
    {
        "title": "Finite-Time Analysis of On-Policy Heterogeneous Federated Reinforcement Learning"
    },
    {
        "review": {
            "id": "LvZaY3SfuP",
            "forum": "D2eOVqPX9g",
            "replyto": "D2eOVqPX9g",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8544/Reviewer_pmTu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8544/Reviewer_pmTu"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes the federated version of SARSA algorithm and analyses its convergent performance with the existence of heterogeneity in both transition dynamics and reward functions.\nDifferent from classical settings of federated reinforcement learning, the paper does not assume that agents have to share the same transition dynamics and reward functions.\nThe paper demonstrates that its proposed algorithm achieves a linear speedup for the convergence to the optimal answer in each local environment both theoretically and empirically."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper considers heterogeneity in both transition dynamics and reward functions. Moreover, it quantifies the degree of these heterogeneities and discusses their effect in the final convergence of FedSARSA.\n2. The paper discusses the convergence region and linear speedup of FedSARSA. It is claimed that smaller learning rates and a larger number of participating agents will help tighten the convergence region, which matches the intuition.\n3. The numerical experiment is carried out in settings with different degrees of heterogeneity."
                },
                "weaknesses": {
                    "value": "1. What does MSE in the numerical experiments stand for? Does it mean the averaged MSE of current parameter to optimal parameters in different environments?\n2. The explanation of numerical experiments is not enough. For example, why the MSE of FedSARSA with a large number of $N$ ($N=40$) increase along the training process when $\\epsilon_p>0,\\epsilon_r>0$? And where is the confidence bound for the numerical experiments?\n3. The convergence MSE of FedSARSA with different number of agents are different from each other. What makes that difference?"
                },
                "questions": {
                    "value": "See Weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8544/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8544/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8544/Reviewer_pmTu"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698669126950,
            "cdate": 1698669126950,
            "tmdate": 1699637068982,
            "mdate": 1699637068982,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FG7U7uNL9U",
                "forum": "D2eOVqPX9g",
                "replyto": "LvZaY3SfuP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer pmTu"
                    },
                    "comment": {
                        "value": "Dear Reviewer pmTu,\n\nWe thank your for the detailed review and positive feedback. Below we provide the responses clarifying the questions:\n\n> **W1. What does MSE in the numerical experiments stand for? Does it mean the averaged MSE of current parameter to optimal parameters in different environments?**\n\nWe deferred the detailed simulation setup to Appendix C.\nIn the second paragraph of Appendix C.1 (ADDITIONAL SIMULATIONS FOR FEDSARSA), we defined our MSE: the mean squared error of the current *averaged* parameter $\\bar{\\theta}\\_t$ to the *reference* parameter $\\theta\\_{\\mathrm{ref}}^{(1)}$, where the latter is an approximate optimal parameter of the *first* MDP."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282551548,
                "cdate": 1700282551548,
                "tmdate": 1700282551548,
                "mdate": 1700282551548,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5kv23EOkjT",
                "forum": "D2eOVqPX9g",
                "replyto": "LvZaY3SfuP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer pmTu [Continued]"
                    },
                    "comment": {
                        "value": "> **W2. The explanation of numerical experiments is not enough. For example, why the MSE of FedSARSA with a large number of $N$ ($N=40$) increase along the training process when $\\epsilon _{p}>0,\\epsilon _{r}>0$? And where is the confidence bound for the numerical experiments?**\n\nWe thank the Reviewer for their constructive suggestions. In the revised paper, we have now re-plotted all the graphs with 95\\% confidence regions.\nRegarding the non-monotonic behavior of the MSE, we have the following explanation.\nOur theoretical analysis considers the expected MSE, whereas the simulation results only approximate this expectation.\nAdditionally, our theoretical analysis provides an upper bound of the convergence region radius, while the actual empirical MSE may vary from this upper bound to different extents.\nAs such, the fact that the plotted error-curve is not exactly monotone does not violate our theory; it does still reflect what Corollary 2.1 reveals: an initial exponential decay phase, followed by the error trajectory settling down.\nWe also want to remark three facts that complement the above explanation: (i) this phenomenon is influenced by the distribution of agents' optimal parameters. Given that we re-generate all agents' MDPs for different numbers of agents, this phenomenon only occurs in certain instances; (ii) the MSE is relative to a reference point, which is returned by an approximation algorithm (since we don't have the closed-form expression of the optimal parameter), and thus it only approximates the actual MSE relative to the optimal parameter; and (iii) this phenomenon only occurs when the heterogeneity level is high, where the performance of `FedSARSA` could be significantly hindered by the disparity among agents."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282650271,
                "cdate": 1700282650271,
                "tmdate": 1700282650271,
                "mdate": 1700282650271,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "iVQFRSC94m",
            "forum": "D2eOVqPX9g",
            "replyto": "D2eOVqPX9g",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8544/Reviewer_uJdU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8544/Reviewer_uJdU"
            ],
            "content": {
                "summary": {
                    "value": "This work performs theoretical studies on federated reinforcement learning with clients facing heterogeneous environments. In particular, the classical SARSA algorithm is extended to the federated version. Theoretical analyses are established to demonstrate the finite-sample convergence of the proposed FedSARSA under linear function approximation. In particular, linear speedups are reported with the established results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This work follows the interesting line of work of extending federated learning to the domain of decision-making under environmental heterogeneity. This setting is well-motivated and has wide practical implications.\n\n- The established results are solid and novel based on my reading. In particular, no similar results have been reported on FRL with heterogeneous clients in the planning task with both linear function approximation and linear speedup.\n\n- Despite the theoretical nature, the overall presentation is clear and the key intuitions are provided. The listed sketch of the proof especially facilitates the readability."
                },
                "weaknesses": {
                    "value": "- I am overall satisfied with this work. There is just one minor question I have for the authors. As mentioned at the end of page 8, the obtained results from federated RL can be leveraged as initialization points for finetuning with just local data. I imagine the analyses would not be different given existing works, and wonder whether it would be possible to state the finetuning results, which may better highlight the impact of cooperation on accelerating individual learning."
                },
                "questions": {
                    "value": "Please see the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698765910910,
            "cdate": 1698765910910,
            "tmdate": 1699637068850,
            "mdate": 1699637068850,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ThNq7FDSG9",
                "forum": "D2eOVqPX9g",
                "replyto": "iVQFRSC94m",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uJdU"
                    },
                    "comment": {
                        "value": "Dear Reviewer uJdU, \n\nThank you for your encouraging comments. We are very glad to know that you find our results solid and novel. \n\nRegarding the interesting question you raised, we first note that the finite-time error of local single-agent SARSA is given by:\n$$O\\left(\\frac{e_0^2}{M^2} + \\frac{\\sigma^2\\log M}{M}\\right),$$\nwhere $e\\_0$ is the initial mean-squared error, $\\sigma^2$ is the noise variance described by problem constants, and $M$ is the number of iterations performed by the agent. Now consider any agent $i$, and suppose it uses the output of `FedSARSA` as a warm-start. From Corollary 2.2, we then observe that the initial expected squared error $e\\_0^2$ would be $\\tilde{O}(1/(NT) + \\Lambda^2(\\epsilon\\_p, \\epsilon\\_r))$, where $\\Lambda^2(\\epsilon\\_p, \\epsilon\\_r)$ is a measure of the heterogeneity in the agents' MDPs, as defined in Theorem 1. The above discussion suggests that if the agents' MDPs are similar, i.e., if $\\Lambda^2(\\epsilon\\_p, \\epsilon\\_r)$ is small, then federation yields a small initial error $e\\_0$. This is precisely the benefit of collaboration afforded by our approach. At this point, we do not have a better analytical explanation of the benefits of collaboration + fine-tuning; we are happy to add the above discussion to the main paper as the Reviewer sees fit. We should note here that it is possible to potentially provide a sharper analysis of the benefits of fine-tuning in federated RL by drawing on analogous recent studies for federated supervised learning; see, for instance, Collins et al. (2022) and Cheng et al. (2021). This is a ripe direction of research that we are exploring at this point.\n\n## References\n\n- Collins, L., Hassani, H., Mokhtari, A. and Shakkottai, S., 2022. Fedavg with fine tuning: Local\nupdates lead to representation learning. In *Proc. Advances in Neural Information Processing\nSystems (NeurIPS)*.\n- Cheng, G., Chadha, K. and Duchi, J., 2021. Fine-tuning is fine in federated learning. arXiv\npreprint arXiv:2108.07313, 3."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282380076,
                "cdate": 1700282380076,
                "tmdate": 1700282380076,
                "mdate": 1700282380076,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "K6IPWGSrs0",
                "forum": "D2eOVqPX9g",
                "replyto": "ThNq7FDSG9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Reviewer_uJdU"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Reviewer_uJdU"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response! I would like to keep my score for now and discuss with AC and other reviewers."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700732448533,
                "cdate": 1700732448533,
                "tmdate": 1700732448533,
                "mdate": 1700732448533,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oVEQlnaJ6N",
            "forum": "D2eOVqPX9g",
            "replyto": "D2eOVqPX9g",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8544/Reviewer_qewk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8544/Reviewer_qewk"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies federated on-policy reinforcement learning with linear function approximation. It proposes FedSARSA that is a federated version of SARSA. It proves that FedSARSA converges to the neighborhood of the optimal parameter with a linear speed up."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ FedSARSA is intuitive and reasonable.\n+ The theoretical result that proves linear speedup is interesting."
                },
                "weaknesses": {
                    "value": "- The theoretical results do not have the impact of periodic updating. \n- The authors do not specify the communication cost and how it trades off with the convergence.\n- The FedSARSA is a straightforward of single-agent SARSA -- the only difference is to aggregate the parameter estimation from all agents, which is a straightforward average.\n- The authors talked about how heterogeneity is captured in the convergence, but this relationship is not well articulated. In FL, one would first need to define the heterogeneity metric and then express the convergence bound as a function of this metric. Furthermore, such heterogeneity should be defined on the data, not the underlying distribution.\n- Paper writing needs some work. It is strange to not have a Conclusion section."
                },
                "questions": {
                    "value": "- The motivation is unclear to me -- why do we want to learn a single universal policy? Each agent may interact with his/her own environment and learn a personalized policy for that environment. Isn't that better to be deployed on that environment than the single averaged policy across all environments?\n- I don't see the linear speedup in the simulation results?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813037349,
            "cdate": 1698813037349,
            "tmdate": 1699637068735,
            "mdate": 1699637068735,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hc4zoDrlDR",
                "forum": "D2eOVqPX9g",
                "replyto": "oVEQlnaJ6N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qewk"
                    },
                    "comment": {
                        "value": "Dear Reviewer qewk,\n\nThank you for your review and constructive suggestions. Regarding the weaknesses and questions, we provide the following detailed responses:\n\n> **W1. & W2. The theoretical results do not have the impact of periodic updating. The authors do not specify the communication cost and how it trades off with the convergence.**\n\nThank you for raising the points about the effects of periodic synchronization, and the trade-offs between convergence and communication cost. In what follows, we explain that the effect of periodic synchronization\u2014as captured by the number of local steps $K$\u2014**does, in fact, manifest in our finite-time bounds**. To see this, notice, for instance, that in Corollary 2.2, we need the **initial step-size** to satisfy $\\alpha_0 \\lesssim 1 /K$. This is achieved by picking the parameter $a$ (in Corollary 2.2) to be large enough such that $\\alpha\\_0 \\leq \\min \\\\{1/(8K), w/64\\\\}$. The effect of $a$ shows up in only the quadratic $O(K^2/T^2)$ term of our bound. Since for large $T$, this term will eventually get dominated by the $O(1/(NT))$ term, we had initially deferred the exact dependence on $K$ to the appendix. In response to the Reviewer's comment, we have now explicitly shown this dependence in the main paper. The main takeaway here is that a larger $K$ reduces communication, but comes at the expense of increasing the convergence bound via the (eventually negligible) $O(K^2/T^2)$ term. **Thus, our result clearly reveals the trade-off between the convergence speed and communication cost**."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251108045,
                "cdate": 1700251108045,
                "tmdate": 1700275576597,
                "mdate": 1700275576597,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rpjYYiZcQD",
                "forum": "D2eOVqPX9g",
                "replyto": "oVEQlnaJ6N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qewk [Continued]"
                    },
                    "comment": {
                        "value": "> **W3. The FedSARSA is a straightforward of single-agent SARSA -- the only difference is to aggregate the parameter estimation from all agents, which is a straightforward average.**\n\nWe thank the Reviewer for pointing out the straightforwardness of our method, which, in fact, also highlights the practicality of our method. We consider this to be a strength, and not a weakness of our paper. The main point here is that while our approach is \"simple\", its analysis is not by any means: it takes significant technical effort to clearly establish the benefits - in terms of linear speedup - offered by our approach. We explain these challenges again as is done in the paper in Section 5.3. \n\n***Challenges and Novelty in our Technical Approach.*** Arriving at our main result Theorem 2 is not simply a matter of tweaking the proofs in existing papers. Why? *The update direction of our algorithm `FedSARSA` may not correspond to the SARSA update direction of any MDP.* This challenge is unique to our setting, and neither shows up in the centralized SARSA analysis, nor in the existing MARL/FRL analyses with homogeneous MDPs. Second, unlike the standard FL optimization setting on i.i.d data, our problem does not correspond to minimizing a static loss function; moreover, we need to contend with *temporally correlated Markovian data from heterogeneous MDPs*. This clearly sets our work apart from existing FL literature. To make things even harder, the policies keep changing at the agents, and they only communicate once in a while. Given these challenges, our work develops a theoretical framework for answering the following fundamental question:\n**What is the long-term effect of combining local SARSA directions with function approximation from heterogeneous non-stationary Markov chains?** As far as we are aware, despite the long list of papers in the MARL area, no work has investigated this important question theoretically. \n\nTo answer the above question, our first key innovation is to rigorously quantify the effect of heterogeneity on SARSA fixed points in Theorem 1. This result is significant in that it reveals how heterogeneity in the rewards\nand transition kernels of MDPs can be mapped to differences in the limiting behavior of\nSARSA on such MDPs from a fixed-point perspective. To prove Theorem 2, we need to control seven different terms that appear in the error-decomposition in Section 5.3. In particular, the complex interplay between function approximation, temporal correlations, and non-stationary heterogeneous Markov chains, makes it highly non-trivial to bound the client-drift effect that arises due to performing multiple local steps. Finally, in the single-agent setting, one does not need to worry about establishing a linear speedup. In our case, however, we establish the (a priori non-obvious) fact that combining information from non-stationary heterogeneous Markov chains can in fact lead to a linear speedup in sample-complexity. \n\nWe should also note here that the most popular FL algorithm to date\u2014`FedAvg`\u2014also relies on a simple averaging of models. This has not diminished its impact in any way. Given that `FedSARSA` is the first on-policy FRL algorithm, we did not find any reason to study anything more involved, since even our simple approach provides strong guarantees that are challenging to establish."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251186647,
                "cdate": 1700251186647,
                "tmdate": 1700251186647,
                "mdate": 1700251186647,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2ZXPi4JQ10",
                "forum": "D2eOVqPX9g",
                "replyto": "oVEQlnaJ6N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qewk [Continued]"
                    },
                    "comment": {
                        "value": "> **W4. The authors talked about how heterogeneity is captured in the convergence, but this relationship is not well articulated. In FL, one would first need to define the heterogeneity metric and then express the convergence bound as a function of this metric. Furthermore, such heterogeneity should be defined on the data, not the underlying distribution.**\n\nFirst, we define the heterogeneity metrics in Definitions 1 and 2, and their impact on the convergence bound is indeed expressed as a function of these metrics: $\\Lambda(\\epsilon _{p},\\epsilon _{r})$, defined in Theorem 1. In fact, each of the bounds in Corollaries 2.1 and 2.2. exhibit the effect of $\\Lambda(\\epsilon _{p},\\epsilon _{r})$; we even discuss this point in the paragraph titled \"Convergence Region.\" As for the heterogeneity metric, since the data in our online RL setting are precisely the **Markovian observations**, we defined heterogeneity on the basic **data-generating** components\u2014the transition kernels and reward functions in the MDPs. Since transition kernels and reward functions are the basic elements of MDPs, this seemed like the most natural thing to do. That said, it is important to note that our analysis is **agnostic** to the level of heterogeneity. As such, one could in principle formulate other notions of heterogeneity, and an analysis akin to what we provide will very likely go through."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251280986,
                "cdate": 1700251280986,
                "tmdate": 1700251280986,
                "mdate": 1700251280986,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cBUuSLlqV6",
                "forum": "D2eOVqPX9g",
                "replyto": "oVEQlnaJ6N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qewk [Continued]"
                    },
                    "comment": {
                        "value": "> **W5. Paper writing needs some work. It is strange to not have a Conclusion section.**\n\nThanks for the suggestion! We have added a conclusion. We would greatly appreciate any additional input concerning our manuscript's writing issues that we can improve."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251434188,
                "cdate": 1700251434188,
                "tmdate": 1700251434188,
                "mdate": 1700251434188,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vWzfYOmq8Z",
                "forum": "D2eOVqPX9g",
                "replyto": "oVEQlnaJ6N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qewk [Continued]"
                    },
                    "comment": {
                        "value": "> **Q1. The motivation is unclear to me -- why do we want to learn a single universal policy? Each agent may interact with his/her own environment and learn a personalized policy for that environment. Isn't that better to be deployed on that environment than the single averaged policy across all environments?**\n\nWe note that the Reviewer's question also applies to federated supervised learning: why learn a common model if the agents' data distributions are very different?  The rationale here - as in our work - is that if the agents' distributions (MDPs) are not too different, then even a common model can serve as a coarse good model that the agents can use to further fine-tune. In fact, this is precisely the approach adopted in recent FL works; see \"Fedavg with fine tuning: Local updates lead to representation learning\", Collins et al., NeuRIPS 22. In line with this work and others, the main motivation of our paper is to develop a federated method that allows each agent to quickly (i.e., with a linear speedup) identify a common policy that lies in the vicinity of its own optimal policy (as characterized by Theorem 1). Each agent can then use this common policy to warm-start its fine-tuning process (Zeng et al., 2021; Cheng et al., 2021; Beck et al., 2023).\n\nMoreover, learning a common policy for different agents is motivated by real-world needs. \nFor instance, Spotify, a leading audio streaming company, intends to design a uniform pricing plan that suits the listening habits of all users. Given the substantial variations in listening habits among users, establishing a pricing strategy that aligns with the preferences of all users is of great importance.\n\n## References\n\n- Collins, L., Hassani, H., Mokhtari, A. and Shakkottai, S., 2022. Fedavg with fine tuning: Local updates lead to representation learning. In *Proc. Advances in Neural Information Processing Systems (NeurIPS)*.\n- Zeng, S., Anwar, M. A., Doan, T. T., Raychowdhury, A., and Romberg, J., 2021. A decentralized policy gradient approach to multi-task reinforcement learning. In *Uncertainty in Artificial Intelligence*. PMLR.\n- Beck, J., Vuorio, R., Liu, E.Z., Xiong, Z., Zintgraf, L., Finn, C. and Whiteson, S., 2023. A survey of meta-reinforcement learning. arXiv preprint arXiv:2301.08028.\n- Cheng, G., Chadha, K. and Duchi, J., 2021. Fine-tuning is fine in federated learning. arXiv preprint arXiv:2108.07313, 3."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251559340,
                "cdate": 1700251559340,
                "tmdate": 1700272856469,
                "mdate": 1700272856469,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bbUBNlbk75",
                "forum": "D2eOVqPX9g",
                "replyto": "oVEQlnaJ6N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer qewk [Continued]"
                    },
                    "comment": {
                        "value": "> **Q2. I don't see the linear speedup in the simulation results?**\n\nOur simulations are run with a constant-step size. As Corollary 2.1 reveals, in this case, the effect of the linear speedup shows up in tightening the size of the ball (roughly by a factor of $1/N$) to which the iterates converge. **Figure 1 does in fact show that increasing the number of agents causes the error-floor (i.e., the height of the flat line) to decrease.**  The decrease is only approximately linear since the error-floor is also affected by heterogeneity."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251591446,
                "cdate": 1700251591446,
                "tmdate": 1700251591446,
                "mdate": 1700251591446,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OnXK45wab1",
                "forum": "D2eOVqPX9g",
                "replyto": "oVEQlnaJ6N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Following-up"
                    },
                    "comment": {
                        "value": "We kindly ask the reviewer if any of their concerns remain, and if so, what in particular?"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700603987426,
                "cdate": 1700603987426,
                "tmdate": 1700603987426,
                "mdate": 1700603987426,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IuyhSrIkxh",
                "forum": "D2eOVqPX9g",
                "replyto": "OnXK45wab1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Reviewer_qewk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Reviewer_qewk"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the responses. They provide more insight into this work."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660551972,
                "cdate": 1700660551972,
                "tmdate": 1700660551972,
                "mdate": 1700660551972,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4c2NRfAAHA",
            "forum": "D2eOVqPX9g",
            "replyto": "D2eOVqPX9g",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8544/Reviewer_rA2b"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8544/Reviewer_rA2b"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the problem of on-policy federated RL with agents interacting with potentially different environments. A new algorithm FedSARSA is proposed, and shown to converge to a near-optima policy for all gents. Convergence speed analysis is also provided."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well written. The formulation and ideas are explained clearly."
                },
                "weaknesses": {
                    "value": "- It would be helpful if the authors could provide more intuition about where the speed up comes from. Specifically, what in the problem formulation/assumptions enable this speedup? Intuitively, this would be possible only when things are homogeneous (or close to that). \n- Is it possible to comment on the optimality of the finite-time error? Right now only upper bounds are provided."
                },
                "questions": {
                    "value": "- It would be helpful if the authors could provide more intuition about where the speed up comes from. Specifically, what in the problem formulation/assumptions enable this speedup? Intuitively, this would be possible only when things are homogeneous (or close to that). \n- Is it possible to comment on the optimality of the finite-time error? Right now only upper bounds are provided."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699372038766,
            "cdate": 1699372038766,
            "tmdate": 1699637068613,
            "mdate": 1699637068613,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "C2EuUf9GZ3",
                "forum": "D2eOVqPX9g",
                "replyto": "4c2NRfAAHA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rA2b"
                    },
                    "comment": {
                        "value": "Dear Reviewer rA2b, \n\nThank you for the constructive comments and positive feedback on our paper. Below, we provide detailed responses to the questions you raised.\n\n> **W1. & Q1. It would be helpful if the authors could provide more intuition about where the speed up comes from. Specifically, what in the problem formulation/assumptions enable this speedup? Intuitively, this would be possible only when things are homogeneous (or close to that).**\n\nTo be precise, the linear speedup effect comes from the fact that the Markovian observation sequences across agents are assumed to be **statistically independent**. This is the key assumption that eventually leads to a \"variance-reduction\" effect when one merges information from different agents. That said, even when the agents' MDPs are identical, a few important things worth noting are the following: (i) for each agent, its own Markovian observations are temporally correlated over time, and are generated based on time-varying Markov chains; (ii) the agents fuse models, and not raw data (e.g., rewards); and (iii) the realizations of rewards and state transitions can differ across agents. Under these conditions, establishing the linear speedup effect requires significant technical work - which is one of the main contributions of our paper.\n\nThe Reviewer's intuition is entirely correct. The linear speedup effect is prominent only when the agents' MDPs are not too different. Indeed, if one inspects the final bound in Corollary 2.2, it is of the form $\\tilde{O}(1/(NT) + \\Lambda^2(\\epsilon\\_p, \\epsilon\\_r))$, where $\\Lambda^2(\\epsilon\\_p, \\epsilon\\_r)$ is a term that captures the heterogeneity in the agents' MDPs. The implication of this result is as follows: FedSARSA enables each agent to converge to a ball of radius $\\Lambda(\\epsilon\\_p, \\epsilon\\_r)$ around its own optimal parameter at a rate that gets linearly expedited by the number of agents $N$. Each agent can then use the output of FedSARSA as a *warm-start* to further fine-tune based on its own data. Clearly, if the heterogeneity level is low, i.e., if $\\Lambda(\\epsilon\\_p, \\epsilon\\_r))$ is small, the agents converge quickly to a smaller ball around their optimal parameter. Conversely, if the heterogeneity is large, the $\\Lambda(\\epsilon\\_p, \\epsilon\\_r)$ dominates, and the benefit of the speedup gets obscured.\nThis intuition is also verified in our simulations, as demonstrated in Figure 4 (and additional experiments in Appendix)."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251739466,
                "cdate": 1700251739466,
                "tmdate": 1700275522451,
                "mdate": 1700275522451,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3pfga1NDFR",
                "forum": "D2eOVqPX9g",
                "replyto": "4c2NRfAAHA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer rA2b [Continued]"
                    },
                    "comment": {
                        "value": "> **W2. & Q2. Is it possible to comment on the optimality of the finite-time error? Right now only upper bounds are provided.**\n\nThis is a great question! To the best of our knowledge, there is no sample complexity lower bound for SARSA or federated reinforcement learning. As such, we cannot claim that our bounds are minimax optimal. That said, we now explain that are bounds are consistent with existing results. For instance, when the number of agents is $1$ (and hence, there is no heterogeneity), our finite-time bound in Corollary 2.2 matches that for SARSA in Zou et al. (2019). Second, when there is no heterogeneity, the final bound we achieve in Corollary 2.2 is $\\tilde{O}(1/(NT))$. With $N$ agents, each of whom receives $T$ samples, the total number of samples is $NT$. Given $NT$ samples, we can hope to reduce noise variance by at most a factor of $NT$; so it seems quite unlikely that our bound can be improved in this regard. Thus, it only remains to argue whether the additive $\\tilde{O}(\\Lambda(\\epsilon _{p},\\epsilon _{r}))$ term - a measure of heterogeneity defined in Theorem 1 - is an artifact of our analysis, or something unavoidable. Notice that the bound we provide is w.r.t. each agent's own optimal parameter. When the agent's MDPs are non-identical, their optimal parameters need not be identical. Thus, for an algorithm like FedSARSA that combines models from all agents, the average model at the server will - in the general case - not converge to any particular agent's optimal parameter. Thus, it seems unlikely that one can hope to achieve a bound that does not exhibit any bias term at all, unless additional assumptions are made. As to the specific bound of $\\tilde{O}(\\Lambda(\\epsilon _{p},\\epsilon _{r}))$, this is consistent with the difference in fixed points established in Theorem 1. Furthermore, a heterogeneity bias term of exactly this form is proven to be **unavoidable** in the recent paper  Wang et al. (2023) that studies federated TD learning. We conjecture that a similar lower bound exemplifying the heterogeneity-induced bias can be established for our setting as well; but this requires more work since unlike the linear operators in TD, SARSA involves nonlinear operators. This is indeed a very promising direction of future work, as identified by the Reviewer. \n\nIn response to the Reviewer's comment, and to provide more clarity on our bounds, we have now added a **new section**, Appendix B (FINITE-TIME RESULTS COMPARISON), in our revised manuscript. This section provides a comparison of our finite-time results with other related work, demonstrating that our finite-time error bound is consistent with existing studies. \n\n## References\n\n- Zou, S., Xu, T., and Liang, Y., 2019. Finite-sample analysis for sarsa with linear function approximation. In *Proc. Advances in Neural Information Processing Systems (NeurIPS)*.\n- Wang, H., Mitra, A., Hassani, H., Pappas, G.J. and Anderson, J., 2023. Federated temporal difference learning with linear function approximation under environmental heterogeneity. arXiv preprint arXiv:2302.02212."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251858145,
                "cdate": 1700251858145,
                "tmdate": 1700252024441,
                "mdate": 1700252024441,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o2CNQ3WT2r",
                "forum": "D2eOVqPX9g",
                "replyto": "3pfga1NDFR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8544/Reviewer_rA2b"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8544/Reviewer_rA2b"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the responses."
                    },
                    "comment": {
                        "value": "Thanks for the responses. They address my comments. I will keep my score."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700632223408,
                "cdate": 1700632223408,
                "tmdate": 1700632223408,
                "mdate": 1700632223408,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]