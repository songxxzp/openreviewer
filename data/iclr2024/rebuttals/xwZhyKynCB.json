[
    {
        "title": "${\\rm EFO}_k$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation"
    },
    {
        "review": {
            "id": "anLJXOnJUO",
            "forum": "xwZhyKynCB",
            "replyto": "xwZhyKynCB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4868/Reviewer_LSNr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4868/Reviewer_LSNr"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a framework for generating existential first-order\nqueries over knowledge graphs, which considers different parameters\nthat make queries harder or easier to evaluate (for example, being\neither graph-shaped or tree-shaped). Besides, they use this framework\nto compare existing complex query answering models, shedding light on\nthe sources of the hardness of existential first-order queries over\nknowledge graphs."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The development of methods to compare complex query answering models\n  over knowledge graphs is important. This paper contributes by\n  proposing a comprehensive approach to generate existential\n  first-order queries over knowledge graphs, significantly expanding\n  the benchmarks for such comparisons."
                },
                "weaknesses": {
                    "value": "* The presentation of the paper needs to be improved. \n\n* The treatment of parameters upon which the difficulty of conjunctive\n  query evaluation depends is somewhat superficial. Much research on\n  this topic has been conducted in databases, but the authors do not\n  take this into consideration."
                },
                "questions": {
                    "value": "(1) The presentation of the paper needs to be improved. In particular,\nsome definitions need to be clarified.\n\n- Definition 4: Consider the formula $P(x) \\wedge \\exists x R(x,y)$. In\n  this case, both $x$ and $y$ are free variables, although only $y$ is\n  considered free according to the definition in the paper. This may\n  seem like a minor point, but the correct definition of this notion\n  is necessary when considering a logic with a bounded number of\n  variables, which is a standard way to construct fragments of\n  first-order logic with tractable query evaluation.\n\n- Paragraph after Definition 9: The authors claim the following:\n  \"... the inference of existential formulas is easier than solving\n  CSP instances since the existential variables do not need to be kept\n  track of\". I do not understand this claim, as the complexity of CSP\n  solving and conjunctive query evaluation is the same (both problems\n  are NP-complete).\n\n- Definition 7: What does it mean that \"$\\phi(a_1, ..., a_k)$ is True\"?\n  Where is this query evaluated? Do you assume a fixed knowledge graph\n  over which all queries are evaluated?\n\n- Definition 7: How is the semantics of negation defined under OWA? Do\n  you consider a certain answer semantics over some possible worlds\n  (otherwise no negative atoms can be inferred)? The authors use the\n  term \"$\\phi(a_1, ..., a_k)$ is True\" without defining it.\n\n- Definition 12: For an abstract query graph G, a grounding is a\n  function I that maps G into a query graph. Do you impose any\n  restrictions on this mapping? For example, could two distinct nodes\n  with the type \"Free variable\" be mapped to the same variable? This\n  is relevant for the bottom-left graph in Figure 2, which is claimed\n  to violate Assumption 14 (this is not true if you can map both\n  yellow nodes to the same variable).\n\n- Paragraph after Assumption 15: The authors mention the following\n  \"Assumption 15 treats negation separately because of the fact that\n  for any KG, any relation r in R, there is |{ (h,t) | h,t in E,\n  (h,r,t) in KG}| << E^2\". I do not understand this notation. On the\n  left-hand side of <<, you count a number of tuples, while on the\n  right-hand side, you are considering the cross product of a set with\n  itself. Isn't this a comparison of a number with a set?\n\n\n(2) The treatment of parameters upon which the difficulty of\nconjunctive query evaluation depends is somewhat superficial. In fact,\nthe authors have made a contribution by lifting the restriction that\nconjunctive queries must be tree-shaped and by considering an approach\nto generate general graph-shaped queries. However, between trees and\ngeneral graphs, there exists a large number of structures that are\ndefined in terms of parameters which have been studied precisely to\nanalyze the complexity of query evaluation. Most notably, the authors\ncould have considered the notions of treewidth and hypertree width,\nwhich are explained in the following references:\n\nJ\u00f6rg Flum, Martin Grohe: Parameterized Complexity Theory. Texts in\nTheoretical Computer Science. An EATCS Series, Springer 2006.\n\nGeorg Gottlob, Gianluigi Greco, Nicola Leone, Francesco Scarcello:\nHypertree Decompositions: Questions and Answers. PODS 2016: 57-74\n\nMoreover, the following book provides a detailed view of fast\nconjunctive query evaluation:\n\nhttps://github.com/pdm-book/community\n\n\n(3) Why do you need to develop your own algorithm to compute the\nanswers to an existential formula, as described in Section 4.3? Why\ncan't you leverage the substantial body of work and existing\nimplementations for answering first-order queries?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Reviewer_LSNr"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4868/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698727393204,
            "cdate": 1698727393204,
            "tmdate": 1699636470746,
            "mdate": 1699636470746,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "isNaaqPpfz",
                "forum": "xwZhyKynCB",
                "replyto": "anLJXOnJUO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4868/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4868/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback. We highly value your expertise in logic and databases, and will improve our paper, including more rigorous definitions, correcting typos in presentation, and citing related previous research according to your suggestions. However, there are also some misunderstandings we would like to clarify:\n\n> Definition 4: Consider the formula\u2026. This may seem like a minor point, but the correct definition of this notion is necessary when considering a logic with a bounded number of variables, which is a standard way to construct fragments of first-order logic with tractable query evaluation.\n\nWe appreciate your suggestions. We presume that all variables are named differently as it is the standard way in first order logic without clear explanation. We have corrected this point to make our discussion more clear.\n\n> Paragraph after Definition 9: The authors claim the following: \"... the inference of existential formulas is easier than solving CSP instances since the existential variables do not need to be kept track of\". I do not understand this claim, as the complexity of CSP solving and conjunctive query evaluation is the same (both problems are NP-complete).\n\nYour understanding is right and both solving  CSP and conjunctive query evaluation are NP-complete. However, our claim is about the polynomial time reduction itself. Moreover, this polynomial reduction is very powerful in a smaller n (<10) like in our cases. In practice, our inference techniques are 100 times faster than CSP solvers. Certainly, both problems are NP-complete and it doesn\u2019t conflict.\n\n> Definition 7: What does it mean that \" is True\"? Where is this query evaluated? Do you assume a fixed knowledge graph over which all queries are evaluated?\n\n> Definition 7: How is the semantics of negation defined under OWA? Do you consider a certain answer semantics over some possible worlds (otherwise no negative atoms can be inferred)? The authors use the term \" is True\" without defining it.\n\nThank you for your suggestions, since our semantics is standard and it is a common practice[1] to state in a intuitive way, we didn\u2019t give a rigorous definition of the semantics of the query. Regarding the evaluation and OWA, the underlying knowledge graph KG is taken as ground truth to evaluate the query. Regarding the negation, any unobserved triple is considered negated. We will include this part of definition in the preliminary.\n\n\n> Definition 12: For an abstract query graph G, a grounding is a function I that maps G into a query graph. Do you impose any restrictions on this mapping?.....\n\nWe are extremely sorry for this typo, causing confusion in the reading, as stated in the answer regarding Definition 4, we need to assume all nodes in the abstract query graph G should be named differently. We have corrected this typo thanks to your advice.\n\n> Paragraph after Assumption 15: The authors mention the following \"Assumption 15 treats negation separately because of the fact that for any KG, any relation r in R, there is |{ (h,t) | h,t in E, (h,r,t) in KG}| << E^2\".....\nSorry for this Typo, it should be |\\mathcal{E}|^2, we have corrected it and thank you for your observation.\n\n>  In fact, the authors have made a contribution by lifting the restriction that conjunctive queries must be tree-shaped and by considering an approach to generate general graph-shaped queries. \u2026.Most notably, the authors could have considered the notions of treewidth and hypertree width\u2026\n\n\nWe really appreciate your suggestion. It is really important and necessary to include more parameters like treewidth and is also a common practice in the discussion of traditional database/CSP communities. However, we want to point out that we have made the assumption in Section 5, the footnote on the 8th page that the number of edge of query graph is no more than the number of nodes, therefore, the treewidth is either 2 or 1, making it pointless for discussion. We will leave this to future work to include even more complicated query graph.\n\n> Why do you need to develop your own algorithm to compute the answers to an existential formula, as described in Section 4.3? Why can't you leverage the substantial body of work and existing implementations for answering first-order queries?\n\n\nThank you for your suggestions. Firstly, our implementation is consistent with existing implementations and we have already double-checked its correctness. Additionally, we will cite more existing work for clarification and we reckon that our own algorithm in Section 4.3 was not a theoretical innovation but rather a convenient implementation that fits into our framework well.\n\n[1] Ren H, Leskovec J. Beta embeddings for multi-hop logical reasoning in knowledge graphs[J]. Advances in Neural Information Processing Systems, 2020, 33: 19716-19726."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4868/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700411717471,
                "cdate": 1700411717471,
                "tmdate": 1700411717471,
                "mdate": 1700411717471,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "A8LQkQSh7z",
            "forum": "xwZhyKynCB",
            "replyto": "xwZhyKynCB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4868/Reviewer_d2wZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4868/Reviewer_d2wZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a  new framework for studying complex query answering. This framework covers a bigger family of Existential First Order (EFO) queries while previous ones only cover a subset of EFO queries. Besides, the paper introduces a new datasets that contains 741 types of query. The generated queries are several guaranteed to have high quality based on several rules. Finally, the paper implements the entire pipeline for query generation, answer sampling, model training and inference, and evaluation. The paper also includes some evaluation results of existing methods on this benchmark."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Strengths:\n1) As far as I know, this framework covers the bigest family of EFO queries. The task is much more challenging than that of previous benchmark as they only consider a small subset of the EFO queries. I believe that this framework has enough impact in the knowledge graph reasoning community. \n2) Also, when desiging the benchmark, the authors consider both combinatorial hardness and structural hardness\n3) The paper introduces a comprehensive benchmark dataset consisting of 741 types of query with guaranteed quality."
                },
                "weaknesses": {
                    "value": "1) The authors discussed some theoretical properties of EFO(k) queries, but did not provide enough insights on how to design a CQA model for the new types of queries that satisfy these properties. It would significantly increase the impact of the paper if the authors could explictly include such a section.  \n2) It is not clear how the previous model like BetaE/LogicE/ConE etc. are extended to handle cyclic and multigraph queries. These models are known to be able to only handle tree-form queries, as far as I know.\n\n**Post-rebuttal:** After reading the authors' rebuttal and the other reviews, it seems that there are some key limitations that the authors did not address during the rebuttal. Also, there are no methodological contributions or insights for designing new CQA method except a new dataset in this paper. Hence, I downgrade my rating."
                },
                "questions": {
                    "value": "In Fig 3, the authors used some figures from public media. I am not sure whether the authors have the license or need to ask for a license."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Reviewer_d2wZ",
                        "ICLR.cc/2024/Conference/Submission4868/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4868/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698744820836,
            "cdate": 1698744820836,
            "tmdate": 1700830508817,
            "mdate": 1700830508817,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Nu1BjrvX9Q",
                "forum": "xwZhyKynCB",
                "replyto": "A8LQkQSh7z",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4868/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4868/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your kind feedback. We are honored by your approval of the completeness of our dataset.. We firmly believe that our proposed dataset will contribute to the advancement and development of new models in this field and here is our rebuttal:\n\n\n> The authors discussed some theoretical properties of EFO(k) queries, but did not provide enough insights on how to design a CQA model for the new types of queries that satisfy these properties. It would significantly increase the impact of the paper if the authors could explictly include such a section.\n\nWe would like to express our gratitude for your helpful reminder regarding the details of extending previous models to answer queries beyond tree structures. In fact, we believe this is a general direction in the database community, and we have noted very recent research trying to filling this gap[1], we will provide this discussion in our paper. Actually, our work provides some general extension of the previous model like ConE which can only deal with tree-form query initially. And we show that more general methods like LMPNN suffers from the biased selection of training data severely. However, we have not designed any new methods since this is a dataset and benchmark paper, and we strive to test the generalizability of existing methods, providing corresponding discussion. We will leave the more sophisticated design of CQA models in the future but we will surely include more discussions of it thanks to your advice.\n\n> It is not clear how the previous model like BetaE/LogicE/ConE etc. are extended to handle cyclic and multigraph queries. These models are known to be able to only handle tree-form queries, as far as I know.\n\nThank you for your correct observation, surely these models are known to be able to only handle tree-form queries. In fact, this extension is done by us while ensuring the backward compatibility, this is explained in the Section 4.4 and detailed in Appendix F, and we consider this as one of our contribution of our paper.\n\n[1] Barcel\u00f3, Pablo, et al. \"A neuro-symbolic framework for answering conjunctive queries.\" arXiv preprint arXiv:2310.04598 (2023)."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4868/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700411783909,
                "cdate": 1700411783909,
                "tmdate": 1700411783909,
                "mdate": 1700411783909,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ahuoMAlUQj",
            "forum": "xwZhyKynCB",
            "replyto": "xwZhyKynCB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4868/Reviewer_wF2V"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4868/Reviewer_wF2V"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses Complex QA (space of Existential First Order Queries) on a Knowledge Graph. The question is assumed to be represented as a query graph (for first order logic e.g. \"Find a city that is located in Europe and is the capital of a country that has not held the Olympics\") with associated Answer Set for the free variables of that graph, from the KG, based on previous work.\n\nIt proposes a query graph sampling approach to generate graphs, and solve them as constraint satisfaction problems on the KG. These graph-answer pairs are provided as a dataset of 741 query types in first order logic. This I believe is used to train different learning-based methods from prior works, on the query graph to infer the answer set. The evaluation provides the Hit@10 scores for these."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Dataset of query graphs with Answer Sets (but the quality of the grounding of the query graphs to the real world concepts is not validated in any way. It is unclear how useful the dataset is, or how meaningful the generated query graphs are in terms of real concepts).\n\n2. Heuristic approach for query graph sampling (abstract graph with fixed number of variables, then sampling entities and relations to fill it)."
                },
                "weaknesses": {
                    "value": "1. Dataset of query graphs with Answer Sets built from Query graph sampling - It is not validated whether these produce meaningful query graphs when grounded to real-concepts, and how representative is this dataset for Complex QA on a KG with natural questions.\n\n2. There seem to be several key limitations - How does this help with improving Complex questions answering of natural question datasets e.g. WebQSP, Complex WebQSP. First, the approach here does not examine how natural questions from such datasets can be formulated into query graphs with any automatic methods (that are not manual, which would be critical to use this approach). Secondly, it does not suggest how the dataset can improve results on standard QA datasets like Complex WebQSP or the likes for KGQA.\n\n3. I am not clear about how the learning-based methods are relevant here. The dataset is formed by solving some version of CSP (details lacking entirely of their \"own algorithm\" in Sec 4.3), and then what is the relevance of learning based methods to embed the query graph and try to infer the answer? And this still does not connect to the complex natural question KGQA methods to produce answers for natural questions from the KG.  \n- Section 4.3 \"we develop our own algorithm following the standard solving technique of CSP, which ensures\nconsistency conditions in the first step, and do the backtracking to get the final answers in the\nsecond step\".\n\n4. Approach presentation and clarity - The whole Framework section (4.1-4.4) in the main paper is limited, and does not at all deliver what the approach is (and even if we read through the Appendix, its not presented well enough to grasp the key points of the approach at high-level but with sufficient detail). The presentation is poor with unnecessary assumptions and elaborations (unrelated to the proposed contributions) listed in the main paper, and much of the methodology in the Appendix.\n\n5. This paper is derivative \n- It extends to only 2 free variables in practice (and the extension to multiple free variables, over their prior work Yin et al 2023 seems trivial?). \n- The two assumptions they define are extraneous as they themselves suggest this cannot be checked in practice (so the contribution claim that \"Our assumption is more systematic than previous ones as shown by the example in Figure 2.\" is not useful. \n- We include the whole family of EFO1 query, many of them can not be represented by operator tree. This is based on prior work directly, so its not a contribution of this paper. In which case the only contribution seems to be the dataset with 2 free variables and the heuristics extended to sample and ground the query graphs and get its Answer set for the dataset. The usefulness and solidity of the dataset is unexplored to be clearly justifiable as useful.\n- The heuristics to sample and ground the dataset are not obvious, clear, or validated, or effectively presented."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Reviewer_wF2V"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4868/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698765529408,
            "cdate": 1698765529408,
            "tmdate": 1699636470550,
            "mdate": 1699636470550,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0hxAkE8nYq",
                "forum": "xwZhyKynCB",
                "replyto": "ahuoMAlUQj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4868/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4868/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback, which provides a new perspective from the NLP community. However, we believe there are some misunderstandings about the contribution and importance of the task of complex query answering and our work that we would like to clarify.\n\n\n\n> Dataset of query graphs with Answer Sets built from Query graph sampling - It is not validated whether these produce meaningful query graphs when grounded to real-concepts\u2026.\n\n> There seem to be several key limitations - How does this help with improving Complex questions answering of natural question datasets e.g. WebQSP, Complex WebQSP..\u2026\n\nWe would like to answer these two questions together, as they seem to make the same presumption that query in formal language (first order logic) is only practical when it can be found in natural language, and the task of complex query answering (CQA) is therefore subordinate to natural language task like Knowledge Graph Question Answering (KGQA). However, this is not the case. We would like to refer you to the first question in our general feedback for the discussion where we refute this presumption and we do not reiterate the context here.\n\nIn short, the introduction of complicated queries, such as multi-variable queries, even though hard to find in natural language, is crucial for advancing the development of CQA in the sense of strengthening/benchmarking the combinatorial generalizability, which greatly differs from KGQA which is conducted in natural language. \n\n> I am not clear about how the learning-based methods are relevant here\u2026And this still does not connect to the complex natural question KGQA methods to produce answers for natural questions from the KG\u2026.\n\nWe thank you for your questions. In fact, there have been many previous learning-base methods that focus on complex query answering, and one of our core contributions of this paper, is to benchmark the generalizability, how well they can handle query with different graph features, like different topology properties that may have not been considered during their model design. Regarding the connection to KGQA, we believe this question are addressed above.\n\n\n\n\n> Approach presentation and clarity - The whole Framework section (4.1-4.4) in the main paper is limited,..not presented well enough to grasp the key points \u2026\nRegarding the issue of presentation, we would like to hear actionable suggestions about the context, both in the main paper and the appendix. Our goal is to explain the intuitive and brief idea in the main paper and provide enough details in the appendix. For example, in the main paper, we provide Figure 3, where each component in the framework section  (4.1-4.4) is clearly illustrated, which can grasp the key point of our framework. In the appendix, we offer additional illustrations in Figure 5, together with the writing in Appendix D.1 and Section 4.1, clearly explains how to enumerate all possible abstract query graphs. Similarly, Appendix F is for Section 4.4 where we provide with the pseudo-code here. We will certainly strive to improve the presentation of our paper, but we would like to hear more actionable suggestions.\n\n\n\n> This paper is derivative\u2026..\n\nRegarding this issue, we would like to refer you to the second question in our general rebuttal. Here, we add some brief additional comments.\n\n>> It extends to only 2 free variables in practice (and the extension to multiple free variables, over their prior work Yin et al 2023 seems trivial?).\n\nAs discussed in the general rebuttal, the extension from 1 free variable to 2 is fundramental, while 2 to k is derivative instead.\n\n>> The two assumptions they define are extraneous as they themselves suggest this cannot be checked in practice.\n\nThis is a very ** clear misunderstandings**. As we state in Section 3.1, Assumption 13 and 14 apply to **abstract query graph** because putting these assumptions to **grounded query graph** should be avoided in practice. Therefore, we strictly abide by these two assumptions we put forward in practice.\n\n>>  We include the whole family of EFO1 query, many of them can not be represented by operator tree. This is based on prior work directly, so it's not a contribution of this paper.\n\nHowever, no previous work has discussed how to enumerate the whole family of EFO1 query. Those assumptions in Section 3.1 and 3.2, help us greatly when exploring the combinatorial space and has never been discussed to the best of our knowledge. \n\n>> The heuristics to sample and ground the dataset are not obvious, clear, or validated, or effectively presented.\n\nIf your concern is about the natural language,  it has been addressed above. If you concern is about our presentation, we would like to hear more detailed suggestions as we have also discussed above."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4868/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700413873052,
                "cdate": 1700413873052,
                "tmdate": 1700413873052,
                "mdate": 1700413873052,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "C3vkK4HQqw",
                "forum": "xwZhyKynCB",
                "replyto": "0hxAkE8nYq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4868/Reviewer_wF2V"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4868/Reviewer_wF2V"
                ],
                "content": {
                    "title": {
                        "value": "Further questions"
                    },
                    "comment": {
                        "value": "I see the difference of complex query answering vs complex question answering (common in the NLP community) of this paper as acceptable now.\n\nStill, once the abstract graph is constructed, the entities sampled to created the grounded graph? How does that latter sampling ensure that the queries make logical sense? And there is no validation of that in the paper, correct?\n\nMy other question is as follows: The CSP approximation solver (since its NP hard otherwise) is used to find the answer set of free variables in that query graph. When sampling, isn't it already known what entities/concepts from the KG fill those free variables? then why is CSP needed? And if I understand correctly, the learning based approach is just used to learn the CSP solution- because prior works have used learning based solutions? But how is it necessary when CSP solver can just be used instead?"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4868/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700414628048,
                "cdate": 1700414628048,
                "tmdate": 1700414628048,
                "mdate": 1700414628048,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9I5OcclLOl",
            "forum": "xwZhyKynCB",
            "replyto": "xwZhyKynCB",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4868/Reviewer_Cfvr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4868/Reviewer_Cfvr"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a full benchmark for evaluating existential first order queries (in DNF) over knowledge graphs. The benchmark provides a way to generate data, as well as sampling over all possible abstract query types following certain parameters, such as number of variables, as long as they satisfy certain assumptions. \nI think the benchmark might prove useful, and gives us a way of sampling all kinds of queries from datasets. \nI am somewhat uncomfortable with the benchmark design for queries with several variables, as there is no justification for the choices taken by the authors: why would one try to evaluate queries with more than one free variable by means of architectures designed for unary queries? \nRegarding the score, I try to gauge the impact of this benchmark in the community in terms of its difference with standard benchmark of Ren et al. As I see it, the additional power that the authors provide is 1- more unary queries (actually all of them), and 2- support for k-ary queries. I believe this benchmark may impact future contributions in the area of neural query answering, but I don't think just adding more queries would become in an impact that merit publication in ICLR."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- benchmark appears to be working, and code is avaliable for future authors. \n- benchmark goes beyond what is currently used for papers in the area. \n- additional support for answering queries with more than one free variable, even though it is not clear that this is the direction one must go in supporting these queries."
                },
                "weaknesses": {
                    "value": "- benchmark does not include ways of generating new data\n- no concern over which queries are more practical than others, results may be altered by queries that would be hard to find in practice. \n- limited impact: I consider this as an add on to complement work by Ren et al."
                },
                "questions": {
                    "value": "Please clarify the rationale behind the idea of answering queries with more than 1 free variable by decomposing that queri into several unary pieces. Queries with more than one free variable have a standard interpretation, which is answering tuples, and it is not clear to me that any of the measures would be actually important in practice."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4868/Reviewer_Cfvr",
                        "ICLR.cc/2024/Conference/Submission4868/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4868/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698786470018,
            "cdate": 1698786470018,
            "tmdate": 1700755730289,
            "mdate": 1700755730289,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "RVyFvtpeDR",
                "forum": "xwZhyKynCB",
                "replyto": "9I5OcclLOl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4868/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4868/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback.  However, we believe there are some misunderstandings about the contribution and importance of the task of complex query answering and our work that we would like to clarify.\n\n> benchmark does not include ways of generating new data.\n\nThank you for your questions. However, we have produced many new queries with novel query types including both single variable and multi variables. To the best of our knowledge, we surpass all previous work regarding the query types we investigated and the process of sampling data is totally novel. \n\n> no concern over which queries are more practical than others, results may be altered by queries that would be \n\nWe thank you for your concerns, however, it seems that you presume query in formal language (first order logic) is only practical when it can be found in natural language. However, this is not the case. We refer you to the first question in our general feedback for the discussion where we refute this presumption. In short, the input of CQA models is in formal language rather than neutral language, and the CQA models aim to be trained on selected query types and combinatorially generalize to unseen complex patterns in first-order logic[1]. In this way, the study of combinatorial generalizability of the CQA models plays a pivotal role in the task of representation learning[2]. Therefore, the introduction of those complicated queries that can hardly be found in natural language has its own merit: benchmarking the combinatorial generalizability of the CQA models. \n\n> limited impact: I consider this as an add on to complement work by Ren et al.\n\nWe thank you for your concerns, however, our dataset is a huge extension to the work of Ren[1]. We would like to refer you to the second question in our general feedback. In short, we already explained in the introduction that existing dataset in complex query answering is severely inadequate, because their construction is biased and has not discussed queries with some patterns entirely: multigraph, cyclic graph, multiple free variables, resulting in lack of both combinatorial answers and structural hardness. This huge extension was also mentioned in Section 3.2 and detailed in Appendix D.3, where we provide Figure 6, clearly illustrating how huge our extension is. We welcome you to check that.\n\n\n\n\n\n\n\n\n\n[1] Ren H, Leskovec J. Beta embeddings for multi-hop logical reasoning in knowledge graphs[J]. Advances in Neural Information Processing Systems, 2020, 33: 19716-19726.\n\n[2] Bai, Jiaxin, et al. \u2018Sequential Query Encoding for Complex Query Answering on Knowledge Graphs\u2019. Transactions on Machine Learning Research, 2023, https://openreview.net/forum?id=ERqGqZzSu5."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4868/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700413444624,
                "cdate": 1700413444624,
                "tmdate": 1700413444624,
                "mdate": 1700413444624,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "NwxFTQXV0E",
                "forum": "xwZhyKynCB",
                "replyto": "RVyFvtpeDR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4868/Reviewer_Cfvr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4868/Reviewer_Cfvr"
                ],
                "content": {
                    "title": {
                        "value": "Pplease consider also answering my question"
                    },
                    "comment": {
                        "value": "Thanks for the answers. While I think about them and post back, please consider answering my question, about how you treat queries with multiple output variables."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4868/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493857070,
                "cdate": 1700493857070,
                "tmdate": 1700493857070,
                "mdate": 1700493857070,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]