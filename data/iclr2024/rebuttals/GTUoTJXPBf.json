[
    {
        "title": "Noisy Interpolation Learning with Shallow Univariate ReLU Networks"
    },
    {
        "review": {
            "id": "ntbYqJUfqV",
            "forum": "GTUoTJXPBf",
            "replyto": "GTUoTJXPBf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission774/Reviewer_toQ6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission774/Reviewer_toQ6"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the min-$\\ell_2$ norm interpolation learning of two-layer ReLU neural networks under the univariate data. The results start from linear splines, demonstrating that linear-spline interpolator exhibits tempered behavior. Then the min-norm interpolator is studied based on the relationship with the linear-spline. Then the results show that, tempered overfitting occurs in the Lp space with $1 \\leq p <2$ but catastrophic overfitting occurs for $p > 2$."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The generalization performance of linear splines and min-norm solution is studied in terms of tempered overfitting and catastrophic overfitting"
                },
                "weaknesses": {
                    "value": "There is no distinct drawback in my view. The proof is based on the nice statistical property of $\\ell_i$, which might be the key technical difficulty when extending to the $d$-dimensional data. For example, the two-dimensional data, we sort the data, split the space, define the risk in the two-dimensional interval. But the estimation based on $\\ell_i$ is unclear to me.\n\nBesides, comparison with (Kornowski et al. 2023) requires more discussion, especially in terms of the technical tools.\n\nApart from this, some references on the following topics in the related work are missing:\n-\tNeural networks, the representer theorem, splines, Banach spaces\n-\tBenign overfitting papers"
                },
                "questions": {
                    "value": "- Could you please intuitively explain why catastrophic overfitting occurs for $p>2$ under the min-norm solution while linear spline does not?\n\n- Can Linear splines obtain better performance than the min-norm solution?\n- What is the result under the min-$l1$ norm solution? Intuitively, there is no significant difference for univariate data but I expect that some results from previous min-l1 norm literature can be discussed under the univariate setting.\n- What\u2019s the meaning of \u201cmildly dependent random variables\u201d of $\\ell_i$?\n- How does $(n+1)/X -> 1$ hold with almost surely?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698581536691,
            "cdate": 1698581536691,
            "tmdate": 1699636004827,
            "mdate": 1699636004827,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "I19qUglSmQ",
                "forum": "GTUoTJXPBf",
                "replyto": "ntbYqJUfqV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission774/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Addressing Questions of Reviewer toQ6"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive feedback on the work! We will add a more detailed comparison with Kornowski et. al. [1] and a discussion on the topics raised by the reviewer. We address their primary questions in order:\n\n------\n* **Intuition regarding catastrophic vs tempered overfitting for $p>2$:** It\u2019s best to see this through Figure 2.  The value of the linear splines stays between the value of the observed labels, and so in a sense are not too \u201ccrazy\u201d and their distance from the target is similar to the magnitude of the noise, hence the $L_p$ error (for any $p$) is proportional to that of $p$-th moment of the noise (the Bayes $L_p$ error), which corresponds to \u201c*tempered*\u201d overfitting (tempered here means excess error proportional to the Bayes error, or noise level). More technically, consider $f^* \\equiv 0$ for simplicity. The fitted function in any interval $[x_i,x_{i+1}]$ linearly interpolates between $y_i$ and $y_{i+1}$ and does not exceed the label values. Moreover, these labels are just noise random variables $\\varepsilon_i$ and $\\varepsilon_{i+1}$ when $f^* \\equiv 0$, thus, for linear splines the $L_p$ risk will be proportional to the $p$-th moment of noise random variables, which is the Bayes $L_p$ risk. \n\n    However, as illustrated in Figure 2, min norm neural nets prefer solutions with fewer \u201ckinks\u201d, which leads to spikes that go well \n    beyond the observed values.  With more points, there will be some extreme spikes, but these extreme spikes will also be *narrow*. \n    For higher $p$, the contribution of extreme spikes to the $L_p$ error is more significant (scaling as height$^p$), and $p=2$ is the tip-off point \n   where the thin and extreme spikes dominate the error. At a technical level, the height of the spike in the interval $[x_i,x_{i+1}]$ of length \n   $\\ell_i$ depends on the relative ratio of $\\ell_i$ and its neighboring intervals $\\ell_{i-1}$ and $\\ell_{i+1}$. Thus, if $\\ell_{i-1}$ and $\\ell_{i+1}$ are \"very small\u201d as compared to $\\ell_{i}$ then the effect of spikes would be large. The precise dependence on $\\ell_i$ s and $p$ in the risk comes up in eq 25, which is analyzed using the distributional properties of $\\ell_i$ s. Note that when the input is on the grid and the points are equally spaced, the relative ratio of $\\ell_{i}$ with $\\ell_{i-1}$ and $\\ell_{i+1}$ remains constant. Thus, the asymptotic risk is worsened but only by a constant factor from linear splines, and we get tempered overfitting for $L_p$ losses for any $p \\geq 1$.\n\n* **Linear splines vs min-norm networks:** The paper indeed establishes that if we insist on overfitting, then min-norm networks are more problematic than linear splines, and we are better off with linear splines.  But even better would be to not overfit in the first place and balance norm with training error, in which case low-norm networks would be better (e.g. for Lipschitz functions + noise, balancing network norm with training error would converge to the Bayes optimal predictor, whereas linear splines would be *\u201ctempered\u201d* with population error larger than Bayes optimal).  Disclaimer: the purpose of this paper is NOT to advocate for overfitting, but rather to study its effect, in line with recent interest in the topic.\n\n* We are not aware of work looking at min-$\\ell_1$-norm neural nets, and are not sure how they would behave, but this could be interesting to look at.\n\n* **\u201cMildly dependent\u201d:** It is an informal term used to give intuition, not in a formal context.  It roughly means that although the random variables are not, strictly speaking, independent, the effect of the dependencies is small, and vanishes as $n\u2192\\infty$.  This is again an informal statement\u2014-in our analysis, this dependence is taken care of precisely.\n\n* Note that $X$ is the sum of $(n+1)$ i.i.d. $\\textnormal{Exponential}(1)$. Thus, by the strong law of large numbers, as $n\u2192 \\infty$, $X/(n+1) \\rightarrow \\mathbb{E}[\\textnormal{Exponential}(1)]=1$ almost surely. By the laws of limits and the definition of almost surely convergence, this implies that $(n+1)/X \\rightarrow 1$ almost surely.\n\n------\n[1] Guy Kornowski, Gilad Yehudai, and Ohad Shamir. From tempered to benign overfitting in relu neural networks. arXiv preprint arXiv:2305.15141, 2023."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700609429118,
                "cdate": 1700609429118,
                "tmdate": 1700609429118,
                "mdate": 1700609429118,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UszVpeIUWs",
            "forum": "GTUoTJXPBf",
            "replyto": "GTUoTJXPBf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission774/Reviewer_9Vzu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission774/Reviewer_9Vzu"
            ],
            "content": {
                "summary": {
                    "value": "This paper delves into the nuanced behaviors of tempered overfitting and catastrophic overfitting within regression scenarios employing a min-norm two-layer ReLU network with skip connections. The key contribution lies in the establishment of significant results, notably demonstrating the occurrence of catastrophic overfitting when the $L_p$ loss is applied with $p\\geq2$. Furthermore, the paper uncovers the phenomenon of tempered overfitting, which surfaces when utilizing the $L_p$ loss with $1\\leq p<2$.\n\nIn a noteworthy extension of its findings, the paper also establishes that when working with samples distributed on a grid, tempered overfitting manifests for the $L_p$ loss with $p\\geq1$. These results shed valuable light on the interplay between loss functions, network architecture, and data distribution in the context of regression with min-norm ReLU networks."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "This paper is exceptionally well-crafted, boasting a highly organized structure that enhances its clarity and readability. The main paper is thoughtfully structured, and the presentation of the proof concept is remarkably accessible, thanks in part to the informative graphs provided.\n\nThe theoretical framework is excellent, as this paper conducts a comprehensive examination of the overfitting tendencies observed in min-norm ReLU networks within the context of regression. In doing so, it effectively bridges a critical gap, especially when contrasted with the closely related work by Kornowski et al. (2023), which primarily addressed overfitting within a classification setting."
                },
                "weaknesses": {
                    "value": "It appears that this paper can be regarded as a subsequent work to Boursier & Flammarion (2023). The connection is evident as the pivotal lemma (Lemma 2.1) employed in this paper is directly drawn from Boursier & Flammarion (2023). Furthermore, the neural network model studied in this paper aligns with the one extensively examined in Boursier & Flammarion (2023). Consequently, the technical innovation in this paper seems somewhat limited in this regard.\n\nIt's important to note that this paper adopts a one-dimensional perspective, assuming $x$ to be a single dimension, confined within the range $x\\sim[0,1]$. In contrast, Kornowski et al. (2023) considered high-dimensional $x$. Another differentiating factor is that this paper primarily focuses on characterizing the asymptotic behavior of population error and reconstruction error, while Kornowski et al. (2023) delved into an analysis that extends beyond the asymptotic realm.\n\nIn Theorem 4, which addresses catastrophic overfitting for $L_p$ with $p\\geq 2$, it is essential to note that only a specific case with $f^*=0$ is considered. To enhance the depth and relevance of the analysis, it would be particularly intriguing to explore this phenomenon with a more general $f^*$."
                },
                "questions": {
                    "value": "1. I have observed that in both your Theorem 1 and Theorem 2, you made the assumption that $f^*$ is a Lipschitz function. Assuming the Lipschitz constant is denoted as $c$, I am interested in understanding how the constants $C_p$ in Theorem 1 and the constant $C$ in Theorem 2 are related to this Lipschitz constant $c$.\n\n2. What would be the impact on the analysis if we were to assume that $f^*$ is Holder continuous instead of Lipschitz continuous in your main theorem? Could this alternative assumption be beneficial, given that you are dealing with $L_p$ loss in this context?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721776605,
            "cdate": 1698721776605,
            "tmdate": 1699636004761,
            "mdate": 1699636004761,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KC0LFRFolv",
                "forum": "GTUoTJXPBf",
                "replyto": "UszVpeIUWs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission774/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 9Vzu"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their thorough review and positive feedback on the work! \n\n------\n\nWe want to first address some of the points mentioned as weaknesses, where we see things differently:\n* **Novelty relative to Boursier and Flammarion [1]:** Indeed, we study the same model as in Boursier and Flammarion [1].  This is also the same model studied in several other papers (e.g. Severese et. al. [2], Ergen and Pilanci [4], Hanin [5], and many more). The main novelty is in the question we ask, which is completely different: none of the previous papers, including Boursier and Flammarion [1], asked how such a model overfits, i.e. how it behaves when interpolating noisy data. In particular, our main results do not appear in any way in previous papers. To answer this novel question we indeed build on a characterization given by Boursier and Flammarion [1], but this is just a component of our analysis.\n\n* **Limiting to one dimension:** This is indeed a limitation, which is shared also by many other papers studying low-norm ReLU networks (e.g. Boursier and Flammarion [1], Hanin [5], Severevse et. al. [2], Debarre et. al. [3] and others mentioned above) and in-fact also the Kornowski et. al. [6] paper mentioned.  Kornowski et. al.\u2019s treatment of higher dimensions is limited to simulations or the extreme case $d \\gg n^2$ (in which case learning is essentially linear and the overfitting is benign\u2014see paragraph 2 on page 1 and also the footnote)--they also do not have theoretical analysis for *fixed* dimensions beyond $d=1$.  Going beyond one dimension is very interesting, and we believe it is possible, but has proven to be difficult not only for us but also for the entire community.\n\n* **Considering** $f^* \\equiv 0$ **for catastrophic overfitting:** As this is a lower bound, we find it strongest to show that overfitting is catastrophic even in the easiest case, i.e. $f^* \\equiv 0$. Our result should be interpreted as: \"Even for such a simple target function $f^* \\equiv 0$, in the presence of noise, the interpolating predictor exhibits catastrophic behavior.\"  Overfitting will also be catastrophic with any Lipschitz target and non-zero noise. \n\n----\nBelow we answer their questions.\n\n* Our constant $C_p$ (in Theorem 1) only depends on $p$ and $C$ (in Theorem 2) is a universal constant (the dependence on $p$ is explicit). These constants do not have any dependence on the Lipschitz constant. Our result should be interpreted as \u201cas long as the Lipschitz constant is finite, the asymptotic $L_p$ risk is proportional to the Bayes $L_p$ risk, where the constant of proportionality only depends on $p$.\u201d Note that the dependence in the Lipschitz constant will show up in the non-asymptotic rates, but at least for the asymptotic results as we show here, the terms associated with the Lipschitz constant vanish as $n\u2192 \\infty$, and we get no dependence.\n\n* We believe our upper bounds of tempered overfitting continue to hold for any $(G,\\alpha)$ Holder continuous functions with $0<\\alpha \\leq 1$. The same phenomenon of transition from tempered to catastrophic at $p=2$ would occur. The primary reason we consider Lipschitz continuity is because the Lipschitz functions can be exactly represented by ReLU nets with bounded weights (see Boursier and Flammarion [1], Theorem 1). If the function is not Lipschitz, then its representation cost (minimum norm to represent the function exactly) is infinite. However, we agree that even if one cannot represent the function *exactly*, it is possible to talk about *approximation*, and it seems like the same analysis generalizes to even Holder continuous functions. The only difference is that now the terms with dependence on $G$ vanish but at a slower rate.\n\n-----\n[1] Etienne Boursier and Nicolas Flammarion. Penalizing the biases in norm regularisation enforces sparsity. arXiv preprint arXiv:2303.01353, 2023.\n\n[2] Pedro Savarese, Itay Evron, Daniel Soudry, and Nathan Srebro. How do infinite-width bounded norm networks look in function space? In Conference on Learning Theory, pp. 2667\u20132690. PMLR, 2019.\n\n[3] Thomas Debarre, Quentin Denoyelle, Michael Unser, and Julien Fageot. Sparsest piecewise-linear regression of one-dimensional data. Journal of Computational and Applied Mathematics, 406:114044, 2022.\n\n[4] Tolga Ergen and Mert Pilanci. Convex geometry and duality of over-parameterized neural networks. Journal of Machine Learning Research, 2021.\n\n[5] Boris Hanin. Ridgeless interpolation with shallow relu networks in 1d is nearest neighbor curvature extrapolation and provably generalizes on Lipschitz functions. arXiv preprint arXiv:2109.12960, 2021.\n\n[6] Guy Kornowski, Gilad Yehudai, and Ohad Shamir. From tempered to benign overfitting in relu neural networks. arXiv preprint arXiv:2305.15141, 2023."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700518262841,
                "cdate": 1700518262841,
                "tmdate": 1700612400815,
                "mdate": 1700612400815,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "JLZyg1HFBU",
            "forum": "GTUoTJXPBf",
            "replyto": "GTUoTJXPBf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission774/Reviewer_bbgZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission774/Reviewer_bbgZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper tries to understand the generalization performance of overparametrized neural networks when interpolating noisy training data. Specifically, the authors consider the univariate 2-layer ReLU networks in regression setting and focus on the min $\\ell_2$ norm interpolator. This paper shows that the generalization performance is subtle and depends on the factors such as the choice of loss at evaluation time and whether one is considering high probability case or taking expectation over the training samples. The overfitting is tempered (test loss neither goes to Bayes optimal nor to infinity) when loss is $L_p$ for $1<p<2$ and considering the high probability outcomes. The overfitting is catastrophic (test loss goes to infinity) when loss is $L_2$ or considering expectations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "-\tUnderstanding the generalization performance of interpolating solutions, especially non-linear interpolators such as ReLU networks, is an important and interesting question in deep learning theory.\n-\tThe paper gives a detailed characterization of the min $\\ell_2$ norm interpolating ReLU networks, compares it with the linear splines, and shows the subtle generalization performance depending on the loss function. I believe this is a good result and it seems to be novel in the literature of implicit bias and benign overfitting.\n-\tThe paper is overall well-written and easy-to-follow."
                },
                "weaknesses": {
                    "value": "-\tThe paper focuses on the univariate ReLU networks which is relatively simple. (though it is understandable from technical point of view)\n-\tThe results are in the asymptotic regime that sample size $n$ goes to infinity. Thus, it does not give explicit rate of convergence."
                },
                "questions": {
                    "value": "-\tThe results in this paper seem to consider the asymptotic regime that sample size $n$ goes to infinity. I was wondering if there is a rate for this asymptotic convergence.\n-\tI was wondering if the min-norm interpolation considered in the paper can be naturally reached based on the implicit bias of some simple algorithms. For example, the authors mentioned that Shevchenko et al. showed similar spikes as the current paper. Does their algorithm exactly lead to the same implicit bias here?\n-\tI wonder if results like Theorem 1 and Theorem 5 are enough to say they are tempered overfitting, as they are only upper bound on the test loss. I feel there needs to also have a lower bound on the test loss?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698772867374,
            "cdate": 1698772867374,
            "tmdate": 1699636004689,
            "mdate": 1699636004689,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YumPevXoFU",
                "forum": "GTUoTJXPBf",
                "replyto": "JLZyg1HFBU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission774/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Adressing the questions of Reviewer bbgZ"
                    },
                    "comment": {
                        "value": "We seriously thank the reviewer for their constructive feedback! Below we address the questions.\n\n* In line with other papers on interpolation learning, we indeed provide an asymptotic characterization (benign/tempered/catastrophic).  Obtaining a finite sample bound on the convergence (or divergence) would require additional assumptions (which we preferred not to get into in order to keep the paper focused\u2014e.g. our results do not depend on the Lipschitz constant, only on it being finite) but should be possible using standard concentration inequalities and a more elaborate analysis.\n\n* As we explain on page 2, the precise implicit bias of GD (and even Shevchenko et. al. [1]\u2019s analysis) does not guarantee that min-norm interpolators are reached. However, we note that the main property of min-norm interpolators that determines the overfitting behavior in our analysis is the formation of \u201cspikes\u201d, and such spikes are empirically observed while interpolation with GD in Shevchenko et. al. [1]. Thus, studying min-norm interpolators with these properties is a good starting point. Moreover, considering the min-norm interpolator is natural when training with small weight decay.\n\n* Indeed, for linear splines (warmup) and data on the grid (contrast analysis), we do not explicitly provide lower bounds showing that overfitting is tempered rather than benign.  These are fairly straightforward and we will include them in the final version for completeness. Thanks for pointing this out! To be clear: we do provide lower bounds in the main analysis (min-norm neural nets on i.i.d. samples), just not for the warmup and the contrast analysis. \n-----\n[1] Alexander Shevchenko, Vyacheslav Kungurtsev, and Marco Mondelli. Mean-field analysis of piecewise linear solutions for wide relu networks. The Journal of Machine Learning Research, 23(1): 5660\u20135714, 2022."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700501485265,
                "cdate": 1700501485265,
                "tmdate": 1700610119998,
                "mdate": 1700610119998,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0XECdiDA6l",
                "forum": "GTUoTJXPBf",
                "replyto": "YumPevXoFU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission774/Reviewer_bbgZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission774/Reviewer_bbgZ"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the responses. I will keep my score."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700714315977,
                "cdate": 1700714315977,
                "tmdate": 1700714315977,
                "mdate": 1700714315977,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]