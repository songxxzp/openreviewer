[
    {
        "title": "Gandalf: Learning label correlations in Extreme Multi-label Classification via Label Features"
    },
    {
        "review": {
            "id": "WWythtt6L4",
            "forum": "JuyFppXzh2",
            "replyto": "JuyFppXzh2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9159/Reviewer_pzXY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9159/Reviewer_pzXY"
            ],
            "content": {
                "summary": {
                    "value": "Gandalf, a novel approach which makes use of a label correlation graph to leverage label features as additional data points to supplement the training distribution. Their approach can be applied in a plug-and-play manner with several existing methodologies, leading to a 30% performance improvement. The authors focus on the short-text setting where they exploit the symmetry between inputs and labels to obtain improved learning of label correlations. They propose an approach leverages the innate symmetry of short-text XMC along the LCG to construct valid data-points."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* The approach can be applied in a plug-and-play manner with several existing methodologies - the results of which have been demonstrated in Table 2. \n* They have used publicly available benchmark datasets to evaluate their results.\n* Gandalf shows relatively large improvement of 30% over 5 state-of-the-art algorithms across 4 benchmark datasets."
                },
                "weaknesses": {
                    "value": "* The authors focus on short text. While it is widely used across the industry, it will be good to demonstrate why their approach is better for short text when compared to other approaches. In a sense what makes the approach more suited for short-text? At the same time, would the approach work on large text as well?\n\n* It will be great if the authors can elaborate on the \"Symmetric nature of short-text XMC\". An example to illustrate the symmetric form would strengthen the reasoning for utilizing the symmetry. Especially when the paper in a way hinges on the utilizing the symmetry along with the label correlation graph; LCGs have been used in other approaches.\nAs a result, the novelty seems limited. \n\n*Along the same lines, it will greatly help if the authors can detail how the approach can handle the sparse instance-to-label mapping present in the datasets.  \n\n\nA minor issue: I believe there are a few missing references in the paper and the supplemental material."
                },
                "questions": {
                    "value": "Addressed in the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698821304046,
            "cdate": 1698821304046,
            "tmdate": 1699637152895,
            "mdate": 1699637152895,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "u2G0gDAzxd",
                "forum": "JuyFppXzh2",
                "replyto": "WWythtt6L4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9159/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the review. Each argument is considered below:\n\n > The authors focus on short text. While it is widely used across the industry, it will be good to demonstrate why their approach is better for short text when compared to other approaches. In a sense what makes the approach more suited for short-text? At the same time, would the approach work on large text as well?\n\nThe approach is particularly well suited for short input text problems such as those encountered in prediction of Related Searches on a search engine or suggestion of similar product titles in response to a user\u2019s purchase/interest of a product on a recommender system. Apart from both the inputs (by the user) and the prediction/recommendation (by a machine learning system) being of short-text nature, these come from the same space. One could equally well replace a prediction by the ML system as an input by a user, making them interchangeable. This is no longer true in long-text problems such as that of assigning tags (with few words) to Wikipedia articles with hundreds of input words. \n\n> It will be great if the authors can elaborate on the \"Symmetric nature of short-text XMC\". An example to illustrate the symmetric form would strengthen the reasoning for utilizing the symmetry. Especially when the paper in a way hinges on the utilizing the symmetry along with the label correlation graph; LCGs have been used in other approaches. As a result, the novelty seems limited.\n\nTwo examples highlighting the symmetric nature of the input and outputs in the short-text XMC problems have already been provided in the Preliminaries section of our paper. We would like to clarify that \u201csymmetry\u201d in the paper refers to the interchangeability of the input data points and the label features, and NOT the fact that \u201cmatrix representing the label correlation graph is symmetric\u201d. It is important to remark that the novelty of our approach stems from exploiting the problem structure to propose an efficient and effective data augmentation technique leading to significant performance improvements in prediction accuracy, and not from the choice of LCG.\n\n> *Along the same lines, it will greatly help if the authors can detail how the approach can handle the sparse instance-to-label mapping present in the datasets. \n\nWe would like to highlight that all XMC methods handle the sparsity issue by leveraging one-vs-all classifiers. While some approaches directly employ these classifiers [DiSMEC, XR-Linear], the others perform curriculum learning where they first train on a surrogate task where the model is trained on relatively denser instance-to-meta-label mappings by clustering labels into meta labels. Many approaches have also successfully leveraged label-clusters in different ways [AttentionXML, XR-Transformer, CascadeXML]. We do not propose a new approach to tackle this issue. Rather, the proposed Gandalf augmentation enables existing XMC models to learn label-label correlations from this sparse mapping that were previously being missed."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700470590046,
                "cdate": 1700470590046,
                "tmdate": 1700470913871,
                "mdate": 1700470913871,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6Cj5ySQMT6",
            "forum": "JuyFppXzh2",
            "replyto": "JuyFppXzh2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9159/Reviewer_tePQ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9159/Reviewer_tePQ"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a data augmentation method called Gandalf which leverage label correlation as additional data points against short-text extreme multi-label text classification problem. The presented experiment results show Gandalf is able to improve the performance on other extreme classifiers on several benchmark datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1)\tThe proposed data augumentation idea is relatively simple and work effectively on several benchmark datasets.\n\n2)\tThe empirical studies are relatively abundant."
                },
                "weaknesses": {
                    "value": "1) The underlying idea of the main method a little bit lacks novelty and seems an extension of the existing work likes ECLARE.\n\n2) The method does not contribute to the real-world settings as most XMC methods choose to make partial experiments on long-text benchmark datasets. Besides, the method seems to increases the overhead of training datasets which may cause limitations."
                },
                "questions": {
                    "value": "1)\tWhy classical XMC problems like AttetionXML, SiameseXML++ are not experimented with Gandalf?\n\n2)\tIt seems that the proposed Gandalf does not give competitative performance on PSP metrics compared to existing methods. Do you think Gandalf is an effective method dealing with the tail labels in XMC problem?\n\n3)\tCan Gandalf work on long-text XMC datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698823182740,
            "cdate": 1698823182740,
            "tmdate": 1699637152770,
            "mdate": 1699637152770,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SA5oM0MJPM",
                "forum": "JuyFppXzh2",
                "replyto": "6Cj5ySQMT6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9159/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your constructive comments. We rebut each point below:\n\n> The underlying idea of the main method a little bit lacks novelty and seems an extension of the existing work likes ECLARE.\n\nTo the best of our knowledge, this is the first method which proposes a generalisable data augmentation in XMC that leads to significant improvements over a variety of baselines methods. ECLARE is only related to our approach in that their proposed label correlation graph is one of the possible ways to annotate label features. This is merely an implementation detail, and our novelty lies in the way we annotate label features with label correlations. \n\nMore specifically, ECLARE uses the LCG to generate an additional feature \"graph-augmented label embedding\" i.e. GALE, whereas Gandalf uses the LCG to get the supervised classifier targets for label features. This has also been mentioned in \u201cGandalf vs ECLARE\u201d under section 5.2 of the revised submission.\n\n> The method does not contribute to the real-world settings as most XMC methods choose to make partial experiments on long-text benchmark datasets. Besides, the method seems to increase the overhead of training datasets which may cause limitations.\n\nWe would like to reiterate that short-text XMC has a very high impact in the real-world, as also acknowledged by Reviewer pzXY. It forms the backbone for search queries on leading search engines and product recommendation systems and for ad-phrase matching [DECAF, ECLARE, SiameseXML, NGAME]. For computational overheads, please refer to the common rebuttal.\n\n> Why classical XMC problems like AttetionXML, SiameseXML++ are not experimented with Gandalf?\n\nFor short-text problems, our method is also applicable to AttentionXML, which has been superseded by many recent state-of-the-art methods. SiameseXML does not use traditional XMC losses(Binary Cross-Entropy Loss, Hinge Loss, Squared Hinge Loss). Instead, it uses a customized loss named \u201ckProbContrastive\u201d in code and explained in the paper. Our method is suitable for traditional XMC losses, and we show that using Gandalf is sufficient to outperform such especially designed loss functions.\n\nThrough our experiments, we find that modifying Astec with Gandalf is more beneficial than modifying it with SiameseXML training schedules and loss functions (Note that Astec and SiameseXML use the same architecture).\n\n> It seems that the proposed Gandalf does not give competitative performance on PSP metrics compared to existing methods. Do you think Gandalf is an effective method dealing with the tail labels in XMC problem?\n\nContrary to the reviewer\u2019s assertion that Gandalf does not improve upon PSP metrics, we would like to bring to attention Table 2, where Gandalf consistently increases the outperforms the unaugmented models, with absolute improvements up to 10 additional points on the PSP metrics. This shows its  effectiveness in dealing with tail labels. \n\nThis has further been shown in Figure 2, where we show the P@5 scores with consistent improvements, particularly on head and tail labels.\n\n> Can Gandalf work on long-text XMC datasets?\n\nGandalf is rooted in the fact that the input data points and label features are symmetric in nature. Paraphrasing our arguments from \u201cSymmetric nature of short-text XMC with Label Features\u201d in the manuscript, this symmetry arises from both of them being short-text features. Since this does not hold for long-text datasets, as also mentioned in the \u201cConclusion\u201d, it does not directly apply for such scenarios. \n\nData augmentation for long-text problems could potentially involve using an external source such as an LLM to generate similar passages to input long-text data points without changing the label annotations. Unlike Gandalf this could be much more computationally expensive and beyond the scope of our paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471042960,
                "cdate": 1700471042960,
                "tmdate": 1700471596530,
                "mdate": 1700471596530,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "adD28lkoss",
            "forum": "JuyFppXzh2",
            "replyto": "JuyFppXzh2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9159/Reviewer_Wc5R"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9159/Reviewer_Wc5R"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes Gandalf, which augments the training dataset in extreme classification by using label features as documents, with their corresponding \u201clabel mapping\u201d being constructed using a label-label graph. Such a setup allows most existing extreme classifiers to now leverage label features for improved generalization, without any changes to the training pipeline and no added inference cost. Gandalf shows significant improvement in both Precision and Propensity-scored Precision metrics over four commonly used extreme classification datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed methodology is architecture-agnostic thereby resulting in easy and widespread adoption.\n- Consistently improved performance for a variety of extreme classifiers, especially for tail labels."
                },
                "weaknesses": {
                    "value": "- The training time will be significantly increased since the new number of training points will be number of documents + number of labels. And in typical extreme classification setups, the number of labels can be much greater than the number of available documents.\n- The approach assumes (1) label features exist in the same input space as documents; and (2) the extreme classifier is NOT a two-tower approach, and embeds the labels and documents in the same space."
                },
                "questions": {
                    "value": "- What if you use graphs other than the random-walk graph in ECLARE? For example, the co-occurrence graph?\n- Why should the performance of classifiers that already use label-features (e.g., ECLARE, DECAF) improve with Gandalf?\n- To combat the increased training cost, it would be interesting to understand the sample efficiency of Gandalf. To be more specific, how much performance is improved when augmenting, e.g., {0, 25, 50, 75, 100}% of random labels to the training data?\n- Missing citations in multiple places in the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9159/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9159/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9159/Reviewer_Wc5R"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698926610740,
            "cdate": 1698926610740,
            "tmdate": 1699637152641,
            "mdate": 1699637152641,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xjKI9YW73c",
                "forum": "JuyFppXzh2",
                "replyto": "adD28lkoss",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9159/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the review. Each argument is considered below:\n\n> The training time will be significantly increased since the new number of training points will be number of documents + number of labels. And in typical extreme classification setups, the number of labels can be much greater than the number of available documents.\n\nThis has been answered in the common rebuttal, and added to Appendix C of the revised submission.\n\n> The approach assumes (1) label features exist in the same input space as documents; and (2) the extreme classifier is NOT a two-tower approach, and embeds the labels and documents in the same space.\n\nWe believe there has been a misunderstanding and the below two points have been confused:\n* The idea that label features co-exist in the same distribution as input queries is a well-accepted and proven fact in short-text XMC that has been leveraged in former two-tower XMC approaches like SiameseXML and NGAME.\n* Two-tower approaches predominantly only make use of an encoder and are trained for retrieval tasks. By extreme classifiers we essentially imply encoders with an additional large classifier component i.e. the last classification layer having the number of weight vectors equal to the number of labels. \nPlease check \u201cTwo-tower Models & Classifier Learning '' under \u201cRelated Work\u201d for further discussion. \n\n> What if you use graphs other than the random-walk graph in ECLARE? For example, the co-occurrence graph?\n\nWe tried this experiment and provide scores on InceptionXML below. While this also leads to improvements over baselines, it still does not surpass the gains obtained from LCG (ECLARE). We posit that this is due to extra correlations being captured via random walk in the latter.\n* LF-AmazonTitles-131K: P@1: 41.39, P@3: 26.93, P@5: 19.41, PSP@1: 34.38, PSP@3: 40.81, PSP@5: 45.13\n* LF-WIkiSeeAlsoTitles-320K: P@1: 29.64, P@3: 19.78, P@5: 15.04, PSP@1: 22.81, PSP@3: 25.18, PSP@5: 26.96\n\n> Why should the performance of classifiers that already use label-features (e.g., ECLARE, DECAF) improve with Gandalf?\n\nClassifiers like ECLARE and DECAF incorporate architectural strategies in order to capture higher order document-label correlations. In this work, we aim to learn label-label correlations which were not captured by previous models. Gandalf is designed to explicitly capture label-label correlations, which leads to significant improvements. This has also been discussed in Section 5.2, \u201cGandalf vs ECLARE\u201d.\nTo combat the increased training cost, it would be interesting to understand the sample efficiency of Gandalf. To be more specific, how much performance is improved when augmenting, e.g., {0, 25, 50, 75, 100}% of random labels to the training data?\nThat is an interesting idea! We tried this and added the results in Appendix C.2. Summarizing:\n* As suggested, we randomly sample {0, 25, 50, 75, 100}% of the labels and augment the training dataset with their annotations from Gandalf. With random sampling, we note a near linear increase in scores with an increasing number of labels in the dataset. This signifies the importance of learning label-label correlations, and the efficacy of Gandalf towards this goal.\n* Moreover, we also perform this sampling while prioritizing tail labels. More specifically, we sample {0, 25, 50, 75, 100}% of the labels from equi-voluminous bins of labels of increasing frequency. This implies that the added labels would primarily be tail labels for lower sampling percentages. We note that this consistently outperforms the random sampling baselines, with improvements even on the PSP@5 metric. This experiment shows that Gandalf is also useful in tackling the data-scarcity issue in XMC."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700471023638,
                "cdate": 1700471023638,
                "tmdate": 1700471023638,
                "mdate": 1700471023638,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5siZhvY8Fq",
                "forum": "JuyFppXzh2",
                "replyto": "xjKI9YW73c",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9159/Reviewer_Wc5R"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9159/Reviewer_Wc5R"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thank you for your response and additional experiments. I would like to stick to my original rating."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733891796,
                "cdate": 1700733891796,
                "tmdate": 1700733891796,
                "mdate": 1700733891796,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3lWGRa4ztm",
            "forum": "JuyFppXzh2",
            "replyto": "JuyFppXzh2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9159/Reviewer_S9V4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9159/Reviewer_S9V4"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies Extreme Multi-label Text Classification (XMC) problems, which assigns a short text input sample with a subset of most relevant labels from millions of label choices. The principal difficulty in XMC is managing the vast array of possible classes. Building upon existing research, this work incorporates the textual features of labels into the classifier's training process. Especially, given that input samples often share common tokens with the labels they're associated with, this task becomes correlating short text inputs with related sets of text.  For example, the input sample \u201c2022 French presidential election\u201d could be associated with \u201cApril 2022 events in France\u201d,  \u201c2022 French presidential election\u201d, \u201c2022 elections in France\u201d, \u201cPresidential elections in France.\u201d\n\nWhile previous research has explored various methods for aligning input and label texts, this paper proposes a straightforward technique for data augmentation, illustrated in Figure 1. It enhances the original N*L training data matrix with an additional L*L matrix, which captures the interrelationships between the L labels. The results from experiments suggest that this enrichment with the L*L matrix enables established XMC classifiers to attain better accuracy in classification tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1)\tThe data augmentation concept introduced in this paper is refreshingly straightforward, offering an intuitive strategy to expand the training dataset.\n2)\tEmpirical assessments indicate that incorporating this additional data into the training process proves beneficial."
                },
                "weaknesses": {
                    "value": "1.\tThe augmented dataset introduced is considerably large, e.g., potentially consisting of a large matrix in size of millions by millions. The training time will be significantly increased.  While it's true that this does not affect the inference time, it substantially extends the duration of the training phase due to the increased volume of data.\n2.\tThe two-tower model \u201cNGAME + classifier\u201d yields the highest performance on the Amazon datasets. Even with the introduction of additional data, the base algorithms do not surpass the efficacy of the two-tower. \n3.\tSome reference citations are missing: Zhang et al., 2021a; ?; Lu et al., 2022),  ANCE (?)"
                },
                "questions": {
                    "value": "1)\tWhat is the computation cost for training the base algorithms when taking the additional L*L matrix? including the process of obtaining the L*L matrix.  It would be beneficial for the paper to detail the expected impact on the training duration.\n2)\tWhy there is no evaluation of two-tower models on the two wiki-dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9159/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699195530715,
            "cdate": 1699195530715,
            "tmdate": 1699637152535,
            "mdate": 1699637152535,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GfTkpzvzI2",
                "forum": "JuyFppXzh2",
                "replyto": "3lWGRa4ztm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9159/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9159/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the review. Each argument is considered below:\n\n> The augmented dataset introduced is considerably large, e.g., potentially consisting of a large matrix in size of millions by millions. The training time will be significantly increased. While it's true that this does not affect the inference time, it substantially extends the duration of the training phase due to the increased volume of data. & What is the computation cost for training the base algorithms when taking the additional LL matrix? \n\nPlease refer to \u201cAdditional Training Time and Computational Cost\u201d in the Common Rebuttal\n\n> The two-tower model \u201cNGAME + classifier\u201d yields the highest performance on the Amazon datasets. Even with the introduction of additional data, the base algorithms do not surpass the efficacy of the two-tower. \n\nWhile the two-tower model,  \u201cNGAME + classifier\u201d yields the highest performance on the Amazon datasets, it must be noted that it uses a 6 layer DistilBERT as its encoder, in comparison to the frugal MLP encoders used in our experiments. We do, in fact, demonstrate the efficacy of Gandalf over two-tower models by comparing with \u201cSiameseXML++ + Classifier\u201d, which proposes a two-tower model on a frugal MLP encoder. While this was mentioned in the manuscript in Table 2, we have made it clearer in the revised submission. Reiterating, all baselines above the double line denote transformer based encoders, and below it denote MLP encoders. The * denotes two-tower approaches, as mentioned in the caption.\n\n> Why there is no evaluation of two-tower models on the two wiki-dataset?\n\nAs a standard practice in the domain, recent papers only evaluated the performance of \u201cDense Retrieval Two Tower\u201d approaches on Amazon Datasets. \nThe two-tower model scores have been taken from previous publications which have not reported their scores for the wiki-datasets. Provided that it is non-trivial to run DR models directly on XMC datasets and due to our restricted computational budget, we could not run the heavy DR models on these datasets ourselves."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9159/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700470839304,
                "cdate": 1700470839304,
                "tmdate": 1700470888185,
                "mdate": 1700470888185,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]