[
    {
        "title": "An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment"
    },
    {
        "review": {
            "id": "7TtbnTi743",
            "forum": "mE52zURNGc",
            "replyto": "mE52zURNGc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3498/Reviewer_1Yhm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3498/Reviewer_1Yhm"
            ],
            "content": {
                "summary": {
                    "value": "This paper builds on the Gauss-Newton loss and establishes a closed-form solution for the expected optimum of this loss; it doesn't depend on the specific feature representation being used, and it enables the adjustment of the convergence basin based on assumptions about the uncertainty in the current estimates. This provides a means to effectively control the convergence properties of the algorithm. Notably, even when employing self-supervised feature embeddings, this approach attains impressive accuracy compared to the SOTA direct image alignment methods that are trained end-to-end with pose supervision. Furthermore, it demonstrates enhanced robustness in terms of pose initialization."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "To the best of my knowledge, the closed-form derivative of the Gauss-Newton loss is innovative, and its effectiveness has been confirmed through empirical evaluation within the domain of direct image alignment, specifically with self-supervised feature descriptors - SuperPoint. What's particularly noteworthy is that this derivative can be applied to other areas to encompass methods employing backpropagation through Gauss-Newton or Levenberg-Marquardt optimization, among others."
                },
                "weaknesses": {
                    "value": "No major weakness. \n1. It would be interesting to see more discussions on the insight to the end-to-end learning framework's limitation, and a solution to that.\n2. It would be interesting to see this approach handles outliers inherently.\n3. It would be interesting to see this approach is applied to other areas."
                },
                "questions": {
                    "value": "N/A"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3498/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698642881264,
            "cdate": 1698642881264,
            "tmdate": 1699636302911,
            "mdate": 1699636302911,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7xdWKmqGSY",
                "forum": "mE52zURNGc",
                "replyto": "7TtbnTi743",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3498/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3498/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your insightful suggestions and positive review. We are glad to hear that you consider our contribution innovative.\n\nRegarding the points raised in the weaknesses section, they indeed present interesting directions for further research. We are currently exploring the feasibility of end-to-end network training with our closed-form solution. In our preliminary experiments, we have found that backpropagation through this solution poses challenges due to numerical instability, and we are actively investigating potential solutions to this issue.\n\nAs we explain in the Implementation Details appendix, we currently address outliers only at the feature alignment stage. To manage outliers prior to the feature map creation stage (on the point of interest\u2019s level), information from both reference and target images is required. However, our map creation process is based solely on a single image.\n\nWe are also excited about the prospect of applying our method in other domains.\n\nOnce again, thank you for your valuable feedback and support."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700149778132,
                "cdate": 1700149778132,
                "tmdate": 1700149778132,
                "mdate": 1700149778132,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HTdd8YnT6G",
            "forum": "mE52zURNGc",
            "replyto": "mE52zURNGc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3498/Reviewer_TZP4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3498/Reviewer_TZP4"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a closed-form solution to the Gauss-Newton loss in the field of direct image alignment. This method allows for dynamic control of the convergence basin to improve the robustness of the alignment to pose initialization. Moreover, the proposed method shows the intrinsic limitations of employing Gauss-Newton loss in deep learning, which offers an insight between direct image alignment and feature matching. The simulation experiments have shown its superior performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe paper provides an analytical solution to the Gauss-Newton loss, which is a novel technology for generating a dense feature map.\n2.\tThe paper shows the inherent limitations of feature learning with backpropagation via the Gauss-Netwon optimization.\n3.\tThe paper is well-organized and shows the explicit introduction to notion of the Gauss-Newton."
                },
                "weaknesses": {
                    "value": "1.\tThe paper is required to give more comparisons with state-of-the-art in terms of accuracy of SE3\n2.\tCan the authors provide more training details of the proposed method, for example, the feature embedding network E, the learning rate, the batch size."
                },
                "questions": {
                    "value": "See the weakness part"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3498/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3498/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3498/Reviewer_TZP4"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3498/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698681774341,
            "cdate": 1698681774341,
            "tmdate": 1699636302841,
            "mdate": 1699636302841,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yF8MFL8EPz",
                "forum": "mE52zURNGc",
                "replyto": "HTdd8YnT6G",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3498/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3498/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your valuable review and for acknowledging the novel aspects of our work.\n\nIn response to your first point about comparing our method with state-of-the-art methods in terms of SE3 accuracy, we have conducted extensive evaluations across various well-known datasets. Our comparisons, as detailed in the paper (e.g., in Table 1), focus on the Recall with respect to translation and rotation thresholds, which directly reflect the accuracy of the estimated SE(3) camera pose. If there are specific datasets or aspects that you believe we may have overlooked, we would appreciate your guidance to further enhance our comparative analysis.\n\nRegarding your second point on the absence of training details, our method does not involve a traditional training process. However, it does leverage self-supervised SuperPoint descriptors. We will make it clearer in the updated manuscript.  \n\nThank you once again for your valuable feedback."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700149630785,
                "cdate": 1700149630785,
                "tmdate": 1700149630785,
                "mdate": 1700149630785,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "oiz1rIFp52",
                "forum": "mE52zURNGc",
                "replyto": "yF8MFL8EPz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3498/Reviewer_TZP4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3498/Reviewer_TZP4"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks. The authors have addressed my concerns."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700487689409,
                "cdate": 1700487689409,
                "tmdate": 1700487689409,
                "mdate": 1700487689409,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UBLigz03qp",
            "forum": "mE52zURNGc",
            "replyto": "mE52zURNGc",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3498/Reviewer_hDb9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3498/Reviewer_hDb9"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the task of Direct Image Alignment, which is used to estimate the relative 6DoF pose between two images. The task is strongly affected by pose initialization, which has been addressed by prior art by switching to optimization methods that increase the convergence basin, such as the Gauss-Newton loss. The authors claim that these prior methods induce bias towards the training data which limits their generalization. \nThe papers main contribution addresses this problem. The authors introduce an analytical close from solution to the Gauss-Newton loss. This solution is independent of the feature representation and enables adjustment of the convergence basin based on the uncertainty in current estimates, giving control over the algorithm\u2019s convergence properties. This property is used during the experimental evaluation, where optimization is first performed on a uniform distribution with a wider range, but then is switched out to a Gaussian with an increasingly narrowing distribution. \nTheir secondary contributions are insights that the analytical solution provides. Specifically, they show that under their simplified conditions, the Gauss-Newton step is determined by the neighboring points of interest. The author conclude that this is inherently limiting in comparison to other optimization methods. \nExperimental results demonstrate superior performance in almost all results over supervised state-of-the-art methods using self-supervised descriptors. \nThe appendix provides further insights on the derivations, as well as more interesting experimental results."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1) Well-written paper. It was a joy to read. It explains the context of the problem well, as well as establishing the necessary preliminary knowledge before delving into its actual contribution. There is a minor exception to this for the derivations (see Weaknesses)\n2) Under the simplifying assumption that eps follows an isotropic Gaussian, the authors derive a close-form solution to the minimizer of the Gauss-Netwon loss in expectation. Under the assumption that the authors claim about poor generalization due to training-data-biased feature maps holds (see Weaknesses), the proposed solutions has the main advantage that it provides unbiased feature map. In addition, it provides the ability to control the basin of convergence, which in turn makes the proposed method more robust to bad initialization (cf. Fig 3). Lastly, the assumed simplification which was necessary to derive the closed-form solution has been shown to lead to negligible differences (cf. Fig 5)\n3) Using self-supervised features, the proposed method is capable of outperforming supervised related work on almost all metrics. This is a strong statement, as the method can be used in conjunction with large and powerful foundation models, enabling bigger generalization due to the superior dataset sizes of such models. Therefore it is complimentary to these works.\n4) The authors provide an interesting insight when using Gauss-Newton as feature matching and indicate that it may be inherently limited. This is important for informing future work in optimization-based methods. Further analysis also shows that joint training of both losses for L_GN may lead to numerical instability and may shed light on reported training divergence of prior work."
                },
                "weaknesses": {
                    "value": "1) My biggest gripe with the paper is that their claim that motivates the approach is not empirically validated and there is no mention of such validation elsewhere. The authors claim both in the abstract as well as in the appendix that prior art use feature maps that may embed the inductive bias of the training data. While I can comprehend the underlying reasoning, such a claim needs to be empirically shown. \nFor example, an experiment on out-of-distribution test sets demonstrating the superiority of the closed-form solution would back the authors claims and in turn strengthen the paper.\n2) On the same topic of bias, I argue that the authors should explicitly state that their method still exhibits bias, but that the source of this is the underlying feature representation (result of this can be seen in Tbl. 1, Aachen Night dataset). Otherwise it may read that the authors claim their method is not biased. This is stated at the end of Section 3, but I think it should be stated clearly in either Abstract, Introduction and Conclusion section. This is a minor point however and only serves to improve clarity.\n3) A little contradictory to my point in the Strengths section, I believe the math heavy section 4 and 5 could be made a little more clearer when derivations skip multiple steps. Otherwise the sections read as if one equation immediately follows from the other, which is not always the case. (e.g Eq 6. -> Eq. 7). This would enhance the readability of the paper.\n4) On the Aachen-Night dataset, the proposed method clearly suffers. The authors claim that this is due to the underlying feature representation used, which was not trained day-night correspondences. While I find the reasoning sound, it would help the authors claim to have used a feature representation that have used such correspondences during training. This in turn would again strengthen the papers contribution and indicate that it can work in different settings."
                },
                "questions": {
                    "value": "Questions:\n- Eq. 23 leads to numerical instability. Is there a way to avoid this for stochastic optimization?\n- Fig. 4) The median is stable for all tested errors. For what ranges does this hold? I.e How far can the initial error be?\n- Fig. 4) Is there a similar plot for translation?\n\nComments:\n- Sec 2, Image Alignment: Add the variable T to make the text more consistent with the rest -> \"(...) estimate the relative 6DoF camera pose T.\""
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3498/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3498/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3498/Reviewer_hDb9"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3498/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698713466086,
            "cdate": 1698713466086,
            "tmdate": 1699636302767,
            "mdate": 1699636302767,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6bnbGB5psV",
                "forum": "mE52zURNGc",
                "replyto": "UBLigz03qp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3498/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3498/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your comprehensive review of our paper and for acknowledging its strength.\n\nWe have taken your feedback into consideration and have accordingly modified the manuscript to address the key points you raised:\n1) To empirically support our claim regarding the inductive bias of training data, we have added additional analysis to Appendix A. \n2) We have refined our claim on the absence of bias in our method (at the end of Sec. 3) to make it more concrete. \n3)  We modified the transition between Eq. 6 and Eq. 7 to show that there is no direct connection between them.\n4) We agree that using a feature representation trained on day-night correspondences would be a significant enhancement. Unfortunately, we could not find an off-the-shelf feature embedder trained for the day-night pairs.\n(Note that training such a feature embedder would require supervision.)\n\nAdditionally, we have addressed your questions in the revised manuscript:\n\nThe revised version of Fig. 4 now contains an extended analysis of the stability of the median error across broader ranges.\n\nWe have added a corresponding plot for robustness w.r.t. translation to supplemental material.\n\nWe are currently exploring the feasibility of end-to-end network training with our closed-form solution, but addressing all issues lies beyond the scope of this work. \n\nThank you again for your valuable feedback and for supporting our work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700384443543,
                "cdate": 1700384443543,
                "tmdate": 1700384443543,
                "mdate": 1700384443543,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XyGSVsfgPZ",
                "forum": "mE52zURNGc",
                "replyto": "UBLigz03qp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3498/Reviewer_hDb9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3498/Reviewer_hDb9"
                ],
                "content": {
                    "title": {
                        "value": "Points addressed"
                    },
                    "comment": {
                        "value": "I thank the authors for addressing the points raised in my review. It is a pity that a day-night correspondence feature representation experiment could not be performed, but I understand the authors reasoning.\n\nAs I already voted for acceptance, I will keep my original voting."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685498494,
                "cdate": 1700685498494,
                "tmdate": 1700685570313,
                "mdate": 1700685570313,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]