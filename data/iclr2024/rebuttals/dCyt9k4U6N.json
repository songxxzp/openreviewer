[
    {
        "title": "FLNERF: 3D FACIAL LANDMARKS ESTIMATION IN NEURAL RADIANCE FIELDS"
    },
    {
        "review": {
            "id": "e6ZjQT1YEb",
            "forum": "dCyt9k4U6N",
            "replyto": "dCyt9k4U6N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1671/Reviewer_Mp21"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1671/Reviewer_Mp21"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, a facial landmark detection algorithm is proposed on the NeRF-generated 3D face images. The proposed method follows the coarse-to-fine approach. It first samples the 3D face image from face NeRF. It then detects the coarse facial landmark locations given the frontal face. Then, the fine model will refine the accurate landmark locations based on the estimated coarse locations from the previous step. The experimental results have been conducted to demonstrate the effectiveness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "It is interesting to see the facial landmark detection algorithm on the face NeRF images. The final detection accuracy seems to be significantly better than the other works."
                },
                "weaknesses": {
                    "value": "The 3D facial landmark detection algorithm itself is straightforward. Once the 3D face is sampled from face NeRF, a typical detection algorithm is used.\n\n=================================\nAfter carefully reading the comments from the other reviewers. I do agree that the experiments are limited. Therefore, lower my rating."
                },
                "questions": {
                    "value": "The authors should further justify the novelty of the proposed method.\nIt is not very clear how the feature and loss function are selected in the coarse model in Equations 3) and 4). \nThe authors should justify if the comparison of the proposed methods with other baseline methods in Table 1 is fair. Some of the baseline methods are only using 1 image for 3D detection. It is also not clear how the `triangulation` based method is done if detection is only from 1 2D image.\nIs that possible to directly train/detect facial landmarks during face NeRF construction or to learn the mapping between face NeRF images and 3D landmark locations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1671/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1671/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1671/Reviewer_Mp21"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1671/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698642806286,
            "cdate": 1698642806286,
            "tmdate": 1700352519720,
            "mdate": 1700352519720,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jgINDkQtGc",
                "forum": "dCyt9k4U6N",
                "replyto": "e6ZjQT1YEb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1671/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1671/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate your insightful reviews and constructive suggestions. We are encouraged that you appreciate our method as the first to estimate 3D face landmarks estimation on NeRFs, surpassing state-of-the-art methods.\n\nFor selection of feature and loss function in the coarse model in Eq. 3 and Eq 4, as highlighted by CoordConv, incorporating positional encoding can enhance the capacity of CNNs to extract spatial information effectively. Eq. 3 represents a widely utilized function that encodes positional information, which is subsequently appended to the volume features sampled from the NeRF. Eq. 4 refers to the Wing loss function, which has been shown to improve the training capabilities of deep neural networks in addressing small to medium-range errors, as compared to the $L_1$ and $L_2$ loss functions.\n\nFor fairness of comparisons, we compared FLNeRF which estimates 3D face landmarks from face NeRFs, with triangulation and average single-image 3D landmarks estimation, as shown in Table 1 in main paper, and Table 1-5 in supplementary mateiral. For triangulation, we used state-of-the-art 2D face landmarks detection methods to detect 2D landmarks on single images, and then we performed triangulation to obtain 3D landmarks from 2D landmarks estimated from different single images. For average single-image 3D landmarks estimation, we performed 3D landmarks estimation on single images, and then take the average. We are not comparing our FLNeRF with methods performing 3D landmarks estimation on a single image. As elaborated in Sec. 3.5 in main paper, the number of images to perform 2D landmarks detection followed by triangulation, the number of images to perform average 3D single-image 3D landmarks estimation, and the number of images to train a face NeRF used by FLNeRF, are all the same. Therefore, our comparison is fair in terms of the number of input images.\n\nAs pointed out in Sec. 3.5 in our main paper, definitions of landmarks on cheeks are indeed different from FaceScape. This conforms to R-1tLM's comment that landmarks in those 2D datasets around jaw do not have a fixed location, but represent the face occluding contour. However, when performing comparisons, as shown in Table 1 in our main paper, and Sec. 2.1, Sec. 2.2 and Sec. 2.3 (Table 1-5) in our supplementary material, we only show quantitative comparisons in those landmarks around mouth, eyes, and nose whose definitions are the same. Therefore, our comparison is fair in terms of landmarks definition.\n\nQuantitative and qualitative comparisons show that our FLNeRF which estimates 3D landmarks on NeRF significantly outperforms 2D landmarks estimation followed by triangulation, and average single-image 3D face landmarks estimation. Please refer to Sec. 2.2 and Sec. 2.3 in our supplementary material for reasons why our method produces better results. This could provide insights into the advantage of estimating 3D landmarks on NeRF over estimating 3D landmarks on images.\n\nNeRFs are becoming more and more popular these days. Even some mobile apps could reconstruct NeRF from mobile phone cameras. Currently those mobile apps require multi-view photo taking. Given that our FLNeRF could achieve reasonable results on low-quality NeRFs reconstructed from single images, we believe our technology could benefit users who could use their mobile apps to reconstruct high-quality in-the-wild NeRFs from multi-view images. Users could perform fancy downstream tasks with our technology, such as face animation shown in our paper, enabled by our FLNeRF + modified MoFaNeRF.\n\nFinally, we want to emphasize that we are the first to accurately estimate 3D face landmarks on NeRFs, with potential generalization to in-the-wild NeRFs. Despite the current scarcity of datasets with multi-view face images and ground truth 3D face landmarks, we are optimistic that our work will inspire further advancements in the community. Please let us know if you have further questions. We are happy to provide you detailed answers. We will appreciate it a lot if you could raise your score."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1671/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700545850495,
                "cdate": 1700545850495,
                "tmdate": 1700545850495,
                "mdate": 1700545850495,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wroDJlfeL1",
            "forum": "dCyt9k4U6N",
            "replyto": "dCyt9k4U6N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1671/Reviewer_D4Fc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1671/Reviewer_D4Fc"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a NERF based approach for predicting 3D face landmarks directly from neural radiance fields. This NeRF based solution is shown to surpass existing single or multi-view image approaches. The proposed 3D coarse-to-fine Face Landmarks FLNeRF model samples from a given face NeRF individual facial features for landmarks detection. Expression augmentation is applied at facial features in fine scale to simulate large emotions range including exaggerated facial expressions for training FLNeRF."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The work presents a first contribution in using NERF for face landmarks detection in 3D. \n- Results seems promising. \n- The paper is presented in a good way."
                },
                "weaknesses": {
                    "value": "- A NERF model is normally constructed for each 3D object to render. This limitation seems to apply also to this work. This represents quite a drawback for the proposed solution in that a different NERF model should be constructed for each identity. This drastically reduces the generality of the approach and results in a substantially increased computational effort that appears to be not much compatible with a problem of landmarks detection.\n- Based on the above, the comparison with other methods that do not incur in such limitation is not completely fair in my opinion. Authors should at least clarify this point. \n- In Section 3.5 it is reported that only five identities have been used in the test dataset. This appears as an insufficient number to derive a complete understanding of the proposed solution in comparison to state-of-the-art approaches. This very small number of identities does not have a sufficient statistical significance. \n- It is not clear how much of the performance derive from data augmentation. A better insight of this should be provided.\n- Limitations of the proposed method have not been discussed. \n\nMinor corrections:\n- Caption of Table 2: \u201cby method described\u201d --> by the method described"
                },
                "questions": {
                    "value": "Q1: A NERF model is normally constructed for each 3D object to render. This limitation seems to apply also to this work. This represents quite a drawback for the proposed solution in that a different NERF model should be constructed for each identity. This drastically reduces the generality of the approach and results in a substantially increased computational effort that appears to be not much compatible with a problem of landmarks detection. Can author clarify this point? \n\nQ2: Based on the above, could the authors present the results in a better way so that the comaprison account for other aspects than only accuracy?\n\nQ3: It is not clear how much of the performance derive from data augmentation. A better insight of this should be provided."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1671/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698683097869,
            "cdate": 1698683097869,
            "tmdate": 1699636095151,
            "mdate": 1699636095151,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ekPy8kqdhP",
                "forum": "dCyt9k4U6N",
                "replyto": "wroDJlfeL1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1671/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1671/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate your insightful reviews and constructive suggestions. We are encouraged that you appreciate our method as the first to estimate 3D face landmarks estimation on NeRFs, surpassing state-of-the-art methods.\n\nFor Q1, we do need to train a seperate NeRF for each inference. However, instant-ngp already accelerated NeRF training from hours to seconds. Those 2D landmarks detections followed by triangulation or single-image 3D landmarks detections are also not immediate, taking from 30 seconds to 2 minutes. We believe as NeRF being more and more popular, more NeRF training acceleration techniques will be proposed. Also, there are many downstream tasks that do not require super fast face landmarks detection speed. For example, people may be able to produce his/her own face animations enabled by our FLNeRF + modified MoFaNeRF, as shown in our paper and video. Many mobile apps could already reconstruct NeRFs using mobile phone cameras in seconds. Imagine people could possibly make vivid face animations totally on their own, driving a cartoon face, a super man's face, or a celebrity's face by simply performing corresponding expressions themselves and feed the face NeRFs to our FLNeRF + modified MoFaNeRF pipeline, without experts drawing every frame.\n\nFor Q2, please refer to Sec. 2.1, Sec. 2.2 and Sec. 2.3 (Table 1-5) in our supplementary material. They provide detailed analysis of why performing 3D landmarks estimation on NeRFs is a better choice. Our estimation process can be effectively performed in a single forward pass through the model. As a result, the inference time for each expression is less than one second (tested on the GTX 1080), which is comparable to the magnitude of the 2D landmarks detector.\n\nFor Q3, for the improvement derived from the data augmentation, please refer to Sec. 4.3 in the main paper. This section presents an ablation study, illustrating the effects of excluding expression augmentation.\n\nFinally, we want to emphasize that we are the first to accurately estimate 3D face landmarks on NeRFs, with potential generalization to in-the-wild NeRFs. Despite the current scarcity of datasets with multi-view face images and ground truth 3D face landmarks, we are optimistic that our work will inspire further advancements in the community. Please let us know if you have further questions. We are happy to provide you detailed answers. We will appreciate it a lot if you could raise your score."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1671/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700545698626,
                "cdate": 1700545698626,
                "tmdate": 1700545698626,
                "mdate": 1700545698626,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "GD6OJgL3ud",
            "forum": "dCyt9k4U6N",
            "replyto": "dCyt9k4U6N",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1671/Reviewer_1tLM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1671/Reviewer_1tLM"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a model, termed FLNeRF, for estimating 3D facial landmarks from a face NeRF representation. In a first step it performs a coarse sampling of the NeRF volume to obtain an initial estimate of the face parameters. In a second step it re-samples again, at a finer scale, the face, eyes and mouth spatial locations. In both steps the reconstructed face volume, combined with positional encoding,  are the input to a CNN that estimates the face pose and the configuration parameters of a bi-linear model (a compressed version of FaceScape's) representing identity and expression, from which a set of 3D landmarks can be produced.\n\nThe experimentation evaluates the accuracy of the estimated landmarks so as their use for face editing and swapping."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper is easy to read and the problem addressed, face landmark estimation, is quite significant, with relevant applications and theoretical issues."
                },
                "weaknesses": {
                    "value": "As the abstract reads, the central claim in the paper is that the approach can accurately estimate 3D face landmarks surpassing existing single or multi-view approaches. Also, since the starting point of the approach is a NeRF, to stress its practical use, the last sentence in section 2 reads \"We will show our FLNeRF can be generalized to estimate 3D face landmarks on 2D in-the-wild images, using face NeRFs reconstructed by EG3D Inversion.\"\n\nThe paper does not convincingly demonstrate any of these claims. \n\nThe proposed approach is compared with the reconstructions computed with the landmarks detected with 2D methods and the 3D landmarks obtained with 3D methods in terms of the average Wing loss values multiplied by 10. I have several comments concerning this experiment:\n- The evaluation is performed with 5 identities from the test dataset from FaceScape.  While this experiment provides some information, a sound comparison should include several other benchmark datasets in the literature and a widely used metric, such as e.g. the mean, median and std reconstruction errors.\n- Is the comparison fair?  I have doubts since FLNeRF was trained with a train set from FaceScape, whereas competing approaches seem to have been trained with different datasets.\n- In 2D datasets landmarks around the jaw do not have a fixed location, but rather represent the face occluding contour, so a reconstruction from their correspondences does not make much sense.\n\nFinally, the experimentation concerning the estimation of landmarks on in-the-wild images, was made with a single image of president Obama, in which the estimated landmark locations are not very good."
                },
                "questions": {
                    "value": "The authors should elaborate more on the complexity of estimating a detailed NeRF from an image, compared to a set of facial landmarks, and what are the advantages of estimating the landmarks from the NeRF, rather than from the image.\n\nSpecific questions:\n- Is the comparison in Table 1 fair?\n- Does a test on a single image provide sufficient experimental support to conclude that FLNeRF can be generalized to estimate 3D face landmarks on 2D in-the-wild images?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1671/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698741953845,
            "cdate": 1698741953845,
            "tmdate": 1699636095067,
            "mdate": 1699636095067,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "iNe9mXGnyJ",
                "forum": "dCyt9k4U6N",
                "replyto": "GD6OJgL3ud",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1671/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1671/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate your insightful reviews and constructive suggestions. We are encouraged that you appreciate the importance of 3D face landmarks estimation and our method to solve the problem. \n\nFor profoundness of comparisons, we also provided quantitative results in terms of adaptive average Wing loss and MSE. Please refer to Sec. 2.1 and Sec. 2.2 in the supplementary material, which show comparison in terms of more metrics in Table 1, Table 2, Table 3, Table 4 and Table 5 in the supplementary material. We conducted these comparisons using 20 different expressions for each identity, resulting in 100 diverse test cases. Acknowledging your insightful suggestion, we agree that testing on additional datasets would be beneficial. However, since NeRF and its variants are still young, and few people recognized its potential in 3D face landmarks estimation, FaceScape remains the only dataset to our knowledge providing multi-view face images with ground truth 3D face landmarks. Nonetheless, our tests on face NeRFs reconstructed by EG3D from single in-the-wild images demonstrate potential applicability to other datasets from another perspective. We believe that our work could stimulate the field of 3D face landmarks estimation by bringing the insights that estimating 3D landmarks on NeRF outperforms triangulation and average single-image 3D face landmarks estimation. Hopefully with this insight, more datasets with multi-view face images and 3D ground truth landmarks will be constructed.\n\nFor fairness of comparisons, we compared FLNeRF which estimates 3D face landmarks from face NeRFs, with triangulation and average single-image 3D landmarks estimation, as shown in Table 1 in main paper, and Table 1-5 in supplementary mateiral. For triangulation, we used state-of-the-art 2D face landmarks detection methods to detect 2D landmarks on single images, and then we performed triangulation to obtain 3D landmakrs. For average single-image 3D landmarks estimation, we performed 3D landmarks estimation on single images, and then take the average. As elaborated in Sec. 3.5 in main paper, the number of images to perform 2D landmarks detection followed by triangulation, the number of images to perform average 3D single-image 3D landmarks estimation, and the number of images to train a face NeRF used by FLNeRF, are all the same. Therefore, our comparison is fair in terms of the number of input images.\n\nAs pointed out in Sec. 3.5 in our main paper, definitions of landmarks on cheeks are indeed different from FaceScape. This conforms to your comment that landmarks in those 2D datasets around jaw do not have a fixed location, but represent the face occluding contour. However, when performing comparisons, as shown in Table 1 in our main paper, and Sec. 2.1 and Sec. 2.2 (Table 1-5) in our supplementary material, we only show quantitative comparisons in those landmarks around mouth, eyes, and nose whose definitions are the same. Therefore, our comparison is fair in terms of landmarks definition.\n\nQuantitative and qualitative comparisons show that our FLNeRF which estimates 3D landmarks on NeRF significantly outperforms 2D landmarks estimation followed by triangulation, and average single-image 3D face landmarks estimation. Please refer to Sec. 2.2 and Sec. 2.3 in our supplementary material for reasons why our method produces better results. Hope this could answer your question regarding the advantage of estimating 3D landmarks on NeRF over estimating 3D landmarks on images.\n\nWe are grateful for your suggestions on generalization. Accordingly, we will revise our terminology to 'generalization to in-the-wild NeRF' for greater accuracy. The reason for showing estimations results by our FLNeRF on face NeRFs reconstructed by EG3D from single images is to show that our FLNeRF could produce reasonable results even given face NeRFs of low quality and background. NeRFs are becoming more and more popular these days. Even some mobile apps could reconstruct NeRF from mobile phone cameras. Currently those mobile apps require multi-view photo taking. Given that our FLNeRF could achieve reasonable results on low-quality NeRFs reconstructed from single images, we believe our technology could benefit users who could use their mobile apps to reconstruct high-quality in-the-wild NeRFs from multi-view images. Users could perform fancy downstream tasks with our technology, such as face animation shown in our paper, enabled by our FLNeRF + modified MoFaNeRF. \n\nFinally, we want to emphasize that we are the first to accurately estimate 3D face landmarks on NeRFs, with potential generalization to in-the-wild NeRFs. Despite the current scarcity of datasets with multi-view face images and ground truth 3D face landmarks, we are optimistic that our work will inspire further advancements in the community. Please let us know if you have further questions. We are happy to provide you detailed answers. We will appreciate it a lot if you could raise your scores."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1671/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700505496294,
                "cdate": 1700505496294,
                "tmdate": 1700505496294,
                "mdate": 1700505496294,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]