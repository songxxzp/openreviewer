[
    {
        "title": "A Critical Study of What Pre-trained Code Models (do not) Learn"
    },
    {
        "review": {
            "id": "7hM1OzeAIy",
            "forum": "I0wEUVzbNY",
            "replyto": "I0wEUVzbNY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7451/Reviewer_Yafu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7451/Reviewer_Yafu"
            ],
            "content": {
                "summary": {
                    "value": "The paper is a critical study of pre-trained code models, focusing on what kinds of information are or aren\u2019t encoded in the PCMs, to explain why PCMs fail to generalize beyond the datasets they are trained on. The paper creates model graphs by attention analysis and compares them with syntax graphs, dataflow graphs, and non-identifier graphs. Based on the comparison results, the paper argues that while PCMs encode syntactic and data flow relations in the attention layers, but fail to encode relations between syntactic and identifier tokens. The paper further performs a distance prediction task with DirectProbe on hidden representations and finds that hidden representations do not encode enough information to discriminate between different identifier types and syntax structures, which may lead to syntactic errors in the outputs of PCMs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. A critical study of several popular PCMs with careful analysis of their attention maps and hidden representations to reveal the limitations of those PCMs on encoding specific relations.\n2. The paper points out some wrong assumption used by prior works."
                },
                "weaknesses": {
                    "value": "1. To my understanding, most of the studied models are primarily token-based models. It is somewhat unexpected by construction that the models will have accurate knowledge of AST and DFG. Also, depending on the tasks it may not matter very accurate knowledge of these code properties. For example, many previous studies have shown that for code summarization tasks, a good choice of variable names is good enough. It is not very clear from the paper what kind of properties primary token-based models are expected to learn and how they have learned it.  \n\n2. Why do authors expect the self-attention score between syntactic and identifier nodes to be high? \n\n3.  Overall, the paper's presentation is poor. It does not have a clear and logical structure, which poses difficulty in reading and understanding. The visualization is not clear. Explanations of the figures and data are not detailed enough, so it is a bit hard to relate them to the conclusions.\n\n4. While the use of the \u201cmotif structure\u201d seems integral to the construction of the code graph, it is not explicitly defined in the work; providing some background or context for this concept may be critical.\n\n5. The paper makes some unsubstantial claims. For example, in the intro, they say one group of papers says LLMs are working for code, while some other group of papers find cases where LLMs fail. The authors say these two trends are contradictory. I think this is how any field progresses ---they are not necessarily contradictory trends."
                },
                "questions": {
                    "value": "1. Why do you set all the values above threshold to 1? Why not maintain an individual attention score?\n\n2. What is the intuition behind expecting a higher self-attention score between identifiers and keywords, especially for a token-cased model?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7451/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721006024,
            "cdate": 1698721006024,
            "tmdate": 1699636894892,
            "mdate": 1699636894892,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "z9VNc5ErM3",
                "forum": "I0wEUVzbNY",
                "replyto": "7hM1OzeAIy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7451/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7451/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive comments about the papers and for pointing out the weaknesses. Based on the suggestion, we have made changes to the paper which we enumerate in the common response to all reviewers. We kindly ask the reviewer to go through those comments. In the following, we address the weaknesses pointed out and the questions raised by the reviewer.\n\n**Weaknesses**\n1. These models indeed act on tokens but they do not just take in some tokens and split out a new one. They are optimized to perform some task. There is an implicit assumption that structure in input data can be learned by the models from simple inputs with proper optimizations. Evidence has been provided to support this assumption by multiple studies in different fields, including NLP and vision. Previous work in NLP has shown that with tokens as inputs and proper optimization, models can learn the language grammar. Similarly, code models have been shown to learn program syntax. Our work is an attempt to understand how much structure can be encoded in models with optimizations based on tokens. So, we believe it is not correct to say it should be unexpected using construction. \n\n    Our work points out a significant limitation in learning these structures about code, which has been previously unexplored. We do not claim that the learning should be perfect; we only point out that some very important relations necessary for comprehending code syntax and code logic are not encoded by the models in the self-attention values and hidden representations.\n\n    Moreover, not all models are trained only with tokens. GraphCodeBERT takes data flow graph nodes as inputs along with tokens, while, UniXcoder takes nodes of flattened AST as input.\n \n    The reviewer rightly points out that for code summarization a good choice of variable names is good enough. However, we argue that such dependence on function names as opposed to code logic for summarization is a symptom of shortcut learning and hinders generalization. We have added a discussion on this argument in Section 4.3 of the updated paper as well as in the common comments to all reviewers. We kindly ask the reviewer to consider these too.\n\n2. We assume self-attention between syntactic and identifier tokens to be high only if they are within the same motif structure. This assumption is based on results in previous works such as Wan et al (2022). Further, the relation between syntactic tokens and identifiers plays an important role in program flow. For example, `if` and `else` defines code blocks but the flow of the program is decided by the identifiers related to these syntactic tokens.\n3. We have made changes to the paper described in general comments to make the flow and the conclusions of the paper more clear. We have also modified the captions of Figures and Tables to add additional details.\n4. The term 'motif structure' was defined in Wan et al (2022) and we use the definition as is. The citation was missing in the Introduction section. Following the suggestion of the reviewer, we have described the motif structure in Appendix B of the updated paper and have cited the relevant work in the Introduction.\n5. Based on the suggestions of the reviewer, we have made changes to the Introduction section to make our claims clearer and have also reworded the text about contradictory trends.\n\n**Questions**\n1. We had initially set the values to 1 to replicate previous work and then continued our analysis with this value to ensure our work remained comparable to those works. We can use the individual attention values by weighing all computations with the original value. Since the attention values are between 0 and 1, it will make the limitations of the models more stark. But, it will not change the conclusions drawn from the analysis. Setting it to 1 shows that the limitations remain even if the attention is very high. We have added this explanation in Section 3.2.1 of the updated paper.\n2. Please see point 2 of weakness."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7451/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663820784,
                "cdate": 1700663820784,
                "tmdate": 1700663820784,
                "mdate": 1700663820784,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JI0lqtIBha",
                "forum": "I0wEUVzbNY",
                "replyto": "7hM1OzeAIy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7451/Reviewer_Yafu"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7451/Reviewer_Yafu"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your detailed comments and update the paper. While I agree token based models should understand some approximate structures, aligning the models to different downstream tasks may enforce them to learn the structures better. However, as you have conducted the experiments with a pre-trained model, where most of the models are not challenged to learn the structure, it is not clear to me why we would expect the model to learn the structure. \n\nAuthors claim the models should learn some approximate structure----in such case, there should be some estimate for approximation. \n\nI think with more experiments with more downstream tasks may clarify some of these points better."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7451/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700692007470,
                "cdate": 1700692007470,
                "tmdate": 1700692007470,
                "mdate": 1700692007470,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BvD5SIaaFj",
            "forum": "I0wEUVzbNY",
            "replyto": "I0wEUVzbNY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7451/Reviewer_vS1o"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7451/Reviewer_vS1o"
            ],
            "content": {
                "summary": {
                    "value": "This paper presented an analysis of the self-attention mechanism and the hidden representations within PCMs (pre-trained code models). The study reveals that while PCMs do encode syntactic and data flow relations in self-attention, they only encode relations within specific subsets of input tokens and do not encode syntactic-identifier relations between code tokens. The authors believe that this limitation is what leads to syntactic errors in outputs of PCMs. The authors also observe that this problem persists across different model architectures, datasets, and pre-training objectives."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper targets an important problem.\n- Detailed analysis. It is commendable that the authors performed a visualization analysis of the hidden states of pre-trained code models."
                },
                "weaknesses": {
                    "value": "This paper targets an important problem of understanding why PCMs work/don\u2019t work. The findings could provide useful insights that could help address current models\u2019 limitations and inspire further research in this area.\n\nCurrently, the analysis was performed on 5 PCMs that were proposed in 2020-2022 and are relatively small. No investigation of more recent models, especially LLMs (such as CodeLLaMa and Starcoder), is performed. It is not clear if the obtained findings are applicable to more recent, large models.\n\nIt seems that this work closely aligns with the research conducted by Wan et al. (2022) and places a greater emphasis on the fine-grained details of code tokens, achieved by categorizing input tokens into syntactic tokens and identifiers. From this standpoint, this work is considered a bit incremental.\n\nThe authors claimed that their findings shed light on why PCMs fail to generalize beyond dataset they are trained on and in real world applications. I do not think this statement can be well supported by the findings shown in this paper. The authors investigate the inability of pre-trained code models to comprehending relations across the syntactical keywords and identifier tokens, however, the connections between the comprehending ability and the generalization ability are non-trivial and need to be explained explicitly.\n\nSeveral statements in this paper are not consistent. For example, the research objectives are inconsistent, the study attempts to explore the extrapolation ability of a model in the introduction, however, the methods mainly focus on evaluating the ability of a model distinguishing syntactical tokens and identifiers.\n\nIn the Introduction, the authors point out that certain prior works often make incorrect assumptions in their experimental settings. Unfortunately, the authors do not specify what kinds of incorrect assumptions these works often make."
                },
                "questions": {
                    "value": "- Are the obtained findings applicable to more recent, large models?\n\n- What are the connections between the comprehending ability and the generalization ability?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7451/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698752179346,
            "cdate": 1698752179346,
            "tmdate": 1699636894757,
            "mdate": 1699636894757,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rXB49wJOjX",
                "forum": "I0wEUVzbNY",
                "replyto": "BvD5SIaaFj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7451/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7451/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive comments about the papers and for pointing out the weaknesses. Based on the suggestion, we have made changes to the paper which we enumerate in the common response to all reviewers. We kindly ask the reviewer to go through those comments. In the following, we address the weaknesses pointed out and the questions raised by the reviewer.\n\n**Weaknesses**\n1. Selection of models: We agree that the paper focuses on slightly older and smaller models. However, we believe that the analysis of these models is still relevant and provides important insights for future research. We provide our argument for selecting these models in common response to all reviewers and also in Appendix C of the updated paper.  \n2. Incremental work: We disagree with this comment. While the initial motivation was to replicate the work by Wan et al. (2022), we found that the results and conclusions of that work were significantly affected by the choice of assumptions that were made. Subsequently, we did a comprehensive analysis of existing works in this domain and found that such assumptions abound.  We, then, extended previous works to point out the limitations of current models. We used DirectProbe, which has not been used for PCMs before. For analysis with DirectProbe, we did a complete experimental design and created a dataset to run DirectProbe. We also extended the existing analysis to more models and data flow graphs. In previous work, data flow graphs were only used with probing-based classifiers with an assumption of linearity in encoding. Our work revealed that the linearity assumption is not valid. Similarly, our work is the first to use graph edit distance for attention analysis, which provided new insights into the limitations of PCMs.  \n3. We agree with the reviewer that the original paper did not discuss how our findings shed light on why PCMs fail to generalize beyond dataset. We have now added details explaining the relation between the ability of models to comprehend code logic and syntax and their generalization ability in Section 4.3 of the update paper.\n4. The research objective of the paper is to understand the limitations of PCMs with respect to what code information they do not encode. We have stated this in the Abstract as well as in the Introduction. We had additionally claimed that the limitations we found shed light on the limitations of models to generalize. However, we had not made this connection clear in the paper. We now do so in Section 4.3 of the updated paper.\n5. In the last paragraph of the Introduction, we have detailed the non-systematic assumptions made by previous works. These are the choice of attention threshold and evaluation metric for attention analysis as well as the assumption of linearity in information encoded in hidden representation. In our analysis, we found that these assumptions impact the conclusions drawn from the analysis (See Section 3.2.1 for attention analysis and Section 4.2 for linearity assumption) and can lead to wrong conclusions.\n\n**Questions**\n1. This cannot be answered without evaluating the larger models. However, a comparison between PLBART and CodeT5, two encoder-decoder models with different sizes, did not reveal any difference in the model's ability to understand syntax better only because of size. Moreover, as we explain in Appendix C of the updated paper, analysis of smaller models also reveals relevant insights.\n2. We now address this question in the last two paragraphs of Section 4.3 of the updated paper and have also explained in the general comments for all reviewers."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7451/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663350589,
                "cdate": 1700663350589,
                "tmdate": 1700663350589,
                "mdate": 1700663350589,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cpCXpe1GkF",
            "forum": "I0wEUVzbNY",
            "replyto": "I0wEUVzbNY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7451/Reviewer_GkFF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7451/Reviewer_GkFF"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a critical study of pre-trained code models (PCMs) to understand what they do and do not learn regarding code relations. By analyzing the self-attention mechanism and hidden representations, the authors reveal that while PCMs encode syntactic and data flow relations among input tokens, they fail to encode relations between syntactic tokens and identifiers. This limitation results in hidden representations not being able to discriminate between different identifier types and syntax structures. The authors show that these learning gaps persist across different model architectures, datasets, and pre-training objectives, providing insights into why PCMs fail to generalize beyond the dataset they are trained on and in real-world applications. The findings encourage further research to address the limitations of current PCMs and develop more robust experimental designs for model interpretability and improvement in training methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper exhibits originality by providing a fine-grained analysis of pre-trained code models, uncovering previously unaddressed limitations. The quality is high due to its critical examination of assumptions in prior work, leading to more accurate conclusions. The paper's clarity is evident in its well-written presentation, making the experiments and findings easily understandable. Its significance lies in inspiring further research to address the identified limitations and develop more robust experimental designs and training methods for PCMs."
                },
                "weaknesses": {
                    "value": "1. The scope of the models and datasets analyzed is limited, and the paper could be strengthened by considering a wider range of model architectures, sizes, and training data sources to provide a more comprehensive understanding of the limitations across various PCMs.\n2. The paper focuses primarily on syntax and data flow relations but could extend its analysis to other aspects, such as the influence of natural language on code understanding and the alignment between natural language and programming languages.\n3. The experiments conducted in the paper focus on Python code. Including other programming languages in the analysis would provide insights into whether the observed limitations are language-specific or general across different programming languages."
                },
                "questions": {
                    "value": "1. How do the observed limitations in PCMs affect their performance on real-world tasks? It would be helpful to provide examples or case studies to illustrate the practical implications of these limitations.\n2. Are the identified limitations specific to the Transformer-based models studied in the paper, or do they extend to other types of models, such as RNNs or LSTMs, in the context of code understanding?\n3. Have the authors considered exploring the impact of different pre-training objectives or methods that could potentially address the limitations identified in the paper? Some suggestions or proposals to improve the training process would be valuable.\n4. How do the limitations in the PCMs affect their ability to learn from more diverse training data, such as codes from different domains or programming languages? Would incorporating such variety during the training phase help in mitigating the observed limitations?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7451/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698820762159,
            "cdate": 1698820762159,
            "tmdate": 1699636894643,
            "mdate": 1699636894643,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "XrnFr1fT58",
                "forum": "I0wEUVzbNY",
                "replyto": "cpCXpe1GkF",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7451/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7451/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive comments about the paper and for pointing out the weaknesses. Based on the suggestion, we have made changes to the paper which we enumerate in the common response to all reviewers. We kindly ask the reviewer to go through those comments. In the following, we address the weaknesses pointed out and the questions raised by the reviewer.\n\n**Weaknesses**\n1. Limited choice of model architectures, sizes, and data sources: \n \n     We have explained the limitations regarding model architecture in Appendix C of the updated paper and also mentioned it in common response to all reviewers.\n\n    The limited choice of the dataset was deliberate to remove any effect of data distribution shift. All models except PLBART were trained on the CodeSearchNet (CSN) dataset. Also, CSN is a fairly large dataset with 6 programming languages and 2 million comment-code pairs. PLBART was trained on Java and Python code from Google BigQuery. Despite a different dataset and the potential for distribution shift, we considered PLBART due to its smaller size compared to other encoder-decoder models. \n\n    PLBART is about half the size of encoder-decoder models such as CodeT5, but the difference in sizes does not seem to affect the conclusion. Moreover, the idea behind analyzing smaller models was to understand the limitations of smaller models, to improve them instead of always going for larger sizes. We have added a discussion on the use of smaller models in Appendix C of the updated paper.\n\n2. Alignment between Natural and Programming Language:\n\n    We agree that understanding the effect of natural language and NL-PL alignment is important and see it as the next logical extension of our work. However, we consider this to be out-of-scope for this paper because it is non-trivial to extend the current work to natural languages. The major challenge with natural language is that semantically similar texts can lead to significantly different output, as is seen with various prompting strategies and in-context learning. Thus, we cannot simply take a specific text-code pair and analyze the models. Instead, we need to consider which version of the text can give the best output and which one gives the poorest. To do this, we are currently working towards a statistical method to analyze NL-PL alignment in a principled manner. Moreover, analyzing only on code is also important for many downstream tasks such as code completion, clone detection, code retrieval etc.\n3. Python-only Analysis:\n\n    We agree that including more languages in the analysis would provide additional insights. However, the analysis of Python in itself is very relevant and important. PCMs perform significantly better on Python compared to other languages. Better performance on Python has also resulted in works such as Math Coder which generates Python code to solve math problems. In general, Python has become the primary focus of recent works. Moreover, widely used benchmarks such as HumanEval, MBPP and DS1000 have reference solutions in Python and so, the recent state-of-the-art models are evaluated usually on Python. Similarly, the models analyzed in the paper perform significantly better on Python benchmarks compared to other programming languages."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7451/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662495388,
                "cdate": 1700662495388,
                "tmdate": 1700662495388,
                "mdate": 1700662495388,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZRTbfRhWPw",
            "forum": "I0wEUVzbNY",
            "replyto": "I0wEUVzbNY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7451/Reviewer_gkoc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7451/Reviewer_gkoc"
            ],
            "content": {
                "summary": {
                    "value": "The paper analyzes the limitations of pre-trained code models (PCMs) by studying what relations they do and do not encode in their internal representations. It focuses on syntactic, data flow, and semantic relations between code tokens.\n\nThe main finding is that while PCMs encode some syntactic and data flow relations, they fail to encode relations between syntactic tokens like keywords and identifiers like variable names.\n\nThe authors perform comprehensive attention analysis and probing of hidden representations across multiple models like CodeBERT, GraphCodeBERT, CodeT5, etc. The limitations are found to persist across models, architectures, objectives and datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. **Comprehensive analysis of multiple relation types.** A key contribution is analyzing syntactic-syntactic, identifier-identifier, and syntactic-identifier relations separately. This allows the authors to uncover that while models encode some relations well, they fail to encode syntactic-identifier relations. The fine-grained categorization and analysis provides valuable insights into exactly where models fall short.\n\n2. **Rigorous experimental methodology.** The paper investigates limitations rigorously through both attention analysis and probing of hidden representations. The authors also avoid common pitfalls by using suitable thresholds, metrics, and probing techniques. The robust experimental design lends credibility to the conclusions drawn.\n\n3. **Analysis across multiple models and settings.** Rather than evaluating a single model, the study analyzes limitations across transformer architectures, training objectives, and datasets. The consistency of observations across these varying settings strongly indicates fundamental, widespread limitations in encoding certain code relations. The cross-model analysis strengthens the paper's central claim regarding limitations of pre-trained code models."
                },
                "weaknesses": {
                    "value": "1. The selection of models analyzed is limited. While the paper has covered 5 models that are either encoder-only or encoder-decoder, it has not covered decoder-only PCMs, which seem to be the major choice of pre-trained language models currently.\n2. Lack of real-world evaluation. The paper focuses on analyzing model internals. It does not evaluate how the limitations discovered actually affect model performance on downstream tasks. Testing on real-world code generation and code search benchmarks could better highlight the practical implications.\n3. The paper does not provide architecture-related or data-related explanation for the limitations of current PCMs. Also, it does not propose methods to address the limitations identified. Providing ideas to improve relation encoding could make the work more constructive."
                },
                "questions": {
                    "value": "Please see the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7451/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7451/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7451/Reviewer_gkoc"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7451/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699207747714,
            "cdate": 1699207747714,
            "tmdate": 1699636894540,
            "mdate": 1699636894540,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YUSXwohpFb",
                "forum": "I0wEUVzbNY",
                "replyto": "ZRTbfRhWPw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7451/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7451/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the positive comments about the paper and for pointing out the weaknesses. Based on the suggestion we have made changes to the paper which we enumerate in the general response to all reviewers. We kindly ask the reviewer to go through those comments. In the following, we address the weaknesses pointed out by the reviewer.\n1. On limited selection of models:\nSince this weakness was mentioned by multiple reviewers, we have explained how the models we have analyzed provide important and relevant insights in the common response to all reviewers and also in Appendix C.\n 2. Lack of real-world evaluations: \nSince this weakness was mentioned by multiple reviewers, we have provided explanations in common response to all reviewers. Based on the suggestion, in Section 4.3 of the updated paper, we discuss how our work relates to real-world tasks and limits to generalization.\n3. Suggestions to address limitations: \nBased on our analysis, we provided some suggestions in Section 4.3 of the original paper. However, the suggestions were not clear. In the updated paper, we discuss these suggestions in Section 4.4 after pointing out the limitations. Further, we have modified the section to make the suggestion more clear."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7451/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700661837166,
                "cdate": 1700661837166,
                "tmdate": 1700661837166,
                "mdate": 1700661837166,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DSLr4husDq",
                "forum": "I0wEUVzbNY",
                "replyto": "YUSXwohpFb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7451/Reviewer_gkoc"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7451/Reviewer_gkoc"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response.\n\nWhile it has solved some of my concerns, I find the discussion without experimental evidence not convincing enough. Hence I'm not changing my rating."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7451/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700688165199,
                "cdate": 1700688165199,
                "tmdate": 1700688165199,
                "mdate": 1700688165199,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]