[
    {
        "title": "Robust Model-Based Optimization for Challenging Fitness Landscapes"
    },
    {
        "review": {
            "id": "eXjKOEi8iU",
            "forum": "xhEN0kJh4q",
            "replyto": "xhEN0kJh4q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5990/Reviewer_7H3r"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5990/Reviewer_7H3r"
            ],
            "content": {
                "summary": {
                    "value": "Authors propose to use a Variational Autoencoder (VAE) to model a protein engineering task. Obtained model would allow scientists from the area to better know where to look for promising compounds in such difficult search space. They argue that their approach is more effective and efficient than other normally attempted approaches, such as RL guided searches or evolutionary optimization. Authors provide some experimental assessments that include experiments with artificial datasets to properly evaluate their approach."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Unfortunately, Bioinformatics is far outside my scope areas. I can't really assess quality of the paper. For the untrained eye, everything seems to fit. The proposed approach seems correct for the task at hand (as far as I could understand it), but I'm completely unfamiliar with the related work, can't really say if this has been attempted before for this particular domain, or to what extent. All I can say is that presentation of the paper is good, and the artificial dataset experiments somewhat seem to validate what authors attempted to do."
                },
                "weaknesses": {
                    "value": "As I already mentioned, I can't really assess the draft.\nThe only one thing that I'd like to bring forward, it's that for the given bioinformatics task described -as far as I could understand it- VAEs seem like a natural thing to try. I'm surprised nobody has done it before; but since I'm unfamiliar with the Related Work, surely there are things that I'm missing."
                },
                "questions": {
                    "value": "I'm leaning a bit towards rejection of the paper, just for the reason I mentioned in the 'weaknesses' section, about novelty and contribution. \nBut if other reviewers go with acceptance, I won't argue against.\nAC has been alerted to seek another opinion if needed."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5990/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5990/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5990/Reviewer_7H3r"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698448734829,
            "cdate": 1698448734829,
            "tmdate": 1700668524293,
            "mdate": 1700668524293,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xlnceclDLO",
                "forum": "xhEN0kJh4q",
                "replyto": "eXjKOEi8iU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 7H3r"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their feedback and time.\n\n**Question 1:** The only one thing that I'd like to bring forward, it's that for the given bioinformatics task described -as far as I could understand it- VAEs seem like a natural thing to try. I'm surprised nobody has done it before; but since I'm unfamiliar with the Related Work, surely there are things that I'm missing\n\n**Response:**\nThe novelty of our work lies in looking into the less explored problem of separation in the design space, in which the desired optimum is in a region that is not only poorly represented in training data, but also relatively far from the highly represented low-fitness regions.\n\nPrior work, such as CbAS included in the benchmark, have used VAE for the task of sequence generation. Our work is not novel in proposing to use VAEs for the first time. Rather, it addresses the overlooked problem of separation using a modified VAE."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612674130,
                "cdate": 1700612674130,
                "tmdate": 1700612716659,
                "mdate": 1700612716659,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yKoo6XKZoc",
                "forum": "xhEN0kJh4q",
                "replyto": "xlnceclDLO",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5990/Reviewer_7H3r"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5990/Reviewer_7H3r"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your clarification. I'll revisit your modified draft in the future under a new light considering your answer to my concern. In the meanwhile I'll update my score to 6.\nRegards"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700668507900,
                "cdate": 1700668507900,
                "tmdate": 1700668507900,
                "mdate": 1700668507900,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "P03iqY1rPr",
            "forum": "xhEN0kJh4q",
            "replyto": "xhEN0kJh4q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5990/Reviewer_R8Dk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5990/Reviewer_R8Dk"
            ],
            "content": {
                "summary": {
                    "value": "This paper identifies the scenarios where the desired optimum is in a region that is not only poorly represented in training data but also relatively far from the highly represented low-fitness regions for model-based optimization for sequence-function landscapes, named separation, and proposes a new method using a variational auto-encoder to explicitly structure the latent space by property values of the sequences such that more desired samples are prioritized over the less desired ones and have higher probability of generation. Empirical studies on three real and semi-synthetic protein datasets show the robustness of the proposed method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThis paper identifies the problem of separation for model-based optimization for sequence-function landscapes.\n2.\tA robust method based on a variational auto-encoder is proposed to solve the separation and sparsity problems.\n3.\tEmpirical studies are conducted on three real and semi-synthetic protein datasets to study the effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1.\tA clear description of the robustness concept needs to be provided for friendly reading.\n2.\tA description of the organization of this paper as well as a Conclusion session should be added."
                },
                "questions": {
                    "value": "What is the maximum dimensionality examined in the experiments? How will the proposed method perform when increasing the dimensionality of an optimization problem?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698742766682,
            "cdate": 1698742766682,
            "tmdate": 1699636641521,
            "mdate": 1699636641521,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tYJ6BAZUis",
                "forum": "xhEN0kJh4q",
                "replyto": "P03iqY1rPr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer R8Dk"
                    },
                    "comment": {
                        "value": "We thank the reviewer for understanding the strengths and contribution of our work to the field of protein design. \n\n**Question 1**\nA clear description of the robustness concept needs to be provided for friendly reading.\n\n**Response:**\nThanks for your suggestion. We have now added the following sentence to the Introduction, where the central goal of the work is introduced: \u201c A robust algorithm should have consistent performance under varying separation and imbalance.\u201d\n\n\n**Question 2**\nA description of the organization of this paper as well as a Conclusion session should be added.\n\n**Response:**\nDescription of the organization of the paper has been added. The section previously titled \u201cDiscussion\u201d is meant to be our conclusion section and has been re-titled following the reviewer\u2019s suggestion. \n\n\n**Question 3**\nWhat is the maximum dimensionality examined in the experiments? How will the proposed method perform when increasing the dimensionality of an optimization problem?\n\n**Response:**\nThe input dimension changes from one to 2500 in our experiments. PPGVAE did well in all benchmarks. PINN benchmark has the maximum input dimension of 2500. For protein datasets, AAV has the largest input dimension with sequences of length 28 and encoding of each amino acid with a 20-dimensional vector. The dimension of the latent space ranges from 2 to 20 in our experiments. This is included in the Appendix Table A2."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612557328,
                "cdate": 1700612557328,
                "tmdate": 1700612557328,
                "mdate": 1700612557328,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nW184lyYZ4",
            "forum": "xhEN0kJh4q",
            "replyto": "xhEN0kJh4q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5990/Reviewer_soEo"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5990/Reviewer_soEo"
            ],
            "content": {
                "summary": {
                    "value": "Note: I am not familiar with the field of protein design, so this review is largely from the perspective of generative modelling.\n\n**Problem Setting**\n\nWe are considering the problem of protein design, in which data consists of sparse examples of high-fitness designs. Due to the nature of the optimization problem, it is desirable to learn a model that can judge the fitness of specific sequences.\n\n**Novel Idea**\n\nThis work proposes the learning of a weighted VAE such that high-fitness samples are weighted in the probability distribution. The intuition is that exploration in VAE space is more likely to result in succesful generations with this bias in place. However, all samples can still be used in training the model.\n\nThe PPGVAE is structured so that designs with higher fitness are generated closer to the origin. This means they will be more likely to be sampled when using a normal distribution prior. This is implemented in the form of a constraint between the ratio of log probabilities vs. fitness, and this constraint is relaxed to a weighted penalty.\n\n**Findings**\n\nExperiments showcase that the PPGVAE model can correctly separate between two modes. The modes are defined as the probabilities represented by a two-mode Gaussian mixture model. On protein datasets, the method showcases that the PPGVAE can separate between low and high fitness examples, and that separated models lead to faster convergence when using MBO."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper presents a useful method for learning an exploration prior for model based optimization. In the area of protein design, there are sparse examples of high fitness designs, and many low fitness designs. A good prior should bias towards the space of high-fitness designs, while still making use of all examples. This work presents a simple and clean objective that learns a variational auto-encoder. The methodology is clear and theoretical justification is provided. It may provide significance in the specific problem domain, although the method itself is domain-agnostic."
                },
                "weaknesses": {
                    "value": "The figures of the paper were confusing in terms of what message they were trying to convey. A more informative caption describing why the results are important would improve the clarity here.\n\nThe experiments do showcase the the proposed architecture helps in terms of separating high-fitness examples. It would be insightful to include some experiments on what happens if the VAE is simply trained on only the high-fitness examples and the low-fitness examples are dropped altogether. \n\nIt is unclear the difference between the hard constraint and the soft constraint. Are these just different hyperparameters on the penalty? Or is it a true constraint using i.e. a Lagrange multiplier?"
                },
                "questions": {
                    "value": "See above for a list of questions.\n\nIs the intent of this work to be applicable to other domains, or only protein design? If the answer yes, as implied by the title, it would be greatly strengthening to apply this method on more classical generative modelling tasks larger than MNIST."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698785726523,
            "cdate": 1698785726523,
            "tmdate": 1699636641408,
            "mdate": 1699636641408,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "0qEEjEXPn9",
                "forum": "xhEN0kJh4q",
                "replyto": "nW184lyYZ4",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer soEo"
                    },
                    "comment": {
                        "value": "We thank the reviewer for recognizing the novelty of PPGVAE and proposing new analysis to improve the work.\n\n**Question 1** \nThe figures of the paper were confusing in terms of what message they were trying to convey. A more informative caption describing why the results are important would improve the clarity here\n\n**Response:**\nThanks for the suggestion. We have now updated the captions to be more informative. We have also clarified \"robustness\" in the main text.\n\n**Question 2**\nIt would be insightful to include some experiments on what happens if the VAE is simply trained on only the high-fitness examples and the low-fitness examples are dropped altogether.\n\n**Response:**\nWe thank the reviewer for the suggestion. We have repeated AAV experiments using CEM-PI and the high-fitness samples (\u201cCEM-PI/High\u201d) as the initial training set. The aggregated performance over all imbalance ratios vs the separation level is plotted in Appendix Figure A13 for PPGVAE and CEM-PI (both trained on all samples), as well as CEM-PI/High.\n\nAggregated performance over all imbalance ratios for PPGVAE is better than both CEM-PI and CEM-PI/High. This demonstrates the importance of including all samples in the training (as in PPGVAE). Furthermore, CEM-PI/High has better performance than CEM-PI for higher separation, showing that filtering the samples might be beneficial for weighting based approaches as the optimization task gets harder by separation criterion.\n\nIn practice it is not known where to set the threshold for defining low and high-fitness samples. The weighting-based methods may take advantage of filtering the samples as they suffer more from the overabundance of low-fitness samples; however this comes at the expense of losing the chance of generating samples that are interpolations of low and high fitness samples, which in turn may hurt the overall performance of MBO.\n\n**Question 3**\nIt is unclear the difference between the hard constraint and the soft constraint. Are these just different hyperparameters on the penalty? Or is it a true constraint using i.e. a Lagrange multiplier?\n\n**Response:**\nIn the hard constraint, $\\lambda_r$ (coefficient of the relationship loss, Equation 5) is set to a relatively large constant throughout the training. While in the soft constraint, $\\lambda_r$ gradually decreases as the training goes on. We have added this clarification to the text.\n\n**Question 4**\nIs the intent of this work to be applicable to other domains, or only protein design? If the answer yes, as implied by the title, it would be greatly strengthening to apply this method on more classical generative modelling tasks larger than MNIST.\n\n**Response:**\nThe reviewer is correct in that our method is domain agnostic. However, it was originally motivated to improve MBO for the problem of protein design in challenging real world examples. We mainly used the MNIST example to showcase the characteristics of PPGVAE compared to other approaches. Our intention is to improve upon the current model and apply it for image generation for larger image datasets in future."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612488935,
                "cdate": 1700612488935,
                "tmdate": 1700612488935,
                "mdate": 1700612488935,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "R8aX9bjPn9",
                "forum": "xhEN0kJh4q",
                "replyto": "0qEEjEXPn9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5990/Reviewer_soEo"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5990/Reviewer_soEo"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the response and the clarifications, which look to strengthen the paper. Given that the details above were fixed in the revision, I would update my score to a 6."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633546209,
                "cdate": 1700633546209,
                "tmdate": 1700633546209,
                "mdate": 1700633546209,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "UhnzZO5IAk",
            "forum": "xhEN0kJh4q",
            "replyto": "xhEN0kJh4q",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5990/Reviewer_e46j"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5990/Reviewer_e46j"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses a crucial challenge in protein design, which involves optimization on a fitness landscape. The main concern in current model-based optimization methods is the sparsity of high-fitness samples in training datasets and the separation problem - wherein the desired optimum is situated in a region that is poorly represented and far from low-fitness areas. This paper pinpoints that existing tools do not efficiently handle this separation problem in the design space.\n\nThe authors introduce a new method using Property-Prioritized Generative Variational Auto-Encoder (PPGVAE). This VAE's latent space is structured by the fitness values of the samples, ensuring higher prioritization and generation probability for more desired sequences. This new method aims for better results with fewer optimization steps, which is particularly valuable for sequence design problems.\nA comparative advantage of this approach over prior methods is demonstrated via extensive benchmarks on real and semi-synthetic protein datasets. \n\nThe PPGVAE proves to be superior in robustly finding improved samples, regardless of the imbalance between low- and high-fitness samples and the degree of their separation in the design space. The authors further extend the versatility of their method by testing it on continuous design spaces, showcasing its efficacy on physics-informed neural networks (PINN)."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper recognizes the less-explored challenge of \"separation\" in protein design space, which is a significant departure from recent studies that have mostly focused on the sparsity of high-fitness samples. And The PPGVAE proposed in the paper is an effective approach to tackling the separation issue in model-based optimization.\n\n2. The paper does not just present a theoretical model but comprehensively demonstrates its effectiveness through extensive benchmarking on real and semi-synthetic protein datasets. Beyond just protein datasets, the paper further validates the model on continuous design spaces, exemplified with physics-informed neural networks (PINN)."
                },
                "weaknesses": {
                    "value": "1. Limitation on the conducting experiments exclusively on the real protein dataset of AAV. While this might result in high accuracy and performance metrics within this context, the method may not readily translate to other proteins or protein datasets, especially if they possess distinct characteristics or functionalities."
                },
                "questions": {
                    "value": "1. How easily can PPGVAE be extended to prioritize or balance multiple properties simultaneously? Would this require a significant alteration to the existing framework? \n2. Could you provide insights into the sensitivity of the model's performance to changes in the temperature in the relationship loss?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5990/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5990/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5990/Reviewer_e46j"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5990/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698828488362,
            "cdate": 1698828488362,
            "tmdate": 1699636641305,
            "mdate": 1699636641305,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "DI7BvFEe1L",
                "forum": "xhEN0kJh4q",
                "replyto": "UhnzZO5IAk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5990/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5990/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer e46j"
                    },
                    "comment": {
                        "value": "We thank the reviewer for appreciating the novelty of our work and its extensive benchmark.\n\n**Question 1 (Weakness):**\nExperiments exclusively on the real protein dataset of AAV, hence the method may not readily translate to other proteins or protein datasets.\n\n**Response:**\nThe choice of AAV dataset was mainly due to its wide mutational coverage (samples dispersed in the sequence space) which allows us to test the effectiveness of our approach. Most other experimental protein datasets do not have such wide coverage; this is because typically protein engineering seeks an optimum close to the starting point (wild type). However, there are protein engineering challenges in which the optimum is expected to lie far from the starting sequence, as explained in the paper, e.g., design of an enzyme for an unnatural target substrate.\n\nWe agree with the reviewer that the advantages of our method may not readily translate to the goals of other protein engineering tasks, e.g., when the designer can safely assume the existence of an optimum close to the starting sequence. We strongly believe that our method will open up the opportunity to address the more general but harder engineering problem where this assumption cannot be made. With our method in hand researchers will be more open to embarking on the harder problem, thus leading to more data sets of wide mutational coverage. \n\n**Question 2**\nHow easily can PPGVAE be extended to prioritize or balance multiple properties simultaneously? Would this require a significant alteration to the existing framework?\n\n**Response:**\nThanks for this important question/suggestion. There are two ways to approach this. The simpler approach will be to combine multiple properties into a single property with a proper transformation. A second possible approach may be through modified training of PPGVAE: assign a subset of dimensions in the latent space to each property and enforce the relationship loss for each subset of latent dimensions (property). This idea will require future implementation and testing.\n\n**Question 3**\nCould you provide insights into the sensitivity of the model's performance to changes in the temperature in the relationship loss?\n\n**Response:**\nTo study the sensitivity of performance to temperature, we reran the GMM experiments in the lowest imbalance ratio and highest separation setting (the most challenging scenario), with varying temperature values. The results are included in Appendix E3. Based on this analysis, the performance is almost the same for $\\log_{10}(\\tau)\\in [-1,1]$. Also, the sensitivity to temperature decreases as the number of MBO steps increases (see Figure A13).\n\nIn general, at very high temperature, even small differences in property values will be reflected in the ordering of samples in the latent space. On the other hand, at very low temperature all samples will have the same probability of generation and lie on the same sphere. As an added constraint to the reconstruction loss, both extremes damage a good reconstruction of samples and affect the quality and diversity of generated samples. Thus, it is important to set it to a reasonable value.\n\nWe should point out that we performed all the experiments in the paper with a fixed temperature, as mentioned in the paper. Further tuning of the temperature may improve the results, however we were able to show the usefulness of our approach without tailored tuning for each design scenario."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5990/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700612303494,
                "cdate": 1700612303494,
                "tmdate": 1700612303494,
                "mdate": 1700612303494,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]