[
    {
        "title": "Re-imagine the Negative Prompt Algorithm for 2D/3D Diffusion"
    },
    {
        "review": {
            "id": "RJPFHjdfuz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1066/Reviewer_6H1W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1066/Reviewer_6H1W"
            ],
            "forum": "Q7jXHlWVLC",
            "replyto": "Q7jXHlWVLC",
            "content": {
                "summary": {
                    "value": "This paper solves the training data bias problem in the text-to-image model using a new formulation of negative prompt: Perp-Neg. This paper first presents the perp-neg algorithm where the latents are updated in the perpendicular gradient of \u201cnegative prompt- unconditional prompt\u201c with \u201cpositive prompt - unconditional prompt\u201d. Then, this idea is utilized in solving 2D image generation with Janus problem in text-to-3d."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "It is clever to solve Janus problem using negative prompts. \nThe illustration of the algorithm is very easy to understand and plausible.\nCode is provided to reproduce the results."
                },
                "weaknesses": {
                    "value": "The visual results in the paper are good and interesting. \nA quantitative successful generation rate is also provided. My only concern is result part lacks quantitative fidelity results like FID, clip similarity, and user preference."
                },
                "questions": {
                    "value": "I am happy to see more quantitative results"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Reviewer_6H1W"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1066/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697436996035,
            "cdate": 1697436996035,
            "tmdate": 1699636033082,
            "mdate": 1699636033082,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fZE76r2Ewj",
                "forum": "Q7jXHlWVLC",
                "replyto": "RJPFHjdfuz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1066/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1066/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 6H1W"
                    },
                    "comment": {
                        "value": "Dear Reviewer 6H1W,\n\nThank you for your thorough review and positive feedback on our paper. We appreciate your recognition of our novel approach in solving the Janus problem using a novel negative prompt algorithm.\n\nWe acknowledge your suggestion regarding the inclusion of quantitative fidelity results like FID, CLIP similarity, and user preference. We agree that these metrics will enhance our paper's robustness and will include them in our revised submission.\n\nThank you again for your support and positive comments on the value of our work!!"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1066/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634475270,
                "cdate": 1700634475270,
                "tmdate": 1700634475270,
                "mdate": 1700634475270,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZrmTRAkjZU",
            "forum": "Q7jXHlWVLC",
            "replyto": "Q7jXHlWVLC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1066/Reviewer_j2ct"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1066/Reviewer_j2ct"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes Perp-Neg, a method of using negative prompting without the negative effect of semantic overlap. The basic idea is to find the component of the negative prompt gradient that is orthogonal to the original prompt gradient. The authors show that this method can be used as a more effective negative prompting method, and also helps alleviate the Janus problem in score distillation for 3D generation."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The motivation (Section 2.2.1) is insightful. Semantic overlap seems to be an important drawback of naive negative prompting, and is not mentioned in previous papers before as far as I know.\n\n2. The proposed method (Section 2.2.2 and 2.2.3) is elegant and intuitive.\n\n3. The proposed method shows good qualitative results in generating view-dependent images (Figure 6)."
                },
                "weaknesses": {
                    "value": "1. The proposed method seems to be applicable in many tasks where gradients are mixed during inference (See [1] for an example). But the authors only focus on alleviating the Janus problem in 3D generation. I think it would be a stronger paper if more applications are included.\n\n2. The number of qualitative results of 3D generation is too small. All I can find is Figure 2, 7, 20, which contain 9 examples with overlapping prompts (e.g. lions). The Janus problem is very common in score distillation based generation methods, so more such comparisons with a diverse set of prompts should be presented.\n\n3. The qualitative results for view-dependent image generation (Figure 6, 10-18) re-use the same prompts (lion, panda, peacock) over and over again. It is better to use more different prompts to showcase the effectiveness of the method in the wild.\n\n4. The comparison to other methods of 3D generation is limited and incomplete. I only see it in Figure 2 with 3 examples, and the last one for Magic3D does not show obvious difference to me. Weirdly in Figure 7, the captions claims the original Magic3D model fails to generate satisfactory results, but the figures do not show any of these \"unsatisfactory\" results.\n\n[1] Universal Guidance for Diffusion Models, Bansal et al."
                },
                "questions": {
                    "value": "I think this method is interesting, but why do you focus so much on the Janus problem of 3D generation, instead of trying to demonstrate the method's effectiveness on more applications?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Reviewer_j2ct"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1066/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698541888782,
            "cdate": 1698541888782,
            "tmdate": 1700719636397,
            "mdate": 1700719636397,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Tsaz5DiuEE",
                "forum": "Q7jXHlWVLC",
                "replyto": "ZrmTRAkjZU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1066/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1066/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer j2ct"
                    },
                    "comment": {
                        "value": "Dear Reviewer j2ct,\n\nThank you for your thorough review and insightful observations regarding our submission. Your feedback has been invaluable in enhancing the quality and scope of our research.\n\n**1-Expanding the Scope Beyond 3D Generation:**\n\nWe appreciate your emphasis on the broader potential applications of our Perp-Neg methodology. Initially, our focus was predominantly on 3D generation due to its profound impact and the specific challenges presented by the Janus problem in score distillation-based methods. Recognizing the value of your suggestion, we will extend our research to encompass additional applications, such as segmentation mapping and guided bounding box generation, and leave the rest for future work. \n\n**2-More 3D Experiment**\n\n We thank you for pointing out the need for a wider array of examples. Initially, we presented results from 12 prompts, totaling 240 experiments. Based on your valuable feedback, we expanded our dataset to include 10 additional prompts, each tested with and without Perp-Neg. The diversity and increased number of experiments strengthen our findings, as detailed in the revised Table.\n\nPlease refer to the response provided to reviewer vLLW question 2nd.\n\n**3- More 2D view Experiment**\n\nFor view-dependent images, we've now included varied and creative prompts, enhancing the demonstration of our method's effectiveness in 'real-world' scenarios. The updated results are as follows:\n\n| Prompt                                                 | SD Side View (%) | Ours Side View (%) | SD Back View (%) | Ours Back View (%) |\n|--------------------------------------------------------|------------------|--------------------|------------------|--------------------|\n| Michelangelo style statue of an astronaut              | 37.6             | 62.3               | 22.9             | 47.6               |\n| A blue poison-dart frog sitting on a water lily        | 46.9             | 71.7               | 32.1             | 56.9               |\n| A humanoid robot using a laptop                        | 47.9             | 68.9               | 36.9             | 57.9               |\n| A kangaroo sitting on a bench playing the accordion    | 39.6             | 60.1               | 22.2             | 42.7               |\n| A rabbit cutting grass with a lawnmower                | 42.6             | 66.3               | 28.9             | 52.6               |\n| A teddy bear pushing a shopping cart full of fruits... | 51.2             | 74.0               | 38.4             | 61.2               |\n| A high quality photo of a classic silver muscle car    | 78.4             | 93.2               | 64.6             | 88.4               |\n| A DSLR photo of a yellow duck                          | 46.8             | 70.7               | 16.4             | 28.4               |\n| A photo of a horse walking                             | 46.3             | 78.5               | 36.1             | 68.2               |\n| A chimpanzee dressed as a football player              | 39.9             | 64.8               | 25.0             | 49.9               |\n\n\n**4(a)- More 3D Baseline**\n\nThanks for raising this point! Our intention was not to directly compete with existing text-to-3D models but to show how Perp-Neg can enhance them as a plug-in when combined with them. We will clarify this in the paper. The provided examples, highlight the significant reduction of the Janus problem when our method is integrated into these baselines. \n\n**4(b)- Figure 7 Clarification**\n\nTo clarify, Figure 7 in our paper is intended to demonstrate the improved results achieved by integrating Perp-Neg with the Magic3D model. We acknowledge that the absence of standalone results from \"Magic3D without Perp-Neg\" might have caused a lack of context and confusion. \n\nFigure 7 only shows the result of \"Magic3D + Perp-Neg.\" To make things clearer, we'll add some pictures to the appendix of our paper. These pictures will show what happens when we use \"Magic3D without Perp-Neg\" method. This will help show why our method is important and how it fixes the problems with Magic3D. For all tries \"Magic3D without Perp-Neg\" we observed the Janus problem.\n\nWe are truly grateful for your comprehensive review and constructive feedback, which have been instrumental in enhancing the quality and clarity of our paper. Thank you so much!"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1066/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700633881496,
                "cdate": 1700633881496,
                "tmdate": 1700633881496,
                "mdate": 1700633881496,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3Skh3IdMMB",
                "forum": "Q7jXHlWVLC",
                "replyto": "Tsaz5DiuEE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1066/Reviewer_j2ct"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1066/Reviewer_j2ct"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the additional experiments. I will increase my rating to 6."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1066/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719620073,
                "cdate": 1700719620073,
                "tmdate": 1700719620073,
                "mdate": 1700719620073,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DZvNeediM9",
            "forum": "Q7jXHlWVLC",
            "replyto": "Q7jXHlWVLC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1066/Reviewer_Vwgv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1066/Reviewer_Vwgv"
            ],
            "content": {
                "summary": {
                    "value": "The submission discusses the limitations of text-to-image diffusion models that the 2D results of diffusion models can not align exactly with the provided prompt in terms of the view angles. To address this issue, the authors propose a new algorithm called Perp-Neg, which leverages geometrical properties of the score space and does not require any training or fine-tuning of the model. The algorithm can be applied to both 2D and 3D generation. The paper shows the effectiveness of Perp-Neg in addressing the Janus problem in 3D object generation, the results show a fair improvement in the success rate of side/back views, leading to more view-consistent 3D objects. Additionally, the appendix contains sufficient ablations that confirm the importance of the design choices."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "While the proposed method is simple, the authors have demonstrated its efficacy in 2D/3D diffusion. In addition, it does not require offline training and fine-tuning of the image diffusion model and can preserve the generalizability of the original diffusion model to a great extent.\n\nThe paper is clearly written and well organized, and the pipeline described in this submission is technically sound and reproducible.\n\nSufficient evaluations, such as the quantitative results of the success rate and qualitative results of the generated images of the side and back sides."
                },
                "weaknesses": {
                    "value": "One of the most important applications of the proposed method is to boost the text-to-3D generation task. However, the experiment results shown in the paper mainly focus on 2D images on the side/back views, rather than the 3D generation.\n\nThe generated 3D objects are rather simple, so the effectiveness of the proposed method in the 3D generation of detailed objects needs to be further verified.\n\nThe comparison is a bit weak, it seems like CEBM is not designed for the task of this submission. Instead, the work [1], which also focuses on the view-consistent text-to-3D generation, should be cited and compared.\n\n[1] Hong et. al., Debiasing Scores and Prompts of 2D Diffusion for View-consistent Text-to-3D Generation, NIPS 2023"
                },
                "questions": {
                    "value": "What is the Compositional Energy-based Model (CEBM) and why choose it as a competing baseline? The paper does not provide an explanation for this choice, nor does it refer to any related work for CEBM.\n\nWhat are the consequences of using just negative prompts instead of the proposed Perp-Neg in 3D generation? I think simply using negative prompts the regulate the 2D results on the back/side views may also alleviate the janus problem."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1066/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810221403,
            "cdate": 1698810221403,
            "tmdate": 1699636032920,
            "mdate": 1699636032920,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7eGfXOsoWL",
                "forum": "Q7jXHlWVLC",
                "replyto": "DZvNeediM9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1066/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1066/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer Vwgv,\n\nWe are truly grateful for your valuable feedback on our manuscript. We have carefully considered your comments and have made several enhancements to our paper to address your concerns.\n\n**1-Focus on 2D Images and Relevance to 3D Generation:**\n\nThanks for raising this point! We will clarify in the paper that in our initial submission, we conducted 240 trials of text-to-3D generation, incorporating 12 different prompts. Our emphasis on 2D was primarily due to the significant computational demands of 3D experiments. Each 3D trial required over 30 minutes of processing, compared to just 8 seconds for 2D.\n\nAdditionally, we found that improvements in 2D were closely linked to enhancements in 3D generation, offering a more efficient pathway to examine the root cause of the Janus problem. We will add this clarification to the revised manuscript to better explain our methodology and focus.\n\n**2-Extended Experiments and Comparative Analysis with Paper [1]:**\n\nIn response to your suggestion, we expanded our experimental scope. We conducted an additional 180 experiments for each prompt, with variations including the use of Perp-Neg, no Perp-Neg, and prompt debiasing (using DeepFloyd-IF). These experiments have provided more comprehensive insights into the effectiveness of our proposed method, especially in comparison to the work presented in Hong et al. (2023). We will include these additional results and a more thorough comparative analysis in our revised manuscript.\n\nHere are the updated results from these experiments:\n\n| Prompt                                                         | % Success with Perp-Neg | % Success without Perp-Neg | % Success with Prompt Debiassing |\n|----------------------------------------------------------------|-------------------------|----------------------------|----------------------------------|\n| Michelangelo style statue of an astronaut                      | 50.00%                  | 16.67%                     | 33.33%                           |\n| Blue poison-dart frog sitting on a water lily                  | 66.67%                  | 33.33%                     | 66.67%                           |\n| Humanoid robot using a laptop                                  | 50.00%                  | 16.67%                     | 33.33%                           |\n| Kangaroo sitting on a bench playing the accordion              | 50.00%                  | 0.00%                      | 33.33%                           |\n| Rabbit cutting grass with a lawnmower                          | 66.67%                  | 33.33%                     | 50.00%                           |\n| Teddy bear pushing a shopping cart full of fruits and vegetables | 50.00%               | 0.00%                      | 16.67%                           |\n| High quality photo of a classic silver muscle car              | 83.33%                  | 83.33%                     | 83.33%                           |\n| DSLR photo of a yellow duck                                    | 33.33%                  | 0.00%                      | 33.33%                           |\n| Photo of a horse walking                                       | 33.33%                  | 0.00%                      | 33.33%                           |\n| Chimpanzee dressed as a football player                        | 33.33%                  | 16.67%                     | 16.67%                           |\n\n\nThese findings reinforce our initial conclusions and demonstrate the practical effectiveness of Perp-Neg in various scenarios.\n\n**3-Simplicity of Generated 3D Objects and Detailed Object Generation:**\n\nThank you so much for this comment! Our choice of simple prompts was intentional, as we aimed to isolate and address the view consistency issue without the confounding factor of complex object generation. By confounding factors, we refer to the problem of the text-to-image model missing some objects provided in the prompt. However, following your suggestion, we have now also tested our algorithm with more complex prompts and provided the result above.\n\n**4-Choice of CEBM as a Baseline and Exploration of Negative Prompts:**\n\nThanks for this question! We would like to clarify that the Compositional Energy-based Model (CEBM) is exactly the naive negative prompt algorithm. CBEM just mathematically motivates why the negative prompt algorithm works.  In the revised version of our paper, we will clarify this distinction more explicitly to ensure a better understanding of why CEBM was referenced \n\n We want to express our sincere gratitude for the time and effort you've dedicated to reviewing our paper.  Thank you again for your invaluable contribution to our work."
                    },
                    "title": {
                        "value": "Response to Reviewer Vwgv"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1066/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627320604,
                "cdate": 1700627320604,
                "tmdate": 1700630258343,
                "mdate": 1700630258343,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Eq11GV0JG9",
            "forum": "Q7jXHlWVLC",
            "replyto": "Q7jXHlWVLC",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1066/Reviewer_vLLW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1066/Reviewer_vLLW"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a Perp-Neg method to control the text-to-image diffusion model by pependicular gradient sampling. This method leverage the geometry properties of the score space in diffusion models.  Authors present experiments of this method in 2d image translation and 3D generative models with SDS to mitigate the janus problem in text-to-3D task."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed pependicular gradient sampling is performed on the latent noise space of diffusion models, is easy to follow. \n2. This method gives a tractable method to balance betweet the score of postive and negative text prompts. \n3. The method is easy to implement and follow."
                },
                "weaknesses": {
                    "value": "1. The assumption of this method is based on the pependicular gradient sampling, but this design is somewhat heuristic, and have not been proved in the paper. \n2. Weakness 1 caused the effectiveness of this method on text-to-3D is limited actually. Janus problems almost cannot be mitigated according to implementation in threestudio. [1]\n3. The balance factor defined between eq.8 and eq.9 may be hard to tune in experiments\n\n[1] https://github.com/threestudio-project/threestudio/issues/8"
                },
                "questions": {
                    "value": "please refer to the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1066/Reviewer_vLLW"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1066/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699035964300,
            "cdate": 1699035964300,
            "tmdate": 1699636032842,
            "mdate": 1699636032842,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "JPEx5J2jbB",
                "forum": "Q7jXHlWVLC",
                "replyto": "Eq11GV0JG9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1066/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1066/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to the reviewer vLLW"
                    },
                    "comment": {
                        "value": "Dear Reviewer vLLW,\n\nWe greatly appreciate your comprehensive review and constructive feedback on our paper. Your insights are invaluable in refining our paper!\n\n**1-Regarding Perpendicular Gradient Sampling Theory:**\n\nWe acknowledge your concern regarding the lack of formal mathematical proof for our perp-neg method. While a formal mathematical proof is not presented, we believe our geometric reasoning and mathematical motivations, detailed in sections 2.2.1 and 2.2.2, provide a solid foundation for our approach. We appreciate your pointing out this limitation and will consider adding a more rigorous theoretical underpinning in future work.\n\n**2-Effectiveness of Perp-Neg in alleviating the Janus Problem - Threestudio:**\n\nWe acknowledge your concern about our method's limited effectiveness in text-to-3D as highlighted in the Threestudio implementation.\n\nIt is essential to clarify that the Threestudio version is a derivative of our original algorithm and does not mirror our methodology or results. In our experiments, we observed a significant reduction in the Janus problem, as presented in the appendix. \n\nIn our experiments, comprising 240 trials (120 with Perp-Neg and 120 without), we observed a significant mitigation of the Janus problem. The following table, which we plan to include in the revised manuscript, details our findings:\n\n| Algorithm                     | Perp-Neg Usage    | Acceptance Rate | Total Trials | Total Prompts |\n|-------------------------------|-------------------|-----------------|--------------|---------------|\n| Stable-Diffusion DreamFusion  | With Perp-Neg     | 20.24%          | 84           | 6             |\n| Stable-Diffusion DreamFusion  | Without Perp-Neg  | 7.14%           | 84           | 6             |\n| DeepFloyd-IF DreamFusion      | With Perp-Neg     | 50.00%          | 36           | 6             |\n| DeepFloyd-IF DreamFusion      | Without Perp-Neg  | 2.78%           | 36           | 6             |\n\nOverall, our method with Perp-Neg demonstrated a 29.17% improvement over the non-Perp-Neg approach (5.83%). These results are presented in the original manuscript with 12 different prompts in total. We have mentioned the success rate for each prompt in the paper.\n\n\nIt's crucial to note that while we haven't entirely solved the Janus problem, our method offers a significant advancement in addressing it. We will clarify this in the paper.\n\nFollowing your suggestion and other reviewers, we will also include an additional 120 experiment results on text-to-3D experiments in the appendix to further substantiate our claims. The table of the new results is presented in the following:\n\n| Prompt                                                             | % Success with Perp-Neg | % Success without Perp-Neg |\n|:-------------------------------------------------------------------|------------------------:|---------------------------:|\n| Michelangelo style statue of an astronaut                          |                 50.00%  |                    16.67% |\n| A blue poison-dart frog sitting on a water lily                    |                 66.67%  |                    33.33% |\n| A humanoid robot using a laptop                                    |                 50.00%  |                    16.67% |\n| A kangaroo sitting on a bench playing the accordion                |                 50.00%  |                     0.00% |\n| A rabbit cutting grass with a lawnmower                            |                 66.67%  |                    33.33% |\n| A teddy bear pushing a shopping cart full of fruits and vegetables |                 50.00%  |                     0.00% |\n| A high quality photo of a classic silver muscle car                |                 83.33%  |                    83.33% |\n| A DSLR photo of a yellow duck                                      |                 33.33%  |                     0.00% |\n| A photo of a horse walking                                         |                 33.33%  |                     0.00% |\n| A chimpanzee dressed as a football player                          |                 33.33%  |                    16.67% |\n\n\n**3-On Tuning the Balance Factor Between Equations 8 and 9:**\n\nWe appreciate your concern about the balance factor's tuning difficulty. We wanted to clarify that Equation 9 is used across all text-to-3D tasks. Regarding the weight of negative prompts, we found that the model is not sensitive to the weight of negative prompts if they are beyond a certain threshold, as observed in both 2D and 3D settings. This observation will be elaborated in our revised manuscript for better clarity.\n\nThank you once again for your thorough evaluation and constructive criticism. Your feedback has been instrumental in refining our work, and we are confident that these revisions will significantly improve our paper."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1066/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700623940321,
                "cdate": 1700623940321,
                "tmdate": 1700624154910,
                "mdate": 1700624154910,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wp6rTKZcAb",
                "forum": "Q7jXHlWVLC",
                "replyto": "Eq11GV0JG9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1066/Reviewer_vLLW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1066/Reviewer_vLLW"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nI appreciate your response. These added experiments have addressed some of my concerns.\nHowever, I still have doubts about the effectiveness of your methods in text-to-3D models.\n\nI have tried your released code, but it is still prone to generating Janus-faced objects.\nThe interpolation weight between the negative prompts and positive prompts is hard to decide; it needs to be tuned case by case.\n\nBesides, I also tried your code on 2D-image generation. I found that the generated image may encounter distortions and oversaturation when adopting your proposed method. I speculate it's the perp-neg sampling method in Equation 6 that poses an OOD issue for the latent decoder of diffusion models.\n\nSo, I tend to keep my previous rating."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1066/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720574089,
                "cdate": 1700720574089,
                "tmdate": 1700720794692,
                "mdate": 1700720794692,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]