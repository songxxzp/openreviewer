[
    {
        "title": "Towards robust unlearnable examples via deep hiding"
    },
    {
        "review": {
            "id": "TAqRKIxRop",
            "forum": "JKpk2p4O99",
            "replyto": "JKpk2p4O99",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7150/Reviewer_Xq8x"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7150/Reviewer_Xq8x"
            ],
            "content": {
                "summary": {
                    "value": "The majority of existing methods for generating Unlearnable Examples primarily focus on investigating the robustness against adversarial training, while overlooking the resilience to other attack strategies such as data augmentation and preprocessing. Previous research has found that images containing semantic information are robust against common attacks. In this paper, the authors propose a novel defense mechanism that is effective under various prevalent attack methods. The authors first generate multiple image samples corresponding to the number of categories using ControlNet, and then employ Image Hiding techniques to conceal the generated image samples within the dataset to be protected, utilizing Invertible Neural Networks (INN). This process disrupts the original semantic information of the images, thereby achieving the goal of protecting the data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The authors introduce Image Hiding techniques into Data Unlearning, providing a new reference direction for the field of Data Unlearning.\n- The authors employ a Latent Feature Concentration module during the image hiding process to achieve consistency in semantic features within the same class, thus allowing the features of similar data to become more concentrated.\n- The selection of attack methods for the experiments in this paper is fairly comprehensive."
                },
                "weaknesses": {
                    "value": "- The method consists of three modules: The Deep Hiding Scheme, which introduces the concept of Image Hiding, an existing work; the Semantic Image Generation Module, which utilizes the existing ControlNet; and the Latent Feature Concentration Module, which is very similar to the idea of EntF mentioned in the related work. In summary, the ideas presented in this paper are intriguing, but the innovation is insufficient.\n- Previous research has shown that some Unlearnable Examples possess an inherent resistance to data augmentation, which contradicts the paper's claim that prior methods have overlooked these issues.\n- In the experimental settings of the paper, the perturbation for adversarial training is set to $8/255$, and the perturbation for protection noise also appears to be set to $8/255$ according to the experimental table. Under this setting, which is consistent with EntF, the paper's experiments lack a comparison with this method.\n- The paper doesn't explain why it's also effective under adversarial training.\n\nAlthough the introduction of Image hiding in the paper is interesting, the three important parts of the article are existing work and lack innovation. In addition, there is a lack of comparison of EntF methods, a lack of inquiry about defense against training, and a lack of inquiry about the effect of the generated hiding image on protection. All in all, at this point in time, I would recommend this paper as weak reject."
                },
                "questions": {
                    "value": "see weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7150/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697700491997,
            "cdate": 1697700491997,
            "tmdate": 1699636846789,
            "mdate": 1699636846789,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uoMpEx43E4",
                "forum": "JKpk2p4O99",
                "replyto": "TAqRKIxRop",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** The method consists of three modules: The Deep Hiding Scheme, which introduces the concept of Image Hiding, an existing work; the Semantic Image Generation Module, which utilizes the existing ControlNet; and the Latent Feature Concentration Module, which is very similar to the idea of EntF mentioned in the related work. In summary, the ideas presented in this paper are intriguing, but the innovation is insufficient.\n\n**Ans:** Thank you for the comments. We would like to clarify that our Latent Feature Concentration module (LFC) differs from EntF in various aspects. Firstly, EntF aims to generate entangled features associated with perturbed data, causing confusion in models; while our module encourages the concentration of the perturbation itself, creating stronger shortcuts. Secondly, EntF focuses on robustness against adversarial training, while we use LFC to achieve more general robustness. Besides, we would like to emphasize our novelty in semantic-based unlearnable examples. The proposed modules (i.e., Semantic Image Generation (SIG) and LFC) all combine to increase the inter-class distance and reduce the intra-class variance, enhancing the general robustness of unlearnable examples, shown in Table 4.\n\n\n\n\n**Table 4: Ablation studies on CIFAR10 for designed Latent Feature Concentration module (LFC), and Semantic Images Generation module (SIG), including Text Prompts Clustering (TPC) and Stable Diffusion model and ControlNet (SD+C).**\n\n\n| Setting | LFC | SIG: TPC | SIG: SD+C | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR   | Gray  | GaussN | GaussF | JPEG10 | JPEG50 | AT    | Mean  |\n|:-------:|:---:|:--------:|:---------:|:-------:|:------:|:------:|:-----:|:-----:|:-------:|:-----:|:-----:|:------:|:------:|:------:|:------:|:-----:|:-----:|\n| Sample-wise|   \u00d7  |       \u00d7   |        \u00d7   | 94.08   | 94.52  | 94.07  | 88.23 | 65.42 | 87.04   | 89.46 | 91.45 | 88.36  | 94.07  | 83.29  | 89.97  | 86.26 | 88.17 |\n|    Sample-wise     | \u00d7    | \u2713        | \u2713         | 14.77   | 22.20  | 13.06  | 23.44 | 30.18 | 51.43   | 35.66 | 17.31 | 37.50  | 15.80  | 81.97  | 81.48  | 81.24 | 38.93 |\n|  Sample-wise       | \u2713   |    \u00d7       | \u2713         | 10.00   | 16.53  | 20.81  | 17.14 | 18.51 | 21.73   | 24.98 | 13.85 | 22.07  | 10.59  | 80.09  | 82.90  | 46.54 | 29.67 |\n|    Sample-wise     | \u2713   |    \u00d7       |    \u00d7        | 94.09   | 94.34  | 93.84  | 94.00 | 64.55 | 85.94   | 88.86 | 91.00 | 88.70  | 94.20  | 82.84  | 90.31  | 85.31 | 88.38 |\n|     Sample-wise    | \u2713   | \u2713        | \u2713         | 15.36   | 10.79  | 10.00  | 14.72 | 17.68 | 17.00   | 21.12 | 17.61 | 22.78  | 11.16  | 80.41  | 81.03  | 38.31 | **27.54** |\n| Class-wise |  \u00d7    |     \u00d7      |    \u00d7        | 12.16   | 11.02  | 11.43  | 10.81 | 10.14 | 13.28   | 10.10 | 12.12 | 10.00  | 10.00  | 78.21  | 15.32  | 12.87 | 16.73 |\n|    Class-wise     |  \u00d7    | \u2713        | \u2713         | 10.00   | 10.00  | 10.06  | 10.82 | 13.26 | 25.76   | 15.83 | 14.20 | 10.03  | 10.00  | 76.26  | 20.28  | 14.78 | 18.56 |\n|    Class-wise     | \u2713   |      \u00d7     | \u2713         | 10.00   | 10.00  | 10.00  | 12.32 | 9.72  | 10.00   | 10.00 | 10.59 | 10.00  | 10.00  | 71.44  | 30.27  | 10.00 | 16.49 |\n|    Class-wise     | \u2713   |     \u00d7      |    \u00d7        | 10.00   | 10.00  | 11.41  | 10.00 | 10.01 | 11.71   | 10.00 | 10.01 | 10.00  | 10.00  | 58.38  | 10.05  | 10.00 | **13.97** |\n|    Class-wise     | \u2713   | \u2713        | \u2713         | 10.00   | 10.00  | 11.25  | 10.02 | 10.59 | 10.04   | 13.53 | 10.00 | 10.00  | 10.00  | 72.97  | 23.62  | 10.00 | 16.31 |\n\n**Q2:** Previous research has shown that some Unlearnable Examples possess inherent resistance to data augmentation, which contradicts the paper's claim that prior methods have overlooked these issues.\n\n**Ans:** We agree that previous works have shown resistance to data augmentations to some extent. However, the recent work ISS[G] found that these methods are extremely vulnerable to simple data processing like Grayscaling and JPEG compression with low quality factors. We follow the protocol in ISS and gain insights from the results in Table 1:\n- The existing methods are not generally robust against different types of data augmentations and processing. For example, though EM and REM are resistant to popular data augmentations like cutout and mixup, they are very vulnerable to grayscaling and JPEG compression.\n- The existing methods are not resistant to the countermeasures with higher-level severity. We find most of the existing methods will be mitigated once the quality factor of JPEG decreases to 10.\nAs a result, we argue that the resistance of UEs against countermeasures is not generally solved. We aim to improve general robustness with the deep hiding technique in this paper.\n\n```\n[G] Zhuoran Liu, Zhengyu Zhao, and Martha A. Larson. \"Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression.\" In International Conference on Machine Learning, 2023.\n```"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700472614328,
                "cdate": 1700472614328,
                "tmdate": 1700479639231,
                "mdate": 1700479639231,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5v5J5PvdOj",
            "forum": "JKpk2p4O99",
            "replyto": "JKpk2p4O99",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7150/Reviewer_4Lh6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7150/Reviewer_4Lh6"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on methods for generating unlearnable samples. The paper takes the unique perspective of deep hiding and improves based on existing deep hiding methods, which consequently proposes new methods for generating unlearnable samples. Experiments demonstrate the effectiveness and robustness of the proposed method."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well written and has clear figures.\n\n2. The paper proposed methods for generating unlearnable samples from such an interesting perspective as deep hiding.\n\n3. The experiments demonstrate the high effectiveness and robustness of the method proposed in the paper."
                },
                "weaknesses": {
                    "value": "1. The comparison experiments do not show the relationship between the scale of the perturbations generated by the proposed method and the comparison method, and the size of the generated perturbations cannot be fully controlled by $L_{hide}$ alone, because there are other losses included in the total loss.\n\n2. An ablation experiment on the semantic image generation module is missing to demonstrate its advantages compared with randomly selected hidden images."
                },
                "questions": {
                    "value": "1. There is a backward revealing process for the INN-based hiding model used in the paper, but what is the significance of the existence of this process?\n\n2. The paper proposed a concentration loss (Eq. 7), and how are sample i and sample j selected in the specific implementation?\n\n\n======================After rebuttal===================\n\nThe authors' response address most of my concerns. Thus I am willing to increase the rating score to 6."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7150/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7150/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7150/Reviewer_4Lh6"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7150/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698539694509,
            "cdate": 1698539694509,
            "tmdate": 1700711800927,
            "mdate": 1700711800927,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Sor5WN05Wj",
                "forum": "JKpk2p4O99",
                "replyto": "5v5J5PvdOj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** The comparison experiments do not show the relationship between the scale of the perturbations generated by the proposed method and the comparison method, and the size of the generated perturbations cannot be fully controlled by alone, because there are other losses included in the total loss.\n\n**Ans:** Thank you for your insightful comment. We evaluate the image quality (PSNR) between the generated unlearnable examples and clean image to analysize the perturbation scale. The PSNR results are: Ours (34.04), EM(34.17), REM(33.96), TAP(35.86) and LSP(37.73). This similarity in image quality indicates our method achieve comparable scale of the pertuibations compared to comparison methods.\nDespite we did not solely control the perturbation loss, this result further demonstrates that our perturbation loss incorporates well with other losses to restrict the perturbation scale (8/255) during joint optimization.\n\n**Q2:** An ablation experiment on the semantic image generation module is missing to demonstrate its advantages compared with randomly selected hidden images.\n\n**Ans:** Thank you for the comments. We conduct a comprehensive ablation study on the effectiveness of the semantic image generation module. We show the results in Table 4 and we have added it into the paper. In the class-wise setting, we find that the improvement of the generation module is marginal; however, in the sample-wise setting, the semantic generation module (SIG) can degrade the mean accuracy from 88% to 38%. It is further reduced to 27.5% with latent feature concentration (LFC). When we disentangle the text prompt clustering (TPC) and Stable Diffusion+ControlNet generation (SD+C), we find that SD+C contributes the most and TPC contributes around a 2% reduction. The ablation study shows that each component in our proposed method plays an important role in the generally robust unlearnable examples.\n\n**Table 4: Ablation studies on CIFAR10 for designed Latent Feature Concentration module (LFC), and Semantic Images Generation module (SIG), including Text Prompts Clustering (TPC) and Stable Diffusion model and ControlNet (SD+C).**\n\n| Setting | LFC | SIG: TPC | SIG: SD+C | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR   | Gray  | GaussN | GaussF | JPEG10 | JPEG50 | AT    | Mean  |\n|:-------:|:---:|:--------:|:---------:|:-------:|:------:|:------:|:-----:|:-----:|:-------:|:-----:|:-----:|:------:|:------:|:------:|:------:|:-----:|:-----:|\n| Sample-wise|   \u00d7  |       \u00d7   |        \u00d7   | 94.08   | 94.52  | 94.07  | 88.23 | 65.42 | 87.04   | 89.46 | 91.45 | 88.36  | 94.07  | 83.29  | 89.97  | 86.26 | 88.17 |\n|    Sample-wise     | \u00d7    | \u2713        | \u2713         | 14.77   | 22.20  | 13.06  | 23.44 | 30.18 | 51.43   | 35.66 | 17.31 | 37.50  | 15.80  | 81.97  | 81.48  | 81.24 | 38.93 |\n|  Sample-wise       | \u2713   |    \u00d7       | \u2713         | 10.00   | 16.53  | 20.81  | 17.14 | 18.51 | 21.73   | 24.98 | 13.85 | 22.07  | 10.59  | 80.09  | 82.90  | 46.54 | 29.67 |\n|    Sample-wise     | \u2713   |    \u00d7       |    \u00d7   | 94.09   | 94.34  | 93.84  | 94.00 | 64.55 | 85.94   | 88.86 | 91.00 | 88.70  | 94.20  | 82.84  | 90.31  | 85.31 | 88.38 |\n|     Sample-wise    | \u2713   | \u2713  | \u2713  | 15.36   | 10.79  | 10.00  | 14.72 | 17.68 | 17.00   | 21.12 | 17.61 | 22.78  | 11.16  | 80.41  | 81.03  | 38.31 | **27.54** |\n| Class-wise |  \u00d7    |     \u00d7      |    \u00d7        | 12.16   | 11.02  | 11.43  | 10.81 | 10.14 | 13.28   | 10.10 | 12.12 | 10.00  | 10.00  | 78.21  | 15.32  | 12.87 | 16.73 |\n|    Class-wise     |  \u00d7    | \u2713   | \u2713   | 10.00   | 10.00  | 10.06  | 10.82 | 13.26 | 25.76   | 15.83 | 14.20 | 10.03  | 10.00  | 76.26  | 20.28  | 14.78 | 18.56 |\n|    Class-wise     | \u2713   |  \u00d7     | \u2713   | 10.00   | 10.00  | 10.00  | 12.32 | 9.72  | 10.00   | 10.00 | 10.59 | 10.00  | 10.00  | 71.44  | 30.27  | 10.00 | 16.49 |\n|    Class-wise     | \u2713   |  \u00d7  |    \u00d7  | 10.00   | 10.00  | 11.41  | 10.00 | 10.01 | 11.71   | 10.00 | 10.01 | 10.00  | 10.00  | 58.38  | 10.05  | 10.00 | **13.97** |\n|    Class-wise     | \u2713   | \u2713 | \u2713  | 10.00   | 10.00  | 11.25  | 10.02 | 10.59 | 10.04   | 13.53 | 10.00 | 10.00  | 10.00  | 72.97  | 23.62  | 10.00 | 16.31 |\n\n**Q3:** There is a backward revealing process for the INN-based hiding model used in the paper, but what is the significance of the existence of this process?\n\n**Ans:** The backward revealing process is necessary to ensure that the semantic image is successfully hidden into the clean images.\nIn the case of without revealing process, the network tends to embed nothing for satisfying the invisibility.\nIn practice, during inference when generating UE, we do not require the revealing process but only utilize the hiding process.\n\n**Q4:** The paper proposed a concentration loss (Eq. 7), and how are sample i and sample j selected in the specific implementation?\n\n**Ans:** Sample ij refers to two samples within the same minibatch that have the same label. This is because our LFC only operates on pairs of samples with matching labels."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700479525647,
                "cdate": 1700479525647,
                "tmdate": 1700479525647,
                "mdate": 1700479525647,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "siMIBH6DBh",
                "forum": "JKpk2p4O99",
                "replyto": "Sor5WN05Wj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Reviewer_4Lh6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Reviewer_4Lh6"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thanks for the authors' respnse. Although the authors provide some results and explanations, I still believe that solely controlling the perturbation loss is useful to comprehensively present the effects of the proposed method. I am sorry that the I will maintain the original rating score."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700643701450,
                "cdate": 1700643701450,
                "tmdate": 1700643701450,
                "mdate": 1700643701450,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LIORs3XWAz",
                "forum": "JKpk2p4O99",
                "replyto": "5v5J5PvdOj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your prompt response and insightful speculation.\n\nTo demonstrate the impact of solely training with perturbation loss (i.e., **$\\mathcal{L}_{hide}$**), we conduct relevant experiments. **1.** The training plot (Figure A in the supp) shows that the perturbation loss remains at 0, which indicates there is no optimization in hiding semantic images. **2.** The perturbation maps generated by the hiding model trained on only **$\\mathcal{L}_{hide}$** ( Figure B in the supp) show minimal information with no semantic patterns (i.e., black images). **3.** Our evaluation of unlearnable examples generated with only **$\\mathcal{L}_{hide}$** reveals that the test accuracy is close to that of clean images (Table. K). This indicates that minimal information is hidden in clean images, leading to ineffective unlearnability. \n\n**Table. K: Evaluation of the different hiding models trained by solely controlling the hiding loss (**$\\mathcal{L}_{\\text{hide}}$**) and using our designed loss ($\\mathcal{L}_{\\text{total}}$). The test accuracy (\\%) is evaluated on CIFAR-10 in the class-wise setting.**\n| Method | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR | Gray | GaussN | GaussF | JPEG10 | JPEG50 | AT | Mean |\n| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n| Clean | 94.59 | 95.00 | 94.77 | 94.96 | 49.70 | 86.64 | 89.07 | 92.80 | 88.71 | 94.54 | 85.22 | 90.89 | 84.19 | 87.78 |\n| only $\\mathcal{L}_{\\text {hide }}$ | 94.71 | 95.05 | 94.68 | 95.4 | 38.88 | 87.39 | 89.12 | 93.1 | 88.55 | 87.39 | 85.04 | 91.04 | 88.59 | 86.84 |\n| ours | 10.00 | 10.00 | 11.25 | 10.02 | 10.59 | 10.04 | 13.53 | 10.00 | 10.00 | 10.00 | 72.97 | 23.62 | 10.00 | **16.31** |\n\nThis phenomenon is because only controlling the perturbation loss (i.e., $\\mathcal{L}_{hide}$) alone will lead to unstructured minimal perturbation. When solely optimizing the perturbation loss, the network tends to discard the information of the semantic image to meet the requirement of minimizing the difference between the clean image and generated UE rather than hide it. Thus, the revealing loss is important to enforce the network to hide the information of semantic image into the clean image by ensuring the revealing of the hidden information from the UE. \n\nBased on the experimental results and our analysis, we argue that the revealing process with reveal loss is necessary to hide semantic information to create UEs. We hope it can address your concerns."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700681485446,
                "cdate": 1700681485446,
                "tmdate": 1700685561218,
                "mdate": 1700685561218,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "C0ILVrUnPB",
                "forum": "JKpk2p4O99",
                "replyto": "LIORs3XWAz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Reviewer_4Lh6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Reviewer_4Lh6"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thanks for your quick response. Based on the results you provided, I recognize the validity of the proposed method. Thus, I am willing to increase the rating score."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700711368403,
                "cdate": 1700711368403,
                "tmdate": 1700711368403,
                "mdate": 1700711368403,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Nj8e0PMerz",
            "forum": "JKpk2p4O99",
            "replyto": "JKpk2p4O99",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7150/Reviewer_Naq4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7150/Reviewer_Naq4"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a novel method to generate robust unlearnable examples by hiding semantic images within clean images using invertible neural networks (INNs). This introduces perturbations to mislead classifiers while leveraging semantic features that are robust to countermeasures. A Latent Feature Concentration (LFC) module regularizes the intra-class variance of perturbations. A Semantic Images Generation module creates hidden images with consistent semantics within a class to maximize inter-class separation. Experiments on CIFAR and ImageNet datasets demonstrate state-of-the-art unlearnability and robustness against data augmentations and preprocessing."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Novel deep hiding scheme to generate unlearnable examples by hiding semantic images using INNs. \n\n2. Introduces LFC module to regularize intra-class variance of perturbations.  \n\n3. Introduces Semantic Image Generation module to maximize inter-class separation. \n\n4. State-of-the-art results on CIFAR and ImageNet datasets against various countermeasures."
                },
                "weaknesses": {
                    "value": "1. Additional Requirements of generating a large dataset of semantic images using paired text prompts and canny edge maps. \n\n2. The sample-wise setting may leak information about hidden images. If some hackers know an image is protected in this way, they may find a countermeasure for the unlearnable examples based on the proposed hidden semantic generations.  \n\n3. A pre-trained ResNet-18 is used as the feature extractor, all text prompts are clustered using K-means with the semantic features from the CLIP model, and Stable Diffusion model and ControlNet to generate semantic images. It's hard to analyze the effectiveness of each component.  \n\n4. From the above, the connection between the hidden image and the unlearnable example is unclear. The hidden semantic image may not directly contribute to unlearnability.  \n\n5. The robustness and effectiveness may come from the pre-trained ResNet-18, CLIP, Stable Diffusion, or ControlNet. Therefore, the effectiveness and robustness may not come from the architecture and the idea; instead, these may only come from the extra information from the four pre-trained models.  \n\n6. Although an LFC (a pretrained ResNet18) is used to regularize intra-class variance, and the CLIP, Stable Diffusion, and ControlNet are used to maximize inter-class separation, the author should consider the alignment between these pretrained models.  \n\n7. Although Grad-CAM is used to visualize the attention of DNNs, the intra-class and inter-class relationship with the classification and semantic generation should be more fully exploited. Evaluating the inter-class and intra-class statistics directly could also substantiate the claims around controlled semantics, see questions."
                },
                "questions": {
                    "value": "On page 4, the paper mentions the previous work lacks semantic high-level features and redundancy. However, I don\u2019t know how redundancy is solved in this work.  \n\nThere are some ablation experiments that remove each major component would indeed provide better insights into their individual contributions: \n\n1. Using clean images from different classes as hidden semantic images, or using random natural images as hidden semantic images, rather than generated ones. As you noted, this removes the control over the consistency of semantics within a class. The drop in unlearnability can show the importance of controlled generation. \n\n2. Removing the Latent Feature Concentration (LFC) module. This would demonstrate the impact of the proposed module in regularizing intra-class perturbations. \n\n3. Removing the CLIP-based clustering of text prompts. Using random prompts for generation removes controlled inter-class differences. \n\n4. Evaluating inter-class and intra-class separation quantitatively using metrics like mean intra-class distance and mean inter-class distance. This can formally validate the claims."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7150/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698598890126,
            "cdate": 1698598890126,
            "tmdate": 1699636846549,
            "mdate": 1699636846549,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "r0RJLFXsUO",
                "forum": "JKpk2p4O99",
                "replyto": "Nj8e0PMerz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** Additional Requirements of generating a large dataset of semantic images using paired text prompts and canny edge maps.\n\n\n**Ans:** Thank you for your invaluable comments on the \u2018semantic image generation\u2019 module. As we mention in Section 3.2.3, we use the paired text prompt and canny edge maps to control the generated semantic content more precisely, which leads to better robustness of the UEs.\nWe conduct ablation studies using random natural images, and next-class images, without using paired text prompts and canny edge maps.\nTable D demonstrates that without the ControlNet based generation, the performance is still competitive in the class-wise setting while dropping dramatically in the sample-wise setting.\nThe competitive results in the class-wise setting prove the effectiveness of unlearnability brought from hiding semantic images, highlighting robust generalizability across various countermeasures.\nHowever, simply using next-class images or random natural images in the sample-wise setting fails to achieve unlearnability due to without controlling the similarity of hidden semantic images within intra-class data, which validates the effectiveness of generating a large dataset of semantic images using paired text prompts and canny edge maps.\n\n**Table D: Additional experimental results on CIFAR10 by using different hidden semantic images, including images from the next class, random natural images (CIFAR100), and our semantic image generation module.**\n\n| Setting         | Hidden Semantic Images       | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR   | Gray  | GaussN | GaussF | JPEG10 | JPEG50 | AT    | Mean  |\n|:---------------:|:---------------------:|:-------:|:------:|:------:|:-----:|:-----:|:-------:|:-----:|:-----:|:------:|:------:|:------:|:------:|:-----:|:-----:|\n| Sample-wise | Next Class            | 80.19   | 75.79  | 74.79  | 71.26 | 60.57 | 82.25   | 72.89 | 67.46 | 72.38  | 78.66  | 82.01  | 87.68  | 82.53 | 76.04 |\n|      Sample-wise           | Random Natural Images | 94.09   | 94.34  | 93.84  | 94.17 | 64.55 | 85.94   | 88.86 | 91.81 | 88.70  | 94.20  | 82.84  | 90.31  | 85.31 | 88.38 |\n|      Sample-wise           | Ours                  | 15.36   | 10.79  | 10.00  | 14.72 | 17.68 | 17.00   | 21.12 | 17.61 | 22.78  | 11.16  | 80.41  | 81.03  | 38.31 | **27.54** |\n|                 |                       |         |        |        |       |       |         |       |       |        |        |        |        |       |       |\n| Class-wise  | Next Class            | 10.00   | 10.00  | 9.96   | 10.18 | 10.47 | 10.18   | 10.00 | 10.00 | 10.00  | 10.00  | 62.91  | 17.26  | 10.01 | 14.69 |\n|         Class-wise        | Random Natural Images | 10.00   | 10.00  | 11.41  | 10.00 | 10.01 | 11.71   | 10.00 | 10.01 | 10.00  | 10.00  | 58.38  | 10.05  | 10.00 | **13.97** |\n|         Class-wise        | Ours                  | 10.00   | 10.00  | 11.25  | 10.02 | 10.59 | 10.04   | 13.53 | 10.00 | 10.00  | 10.00  | 72.97  | 23.62  | 10.00 | 16.31 |\n\n**Q2:** The sample-wise setting may leak information about hidden images. If some hackers know an image is protected in this way, they may find a countermeasure for the unlearnable examples based on the proposed hidden semantic generations.\n\n**Ans:** Thank you for your insights. We would like to clarify that we reduce the exposure risk of the sample-wise setting from 2 aspects:\n\n1. We hide different semantic images into the images in each class. Though the semantic images share similar semantics, they are totally different in textures and colors.\n2. Our deep hiding model will generate content-dependent perturbations. When we hide the semantic image into the original image, the perturbation will embed into the original content adaptively, leading to more pixel-wise changes.\n\nIn data protection and adversarial learning research, we will always face challenges from hackers who wish to mitigate the effects of the perturbations. We are consistently improving the robustness of the defensive perturbations, so the hackers will need more effort to remove them. It is the initiative of our work as well, and we believe the research community is working towards more generally robust unlearnable examples endlessly."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700472680917,
                "cdate": 1700472680917,
                "tmdate": 1700480294398,
                "mdate": 1700480294398,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lqx6w47528",
                "forum": "JKpk2p4O99",
                "replyto": "Nj8e0PMerz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q3:** A pre-trained ResNet-18 is used as the feature extractor, all text prompts are clustered using K-means with the semantic features from the CLIP model, and Stable Diffusion model and ControlNet to generate semantic images. It's hard to analyze the effectiveness of each component.\n\n**Ans:** Thank you for the comments. We conduct a comprehensive ablation study on the effectiveness of each component. We show the results in Table 4, and we have added it into the paper. In the class-wise setting, we find that the improvement of the generation module is marginal; however, in the sample-wise setting, the semantic generation module (SIG) can degrade the mean accuracy from 88% to 38%. It is further reduced to 27.5% with latent feature concentration (LFC). When we disentangle the text prompt clustering (TPC) and Stable Diffusion+ControlNet generation (SD+C), we find that SD+C contributes the most and TPC causes around a 2% reduction. The ablation study shows that each component in our proposed method plays an important role in the generally robust unlearnable examples.\n\n**Table 4: Ablation studies on CIFAR10 for designed Latent Feature Concentration module (LFC), and Semantic Images Generation module (SIG), including Text Prompts Clustering (TPC) and Stable Diffusion model and ControlNet (SD+C).**\n\n| Setting | LFC | SIG: TPC | SIG: SD+C | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR   | Gray  | GaussN | GaussF | JPEG10 | JPEG50 | AT    | Mean  |\n|:-------:|:---:|:--------:|:---------:|:-------:|:------:|:------:|:-----:|:-----:|:-------:|:-----:|:-----:|:------:|:------:|:------:|:------:|:-----:|:-----:|\n| Sample-wise|   \u00d7  |       \u00d7   |        \u00d7   | 94.08   | 94.52  | 94.07  | 88.23 | 65.42 | 87.04   | 89.46 | 91.45 | 88.36  | 94.07  | 83.29  | 89.97  | 86.26 | 88.17 |\n|    Sample-wise     | \u00d7    | \u2713        | \u2713         | 14.77   | 22.20  | 13.06  | 23.44 | 30.18 | 51.43   | 35.66 | 17.31 | 37.50  | 15.80  | 81.97  | 81.48  | 81.24 | 38.93 |\n|  Sample-wise       | \u2713   |    \u00d7       | \u2713         | 10.00   | 16.53  | 20.81  | 17.14 | 18.51 | 21.73   | 24.98 | 13.85 | 22.07  | 10.59  | 80.09  | 82.90  | 46.54 | 29.67 |\n|    Sample-wise     | \u2713   |    \u00d7       |    \u00d7        | 94.09   | 94.34  | 93.84  | 94.00 | 64.55 | 85.94   | 88.86 | 91.00 | 88.70  | 94.20  | 82.84  | 90.31  | 85.31 | 88.38 |\n|     Sample-wise    | \u2713   | \u2713        | \u2713         | 15.36   | 10.79  | 10.00  | 14.72 | 17.68 | 17.00   | 21.12 | 17.61 | 22.78  | 11.16  | 80.41  | 81.03  | 38.31 | **27.54** |\n| Class-wise |  \u00d7    |     \u00d7      |    \u00d7        | 12.16   | 11.02  | 11.43  | 10.81 | 10.14 | 13.28   | 10.10 | 12.12 | 10.00  | 10.00  | 78.21  | 15.32  | 12.87 | 16.73 |\n|    Class-wise     |  \u00d7    | \u2713        | \u2713         | 10.00   | 10.00  | 10.06  | 10.82 | 13.26 | 25.76   | 15.83 | 14.20 | 10.03  | 10.00  | 76.26  | 20.28  | 14.78 | 18.56 |\n|    Class-wise     | \u2713   |      \u00d7     | \u2713         | 10.00   | 10.00  | 10.00  | 12.32 | 9.72  | 10.00   | 10.00 | 10.59 | 10.00  | 10.00  | 71.44  | 30.27  | 10.00 | 16.49 |\n|    Class-wise     | \u2713   |     \u00d7      |    \u00d7        | 10.00   | 10.00  | 11.41  | 10.00 | 10.01 | 11.71   | 10.00 | 10.01 | 10.00  | 10.00  | 58.38  | 10.05  | 10.00 | **13.97** |\n|    Class-wise     | \u2713   | \u2713        | \u2713         | 10.00   | 10.00  | 11.25  | 10.02 | 10.59 | 10.04   | 13.53 | 10.00 | 10.00  | 10.00  | 72.97  | 23.62  | 10.00 | 16.31 |\n\n**Q4:** From the above, the connection between the hidden image and the unlearnable example is unclear. The hidden semantic image may not directly contribute to unlearnability.\n\n**Ans:** We agree that it is difficult to give a certain answer about the source of unlearnability, since the image generation and hiding network are still black boxes. We want to reclaim our hypothesis in Section 3.3 that deep hiding semantic images can create shortcuts, leading to unlearnability. Furthermore, based on the ablation results in Table D(**Q1**) and Table 4(**Q3**), we show the hidden semantic image contributes to the unlearnability in the class-wise setting; In the sample-wise setting, the unlearnability mainly comes from the controlled semantic image generation. These results highlight the effectiveness of the hidden semantic image.\n\n**Q5:** The robustness and effectiveness may come from the pre-trained ResNet-18, CLIP, Stable Diffusion, or ControlNet. Therefore, the effectiveness and robustness may not come from the architecture and the idea; instead, these may only come from the extra information from the four pre-trained models.\n\n**Ans:** Similar to the previous responses, we would like to clarify that the effectiveness of the unlearnable examples comes from the semantic hiding images instead of the pre-trained models, based on the analysis and experimental results."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700472750768,
                "cdate": 1700472750768,
                "tmdate": 1700477310464,
                "mdate": 1700477310464,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "U7k3VyZ5Ar",
                "forum": "JKpk2p4O99",
                "replyto": "Nj8e0PMerz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q6:** Although an LFC (a pretrained ResNet18) is used to regularize intra-class variance, and the CLIP, Stable Diffusion, and ControlNet are used to maximize inter-class separation, the author should consider the alignment between these pretrained models.\n\n**Ans:** We've conducted an ablation study by removing the LFC (Table 4(Q3)) and found that there is a slight decrease on the experimental results.\nThe reason is that these components serve as auxiliary elements to control the semantic image. Therefore, alignment is not an urgent requirement and does not significantly affect the results.\n\n**Q7:** Although Grad-CAM is used to visualize the attention of DNNs, the intra-class and inter-class relationship with the classification and semantic generation should be more fully exploited. Evaluating the inter-class and intra-class statistics directly could also substantiate the claims around controlled semantics, see questions.\n\n**Ans:** We investigate the intra-/inter-class distance in latent features using a trained (for unlearnable examples) or pre-trained (for clean images) ResNet18, shown in Table J. We observe that our unlearnable examples, in both class-wise and sample-wise settings, exhibit significantly reduced intra-class distances, as evidenced by a higher cosine similarity approaching 1.0000. Furthermore, by compacting the semantics within each class, we also achieve an increased inter-class distance. These outcomes suggest that our method successfully generates unlearnable examples characterized by minimal intra-class distances and maximized inter-class distances, thereby enhancing unlearnability.\n\nThe calculation detail of intra-/inter-class distance is shown below.\nWe consider the output of the last CNN layer as the latent feature for each sample and average these to determine the mean latent feature per class. For intra-class distance, we compute and report the mean cosine similarity between each sample's latent feature and its class mean. For inter-class distance, we calculate the mean cosine similarity between each class's mean latent feature and the overall dataset mean.\n\n**Table J: Evaluation of Inter-Class and Intra-Class Distances.**\n\n| Data         | Intra-class | Inter-class |\n|:------------:|:-----------:|:-----------:|\n| Clean images | 0.8457      | 0.8742      |\n| Ours(S)      | 0.9702      | 0.9030      |\n| Ours(C)      | 0.9882      | 0.8815      |\n\n**Q8:** On page 4, the paper mentions the previous work lacks semantic high-level features and redundancy. However, I don\u2019t know how redundancy is solved in this work.\n\n**Ans:** In our paper, we solve the redundancy issue by using the image-hiding framework, which can inherently and adaptively hide different amounts of information in each pixel.\nIn this way, we can hide semantic images instead of noise-based perturbations in clean images. The redundancy found in semantic images \u2013 such as the repeated shapes and colors in a forest scene \u2013 allows for a certain degree of data loss or alteration without significantly impacting the image's overall structure or meaning. As a result, the high redundancy of the hidden semantic information contributes to the high tolerance of unlearnability when under image processing.\n\n\n**Q9:** Ablation studies:\nThere are some ablation experiments that remove each major component would indeed provide better insights into their individual contributions:\n1. Using clean images from different classes as hidden semantic images, or using random natural images as hidden semantic images, rather than generated ones. As you noted, this removes the control over the consistency of semantics within a class. The drop in unlearnability can show the importance of controlled generation.\n2. Removing the Latent Feature Concentration (LFC) module. This would demonstrate the impact of the proposed module in regularizing intra-class perturbations.\n3. Removing the CLIP-based clustering of text prompts. Using random prompts for generation removes controlled inter-class differences.\n4. Evaluating inter-class and intra-class separation quantitatively using metrics like mean intra-class distance and mean inter-class distance. This can formally validate the claims.\n\n**Ans:** Thank you so much for the detailed suggestions on ablation studies. The ablations significantly improve our papers. We have conducted the following ablations and show the results in the respective tables:\n- Ablation on each component in Semantic Generation Module. The results are shown in Table D and Table 4.\n- Ablation on LFC. The results are shown in the modified Table 4.\n\nWe hope ablation studies can address your concerns and provide better insights into the components."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700472920072,
                "cdate": 1700472920072,
                "tmdate": 1700477463866,
                "mdate": 1700477463866,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "i3mgZOMyik",
            "forum": "JKpk2p4O99",
            "replyto": "JKpk2p4O99",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7150/Reviewer_p8VW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7150/Reviewer_p8VW"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an approach to generate unlearnable examples by hiding the semantic images in the natural images. To hide the semantic images, DWT along with INN has been used. The loss functions are combined to ensure a frequency image is close to the natural image and only high-frequency features are disturbed. The experiments are performed on multiple datasets and the resiliency of the proposed approach is also demonstrated."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper presents straightforward unlearnable examples generation algorithms.\nThe generated examples are robust to several defense strategies."
                },
                "weaknesses": {
                    "value": "* The paper can bring the hiding process into the main text in comparison to adding it to the supplementary file.\n* The experimental section of the paper is weak. The ablation studies with several parameters used in the proposed algorithm are missing. For example: ablation concerning the role of individual loss items, concerning values of $w_i$.\n* The authors have mentioned that $100$ semantic images are generated for image hiding. Are these all $100$ images used and how?\n* Why the existing algorithms are re-implemented? Are they implemented and fine-tuned using the parameters provided in the papers? can't we use the protocols of existing work for direct comparisons?\n* Any reason why *JPEG10* is yielding significantly higher robustness across each unlearnable example? Any explainable reason for this and have the authors tried with a lower **JEPG** value?\n* have the authors studied the transferability of the proposed examples in the presence of defenses?\n* It is surprising to see that even at 80\\%, the test accuracy is significantly high (84.40\\%), which suddenly drops to 10.00\\% in presence of 100\\% examples. Am I correct? If yes, what is the reason?\n* What about transferability in terms of limited samples used to learn unlearnable examples?\n* The paper also needs to discuss existing contemporary image-hiding works effective in generating adversarial examples and how they are different from this work. Why they can not be used as compared to the proposed DH?\n\n[1] Din SU, Akhtar N, Younis S, Shafait F, Mansoor A, Shafique M. Steganographic universal adversarial perturbations. Pattern Recognition Letters. 2020 Jul 1;135:146-52.\n\n[2] A. Agarwal, N. Ratha, M. Vatsa and R. Singh, \"Crafting Adversarial Perturbations via Transformed Image Component Swapping,\" in IEEE Transactions on Image Processing, vol. 31, pp. 7338-7349, 2022, doi: 10.1109/TIP.2022.3204206."
                },
                "questions": {
                    "value": "Please check the weakness section.\n\n---------------------------------- Post Rebuttal ----------------\n\nThe responses posted addressed my concerns."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7150/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7150/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7150/Reviewer_p8VW"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7150/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698650244102,
            "cdate": 1698650244102,
            "tmdate": 1700644874594,
            "mdate": 1700644874594,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SrzH9y4CsQ",
                "forum": "JKpk2p4O99",
                "replyto": "i3mgZOMyik",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** The paper can bring the hiding process into the main text in comparison to adding it to the supplementary file.\n\n\n**Ans:**  Thank you for your suggestion. We've added the specific hiding process to the main text, making it easier for readers to understand our method.\n\n\n**Q2:** The experimental section of the paper is weak. The ablation studies with several parameters used in the proposed algorithm are missing. For example: ablation concerning the role of individual loss items, concerning values of wi.\n\n\n**Ans:** Thank you for your comments on the experimental sections. We have added several ablation results based on your suggestions:\n- Ablation on weights of individual loss wi: we conduct a grid search on the 3 loss weights separately. We search from 0.01 to 10 for w1 and w2, and search from 1e-5 to 1e-2 for w3, since loss associated with w3 is generally 1000 times larger. The results in Table A&B&C show that when we set weights to 1, 1, 0.0001, the mean accuracy against countermeasures archives the best performance. Hence, we adopt these hyperparameters in all our experiments.\n- Ablation on generation module: we further conduct ablation study on the impact of the semantic image generation module (Table 4 and Table D). We show that each module plays significant role to further improve the robustness of the deep hiding unlearnable examples.\n\n\nWe hope these amendments address your concerns and further strengthen our paper.\n\n\n**Table A: The experimental results of different settings on parameters of $\\omega_1$.**\n| Setting     | $\\omega_1$ | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR   | Gray  | GaussN | GaussF | JPEG10 | JPEG50 | AT    | Mean      |\n|:-----------:|:----------:|:-------:|:------:|:------:|:-----:|:-----:|:-------:|:-----:|:-----:|:------:|:------:|:------:|:------:|:-----:|:---------:|\n| Sample-wise | 10         | 16.00   | 16.35  | 13.69  | 17.28 | 30.86 | 64.48   | 23.40 | 18.34 | 24.11  | 13.70  | 82.03  | 70.60  | 48.92 | 33.83     |\n|  Sample-wise  (Ours)         | 1    | 15.36   | 10.79  | 10.00  | 14.72 | 17.68 | 17.00   | 21.12 | 17.61 | 22.78  | 11.16  | 80.41  | 81.03  | 38.31 | **27.54** |\n|      Sample-wise       | $10^{-1}$  | 13.54   | 17.32  | 14.11  | 17.24 | 29.90 | 37.61   | 28.54 | 19.15 | 25.25  | 16.23  | 81.48  | 63.96  | 58.30 | 32.51     |\n|    Sample-wise         | $10^{-2}$  | 11.31   | 12.48  | 10.01  | 11.12 | 17.11 | 23.48   | 17.46 | 13.89 | 22.41  | 10.05  | 80.04  | 84.38  | 45.20 | 27.61     |\n| Class-wise  | 10         | 11.60   | 10.10  | 12.52  | 10.83 | 11.92 | 21.24   | 17.48 | 11.45 | 12.42  | 10.00  | 76.42  | 20.26  | 17.56 | 18.75     |\n|    Class-wise  (Ours)     | 1    | 10.00   | 10.00  | 11.25  | 10.02 | 10.59 | 10.04   | 13.53 | 10.00 | 10.00  | 10.00  | 72.97  | 23.62  | 10.00 | **16.31** |\n|      Class-wise     | $10^{-1}$  | 10.00   | 10.00  | 9.99   | 10.00 | 10.11 | 10.09   | 12.44 | 10.00 | 10.00  | 10.00  | 72.36  | 28.89  | 10.05 | 16.46     |\n|      Class-wise      | $10^{-2}$  | 10.00   | 10.00  | 10.02  | 10.00 | 10.09 | 10.00   | 16.34 | 10.00 | 10.00  | 10.00  | 72.45  | 58.50  | 10.00 | 19.03     |\n\n**Table B: The experimental results of different settings on parameters of $\\omega_2$.**\n| Setting | $\\omega_2$ | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR   | Gray  | GaussN | GaussF | JPEG10 | JPEG50 | AT    | Mean      |\n|:-------:|:----------:|:-------:|:------:|:------:|:-----:|:-----:|:-------:|:-----:|:-----:|:------:|:------:|:------:|:------:|:-----:|:---------:|\n| Sample-wise  | 10         | 15.12   | 10.35  | 10.34  | 13.58 | 17.94 | 23.41   | 20.41 | 16.00 | 24.53  | 10.01  | 81.89  | 80.81  | 39.88 | 28.02     |\n|    Sample-wise (Ours)     | 1    | 15.36   | 10.79  | 10.00  | 14.72 | 17.68 | 17.00   | 21.12 | 17.61 | 22.78  | 11.16  | 80.41  | 81.03  | 38.31 | **27.54** |\n|    Sample-wise      | $10^{-1}$  | 16.99   | 16.81  | 11.01  | 12.22 | 25.72 | 35.44   | 26.33 | 20.33 | 27.34  | 16.66  | 82.40  | 81.74  | 69.43 | 34.03     |\n|     Sample-wise     | $10^{-2}$  | 10.57   | 15.16  | 21.60  | 14.12 | 19.67 | 35.44   | 22.87 | 18.17 | 29.63  | 10.82  | 82.99  | 87.50  | 76.03 | 34.20     |\n| Class-wise   | 10         | 10.00   | 10.00  | 11.22  | 11.94 | 10.09 | 10.10   | 13.27 | 10.00 | 10.00  | 10.08  | 77.23  | 22.81  | 10.12 | 16.68     |\n|  Class-wise  (Ours) | 1    | 10.00   | 10.00  | 11.25  | 10.02 | 10.59 | 10.04   | 13.53 | 10.00 | 10.00  | 10.00  | 72.97  | 23.62  | 10.00 | **16.31** |\n|   Class-wise      | $10^{-1}$  | 10.04   | 10.00  | 11.64  | 13.81 | 15.49 | 10.43   | 17.09 | 10.16 | 10.94  | 10.05  | 77.79  | 25.29  | 18.35 | 19.25     |\n|     Class-wise    | $10^{-2}$  | 10.00   | 10.00  | 10.03  | 10.28 | 10.41 | 10.36   | 15.29 | 10.87 | 10.00  | 10.00  | 79.46  | 29.51  | 10.00 | 17.40     |"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700473176799,
                "cdate": 1700473176799,
                "tmdate": 1700473176799,
                "mdate": 1700473176799,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VIvHeQFvN7",
                "forum": "JKpk2p4O99",
                "replyto": "i3mgZOMyik",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Table D: Additional experimental results on CIFAR10 by using different hidden semantic images, including images from the next class, random natural images (CIFAR100), and our semantic image generation module.**\n| Setting         | Hidden Semantic Images       | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR   | Gray  | GaussN | GaussF | JPEG10 | JPEG50 | AT    | Mean  |\n|:---------------:|:---------------------:|:-------:|:------:|:------:|:-----:|:-----:|:-------:|:-----:|:-----:|:------:|:------:|:------:|:------:|:-----:|:-----:|\n| Sample-wise | Next Class            | 80.19   | 75.79  | 74.79  | 71.26 | 60.57 | 82.25   | 72.89 | 67.46 | 72.38  | 78.66  | 82.01  | 87.68  | 82.53 | 76.04 |\n|      Sample-wise           | Random Natural Images | 94.09   | 94.34  | 93.84  | 94.17 | 64.55 | 85.94   | 88.86 | 91.81 | 88.70  | 94.20  | 82.84  | 90.31  | 85.31 | 88.38 |\n|      Sample-wise           | Ours                  | 15.36   | 10.79  | 10.00  | 14.72 | 17.68 | 17.00   | 21.12 | 17.61 | 22.78  | 11.16  | 80.41  | 81.03  | 38.31 | **27.54**|\n| Class-wise  | Next Class            | 10.00   | 10.00  | 9.96   | 10.18 | 10.47 | 10.18   | 10.00 | 10.00 | 10.00  | 10.00  | 62.91  | 17.26  | 10.01 | 14.69 |\n|         Class-wise        | Random Natural Images | 10.00   | 10.00  | 11.41  | 10.00 | 10.01 | 11.71   | 10.00 | 10.01 | 10.00  | 10.00  | 58.38  | 10.05  | 10.00 | **13.97** |\n|         Class-wise        | Ours                  | 10.00   | 10.00  | 11.25  | 10.02 | 10.59 | 10.04   | 13.53 | 10.00 | 10.00  | 10.00  | 72.97  | 23.62  | 10.00 | 16.31 |\n\n**Q3:** The authors have mentioned that 100 semantic images are generated for image hiding. Are these all 100 images used and how?\n\n**Ans:** We generate 100 images for each class, resulting in a total of 1k, 10k, and 10k semantic images for CIFAR10, CIFAR100, and ImageNet-100, respectively. Thus, these semantic images have the same class number as the target dataset.\n\nDuring the hiding process, we differ in the image selection for two types of hiding settings:\n\n- In the class-wise setting, we randomly select only one semantic image for all the clean images in the same class. In other words, each image in a class shares the same selected semantic images, while images in different classes are assigned with different semantic images.\n\n- In the sample-wise setting, for each class, we generate 100 semantic images with the same text prompt and canny edge map, to balance the diversity and generation efficiency of the semantic images. For each image in the same class, we randomly pick one semantic image from the 100-image pool and hide it into the clean image.\n\n**Q4:** Why the existing algorithms are re-implemented? Are they implemented and fine-tuned using the parameters provided in the papers? can't we use the protocols of existing work for direct comparisons?\n\n\n**Ans:** Thanks for your question regarding the re-implementation of existing algorithms.\nWe would like to clarify that we follow the same protocols of existing works based on their papers and the public code repositories. Besides, we implement and fine-tune the parameters provided in the papers. The \u2018re-implementation\u2019 indicates that we integrate all the existing methods into a unified code framework.\n\nThe primary reason for \u2018re-implementing\u2019 these algorithms was to ensure consistency and fairness in our comparisons. To evaluate the general robustness of the UEs, our study involved 13 different countermeasures. Since the existing papers did not provide all the necessary results for these specific conditions, we opted to implement the existing methods in a unified framework.\n\n**Q5:** Any reason why JPEG10 is yielding significantly higher robustness across each unlearnable example? Any explainable reason for this and have the authors tried with a lower JEPG value?\n\n**Ans:** We show examples of images compressed by JPEG(quality factor=10) in the supplementary. The examples show that the compression level of JPEG10 can result in significant distortion to the images, leading to a decrease in the performance of UE.\nIn response to your suggestion, we experimented with lower JPEG values (Table I). We found that lower JPEG values result in even lower test accuracy, which confirms that stronger compression not only damages the unlearnable example perturbations but also distorts the original image features significantly.\n\n**Table I: Test accuracy (\\%) of model train on unlearnable examples from CIFAR10 against JPEG compression.**\n| JPEG Quality Factor |2|     4     | 6     | 8     | 10    | 50    |\n|:-------------------:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n| Ours(S)         | 68.01 | 74.35 | 77.39 | 78.56 | 80.41 | 81.03 |\n| Ours(C)      | 64.53 | 70.18 | 72.56 | 72.72 | 72.97 | 23.62 |"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700473273432,
                "cdate": 1700473273432,
                "tmdate": 1700480321432,
                "mdate": 1700480321432,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lK5X9ivgpl",
                "forum": "JKpk2p4O99",
                "replyto": "i3mgZOMyik",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7150/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q8:** What about transferability in terms of limited samples used to learn unlearnable examples?\n\n**Ans:** We conducted the transferability study across architectures with limited unlearnable examples, and we show the results in Table F in the supplementary. The test accuracy decreases in a similar trend when we increase the percentage of the unlearnable examples.\n\n**Table F: Test accuracy (\\%) of CIFAR-10 on the different models trained by\nthe clean data mixed with different percentages of unlearnable examples.**\n\n| Setting                      | Model | 20\\%  | 40\\%  | 60\\%  | 80\\%  |\n|:----------------------------:|:-----:|:-----:|:-----:|:-----:|:-----:|\n| Ours(S) | R18   | 93.73 | 92.41 | 90.08 | 84.40 |\n|            Ours(S)                   | R50   | 94.16 | 92.82 | 90.51 | 85.66 |\n|          Ours(S)                     | V19   | 92.11 | 91.14 | 88.77 | 83.48 |\n|           Ours(S)                    | D121  | 89.02 | 87.77 | 84.94 | 81.39 |\n|            Ours(S)                   | ViT   | 75.95 | 74.77 | 74.09 | 70.50 |\n| Ours(C)  | R18   | 93.53 | 92.67 | 89.99 | 84.47 |\n|             Ours(C)                  | R50   | 94.04 | 92.31 | 90.58 | 85.15 |\n|              Ours(C)                 | V19   | 92.13 | 90.23 | 87.99 | 80.60 |\n|               Ours(C)                | D121  | 88.28 | 86.56 | 83.57 | 77.79 |\n|                Ours(C)               | ViT   | 75.44 | 74.58 | 69.34 | 64.80 |\n\n**Q9:** The paper also needs to discuss existing contemporary image-hiding works effective in generating adversarial examples and how they are different from this work. Why they can not be used as compared to the proposed DH?\n```\n1. Din SU, Akhtar N, Younis S, Shafait F, Mansoor A, Shafique M. Steganographic universal adversarial perturbations. Pattern Recognition Letters. 2020 Jul 1;135:146-52.\n2. A. Agarwal, N. Ratha, M. Vatsa and R. Singh, \"Crafting Adversarial Perturbations via Transformed Image Component Swapping,\" in IEEE Transactions on Image Processing, vol. 31, pp. 7338-7349, 2022, doi: 10.1109/TIP.2022.3204206.\n```\n**Ans:** Thank you for suggesting a comparison with contemporary image-hiding techniques in the context of adversarial examples. Our work indeed shares the image-hiding framework with the studies you mentioned, but our goals and methodologies differ substantially.\n\nThe specific aim of our work is to disrupt the learning process of a model. We seek to ensure high training accuracy on the unlearnable examples we generate, while deliberately reducing accuracy on a clean testing set. The adversarial examples crafted in the studies you listed are intended to lead a fully trained model to make incorrect predictions, a different goal than ours.\n\nAdditionally, we have expanded our research to different image-hiding networks, notably the ISGAN [D]. Our experiments assess the effectiveness of ISGAN-hidden unlearnable examples. The findings reveal that while unlearnability can be achieved with other deep hiding models like ISGAN, the performance is not as optimal as with our applied Invertible Neural Network (INN). INN demonstrates superior performance in deep hiding [E][F], which is why we chose it as our baseline model to validate our concepts.\n\nWe believe these distinctions, along with our comprehensive evaluations, underscore the unique contribution of our work in the field of image hiding and data privacy.\n\n```\n[D] Zhang, R., Dong, S., & Liu, J. (2019). Invisible steganography via generative adversarial networks. Multimedia tools and applications, 78, 8559-8575.\n[E] Xu Y, Mou C, Hu Y, et al. Robust invertible image steganography. CVPR, 2022: 7875-7884.\n[F] Mou C, Xu Y, Song J, et al. Large-capacity and flexible video steganography via invertible neural network. CVPR, 2023: 22606-22615.\n```\n\n**Table H: Test accuracy (\\%) of model train on unlearnable examples generated by using another deep hiding model (ISGAN).**\n| ISGAN      | Vanilla | Cutout | Cutmix | Mixup | MeanF | MedianF | BDR   | Gray  | GaussN | GaussF | JPEG10 | JPEG50 | AT    | Mean  |\n|------------|---------|--------|--------|-------|-------|---------|-------|-------|--------|--------|--------|--------|-------|-------|\n| Sample-wise| 54.05   | 53.74  | 55.97  | 72.61 | 48.83 | 85.11   | 86.77 | 53.04 | 88.45  | 54.25  | 84.35  | 90.55  | 87.22 | 70.38 |\n| Class-wise| 23.99   | 24.07  | 28.42  | 42.69 | 37.56 | 79.3    | 83.64 | 30.06 | 87.92  | 25.24  | 84.46  | 90.28  | 87.46 | 55.78 |"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7150/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700473377893,
                "cdate": 1700473377893,
                "tmdate": 1700540531176,
                "mdate": 1700540531176,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]