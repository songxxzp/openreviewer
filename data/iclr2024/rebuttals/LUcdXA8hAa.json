[
    {
        "title": "Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank"
    },
    {
        "review": {
            "id": "Yse4eSp0VV",
            "forum": "LUcdXA8hAa",
            "replyto": "LUcdXA8hAa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5474/Reviewer_CYAM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5474/Reviewer_CYAM"
            ],
            "content": {
                "summary": {
                    "value": "The submission studies the identifiability problem of unbiased learning to rank (ULTR) - given a dataset of implicit feedback, whether the true relevance can be identified or not. By treating each bias configuration as a node, and the shared input feature vector for the edges, the relevance model is identifiable if and only if the graph is connected. Then two methods are proposed to try to address the issues (making the graph connected). Experiments are conducted on two synthetic datasets and an offline dataset, where it shows that using the two methods to change data can improve the performance of a naive baseline."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "It is interesting to study the identifiability problem of unbiased learning to rank from the graph connectivity perspective, though the reviewer is not convinced that this is \"the first work\" to study the identifiability issue given existing work on coupling / confounding, etc. The major novelty seems to be the graph view.\n\nThe proposed two methods are easy to understand. The authors do acknowledge the caveats of the proposed methods (one being not very practical and one may propagate errors).\n\nThe paper is overall clearly written."
                },
                "weaknesses": {
                    "value": "Overall the paper is not satisfactory in term of theories or experiments.\n\nThough the theorems look interesting at first glance, the reviewer feels they are generally not very solid or practical after a closer look at them. A major issue is the reviewer feels the submission has self-contradictions in several places. \n\nSo there are two scenarios in practice: 1) there are a lot of data, and the bias factor space is small. This is the a common case in practice and people are just fine without worrying about identifiability. The analysis and methods in this paper mostly do not apply since the graph is small and likely connected. 2) There are a lot of bias factors and the graph is more likely to be not connected. The paper mainly argues about this scenario. So far so good and it is ok to focus on 2).\n\nHowever, by closing look at each theorem, all of them are questionable and some look contradictory to the focus/motivation:\n\nTheorem1: while the trend of using more bias factors is the trend is debatable (especially given existing work showing the coupling / confounding effect), the trend to enrich x is clear. Many real-world applications have personalized feature vectors - then the graph is not likely to be connected even with a small number of bias factors. The paper does not concern this perspective, also, people are fine working with ULTR with such datasets. This questions the value of the proposed framework - one should also note that the condition is only a sufficient condition. \n\nTheorem 2: The assumptions are too strong to make meaningful value from this theorem. The reviewer understands this is to show a simplified \u201cestimate\u201d, but still the value is quite limited for this highly practical field.\n\nTheorem 3: There\u2019s self-contradiction with the motivation of the paper. As discussed, the paper mainly concerns large bias factor space. However, this theorem assumes that each (input feature , bias factor) pair need to sample N observations from a Bernoulli distribution, and the theorem is based on \u201cN is sufficiently large\u201d. How can this be meaningful under the scenario the paper is concerned with?\n\nTheorem 4: The error bound is only shown to merge two subgraphs. Again, the paper is concerned with large bias factor space and the number of subgraphs could be be high - what is the error bound for the entire merge process? Will the errors propagate to meaningless values? Showing error bound only for merging two subgraphs looks quite limited.\n\nThere are also several places in the paper that also look contradictory, e.g. when it argues about the benefit of node intervention, \u201cIt should be noted that K is typically smaller the the number of positions (assuming that positions are the sole bias factor)\u201d - the reviewer is confused about such claims. If the paper is concerned with such scenario, then there\u2019s probably no need to worry about the identifiability issue.\n\nOn the experiments part, the evaluation is weak. The major issue is, the proposed methods are only shown to improve the very basic baseline. The authors argue that the methods are agnostic to the actual algorithm and \u201captly represents the current research\u201d - the reviewer strongly disagrees - to show the proposed method is really meaningful,  it needs to show that they can help more sensible baselines. For example, will they help state-of-the-art ULTR methods? If not, why would people care? This is important since the proposed two methods have clear caveats (the node intervention method is not very practical, the node merging method is likely to introduce errors)."
                },
                "questions": {
                    "value": "See questions above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5474/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698674778905,
            "cdate": 1698674778905,
            "tmdate": 1699636558514,
            "mdate": 1699636558514,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PGB904uqLR",
                "forum": "LUcdXA8hAa",
                "replyto": "Yse4eSp0VV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors (1/2)"
                    },
                    "comment": {
                        "value": "Thank your for your detailed and valuable feedback. Below are our responses to the weaknesses.\n\n> Theorem 1: Many real-world applications have personalized feature vectors - then the graph is not likely to be connected even with a small number of bias factors ... people are fine working with ULTR with such datasets ... one should also note that the condition is only a sufficient condition.\n\n- We appreciate your insightful suggestion about the feature count. We completely agree that the graph is not likely to be connected when enriching $X$. To demonstrate it, we conducted a thorough experiment for tuning the feature numbers, confirming that increasing X can indeed lead to potential unidentifiability issues. The results are in Appendix E.6 in the revised version. **The current work is okay in public ULTR datasets because the number of features hasn't reached the unidentifiability threshold, as we showed in Section 5.2.**\n\n- We would like to kindly highlight that Theorem 1 is not just a sufficient condition. It's a **necessary and sufficient** condition for identifiability and relevance recovery.\n\n> Theorem 2: The assumptions are too strong to make meaningful value from this theorem. The reviewer understands this is to show a simplified \u201cestimate\u201d, but still the value is quite limited for this highly practical field.\n\nThanks for pointing it out. Note that this theorem is not critical for our proposed method and the experiments we conducted. Its purpose is to provide an intuition of how \"increasing bias factors or decreasing data can potentially lead to unidentifiability\" in a simple scenario. We've verified this in a more complex and practical setting in Section 5.2. **To reduce its significance, we've renamed Theorem 2 to Corollary 1.**\n\n> Theorem 3: There\u2019s self-contradiction with the motivation of the paper ... the theorem is based on \u201cN is sufficiently large\u201d.\n\nThanks for pointing it out. After careful inspection, we've discovered that the assumption \"N is sufficiently large\" is not necessary for our proposed method, as it's only used for applying the central limit theorem. **We have removed this unnecessary assumption and restructured the theorem to present only the variance term, which is all our method requires.**\n\n> Theorem 4: The error bound is only shown to merge two subgraphs.\n\nApologies for the confusion about the theorem name \"error bound of merging\". Its purpose is not to establish the error bound for node merging but to illustrate the error when combining two components, which forms the foundation for the below merging cost (Eq.7). **To address the error bound for node merging, we have created another corollary in Appendix B.5.**\n\n> \u201cIt should be noted that K is typically smaller the the number of positions (assuming that positions are the sole bias factor)\u201d ... there\u2019s probably no need to worry about the identifiability issue.\n\nThis is because most of current existing ULTR intervention research (Joachims et al., 2017; Radlinski & Joachims, 2006; Carterette & Chandar, 2018; Yue et al., 2010) swap documents between positions. To make fair comparisons, we use positions as an example and show that our method involves far fewer swaps compared to these intervention methods. As you mentioned earlier, increasing X might lead to an unidentifiability issue even if the number of bias factors isn't large. Therefore studying identifiability in such case is still valuable.\n\n> Experiment: will they help state-of-the-art ULTR methods? \n\nWe appreciate your feedback about the evaluation. **We've made changes to the paper, and now it includes results for DLA, Regression-EM, and Two-Tower**. Please check our general response for more details.\n\n---\n\n*To be continued*"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699876468877,
                "cdate": 1699876468877,
                "tmdate": 1699876468877,
                "mdate": 1699876468877,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "S4WZqMYBbz",
                "forum": "LUcdXA8hAa",
                "replyto": "Yse4eSp0VV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors and Awaiting for Further Response (2/2)"
                    },
                    "comment": {
                        "value": "(*Continuing from the previous comment*)\n\n---\n\nBelow are the responses for your other reviews:\n\n> The reviewer is not convinced that this is \"the first work\" to study the identifiability issue given existing work on coupling / confounding, etc\n\nTo the best of our knowledge, **traditional approaches doesn't give a necessary and sufficient condition for relevance recovery without specific model constraint**. Previous work on coupling [1] and confounding [2] demands significant changes to the observation model structure, which limits their application in all cases. Our approach from a graph connectivity standpoint offers a principled solution: when the graph is connected, recovery is possible, but when it's not, there's a risk of unrecoverable cases. If you know about any other related work, feel free to share with us.\n\n[1] LBD: Decouple relevance and observation for individual-level unbiased learning to rank.\n\n[2] Towards disentangling relevance and bias in unbiased learning to rank.\n\n> So there are two scenarios in practice: 1) there are a lot of data, and the bias factor space is small. The analysis and methods in this paper mostly do not apply in such case ...\n\nWe acknowledge that node intervention/merging are indeed unnecessary in the identifiability issue. However, **we would like to kindly highlight that Theorem 1 (identifiability checking) is also our central contribution and important analysis**, which builds a theoretical base for current ULTR algorithms and is applicable to all cases. As R ggp4 said, this graph view is useful for nicer properties, more intuition-based understandings and more explainability in ULTR. This might provide a new perspective for future ULTR research.\n\n---\n\nWe hope the above responses and revisions could address your concerns. **We genuinely appreciate your insights and are open to hearing which specific parts you still find contradictory.** If you have further questions or any additional concerns, please don't hesitate to ask, and we'll do our best to address them. We eagerly await your further response."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699876551985,
                "cdate": 1699876551985,
                "tmdate": 1699950466627,
                "mdate": 1699950466627,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "u5D0KiCL9K",
                "forum": "LUcdXA8hAa",
                "replyto": "Yse4eSp0VV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Does our response address your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer CYAM,\n\nThank you for reviewing our work and helping us enhance it. In this revision, we've tried our best to **address any contradictory in the paper** and **compare the existing ULTR algorithms**. Please inform us if these improvements address your concerns. We're open for further discussion if necessary. Thank you for your time and consideration.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700207543598,
                "cdate": 1700207543598,
                "tmdate": 1700207543598,
                "mdate": 1700207543598,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qWh6rU969u",
                "forum": "LUcdXA8hAa",
                "replyto": "Yse4eSp0VV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion period will end soon and we're eagerly waiting for your feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer CYAM,\n\nHope you are well! ***The discussion is coming to an end***, and we're really excited to hear what you think about our response. We're just checking to see if our rebuttal improved the paper. It would be wonderful if you could tell us if we addressed your previous concerns. Thank you so much for your dedication to reviewing our paper.\n\nBest wishes,\n\nThe Authors"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382705528,
                "cdate": 1700382705528,
                "tmdate": 1700382705528,
                "mdate": 1700382705528,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oUsbhwPuHt",
            "forum": "LUcdXA8hAa",
            "replyto": "LUcdXA8hAa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5474/Reviewer_tHmn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5474/Reviewer_tHmn"
            ],
            "content": {
                "summary": {
                    "value": "This paper delves into the identifiability issue of the ranking model within the context of unbiased learning to rank (ULTR). Previous studies have established the model's unbiasedness, assuming perfect fits for both clicks and the observation model, inadvertently overlooking the identifiability challenge at its core. Motivated by this, the article investigates the conditions necessary to recover identifiability, primarily in the context of scale transformation. The authors formalize the identifiability challenge as a graph connectivity test problem. Based on it, they further propose two methods, namely node intervention and node merging, to tackle this problem for empirical applications."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The topic is interesting and important both theoretically and empirically;\n2. The methods of graph connectivity are novel to me;\n3. This paper is well-written."
                },
                "weaknesses": {
                    "value": "1. Experiments are weak and not very convincing, since it has very little baseline (see Q1 below for more details);\n\n2. Theorem 3 is straightforward and does not seem useful; the conditions required by Theorems 2 and 4 are stringent (see Q2 below for more details)."
                },
                "questions": {
                    "value": "I have two main concerns: \n\n**Q1.** In the experiment, there are only two weak baselines. In addition, there are lack of details about the two baselines. However, this article mentions a lot of related works but does not include them as part of the baselines for comparison empirically. This is inconsistent with the requirements in this area of ULTR. Could you add some cutting-edge ULTR methods as baselines? \n\n**Q2.** In terms of the theoretical results. \n\n>(1)\tTheorem 2 is a very simple case (\u2026 $x$ and $t$ are selected independently and uniformly \u2026). Thus, it is not sufficient to write it as a Theorem; it might be more appropriate to write it as a Proposition.\n\n> (2)\tTheorem 3 is simple and straightforward (just by the central limit theorem) and does not seem useful. Could you clarify the purpose and use of Theorem 3? Also, it is not sufficient to write it as a Theorem; it might be more appropriate to write it as a Lemma.\n\n> (3)\tThe condition required in Theorem 4, \"A disconnected IG consists of two connected components G1 and G2\" is strong and difficult to fulfill in practice. \n\n**In fact, the soundness of Theorems 3 and 4 is very critical to this paper.** Here are the two main reasons: (a) The graph is always disconnected in practice, and will suffer from identifiability problems; (b) To recover the identifiability, we always need node intervention and node merging to recover the connected graph for empirical applications. Thus, the rationality of these two proposed algorithms (node intervention and node merging) becomes critical. Regrettably, Theorems 3 and 4 are slightly weak, which seriously undermines the contribution of this paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5474/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5474/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5474/Reviewer_tHmn"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5474/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698734136106,
            "cdate": 1698734136106,
            "tmdate": 1699636558418,
            "mdate": 1699636558418,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "I2ZUzQ3GSv",
                "forum": "LUcdXA8hAa",
                "replyto": "oUsbhwPuHt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank your for your valuable feedback. Below are our responses to the weaknesses and questions:\n\n> Experiments are weak and not very convincing, since it has very little baseline.\n\nWe appreciate your feedback about the evaluation. **We've made changes to the paper, and now it includes results for DLA, Regression-EM, and Two-Tower**. Please check our general response for more details.\n\n> (1) Theorem 2 is a very simple case. Thus, it is not sufficient to write it as a Theorem; it might be more appropriate to write it as a Proposition.\n\nThanks for pointing out the problem. This theorem is not critical for our proposed method and the experiments we conducted. Its purpose is to provide an intuition of how \"increasing bias factors or decreasing data can potentially lead to unidentifiability\" in a simple scenario. We've verified this in a more complex and practical setting in Section 5.2. **We appreciate your suggestion of renaming and we've renamed Theorem 2 to Corollary 1.**\n\n> (2) Theorem 3 is simple and straightforward (just by the central limit theorem) and does not seem useful. Could you clarify the purpose and use of Theorem 3? Also, it is not sufficient to write it as a Theorem; it might be more appropriate to write it as a Lemma.\n\nThanks for pointing out this point. We kindly remind that this theorem is necessary in the proposed node intervention method: The purpose is to used to compute the specific form of variance, which serves as the cost function (Eq.3). The basic idea is that there are too many choices that the intervention targets can be selected, and in Theorem 3 we find that minimizing the variance helps facilitate the identifiability. This is why we've chosen variance as our cost function for choosing intervention target, and **we've highlighted this point in Theorem 3, which is now renamed Proposition 1.**\n\n> (3) The condition required in Theorem 4, \"A disconnected IG consists of two connected components G1 and G2\" is strong and difficult to fulfill in practice.\n\nApologies for the confusion about the theorem name \"error bound of merging\". Its purpose is not to establish the error bound for node merging but to illustrate the error when combining two components, which forms the foundation for the below merging cost (Eq.7). **To address the error bound for node merging, we have created another corollary in Appendix B.5.**\n\n---\n\nWe hope the above responses and revisions could strengthen Theorem 3 and 4. Please confirm whether our explanations address your concerns. If you have any more questions or additional concerns, please feel free to ask, and we will make every effort to address them."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699876203688,
                "cdate": 1699876203688,
                "tmdate": 1699876203688,
                "mdate": 1699876203688,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xrvTw5XIXU",
                "forum": "LUcdXA8hAa",
                "replyto": "oUsbhwPuHt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Does our response address your concerns?"
                    },
                    "comment": {
                        "value": "Dear Reviewer tHmn,\n\nThank you for reviewing our work and aiding in its improvement. In this revision, we've **compared the existing ULTR algorithms**, **clarified the motivation behind Theorem 3**, and **introduced an additional corollary to fortify Theorem 4 for increased reliability**. Please let us know if these efforts address your concerns. We remain open for further discussion if needed. Thank you for your time and consideration.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700206973830,
                "cdate": 1700206973830,
                "tmdate": 1700206973830,
                "mdate": 1700206973830,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BOdtwQOwUo",
                "forum": "LUcdXA8hAa",
                "replyto": "oUsbhwPuHt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion period will end soon and we're eagerly waiting for your feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer tHmn,\n\nI hope you're doing well! ***The discussion period is ending soon***, and we're excited to know your thoughts on our response. We're just checking in to see if our rebuttal improved the paper. It would mean a lot if you could kindly inform us if we addressed your previous concerns properly. Thank you for your dedication to reviewing our paper.\n\nBest regards,\n\nThe Authors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382568915,
                "cdate": 1700382568915,
                "tmdate": 1700382568915,
                "mdate": 1700382568915,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AL6AjuUYlX",
            "forum": "LUcdXA8hAa",
            "replyto": "LUcdXA8hAa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5474/Reviewer_ggp4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5474/Reviewer_ggp4"
            ],
            "content": {
                "summary": {
                    "value": "The paper investigates the problem of position bias in the task of Unbiased Learning to Rank. It first introduces the widespread concern of biased user logs and the consequent appriximation error in most of the commonly used ranking models. With a clear problem setup and definition of identifiability, the author states the conditions under which the true relevances can be extracted from click data. Particularly, the paper converts the identifiability problem into a graph connectivity problem. Based on the connectivity problem,  the authors further come up two new approaches to deal with \u201cunidentifiable\u201d datasets and optimize the ranking models using structures of the graph. Experiments are conducted to prove the validity of the graph conversion, the performance of new approaches, and the application to the real-world datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1: As one of its major contributions, this paper tansfers the identifiability of a ULTR task to the connectivity of a graph constructed based on the dataset. This equivalence is useful in that tasks related to a graph usually have more efficient computations, nicer properties, and more intuition-based understandings. The work also allows for more explainability in the field of ULTR and thus simplifies difficult questions.\n\nS2: This paper proposes two novel methods, node intervention and node merging, to bridge the \u201cunidentifiability gap\u201d by utilizing the graph properties. These two methods are theoretically supported and empirically verified."
                },
                "weaknesses": {
                    "value": "W1: Since the theory of this paper relies heavily on the examination hypothesis, the graph-equivalence idea is not generalizeable to other general hypotheses on the dataset.\n\nW2: Since the methods are still propensity-based, there are a plethora of such ranking models. It would be fair game if the paper uses such methods as baselines to strengthen the validity of the proposed methods.\n\nW3: When choosing the bias factors, we can choose either fewer factors, which makes the graph more likely to be connected, or more factors, which accounts for more bias but poses a more disconnected graph. It would be great if there is any discussion on the tradeoff and the corresponding performance of the two proposed methods. In addition, assume that each feature x and bias factor t are independently and uniformly chosen to construct the dataset D is nearly impossible in practice."
                },
                "questions": {
                    "value": "Q1: In the real world, the dataset is mostly sparse and thus there might be a large number of connected components in IG. How much does the performance of the two methods deteriote with the increasing sparsity? Is there a systematic way to deal with that issue?\n\nQ2: In the node merging method, the costs between nodes are computed based on the their deterministic features X_t. However, how is it guaranteed that the features reflect their true similarity? For example, we may use document rank as a bias factor when only considering the position bias. But it turns out that the user may notice the documents in the order of: the first several documents (since they\u2019re most noticeable), the last several documents on this page (since users may scroll down), and then documents in the middle. In the more complex settings of several factors, it\u2019s even less obvious which nodes are similar to each other. Is it possible to make the features not deterministic but rather learned throughout multi-task learning?\n\nQ3: In the application of the method, the dataset is mostly online and continuously taking in new data points. How does the proposed method handle the updates efficiently? For example, if two nodes (bias factors) with similar features are already merged but the new datapoints from the user creates an edge between them, is there a way to efficiently deal with this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5474/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5474/Reviewer_ggp4",
                        "ICLR.cc/2024/Conference/Submission5474/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5474/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698841999536,
            "cdate": 1698841999536,
            "tmdate": 1700631350316,
            "mdate": 1700631350316,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pzvNOMn7RH",
                "forum": "LUcdXA8hAa",
                "replyto": "AL6AjuUYlX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank your for your valuable feedback. Below are our responses to the weaknesses and questions:\n\n> W1: Since the theory of this paper relies heavily on the examination hypothesis, the graph-equivalence idea is not generalizeable to other general hypotheses on the dataset.\n\nWe agree that this paper is based on the examination hypothesis. We opted to focus on it because it's the most widely used generation process (see Appendix A). However, we kindly remind that it does not mean the graph idea is not applicable to other hypothesis. **Actually, to generalize this idea to other hypothesis, only small adjustments in Definition 1 and Theorem 1 are required while maintaining the core structure of IG**. We leave it as future work since it is more complicated and falls beyond the scope of this work.\n\n> W2: Since the methods are still propensity-based, there are a plethora of such ranking models. It would be fair game if the paper uses such methods as baselines to strengthen the validity of the proposed methods.\n\nWe appreciate your feedback about the evaluation. **We've made changes to the paper, and now it includes results for DLA, Regression-EM, and Two-Tower**. Please check our general response for more details. \n\n> W3 (1): It would be great if there is any discussion on the trade-off between bias vs connected and the corresponding performance of the two proposed methods. \n\nWe report the MCC performance of (1) only considering one bias factor; (2) considering all bias factors; and (3)(4) our proposed methods in the K=2 simulation dataset:\n\n|ULTR method|DLA|Regression-EM|Two-Tower|\n|-|-|-|-|\n|(1) one bias factor|0.641|0.641|0.641|\n|(2) all bias factors|0.738|0.634|0.892|\n|(3) node intervention|1.000|0.982|1.000|\n|(4) node merging|0.987|0.975|0.987|\n\nThe trade-off depends on the specific ULTR algorithms: Regression-EM faces more trouble with unidentifiability, whereas DLA and Two-Tower have more issues with bias. This happens because when there's no assurance of identifiability, different ULTR algorithms might end up with various poor model parameters. But when our methods ensure identifiability, they all converge to a shared set of good settings that recover the relevance accurately.\n\n> W3 (2): In addition, assume that each feature x and bias factor t are independently and uniformly chosen to construct the dataset D is nearly impossible in practice.\n\nThanks for pointing it out. Note that this theorem is not critical for our proposed method and the experiments we conducted. Its purpose is to provide an intuition of how \"increasing bias factors or decreasing data can potentially lead to unidentifiability\" in a simple scenario. We've verified this in a more complex and practical setting in Section 5.2. **To reduce its significance, we've renamed Theorem 2 to Corollary 1.**\n\n> Q1: How much does the performance of the two methods deteriote with the increasing sparsity of IG? \n\nWe presents the `nDCG@10 / MCC` results with the increasing numbers of connected components (K) in the fully-simulation datasets as follows:\n\n||K=1|K=2|K=3|K=4|\n|-|-|-|-|-|\n|No debias|0.863 / 0.657|0.858 / 0.641|0.859 / 0.638|0.870 / 0.655|\n|DLA|1.000 / 1.000|0.900 / 0.738|0.889 / 0.700|0.876 / 0.660|\n|+ Node intervention |-|1.000 / 1.000 |1.000 / 1.000|1.000 / 1.000|\n|+ Node merging |-|1.000 / 0.987|1.000 / 0.978|0.947 / 0.835|\n\nWe can observe that the performance of DLA and Node merging drops as the $K$ increases, while Node intervention always recovers the relevance accurately. Overall, our proposed methods significantly improve the initial results.\n\n> Is there a systematic way to deal with that issue?\n\nIf doing intervention experiments is allowed, node intervention is always perfered. Otherwise, node merging is also acceptable since it can siginificantly reduce the unidentifiability issue.\n\n> Q2: Is it possible to make the features not deterministic but rather learned throughout multi-task learning?\n\nThis is an interesting question. This depends on prior knowledge, often needing practitioners to manually define click models based on their experience to represent this bias similarity. While it's beyond this paper's scope, we speculate that automatically learning this similarity might not be viable. This is because unidentifiability arises from incomplete datasets and limited information, which challenges learning the actual similarity.\n\n> Q3: In the application of the method, the dataset is mostly online and continuously taking in new data points. How does the proposed method handle the updates efficiently? \n\nWe can maintain a set recording all the merging pairs. When new data arrives, we can check if it's already in the merging set. If it is, we can separate the two nodes and handle them individually in the upcoming training.\n\n---\n\nPlease confirm whether our explanations address your concerns. If you have any more questions or additional concerns, please feel free to ask, and we will make every effort to address them."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699876074826,
                "cdate": 1699876074826,
                "tmdate": 1699876074826,
                "mdate": 1699876074826,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "YfDL4ZZiJc",
                "forum": "LUcdXA8hAa",
                "replyto": "AL6AjuUYlX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Does our response address your concerns?"
                    },
                    "comment": {
                        "value": "Dear reviewer ggp4,\n\nThanks for reviewing our work and joining in to help make the paper better. We've tried our best to **do the experiments you asked for and answer your questions**. Please let us know if our responses have addressed your concerns. We're ready to talk more if needed. Thanks for your time and thinking about this.\n\nBest,\n\nAuthors."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700206708172,
                "cdate": 1700206708172,
                "tmdate": 1700206708172,
                "mdate": 1700206708172,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zAzNeLI5et",
                "forum": "LUcdXA8hAa",
                "replyto": "AL6AjuUYlX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion period will end soon and we're eagerly waiting for your feedback."
                    },
                    "comment": {
                        "value": "Dear Reviewer ggp4,\n\nI hope you're doing well! ***The discussion period is ending soon***, and we're really excited to hear your thoughts on our response. We just want to check if our rebuttal helped to improve the paper. It would be greatly appreciated if you could kindly tell us if we addressed your previous concerns properly. Thank you once more for your commitment to reviewing our paper.\n\nBest wishes,\n\nThe Authors"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382465196,
                "cdate": 1700382465196,
                "tmdate": 1700382465196,
                "mdate": 1700382465196,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "syzOEASMtM",
                "forum": "LUcdXA8hAa",
                "replyto": "zAzNeLI5et",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Reviewer_ggp4"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewer_ggp4"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\n\nThank you for your responses. On W2, the three extra baseline models provides more solid practical support for the proposed novel techniques in the paper. On W3(1), it\u2019s interesting to see how different models deal with the trade-off between more bias factors and more connected IG. It\u2019s also good to see that the proposed techniques handle the issues properly.  On Q1, the follow-up experiment on disconnectedness verifies the intuitions of the phenomenon and strengthens the validity of the proposed methods. Therefore, I would like to raise the rating to 6. \n\nBest,\nReviewer ggp4"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631326347,
                "cdate": 1700631326347,
                "tmdate": 1700631326347,
                "mdate": 1700631326347,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Zy5oTullrw",
            "forum": "LUcdXA8hAa",
            "replyto": "LUcdXA8hAa",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5474/Reviewer_2RKu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5474/Reviewer_2RKu"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors explore if or when the true relevance can be recovered from click data. Overall, it is a solid paper. My concern lies in whether and how can this approach apply to the existing unbiased learning-to-rank framework that developed from the examination hypothesis. Or, how the proposed framework incorporates current ranking models. Also, it would be better to compare this work against more recently proposed existing unbiased learning-to-rank algorithms. Overall, I give a weak rejection. If the authors would clarify the above concerns, I will be happy to raise my score."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. It is an interesting and important topic to investigate when the true relevance can be recovered from click data.\n2. I like the theoretical analysis in this paper (i.e., Sections 3 and 4).\n3. They have conducted experiments on Yahoo! and Istella-S datasets, verifying the performance of the proposed model."
                },
                "weaknesses": {
                    "value": "1. It lacks recently proposed methods as the baselines.\n2. It would be interesting to discuss the difference between the proposed method and the existing approaches based on the examination hypothesis.\n3. For an unbiased learning-to-rank algorithm, there is always a ranking algorithm base. It is not clear how the proposed model incorporates the existing ranking models."
                },
                "questions": {
                    "value": "It is essential to evaluate if or when the true relevance can be recovered from click data. I like this idea very much. However, in the context of unbiased learning-to-rank, there should be a ranking function (often referred to as biased), and then the core goal of unbiased learning-to-rank is to build a debiasing method that can be incorporated into the biased ranking models. After reading this paper multiple times, I consider that it is not clear how this approach can be applied to existing ranking models. Also, in the experiment part, the authors only compare no debias and a simple examine hypothesis method. I highly recommend the authors compare and discuss the connections to existing unbiased learning-to-rank algorithms such as \u201cUnbiased Learning to Rank with Unbiased Propensity Estimation\u201d and \u201cAn Unbiased Pairwise Learning-to-Rank Algorithm\u201d. Therefore, I would like to give a weak rejection.  If the authors would clarify the above concerns, I will be happy to raise my score."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5474/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698915570791,
            "cdate": 1698915570791,
            "tmdate": 1699636558190,
            "mdate": 1699636558190,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eQZtyMHI2L",
                "forum": "LUcdXA8hAa",
                "replyto": "Zy5oTullrw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission5474/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5474/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank your for your valuable feedback. We are glad that you enjoy the idea in our work. Below are our responses to the weaknesses and questions:\n\n> W1 & Q: It lacks recently proposed methods as the baselines.\n\nWe appreciate your feedback about the evaluation. **We've made changes to the paper, and now it includes results for DLA, Regression-EM, and Two-Tower**. Please check our general response for more details. Our initial submission is linked with DLA, the paper you first shared, as mentioned in Appendix E.3. As for the second paper you shared (known as Pairwise-Debiasing), we didn't compare with it for specific reasons:\n\n- It is not a theoretically sound method, which is proved in [1] (Section 7.1) and [2] (Section 4.1.4).\n\n- It's not based on examination hypothesis, which is our framework developed on.\n\n[1] Reaching the End of Unbiasedness: Uncovering Implicit Limitations of Click-Based Learning to Rank.\n\n[2] Unbiased Learning to Rank: Online or Offline?\n\n> W2. It would be interesting to discuss the difference between the proposed method and the existing approaches based on the examination hypothesis.\n>\n> W3. For an unbiased learning-to-rank algorithm, there is always a ranking algorithm base. It is not clear how the proposed model incorporates the existing ranking models.\n>\n> Q: I consider that it is not clear how this approach can be applied to existing ranking models.\n\n**Our proposed algorithms work with the dataset**: First, we use algorithm 1 to assess if the dataset is identifiable. If it's not, we use algorithm 2 and 3 to adjust the dataset and ensure that its IG is connected. Once that's done, **we apply existing ULTR algorithms and train ranking models using this processed dataset**. This means our method is compatible with various models. We've explained this in Section 5.1 (in initial submission) and explicitly mentioned it in the Introduction (in the revised paper).\n\n---\n\nPlease confirm whether our explanations address your concerns. If you have any more questions or additional concerns, please feel free to ask, and we will make every effort to address them."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699875980461,
                "cdate": 1699875980461,
                "tmdate": 1699875980461,
                "mdate": 1699875980461,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HoXDHBn9nf",
                "forum": "LUcdXA8hAa",
                "replyto": "Zy5oTullrw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Does our response address your concerns?"
                    },
                    "comment": {
                        "value": "Dear reviewer 2RKu,\n\nThanks for reviewing our work and participating in the rebuttal process to improve the paper. We've **compared the existing ULTR algorithms in the revision** and explained **how our methods can be applied to existing methods**. Please let us know if our responses have addressed your concerns. We're open to further discussions if necessary. Appreciate your time and consideration.\n\nBest,\n\nAuthors."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700044533873,
                "cdate": 1700044533873,
                "tmdate": 1700044533873,
                "mdate": 1700044533873,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZdePOAh4OJ",
                "forum": "LUcdXA8hAa",
                "replyto": "Zy5oTullrw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5474/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Discussion period will end soon and we're eagerly waiting for your feedback."
                    },
                    "comment": {
                        "value": "Dear Reviewer 2RKu,\n\nHope you are well! ***The discussion time is wrapping up soon***, and we're really eager to hear your thoughts on our response. We're just checking in to see if our rebuttal helped to make the paper better. It would mean a lot if you could kindly let us know whether we've addressed your earlier concerns properly. Thanks again for your dedication to reviewing our paper.\n\nWarm regards,\n\nThe Authors."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5474/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700382316080,
                "cdate": 1700382316080,
                "tmdate": 1700382316080,
                "mdate": 1700382316080,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]