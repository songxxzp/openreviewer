[
    {
        "title": "De Novo Drug Design with Joint Transformers"
    },
    {
        "review": {
            "id": "EqCT7TIHj5",
            "forum": "PiPaNgOaVP",
            "replyto": "PiPaNgOaVP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6491/Reviewer_jRVR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6491/Reviewer_jRVR"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the de novo molecule design problem by employing a joint transformer that consists of an encoder, a decoder, and a predictive network. Moreover, they also propose a black-box optimization algorithm that is able to generate new molecules with improved proproteis."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The paper tackles an important problem and the chosen properties to condition on are also interesting."
                },
                "weaknesses": {
                    "value": "1. The novelty is not very strong\n2. There are many baselines are missing"
                },
                "questions": {
                    "value": "1. The paper a bit undermines the existing works that are already developed to tackle the conditional generation directly without relying on extra black box optimizers such as Bayesian optimization.  Works such as\n   1)Conditional Molecular Design with Deep Generative Models, https://arxiv.org/pdf/1805.00108.pdf\n   2) MolGPT: Molecular Generation Using a Transformer-Decoder Model, which is mentioned in the paper and pointed out that the model \n      lacks a predictor, but if the goal is the conditional generation, and if we have enough labeled data (which was also used in this paper to \n      learn the predictor), where we can train a conditional generative model that later can be used to generate molecules with the target \n      property, do we still need a predictor during the generation which we can always obtain by separate training if we want to evaluate the \n      newly generated molecules property. \n 3) Conditional generation of molecules from\n     disentangled representations https://ml4molecules.github.io/papers2020/ML4Molecules_2020_paper_52.pdf\n     and many others in recent years, there are many papers that directly tackle conditional generation without the need for extra \n     optimization. \nThere are many baselines shown in Guacamol paper, for instance, for the goal directed generating, for the ZALEPLON MPO score, the highest performance reached 0.754 from graphGA, but this baseline did not appear in the paper. \n\n\n2. The baselines for the property predictor are very weak, in recent years there have been tons of papers published for molecule property prediction. If we skip all the papers that actually use graphs or 3D structures, the models that are trained on SMILES representation which have a predictor are also missing for instance:\nAutomatic Chemical Design Using a Data-Driven Continuous Representation of Molecules\n\nIt is true that there are too many baselines exist around the topic, it is impossible to compare all of them but a good selection of recent work would needed to make the point that the current model is superior to the existing ones.\n\n3. I am a bit confused about model architecture, was wondering how the parameter sharing happens between encoder and decoder, the parameters are fully shared or only part of them are shared? A figure explaining the model architecture would have been helpful.\n\n4. The probabilistic black-box optimization method proposed in algorithm 2 seems to me more like a  filtering process but not really an optimization, unless I have misunderstood. \n5. The proofs for the proposition are said provided in the appendix but there was no appendix is available."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6491/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698328828181,
            "cdate": 1698328828181,
            "tmdate": 1699636727676,
            "mdate": 1699636727676,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "487CVQp9jT",
            "forum": "PiPaNgOaVP",
            "replyto": "PiPaNgOaVP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6491/Reviewer_FkeG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6491/Reviewer_FkeG"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a transformer-based, encoder-decoder framework for conditional molecule generation and property prediction. and several experiments demonstrate that this framework achieves SOTA in targeted virtual screening and de novo drug design."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "Formulate a generic sampling algorithm with theoretical guarantees to guide the generation of novel compounds with this methods."
                },
                "weaknesses": {
                    "value": "1. The experiments and benchmarks presented are not very convincing. In targeted virtual screening, this is a typical problem. It would be better to use DUDE or PCBA as benchmark datasets, also the baseline methods are not highly comparable, lacking pretraining or deep learning-based methods. In de novo drug design, it is also necessary to compare with recent deep learning-based state-of-the-art methods, including popular VAE, GAN, diffusion, and flow matching-based models, such as G-SchNet and EDM.\n\n2. I disagree with the approach of treating molecule generation as BBO problems, as molecules should be calculated accurately using first-principle methods, such as DFT and MD. The author should clarify their reasoning for considering this as a BBO problem.\n\n3. The statement, `it is probabilistic and therefore tailored to avoid non-realistic molecules as sampled examples.` is unclear as to why this sampling strategy can lead to generating realistic molecules. Further discussion and experiments are needed to emphasize this point."
                },
                "questions": {
                    "value": "I believe that incorporating a framework or workflow diagram into the author's writing would greatly enhance the clarity and organization of the text."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6491/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6491/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6491/Reviewer_FkeG"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6491/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698655295115,
            "cdate": 1698655295115,
            "tmdate": 1699636727565,
            "mdate": 1699636727565,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "fEMfmWT19d",
            "forum": "PiPaNgOaVP",
            "replyto": "PiPaNgOaVP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6491/Reviewer_LFPx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6491/Reviewer_LFPx"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposed a method that uses generative transformer architecture for $\\textit{de novo}$ drug design. To achieve the goal, the authors use a joint transformer architecture which combines a transformer encoder, a transformer decoder, and a predictive head. The encoder and decoder share the same weights and the only difference is the mask applied to the weights during training and inference. The joint transformer model is trained with penalized negative log-likelihood loss function with a probability parameter to shift between mask language modeling + regression loss and autoregressive loss. The authors claim that the joint transformer model can reach high accuracy in prediction task for virtual screening, and outperforming SOTA optimization methods in $\\textit{de novo}$ drug design tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The share weight design of the encoder and decoder enables the model to learn robust representation of molecules for both target prediction and SMILES sequence generation. It can also lead to more computationally efficient model, as claimed by the authors.\n\n2. The design of training the joint transformer using a probability hyperparameter to shift between encoder and decoder mode is interesting. It can also cast influence on future works in similar tasks.\n\n3. The manuscript is written with high clarity and easy to follow proofs."
                },
                "weaknesses": {
                    "value": "1. The joint transformer design adds complexity to the training. Despite the advantages mentioned in the Strength section, the three terms (penalty, prediction loss, generative loss) in the loss function needs extra heuristic hyperparameter tuning ($p_{task}$). From the result of Table 1, the choice of $p_{task}$ and the penalty term in loss function will result in trade-off between Validity/FCD and the prediction accuracy of the model. \n\n2. According to Algorithm 2, the probabilistic black-box optimization follows a rejection sampling type of method: if the predicted value of a generate molecule is not higher than a pre-defined threshold, the generated molecule is rejected. I am wondering if such a sampling method will affect the efficiency of the algorithm, especially when the prediction part of the model is undertrained (e.g. when labeled data of a desired property is limited)."
                },
                "questions": {
                    "value": "1. It seems like the property prediction head can only be used to sample a label $y$ from $x$ due to the joint training loss. Is there any deterministic way of predicting the label? What is the loss to train the predictive MLP head? If the MLP head predicts a single value, how is it a sampling process?\n\n2. Page 6, \u201cit is probabilistic and therefore tailored to avoid non-realistic molecules as sampled examples\u201d. This claim seems odd to me as a probabilistic model can sample non-realistic molecules. This is also reflected from the results of the manuscript, like Table 1, in which the validity of generated molecules is not 1. \n\n3. Section 4.2, what\u2019s the purpose of virtual screening benchmarking? Also, the baseline is weak from my perspective because in low data regime, simple ECFP with XGBoost/LightGBM can be the best model compared to pretrained learned features. \n\n4. Some important previous works for $\\textit{de novo}$ drug design are missing such as arxiv.org/abs/2206.09010 and www.science.org/doi/10.1126/sciadv.aap7885"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6491/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698718081147,
            "cdate": 1698718081147,
            "tmdate": 1699636727448,
            "mdate": 1699636727448,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "SGVsTXwFp1",
            "forum": "PiPaNgOaVP",
            "replyto": "PiPaNgOaVP",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6491/Reviewer_etCU"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6491/Reviewer_etCU"
            ],
            "content": {
                "summary": {
                    "value": "The core contribution of this paper is proposing JOINT TRANSFORMER, combining a Transformer decoder, a Transformer encoder, and a predictor with shared parameters. With theoretical basis, *de novo* drug design is formulated as a probabilistic black-box optimization problem, and a general-purpose sampling algorithm is proposed. The authors use some experiments to show the performance of their approach."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "## Strengths\n\n1. Formulating *de novo* drug design as a probablistic BBO problem is a novel perspective.\n2. The writing of the paper is smooth, logical and clear, especially the theoretical formulation is solid."
                },
                "weaknesses": {
                    "value": "## Weaknesses\n\n### Related works\n\nChemformer (https://iopscience.iop.org/article/10.1088/2632-2153/ac3ffb/pdf) also incorporates a bidirectional encoder and an autoregressive decoder to process SMILES. It seems that the model architectures of JOINT TRANSFORMER and Chemformer are similar, but the authors make no mention of this.\n\n### Experiments on targeted virtual screening (section 4.2)\n\n**This part of experiments cannot prove the effectiveness of the algorithm in virtual screening tasks.** The author seems completely unaware of the important baselines and evaluation ways of virtual screening. Please refer to https://pubs.acs.org/doi/10.1021/acs.jcim.5b00090, https://arxiv.org/pdf/2310.06367.pdf.\n\nIn addition, the model for virtual screening can be separated from the model for drug design (molecular generation). This paper should focus on experiments on drug design tasks.\n\n### **Experiments on *de novo* drug design (section 4.3)**\n\nAs indicated by the title, experiments on *de novo* drug design is the most important part to demonstrate the effectiveness of JOINT TRANSFORMER. However, experiments are only conducted on three tasks selected from the GuacaMol dataset, and there are obvious problems with the experimental setup.\n\n1. The authors claim that they choose three tasks \"that are hardest to optimize\" from the GuacaMol benchmark, but there is no basis for this. The GuacaMol benchmark for de novo drug design contains 20 goal-directed tasks, and Gao et al. (2022) also conduct experiments on all the 20 tasks. To the best of my knowledge, no previous work has come to the conclusion that these three MPO tasks are the hardest in GuacaMol. (Note: Low scores do not necessarily mean difficulty, as the score distribution is different for different tasks.)\n\n   **The experiments should be conducted on all 20 tasks in the GuacaMol benchmark.**\n\n2. The evaluation budget is set to 1000, and the authors claim that \"this is more practical than 10000\", \"in many applications a realistic number of evaluations is closer to 100\", but no evidence is provided. Actually, the official setting of the GuacaMol benchmark does not limit the number of evaluations at all, and in most recent works on computer-aided drug design, the number of evaluations is larger than 10000, thanks to the development of computing tools such as docking software.\n\n   **It doesn't make sense to limit the number of evaluations to 1000, and the authors should follow the official settings of GuacaMol.** (Gao et al. (2022) focuses on sample efficiency, but this is not mainstream practice.)\n\n3. The authors only report the highest score (top-1) of the generated molecules, which is different from the official setting of the GuacaMol benchmark (average of top-1, top-10 and top-100 scores). \n\n   **Similarly, the authors should follow the official settings of GuacaMol.**\n\n4. The authors claim that \"JOINT TRANSFORMER outperforms state-of-the-art approaches\" without comparisons to some important recent baselines, such as https://arxiv.org/pdf/2007.04897.pdf.\n\n5. One minor problem: The results of GuacaMol experiments are usually expressed in three decimals, but two decimals are used in this paper.\n\n6. \"Designing molecules that dock well\" has been recognized as the key criterion for algorithms for drug design (https://pubs.acs.org/doi/epdf/10.1021/acs.jcim.2c01355), and most recent works conduct experiments on docking (https://arxiv.org/pdf/2206.09010.pdf). So, I suggest the author add docking experiments.\n\nIn short, **this part of the experiments cannot fully support the effectiveness of JOINT TRANSFORMER on *de novo* drug design**, which is the major concern in this paper."
                },
                "questions": {
                    "value": "## Questions\n\n1. What if I use the scoring function to replace the predictor, as they are more accurate? In this paper there is no experiment on property prediction, so I doubt the effectiveness of the predictor.\n2. I am puzzled by the PBBO algorithm in section 3.2. In real-world *de novo* drug design tasks, there may not be any molecules in the prior distribution that satisfy the property conditions, i.e. $p=0$ in Proposition 2 (that is what *de novo* means). In this case, JOINT TRANSFORMER will not work at all.\n3. I am not sure if this is a typo, but there is no update to the model parameters in Proposition 2, even if $y_i\\geq y_c$."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6491/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6491/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6491/Reviewer_etCU"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6491/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698723677917,
            "cdate": 1698723677917,
            "tmdate": 1699636727308,
            "mdate": 1699636727308,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]