[
    {
        "title": "DAS$^2$C: A Distributed Adaptive Minimax Method with Near-Optimal Convergence"
    },
    {
        "review": {
            "id": "k3hugm6DE1",
            "forum": "WBCPdhQPuz",
            "replyto": "WBCPdhQPuz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9142/Reviewer_Wx7b"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9142/Reviewer_Wx7b"
            ],
            "content": {
                "summary": {
                    "value": "The paper delves into distributed minimax optimization problems, specifically addressing a min-max problem with costs allocated across network-connected nodes. The authors introduce an adaptive stepsize distributed method, notably agnostic to the problem's inherent parameters."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper introduces a novel adaptive step size approach tailored for distributed optimization, aiming to ensure consistency among all nodes. Leveraging this strategy, the authors put forth a distributed method, demonstrating its convergence at near-optimal rates."
                },
                "weaknesses": {
                    "value": "The paper's assumption that every stochastic gradient remains bounded presents a restrictive condition.\nThe overall presentation and structure of the paper need refinement. The paper initiates with equations without offering adequate motivation or a streamlined introduction. This lack of organization is particularly concerning given the dense notation utilized in the work. Additionally, there's a notable absence of discussions surrounding the principal results and the definitions of each parameter. Delving into these results, understanding their implications, and drawing clear comparisons with other works are essential steps that should not be overlooked."
                },
                "questions": {
                    "value": "Regarding the primary result, does it imply that the method converges for all step sizes $\\gamma_{x,y}$, provided the iteration count is sufficiently large?\n\nWhat drove the development of the proposed method? How did you derive those specific updates for the step size?\n\nIs it possible to do away with the bounded gradient assumption? Generally, to demonstrate the convergence of analogous decentralized methods, only the conditions of bounded variance and bounded gradient disagreement are required."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Reviewer_Wx7b"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9142/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698666863793,
            "cdate": 1698666863793,
            "tmdate": 1699637150756,
            "mdate": 1699637150756,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CyYG4R6aoV",
                "forum": "WBCPdhQPuz",
                "replyto": "k3hugm6DE1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer Wx7b"
                    },
                    "comment": {
                        "value": "Thanks for the valuable comments and suggestions.\n\n\n\n> __W1:__ The paper's assumption that every stochastic gradient remains bounded presents a restrictive condition. \n\n__Response:__ As discussed in Remark 2, Assumption 4 on bounded stochastic gradient is widely used to establish convergence rates of adaptive methods. Furthermore, to the best of our knowledge, in the field of stochastic nonconvex-strongly-concave minimax optimization, no existing parameter-agnostic method achieves a near-optimal convergence rate while also eliminating the bounded gradient assumption. This remains an open question for future research. See also the Response 1 to all reviewers for a more detailed discussion.\n\n\n> __W2:__ The overall presentation and structure of the paper need refinement. The paper initiates with equations without offering adequate motivation or a streamlined introduction. This lack of organization is particularly concerning given the dense notation utilized in the work. Additionally, there's a notable absence of discussions surrounding the principal results and the definitions of each parameter. Delving into these results, understanding their implications, and drawing clear comparisons with other works are essential steps that should not be overlooked. \n\n__Response:__ Thanks for the useful suggestions. We have now added proper comparison with more related works in the revised version. We will also carefully refine the presentation and structure of the paper for better readability, and add more discussions on the notations and theoretical results in the final version.\n\n\n > __Q1:__ Regarding the primary result, does it imply that the method converges for all step sizes $\\gamma_{x,y}$, provided the iteration count is sufficiently large?\n\n__Response:__ Yes, as shown in Theorem 2, the proposed DAS$^2$C algorithm always converges without the need to design the stepsizes $\\gamma_x$ and $\\gamma_y$ as in most existing works, which makes it robust to stepsize tuning as evidenced in our experiments. Nevertheless, it is worth to note that the transient time required for time-scale separation depends on the ratio between $\\gamma_x$ and $\\gamma_y$ as discussed in Remark 4.\n\n\n> __Q2:__ What drove the development of the proposed method? How did you derive those specific updates for the step size?\n\n__Response:__ As discussed in Section 2, we first adapt the centralized TiAda to distributed scenario, which adopts the similar stepsizes with exponential factors $\\alpha$ and $\\beta$ to ensure adaptive time-scale separation for centralized nonconvex minimax problem. We thus construct counterexamples with lower bound showing that directly applying adaptive methods might lead to non-convergence in distributed settings. By carefully analyzing the average system as shown in Eq. (4), we propose the first distributed adaptive minimax method, named DAS$^2$C, that incorporates an efficient stepsize control mechanism to maintain consistency across local stepsizes, which involves transmission of merely two extra (scalar) variables. The effectiveness of DAS$^2$C have been illustrated in both theoretical and experimental results.\n\n> __Q3:__ Is it possible to do away with the bounded gradient assumption? Generally, to demonstrate the convergence of analogous decentralized methods, only the conditions of bounded variance and bounded gradient disagreement are required.\n\n__Response:__ To the best of our knowledge, in the field of stochastic nonconvex-strongly-concave minimax optimization, no existing parameter-agnostic method achieves a near-optimal convergence rate while also eliminating the bounded gradient assumption. This remains an open question for future research. In fact, this challenge -- being near-rate-optimal and agnostic to parameters without the need for bounded gradients -- persists even in stochastic minimization with strongly-convex objectives. See also the Response 1 to all reviewers for a more detailed discussion."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700628181634,
                "cdate": 1700628181634,
                "tmdate": 1700628181634,
                "mdate": 1700628181634,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "CLlJgDUn3v",
            "forum": "WBCPdhQPuz",
            "replyto": "WBCPdhQPuz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9142/Reviewer_wTqn"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9142/Reviewer_wTqn"
            ],
            "content": {
                "summary": {
                    "value": "This paper studied the adaptive minimax method in distributed problems. They proposed a distributed adaptive method DAS2C with time-scale separated stepsize control for minimax optimization. By leveraging the transmission of two extra (scalar) variables, non-convergence issue is solved. For nonconvex-strongly-concave distributed minimax problems, it gets a near-optimal convergence rate of $\\tilde{O}  (\\epsilon^{4+ \\delta})$."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Minimax is an important optimization problem in machine learning and the study of minimax in a distributed setting is necessary. \n\n2. The paper is organized well. it presents a counterexample to show how to design the algorithm.   \n\n3. The strategy is simple to use and extra transmission variables are scalar."
                },
                "weaknesses": {
                    "value": "1. The motivation behind this paper is not clear. What is the advantage of the adaptive method and why do we need these types of methods in the distributed setting?   Although few papers study the application of adaptive methods in distributed minimax problems, are adaptive methods necessary in distributed or federated learning compared with non-adaptive algorithms? \n\n2. Some recent related distributed minimax works are missing.\n\n[1] A faster decentralized algorithm for nonconvex minimax problems, NeurIPS 2021\n\n[2] Taming Communication and Sample Complexities in Decentralized Policy Evaluation for Cooperative Multi-Agent Reinforcement Learning, NeurIPS 2021\n\n[3] FedNest: Federated bilevel, minimax, and compositional optimization. ICML 2022\n\n[4] Decentralized Riemannian Algorithm for Nonconvex Minimax Problems. AAAI 2023\n\n[5] Solving a Class of Non-Convex Minimax Optimization in Federated Learning. NeurIPS 2023.\n\n\n3. For the convergence results, if this paper focuses on the nonconvex-strongly-concave, results should include the depends on $\\kappa$. \n\n4. The baselines in experiments seem to only solve the issues about the design of the adaptive method in distributed learning. It does not present why we need adaptive  algorithms in (minimax) distributed problems."
                },
                "questions": {
                    "value": "1. \"$DAS^2C$ is the first distributed adaptive method guaranteeing exact convergence without requiring to know any problem-dependent parameters for nonconvex minimax problems\". Could you explain what are the  \"problem-dependent parameters \"?\n\n2. The convergence is $\\tilde{O}  (\\epsilon^{4+ \\delta})$. What is the result of its centralized counterpart? It seems that related works does not include their term and this result is not as tight as others.\n\n3. In the eq. (4), first equality should be correct. But for the second equality, if you add a projection operator, is the equality still valid?\n\n4. Why $\\min _x \\max _y 1 / n \\sum_{j=1}^n f_i\\left(x ; \\xi_i+y\\right)-\\eta\\|y\\|^2,$ in Robust training of neural network tasks and Generative Adversarial Networks is NC-SC question?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Reviewer_wTqn"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9142/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698678794390,
            "cdate": 1698678794390,
            "tmdate": 1699637150538,
            "mdate": 1699637150538,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Kl3eLSyiIG",
                "forum": "WBCPdhQPuz",
                "replyto": "CLlJgDUn3v",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer wTqn (part 1/2)"
                    },
                    "comment": {
                        "value": "Thanks for the valuable comments and suggestions.\n\n> __W1:__ The motivation behind this paper is not clear. What is the advantage of the adaptive method and why do we need these types of methods in the distributed setting? Although few papers study the application of adaptive methods in distributed minimax problems, are adaptive methods necessary in distributed or federated learning compared with non-adaptive algorithms?\n\n__Response:__ We believe that the application of adaptive methods to distributed minimax problems is an important and underexplored area. We would like to emphasize that: i) distributed optimization has seen significant research progress over the last decade due to its wide applications in various fields; ii) adaptive methods such as AdaGrad and Adam have become the default choice of optimization algorithms in many machine learning applications owing to their robustness to hyper-parameter selection and fast empirical convergence. Therefore, applying adaptive methods as per-node optimizers to distributed optimization algorithms makes sense to improve performance in many applications. More importantly, the design and analysis of distributed adaptive algorithms are challenging due the existence of inconsistency in stepsizes as illustrated by the counterexamples (c.f., Figure 1) and lower bound analysis (c.f., Theorem 1) in Section 2.\n\n\n> __W2:__ Some recent related distributed minimax works are missing.\n\n__Response:__  Thank you for bring these papers to our attention. As listed by the reviewer, the works in [1-3, 5] use variance reduction methods to improve convergence at the cost of additional computation or memory. The work in [4] considers\nRiemannian optimization, which beyond the scope of this paper. We have added all the related references in the introduction and made proper comparison among them. Please refer to the general Response 3 to all reviewers for more details.\n\n\n> __W3:__ For the convergence results, if this paper focuses on the nonconvex-strongly-concave, results should include the depends on $\\kappa$.\n\n__Response:__ Thanks for the valuable suggestion. The dependence on $\\kappa$ of DAS$^2$C can be found in Eq. (75), which is comparable with the centralized TiAda algorithm. It is worth to note that the proposed DAS$^2$C algorithm exhibits parameter-agnostic capability without requiring to know the smoothness or strongly-convexity of the objective functions, which makes it robust to hyper-parameter tuning.\n\n> __W4:__ The baselines in experiments seem to only solve the issues about the design of the adaptive method in distributed learning. It does not present why we need adaptive algorithms in (minimax) distributed problems.\n\n__Response:__ In general, distributed algorithms can accelerate optimization/learning tasks in a data-parallelized manner comparing to centralized method, thus have wide applications in various fields.  Given the robustness to hyperparameter selection and fast empirical convergence of adaptive methods, applying adaptive methods as per-node optimizers to distributed optimization algorithms makes sense to improve performance in many applications. We will consider to add more comprehensive comparisons with the non-adaptive methods in the final version.\n\n(continued below)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627811481,
                "cdate": 1700627811481,
                "tmdate": 1700627811481,
                "mdate": 1700627811481,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "HNgzLdlrOl",
            "forum": "WBCPdhQPuz",
            "replyto": "WBCPdhQPuz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9142/Reviewer_GJ7M"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9142/Reviewer_GJ7M"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the decentralized minimax optimization problem. It developed an adaptive algorithm. However, it missed some important references and introduced strong assumptions and have errors in convergence analysis."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "1. The problem studied in interesting. \n\n2. The counterexample is good."
                },
                "weaknesses": {
                    "value": "1. This paper missed some state-of-the-art literature. \n\n\n[1] A Faster Decentralized Algorithm for Nonconvex Minimax Problems\n[2]  Taming Communication and Sample Complexities in Decentralized Policy Evaluation for Cooperative Multi-Agent Reinforcement Learning\n[3] Decentralized stochastic gradient descent ascent for finite-sum minimax problems\n[4] Jointly Improving the Sample and Communication Complexities in Decentralized Stochastic Minimax Optimization\n\n2. This paper introduces strong assumptions so that the proof is simplified too much. In particular, it assumes the gradient is upper-bounded in Assumption 4, which is not used in the original TiAda paper. In addition, assuming that the function is strongly concave and has a bounded gradient is not common because the simple quadratic function does not satisfy this assumption. \n\n3. There are some errors in the proof. $\\mathcal{P}$ is not a linear operator so eq (36) is not correct.\n\n4. This paper didn't compare with the aforementioned SOTA algorithms."
                },
                "questions": {
                    "value": "1. This paper missed some state-of-the-art literature. \n\n\n[1] A Faster Decentralized Algorithm for Nonconvex Minimax Problems\n[2]  Taming Communication and Sample Complexities in Decentralized Policy Evaluation for Cooperative Multi-Agent Reinforcement Learning\n[3] Decentralized stochastic gradient descent ascent for finite-sum minimax problems\n[4] Jointly Improving the Sample and Communication Complexities in Decentralized Stochastic Minimax Optimization\n\n2. This paper introduces strong assumptions so that the proof is simplified too much. In particular, it assumes the gradient is upper-bounded in Assumption 4, which is not used in the original TiAda paper. In addition, assuming that the function is strongly concave and has a bounded gradient is not common because the simple quadratic function does not satisfy this assumption. \n\n3. There are some errors in the proof. $\\mathcal{P}$ is not a linear operator so eq (36) is not correct.\n\n4. This paper didn't compare with the aforementioned SOTA algorithms."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Reviewer_GJ7M"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9142/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698853206590,
            "cdate": 1698853206590,
            "tmdate": 1699642055473,
            "mdate": 1699642055473,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SmPgHN27s2",
                "forum": "WBCPdhQPuz",
                "replyto": "HNgzLdlrOl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer GJ7M"
                    },
                    "comment": {
                        "value": "Thanks for the valuable comments and suggestions.\n\n> __W1:__ This paper missed some state-of-the-art literature.\n\n__Response:__ Thank you for bring these papers to our attention. We have carefully read through them and found that all of them use variance reduction techniques to improve convergence performance at the cost of additional computation or memory. It should be noted that our method can be also easily integrated with VR technique, leading to a similar improvement. We have now added all the related references in the introduction and made proper comparison among them. Please refer to the general Response 3 to all reviewers for more details.\n\n> __W2:__ This paper introduces strong assumptions so that the proof is simplified too much. In particular, it assumes the gradient is upper-bounded in Assumption 4, which is not used in the original TiAda paper. In addition, assuming that the function is strongly concave and has a bounded gradient is not common because the simple quadratic function does not satisfy this assumption.\n\n__Response:__ We respectfully disagree with the reviewer. As discussed in Remark 2, Assumption 4 on bounded stochastic gradient is widely used for establishing convergence rates of adaptive methods. In fact, this assumption is also imposed in TiAda (c.f., Assumption 3.4). Furthermore, it should be noted that, with compact and convex constraint set $\\mathcal{Y}$, the assumptions on bounded gradient and strong concavity can be satisfied. Please also refer to the Response 1 to all reviewers for a more detailed discussion.\n\n\n> __W3:__ There are some errors in the proof. $\\mathcal{P} $ is not a linear operator so eq (36) is not correct.\n\n__Response:__ Thanks for pointing this out. Indeed, in Eq.~(36), we used the standard non-expansiveness of projection operator, i.e., $|\\left\\| \\mathcal{P} _{\\mathcal{Y}}\\left( y \\right) -y^* |\\right\\| ^2\\leqslant |\\left\\| y-y^* |\\right\\| ^2- |\\left\\| \\mathcal{P} _{\\mathcal{Y}}\\left( y \\right) -y |\\right\\| ^2$ (c.f., Lemma 1 in Nedich et al., 2010), in the proof of Lemma 7. We have modified the statement about projection in the revised version.\n\n* A. Nedic, A. Ozdaglar, P.A. Parrilo. Constrained consensus and optimization in multi-agent networks. IEEE TAC 2010.\n\n> __W4:__ This paper didn't compare with the aforementioned SOTA algorithms.\n\n__Response:__ All of the above references use variance reduction methods to improve convergence at the cost of additional computation or memory. Instead, for fair comparison, we mainly focus on __distributed adaptive methods__ that exhibit parameter-agnostic capability for minimax problems, such as distributed version of TiAda and NeAda, in this work. These methods use mini-batch stochastic gradient without requiring to tune the batch-size or additional memory.  We have added all the related references pointed out by the reviewer in the introduction and made proper comparison among them. See also the Response 2 and 3 to all reviewers for more details."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627695003,
                "cdate": 1700627695003,
                "tmdate": 1700627695003,
                "mdate": 1700627695003,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "DnnjXlmqvk",
            "forum": "WBCPdhQPuz",
            "replyto": "WBCPdhQPuz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9142/Reviewer_x9Sp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9142/Reviewer_x9Sp"
            ],
            "content": {
                "summary": {
                    "value": "This paper studied the decentralized distributed nonconvex-strongly-concave minimax problems, and proposed an efficient adaptive decentralized algorithm to solve these problems. Theoretically, it proved that the proposed algorithm obtain a near-optimal convergence rate. Experimentally, it provided some experimental results to demonstrate the efficiency of the proposed algorithms."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper studied the decentralized distributed nonconvex-strongly-concave minimax problems, and proposed an efficient adaptive decentralized algorithm to solve these problems. Theoretically, it proved that the proposed algorithm obtain a near-optimal convergence rate. Experimentally, it provided some experimental results to demonstrate the efficiency of the proposed algorithms."
                },
                "weaknesses": {
                    "value": "Although the proposed DAS2C algorithm is the first decentralized distributed adaptive method for nonconvex minimax problem, it basically extends the existing adaptive method [1] to decentralized distributed settings. Meanwhile, the DAS2C algorithm can address the issue of inconsistent stepsizes across different nodes by communicating the adaptive step-sizes, which basically follows the same trick in the adaptive federated learning.  \n\n\n[1] Li, X., YANG, J., and He, N. (2023). Tiada: A time-scale adaptive algorithm for nonconvex minimax optimization. In The Eleventh International Conference on Learning Representations."
                },
                "questions": {
                    "value": "1)\tIn DAS2C  algorithm, why use the exponential factors satisfying $\\beta < \\alpha$ ?\n\n2)\tThe DAS2C algorithm needs some stricter assumptions (e.g., $f_i$ is second-order Lipschitz continuous for $y$) than the existing decentralized minimax optimization methods. \n\n3)\tIn the experiments, the authors should add some existing  decentralized  minimax optimization algorithms such as the DPOSG of [2] as the comparison methods.\n\n[2] Liu, M., Zhang, W., Mroueh, Y., Cui, X., Ross, J., Yang, T., and Das, P. (2020). A decentralized parallel algorithm for training generative adversarial nets. Advances in Neural Information Processing Systems, 33:11056\u201311070.\n\n4) Some related references are missing. E.g.,\n\n[a] A Simple and Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave Minimax Optimization\n\n[b] Jointly Improving the Sample and Communication Complexities in Decentralized Stochastic Minimax Optimization\n\n[c] A faster decentralized algorithm for nonconvex minimax problems"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9142/Reviewer_x9Sp"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9142/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698899322480,
            "cdate": 1698899322480,
            "tmdate": 1700712491312,
            "mdate": 1700712491312,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "AFPC70Mvt7",
                "forum": "WBCPdhQPuz",
                "replyto": "DnnjXlmqvk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9142/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9142/Authors"
                ],
                "content": {
                    "title": {
                        "value": "To reviewer x9Sp (part 1/2)"
                    },
                    "comment": {
                        "value": "Thanks for the valuable comments and suggestions. \n\n>__W1:__ Although the proposed DAS$^2$C algorithm is the first decentralized distributed adaptive method for nonconvex minimax problem, it basically extends the existing adaptive method [1] to decentralized distributed settings. Meanwhile, the DAS$^2$C algorithm can address the issue of inconsistent stepsizes across different nodes by communicating the adaptive step-sizes, which basically follows the same trick in the adaptive federated learning.\n\n__Response:__ We respectfully disagree with the reviewer on the algorithm design. In this work, we propose the *first*  distributed adaptive minimax method, named DAS$^2$C, that incorporates an efficient stepsize control mechanism to maintain consistency across local stepsizes, which involves transmission of merely two extra (scalar) variables. This design is non-trivial in the sense that we construct counterexamples showing that directly applying centralized adaptive methods in distributed settings might lead to non-convergence (c.f., Figure 1 and Theorem 1). We emphasize that the proposed stepsize control mechanism is significantly different from adaptive federated learning algorithm, such as AdaFGDA (Huang et al., 2022) where a centralized server node averages all the variables and there is thus no inconsistency in stepsizes (c.f., Line 5 and 6 of Algorithm 1 in Huang et al., 2022).  In this regard, the existing federated adaptive method is not readily applicable to decentralized scenarios. More importantly, our proposed algorithm achieves near-optimal convergence rate matching that of centralized TiAda algorithm, and exhibits parameter-agnostic capability, i.e., without requiring knowledge of problem-dependent parameters, which is also not available in AdaFGDA.\n\n* F. Huang. Adaptive federated minimax optimization with lower complexities. arXiv 2022.\n\n\n>__Q1:__ In DAS$^2$C algorithm, why use the exponential factors satisfying $\\beta < \\alpha$?\n\n__Response:__ The exponential factors $\\beta <\\alpha$ are designed to satisfy adaptive time-scale separation in stepsizes between the minimization and maximization processes, which is necessary for the convergence of adaptive minimax methods with nonconvex-strongly-concave objective (NC-SC) functions, as illustrated in Lin et al. (2020); Yang et al. (2022). Intuitively, for NC-SC problem, the maximization process needs to be faster than minimization to ensure that the strongly-concave function $f(\\cdot, y)$ can be solved with sufficient precision to ensure convergence of minimax problem. This is also the reason why some adaptive minimax algorithms, such as NeAda (Yang et al., 2022), require an extra inner loop for dual variable. Instead, through the design of $\\beta <\\alpha$, we propose the single-loop algorithm DAS$^2$C exhibiting timescale separation in stepsizes.\n\n* T. Lin, C. Jin and M. Jordan. On gradient descent ascent for nonconvex-concave minimax problems. ICML 2020.\n* J. Yang, X. Li and N. He. Nest your adaptive algorithm for parameter-agnostic nonconvex minimax optimization. NuerIPS 2022.\n\n\n\n>__Q2:__ The DAS$^2$C algorithm needs some stricter assumptions (e.g., $f_i$ is second-order Lipschitz continuous for $y$) than the existing decentralized minimax optimization methods.\n\n__Response:__ Assumption 3 on second-order Lipschitz continuity for $y$ is used in existing work to achieve improved convergence rate for minimax problem (Chen et al., 2021; Li et al., 2023). In specific, as discussed in Remark 2, Assumption 3 ensures that $y^{*} (\\cdot)$ is smooth (c.f., Eq.~(46)), which is essential for achieving (near) optimal convergence rate. However, without this assumption, Lin et al. (2020) only show a worse complexity of $\\tilde{\\mathcal{O}}\\left( \\epsilon ^{-5} \\right)$ without a large batchsize. For further discussion of assumptions, please refer to Response 1 to all reviewers.\n\n* T. Chen, Y. Sun and W. Yin. Closing the gap: Tighter analysis of alternating stochastic gradient methods for bilevel problems. NeurIPS 2021.\n* X. Li, J. Yang and N. He. Tiada: A time-scale adaptive algorithm for nonconvex minimax optimization. ICLR 2023.\n* T. Lin, C. Jin and M. Jordan. On gradient descent ascent for nonconvex-concave minimax problems. ICML 2020.\n\n(continued below)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627210972,
                "cdate": 1700627210972,
                "tmdate": 1700627210972,
                "mdate": 1700627210972,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vWi3QOaRKL",
                "forum": "WBCPdhQPuz",
                "replyto": "v5UxnbRYOx",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9142/Reviewer_x9Sp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9142/Reviewer_x9Sp"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Authors"
                    },
                    "comment": {
                        "value": "Thanks for your responses. My concerns have basically been addressed, so I will increase my score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9142/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700712423569,
                "cdate": 1700712423569,
                "tmdate": 1700712423569,
                "mdate": 1700712423569,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]