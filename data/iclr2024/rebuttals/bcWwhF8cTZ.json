[
    {
        "title": "Gradient norm as a powerful proxy to out-of-distribution error estimation"
    },
    {
        "review": {
            "id": "OxZuRhzYpp",
            "forum": "bcWwhF8cTZ",
            "replyto": "bcWwhF8cTZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4544/Reviewer_16Ha"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4544/Reviewer_16Ha"
            ],
            "content": {
                "summary": {
                    "value": "This paper considered estimating the error in out-of-distribution samples, which is crucial in OOD problems. Specifically, this paper considered a very simple yet effective estimator -- gradient norm w.r.t the down-stream models. I.e, a sample with higher gradient norm indicates an OOD sample. Based on these arguments, theoretical analysis is done in both toy and simple settings. Empirical results clearly support the proposed metric."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- In general, I like the proposed idea with simple but well elegant explanations. \n- The idea seems novel for me and reasonable in some settings. \n- Extensive empirical results\n\nBased on these points, I would recommend a borderline positive."
                },
                "weaknesses": {
                    "value": "- About inherent assumptions. I noticed this paper requires that the model should be calibrated. In general, I would think this assumption may not necessarily be true in several settings. For example, it has been widely proved that deep learning models are poorly calibrated. Based on this, I would suggest (1) additional experiments on the calibration error on current IN-distribution test data (2) additional limitation section about this point. \n- About gradient norm detection. Using gradient norm as a detector can be novel in OOD detection. While this might not be sufficiently novel in border distribution shift related papers. For example, paper [1-3] discussed the role of gradient norm/flow in meta-learning, algorithmic fairness and domain adaptation. It can be great if additional discussion is done in border distribution shift related topics. \n- About the pseudo labels in the test data. I agree this is generally a non-trivial task because we never know the calibration property of deep neural-network. I was wondering two alternative scenarios (1) if we use random labels (2) we compute the average on all labels. \n- Based on the assumption it seems a scoring detector is a sufficient estimator. I.e, a higher gradient score should be OOD and not vice versa (because it depends on the data variance, in your toy example). What do you think about sufficient and necessary conditions in estimating OOD errors? \n\n\nReferences\n\n[1] Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis. NeurIPS 21\n\n[2] Fair Representation Learning through Implicit Path Alignment. ICML 22\n\n[3] Algorithm-Dependent Bounds for Representation Learning of Multi-Source Domain Adaptation. AISTAS 23"
                },
                "questions": {
                    "value": "See the weakness part. The specific questions and suggestions are provided."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697586129653,
            "cdate": 1697586129653,
            "tmdate": 1699636431862,
            "mdate": 1699636431862,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "d8xKsjWYct",
                "forum": "bcWwhF8cTZ",
                "replyto": "OxZuRhzYpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1 of Response to Reviewer 16Ha"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive comments and valuable suggestions. We will address the reviewer's concerns below.\n\n**1. Discussion and additional experiments about the model calibration.**\n> About inherent assumptions. I noticed this paper requires that the model should be calibrated. In general, I would think this assumption may not necessarily be true in several settings. For example, it has been widely proved that deep learning models are poorly calibrated. Based on this, I would suggest (1) additional experiments on the calibration error on current IN-distribution test data (2) additional limitation section about this point.\n> \nWe thank the reviewer for correctly noticing this possible limitation. We have mentioned earlier that, in theory, the proposed pseudo-labeling strategy depends on how well the prediction probabilities are calibrated. In degraded cases, this can have a negative impact on our approach, e.g., one can imagine a model that outputs only one-hot probabilities with not a high accuracy. However, this it is generally not the case. Indeed, in practice, we do not need to have a perfectly calibrated model as we employ a mixed strategy that assigns pseudo-labels to high-confidence examples and random labels to low-confidence ones. The recent success of applying self-training models to different problems [1, 2, 3] provides evidence of the suitability of the label generation strategy we adopted.\n\nMoreover, when we speak of deep neural networks, which are widely accepted to be poorly calibrated, [4] showed that modern SOTA image models tend to be well-calibrated across distribution shifts. \nTo demonstrate it empirically, in the table below, we provide the expected calibration error (ECE, [5]) of ResNet18, one of the considered base models, depending on a difficulty of test data.\nFor this, we test first on CIFAR-10 (ID), and then on CIFAR-10C corrupted by brightness across diverse severity from 1 to 5. We can see that ECE is very low for ID data and remains relatively low across all levels of corruption severity, which shows that ResNet is quite well-calibrated on CIFAR-10.\n\n|Severity|ID|1|2|3|4|5|\n| --- | - | - | - | - | - | - | \n|ECE|0.0067|0.0223|0.0230|0.0243|0.0255|0.0339|\n\nOn the other hand, in the case of more complex distribution shift like Office-31 data set, we can see in the table below that the calibration error has been increased noticeably. It is interesting to analyze this result together with Figure 3 of the main paper, where we compared the results between the usual pseudo-labeling strategy and the proposed one. Although our method has room for improvement compared to the oracle method, it is also significantly better than \"pseudo-labels\", indicating that the proposed label generation strategy is less sensitive to the calibration error.\n\n|Domain |DSLR (ID)|Amazon |Webcam |\n| --- | - | - | - |\n|ECE|0.2183|0.2167 |0.4408 |\n\nWe thank the reviewer for their insightful suggestions and we added this limitation section in the revised version of the paper. \n\n[1] Sohn, Kihyuk, et al. \"Fixmatch: Simplifying semi-supervised learning with consistency and confidence.\" Advances in neural information processing systems 33 (2020): 596-608.\n\n[2] Dong, Jiahua, et al. \"Confident anchor-induced multi-source free domain adaptation.\" Advances in Neural Information Processing Systems 34 (2021): 2848-2860.\n\n[3] Yu, Yaodong, et al. \"Predicting out-of-distribution error with the projection norm.\" International Conference on Machine Learning. PMLR, 2022.\n\n[4] Minderer, Matthias, et al. \"Revisiting the Calibration of Modern Neural Networks.\" Advances in Neural Information Processing Systems 34 (2021).\n\n[5] Guo, Chuan, et al. \"On Calibration of Modern Neural Networks.\" ICML 34 (2017).\n\n**2. About gradient norm detection.**\n> About gradient norm detection. Using gradient norm as a detector can be novel in OOD detection. While this might not be sufficiently novel in border distribution shift related papers. For example, paper [1-3] discussed the role of gradient norm/flow in meta-learning, algorithmic fairness and domain adaptation. It can be great if additional discussion is done in border distribution shift related topics.\n> \nIn Related Work (Appendix B), we have discussed the application of gradient norm in many fields, including OOD detection and generalization error bounds. Basically, GradNorm [1] as an OOD detection method utilizes gradient norm to form a function estimator, where it assumes that the softmax probability of OOD samples should be flatter than that of in-distribution samples. We also discuss the differences between our method and GradNorm [1] in Appendix E. We hope this can address your problem about how gradient norm can be applied in OOD detection.\n\n[1] Huang, Rui, Andrew Geng, and Yixuan Li. \"On the importance of gradients for detecting distributional shifts in the wild.\" Advances in Neural Information Processing Systems 34 (2021): 677-689."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251530736,
                "cdate": 1700251530736,
                "tmdate": 1700474569109,
                "mdate": 1700474569109,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QFrCNbcSyk",
                "forum": "bcWwhF8cTZ",
                "replyto": "OxZuRhzYpp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 2 of Response to Reviewer 16Ha"
                    },
                    "comment": {
                        "value": "*3. About the pseudo labels in the test data.**\n> About the pseudo labels in the test data. I agree this is generally a non-trivial task because we never know the calibration property of deep neural-network. I was wondering two alternative scenarios (1) if we use random labels (2) we compute the average on all labels.\n> \n(1) *If we only use random labels (RandLabel)?*\n\nWe conduct the ablation study with ResNet-18 on 5 datasets. The numerical results of $R^2$ are shown below. From this table, we can observe that if we only use random labels, the performance will degrade drastically. For example, the performance of CIFAR-100 decreases from 0.983 to 0.741.\n\n|Dataset|CIFAR-10|CIFAR-100|TinyImageNet|Entity30|Living17|\n| --- | - | - | - | - | - | \n|RandLabel|0.948|0.741|0.900|0.848|0.881|\n|Ours|**0.971**|**0.987**|**0.971**|**0.970**|**0.949**|\n\n(2) *If we compute the average over all labels (AverLabel)?*\n\nWe also conduct the ablation study with ResNet-18 on 5 datasets. The numerical results of $R^2$ are shown below. From this table, we find that our label generation strategy is superior to using average labels. For example, our strategy enhances the performance of AverLabel from 0.897 to 0.971.\n\n|Dataset|CIFAR-10|CIFAR-100|TinyImageNet|Entity30|Living17|\n| --- | - | - | - | - | - | \n|AverLabel|0.949|0.976|0.897|0.837|0.911|\n|Ours|**0.971**|**0.987**|**0.971**|**0.970**|**0.949**|\n\n**4. The sufficient and necessary conditions in estimating OOD errors.**\n> Based on the assumption it seems a scoring detector is a sufficient estimator. I.e, a higher gradient score should be OOD and not vice versa (because it depends on the data variance, in your toy example). What do you think about sufficient and necessary conditions in estimating OOD errors?\n> \nWe thank the reviewer for this very interesting question. If one focuses on the motivational example provided in our work, we demonstrated that norm of the gradient is directly linked to the magnitude of the data variance $\\sigma_t^x$. An extreme case could be to assume $\\sigma_t^x$ very small, say $\\sigma_t^x = \\varepsilon.$ In this situation, estimating the OOD error is particularly difficult as the norm of the gradient will be scaled down, leading to imperceptible variations between IID and OOD data. Hence, a natural condition to estimate OOD errors could be to consider data with enough variance to avoid degenerated cases such as the one previously mentioned. However, in the general setting, to the best of our knowledge, determining sufficient and necessary conditions on (OOD) error estimation is a hard problem which remains open. We advocate that the analysis needed to answer the question is far from trivial and a real research problem on its own. An example showcasing the complexity of the involved computation is [1], where the authors consider a seemingly simple network for which the analysis is surprisingly very difficult and even requires the usage of the Matlab Symbolic Toolbox to help them simplify the calculation. \n\nWe thank the reviewer for their insightful comments. We hope we have adequately addressed their concerns and we will be happy to answer any additional questions. We would be grateful if the reviewer could reconsider the evaluation of our work accordingly.\n\n[1] Arnold, S\u00e9bastien M. R., et al. \"When MAML Can Adapt Fast and How to Assist When It Cannot\", AISTATS 2021, PMLR 130:244-252."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251636159,
                "cdate": 1700251636159,
                "tmdate": 1700532549549,
                "mdate": 1700532549549,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BGxxHxuz0U",
            "forum": "bcWwhF8cTZ",
            "replyto": "bcWwhF8cTZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4544/Reviewer_8wYw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4544/Reviewer_8wYw"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces an approach that leverages gradients to predict OOD errors. The authors propose a \"GRDNORM Score,\" which quantifies the magnitude of gradients after one gradient step on OOD data. The key idea is that a model should have higher magnitude gradients when it doesn't generalize well to OOD data. The paper provides theoretical insights, demonstrating the effectiveness of this approach through extensive experiments, outperforming state-of-the-art algorithms."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The authors support their proposed concept with a thorough set of experiments to validate its efficacy."
                },
                "weaknesses": {
                    "value": "- The problem is not well defined and authors provide more details in supp. material. This way, the reader can not follow the paper well.\n- Lack of novelty: In my view, this paper bears a strong resemblance to the work presented in reference [1]. The only difference with [1] in my opinion is using pseudo labels in your method which is not a significant change.\n\n Furthermore, it is essential to note the existence of another research study in a similar direction, as evidenced by reference [2]. I kindly request that the authors perform a comparative analysis between their paper and these two references, elucidating the primary distinctions and novel contributions of their methodology.\n\n\n\n[1] Huang, Rui, Andrew Geng, and Yixuan Li. \"On the importance of gradients for detecting distributional shifts in the wild.\" Advances in Neural Information Processing Systems 34 (2021): 677-689.\n[2] Igoe, Conor, et al. \"How Useful are Gradients for OOD Detection Really?.\" arXiv preprint arXiv:2205.10439 (2022)."
                },
                "questions": {
                    "value": "I appreciate it if the authors could conduct a comparative analysis of their paper with the references [1] and [2], highlighting the key distinctions and novel aspects of their approach.\n\n\n[1] Huang, Rui, Andrew Geng, and Yixuan Li. \"On the importance of gradients for detecting distributional shifts in the wild.\" Advances in Neural Information Processing Systems 34 (2021): 677-689.\n\n[2] Igoe, Conor, et al. \"How Useful are Gradients for OOD Detection Really?.\" arXiv preprint arXiv:2205.10439 (2022)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698643059055,
            "cdate": 1698643059055,
            "tmdate": 1699636431779,
            "mdate": 1699636431779,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PyhqDL5ljy",
                "forum": "bcWwhF8cTZ",
                "replyto": "BGxxHxuz0U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1 of Response to Reviewer 8wYw"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive comments and valuable suggestions. We will address the reviewer's concerns below.\n\n**1. Improvement of problem definition**\n> The problem is not well defined and authors provide more details in supp. material. This way, the reader can not follow the paper well.\n> \nWe thank the reviewer for pointing out this confusion to us. We added more details to the problem setup explaining what is the exact goal of OOD error estimation problem and its different with OOD detection as explained below in the revised version of our paper.\n\n**2. Relation to GradNorm [1].** \n> Lack of novelty: In my view, this paper bears a strong resemblance to the work presented in reference [1]. The only difference with [1] in my opinion is using pseudo labels in your method which is not a significant change.\n> \nWe thank the reviewer for pointing out the potential confusion between our method and GradNorm [1]. In Appendix E, we have discussed in a very detailed manner the differences between the two methods from the view of problem setting, methodology, theoretical insights, and performance. To the best of our knowledge, we are the first to certify the strong linear relationship between gradient norm and test error even under the distribution shift. We reiterate it below. \n\nIn general, **OOD error estimation and OOD detection are different problems** with different definitions about OOD. In OOD detection as considered in [1], \"OOD\" samples refer to those test samples with different label space from the training set, which is known as semantic shift. In OOD error estimation, we use \u201cOOD\u201d to describe examples with covariant shifts or concept shifts, where their ground-truth labels are included in the label set of the training dataset. The goal of OOD detection is to design a binary function estimator to classify whether a coming sample is from in-distribution or not, while the goal of OOD error estimation is to design a score that is correlative to the ground-truth test error. Essentially, OOD detection is a classification problem, while OOD error estimation can be regarded as a linear regression problem. \n\nDue to different problem settings, although both utilize gradient norm, **we capture different information from the gradient space**. GradNorm assumes that the softmax probability of OOD samples is flatter than in-distribution samples, so the magnitude of gradients measures whether the test sample has a flat softmax probability or not. In this case, the magnitude of gradients for OOD samples should be **smaller** than that for in-distribution samples. However, our method actually measures the gradient distance from the source distribution to the target distribution, which means the magnitude of gradients for OOD samples should be **larger** than in-distribution samples. In addition, GradNorm is an **instance-level** function estimator, while our method is a **dataset-level** score.\n\n**Above differences are also reflected in theoretical insights**. Basically, the superiority of GradNorm to other OOD detection methods is that it includes information from both the feature and the output. In our work, we demonstrate that the magnitude of gradients formulates an upper bound on the true OOD error (Corollary 3.2), showcasing the theoretical soundness of our method for OOD error estimation.\n\n**Empirical Comparison.**  We also numerically compared our method with [1], and the results obtained ($R^2$) with ResNet18 are shown in Table 4 of the revised version of the paper (table below). We can observe from this table that our method is superior to GradNorm for OOD error estimation across diverse distribution shifts. For example, our method outperforms GradNorm on TinyImageNet with a large margin from 0.894 to 0.971. It shows that **GradNorm is not suitable for OOD error estimation problems**.\n\n|Method|CIFAR-10|CIFAR-100|TinyImageNet|Office-31|Office-Home|Entity-30|Living-17|\n| --- | - | - | - | - | - | - | - | \n|GradNorm [1]|0.951|0.978|0.894|0.596|0.848|0.964|0.942|\n|Ours|**0.971**|**0.987**|**0.971**|**0.675**|**0.876**|**0.970**|**0.949**|\n\n[1] Huang, Rui, Andrew Geng, and Yixuan Li. \"On the importance of gradients for detecting distributional shifts in the wild.\" Advances in Neural Information Processing Systems 34 (2021): 677-689."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251292326,
                "cdate": 1700251292326,
                "tmdate": 1700532430989,
                "mdate": 1700532430989,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xEAWZARsFq",
                "forum": "bcWwhF8cTZ",
                "replyto": "BGxxHxuz0U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 2 of Response to Reviewer 8wYw"
                    },
                    "comment": {
                        "value": "**3.Relation to ExGrad [2].**\n>Furthermore, it is essential to note the existence of another research study in a similar direction, as evidenced by reference [2]. I kindly request that the authors perform a comparative analysis between their paper and these two references, elucidating the primary distinctions and novel contributions of their methodology.\n>\nWe thank the reviewer for pointing out to the interesting ExGrad method [2]. This paper tackles the OOD detection problem as in [1] and proposes an instance-level score based on a similar decomposition in terms $U$ and $V$ as in [1]. As such, all our explanations provided above about GradNorm also apply to ExGrad. \n\nTo compare their performance, we also conduct an experiment on 3 datasets with ResNet-18, which results of $R^2$ are shown below.\n\n|Dataset|CIFAR-10|Entity30|Living17|\n| --- | - | - | - | \n|ExGrad|0.198|0.205|0.018|\n|Ours|**0.971**|**0.987**|**0.971**|**0.970**|**0.949**|\n\nFrom the above table, we find that ExNorm is completely invalid under the OOD error estimation task. This phenomenon is because ExNorm can be only deployed with the batch size as 1, from which we obtain imprecise gradient-norm information about the whole dataset.\n\nWe hope we have adequately addressed the reviewers' concerns and we will be happy to answer any additional questions. If the reviewer finds our answer satisfactory, we would be grateful if they can reconsider their score accordingly. \n\n[1] Huang, Rui, Andrew Geng, and Yixuan Li. \"On the importance of gradients for detecting distributional shifts in the wild.\" Advances in Neural Information Processing Systems 34 (2021): 677-689.\n\n[2] Igoe, Conor, et al. \"How Useful are Gradients for OOD Detection Really?.\" arXiv preprint arXiv:2205.10439 (2022)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251371047,
                "cdate": 1700251371047,
                "tmdate": 1700643567703,
                "mdate": 1700643567703,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3TD2U8M0Cq",
                "forum": "bcWwhF8cTZ",
                "replyto": "BGxxHxuz0U",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Reviewer_8wYw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Reviewer_8wYw"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for providing the rebuttal!\nI have no question any more and would consider your rebuttal in my final decision/score."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700549133616,
                "cdate": 1700549133616,
                "tmdate": 1700549133616,
                "mdate": 1700549133616,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "mFxcP2O1rv",
            "forum": "bcWwhF8cTZ",
            "replyto": "bcWwhF8cTZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4544/Reviewer_XBio"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4544/Reviewer_XBio"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors focus on the problem of Out-of-distribution (OOD) Error Estimation, which aims to estimate the test performances under distribution shifts in an unsupervised manner. Inspired by the relationship between the gradient information and the generalization ability within the deep neural network, the authors proposed a novel approach to solve the OOD error estimation problem by leveraging the magnitude of the gradient. Specifically, by analyzing the fine-tuning process of a pre-trained model on the new test data, the authors showed that the gradient information is crucial for OOD error prediction. Then, a novel statistic, named GRDNORM Score, was proposed by calculating the vector norm of the gradient of the last layer through one-step backpropagation, under a confidence-based pseudo-labeling policy. With the empirical evaluations on different datasets, network architectures, and distribution shifts, the proposed method showed its effectiveness and efficiency for OOD error prediction."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The problem that this work investigated is interesting and valuable. OOD error estimation provides a novel perspective to study how the model performs under the distribution shifts, but without accessing the ground-truth test labels.\n2. The usage of gradient information to perform OOD error prediction is novel. To the best of my knowledge, the role of gradient information was less explored in the field. This work provides another viewpoint to build the relationship between the OOD performance and test data, under a data-centric perspective. The proposed method also showed the advantage of the computational overhead.\n3. The motivation is clear and reasonable. The theoretical analysis and empirical verifications are promising and smooth.\n4. The experiments are extensive. The proposed method is verified under different datasets, distributional shifts, etc.\n5. The presentation is clear. This manuscript is well-written."
                },
                "weaknesses": {
                    "value": "1. Some steps of the proposed highly relied on some hyperparameters, such as the confidence threshold adopted for the pseudo-labeling in Eq.(5). However, the manuscript did not provide a detailed explanation about the choice of this hyperparameter.\n2. It seems that an important baseline is missing in the comparisons with the proposed method. \n\nSee the Questions part."
                },
                "questions": {
                    "value": "1. Discussion about the pseudo-label generation process. In Eq. (5), the authors proposed to apply a threshold $\\tau$ to control the confidence-based label generation process. In my understanding, if we set too small values for this hyperparameter, it seems we will assign a determined pseudo-label even for less confident samples. In contrast, using too large values for $\\tau$ can be viewed as discarding more information in this process. Here are my questions:\n\n    - 1.1. How did the authors choose a proper threshold $\\tau$ in this process? I did not find any discussion or analysis for this in the main body or the appendix. But I believe the choice of this threshold does matter for the final performance.\n\n    - 1.2 About the low-confidence case. In Eq.(5), if the maximum probability predicted by the model is still lower than a threshold $\\tau$, the authors proposed to assign a random label from the label space. Is this process reasonable and can it be replaced by other methods? For example, if we set $\\tau=0.5$ and a sample is predicted with  $f_{\\theta} (\\mathbf{x}_{i})=[0.1,0.4,0.35,0.15]$  in a four-way classification scenario. If we adopt the label-generation strategy in this paper, we should randomly generate pseudo-label from the label space $\\mathcal{Y}=${0,1,2,3}. \n\nHowever, even though the maximum probability $0.4< \\tau=0.5$, we can still observe that the model tends to predict $\\mathbf{x}_{i}$ into Class {1,2} with higher probabilities. Thus, will we discard too much information if we naively select a random label within the whole label space? And I guess there are other ways to deal with low-confidence samples. For example:\n\n(a) randomly generate pseudo labels from the top-$K$ largest confidences, e.g., generating from $\\mathcal{Y}^{\\prime}=${1,2} rather than the full label space $\\mathcal{Y}=${0,1,2,3}; \n\n(b) directly adopt the pseudo label $[0.1,0.4,0.35,0.15]$ for this low-confident sample. \n\n2. It seems that a recent work [1] was missed in the comparisons between the proposed method and the baselines. In that work, the confidence and the disperity of the prediction matrix on the test dataset were considered for OOD error estimation and the nuclear norm was adopted to predict the OOD error. Could the authors provide comparisons between the proposed method and this work, both in terms of estimation performance and computational efficiency?\n\n3. Some typos. For example:\n- After Equation (2),  $\\mathbf{s}_{k}$ should be  $\\mathbf{s}_{w}^{k}$ be for a consistent expression;\n- Before Equation (3), $\\mathcal{D}_{test}=\\{\\tilde{\\mathbf{x}}\\}_{i=1}^{m}$ should be $\\mathcal{D}_{test}=\\{\\tilde{\\mathbf{x}_{i}}\\}_{i=1}^{m}$\n\nReferences:\n\n[1] Deng et al. Confidence and Dispersity Speak: Characterizing Prediction Matrix for\nUnsupervised Accuracy Estimation. International Conference on Machine Learning, 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "no"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4544/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4544/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4544/Reviewer_XBio"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698740902324,
            "cdate": 1698740902324,
            "tmdate": 1699636431687,
            "mdate": 1699636431687,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tg4RGQi3iG",
                "forum": "bcWwhF8cTZ",
                "replyto": "mFxcP2O1rv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 1 of Response to Reviewer XBio"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive comments and valuable suggestions. We will address the reviewer's concerns below.\n\n**1. Choice of a proper threshold $\\tau$ on the final performance?**\n> 1.1. How did the authors choose a proper threshold \n in this process? I did not find any discussion or analysis for this in the main body or the appendix. But I believe the choice of this threshold does matter for the final performance.\n>\n \nIn this work, we set the value of $\\tau$ as 0.5 across all datasets and network architectures. To demonstrate the impact of threshold $\\tau$ on the final performance, we conduct an ablation study on CIFAR-10 with ResNet18 by changing the value of $\\tau$. The results are shown below. From this table, we can observe that the final performance firstly experiences a slight increase, and achieves the top when $\\tau$ is 0.4 and 0.5. Then it decreases with the increase of $\\tau$. \n\n|Threshold|0.0|0.1|0.2|0.3|0.4|0.5|0.6|0.7|0.8|0.9|\n| --- | - | - | - | - | - | - | - | - | - | - |\n|Ours|0.963|0.963|0.964|0.965|**0.971**|**0.971**|0.967|0.962|0.963|0.959|\n\nIn this work, we also set $\\tau$ as 0.5 due to an intuitive reason. If a label contains a softmax probability below 0.5, it means that this predicted label has over 50% probability to be wrong. It means that this label has higher probability to be incorrect than to be correct. Thus, we tend to regard it as an incorrect prediction.\n\n\n**2. Other strategies for label assignment of low-confidence samples.**\n\n> (a) Randomly generate pseudo labels from the top-K largest confidences, e.g., generating from $\\mathcal{Y}' = \\{1,2\\}$ rather than the full label space $\\mathcal{Y} = \\{0,1,2,3\\}$;\n> \nIn this experiment, we replace the whole label set used in our label generation strategy with that from the top-k largest confidences. The set of top-k largest confidences is determinded by its accumulative probability which is required to be at least 90%. The results of $R^2$ with ResNet-18 are shown below. \n\n|Dataset|CIFAR-10|CIFAR-100|TinyImageNet|Entity30|Living17|\n| --- | - | - | - | - | - | \n|Top-K|0.968|0.986|0.967|**0.977**|0.940|\n|Ours|**0.971**|**0.987**|**0.971**|0.970|**0.949**|\n\nFrom the above table, we can see that the two label generation strategies are comparable based on their performance.\n\n> (b) Directly adopt the pseudo label [0.1, 0.4, 0.35, 0.15] for this low-confident sample.\n>\nWe have discussed this scenario in the second ablation study, where \"Entropy\" in Figure 4 shows the corresponding results. It shows that though adopting softmax probability for low-confidence samples enhances the performance under the synthetic shift and the novel subpopulation shift, it struggles under the natural shift. \n\nThe next tables illustrate the numerical results of $R^2$ with diverse network architectures and datasets. We can see that, while entropy is comparable, sometimes better, to our approach when the shift is artificial, this method heavily struggles under natural shift (Office-31, Office-Home). On average, our method enables higher performance and is more robust.\n\n|ReNet-18|CIFAR-10|CIFAR-100|TinyImageNet|Office-31|Office-Home|Entity30|Living17|Average|\n| --- | - | - | - | - | - |  - |  - |  - | \n|Entropy|**0.990**|**0.990**|**0.984**|0.404|0.802|**0.985**|**0.958**|0.874|\n|Ours|0.971|0.987|0.971|**0.675**|**0.876**|0.970|0.949|**0.914**|\n\n|ReNet-50|CIFAR-10|CIFAR-100|TinyImageNet|Office-31|Office-Home|Entity30|Living17|Average|\n| --- | - | - | - | - | - |  - |  - |  - | \n|Entropy|**0.992**|**0.996**|**0.992**|0.400|0.799|**0.987**|**0.953**|0.875|\n|Ours|0.969|0.991|0.980|**0.604**|**0.829**|0.957|0.931|**0.895**|\n\n|WRN-50-2|CIFAR-10|CIFAR-100|TinyImageNet|Office-31|Office-Home|Entity30|Living17|Average|\n| --- | - | - | - | - | - |  - |  - |  - | \n|Entropy|**0.992**|0.996|**0.990**|**0.758**|0.357|**0.977**|**0.924**|0.856|\n|Ours|0.971|**0.997**|0.976|0.694|**0.809**|0.949|0.910|**0.901**|"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251117963,
                "cdate": 1700251117963,
                "tmdate": 1700532354639,
                "mdate": 1700532354639,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bnZFErqCn0",
                "forum": "bcWwhF8cTZ",
                "replyto": "mFxcP2O1rv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Part 2 of Response to XBio"
                    },
                    "comment": {
                        "value": "**3. Comparison with Nuclear Norm [1].**\n> 2. It seems that a recent work [1] was missed in the comparisons between the proposed method and the baselines. In that work, the confidence and the disperity of the prediction matrix on the test dataset were considered for OOD error estimation and the nuclear norm was adopted to predict the OOD error. Could the authors provide comparisons between the proposed method and this work, both in terms of estimation performance and computational efficiency?\n\n\nWe thank the reviewer for point out this this very recent state-of-the-art method. As per reviewer's request, we compare the two methods with ResNet-18 on 6 datasets representing three kinds of distribution shifts, which results of both performance ($R^2$) and computational time ($T$) are shown below. From the tables, we see that our method is much more robust to different types of shift: while being slightly worse under mild shift scenarios (CIFAR datasets, Entity and Living17, ~2% drop), it provides an impressive performance boost under natural shift (Office31 and Office-Home, >10% increase).\n\nWe note, however, that given how recent is this publication (less than two months at the moment of our submission), we would like to ask the reviewer to be indulgent regarding our comparison to [1] as we didn't have time to do it more rigorously. \n\n\nMeanwhile, since Nuclear Norm is training-free but our method is based on self-training, it is naturally more time-consumming than Nuclear Norm.\n\n|$R^2$|CIFAR-10|CIFAR-100|Office-31|Office-Home|Entity30|Living17|Average|\n| --- | - | - | - | - | - |  - |  - |  \n|Nuclear|**0.995**|**0.996**|0.547|0.785|**0.988**|**0.978**|0.882|\n|Ours|0.971|0.987|**0.675**|**0.876**|0.970|0.949|**0.904**|\n\n|$T$|CIFAR-10|CIFAR-100|Office-31|Office-Home|Entity30|Living17|\n| --- | - | - | - | - | - |  - |  \n|Nuclear|**7.523**|**8.311**|13.704|**5.468**|**5.253**|**1.871**|\n|Ours|47.207|47.174|**4.475**|14.559|32.882|32.660|\n\n**4. Typos**\n> 3. Some typos. For example: After Equation (2), $\\mathbf{s}^{k}$ should be $\\mathbf{s}_{w}^{k}$ be for a consistent expression; Before Equation (3), $\\mathcal{D}_{test}=\\{\\tilde{\\mathbf{x}}\\}_{i=1}^{m}$ should be $\\mathcal{D}_{test}=\\{\\tilde{\\mathbf{x}_{i}}\\}_{i=1}^{m}$\n\nWe thank the reviewer for pointing out to these typos and we corrected them in the revised version of our paper.\n\nWe would be grateful if the reviewer could reconsider the evaluation of our work given all the replies above and in case we do not manage to either reproduce the results of [1] or do a full-scale comparison.\n\n[1] Deng et al. Confidence and Dispersity Speak: Characterizing Prediction Matrix for Unsupervised Accuracy Estimation. International Conference on Machine Learning, 2023."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700251177750,
                "cdate": 1700251177750,
                "tmdate": 1700532256385,
                "mdate": 1700532256385,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ifIQK8caJa",
                "forum": "bcWwhF8cTZ",
                "replyto": "tg4RGQi3iG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Reviewer_XBio"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Reviewer_XBio"
                ],
                "content": {
                    "title": {
                        "value": "Further comments after the authors' response"
                    },
                    "comment": {
                        "value": "Thank you for your reply. I appreciate the effort from the authors in answering our questions with further explanations and additional empirical verifications. Some of my concerns have been addressed. And I will carefully consider the provided rebuttal during the AC-Reviewer discussion period."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542124044,
                "cdate": 1700542124044,
                "tmdate": 1700542124044,
                "mdate": 1700542124044,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jfiLBZ4dhs",
                "forum": "bcWwhF8cTZ",
                "replyto": "2hyw8hafps",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Reviewer_XBio"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Reviewer_XBio"
                ],
                "content": {
                    "title": {
                        "value": "Comments from Reviewer XBio (2)"
                    },
                    "comment": {
                        "value": "Thanks for your reply. Based on the responses provided by the author and the discussion with other reviewers, I have some further comments:\n- Additional results about choosing threshold $\\tau$.\n\nI noticed that when you set $\\tau$ for extreme cases ($0.0$ or $0.9$), the final performances on CIFAR10 are still comparable with the case $\\tau=0.5$ (with a drop of only $0.8\\%-1.2\\%$). In your paper, you assumed that the classifier made mistakes mostly on data with low prediction confidence (i.e., smaller than $\\tau$), for which you deliberately assigned noisy pseudo-labels. In my perspective, when setting $\\tau=0.0$, we fully trust the pre-trained model and directly adopt the maximum prediction as the pseudo-class; if we set $\\tau=0.9$, we only trust predictions with very very high maximum probability and assign random labels for any samples whose maximum probability is even slightly lower than $0.9$. It is intuitively weird to see that the final performance did not vary too much within such two extreme cases. I understand that perhaps CIFAR-10 is an easy dataset. However, I wonder whether this phenomenon indicated that we require the pre-trained model a well-calibrated one.\n\n- Comparisons with NuclearNorm\n\nThanks for providing such a comparison. I understand that comparing with a very recently published paper is a hard job. Based on your results, it seems that the proposed method does not have too many advantages over NuclerNorm, especially concerning computational efficiency. For example, on CIFAR10/CIFAR100/Entity30/Living17 datasets, it seems NuclearNorm has better performances as well as smaller time consumption."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700669818844,
                "cdate": 1700669818844,
                "tmdate": 1700669818844,
                "mdate": 1700669818844,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EQ9sdwROKm",
                "forum": "bcWwhF8cTZ",
                "replyto": "mFxcP2O1rv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the valuable comments and additional clarification for Reviewer XBio"
                    },
                    "comment": {
                        "value": "We thank the reviewer for his prompt answer and address their concerns below.\n\n**1. Additional results about choosing threshold $\\tau$.**\n\nWe are sorry for any confusion about this experience. To clarify, we conducted an additional experiment on Office-31 with ResNet-18 to show the model requires good calibration, especially for more complex datasets. The results are shown below. We find that the top performance is achieved near $\\tau=0.5$, and the drop for the extreme cases is clearer.\n\n|Threshold|0.0|0.1|0.2|0.3|0.4|0.5|0.6|0.7|0.8|0.9|\n| --- | - | - | - | - | - | - | - | - | - | - |\n|Ours|0.495|0.498|0.532|0.674|**0.685**|0.667|0.545|0.451|0.114|0.131|\n\n\n**2. Comparisons with Nuclear Norm**\n\nWe appreciate the reviewer's introduction of Nuclear Norm to us. However, despite its slight improvement on synthetic shifts, Nuclear Norm suffers from a dramatic drop in performance under natural shifts (Office-31 and Office-Home), which severely diminishes its robustness. Contrary to Nuclear Norm, our method balances well across different distribution shifts and remains better on average. It means our method is safer in the real world, especially when the type of the test distribution shift is unknown. The same conclusion stands concerning our second ablation study, where we adopt softmax probability for low-confidence samples. We believe that the robustness of our method, as well as its strong performance on a wide range of baselines and models, gives it several advantages compared to its counterparts, including Nuclear Norm. \n\nAs for computational efficiency, compared to training-free methods, our approach requires a reasonable amount of time while ensuring robustness and delivering enhanced performance. Compared to other self-training methods (ProjNorm), our method dramatically decreases their computational cost and enhances their performance.\n\nWe thank again the reviewer for your insightful feedback and interesting questions. We hope we have addressed your concerns and will be happy to answer any additional questions. If you find our answers satisfactory, we hope the reviewer will reconsider the evaluation of our work in this sense."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682959918,
                "cdate": 1700682959918,
                "tmdate": 1700688091720,
                "mdate": 1700688091720,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "MfpmmLOAFc",
            "forum": "bcWwhF8cTZ",
            "replyto": "bcWwhF8cTZ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4544/Reviewer_b4cf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4544/Reviewer_b4cf"
            ],
            "content": {
                "summary": {
                    "value": "The paper explores the use of gradient magnitude from the classification layer as an indicator of Out-of-Distribution (OOD) data, acquired via backpropagation from the cross-entropy loss following a single gradient step. The primary notion is that the model should be fine-tuned with greater gradient magnitudes when it struggles to generalize to the OOD dataset. Empirical evidence further validates this concept."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "S1: The paper considers using the magnitude of gradients from the classification layer as OOD indicator, obtained through backpropagation from the cross-entropy loss following a single gradient step on Out-of-Distribution (OOD) data. \n\nS2: The main concept revolves around the notion that the model needs to be calibrated with larger gradient magnitudes in cases where it fails to generalize to the OOD dataset. Empirical evidences also supports the idea."
                },
                "weaknesses": {
                    "value": "1. I am afraid the paper seems to have significant overlap with the published paper in terms of the idea of using parameterization norm as a measurement: \"[A] Rui Huang et al., On the Importance of Gradients for Detecting Distributional Shifts in the Wild (GradNorm)\", who both consider using the gradients norm of the parameters as an indicator of OOD data. Surprisingly, the name of the approches are even the same (GradNorm). The only difference is that this paper under review is considering backpropogating vanilla softmax loss, under which the parameterization norm is computed, whereas in paper [A], an KL is computed. But this is very minor difference, as both sotfmax and KL are just distinguishes in how the distribution discrepancy is measured. I am afraid this significantly limits the novelty of the paper.  Please compare the proposed method with [A].\n\n2. Please compare empirically with the mentioned paper and illustrates why the proposed method should have any capacity to be more advantageous than [A].\n\n[A] Rui Huang et al., On the Importance of Gradients for Detecting Distributional Shifts in the Wild (GradNorm)"
                },
                "questions": {
                    "value": "Please see above for the questions to be addresed. Please correct me during rebuttal, if there is any misunderstanding here."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4544/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698780040116,
            "cdate": 1698780040116,
            "tmdate": 1699636431603,
            "mdate": 1699636431603,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "M0XpXrHcHm",
                "forum": "bcWwhF8cTZ",
                "replyto": "MfpmmLOAFc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer b4cf"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the positive comments and valuable suggestions. We will address the reviewer's concerns below.\n\n**1. Relation to GradNorm [1].**\n> 1. I am afraid the paper seems to have significant overlap with the published paper in terms of the idea of using parameterization norm as a measurement: \"[A] Rui Huang et al., On the Importance of Gradients for Detecting Distributional Shifts in the Wild (GradNorm)\", who both consider using the gradients norm of the parameters as an indicator of OOD data. Surprisingly, the name of the approches are even the same (GradNorm). The only difference is that this paper under review is considering backpropogating vanilla softmax loss, under which the parameterization norm is computed, whereas in paper [A], an KL is computed. But this is very minor difference, as both sotfmax and KL are just distinguishes in how the distribution discrepancy is measured. I am afraid this significantly limits the novelty of the paper. Please compare the proposed method with [A].\n> \nWe thank the reviewer for pointing out the potential confusion between our method and GradNorm [1]. In Appendix E, we have discussed in a very detailed manner the differences between the two methods from the view of problem setting, methodology, theoretical insights, and performance. To the best of our knowledge, we are the first to certify the strong linear relationship between gradient norm and test error even under the distribution shift. We reiterate it below.\n\nIn general, **OOD error estimation and OOD detection are different problems** with different definitions about OOD. In OOD detection as considered in [1], \"OOD\" samples refer to those test samples with different label space from the training set, which is known as semantic shift. In OOD error estimation, we use \u201cOOD\u201d to describe examples with covariant shifts or concept shifts, where their ground-truth labels are included in the label set of the training dataset. The goal of OOD detection is to design a binary function estimator to classify whether a coming sample is from in-distribution or not, while the goal of OOD error estimation is to design a score that is correlative to the ground-truth test error. Essentially, OOD detection is a classification problem, while OOD error estimation can be regarded as a linear regression problem. \n\nDue to different problem settings, although both utilize gradient norm, **we capture different information from the gradient space**. GradNorm assumes that the softmax probability of OOD samples is flatter than in-distribution samples, so the magnitude of gradients measures whether the test sample has a flat softmax probability or not. In this case, the magnitude of gradients for OOD samples should be **smaller** than that for in-distribution samples. However, our method actually measures the gradient distance from the source distribution to the target distribution, which means the magnitude of gradients for OOD samples should be **larger** than in-distribution samples. In addition, GradNorm is an **instance-level** function estimator, while our method is a **dataset-level** score.\n\n**The above differences are also reflected in theoretical insights**. Basically, the superiority of GradNorm to other OOD detection methods is that it includes information from both the feature and the output. In our work, we demonstrate that the magnitude of gradients formulates an upper bound on the true OOD error (Corollary 3.2), showcasing the theoretical soundness of our method for OOD error estimation.\n\n**2. Empirical Comparison.**\n> 2. Please compare empirically with the mentioned paper and illustrate why the proposed method should have any capacity to be more advantageous than [1].\n\nWe also numerically compared our method with [1], and the results obtained ($R^2$) with ResNet18 are shown in Table 4 of the revised version of the paper (table below). We can observe from this table that our method is superior to GradNorm for OOD error estimation across diverse distribution shifts. For example, our method outperforms GradNorm on TinyImageNet with a large margin from 0.894 to 0.971. It shows that **GradNorm is not suitable for OOD error estimation problems**.\n\n|Method|CIFAR-10|CIFAR-100|TinyImageNet|Office-31|Office-Home|Entity-30|Living-17|\n| --- | - | - | - | - | - | - | - | \n|GradNorm [1]|0.951|0.978|0.894|0.596|0.848|0.964|0.942|\n|Ours|**0.971**|**0.987**|**0.971**|**0.675**|**0.876**|**0.970**|**0.949**|\n\nWe thank the reviewer for their insightful comments. We hope we have adequately addressed their concerns and we will be happy to answer any additional questions. We would be grateful if the reviewer could reconsider the evaluation of our work accordingly.\n\n[1] Huang, Rui, Andrew Geng, and Yixuan Li. \"On the importance of gradients for detecting distributional shifts in the wild.\" Advances in Neural Information Processing Systems 34 (2021): 677-689."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700250941512,
                "cdate": 1700250941512,
                "tmdate": 1700549201652,
                "mdate": 1700549201652,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rZB3sZALMi",
                "forum": "bcWwhF8cTZ",
                "replyto": "MfpmmLOAFc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4544/Reviewer_b4cf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4544/Reviewer_b4cf"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response."
                    },
                    "comment": {
                        "value": "Thanks for the response from the authors. However, even if the method actually measures the gradient distance from the source distribution to the target distribution (rather than the used uniform distribution as in GradNorm), the basic fundamental loss discrepancy still is similar to the gradient computation mentioned in GradNorm. This has shown limited novelty of the method in terms of how loss is defined. The reason why OOD detection (as in GradNorm) uses uniform distribution is because of the OOD detection task assumes OOD samples should be agnostic to in-liners. But I am afraid this does not change the fact that the two (this work under the setting of OOD error estimation and GradNorm) are using basically same measurements, i.e., gradient as the core metric to threshold OOD data. I am afraid I will have to maintain my score."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4544/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700627240406,
                "cdate": 1700627240406,
                "tmdate": 1700627432375,
                "mdate": 1700627432375,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]