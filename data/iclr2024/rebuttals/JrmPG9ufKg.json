[
    {
        "title": "A Mutual Information Perspective on Federated Contrastive Learning"
    },
    {
        "review": {
            "id": "OU5ouwAYr3",
            "forum": "JrmPG9ufKg",
            "replyto": "JrmPG9ufKg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3530/Reviewer_3B5H"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3530/Reviewer_3B5H"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an extension of SimCLR, a contrastive learning framework, to the federated learning (FL) setting, with a focus on mutual information maximization (MI) across multiple views.\nThe authors establish a connection between contrastive representation learning and user verification and propose a method that incorporates a user verification loss into each client\u2019s local SimCLR loss, resulting in a lower bound to the global multi-view mutual information. \nAdditionally, the paper extends the approach to the federated semi-supervised setting, introducing modifications to accommodate labelled data at the clients and proposing an auxiliary head for label prediction. The paper also investigates the impact of different sources of non-i.i.d. data distribution on federated unsupervised learning performance."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The extension of SimCLR to the federated setting and the exploration of MI maximization in this context is particularly given the increasing interest in FL.\nThe paper provides a theoretical foundation for the proposed methods, including the connection between contrastive learning and user verification, and the derivation of a lower bound to the global multi-view MI.\nThe authors conduct both unsupervised and semi-supervised experiments, providing a thorough evaluation of their proposed method."
                },
                "weaknesses": {
                    "value": "The theoretical derivations, propositions, and lemmas mainly connect to and extend existing methods, which might be perceived as a lack of novelty. For example, the idea of decomposed MI in (1) and (2) has been presented in Sordoni et al. (2021). The proofs of propositions and lemmas are quite standard which mostly follow the existing approaches in literature. It would be more beneficial if the authors can clarify the unique aspects and advantages of their approach, and clearly differentiate it from existing methods.\nFurthermore, the authors only provide analysis for a two-view setting, which might not be completely satisfied with the proposed multi-view MI.\nThe paper does not present algorithms for federated training, which is crucial for practical implementation. Moreover, as a federated learning algorithm, there should be a thorough analysis of the convergence guarantees, which seems to be lacking.\nThe experimental setup presented in the paper demonstrates a certain degree of comprehensiveness; however, it appears to be somewhat limited in terms of diversity. The FL baselines utilized in the study are mainly adaptations from centralized methods, which may not fully represent the state-of-the-art in unsupervised representation learning within the FL context. \nLooking at the results outlined in Tables 1 and 2, it becomes evident that in a majority of the scenarios, the performance of the proposed method is either on par with or falls short of other unsupervised baselines. This observation raises questions about the clear and tangible benefits of the proposed approach."
                },
                "questions": {
                    "value": "Additionally, the proposed multi-view MI estimation might result in additional computation overhead.  This is particularly crucial in FL where computational resources are may be limited. Therefore, the paper could be significantly enhanced by a more thorough analysis and discussion of the trade-offs between performance and computational complexity."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3530/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698717977820,
            "cdate": 1698717977820,
            "tmdate": 1699636306901,
            "mdate": 1699636306901,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GCupOWvRnu",
                "forum": "JrmPG9ufKg",
                "replyto": "OU5ouwAYr3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to review"
                    },
                    "comment": {
                        "value": "We thank you for the thoughtful review and the encouraging comments about our work. We hope that with the shared response and the following we address your concerns:\n\n-\t*Theory*: Indeed, Sordoni et al. has also proposed a decomposition of the MI, but we argue that the main goal of Sordoni et al. is different than ours. Sordoni et al. decomposes the MI to get a better estimation of the MI with InfoNCE type of bounds, whereas in our case the decomposition happens due to the partitioning of the data in the federated setting. As a result, we believe that our contribution is orthogonal, since, e.g., the methods from Sordoni et al. could be applied for the SimCLR training on each client. Overall, we believe that the decomposition of the MI itself is not our novel result per se, as it is a trivial consequence of the mutual information properties. We simply highlight this decomposition in order to show that a) simple SimCLR on each client (a common baseline in federated SSL [1, 2]) optimizes one term of the decomposition and b)  (which is one of our main results) how through that decomposition and an auxiliary user-verification task we can lower bound the global mutual information. Furthermore, through this (similar) decomposition we were able to propose a novel, from the perspective of MI, extension of SimCLR (and our baselines) to the semi-supervised setting. We will update the paper accordingly.\n\n-\t*Amount of views*: we use only two views as we adopt the standard convention for SSL methods.\n\n-\t*Algorithms for federated training*: indeed, this is a good point and we updated the paper to include algorithms in the appendix. \n\n-\t*Performance relative to baselines*: please also see the response to wQ6s; overall **the baselines do sometimes better only after we incorporate the intuitions and theoretical results from our MI and FedSimCLR discussion.**\n\n-\t*Computational overhead*: overall, we, at most, include just two additional heads to the feature encoder which, compared to the feature encoder itself, do not add have much extra computational overhead. We have revised the paper accordingly. \n\nWe hope that with the shared response and the above we address your concerns, and we are happy to continue the discussion otherwise.\n\n[1] Federated Unsupervised Representation Learning, Zhang et al., 2020\n\n[2] Federated Contrastive Learning for Decentralized Unlabeled Medical Images, 2021"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3530/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700242052611,
                "cdate": 1700242052611,
                "tmdate": 1700242174824,
                "mdate": 1700242174824,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PgBeLj6Zl0",
                "forum": "JrmPG9ufKg",
                "replyto": "OU5ouwAYr3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Last day of discussion"
                    },
                    "comment": {
                        "value": "Dear 3B5H,\n\nThe discussion period is nearing its end, so we would like to ask you whether our rebuttal and revised submission adequately address your concerns.  More specifically, per your request, we have done the following changes in the submission\n\n- We have discussed Sordoni et al. \n- We have added in the appendix the algorithms for federated training with our methods\n- We have discussed about the convergence guarantees of our methods\n- We have increased the diversity of our experiments by considering more baselines in both the unsupervised and semi-supervised setting.\n- We have updated the discussion to better highlight that the baselines do better only **after** we incorporate the intuitions from our theory and mutual information perspective.\n- We have discussed the computational overhead of our methods.\n\nWe are happy to engage further in discussions to clarify any confusion or misunderstanding."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3530/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674759800,
                "cdate": 1700674759800,
                "tmdate": 1700674759800,
                "mdate": 1700674759800,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OKuLy3oRKr",
            "forum": "JrmPG9ufKg",
            "replyto": "JrmPG9ufKg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3530/Reviewer_wQ6s"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3530/Reviewer_wQ6s"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a federated variant of SimCLR for unsupervised representation learning. It motivates its approach by a mutual information argument: since in standard SimCLR the goal is to maximize the mutual information (MI) between the two generated views, this MI can be decomposed into a local variant that corresponds to local SimCLR and two excess terms that need to be bounded. The first relates the mutual information between the first view and its local client, which is lower bounded using a classifier that seeks to predict the client ID from the first view. The second term relates to the additional or excess mutual information of the second view on the client which can be upper bounded by a second classifier that predicts the client ID from the second view. In addition, the paper presents a semi-supervised variant of this approach."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- unsupervised federated representation learning is an important and interesting use-case\n- the method theoretically motivated and sound"
                },
                "weaknesses": {
                    "value": "- some baselines for semi-supervised learning, and some proper supervised baselines are missing.\n- The empirical results show that the proposed federated SimCLR variant is only en par with spectral constrastive learning when using a user verification loss. This is not properly discussed."
                },
                "questions": {
                    "value": "**Question:**\n- How does the semi-supervised variant of SimCLR relate to pseudo-labeling approaches, such as distributed distillation [2] and federated co-training [1]?\n\n**Detailed Comments:**\n\n- Please discuss the empirical results, in particular the fact that FedSimCLR is not outperforming the baselines, in more detail. The proposed method does not have to outperform the baselines, as long as the benefits and limitations of it in comparison with existing methods are properly discussed. To stress this point: it has become usual to require papers to have large tables where the proposed method has \"the best number\" in each row, but this just promotes scientifically questionable practices to improve the numbers. I am happy that this paper presents more interesting results, but they require, unfortunately, a more thorough discussion. One could even, for example, use mutual information as quality measure (where one would probably rely on the more tractable Wasserstein dependency measure [6], isntead of approximating MI).\n- Please state what exactly the supervised baseline in your experiments is (I assume FedAvg). Please compare to (one of the) FL variants for non-iid data, such as FedProx [4], FedBN [5], and SCAFFOLD [3], as baselines.\n- For the semi-supervised setting, please compare to pseudo-labeling approaches [1,2] as semi-supervised baselines.\n\n\n[1] Abourayya, Amr, et al. \"Protecting Sensitive Data through Federated Co-Training.\" arXiv preprint arXiv:2310.05696 (2023).\\\n[2] Bistritz, Ilai, Ariana Mann, and Nicholas Bambos. \"Distributed distillation for on-device learning.\" Advances in Neural Information Processing Systems 33 (2020): 22593-22604.\\\n[3] Karimireddy, Sai Praneeth, et al. \"Scaffold: Stochastic controlled averaging for federated learning.\" International conference on machine learning. PMLR, 2020.\\\n[4] Li, Tian, et al. \"Federated optimization in heterogeneous networks.\" Proceedings of Machine learning and systems 2 (2020): 429-450.\\\n[5] Li, Xiaoxiao, et al. \"FedBN: Federated Learning on Non-IID Features via Local Batch Normalization.\" International Conference on Learning Representations. 2021.\\\n[6] Ozair, Sherjil, et al. \"Wasserstein dependency measure for representation learning.\" Advances in Neural Information Processing Systems 32 (2019)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3530/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3530/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3530/Reviewer_wQ6s"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3530/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698738183242,
            "cdate": 1698738183242,
            "tmdate": 1700579117862,
            "mdate": 1700579117862,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NBL35N6o9D",
                "forum": "JrmPG9ufKg",
                "replyto": "OKuLy3oRKr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to review"
                    },
                    "comment": {
                        "value": "We thank you for the insightful comments and for acknowledging the theoretical motivation and soundness of our work. We appreciate that you find our results interesting and, together with the shared response, we will provide more details in support of our work\n\n-\t*Empirical results*: we consider FedSimCLR as one instance of a method that optimizes a global pretraining objective, stemming from the following intuition. Since on each client the model contrasts between datapoints of the same distribution, a way to close the gap to the centralized model training is by having the model also distinguishing between users as well, i.e., a user-verification objective. In the case of mutual information this becomes precise due to the user-verification task acting as a lower bound to the gap between the global and local MI. Furthermore, we also demonstrate theoretically at Proposition 3 that closing the gap with such an auxiliary objective is beneficial, as in itself is a lower bound to the, unavailable, label  classification objective. Based on these intuitions from our perspective and theory, we do extend both Spectral CL and SimSiam in a similar manner (i.e., Spectral CL + UV and SimSiam +UV) and we do observe that the results generalize similarly. However, **Spectral CL does better only when incorporating the results from our theory and is worse than FedSimCLR otherwise (e.g., compare FedSimCLR against Spectral CL without the UV loss)**. Now as to why Spectral CL + UV does better than FedSimCLR, this could be attributed the fact that in the centralized setting, Spectral CL can be better than SimCLR [2] and, through the modifications stemming from our intuitions and theory in the case of MI, can also do better in specific federated settings. Exploring alternative dependency metrics such as [6] in the federated setting is definitely interesting and something we will explore in future work.\n\n-\t*Relation to pseudo-labelling approaches*: while from our perspective there are no pseudo-labels, we do agree that having these results as well will help providing a better overall picture. To this end, we are running experiments with two pseudo-label approaches, SemiFed and CBAFed, and so far we observe similar outcomes: the UV loss motivated by our theory is beneficial in the case of label skew.\n\n-\t*Supervised baseline*: you are partially correct, in that the supervised baseline corresponds to variant FedAvg. Specifically, we use the superior server-side averaging FedAdam proposed by [1], as we explain in Appendix A. In [1] the authors show empirically that this approach is strictly superior to SCAFFOLD for the cross-device setting, which is why we have not included SCAFFOLD. We have experimented with FedProx but did not see any effect of $\\mu>0$ for our choice of $E=1$ across experiments unless setting $\\mu>>1$ to detrimental effect. FedBN is a proven FL algorithm under covariate shift, however it prescribes the existence of BatchNorm layers in the network, which we choose to omit. FedBN further assumes the existence of a data-set for computing statistics on a new client, which is an assumption standard FedAvg (FedAdam) does not require with GroupNorm. In summary, we believe that FedAdam is a strong supervised baseline under the given assumptions.\n\nWe hope that with the above we have addressed your concerns, and we are happy to continue the discussion otherwise. \n\n[1] Adaptive Federated Optimization, Reddi et al., ICLR 2021\n\n[2] Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss, HaoChen et al., NeurIPS 2021"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3530/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700241892399,
                "cdate": 1700241892399,
                "tmdate": 1700241892399,
                "mdate": 1700241892399,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "M4nb7NJebv",
                "forum": "JrmPG9ufKg",
                "replyto": "NBL35N6o9D",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3530/Reviewer_wQ6s"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3530/Reviewer_wQ6s"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Dear authors, \n\nThank you for your response. Thank you for clarifying that the results for spectral CL are only better with your proposed UV loss, I indeed missed that. With this in mind, it could improve clarity to present the UV loss as the main contribution that can be applied to many methods (it seems to improve SimCLR and spectral CL, but not SimSiam). Independent of the presentation, this sufficiently addresses my concern about the empirical results. Thank you for also including results on pseudo-labeling approaches. Regarding the supervised baseline, using FedAdam is a sensible choice. In my experience, however, it has often been outperformed by SCAFFOLD and FedProx on non-iid data. Therefore, please consider adding one or both methods as baselines in the next version of the manuscript. This is not a critical point, though. The argument for omitting FedBN is sound.\n\nOverall, my concerns have been addressed and I will raise my score accordingly."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3530/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700579095631,
                "cdate": 1700579095631,
                "tmdate": 1700579095631,
                "mdate": 1700579095631,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "OxGnJIlmTZ",
            "forum": "JrmPG9ufKg",
            "replyto": "JrmPG9ufKg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3530/Reviewer_JEx9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3530/Reviewer_JEx9"
            ],
            "content": {
                "summary": {
                    "value": "This work extends SimCLR for federated learning, emphasizing multi-view mutual information maximization. It connects contrastive representation learning with user verification and introduces a user verification loss to improve global multi-view mutual information. Additionally, the study extends SimCLR to the federated semi-supervised setting, achieving a supervised SimCLR objective with specific modifications. The research explores the impact of non-i.i.d. data on federated unsupervised learning and shows that the global objective has mixed effects depending on the source of non-i.i.d. data."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The problem of pretraining large models in a federated setting is quite important and has seen little progress so far.\n- The proposed LB on the global multi-view objective is principled and as the authors show amenable to federated training. \n- Experiments in the semi-supervised setting are a nice addition to the paper, and clearly shows that their objective can be built upon."
                },
                "weaknesses": {
                    "value": "- The paper lacks convergence analysis of their optimization algorithm, which is quite common in FL papers. \n- Experiments on more challenging/heterogeneous benchmarks like ImageNet are missing. \n- Discussion on how their objective can be adapted to other centralized pretraining objectives is missing. (See questions)\n- (Minor/Nit) Proposition 2 need not be stated, it follows immediately from previous Lemmas."
                },
                "questions": {
                    "value": "- How does the proposed MI LB/relaxation work if we move slightly away from SimCLR and look at related objectives: InfoNCE, or even non-contrastive ones like Barlow Twins? Are federated versions of these similar to Federated SimCLR?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3530/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3530/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3530/Reviewer_JEx9"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3530/-/Official_Review"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699645602581,
            "cdate": 1699645602581,
            "tmdate": 1700750307755,
            "mdate": 1700750307755,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "th2lE7PNga",
                "forum": "JrmPG9ufKg",
                "replyto": "OxGnJIlmTZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to review"
                    },
                    "comment": {
                        "value": "Thank you for reviewing our work and for acknowledging the theoretical soundness of our proposed methods as well as the efficacy of our semi-supervised setting. Regarding your specific points:\n\n-\t*Complexity of the experiments*: we chose these settings as they are the most popular settings considered in the federated SSL literature. Furthermore, while the difficulty of the image dataset itself is lower compared to settings typically considered in centralized SSL (i.e., ImageNet), they are still difficult from the perspective of federated learning due to the extreme non-i.i.d.-ness we consider, e.g., class proportions from Dirichlet sampling with $\\alpha = 0.01$ together with covariate shift, i.e., our joint shift setting. \n\n-\t*Applying our objective to other centralized pretraining objectives*: we have indeed demonstrated how our insights apply to other pretraining objectives, be it contrastive, i.e., SimCLR (which is an instance of InfoNCE) and Spectral CL, or non-contrastive, i.e., SimSiam, by intuitively using the same structure for the loss (see the paragraph above the \u201cUnsupervised Setting\u201d in the experiment section). We will expand more about this in the appendix. Indeed, in doing so we observe similar patterns: In the fully unsupervised case with Spectral CL we have better performance in the presence of label skew when adding the UV loss. We also extended these baselines in the same way to the semi-supervised setting, i.e., applying the pretraining objective between elements that belong to the same class while adding an auxiliary classification head that predicts the correct class for those datapoints where it is available. In this scenario we also observe similar improvements, with our SimSiam modifications and the UV loss we significantly improve performance. Extending to feature contrastive approaches such as Barlow Twins is an interesting direction for future work. \n\n-\t*Proposition 2*: it indeed follows from the previous arguments, so we are happy to remove it. \n\nWe hope that with the shared response and the above, we convince you about the contributions of our work. Let us know if there is something that we should further elaborate upon."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3530/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700241766182,
                "cdate": 1700241766182,
                "tmdate": 1700241766182,
                "mdate": 1700241766182,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mxLPDCjlBQ",
                "forum": "JrmPG9ufKg",
                "replyto": "th2lE7PNga",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3530/Reviewer_JEx9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3530/Reviewer_JEx9"
                ],
                "content": {
                    "title": {
                        "value": "Response to Rebuttal"
                    },
                    "comment": {
                        "value": "I thank the reviewers for the additional experiments on SimSiam and Spectral CL. This clarifies the generality of their approach to other SSL objectives. Given this, I feel this paper presents a useful contribution to the field by providing a principled lower bound  that decomposes the SSL objective into a local objective that only uses client data and a user-verification loss.  \n\nStill, I would encourage the authors to consider adding (in the order of priority): i) experiments on large scale datasets like ImageNet, or medium scale TinyImageNet, since SSL pretraining is often performed at this scale at least, and ii) convergence analysis for the proposed federated optimization objective under assumptions on task diversity, at least in a simplified setting where the SSL objective is convex. \n\nFor now, I will retain my score and will re-evaluate post discussion with other reviewers. I thank the authors again for their efforts to improve the paper."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3530/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700642877307,
                "cdate": 1700642877307,
                "tmdate": 1700642877307,
                "mdate": 1700642877307,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "V04wdogfd9",
                "forum": "JrmPG9ufKg",
                "replyto": "OxGnJIlmTZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3530/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer"
                    },
                    "comment": {
                        "value": "We would like to thank you for acknowledging the generality of our approach, the usefulness of our contribution to the federated SSL field and the additional feedback. Based on your suggestions, we uploaded a revision to our manuscript that includes some very preliminary (i.e., not fully converged and with only one random seed) results on unsupervised and semi-supervised training on TinyImagenet in the Appendix. The preliminary observations are: \n\n- In the unsupervised setting, the user-verification loss is generally beneficial for some models in the cases where we expect it to be \n- In the semi-supervised setting, the user-verification loss is still beneficial for the label skew. Adding the rotation non-i.i.d.-ness in this semi-supervised setting resulted in a very difficult problem where with 10% of the labels the convergence is very slow so we were not able to get meaningful performance with any method during the first 15k rounds. \n\nWe will continue running these experiments and will update, once we are able, our submission accordingly. Once again, we thank you for the positive feedback and for helping us to further improve our work."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3530/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700673782597,
                "cdate": 1700673782597,
                "tmdate": 1700674033091,
                "mdate": 1700674033091,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "boXb8B6D5H",
                "forum": "JrmPG9ufKg",
                "replyto": "V04wdogfd9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3530/Reviewer_JEx9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3530/Reviewer_JEx9"
                ],
                "content": {
                    "title": {
                        "value": "Response to Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for adding the TinyImagenet experiments in such a short time frame. Table 4 in B.1 suggests that Local SimCLR and Federated SimCLR perform similarly. Also, it is unclear if adding UV loss helps since it seems to hurt for all shift types on SimSiam (for both CIFAR-10 and tinyImagenet). \n\nI understand that these are initial results, but unfortunately in the current form do not seem to suggest that the proposed objective is helpful for datasets of the scale of TinyImagenet, at least in the unsupervised case. For the semi-supervised setting there are still some gains observed (though still marginal). So, I encourage authors to consider updating the final version with more statistically significant and carefully hyperparameter tuned performance measurements for their own method and the baselines.\n\nAt the same time, I believe that the reported marginal gains are OK, if the method has other benefits in the federated setting, like faster convergence/fewer communication rounds. Maybe I missed discussion on the latter in the paper, please let me know if that is the case."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3530/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700676538797,
                "cdate": 1700676538797,
                "tmdate": 1700676538797,
                "mdate": 1700676538797,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]