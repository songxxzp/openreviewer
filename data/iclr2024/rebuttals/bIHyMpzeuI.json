[
    {
        "title": "Sparse MoE as a New Treatment: Addressing Forgetting, Fitting, Learning Issues in Multi-Modal Multi-Task Learning"
    },
    {
        "review": {
            "id": "awCj9YIGMe",
            "forum": "bIHyMpzeuI",
            "replyto": "bIHyMpzeuI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5688/Reviewer_rXKX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5688/Reviewer_rXKX"
            ],
            "content": {
                "summary": {
                    "value": "This work tackles multi-modal multi-task learning with sparse mixture-of-experts. The authors identify three problems, namely modality forgetting, modality fitting and heterogeneous learning pace. The proposed method combines solutions for the three problems and shows competitive empirical performance against the SoTA."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This work identifies three important questions in multi-modal multi-task learning, namely forgetting, fitting and learning. Furthermore, the work proposes a framework that can solve the three problems simultaneously."
                },
                "weaknesses": {
                    "value": "1. The novelty of the work is limited. To solve the modality forgetting problem, the authors deploy load and importance balancing loss. To solve the other two problems, the authors use standard hyperparameter tuning methods. It is unclear which part is truly originated from the authors.\n\n2. The connection of the three problems is not organic. Although those three questions indeed exist in multi-modal multi-task learning, the authors do not point out how those problems are related. It seems that the authors tackle those three problems separately and in turn get a better result."
                },
                "questions": {
                    "value": "I am confused about the results in 5. What does 32N mean? Intuitively, increasing N should lead to good performance, and 32N is indeed the largest in the table, so it is not surprising that it has the best result. What is the message to convey here?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5688/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698376097612,
            "cdate": 1698376097612,
            "tmdate": 1699636594917,
            "mdate": 1699636594917,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Ij99QQQ6jV",
                "forum": "bIHyMpzeuI",
                "replyto": "awCj9YIGMe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to rXKX"
                    },
                    "comment": {
                        "value": "## **[Cons 1. The Novelty of The Work is Limited?]**\nWe respectfully disagree. We point out its novelty richness from three distinct aspects: \n1. [**SMoA Designs**] Our approach addresses the modality forgetting problem through the novel SM$^4$ structure, comprising SMoE and SMoA modules governed by modality-specific routing policies. **Note that the load and importance balancing loss is not designed for and can not solve the modality forgetting problem.** \n2. [**Automatic Expert Allocation**] We emphasize that AEA is NOT a standard hyperparameter tuning. While hyperparameters rely on human intervention, our approach automatically decides the expert number based on the model training dynamics. Therefore, in our case, the expert number is not a hyperparameter. \n3. [**Automatic Learning Pace for Different Modality**] The ALP automates the learning pace of each modality in a dynamic fashion, which is also not the standard hyperparameter tuning technique.\n## **[Cons 2. The Connection of The Three Problems is Not Organic?]**\nWe respectfully argue that these facets are intrinsically linked. Our proposal seeks to tackle the optimization problem in multi-modal multi-task learning, wherein the issues of gradient direction, optimization step size, and model capacity represent a comprehensive view of this overarching challenge. \nOur proposed SM$^4$ structure, featuring SMoA and SMoE modules alongside tailored training techniques, serves as a unified solution to alleviate these intertwined optimization challenges of multi-modal multi-task learning.\n## **[Cons 3. Confused About The Results in 5. What Does 32N Mean?]**\nFor the clarification of \u201c32N\u201d, we've revised the notation to N=4, N=8, N=16, and N=32. \nThe optimal number of experts in Mixture-of-Experts (MoEs) remains a subject of debate, with conflicting views on the ideal quantity. While several studies advocate that increased experts enhance performance, an excessive number may introduce redundancy or noise. Table A3 of [1] demonstrates that increasing the expert number brings extra performance will gradually diminish as the expert number goes up, and Table 11 in [2] shows the large expert number may decrease performance.\nTherefore, we investigate this further for multi-modal multi-task learning, and our findings suggest that larger expert pools consistently yield performance improvements.\n\n[1] Mod-Squad: Designing Mixture of Experts As Modular Multi-Task Learners\n\n[2] TUTEL: Adaptive Mixture-of-Experts at Scaler"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700638440177,
                "cdate": 1700638440177,
                "tmdate": 1700642555954,
                "mdate": 1700642555954,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "xbZReGW72A",
            "forum": "bIHyMpzeuI",
            "replyto": "bIHyMpzeuI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5688/Reviewer_cbhp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5688/Reviewer_cbhp"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes SM$^4$ for the Multi-Modal Multitask Learning problem. Particularly, SM$^4$ focuses on the challenges of i) modality forgetting; ii) modality fitting; and iii) heterogeneous learning pace. SM$^4$ introduces several advances to the vanilla Sparse Mixture of Experts (SMoE) techniques, including employing SMoE in both the dense and multi-head self attention layers, implementing the adaptive expert allocation and adaptive learning pace mechanisms. SM$^4$ show promising results compared to SOTA baselines on the MultiBench benchmarks. Authors also conducted various ablation studies to explore different characteristics of SM$^4$."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Multi-modal Multi-task learning is an important emerging problem in both research and industry. \n- The proposed method  achieved encouraging performance against SOTA baselines.\n- The experiments are quite comprehensive where the complexities and ablation studies are included. There are some exceptions that I will mention in the Weakness section.\n- Implementation is available."
                },
                "weaknesses": {
                    "value": "* My most critical concern of this work is the proposed method is quite ad-hoc and heuristic, especially in the AEA and ALP modules.\n    + **AEA**: First, the strategy introduces an additional hyper-parameter: $n$ - number of iterations to monitor the loss. It is unclear how sensitive the results will be with respect to $n$, and there are no guideline to select $n$. Looking at Algorithm 2, it seems like AEA employs a pre-training phase to decide $k_j$ for each modality independently. However, this does not take into account the interaction of multitask learning when the modalities are learned together. There are also no constraints to enforce that all experts are utilized, i.e. $\\sum_j k_j = N$. Lastly, in Figure 2-3, it is unclear why larger training-validation loss gap can lead to better generalization. When this gap is large, the model is either underfitted or overfitted rather than achieved better generalization. \n    + **ALP**: it is unclear what \"learning pace\" mean in this context, i.e. is it the learning rate or some components that directly influence the training trajectory?\n\n* Table 1 and 2 are quite unclear, what is the \"setting\" here referred to, is it the dataset size, or the model size? For example, in Table 2, SM$^4$ Medium - AV-MNIST has 1.23M params while the same method in the large setting has 0.76M params. The results of HighMMT seems to be quite different from the original, which requires further investigations.\n\n* Other suggestions: Figure 2 is not nice, please consider using subfigure, e.g. 2a, 2b, etc. instead of the current presentation."
                },
                "questions": {
                    "value": "- Clarifications regarding the AEA, ALP modules, and the settings in Table 1 & 2."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5688/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5688/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5688/Reviewer_cbhp"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5688/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698424671811,
            "cdate": 1698424671811,
            "tmdate": 1699636594824,
            "mdate": 1699636594824,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "rJ3Crr8P79",
                "forum": "bIHyMpzeuI",
                "replyto": "xbZReGW72A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to cbhp"
                    },
                    "comment": {
                        "value": "## **Summary**\n\nThank you for acknowledging the comprehensive of our experiments. Below are our responses addressing your concerns:\n\n## **[Cons 1. AEA Introduces an Additional Hyper-Parameter, Additional Pre-training Phase?]**\nThe AEA is not working on a pre-train phase; it is executed during our multi-modal multi-task learning, which takes into account multi-task learning, and the AEA stopped tuning expert numbers by itself, not a hyper-parameter. \nThe \u201cn\u201d in Algorithm 2 is actually the number of iterations within a single multi-modal multi-task training epoch. Therefore, we do not include additional hyper-parameters. \nAs we mentioned in Section 3.3, the load and importance balancing loss we used in routing networks make sure most experts will be utilized.\nMoreover, as shown in **T.1** our method doesn't increase training time significantly. \nThe above concerns have been included in our revision.\n\n**T.1** SM$^4$ and HighMMT multi-modal multi-task training time.\n| Model   | Small Setting (h) | Medium Setting (h) | Large Setting (h) |\n| ------- | ----------------- | ------------------ | ----------------- |\n| SM$^4$  | 33                | 18                 | 8                 |\n| HighMMT | 33                | 17.5               | 8                 |\n\n## **[Cons 2. Why Larger Training-Validation Loss Gap Can Lead to Better Generalization?]**\nAs mentioned in [1], the ``generalization gap\u2019\u2019 is defined as the difference between a model\u2019s performance on training data and its performance on unseen data drawn from the same distribution (e.g., the performance difference between training set and validation set). We adopt loss value to measure model performance and define the gap as the difference between training and validation loss. A larger generalization gap indicates that the model is not overfitted on the training set (i.e., higher training loss) but predicts well on the unseen data (i.e., lower validation loss), which indicates better generalization. \nWe've revised the definition of the \"generalization gap\" to align with formal definitions, clarifying the significance of a higher training-valid loss gap indicating better generalization performance.\n## **[Cons 3. What does \"learning pace\" Mean in This Context in ALP? ]**\nThe learning pace in ALP refers to the learning rate (or the optimization step size) of different modalities.\n## **[Cons 3. What is The \"setting\" in Table 1, 2 Refers to?]**\nThe \u201csetting\u201d here refers to the number of tasks that follow the HighMMT.\n## **[Cons 4. Model Parameter Number of Medium Setting is More Than The Large Setting.]**\nAlthough the large setting contains more tasks, more task number does not mean more parameters. As shown in Table 14 and Table 15 of our paper, the total number of experts in the medium setting is $32$, and we use $16$ experts in the large setting. Therefore, the number of model parameters in the medium setting is larger than in the large setting.\n## **[Cons 5. The Results of HighMMT Seem to be Quite Different From The Origine.]**\nOur implementation of HighMMT adheres to their official repo [HighMMT] (https://github.com/pliang279/HighMMT) and the default settings outlined in the HighMMT paper. For instance, our utilization of learning rates is as follows: 0.0005 for the small setting, 0.001 for the medium setting, and 0.0008 for the large setting.\nFurthermore, our supplementary materials contain the HighMMT official code and reproduction scripts, ensuring the exact replication of all hyper-parameters specified in the HighMMT paper.\nIf Reviewer cbhp could kindly point out another better re-implementation of HighMMT, we would like to follow it and update the configurations.\n## **[Cons 6. Expression Suggestion.]**\nWe've made adjustments according to your invaluable suggestions, including improvements to Figure 2 for clarity.\n\n[1] Predicting the Generalization Gap in Deep Networks with Margin Distributions."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700638343374,
                "cdate": 1700638343374,
                "tmdate": 1700642113080,
                "mdate": 1700642113080,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VyQcmFhhB8",
                "forum": "bIHyMpzeuI",
                "replyto": "y8culA0IHS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Reviewer_cbhp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Reviewer_cbhp"
                ],
                "content": {
                    "title": {
                        "value": "Additional Clarification"
                    },
                    "comment": {
                        "value": "Dear Authors\n\nThank you for the detailed feedback. May I seek your clarifications on the following items.\n\n- [Cons 1. AEA and Algorithm 2] It is still unclear to me how Algorithm 2 is executed. In Algorithm 2, there is a step to **train the model for 1 epoch** (comment at line loss_val_i = train(model)). So is it that Algorithm 2 outlines the training procedure for the whole system? Can the authors provide a rough pseudo-code to outline how $SM^4$ is trained, and where AEA and ALP is performed at which step?\n\n- [Cons 4. Small - Medium - Large Settings] It is unclear to me the naming convention used here. From Table 1,  the PUSH dataset used in both small and medium setting, some datasets in the small or medium settings are even larger than those in the large settings (e.g. V&T in small). From your response just now and in Table 2, the small models can have more parameters and more FLOPS than those in medium or large. So what is the size of the setting refer to in this experiment?"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700726592723,
                "cdate": 1700726592723,
                "tmdate": 1700726592723,
                "mdate": 1700726592723,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "I37s8kOX6H",
                "forum": "bIHyMpzeuI",
                "replyto": "xbZReGW72A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Reviewer_cbhp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Reviewer_cbhp"
                ],
                "content": {
                    "title": {
                        "value": "Training model step in AEA"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nIn Algorithm 2, there is a step that state $loss\\\\_val\\\\_i = train(model)$ with a comment **training model for 1 epoch**. So does this step reuse the losses in the pseudo-code that you outlined or it requires re-training the model for 1 epoch?\n\nIf we directly plug Algorithm 2 in the overall_training pseudo-code, I guess there might be a lot of nested training loops in the early stage because each AEA step also requires measuring the validation loss of each modality.\n\nAlgorithm 2 also instructs to continue to train the model for the remaining epochs (2nd last line). So I think it needs to be revised to integrate to the overall_training pseudo-code.\n\nLastly, this is a conceptual questions. Since the authors stated that the expert allocation to a modality is kept until end of training when the flag improved is set to true. This suggests that early stages of training will mostly perform a search to allocate experts to modalities and this configuration will remain fixed. Is it an optimal strategy? Because in early epochs, the experts may not learn well enough and maybe it is beneficial to \"reallocate\" the experts once they have learned good representations. One naive strategy could be perform a reallocation (re-run AEA) after some fixed epochs."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700731667451,
                "cdate": 1700731667451,
                "tmdate": 1700731694693,
                "mdate": 1700731694693,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WsxdHTXIZF",
                "forum": "bIHyMpzeuI",
                "replyto": "xbZReGW72A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer cbhp about the AEA"
                    },
                    "comment": {
                        "value": "> Does this step reuse the losses \"loss_val_i\" in the pseudo-code?\n\nYes, this step reuses the losses in the pseudo-code. \n\n> Revise the Algorithm 2\nThanks to the suggestion, we revised the Algorithm for integrating the overall_training pseudo-code and modified overall_training pseudo-code below:\n```\ndef adaptive_expert_allocation(model, loss):\n    for modality in modality_set:\n\t    # If the modality is signed improved, skip this modality\n\t    if check(modality):\n\t\t    continue\n\t\tn_experts = modality_topk[modality]\n        loss_val = loss[valid][modality]\n\t\t# if the expert number of this modality is increased last time\n\t\tif increase_expert(modality):\n\t\t\tif loss_decrease(loss_val):\n\t\t\t\timproved = True\n\t\telse:\n\t\t\t# if the valid loss does not decrease\n\t\t\tif loss_decrease(loss_val): \n\t\t\t\tif not improved:\n\t\t\t\t\tSign this modality as improved\n\t\t\t\t\tmodality_topk[modality] = n_experts - 1\n\t\t\t\telse:\n\t\t\t\t\tmodality_topk[modality] = n_experts + 1\n\t\t\t\t\timproved = False\n    return modality_topk\n```\n```python\ndef overall_training(modality_topk, modality_weights):\n\tfor i in range(max_epochs):\n\t\t# training 1 epoch\n\t\t# losses include the average valid loss of all modalities in this epoch\n\t\t# routing_entropy includes the average entropy of all modalities in this epoch\n\t\tval_losses, routing_entropy = train(model, modality_topk, modality_weights)\n\t\t\n\t\t# setting topk of all modalities\n\t\t# if the monitoring of specific modality is ended, AEA will skip to tuning the topk of specific modality\n\t\tmodality_topk = AEA(model, val_losses)\n\t\t\n\t\tmodality_weights = ALP(model, routing_entropy)\n```\n\n> Is it an optimal strategy?\n\nThis problem needs further investigation.\nReallocation is a potential solution to further improve the performance of SM$^4$. The problem is this will involve additional hyper-parameters to decide when to reallocate experts which makes the training more complex. However, we think this is a remarkably interesting and important problem, how to decide the optimal model capacity of each modality during training, and expect to investigate this further in our future work.\n\nThanks for your insightful comments!"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735020394,
                "cdate": 1700735020394,
                "tmdate": 1700735058274,
                "mdate": 1700735058274,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QT6YQd0Njc",
            "forum": "bIHyMpzeuI",
            "replyto": "bIHyMpzeuI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5688/Reviewer_mdyv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5688/Reviewer_mdyv"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose a novel framework, SM^4, based on sparse Mixture-of-Exports and designed for multi-modal multi-task learning. Notably, the algorithms address three 3 critical issues in the field: modality forgetting, overfitting to simple modalities, and unaligned learning paces in multi-tasks. The main idea is to disentangle information and adjust model capacities by enforcing sparsity and employing attention models. In the experiments, SM^4 shows the best performance, greatly reduced computational cost, and the ability of mitigating the 3 pain points."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. This work is well-motivated and addresses important issues in multi-modal and multi-task learning via reasonable algorithms. The evaluations and analyses are also detailed, confirming the impact of this work.\n2. The conducted analyses not only prove the effectiveness of the framework SM^4 but also establish solid evaluation protocol for follow-up works.\n3. The writing is impressive. The authors do a great job on presenting the complicated settings and methods, making the article both informative and easy to follow. Also, the experiment settings are thoroughly reported."
                },
                "weaknesses": {
                    "value": "My concerns are mostly about the experiments.\n1. The authors employ MultiBench for evaluation, while the metrics of robustness and training cost are ignored. This raises 2 concerns:\n* a. Without checking robustness, it is unclear if the trained model is robust to missing or noisy modalities, which shall be an important criterion in multimodal learning.\n* b. The trade-off between training cost and model performance of SM^4 is unclear. In particular, deciding number of experts for each modality seems to be time-consuming. I suppose checking the trade-off and comparing SM^4 with simple methods such as early/late can help measuring the practical value of this work more precisely.\n2. The reported performance of MultiBench models in Table 2 may be overly simplified. As the complexities of the MultiBench models greatly vary, simply reporting the aggregated performance (e.g., the range) makes it difficult to position SM^4 in this regard. Also, the dependencies between efficiency and performance are ignored, similar to the issue in weakness 1.b. A candidate method could be the 2D visualization adopted by MultiBench and is used for studying trade-offs.\n3. Minor typo: YR-FUNNY in Table 1."
                },
                "questions": {
                    "value": "1. Following the weaknesses, I am wondering if the authors consider reporting the training cost, robustness, and the trade-offs?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5688/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5688/Reviewer_mdyv",
                        "ICLR.cc/2024/Conference/Submission5688/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5688/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698762611510,
            "cdate": 1698762611510,
            "tmdate": 1700718330999,
            "mdate": 1700718330999,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PyP95CpXQy",
                "forum": "bIHyMpzeuI",
                "replyto": "QT6YQd0Njc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to mdyv 1/3"
                    },
                    "comment": {
                        "value": "## **Summary**\n\nWe are glad that reviewer mdyv appreciates the comments on our writing as \u201cimpressive\u201d, \u201cinformative\u201d, and \u201ceasy to follow\u201d, our proposal as \u201cwell-motivated and addresses important issues\u201d, and our experiments as \u201cdetailed\u201d and \u201csolid\u201d. To address reviewer mdyv\u2019s questions, we provide pointwise responses below.\n\n## **[Cons 1. Without Checking Robustness.]**\n\nWe conduct extra experiments to examine the robustness of SM$^4$ to missing modalities. Due to the limited time in the rebuttal period, we will add the robustness evaluation of noisy modalities in our final version.\nAs shown in Table **T1**, we assess SM$^4$ and HighMMT with the model UR-FUNNY under three missing scenarios of missing text, video, and audio, respectively. Our results imply that SM$^4$ has a relatively better robustness towards missing modalities.\n\n**T.1** The robustness comparison between SM$^4$ and highMMT. We show the $\\delta$ value, which is defined as the value of performance drop when missing one modality. A smaller $\\delta$ value indicates better robustness against the modality missing.\n\n| UR-FUNNY| Missing text | Missing video | Missing audio |\n| -------------------| ------------ | ------------- | ------------- |\n| SM$^4$ | $1.16$ | $4.77$ | $0.92$ |\n|HighMMT| 8.22 | 10.30 | 6.62 |\n\n| MOSEI| Missing image | Missing audio| Missing text |\n| -------------------| ------------ | ------------- | ------------- |\n| SM$^4$ | $0.39$| $0.82$ | $0.92$|\n|HighMMT| 10.45 | 17.38 | 12.23 |\n\n| MIMIC | Missing table| Missing timeseries| \n| -------------------| ------------ | ------------- | \n| SM$^4$ | $8.71$| 17.99 | \n|HighMMT| 9.72 | $11.67$ | \n\n| AV-MNIST| Missing image| Missing audio| \n| -------------------| ------------ | ------------- | \n| SM$^4$ | 60.6| $13.60$ | \n|HighMMT| $55.85$ | 36.27 | \n\n## **[Cons 2. The Trade-off Between Training Cost and Model Performance of SM^4 is Unclear.]**\n\nThanks for the great point.\n- The total number of training epochs for SM$^4$ and other baselines are the same. The procedure of deciding the number of experts for each modality does NOT require extra training epochs. Specifically, both HighMMT and SM$^4$ use $100, 100, 100$ training epochs for the small, medium, and large settings, respectively. \n- To further convince review mdyv, we measure the training time of SM$^4$ and HighMMT in the same device (i.e., single NVIDIA A30 GPU). Our results demonstrate that SM$^4$ uses **similar training costs** to reach consistently enhanced performance, as evidenced in Table **T.2**. It indicates an improved trade-off between training cost and model performance.\n\n**T.2** SM$^4$ and HighMMT multi-modal multi-task training time.\n| Model   | Small Setting (h) | Medium Setting (h) | Large Setting (h) |\n| ------- | ----------------- | ------------------ | ----------------- |\n| SM$^4$  | 33                | 18                 | 8                 |\n| HighMMT | 33                | 17.5               | 8                 |\n\n\n## **[Cons 3. The Reported Performance of MultiBench Models in Table 2 Maybe Overly Simplified.]**\nTo address the concern regarding the detailed performance of MultiBench models, we included a more comprehensive performance report below (Table **T.3**, **T.4**, **T.5**, and **T.6** below) and in our revision (Table 10 (page 22) in our revision). \n\nAlso, the typo in Table 1 has been corrected in our revision."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700638184212,
                "cdate": 1700638184212,
                "tmdate": 1700642001851,
                "mdate": 1700642001851,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pv14D99D0M",
                "forum": "bIHyMpzeuI",
                "replyto": "QT6YQd0Njc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to mdyv 2/3"
                    },
                    "comment": {
                        "value": "**T3**. Detailed performance, parameter usage, and FLOPS of multi-modal learning method on MultiBench benchmark. For the ''FLOPS(G)'', ''-'' indicates the MultiBench does not provide official implementation. Notably, the empty FLOPS of the MultiBench Model (MFAS)'' is due to the FLOPS of ''MFAS'' being dynamic during training. For each dataset, we choose multi-modal models with the best/worst performance and multi-modal models with the largest/smallest parameter numbers, respectively.\n| Method                             | Dataset           | Performance | \\# Parameter (M) | FLOPS (G) | \n| ---------------------------------- | ----------------- | ----------- | ---------------- | --------- |\n| MultiBench Models (TF-LSTM)        | PUSH $\\downarrow$ | 0.574       | 23.5             | 25.11     |    \n| MultiBench Models (LF-LSTM)        | PUSH $\\downarrow$ | $0.290$       | $1.90$             | $14.07$     |     \n| MultiBench Models (MULT)             | PUSH $\\downarrow$ | 0.402       | 14.6             | 19.20     |    \n| MultiBench Models (LRTF)             | V\\&T              | 93.3        | $1.09 $            | $5.20$      |  \n| MultiBench Models (LF)             | V\\&T              | $93.6$        | 1.20             | $5.20$      |    \n| MultiBench Models (RefNet)         | V\\&T              | 93.5        | 135              | $-$       |     \n| MultiBench Models (TF)             | ENRICO            | 46.6        | $19.3$             | 314.13    |   \n| MultiBench Models (GradBlend)      | ENRICO            | $51.0$        | $19.3$             | 314.13    |  \n| MultiBench Models (RefNet)         | ENRICO            | 44.4        | 25.7             | $2.67$      |\n| MultiBench Models (GradBlend)      | AV-MNIST          | 68.5        | 0.29             | 0.50      |   \n| MultiBench Models (MFAS)           | AV-MNIST          | $72.8$        | $0.14$             | $-$       |  \n| MultiBench Models (RefNet)         | AV-MNIST          | 70.9        | 14.1             | $0.25$      |  \n| MultiBench Models (EF-GRU)         | UR-FUNNY          | 60.2        | 3.58             | 3.13      |  \n| MultiBench Models (MULT)           | UR-FUNNY          | $66.7$        | 2.38             | 3.37      | \n| MultiBench Models (MCTN)           | UR-FUNNY          | 63.2        | $0.19$             | $0.17$      |  \n| MultiBench Models (TF)             | UR-FUNNY          | 61.2        | 12.2             | 2.67      | \n| MultiBench Models (MCTN)           | MOSEI             | 76.4        | $0.19$             | $0.15$      |   \n| MultiBench Models (MULT)           | MOSEI             | $82.1$        | 4.75             | 3.35      | \n| MultiBench Models (LF-Transformer) | MOSEI             | 80.6        | 31.5             | 21.6      |   \n| MultiBench Models (MI-Matrix)      | MIMIC             | 67.9        | 0.801            | $0.005 $    |   \n| MultiBench Models (LF)             | MIMIC             | $68.9$       | 0.034            | $0.005$     |   \n| MultiBench Models (LRTF)           | MIMIC             | 68.5        | $0.008$            | $0.005$          |  \n\n**T4**. Performance, parameter usage, and FLOP of our model, and HighMMT in the small setting.\n| Method  | Dataset           | Performance | \\# Parameter (M) | FLOPS (G) |\n| ------- | ----------------- | ----------- | ---------------- | --------- |\n| HighMMT | PUSH $\\downarrow$ | 0.445       | 0.89             | 5.14      |\n| HighMMT | V\\&T              | 96.10       | 0.85             | 32.48     |\n| SM$^4$  | PUSH $\\downarrow$ | $0.331$       |$0.27 $            | $2.59$      |\n| SM$^4$  | V\\&T              | $96.33$       | $0.25$             | $17.38$          |\n\n**T5**. Performance, parameter usage, and FLOP of our model, and HighMMT in the medium setting.\n| Method  | Dataset           | Performance | \\# Parameter (M) | FLOPS (G) |\n| ------- | ----------------- | ----------- | ---------------- | --------- |\n| HighMMT | ENRICO            | 53.10       | $0.58 $            | 79.48     |\n| HighMMT | PUSH $\\downarrow$ | 0.600       | $0.63$             | 21.60     |\n| HighMMT | AV-MNIST          | 68.48       | $0.52 $            | 0.95      |\n| SM$^4$  | ENRICO            | $71.58 $      | 1.23             | $1.10$      |\n| SM$^4$  | PUSH $\\downarrow$ |$ 0.475$       | 1.25             | $2.33$      |\n| SM$^4$  | AV-MNIST          | $71.86$       | 1.23             | $0.41$          |"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700640861064,
                "cdate": 1700640861064,
                "tmdate": 1700642510952,
                "mdate": 1700642510952,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EGJYgLX5Ib",
                "forum": "bIHyMpzeuI",
                "replyto": "QT6YQd0Njc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to mdyv 3/3"
                    },
                    "comment": {
                        "value": "**T6**. Performance, parameter usage, and FLOP of our model, and HighMMT in the large setting.\n| Method  | Dataset  | Performance | \\# Parameter (M) | FLOPS (G) |\n| ------- | -------- | ----------- | ---------------- | --------- |\n| HighMMT | UR-FUNNY | 62.00       | $0.52$             | 1.51      |\n| HighMMT | MOSEI    | 78.40       | $0.52$             | 1.65      |\n| HighMMT | MIMIC    | 65.60       | $0.52$             | 0.67      |\n| HighMMT | AV-MNIST | 70.60       | $0.52$             | 0.95      |\n| SM$^4$  | UR-FUNNY | $64.24$       | 0.76             | $0.38$      |\n| SM$^4$  | MOSEI    | $79.47$       | 0.76             | $0.53$      |\n| SM$^4$  | MIMIC    | $67.91$       | 0.76            | $0.15$      |\n| SM$^4$  | AV-MNIST | $71.05$       | 0.76             | $0.43$          |"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700640887374,
                "cdate": 1700640887374,
                "tmdate": 1700642062638,
                "mdate": 1700642062638,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xOFYRqfHUg",
                "forum": "bIHyMpzeuI",
                "replyto": "2dIwZfE6vj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Reviewer_mdyv"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Reviewer_mdyv"
                ],
                "content": {
                    "comment": {
                        "value": "I appreciate the authors' detailed responses and agree the responses address my concerns. I have adjusted the score accordingly. Nevertheless, I would like to echo the concern from reviewer m8oX and cbhp regarding the performance gap of HighMMT between Liang et al., 2022 and this work. I have read the authors' response about this issue, while I believe some discussion or at least an acknowledgement needs to be included in this manuscript."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700719200283,
                "cdate": 1700719200283,
                "tmdate": 1700719200283,
                "mdate": 1700719200283,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WPBrPUmvJD",
            "forum": "bIHyMpzeuI",
            "replyto": "bIHyMpzeuI",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5688/Reviewer_m8oX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5688/Reviewer_m8oX"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an approach that incorporates routing in the training of general-purpose models for multimodal and multi-task learning to address heterogeneity across modalities and tasks. The overall idea is relatively straightforward. A subset of datasets from MultiBench were used in their evaluation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "+ The performance of the proposed method on included datasets seems impressive based on numbers reported in the paper.\n+ Solid study on the behavior of the proposed method. Plots in Figure 2 are good illustrations, right to the points."
                },
                "weaknesses": {
                    "value": "- The description of proposed method is very difficult to follow. I have no idea how the method works from just reading the paper. For example, it does not clearly state what are exactly the experts and where they come from. I cannot get much from Figure 1. It seems that experts are grouped. But I was not able to find a discussion why/how they are grouped. \n\n- The motivation of ALP is not clear to me. Does unstable routing policy just mean changes in the policy across iterations? Such change does not necessarily link to the routing distribution entropy.  \n\n- Comparing Table 2 with Table 3 of Liang, et al., 2022, there is large difference in the performance of HighMMT on same datasets. A discussion of where the discrepancy coming from is needed."
                },
                "questions": {
                    "value": "- What are the criteria/considerations used in selecting datasets/tasks for evaluation? There are many other tasks and modalities in MultiBench. How the proposed method works for those? \n\nIn addition, refer to the list of weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5688/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698838667934,
            "cdate": 1698838667934,
            "tmdate": 1699636594562,
            "mdate": 1699636594562,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "LI64Eke7zy",
                "forum": "bIHyMpzeuI",
                "replyto": "WPBrPUmvJD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5688/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to m8oX"
                    },
                    "comment": {
                        "value": "## **[Summary]**\nAcknowledgments to Reviewer m8oX for recognizing our work as \"impressive\" and appreciating the clarity of our Figure 2, outlining its directness. We value the constructive feedback provided, which is instrumental in refining our paper. To address reviewer m8oX's queries, we present specific responses below:\n\n## **[Cons 1. What are Exactly the Experts, and Where do They Come From? Are They Grouped? .]**\n\nThe experts are duplicated multi-layer perceptrons (MLP). Specifically, in SMoE, the experts are duplicated from the original feedforward networks. The experts in SMoA are duplicated from the query, key, and value MLPs, respectfully. \n\nIn order to distinguish experts from different sources, we name them as different expert groups. **Experts are grouped by the nature of where they are duplicated from.**\n\nThe above clarifications have been included in our revisions. \n\n## **[Cons 2. Motivation of ALP. How do the Policy Changes Link to the Routing Distribution Entropy?]**\n\n1. *What does an unstable policy mean?*\n\nAn unstable routing policy means the changes in the policy across iterations.\n\n2. *How do such changes link to routing distribution entropy?*\n\nThey are linked. We measure the routing distribution of each expert across the iterations and then calculate an averaged entropy across all the experts. Therefore, the entropy here directly measures the stability of the routing policy over the training iterations. For example, a high entropy indicates that expert routing is quite converged and stable.\n\n3. *Motivation of ALP.*\n\nThe motivation of adaptive learning pace (ALP) is to align different learning paces between modalities, aiming to synchronize the optimization of multiple objectives. To be specific, from Figure 2(d), the stability of modality-specific routing seems to reveal the convergence of modality-specific training, serving as a good guidance to decay its learning rate.\nThe above clarifications have been included in our revisions.\n\n## **[Cons 3. Performance Difference of HighMMT.]**\n\nThanks for pointing it out.\n- We highlight that our performance of HighMMT is produced with the official implementation from HighMMT\u2019s repository (https://github.com/pliang279/HighMMT). We strictly follow the default configurations reported in their paper, as shown in Tables 8, 9, and 10. For example, we use learning rates of 0.0005, 0.001, and 0.0008 for the small, medium, and large settings, respectively.  \n- Additionally, our supplementary materials have included the HighMMT code and reproduction scripts, maintaining exact replication of their hyper-parameter settings.\n- If Reviewer m8oX could kindly point out another better re-implementation of HighMMT, we would like to follow it and update the configurations.\n\n## **[Cons 4. Datasets/Tasks Selection.]**\n\nThe selection of our three multi-modal task groups follows HighMMT\u2019s standards. \n- The small setting encompasses similar research areas with varying modality inputs;\n- The medium setting spans three domains featuring different modalities;\n- The large setting involves three domains incorporating diverse modalities.\n\nYes, our proposed method is a general multi-modal, multi-task pipeline, which can be leveraged for various combinations of tasks and modalities. **In our submission, we follow the standard multi-modal multi-task settings from the HighMMT paper**. That is, HighMMT/Multibench currently only provides the default hyper-parameter configurations for the small, medium, and large settings, which are adopted in our paper as the representative baseline. In our future works, we will examine our methods for extra combinations of tasks and modalities."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5688/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700634719063,
                "cdate": 1700634719063,
                "tmdate": 1700640992260,
                "mdate": 1700640992260,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]