[
    {
        "title": "Contractive Systems Improve Graph Neural Networks Against Adversarial Attacks"
    },
    {
        "review": {
            "id": "yCUN5xk2M8",
            "forum": "7FHrZuKogW",
            "replyto": "7FHrZuKogW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5774/Reviewer_mRqu"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5774/Reviewer_mRqu"
            ],
            "content": {
                "summary": {
                    "value": "A neural diffusion GNN model coupling the evolution of both node features and graph adjacency matrix is proposed. Analytical studies on the contractive properties of this model across model layers are provided."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Using a diffusion process to model the joint evolution of node features and graph adjacency matrix seems to be novel. Numerical experiments indicate that such an approach can provide robustness against adversarial attacks."
                },
                "weaknesses": {
                    "value": "1. The analytical results show contractive properties of the feature/adjacency matrix evolution across model layers for a given input. I am unclear how this proves robustness of the GNN model to input or structure perturbation. \n\n1. Missing comparison to the work \u201cOn the robustness of graph neural diffusion to topology perturbations,\u201d NeurIPS 2022. What are the additional things we learn from this current paper? The results in the NeurIPS 2022 paper relate explicitly to robustness w.r.t. input perturbations."
                },
                "questions": {
                    "value": "1. Please give more information on the attack type. Is it inductive, modification/injection, whitebox/blackbox?  \n\n1. What is the adaptive attack procedure? It seems the paper simply uses unit tests from Mujkanovic et al. (2022). These cannot be considered to be adaptive attacks for the proposed model. Mujkanovic et al. (2022) has emphasized this point too: \"we cannot stress enough that this collection does not replace a properly developed adaptive attack\".\n\n1. GNNGuard is mentioned but not used as baseline in Table 1. \n\n1. The attacks used do not seem strong enough (I am unclear of their settings as well). E.g., in Table 1, even under 25% attack, GCN still has >40% accuracy. In other related papers on GNN adversarial attacks (e.g., Fig. 1 of Mujkanovic et al. (2022)), usually GCN would have performed much worse with accuracies below 20-30%."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697789471770,
            "cdate": 1697789471770,
            "tmdate": 1699636606794,
            "mdate": 1699636606794,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "quSzSsBhED",
                "forum": "7FHrZuKogW",
                "replyto": "yCUN5xk2M8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 1)"
                    },
                    "comment": {
                        "value": "We sincerely appreciate the review comments regarding the novelty of our work and its performance, stating that \u2018Using a diffusion process to model the joint evolution of node features and graph adjacency matrix seems to be novel.\u2019 and that it provides \u2018robustness against adversarial attacks\u2019. We thank the reviewer for the insightful comments and questions, which we address below. In our revised paper, our responses to your queries are marked in **Orange**.\n\n\n**Regarding why contractivity improves robustness**: As defined in our original submission (please see Equations (10) and (11)), contractivity leads to the reduction of the sensitivity of network outputs to input perturbations. Because graph attacks are based on input perturbations such as changes to the node features or adjacency matrix, and our CSGNN encapsulates an inductive bias in the form of a contractive system, it learns to fortify itself against graph attacks (i.e., perturbations), thereby improving the robustness of the model. More explicitly, even without the knowledge of the clean adjacency and feature matrices, having a contractive and stable system allows the outputs one gets with perturbed inputs to be close to the one would get feeding in the clean inputs. Indeed, this understanding is also empirically validated throughout our extensive experiments in Section 4. We discuss this point in our Preliminaries section (Section 3), and have now added an appendix section (Appendix A), to provide a better background on contractive systems.\n\n**Regarding  \"On the robustness of graph neural diffusion to topology perturbations\" (NeurIPS 2022)**: We thank you for this important reference, which we now cite and discuss in our revised paper. The most crucial difference is the underlying method, novelty, and the performance of the methods on various benchmarks. While the mentioned paper also takes inspiration from neural diffusion GNNs, it utilizes **only node feature update neural ODEs**. On the contrary, our CSGNN offers a novel **coupled neural ODE that learns both node features and adjacency matrix updates**. This addition is proven to provide improved performance, as reported in the paragraph \u201cLearning contractive adjacency dynamics is beneficial\u201d of Appendix J (of the revised version of the manuscript). As 3 of 4 of the reviewers noted, this is a novel approach.\n\n**Regarding attack type:** We follow the experimental settings in Pro-GNN, which considers inductive poisoning attacks using both white (metattack, nettack) and black box (random) configurations. In our original submission, we mentioned that in our experimental section, in Section 5.2. We have also revised our Introduction to highlight that, following your question.\n\n**Regarding adaptive attack**: The reviewer is correct that we use the \u2018unit-tests\u2019 from Mujkanovic et al. (2022)., as stated in our original submission. As we discuss in Section 5.2, under the paragraph \u201cRobustness to Adaptive Attacks\u201d, the unit-tests are adaptive in that a different attack can be utilized for a different attack strength. We also note regarding the statement in Mujkanovic et al. (2022), \u201cwe cannot stress enough that this collection does not replace a properly developed adaptive attack\u201d, that our goal is not to propose new attacks based on our method but rather to design a defensive mechanism. Thus, our motivation for using those useful unit tests was to be able to compare with recent baselines on challenging test cases, as shown in Figures 4 and 7. To address your concern, we have revised our text to reflect this discussion. Please see our changes in the revised paper, marked in Orange."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151727649,
                "cdate": 1700151727649,
                "tmdate": 1700152342221,
                "mdate": 1700152342221,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "nLsB3o7eO7",
                "forum": "7FHrZuKogW",
                "replyto": "yCUN5xk2M8",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 2)"
                    },
                    "comment": {
                        "value": "**Regarding GNNGuard in Table 1**: In our experimental results section, we seek to provide a comprehensive comparison with the latest methods. We did not include GNNGuard in Table 1 because there were no reported results on Metattack using a variable % of attack in the original paper. However, to address the reviewer's question, we provide a comparison below with GNNGuard on Metattack with a 20% perturbation rate and 5 targeted nodes using Nettack, as reported in GNNGuard, both on Cora and on Citeseer.\n\n| Cora |              |                                             |                                           |\n|------|--------------|---------------------------------------------|-------------------------------------------|\n|      | Method       | Accuracy on Metattack 20% perturbation rate | Accuracy on Nettack with 5 targeted nodes |\n|      | GNNGuard     | 72.2                                        | 77.5                                      |\n|      | CSGNN (Ours) | 77.4                                   | 83.2                                  |\n\n\n| Citeseer |              |                                             |                                           |\n|----------|--------------|---------------------------------------------|-------------------------------------------|\n|          | Method       | Accuracy on Metattack 20% perturbation rate | Accuracy on Nettack with 5 targeted nodes |\n|          | GNNGuard     | 71.1                                        | 86.5                                      |\n|          | CSGNN (Ours) | 73.0                                        | 84.6                                      |\n\n\nThose results further highlight the significance of our method, given that in most cases, CSGNN outperforms GNNGuard. We have added those results to our revised paper marked in Orange, in the paragraph titled \u201cComparison with GNNGuard\u201d of Appendix J.\n\n**Regarding the strength of the attack**: In our experimental section, we provide results using various settings that follow those presented in Pro-GNN and Mujkanovic et al. (2022). This approach allows us to provide an accurate and comprehensive picture of the current state of GNN defense mechanisms. Furthermore, we would like to kindly note that we include recent tests from  Mujkanovic et al. (2022), that indeed seem to be stronger. Still, even under this harder attack, our CSGNN achieves improved results compared to other methods, as can be seen in Figures 4 and 7."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151785363,
                "cdate": 1700151785363,
                "tmdate": 1700151785363,
                "mdate": 1700151785363,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JWb53kcbWM",
                "forum": "7FHrZuKogW",
                "replyto": "quSzSsBhED",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Reviewer_mRqu"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewer_mRqu"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the clarifications. \n\nPerhaps, I was not specific enough in my initial comment. In eq. (10) of Theorem 2, $\\mathbf{A}$ is fixed but clearly $\\Psi_{X_l}^{h_l}$ is impacted by $\\mathbf{A}*$. You cannot apply eq. (11) here as $\\Psi_{X_l}^{h_l}$ and $\\Psi_{Y_l}^{h_l}$ are two different functions. Therefore, I am unclear how the **individual** contractivity of feature/adjacency matrix evolution imply robustness. \n\nSince unit tests from Mujkanovic et al. (2022) do not imply robustness against adaptive attacks for this model, I don't think the authors should continue to claim that in the paper. This is misleading for the readers. \n\nThere are many other adversarial attacks like injection attacks. This paper only tests on modification attacks using Metattack and NETTACK. If the paper's focus is only on modification attacks, one can argue that the paper title and abstract do not reflect the technical content. Moreover, what is the motivation to focus only on modification attacks? Are these more important in practice?"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700192133089,
                "cdate": 1700192133089,
                "tmdate": 1700192133089,
                "mdate": 1700192133089,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "EixjoGhKn8",
                "forum": "7FHrZuKogW",
                "replyto": "Sq4IqPARzz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Reviewer_mRqu"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewer_mRqu"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for all the clarifications. While the claimed novelty of this paper is the coupled feature and adjacency matrix update model, the result only shows that updates to the adjacency matrix are stable to perturbations. More work needs to be done. I am therefore keeping my score."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631809978,
                "cdate": 1700631809978,
                "tmdate": 1700631809978,
                "mdate": 1700631809978,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YzQHti11K5",
            "forum": "7FHrZuKogW",
            "replyto": "7FHrZuKogW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5774/Reviewer_SPJa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5774/Reviewer_SPJa"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce an approach to enhance the robustness of GNNs against adversarial perturbations by leveraging the concept of contractive dynamical systems."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper presents a novel architecture, CSGNN, that innovatively integrates the principles of contractive dynamical systems to enhance the robustness of GNNs against adversarial poisoning attacks.\n2. The simultaneous evolution of node features and the adjacency matrix is a distinctive feature that can potentially offer intrinsic resistance to adversarial perturbations.\n3. The authors fortify their claims with a rigorous theoretical analysis."
                },
                "weaknesses": {
                    "value": "1. Inadequate Literature Review: The paper's glaring omission of pivotal related works is concerning. The idea of enhancing NN robustness via dynamical systems isn't novel, even within the GNN realm. The authors' failure to acknowledge, let alone differentiate their work from seminal papers [1][2][3][4][5], is a significant oversight.\n    \n\n2. Lack of Clear Motivation: The paper's design choices seem arbitrary, with many equations appearing devoid of clear rationale. For example:\n>The reasoning behind assuming a piecewise constant function in eq(6).\n>The ambiguity surrounding the gradient operator of $A$ in eq(8).\n>The seemingly ad-hoc design of eq(8) and its alignment with the paper's theorems.\n>The choice to enforce symmetry on $\\tilde{\\mathbf{K}}_l$.\n>The intricate design of the adjacency matrix update in eq(14) lacks clear justification.\nThe paper should not be a mere mathematical exercise; it should be accessible and provide clear motivations for design choices.\n\n3. Reproducibility Concerns: The absence of code hinders the verification of the paper's claims. Critical aspects, such as adherence to the adjacency update mechanism in eq(14) and the positive definiteness of $\\tilde{\\mathbf{K}}_l$, remain unchecked.\n\n4. Computational Overheads: The complete matrix representation in eq(14) suggests significant computational demands. The authors should elucidate the memory and time overheads.\n\n5. Narrow Attack Scope:\nThe paper exclusively focuses on poisoning attacks. Is this indicative of the theorems being specifically tailored for such attacks? The theorem statements, including their assumptions and conclusions, don't seem to impose such constraints. What is the rationale behind primarily considering poisoning attacks? Reference [6] suggests that injection attacks pose a greater threat than poisoning attacks. The authors should address these concerns and expand their experiments to include injection attacks, irrespective of the model's performance against them.\nAdditionally, the inclusion of black-box attacks in the evaluation is necessary.\nThe model exhibits suboptimal performance on the Pubmed dataset. Does this suggest that the efficacy of your models and theorems is dataset-dependent? It would be insightful to understand how the model fares on different datasets, especially those characterized by heterophily.\n\n6. Lack of Large-Scale Graph Datasets:\nThe current evaluation is limited to smaller datasets such as Cora, Citesser, and Polblogs. It would be beneficial to see how the model performs on more extensive, widely-recognized datasets like the ogbn series.\n\n\nOverall, I believe this paper has promise. However, in its present state, I cannot endorse its acceptance. I strongly urge the authors to undertake a thorough revision and consider resubmitting to an upcoming top-tier machine learning conference.\n\n[1] Zakwan, Muhammad, Liang Xu, and Giancarlo Ferrari-Trecate. \"Robust classification using contractive Hamiltonian neural ODEs.\" IEEE Control Systems Letters 7 (2022): 145-150.\n\n[2] Kang, Qiyu, Yang Song, Qinxu Ding, and Wee Peng Tay. \"Stable neural ode with lyapunov-stable equilibrium points for defending against adversarial attacks.\" Advances in Neural Information Processing Systems 34 (2021): 14925-14937.\n\n[3] Huang, Yujia, Ivan Dario Jimenez Rodriguez, Huan Zhang, Yuanyuan Shi, and Yisong Yue. \"Fi-ode: Certified and robust forward invariance in neural odes.\" arXiv preprint arXiv:2210.16940 (2022).\n\n[4] Yang, Runing, Ruoxi Jia, Xiangyu Zhang, and Ming Jin. \"Certifiably Robust Neural ODE with Learning-based Barrier Function.\" IEEE Control Systems Letters (2023).\n\n[5] Song, Yang, Qiyu Kang, Sijie Wang, Kai Zhao, and Wee Peng Tay. \"On the robustness of graph neural diffusion to topology perturbations.\" Advances in Neural Information Processing Systems 35 (2022): 6384-6396.\n\n[6] Chen, Yongqiang, Han Yang, Yonggang Zhang, Kaili Ma, Tongliang Liu, Bo Han, and James Cheng. \"Understanding and improving graph injection attack by promoting unnoticeability.\" arXiv preprint arXiv:2202.08057 (2022)."
                },
                "questions": {
                    "value": "NA"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698760379714,
            "cdate": 1698760379714,
            "tmdate": 1699636606678,
            "mdate": 1699636606678,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vziEEhTrMS",
                "forum": "7FHrZuKogW",
                "replyto": "YzQHti11K5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the thorough and detailed feedback. The reviewer says that our paper proposes  \u2018a novel architecture, CSGNN, that innovatively integrates the principles of contractive dynamical systems to enhance the robustness of GNNs against adversarial poisoning attacks\u2019 and that \u2018The authors fortify their claims with a rigorous theoretical analysis.\u2019 We thank you for acknowledging the novelty of our work.  In our revised paper, our responses to your queries are marked in **Magenta**.\n\n\n\n\nThe reviewer also suggests several important points to improve our paper. We now address them individually. Our changes to the submission are marked in Magenta. We hope that the reviewer is satisfied with our updated paper and responses below and that they will consider raising their score.  We are also happy to continue the discussion and address any remaining questions.\n\n\n**Regarding literature review:** We thank the reviewer for the important references, which we now include and discuss in our revised version. Specifically, we note that papers [1-4] consider structured grid data (e.g., 2D images), while our work considers graphs and GNNs. Still, we agree it is essential to discuss the papers working on adversarial robustness and following a similar approach to the one we suggest. We have now updated the manuscript, including Appendix E, where the mentioned references and a few more are included and briefly discussed. This appendix is also referenced in the Introduction section of the main body.  Regarding paper [5], it studies the effectiveness of diffusion neural GNNs to graph topology attacks, showing its resilience compared to other methods. This paper is indeed very important and also adds to the motivation for using such networks for defense. Also, please see, regarding your query about the design of Equation (8), that paper [5] proposes a similar definition of the node feature system. Regarding paper [6], it offers a way to generate new injection attacks, while our paper focuses on a defense mechanism for GNNs. We added papers [5,6] to our Related Work section and a discussion of [1-4] to our revised Appendix. Please see our changes in Magenta.\n\n\nFinally, we would like to mention that the main novelty of our work, which is the learning of a coupled dynamical system that includes the adjacency matrix, is indeed an original contribution of our work, which is not considered in [1-6]. We add to our revised paper Appendix E, that discusses papers [1-4], and include references [5-6] in the \u201cRelated Work\u201d section of the main text."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151404357,
                "cdate": 1700151404357,
                "tmdate": 1700151809988,
                "mdate": 1700151809988,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ejL5botmlN",
                "forum": "7FHrZuKogW",
                "replyto": "YzQHti11K5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 2)"
                    },
                    "comment": {
                        "value": "**Regarding motivation**: We thank the reviewer for the questions. We split our response into different parts according to the questions raised by the reviewer.\n\n\n(i) The assumption of a piecewise constant function in Equation (6) is a common practice in neural ODEs, and it allows us to assume that we can interpret the learned neural network layers as the discretization of some continuous ODE. This is a very basic assumption, and it is also made in [1] as suggested by the reviewer. Furthermore, we kindly refer the reviewer to the following papers [R1,R2,R3,R4,R5] (cited in our original submission), where a similar assumption is made. To clarify this point, we have revised our text (please see changes in Magenta).  \n\n\n(ii) We would like to kindly refer the reviewer to the text above Equation (8), where we discuss the motivation for constructing our node dynamics. As stated, \u201cWe build upon a diffusion-based GNN layer, (Chamberlain et al., 2021; Eliasof et al.,2021), that is known to be stable, and under certain assumptions is contractive\u201d. That is, the construction of this mechanism allows us to theoretically analyze and explain the behavior of the node feature dynamical system of CSGNN. Using the gradient operator in Equation (8), we rely on the definition made in (Chamberlain et al., 2021; Eliasof et al.,2021). The same definitions are also used in the paper provided by the reviewer (paper [5]). To better accommodate the reviewer\u2019s question, we added an explicit definition of the gradient operator in our revised paper in Appendix B (which used to be Appendix A). We refer to appendix B before equation (8) in our revised version.\n\n\n(iii) Our choice to keep $\\tilde{\\mathbf K}_l$ symmetric is not arbitrary. It stems from [R6] (also cited in our original submission), allowing us to view the layers of the GNN as a discretization of a gradient flow. Therefore, it is important so as not to compromise the dynamical system view in our CSGNN. We have revised our paper to include this discussion. \n\n\nIn addition to the findings in [R6], in our case, it is reasonable to keep $\\tilde{\\mathbf K}_l$ symmetric so that if it is also learned to be positive definite, then the forward propagation of our node feature system is stable, as pointed out in Appendix A (now Appendix B after the updates introduced in the revised manuscript). Our original submission also provided this discussion; please see the paragraph after Equation (10) up to Section 4.3.\n\n\n\n\n(iv) We would like to note that the design of Equation (14) is far from an arbitrary choice. As discussed in our original submission, we build on the results shown in [R7], to design an equivariant and symmetry-preserving parameterization of the adjacency matrix, which is used to define our adjacency matrix update step. Furthermore, the design of Equation (14) is a major contribution of our work, and it addresses both mathematical and technical challenges in implementing an adjacency matrix dynamical system. We gently ask the reviewer to read our discussion that motivates this structure in Section 4.3. \n\n\n**Regarding reproducibility**: We are currently not at liberty to share the source code. However, we pledge to publicly share it on GitHub upon acceptance. Additionally, we note that for reproducibility purposes, our original submission includes a detailed description of our method and architectures in Appendices G, H, and I (which used to be E, F, and G in our original submission). \n\n**Regarding checking $\\mathbf K_l$ being positive-definite**: In our submission, we clearly state in Appendix B (used to be Appendix A) that depending on the weights of $K$, we may or may not get a stable update for the node features (which translates to $\\tilde{\\mathbf K}_l$ being positive-definite). Furthermore, **our experiments check the influence of $\\tilde{\\mathbf K}_l$ being positive-definite or not**. Specifically, in Appendix J, under the paragraph \u201cEnforcing contractive node dynamics improves baseline performance\u201d, we experiment with a variant of CSGNN that enforces the stability of the node dynamical system, called ECSGNN. Our results indicate improved performance compared to existing methods with ECSGNN, but further improvements can be obtained if we let $K$ be learned in a data-driven fashion. Our original submission included a reference to the results provided in Appendix J in the paragraph after Equation (10) up to Section 4.3. Therefore, we believe that our original submission offers a fair exposition of our work, both quantitatively and qualitatively, and we would like to hear the reviewer\u2019s opinion on this point after our clarification. To further address your concern, we have revised Appendix J text to reflect the discussion here better."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151501126,
                "cdate": 1700151501126,
                "tmdate": 1700151501126,
                "mdate": 1700151501126,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FJkbxitI71",
                "forum": "7FHrZuKogW",
                "replyto": "YzQHti11K5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 3)"
                    },
                    "comment": {
                        "value": "**Regarding computational overhead:** The reviewer is correct that learning to modify the adjacency matrix in an end-to-end fashion incurs additional computational overhead. We would like to start by noting that such an approach is not computationally light, regardless of the method (whether our CSGNN or other well-known methods like Pro-GNN [R8]). While such mechanisms do require more computations, they also offer improved performance. \nWe now provide a complexity analysis of our CSGNN, followed by a table that reports the training and inference times and memory consumption on an Nvidia RTX-3090 GPU with 24GB of memory, on the Cora dataset.\nTheoretically, the added runtime complexity for a CSGNN adjacency matrix learning layer is $O(9 \\cdot n^2)$ where $n$ is the number of nodes. Thus, assuming L layers, the overall complexity of a CSGNN network is $O(L(n \\cdot c^2 + m\\cdot c + 9\\cdot n^2))$, whereas node-based ODE systems usually are of runtime complexity $O(L(n \\cdot c^2 + m\\cdot c))$. Please recall that $n$ is the number of nodes, $m$ is the number of edges in the graph, and the term of $c^2$ stems from the channel mixing term in Equation (8). The factor of 9 stems from the 9 parameters to be learned in Equation (14). \nBelow, we report the runtimes and memory consumption of our CSGNN and compare it with CSGNN$_{\\textrm{noAdj}}$ (that is, CSGNN without the adjacency matrix update), and Pro-GNN for reference. These experiments were run on the Cora dataset with networks with 64 channels and 2 layers. It can be seen that both CSGNN and Pro-GNN require more resources, however, such an approach offers improved performance. \n\n\n\n\n| Method          | Train time [ms] | Inference time [ms] | Memory consumption [MB] | Accuracy (%) @ 25% Metattack | Accuracy (%) @ 5 nodes nettack |\n|-----------------|-----------------|---------------------|-------------------------|------------------------------|--------------------------------|\n| Pro-GNN         | 1681.17         | 1.01                | 1989                    | 69.72                        | 66.21                          |\n| CSGNN$_{\\textrm{noAdj}}$ | 3.29            | 1.32                | 891                     | 70.25                        | 81.90                           |\n| CSGNN           | 9.24            | 5.96                | 1623                    | 74.46                        | 83.29                          |\n\n\nAlso, we note that while both our CSGNN and Pro-GNN propose methods to evolve the adjacency matrix, our CSGNN shows significantly lower training computational time, due to our solution taking the form of a learned neural ODE system for the adjacency matrix, while Pro-GNN solves an optimization problem with feedback to the downstream task (which is also an end-to-end solution, although different than ours). For inference, Pro-GNN uses the fixed adjacency matrix found by training, while our CSGNN evolves the input adjacency matrix using the learned network. This can also be seen as an advantage of CSGNN, as it can be used for inference on different kinds of attacks and, therefore, can potentially generalize to different attacks, and this is a future research direction. \n\n\nWe also add that investigating the possibility of reducing the computational costs for learning adjacency matrices is an important and interesting topic on its own, that is left for future work.\n\n\nWe added the complexity analysis, reported runtimes, and future directions discussion to our revised paper."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151572125,
                "cdate": 1700151572125,
                "tmdate": 1700152420659,
                "mdate": 1700152420659,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zQUrGipXUO",
                "forum": "7FHrZuKogW",
                "replyto": "YzQHti11K5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (Part 4)"
                    },
                    "comment": {
                        "value": "**Regarding attack scope**: We follow the same experimental setting as in [R8], a popular paper whose settings were followed in multiple papers, allowing us to present a broad picture of the adversarial defense capabilities of our CSGNN and compare it with many methods. The Reviewer is correct that our theoretical assumptions are motivated by attacks where the nodes do not change between clean and attacked graphs (i.e., we do not focus on injection attacks). This is also stated in our \u201cNotations\u201d paragraph in Section 3 (\u201cPreliminaries\u201d). Following your question, we revised our Introduction (Section 1) to highlight this fact to enhance the focus of the paper.\nFurthermore, we would like to add that while our focus is on poisoning attacks (i.e., not on injection attacks), in principle, we are unaware of any inherent limitation in our presented theoretical results regarding changing the number of nodes, which translates to injection attacks. Therefore, in principle, one could extend our work to injection attacks. However, as previously discussed, this is not the main focus of our paper, and it is left for future work.\n \nRegarding black box evaluation, we would like to refer the reviewer to our experiments that include random perturbations in Figures 3, 6, and 9. \n\nRegarding the Pubmed dataset, we do not agree that our model achieves suboptimal results. Indeed, our CSGNN does not achieve the highest accuracy on all configurations on Pubmed. Still, a close look at our tables will also suggest that no model is perfect and offers the highest results across all datasets and configurations, and this is also not our claim. We claim that CSGNN offers a powerful model that stems from an ODE perspective and is the first model within the family of ODE-inspired GNNs, at least to our knowledge, to also learn the adjacency matrix. As we discuss in this rebuttal and the paper, this construction is non-trivial as it requires preserving the equivariance and symmetry of the adjacency matrix. Our model indeed offers impressive (also according to most of the reviewers) results on most of the datasets and configurations in this paper. Furthermore, we kindly ask the reviewer to look at Figures 5 and 6, where our CSGNN achieves the highest results on Pubmed, and also in Table 4 our results are among the top 3 models. As previously mentioned, in our experiments, we seek to offer a broad comparison with as many models as possible, and this is the motivation that led to the selection of datasets included in our paper.\n\n\n**Regarding large datasets**: We would like to refer the reviewer to Appendix I (Appendix J in the updated submission), where we provide results on the larger dataset Pubmed. Since our method includes an adaptive mechanism that alters the adjacency matrix in an end-to-end manner, using even larger datasets can be restrictive (memory-wise, due to the $O(n^2)$ possible edges and the need to keep gradients for backpropagation), which is in line with other GNN defense methods that include a learnable adjacency matrix mechanism, see for example [R8]. For reference, we did manage to run our CSGNN on a GPU with 24GB of memory on Pubmed but could not do the same with Pro-GNN [R8] due to out-of-memory errors. This can be attributed to the rather lightweight parameterization of our adjacency matrix update described in Equation (14).\nIn addition, we note that employing an adaptive adjacency matrix mechanism to even larger scale datasets is a challenge on its own due to the quadratic complexity in the number of nodes. We agree that it would be interesting to develop methods that can significantly reduce the existing computational costs (which could potentially reduce the complexity of O($n^2$), the maximal number of possible edges). However, as previously discussed in our rebuttal, such development is out of the scope of this paper. The investigation of this research direction can have a large positive impact on the GNN community beyond adversarial defense and is left for future research. \n\n[R1] Stable Architectures for Deep Neural Networks  \n\n[R2] Neural Ordinary Differential Equations  \n\n[R3] GRAND: Graph Neural Diffusion\n\n[R4] PDE-GCN: Novel Architectures for Graph Neural Networks Motivated by Partial Differential Equations\n\n[R5] GRAND++: Graph Neural Diffusion with A Source Term\n\n[R6] Graph Neural Networks as Gradient Flows: understanding graph convolutions via energy \n\n[R7] Invariant and Equivariant Graph Networks\n\n[R8] Graph Structure Learning for Robust Graph Neural Networks"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151641218,
                "cdate": 1700151641218,
                "tmdate": 1700151641218,
                "mdate": 1700151641218,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rTGeZ8Oiy0",
                "forum": "7FHrZuKogW",
                "replyto": "YzQHti11K5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reviewer feedback"
                    },
                    "comment": {
                        "value": "Dear Reviewer SPJa, \n\nWe sincerely appreciate the time and effort you dedicated to reviewing our paper, as well as the constructive feedback that helped us to improve our revised submission. After providing clarifications to your question, responding to your suggestions, and revising our paper, we hope that the concerns raised by you have been resolved. Could you kindly let us know if our responses have sufficiently addressed your concerns? We are happy to continue the discussion to clarify any standing doubt you may have. We thank you again for your valuable time.\n\nWith warm regards,\n\nThe authors"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700389798032,
                "cdate": 1700389798032,
                "tmdate": 1700389798032,
                "mdate": 1700389798032,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "4kQXtZwkDC",
            "forum": "7FHrZuKogW",
            "replyto": "7FHrZuKogW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5774/Reviewer_fwuD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5774/Reviewer_fwuD"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel approach to enhance the robustness of Graph Neural Networks (GNNs) against adversarial perturbations using contractive dynamical systems. The authors establish the mathematical foundations of their architecture, offering theoretical insights into its expected behavior. Through real-world benchmarks, they validate its effectiveness, achieving comparable or superior performance to existing methods. The paper's contributions encompass a new GNN architecture, a theoretical framework for behavior analysis, and empirical proof of its ability to bolster GNN resilience against adversarial attacks."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper addresses the critical issue of improving GNNs' robustness against adversarial attacks. It introduces an innovative approach to enhance Graph Neural Networks' (GNNs) robustness against adversarial perturbations by employing contractive dynamical systems. The simultaneous evolution of node features and adjacency matrices is a unique aspect of this approach, demonstrating a high degree of originality.\n\n2. The paper provides a rigorous mathematical derivation of the proposed architecture and comprehensive empirical evaluations. The authors offer theoretical insights into the expected behavior of their method, and empirical results affirm its effectiveness in bolstering GNNs against adversarial attacks.\n\n3. The paper is well-written, ensuring clarity and accessibility for readers."
                },
                "weaknesses": {
                    "value": "No obvious weaknesses from my perspective."
                },
                "questions": {
                    "value": "1. What are the assumptions behind Theorem 1 & 2?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698767002295,
            "cdate": 1698767002295,
            "tmdate": 1699636606525,
            "mdate": 1699636606525,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8Smrbcl1oP",
                "forum": "7FHrZuKogW",
                "replyto": "4kQXtZwkDC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for the positive feedback, saying that our paper is \u2018well-written, ensuring clarity and accessibility for readers\u2019, as well as praising the novelty of our method, stating that \u2018The simultaneous evolution of node features and adjacency matrices is a unique aspect of this approach, demonstrating a high degree of originality.\u2019 We now address your question below.  In our revised paper, our responses to your queries are marked in **Red**.\n\n\n**Regarding the assumptions of Theorems 1 and 2:** In our original submission, we state in Appendix A (now turned to Appendix B, in our revised version), after Equation (16) (now Equation (18)), that we assume the activation function $\\sigma$ should be monotonically increasing and 1-Lipschitz. We agree that explicitly adding the assumptions to Theorems 1 and 2 improves the quality and clarity of our paper, and we have now added them to our revised version. Please see our changes, marked in Red."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151323997,
                "cdate": 1700151323997,
                "tmdate": 1700151323997,
                "mdate": 1700151323997,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0ix5pOdrFb",
            "forum": "7FHrZuKogW",
            "replyto": "7FHrZuKogW",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5774/Reviewer_QT3W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5774/Reviewer_QT3W"
            ],
            "content": {
                "summary": {
                    "value": "This work introduces massage passing layers in the context of graph representation learning, inspired by differential equations with contractive properties, that have promising capabilities in improving the robustness of GNNs. This claim is then further strengthened by a complete theoretical analysis and extensive benchmark covering many GNN architectures & threat models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- Paper is well written.\n- Complete theoretical analysis supported by strong results."
                },
                "weaknesses": {
                    "value": "Unfortunately, the paper is not self-contained for readers with no background in contractive systems and dynamical systems. Since I'm not familiar with these techniques, it's hard for me to point out any weaknesses beyond educated guesses."
                },
                "questions": {
                    "value": "I do not have major questions about the manuscript."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5774/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824338261,
            "cdate": 1698824338261,
            "tmdate": 1699636606419,
            "mdate": 1699636606419,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "r6Gs8oPK8i",
                "forum": "7FHrZuKogW",
                "replyto": "0ix5pOdrFb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the overall positive assessment of our submission. The reviewer mentioned the \u2018well written\u2019 manner of our paper and the \u2018complete theoretical analysis\u2019 with \u2018strong results\u2019. Below, we provide our responses to your concerns. In our revised paper, our responses to your queries are marked in **Blue**.\n\n\n\n**Regarding background on contractive systems:** The reviewer is correct that our submission can benefit from an overview of contractive systems. In our original submission, we briefly discussed the meaning of a contractive system in the last paragraph of Section 3 (Preliminaries) and in the Method section (Section 4). Specifically, we provide the discretized definition of a node contractive system in Theorem 2 (please see Equation (10)) and of the adjacency matrix contractive system definition in Equation (11). In our submission, we focus on discretized dynamical systems and therefore only provided those definitions.\n\n\nWe also note that Reviewer fwuD highlights the mathematical background provided in our submission:\n\u201c2. The paper provides a rigorous mathematical derivation of the proposed architecture and comprehensive empirical evaluations. The authors offer theoretical insights into the expected behavior of their method, and empirical results affirm its effectiveness in bolstering GNNs against adversarial attacks.\u201d\n\n\nTo make our paper more self-contained, following your suggestion, we have added an Appendix section (\u201cContractive Systems\u201d) that discusses the continuous definition of contractive systems and provides a few of their properties. We now refer to the added Appendix section from our main text in the Preliminaries section. Our changes can be viewed in the updated submission, marked in Blue."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700151278140,
                "cdate": 1700151278140,
                "tmdate": 1700151278140,
                "mdate": 1700151278140,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cg58eSIQrx",
                "forum": "7FHrZuKogW",
                "replyto": "r6Gs8oPK8i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5774/Reviewer_QT3W"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Program_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Senior_Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Area_Chairs",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewers/Submitted",
                    "ICLR.cc/2024/Conference/Submission5774/Authors"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5774/Reviewer_QT3W"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your comments. I've maintained my score."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5774/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700552160058,
                "cdate": 1700552160058,
                "tmdate": 1700552160058,
                "mdate": 1700552160058,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]