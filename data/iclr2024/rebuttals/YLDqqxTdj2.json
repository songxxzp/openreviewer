[
    {
        "title": "Information based explanation methods for deep learning agents -- with applications on large open-source chess models"
    },
    {
        "review": {
            "id": "CFzS3MP1WP",
            "forum": "YLDqqxTdj2",
            "replyto": "YLDqqxTdj2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1319/Reviewer_2i6y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1319/Reviewer_2i6y"
            ],
            "content": {
                "summary": {
                    "value": "The paper uses XAI methods for explaining factors that influence the moves of a chess engine. It claims two contributions:\n1. to replicate the results of McGrath et al. with an open source chess engine\n2. to propose a novel technique for computing salient squares.\nThe proposed technique is trained to learn a binary mask for the features along with the model, similar to an attention mechanism (which the authors do not relate to, btw)."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is well written and the approach is illustrated with good examples. \nThe confirmation of the results of McGrath et al. on LeelaChess data is also valuable, but I don't think that this is a research contribution for this conference. It might be more interesting for a computer games conference."
                },
                "weaknesses": {
                    "value": "Of the two claimed contributions, I don't think that 1. is actually a contribution, as there is no reason to expect that results with LeelaChess would be any different than the reported results for AlphaZero. The second contribution - the new method - is maybe more interesting. However, it does not seem to stick out from related work, some of which the authors seem to be unaware of (in particular the work on SARFA, which was published 3 years ago at this conference (Piyust et al. 2020), but also follow-up papers such as (Fritz & F\u00fcrnkranz 2021).\n\nThe evidence for the validity of the proposed method is, as in previous work, only anecdotal, and I do not find the shown examples very convincing. The authors, e.g., claim that the examples shown in \"...Fig. 5 capture the essence of what is necessary to solve the given puzzle....\". Looking at these examples one sees that most (more than half) of the pieces are considered to be important in each of these positions, which includes pieces that are completely irrelevant for the assessment (e.g., Bd1 or Pb7 in Fig. 5 c)), and, on the other hand, miss pieces that are essential (such as Bd5 in Fig.5 c) which delivers the mate-in-1). The latter problem is briefly mentioned by the authors (but explained away), the former problem is not mentioned. Of course, if many pieces are annotated as important, there is a high chance that the essential pieces are among them. In more technical term, the proposed technique seems to have a high recall, but a rather low precision. Both of which are not evaluated. \n\nI think the paper would need a somewhat more founded evaluation methodology. For example, an explanation could be considered useful if it helps a human chess player to find the best move in the position. I doubt that any of the shown explanations can actually do that. Prior works, such as the above-mentioned work on SARFA, tried to at least get a grip on the accuracy of the evaluation by comparing the method's salient squares with those mentioned by human annotators. I am not sure that these techniques work better than what is proposed here, but at least the make a stronger attempt in evaluating it. \n\nMinor Comments\n- The authors often use \"author (year)\" citations in places where \"(author year)\" is clearly required, which is often quite confusing, such as \"Monte Carlo Tree Search Coulom\" in the first sentence of 2.2.\n- There seems to be an error in Figure 3 (the pawn on the f-file is moved backwards by a square).\n- I did not understand the idea behind formula (4). Why the max over all possible pieces for unoccupied squares?\n- The related work saliency-based and perturbation-based methods are not suitable for chess. I did not understand this. The authors themselves propose a form of saliency maps, so I think they do not refer to the representation but to how it is computed in the 5 given references, but they do not explain. For perturbations, they do give an explanation, but it does not seem to be convincing to me (in particular, as the above-mentioned SARFA is based on perturbations).\n\n\nReferences:\nG. Piyush, P. Nikaash, V. Sukriti, K. Dhruv, D. Shripad, K. Balaji, and S. Sameer, \u201cExplain your move: Understanding agent actions using\nspecific and relevant feature attribution,\u201d in International Conference on Learning Representations (ICLR), 2020.\nJessica Fritz, Johannes F\u00fcrnkranz: Some Chess-Specific Improvements for Perturbation-Based Saliency Maps. CoG 2021: 1-8"
                },
                "questions": {
                    "value": "Can you say something about the precision of the squares annotated? As mentioned above, occupied squares tend to be blue, others tend to be red, so that the pieces that are involved in the target move tend to be blue, but many others as well. Are these really helpful for understanding the position? (e.g., those mentioned above, or Pb7 in Fig. 5 b), etc.).\n\nYour work also reminds me of attention mechanisms, maybe even transformer networks. Can you comment on that?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1319/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698618165747,
            "cdate": 1698618165747,
            "tmdate": 1699636059149,
            "mdate": 1699636059149,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "SJSrQeLfFm",
            "forum": "YLDqqxTdj2",
            "replyto": "YLDqqxTdj2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1319/Reviewer_r57g"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1319/Reviewer_r57g"
            ],
            "content": {
                "summary": {
                    "value": "I will note that I have limited expertise in this type of RL research.\n\nThis work notes that the AlphaZero model used to play chess is not publicly available. Explainable AI (XAI) methods for concept detection were applied to the AlphaZero model and are also not public. This work utilizes a publicly available implementation of AlphaZero style implementation to play chess and applies XAI methods to it. The principal contribution is the use of concept detection with the publicly available chess agent implementation. The model employs a binary mask to mask out irrelevant information (tiles) in the training of the concept detection module. This mask signifies the pieces of most importance during the move. Results of the AlphaZero model are replicated using the open-source model, and numerous interpretability findings are shown and described in the context of the mask values."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- This is an important reproduction of an interpretability model applied to a longstanding RL problem.\n- The method appears sound, and the experimental results are interesting. It is clear to see different concepts being identified through the mask values."
                },
                "weaknesses": {
                    "value": "- This is a reproducibility paper with limited novelty. The methods are well-known. I don't think this work meets the bar to be accepted at ICLR.\n- The results appear to be mostly qualitative, requiring the user to identify the meaning of different mask values in the context of the game positions.\n\nI recommend rejection with weak confidence. I was able to understand the method but feel that I do not know enough about RL problems in the chess space. The paper still seems to lack novelty from my perspective"
                },
                "questions": {
                    "value": "N/A.  I would like to see other reviewer comments before asking additional questions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1319/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1319/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1319/Reviewer_r57g"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1319/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698780003958,
            "cdate": 1698780003958,
            "tmdate": 1699636059055,
            "mdate": 1699636059055,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "jI1jSnP806",
            "forum": "YLDqqxTdj2",
            "replyto": "YLDqqxTdj2",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1319/Reviewer_8hN2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1319/Reviewer_8hN2"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to be a re-implementation of Deepmind-Internal interpretability work on AlphaZero in Chess, as well as an introduction of a novel explainable AI method. The introduced method works by distilling the original model via imitation learning into a model with a special structure that ensures that only parts of the input are used, then use that structure to determine what is important for predicting the output of the original model."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The open-sourced implementation of interpretability for Alpha-zero should help others build on the work in the future. Explainability techniques that work for DeepRL policies are still a nascent field, so developing these on the most potent RL policies we have makes sense."
                },
                "weaknesses": {
                    "value": "It is often unclear what in the paper is re-implementation and what is novel explainability work. Much of the paper is spent introducing their own technique, and eventually, they say that it achieves similar results as what was seen in the original paper, but it is unclear where the method they implemented deviates from prior work.\u00a0 Given that part of the goal is the reimplementation of prior work, it would be ideal if the prior method were implemented to the extent that it re-produced existing results.\n\nThe proposed interpretability method is also several steps removed from the model itself, leaving a significant amount of room for error and interpretation. Rather than directly interpreting the model, the method clones the model into an architecture that would make it interpretable by construction. However, there is no guarantee that the resulting policy operate in the same way; we would expect the opposite. Moreover, if the instances we are trying to interpret are off-distribution for the cloned model, we cannot trust the results. The opposite is also true. If there is not enough diversity in the training of the cloned model, the model could also not need some information the original model does need.\n\nThere are also some systematic flaws with the objective of the cloned policy.\u00a0 Since the policy doing the masking sees the whole board, there is information in the mask itself about the unseen pieces. For instance, the two networks could have a convention that if the second network does not see the king, it is in a typical place (as is pointed out in Figure 6). This back door makes it quite hard to draw a direct link between the parts of the board that are revealed and how the network works since we do not know what other information is implied by otherwise arbitrary choices in the mask."
                },
                "questions": {
                    "value": "Is there a way to detect steganography between the two networks via the mask so it could at least be characterized?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1319/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698839527355,
            "cdate": 1698839527355,
            "tmdate": 1699636058981,
            "mdate": 1699636058981,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]