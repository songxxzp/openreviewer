[
    {
        "title": "Brain-inspired $L_p$-Convolution benefits large kernels and aligns better with visual cortex"
    },
    {
        "review": {
            "id": "qCGDi2hGBw",
            "forum": "jz35igczhm",
            "replyto": "jz35igczhm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_qr9c"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_qr9c"
            ],
            "content": {
                "summary": {
                    "value": "Inspired by the observation that the spatial distribution synaptic inputs in the early visual system of the brain is approximately Gaussian, the authors propose a masking strategy for convolution filters in convnets for image recognition. They observe that such (approximately) Gaussian masking enables convnets to learn with larger filters, leading to improved performance on the Sudoku challenge and a number of small-scale image classification tasks. They also show that networks trained with Gaussian masked filters exhibit slightly increased representational similarity to the mouse visual system."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ Creative inductive bias transfer from biology to machine learning\n + Overall well-written paper\n + Well-motivated and well-executed experiments"
                },
                "weaknesses": {
                    "value": "1. Effect sizes are quite small\n 1. A number of details on the experiments remain unclear even after screening the appendix"
                },
                "questions": {
                    "value": "I am somewhat torn on the paper. While I appreciate the clear motivation and hypothesis, I am somewhat underwhelmed by the results and/or how they are (over?)sold in the paper. If the authors can provide convincing answers to the following questions, I am willing to adjust my score.\n\n### 1. Effect size\n\nWhile I very much appreciate the three main experiments presented in Fig. 3, Table 1 and Fig. 5, I am somewhat underwhelmed by the effect sizes.\n\n a) In the Sudoku challenge, the main argument seems to be about the imbalance between row/column and block accuracy, but the difference in accuracy is <10% in all cases, which doesn't strike me as a particularly worrisome imbalance. In particular, the difference between p=2 and 7x7 (Large) is <1% (although I'm not sure what the latter model exactly is; see below). Could this be a matter of presentation and the differences would be much clearer if you looked at error rates instead of accuracy? Could you explain why you think these results are important given such small effect size?\n\n b) In the image classification experiments, there is a clearly significant improvement due to Lp-Conv, but not on all architectures and again the improvement is small (a few percent). Given that architectural modifications alone can now push accuracy on CIFAR-100 >90% (https://arxiv.org/abs/2304.05350v2), the 2\u20133% improvements in the 60\u201370% range feel a bit insignificant. Can you explain why you think your approach is still worthwhile? Would we expect similar gains if we included the Gaussian masking inductive bias into more modern architectures?\n\n c) In the representational similarity experiments the improvements due to p=2 are in the range of 0.5\u20132%. Again, why are such small differences relevant from a scientific point of view if the differences between, e.g., AlexNet and ConvNeXt-T are of the same order of magnitude?\n\n\n### Experimental details\n\n a) Are the masks applied after training to the trained weights or during training? If the latter, does it change anything about what the network learns? It could just learn larger weights W where the mask is small, leading to the exact same network as without masking. Why is this not happening?\n\n b) It is not clear to me what the different networks in Fig. 3 are. It's clear that 3x3 and 7x7 refer to the kernel size. But what does \"Large\" refer to and what is the Lp^{\\dagger} model?\n\n c) As far as I understand Fig. 3, p=2 refers to p being initialized as 2 but then optimized as a trainable parameter, correct? If so, what was p at the end of training for the three models with p={2, 16, 256}? This question actually applies to all experiments.\n\n d) Table 1: ResNet has larger kernels than 3x3 in the first layer. Are they kept the same in all variants and only the 3x3 kernels in the later layers are modified?\n\n e) Fig. 5: I did not fully grasp what \"Max. SSM\" exactly refers to. In panel a) five brain areas are colored; in panel b) five network architectures. Presumably you compared all architectures against all brain areas. What exactly is being reported here? Why is there not one such plot as in b) per brain area?\n\n\n### Other questions\n\n a) Why is the spatial distribution of synapses the right thing to compare to weights in a CNN? The presynaptic neurons also have spatially extended receptive fields (RFs), which means the V1 neuron's RF envelope in pixel space is not the same as the retinotopically mapped synaptic locations."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3144/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697812343370,
            "cdate": 1697812343370,
            "tmdate": 1699636261831,
            "mdate": 1699636261831,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "swhKuUWboj",
                "forum": "jz35igczhm",
                "replyto": "qCGDi2hGBw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate the valuable feedback from the reviewer. Following are pointwise responses to the reviewer.\n\n---\n> __Re.1)__ In the Sudoku challenge, the main argument seems to be about the imbalance between row/column and block accuracy, but the difference in accuracy is <10% in all cases, which doesn't strike me as a particularly worrisome imbalance.  In particular, the difference between p=2 and 7x7 (Large) is <1%. Could this be a matter of presentation and the differences would be much clearer if you looked at error rates instead of accuracy? Could you explain why you think these results are important given such a small effect size?\n\nThank you for the reviewer's critical point. We understand the reviewer's point on the accuracy gap ($\\sim$10%; row/column vs square) may not seem worrisome with respect to the imbalance itself. However, this is slightly different from our intention. We would like to clarify our main claim.\n\nOur main claim here is that ___such a small imbalance can have a significant impact on a greater problem___. Considering the fact that a Sudoku puzzle is solved only when all 81 numbers align correctly, a single error in any of the 18 rows/columns ($\\approx$6% error) results in a Sudoku unsolved. We believe our experimental result in __Fig. 3b__ supports this point; small imbalances in row/col and square accuracies (1$\\sim$10%) can have a significant impact on overall Sudoku accuracy (20$\\sim$60%). \n\nTo convey this point more clearly, we have revised our manuscript by changing the figure, and subsection titles in Section 4 as follows.\n- (Fig. 3 title) $L_p$-convolution enhances Sudoku solving efficiency by effectively balancing accuracy between square and row-column puzzles\n- (subsection 3 title) $L_p$-convolution in Sudoku solving: balancing square and row-column imbalances\n\n---\n> __Re.2)__ In the image classification experiments, there is a clearly significant improvement due to Lp-Conv, but not on all architectures and again the improvement is small. Given that architectural modifications alone can now push accuracy on CIFAR-100 >90%, the 2\u20133% improvements in the 60\u201370% range feel a bit insignificant. Can you explain why you think your approach is still worthwhile? Would we expect similar gains if we included the Gaussian masking inductive bias into more modern architectures?\n\nThank you for sharing the impressive paper. While architectural modifications alone can achieve remarkable performance gains, these results can be seen as the outcome of a combination of various excellent methods. ___Our work can be considered as the discovery of a new method that can be combined with such architectural modifications.___ From this perspective, we believe our work is sufficiently valuable.\n\nIn response to the reviewer's question we applied $L_p$-Conv (p=2) on the ConvNeXt-V2 (Woo et al., CVPR 2023) and other higher accuracy range (70~80%) models with CIFAR100 as follows (See __Appendix A.20, Table 5__):\n\n|$L_p$-Conv|ConvNeXt-V2-T|ResNet-50|ResNeXt-50|DenseNet-121|\n|:-:|:-:|:-:|:-:|:-:|\n|-|64.26\u00b10.41|73.17\u00b10.23|73.55\u00b10.57|74.12\u00b10.16|\n|$\\checkmark$|65.58\u00b10.25|76.66\u00b10.19|77.38\u00b10.36|77.14\u00b10.18|\n\nOur method enhances performance in 1) modern CNN architecture as well as 2) higher accuracy models with 3~4% improvement. These results highlight the versatility of our $L_p$-convolution method to a diverse range of architectures. We believe that integrating our Gaussian masking inductive bias into various architectures could yield similar gains, further affirming the importance of methodological innovations alongside architectural advancements.\n\n---\n> __Re.3)__ In the representational similarity experiments the improvements due to p=2 are in the range of 0.5\u20132%. Again, why are such small differences relevant from a scientific point of view if the differences between, e.g., AlexNet and ConvNeXt-T are of the same order of magnitude?\n\nThank you for your thoughtful question. In the field of computational neuroscience, the use of artificial systems as a comparative tool has proven invaluable, particularly in understanding the brain's visual processing [1, 2]. Although AlexNet and ConvNeXt-T show similar levels of improvement, the reasons behind these gains are quite intricate, especially when considering structural differences. Our research focuses on unraveling these complexities. Specifically, the consistent improvement pattern across various models with the adjustment of the $p$ value is compelling. ___It suggests a shared underlying mechanism in visual information processing___, potentially mirroring the Gaussian-like receptive fields observed in the human brain. I hope this answers your question!\n\n[1] Kriegeskorte et al., \"Representational similarity analysis - connecting the branches of systems neuroscience,\" Frontiers in Systems Neuroscience, 2008.  \n[2] Cadieu et al., \"Deep neural networks rival the representation of primate IT cortex for core visual object recognition,\" PLoS Computational Biology, 2014."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700486740153,
                "cdate": 1700486740153,
                "tmdate": 1700486740153,
                "mdate": 1700486740153,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0tpMGyylgw",
                "forum": "jz35igczhm",
                "replyto": "qCGDi2hGBw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors - 2"
                    },
                    "comment": {
                        "value": "> __Re.4)__ Experimental details a) Are the masks applied after training to the trained weights or during training? If the latter, does it change anything about what the network learns? It could just learn larger weights W where the mask is small, leading to the exact same network as without masking. Why is this not happening?\n\nIn response to the reviewer's question, we clarify that the $ L_p$-mask is trained with weight simultaneously. With proper initialization of $L_p$-mask, ___it imposes a spatial constraint on the weights which leads to a change in learning dynamics___. Since both mask and weights are trained with standard backpropagation after the forward process ($Y = \\phi(X*(W \\odot M))$, Eqn. 4), $L_p$-mask effectively scales down the influence of peripheral weights.  This setup leads to a distinct learning behavior compared to a scenario without a mask, as the mask evolves (Fig. 2, 4, and 8) together with weight update. \n\n---\n> __Re.5)__ Experimental details b) It is not clear to me what the different networks in Fig. 3 are. It's clear that 3x3 and 7x7 refer to the kernel size. But what does \"Large\" refer to and what is the Lp^{\\dagger} model? \n\nApologies for the insufficient information. We have revised the manuscript's Fig. 3b to address this.\n- (new in Fig. 3b caption) '(3x3)' or '(7x7)' denotes the size kernel. '$L_p^\\dagger$' denotes parameters of $L_p$-mask is frozen. 'Large' denotes a simple enlargement of the kernel, without a mask.\n\n---\n> __Re.6)__ Experimental details c) As far as I understand Fig. 3, p=2 refers to p being initialized as 2 but then optimized as a trainable parameter, correct? If so, what was p at the end of training for the three models with p={2, 16, 256}? This question actually applies to all experiments.\n\nThank you for your question regarding the optimization of $p$. \n- In the case of $L_p^\\dagger (p=256)$, the parameters are fixed, meaning that $p$ remains constant at 256 throughout the training process.\n- For the $p=16$ scenario, we have detailed the properties of $L_p$-masks in the revised manuscript, specifically in __Appendix A.18__. \n- Additionally, the distribution of $p$ values across all experiments is comprehensively visualized in __Appendix A.17__ of the revised manuscript.\n\n---\n> __Re.7)__ Experimental details d) Table 1: ResNet has larger kernels than 3x3 in the first layer. Are they kept the same in all variants and only the 3x3 kernels in the later layers are modified?\n\nAll kernels are ___equally modified___.\n- In TinyImageNet, ResNet has a 7x7 kernel size in the first layer and is equally enlarged as 15x15 in '(Large)' or '$L_p$-Conv'. \n- In CIFAR-100 due to its small image size (32 x 32), ResNet has a 3x3 kernel size in the first layer [1, 2].  This is enlarged as 7x7 in '(Large)' or '$L_p$-Conv'.  \n[1] He, Kaiming, et al. \"Deep residual learning for image recognition.\" CVPR. 2016.   \n[2] https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/resnet.py\n---\n\n> __Re.8)__ Experimental details e) Fig. 5: I did not fully grasp what \"Max. SSM\" exactly refers to. In panel a) five brain areas are colored; in panel b) five network architectures. Presumably you compared all architectures against all brain areas. What exactly is being reported here? Why is there not one such plot as in b) per brain area?\n\n\"Max. SSM\" refers to the ___maximum SSM value obtained from our pairwise comparisons___ of all network architectures against each brain area, following the methodology established by Bakhtiari et al. in 2021. As you correctly interpreted, these comprehensive comparisons are detailed in __Appendix A.12, Figure 10__ of our manuscript. Due to limited space, we included this analysis in the Appendix to provide a clear presentation of our result.\n\n- Bakhtiari, Shahab, et al. \"The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning.\" Advances in Neural Information Processing Systems 34 (2021)\n\n---\n> __Re.9)__ Other questions a) Why is the spatial distribution of synapses the right thing to compare to weights in a CNN? The presynaptic neurons also have spatially extended receptive fields (RFs), which means the V1 neuron's RF envelope in pixel space is not the same as the retinotopically mapped synaptic locations.applies to all experiments.\n\nThank you for your insightful feedback. We understand the limitations in our approach, particularly that the spatial distribution of V1 synapses might not perfectly mirror the weights in a CNN. The idea of comparing retinotopically mapped synaptic locations is an intriguing alternative. Our current method, aligning V1 synaptic patterns with CNN weight distributions, is an ___exploratory effort aimed at fostering better dialogue between the realms of biological and artificial vision___. Though it may not be a direct equivalence, this approach marks a significant step in our journey to understand the intricate parallels between these systems."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700487304200,
                "cdate": 1700487304200,
                "tmdate": 1700487304200,
                "mdate": 1700487304200,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xslG94kC7O",
                "forum": "jz35igczhm",
                "replyto": "qCGDi2hGBw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A gentle reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your insightful feedback on our manuscript. We have thoroughly revised it, emphasizing the clarification of effect sizes and experimental details as per your suggestions. We hope these revisions meet your expectations, and we would greatly value any additional comments or thoughts you might have."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637762441,
                "cdate": 1700637762441,
                "tmdate": 1700645689002,
                "mdate": 1700645689002,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gWi1dvhNtG",
            "forum": "jz35igczhm",
            "replyto": "jz35igczhm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_Bf1L"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_Bf1L"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose adding a gaussian mask to the square kernels of CNNs/transformers, parametrized by the L_p metric, to give ANN receptive fields a flexibility similar to Biological NNs (BNNs). They find that these including these Lp masks improve network accuracy"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The basic idea is very compelling. \n\nThe connection to BNNs is well supported.\n\nThe paper is very well-written.\n\nThe results table has +/- std devs."
                },
                "weaknesses": {
                    "value": "I am left wondering if CNNs do this RF masking already, by different means. \n\nI am unclear how the covariant matrix C is trainable. what is the update process?\n\nReviewer limitation: I am not well-versed in this literature, so I am assessing the paper itself with limited background.\n\n\nNotes to ICLR: \n\n1. Please include line numbers in the template. They make reviewing much easier! \n\n2. Please reformat the default bibliography style to make searching the bib easier! eg numbered, last name first, initials only except for last name."
                },
                "questions": {
                    "value": "General review context: Please note that I am simply another researcher, with some overlap of expertise with the content of the paper. In some cases my comments may reflect points that I believe are incorrect or incomplete. In most cases, my comments reflect spots where an average well-intentioned reader might stumble for various reasons, reducing the potential impact of the paper. The issue may be the text, or my finite understanding, or a combination. These comments point to opportunities to clarify and smooth the text to better convey the intended story. I urge the authors to decide how or whether to address these comments. I regret that the tone can come out negative even for a paper I admire; it's a time-saving mechanism for which I apologize.\n\nKey comments:\n\nNote: Addressing the two issues in \"Weaknesses\" above would be great. The rest of the comments can be handled as the authors see fit.\n\nBibliography: Perhaps reformat the bibliography for easier searching, eg numbered, last name first, initials only except for last name.\n\nAbstract \"gaussian-like structured sparsity\": I don't think of gaussian weightings as \"sparse\", since few values get sent to zero. Is this the correct technical term for what is happening?\n\n1. paragraph 1, \"LecCun and ... by introducing backprop\": Backprop was not LeCun. I think more complete citations are needed here. \n\n1. paragraph 1, \"alexNet\": CNNs blew up with the convergence of backprop, CNNs, big data sets, and GPUs that enabled training them.\n\n1. Paragraph 2, list of similarities: A 4th important similarity is local RFs (as you note in the next paragraph).\n\nProvided code :)\n\n2. Multivariate p-general... \"the reference position of the RF\": Do you mean \"reference position of a pixel in the RF?\". If not, I am confused.\n\nEqn 1: Is the superscript \"p\" standard notation? I think I usually see L_p as ||   ||_p (subscript only).\n\nCovariate matrix C: does this raise dimensionality issues, since C includes d^2 new parameters per filter? (doubles the number of free parameters I think).\n\nFig 1 e: this shows up too small on a printed page.\n\nFig 1 f: Did you try p < 2? It looks like the masks converge to rectangles (all weights in mask the same) at low p, so that the difference between 4 and 16 is slight. \n \n3. \"introduce L_p convolution\": clever mechanism.\n\nJust after eqn 4 \"C and p are trainable\": I do not see how to do this. Is it explained in the paper?\n\n\"mask take one\": I stumbled on this. Clearer might be \"equal one\", or \"have the value one\". Also, maybe note that this is the limit as p increases, and in fact is roughly attained at p = (some value).\n\n4. Sudoku: Perhaps explain why this is a good test case for the method (since it is not usual, and the usual image examples come later).\n\nFig 3 b: the line colors/labels are unclear in these subplots. Perhaps make them bigger, or use dashed lines for some cases, or change to brighter colors.\n\nFig 4: What is the definition of \"distortion\"?\n\nFig 4 a: The different labels (alpha, theta) on the two sides of the mosaic are hard to decipher, especially on a printed page. Perhaps make the mosaic horizontal, or make labels larger, or break up the sets of 9 boxes with bolder lines, or provide clearer guidance in the caption.\n\nFig 4 a: what role do diagonal masks play in the Sudoku networks, given the problem's horizontal-vertical-box structure?\n\nFig 4 a: A crucial question for me: These RFs look a lot like what we often see in CNN papers. Is the L_p method generating something novel, or is it a new way of getting to what already happens?\n\nComparisons with base models:  It appears that adding an L_p mask at each filter effectively doubles the free parameter count while holding the filter size fixed. Might this account for the difference in accuracy scores?\n\nSection 7: This looks like it should appear earlier in the paper - it is background."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3144/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698785359467,
            "cdate": 1698785359467,
            "tmdate": 1699636261756,
            "mdate": 1699636261756,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gEL9D0Nyyv",
                "forum": "jz35igczhm",
                "replyto": "gWi1dvhNtG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are extremely happy with the reviewer's recognition of our contribution!  \nFollowing are our point-wise responses to the reviewer.\n\n---\n> __Re.1)__ I am left wondering if CNNs do this RF masking already, by different means.\n\nThank you for your insightful query regarding receptive fields in CNNs.\n\nYou are correct that many CNN studies discuss RFs, similar to what we've illustrated in our revised manuscript, specifically in __Appendix A.14, Figure 11a__. In traditional CNN models, these RFs are shaped by the network's trainable parameters \u2013 the kernel weights \u2013 and evolve naturally during the training process.\n\nHowever, our work takes a distinct approach. ___We've integrated structured sparsity constraints directly into the network's architecture___. This method doesn't just allow the RFs to emerge; it actively shapes them. This targeted shaping is crucial because it ensures the development of receptive fields that adhere to a specific pattern of structured sparsity. This approach is more than a byproduct of training; it's a strategic design choice.\n\nWe believe that this novel method of guiding RF development represents a significant advancement in the field. It opens new avenues for understanding and utilizing receptive fields in CNN architectures, moving beyond traditional methods. Our hope is that this contribution will offer valuable insights into the potential of structured sparsity in neural networks.\n\n---\n> __Re.2)__ I am unclear how the covariant matrix C is trainable. what is the update process?\n\nIn our implementation, we set $C$ and $p$ as trainable parameters within the LpConv2d class, leveraging PyTorch's nn.Parameter (Pseudocod in __Appendix A.13__). These parameters are updated through the standard backpropagation process, just like other weights in the model. The mask in the convolution operation is dynamically generated, utilizing the current values of $C$ and $2$. Thanks to PyTorch's automatic gradient management, efficient training is ensured without the need for a specialized update mechanism. \n\nIn the revised manuscript, we added footnote 3 on page 5 as follows.\n- (added) $C$ and $p$ are updated with the standard backpropagation process. $L_p$-mask is dynamically generated during forward process using $C$ and $p$.\n\n---\n> __Re.3)__ Reviewer limitation: I am not well-versed in this literature, so I am assessing the paper itself with limited background.\nNotes to ICLR:\nPlease include line numbers in the template. They make reviewing much easier!\nPlease reformat the default bibliography style to make searching the bib easier! eg numbered, last name first, initials only except for last name.\n\nEven in such challenging circumstances, we express our sincere gratitude for the valuable feedback you have provided to us :)\n\n---\n> __Re.4)__ General review context: Please note that I am simply another researcher, with some overlap of expertise with the content of the paper. In some cases my comments may reflect points that I believe are incorrect or incomplete. In most cases, my comments reflect spots where an average well-intentioned reader might stumble for various reasons, reducing the potential impact of the paper. The issue may be the text, or my finite understanding, or a combination. These comments point to opportunities to clarify and smooth the text to better convey the intended story. I urge the authors to decide how or whether to address these comments. I regret that the tone can come out negative even for a paper I admire; it's a time-saving mechanism for which I apologize.\n\nWe were able to improve the quality of our manuscript with your thorough review, comment, and suggestion. We appreciate your contribution\n\n---\n> __Re.5)__ Abstract \"gaussian-like structured sparsity\": I don't think of gaussian weightings as \"sparse\", since few values get sent to zero. Is this the correct technical term for what is happening?\n\nOur $L_p$ convolution in Eq. 4 adopts $p$-generalized normal distribution in Eq. 3. In essence, $L_p$ convolution introduces structured sparsity for sufficiently large values of $p$, as shown in Fig. 1. We agree that \u201cgaussian-like structured sparsity\u201d might lead to misunderstanding. Therefore, we revise the expression to \u201cstructured sparsity inspired by $p$-generalized normal distribution\u201d.\n\n---\n> __Re.6)__ paragraph 1, \"LeCun and ... by introducing backprop\": Backprop was not LeCun. I think more complete citations are needed here.\n\nWe apologize for the misleading sentence. We do aware backdrop was not invented by LeCun. \n\nTo clarify this, we revised the sentence as follows.\n\n\n- (before) LeCun and his colleagues built on this by introducing backpropagation, which led to the first implementation of a CNN (LeCun et al., 1989).\n\n- (after) Building upon the backpropagation (Werbos, 1974; Rumelhart et al., 1986), and the concept of weight sharing, LeCun and his colleagues applied it to CNNs, leading to the development of the first practical CNN, known as LeNet (LeCun et al., 1989)."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485622652,
                "cdate": 1700485622652,
                "tmdate": 1700485622652,
                "mdate": 1700485622652,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tNaTHykIrb",
                "forum": "jz35igczhm",
                "replyto": "gWi1dvhNtG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors - 2"
                    },
                    "comment": {
                        "value": "> __Re.7)__ paragraph 1, \"alexNet\": CNNs blew up with the convergence of backprop, CNNs, big data sets, and GPUs that enabled training them.\n\nWe are glad that we could incorporate historical background information as well, thanks to your input.\n\n(before) The turning point for CNNs came in 2012 with the introduction of AlexNet, which outperformed existing models in the ImageNet challenge and brought CNNs into the spotlight (Krizhevsky et al., 2012).\n\n(after) Fueled by advancements in backpropagation, large datasets, and GPU training, the landmark success of AlexNet in 2012, which significantly outperformed existing models in the ImageNet challenge, marked a turning point for CNNs (Krizhevsky et al., 2012).\n\n---\n> __Re.8)__ Paragraph 2, list of similarities: A 4th important similarity is local RFs (as you note in the next paragraph).\n\nGreat point, we have listed your suggestion!\n\n(before) 1) RGB channels emulate retinal computations, 2) stacked layers correspond to various visual areas (such as V1, V2, V4, IT), and 3) deeper layers excel at detecting complex features\n\n(after) 1) RGB channels emulate retinal computations, 2) stacked layers correspond to various visual areas (such as V1, V2, V4, IT), 3) deeper layers excel at detecting complex features, and 4) local receptive fields. \n\n---\n> __Re.9)__ Multivariate p-general... \"the reference position of the RF\": Do you mean \"reference position of a pixel in the RF?\". If not, I am confused.\n\nIn our context, the reference position, represented by $\\mathbf{s}$, is a specific point within this receptive field, with $ s_0 $ as its center. The term $ \\Delta \\mathbf{s} = \\mathbf{s} - s_0 $ measures deviation from this central point. We use this framework to define the receptive field in our model, which is essential for introducing the MPND concept. We'll ensure to clarify this point further in our revised manuscript as following. \n\n(before) Let $\\mathbf{s}$ be the $d$-dimensional random vectors that represent the reference position of the RF. \n\n(after) Let $\\mathbf{s}$ represent the $d$-dimensional random vectors indicating specific points within RF. \n\n---\n> __Re.10)__ Eqn 1: Is the superscript \"p\" standard notation? I think I usually see L_p as || ||_p (subscript only).\n\nAs we noted in the text, $\\| \\cdot \\|_p^p$ denotes the $L_p$-norm raised to the $p$-th power (e.g. $(|| ||_p)^p$, ).\n\n---\n> __Re.11)__ Covariate matrix C: does this raise dimensionality issues, since C includes d^2 new parameters per filter? (doubles the number of free parameters I think).\n\nWe would like to clarify that, $d$ indicates the spatial dimensionality, and in this paper $d=2$. Thus, $C$ is 2$\\times$2 matrix. For the doubling of free parameters, we have tried our best to explain details in __Re.22)__.\n\n---\n> __Re.12)__ Fig 1 e: this shows up too small on a printed page.\n\nThank you. We increased the size of Fig. 1e in the revised manuscript.\n\n___\n> __Re.13)__ Fig 1 f: Did you try p < 2? It looks like the masks converge to rectangles (all weights in mask the same) at low p, so that the difference between 4 and 16 is slight.\n\nThank you for pointing out the behavior of masks at lower values of $p$. In our appendix (Appendix A.16), we have visualizations for $p<2$. Specifically, $p=1$, the mask forms a diamond shape, and for $p$ less than 1, it shifts to a cross-like shape. This change highlights the influence of  $p$ on the mask geometry. In fact, during the training, $p$ lower than 2 can also emerge. \n\nWhile the masks for $p=4$ and $p=16$ may appear similar, converging towards rectangles, as shown in Table 1, these values as initialization parameters can still lead to significant differences in performance. This suggests that even subtle variations in the shape of the mask can have a meaningful impact on the model's effectiveness.\n\n---\n> __Re.14)__ Just after eqn 4 \"C and p are trainable\": I do not see how to do this. Is it explained in the paper?\n\nWe used standard backpropagation, for detail see __Re. 2)__.\n\n---\n> __Re.15)__ \"mask take one\": I stumbled on this. Clearer might be \"equal one\", or \"have the value one\". Also, maybe note that this is the limit as p increases, and in fact is roughly attained at p = (some value).\n\nWe appreciate your review. \nFirst, we have revised our terminology to use \u201cequal one\u201d instead of \u201cmask take one\u201d.\nSecond, theoretically, $L_{p}$ mask converges to a binary mask as p approaches infinity. However, as shown in Fig. 1, we observe that $L_{p}$ mask becomes a binary mask for sufficiently large $p$. We have included this discussion in the second last paragraph of Section 3."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485932108,
                "cdate": 1700485932108,
                "tmdate": 1700487421733,
                "mdate": 1700487421733,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2Qv8BUSTsD",
                "forum": "jz35igczhm",
                "replyto": "gWi1dvhNtG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Official Comment by Authors - 3"
                    },
                    "comment": {
                        "value": "> __Re.16)__ Sudoku: Perhaps explain why this is a good test case for the method (since it is not usual, and the usual image examples come later).\n\nIn response to your observation, we initially observed masks trained with usual images (as shown in __Figure 2 f and g__). This led us to conclude that the adaptability of $L_p$-masks could be advantageous due to their ability to create varied structured RFs. We identified the Sudoku task as an effective way to highlight these benefits, especially in our ablation study comparing column and row accuracy. Presenting the Sudoku task first was a strategic choice to help readers understand the $L_p$-convolution mechanism before demonstrating its performance enhancements and brain alignment.\n\n---\n> __Re.17)__ Fig 3 b: the line colors/labels are unclear in these subplots. Perhaps make them bigger, or use dashed lines for some cases, or change to brighter colors.\n\nThank you for the suggestion. We\u2019ve changed with bigger, dashed lines.\n\n---\n> __Re.18)__ Fig 4: What is the definition of \"distortion\"?\n\n\nIn this work, the concept of \u201cdistortion\u201d, denoted by $\\gamma$, is introduced to quantify the extent of deformation in the shape of a mask. This parameter specifically measures the degree of asymmetry in the mask. A symmetric mask is characterized by $\\gamma = 1$, and as $\\gamma$ increases, the mask becomes increasingly asymmetric.\n\nUpon performing Singular Value Decomposition (SVD) on a $2 \\times 2$ covariance matrix $\\mathbf{C}$ of the distribution, two singular values, $\\lambda_1$ and $\\lambda_2$, are obtained. In a symmetric distribution, these singular values, $\\lambda_1$ and $\\lambda_2$, are identical. However, as the distribution becomes asymmetric, or distorted, these values diverge from each other (See __Appendix A.6__).\n\n---\n> __Re.19)__ Fig 4 a: The different labels (alpha, theta) on the two sides of the mosaic are hard to decipher, especially on a printed page. Perhaps make the mosaic horizontal, or make labels larger, or break up the sets of 9 boxes with bolder lines, or provide clearer guidance in the caption.\n\nThank you for the suggestion. We have enlarged Fig. 4a in the revised manuscript.\n\n---\n> __Re.20)__ Fig 4 a: what role do diagonal masks play in the Sudoku networks, given the problem's horizontal-vertical-box structure?\n\nThank you for this intriguing question. As observed in the 3rd column of Fig 4b, most diagonal masks have diminished, leading us to believe that diagonal masks do not play a significant role in the context of the Sudoku task. However, this observation presents an exciting opportunity for future experiments. For instance, in tasks like the BINGO game, which may require diagonal pattern recognition, diagonal masks could potentially play a crucial role.\n\n---\n> __Re.21)__ Fig 4 a: A crucial question for me: These RFs look a lot like what we often see in CNN papers. Is the L_p method generating something novel, or is it a new way of getting to what already happens?\n\n$L_p$-Convolution enforces Rfs into explicit structural constraints, whereas RFs in conventional CNNs emerge naturally. Please see __Re. 1)__ for details.\n\n---\n> __Re.22)__ Comparisons with base models: It appears that adding an L_p mask at each filter effectively doubles the free parameter count while holding the filter size fixed. Might this account for the difference in accuracy scores?\n\nThank you for your insightful question. To clarify, \"d\" in this context refers to the dimension of the 2D space, which means the shape of C needed to create the mask is 2x2. To aid understanding, let's calculate the number of parameters for three cases, assuming there are \"c\" channels:\n\n1. **(3x3), (Base) Conv**: The number of parameters here is c x 3 x 3, which equals 9c.\n2. **(7x7), (Large) Conv**: For this model, the number of parameters is c x 7 x 7, totaling 49c.\n3. **(7x7), $L_p$-Conv**: In this case, the number of parameters is c x (7 x 7 + 5) = 54c. The $L_p$-Convolution requires a mask for each channel, and each mask has 5 free parameters (comprising of \"p\" and the elements of the C matrix, which is 2x2), leading to an additional c x 5 parameters.\n\nIn the above example, the free parameter increase in '(Base)Conv' to '(Large)Conv' is over __x5__ (9c vs. 49c) whereas '(Large)Conv' to '$L_p$-Conv' is __x1.1__. However, simply increasing free parameters doesn't guarantee the performance gain, as can be seen in row 1 vs row 2 in Table 1. However, $L_p$-Conv parameters stably achieve performance gains with a small increase in free parameters. This analysis suggests that factors beyond just parameter count are contributing to the observed differences in performance.\n\n---\n> __Re.23)__ Section 7: This looks like it should appear earlier in the paper - it is background.\n\nIn response to your comment, Section 7 was initially upfront but was later repositioned to improve the paper's readability and logical progression. Thank you for your recommendation. We deeply appreciate your thorough review!"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700486419073,
                "cdate": 1700486419073,
                "tmdate": 1700486419073,
                "mdate": 1700486419073,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fWpUY96kqC",
                "forum": "jz35igczhm",
                "replyto": "2Qv8BUSTsD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Reviewer_Bf1L"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Reviewer_Bf1L"
                ],
                "content": {
                    "title": {
                        "value": "Response to Authors' responses"
                    },
                    "comment": {
                        "value": "My thanks to the authors for their comprehensive responses to all the reviewers. They reinforce my positive assessment as to the quality of the paper."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700682662587,
                "cdate": 1700682662587,
                "tmdate": 1700682662587,
                "mdate": 1700682662587,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "LwOUvp1cm9",
            "forum": "jz35igczhm",
            "replyto": "jz35igczhm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_UBiz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_UBiz"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, large convolution kernels are masked by multiplication with a parameterizable function that can range from a 2D Gaussian to a more box-like function. The mask parameters are trained with the rest of the network. Suitable masks are learned in a network that solves Sudoku puzzles. Adding this method to several common architectures improves their image classification performance. Activity in these trained networks is compared with mouse visual cortex activity via representational similarity analysis, and it is found that more Gaussian-like masks tend to produce higher peak similarities between mouse and model representations."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The method is interesting, elegant, effective, and as far as I know novel. The paper is clear and well organized. The experiments make sense for demonstrating several different properties of the model, and the results seem convincing."
                },
                "weaknesses": {
                    "value": "I don\u2019t find much to complain about but I will do my best. \n\nIt\u2019s interesting that the mask is more general than a Gaussian function, but the benefits of non-Gaussian versions seem less clear (e.g. Table 1). I don\u2019t know whether I should actually use this mask rather than a simpler Gaussian one. \n\nThe p value that sets the smoothness of the mask seems not to change much during training, judging by the visualizations in Figure 2 and the performance differences due to different initializations of p in Table 1. I wasn\u2019t sure that it was actually being optimized effectively. If it were optimized more successfully then it seems that a method other than initialization might be needed to apply pressure on p one way or another (such as a loss term)."
                },
                "questions": {
                    "value": "In the Figure 1g caption please clarify which comparisons were tested and whether there was a correction for multiple comparisons.  \n\nPage 8 says the models were compared with data from multiple subregions of mouse V1, but the appendix shows VISal, VISam, etc. as well as VISp. Is V1 a typo on page 8? \n\nPlease elaborate on the logic of the definition of functional synapses in the 3rd paragraph of A.2. Is it meant to relate to biological functional synapses? How? \n\nIn Figure 7 b and c, the middle-row (untrained) receptive fields have a grid structure and the ones in the bottom rows (trained) mostly have a bright line along the bottom. Could these phenomena please be explained?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3144/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813107271,
            "cdate": 1698813107271,
            "tmdate": 1699636261667,
            "mdate": 1699636261667,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9hTibrsSPK",
                "forum": "jz35igczhm",
                "replyto": "LwOUvp1cm9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your positive and constructive feedback! We've further improved the clarity and readability of our paper. Please find our responses to each suggestion below.\n\n---\n> __Re.1)__ It\u2019s interesting that the mask is more general than a Gaussian function, but the benefits of non-Gaussian versions seem less clear (e.g. Table 1). I don\u2019t know whether I should actually use this mask rather than a simpler Gaussian one.\n\nWe appreciate your comment. While we recommend using the Gaussian version (p=2) as shown in Table 1 for its overall effectiveness, note, that specific scenarios, such as with AlexNet, benefit more from a non-Gaussian version (p=16). This suggests that the Gaussian version isn't universally superior.\n\n---\n> __Re.2)__ The p-value that sets the smoothness of the mask seems not to change much during training, judging by the visualizations in Fig. 2 and the performance differences due to different initializations of p in Table 1. I wasn\u2019t sure that it was actually being optimized effectively. If it were optimized more successfully then it seems that a method other than initialization might be needed to apply pressure on p one way or another (such as a loss term).\n\nAppreciate your feedback. The result attached in __Appendix A.17__ and table below confirms that the parameter $p$ is actively optimized during training:\n\n| |Lp2|Lp4|Lp8|Lp16|\n|-|-|-|-|-|\n|CIFAR100|1.80~2.07|3.59~4.14|7.36~8.25|14.99~16.73|\n|TINYIMNET|1.72~2.08|3.26~4.10|6.61~8.47|13.77~18.86|\n\nHowever, the variation in post-training $p$ values was not dynamic enough to oscillate across different initialization conditions. Thus, your idea of applying a dedicated loss function to identify the optimal $p$ is very appealing. Thank you for the clever idea!\n\n---\n> __Re.3)__ In the Fig.1g caption please clarify which comparisons were tested and whether there was a correction for multiple comparisons. \n\nWe appreciate the reviewer's expert insight. Since we didn't correct for multiple comparisons, we conducted Holm-Bonferroni correction[1] in __Appendix A.19__.\n\n|p-values|Mouse V1|Train+Image|Train+Noise|Untrain+Noise|Untrain+Image|\n|-|-|-|-|-|-|\n|**Mouse V1**|-|*|*|***|***|\n|**Train+Image**|0.0110|-|n.s|***|***|\n|**Train+Noise**|0.0106|0.76|-|***|***|\n|**Untrain+Noise**|1.23e-15|4.13e-28|1.49e-25|-|***|\n|**Untrain+Image**|8.94e-14|1.59e-25|6.73e-23|1.39e-22|-|\n\nWe believe our results are now more robust and solid with the suggested correction.\nWe also updated the Fig. 1g caption as follows:\n\n\u201cUsing Welch's t-test with Holm-Bonferroni's multiple comparisons correction, all possible combinations between groups were statistically significant (p-value$<$0.05) except for `n.s.' (non-significant) denoted in the figure.\u201d\n\n[1] Holm, Sture. \"A simple sequentially rejective multiple test procedure.\" Scandinavian journal of statistics (1979).\n\n---\n> __Re.4)__ Page 8 says the models were compared with data from multiple subregions of mouse V1, but the appendix shows VISal, VISam, etc. as well as VISp. Is V1 a typo on page 8?\n\nThank you for the correction. The correct term is 'VC', not 'V1', and we revised notations including  __Section 6, Appendix A.12  and Fig. 5__. We are grateful for your expertise and for guiding us to address our areas of deficiency.\n\n---\n> __Re.5)__ Please elaborate on the logic of the definition of functional synapses in the 3rd paragraph of A.2. Is it meant to relate to biological functional synapses? How?\n\nYes, the definition aligns with biological functional synapses, facilitating a direct comparison between biological and artificial systems. In biological contexts, functional synapses are often identified through Z-score-based activity thresholding in calcium recordings, as noted in our revised manuscript's footnote 5 under section A.2. We adopted this approach for our artificial system.\n\nTo clarify this concept, we\n- added new figures illustrating functional synapses in __Appendix A.14 &A.15__,\n- clarified the wording in the third paragraph of __Appendix A.2__, as follows: \"Since spatial connectivity pattern in the biological synapse is measured by the functional calcium activities and given as coordinates, we applied a similar approach to that of CNN layers.\"\n\n---\n> __Re.6)__ In Fig. 7 b&c, the middle-row (untrained) receptive fields have a grid structure and the ones in the bottom rows (trained) mostly have a bright line along the bottom. Could these phenomena please be explained?\n\nThank you for pointing out these phenomena. In the trained model, the bright line could be a result of typical shading patterns in images, as illustrated in Fig. 7b. Its presence in noise inputs, however, hints at potential training limitations related to lack of rotation or vertical flip augmentations. For the untrained model, the grid pattern, as shown in Appendix A.15, Fig. 12d, is an ongoing area of study. Your question has importantly highlighted the role of top-down shading in image processing, paving the way for further exploration."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485195157,
                "cdate": 1700485195157,
                "tmdate": 1700485195157,
                "mdate": 1700485195157,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OPZPWWOjrO",
                "forum": "jz35igczhm",
                "replyto": "9hTibrsSPK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Reviewer_UBiz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Reviewer_UBiz"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your responses. They address my questions well, except that the last point still seems unclear. Overall I think the paper has improved mainly in response to other reviewers' comments (\\which I appreciated)."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700678165329,
                "cdate": 1700678165329,
                "tmdate": 1700678165329,
                "mdate": 1700678165329,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oZWfsWndEY",
            "forum": "jz35igczhm",
            "replyto": "jz35igczhm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_YKuY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_YKuY"
            ],
            "content": {
                "summary": {
                    "value": "The Authors introduce the so-called Lp-convolution that is based on the multivariate p-generalized normal distribution to address the gap between the artificial and biological receptive fields. The Authors study the properties of the Lp-convolution and provide evidence that the proposal benefits, for instance, large kernel sizes in a classification task using previous well-studied architectures (e.g., AlexNet) with the CIFAR-100 and TinyImageNet datasets."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The manuscript has been well-written, and the ideas behind the paper have been legibly presented with an experimental part following the requirements of the ICLR conference.\n\nI have found the most attractive part of the paper in section 6, where The Authors evaluated the alignment between biological\nand artificial models."
                },
                "weaknesses": {
                    "value": "I do not see particular weaknesses in the manuscript."
                },
                "questions": {
                    "value": "Could the Authors comment on how their work is related to the concept of foveation?\n\nhttps://doi.org/10.1007/s11263-016-0898-1"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3144/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3144/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3144/Reviewer_YKuY"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3144/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698889021913,
            "cdate": 1698889021913,
            "tmdate": 1699636261596,
            "mdate": 1699636261596,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3fwWLeiqCT",
                "forum": "jz35igczhm",
                "replyto": "oZWfsWndEY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you to the reviewer for the highly encouraging feedback and for finding merit in our brain alignment experiment!  \nWe also express our gratitude for the introduction of the following insightful paper.\n\n---\n> __Re.1)__ Could the Authors comment on how their work is related to the concept of foveation? https://doi.org/10.1007/s11263-016-0898-1\n\nWe thank the reviewer for introducing this insightful paper. It has been enlightening to read and has significantly influenced our future research directions, encouraging us to explore new methodologies. This paper and our work share a common theme of adopting concepts from human visual processing to enhance computational techniques.\n\nOperationally, both approaches modify the visual receptive area (patch or kernel) as it moves away from the center fixation point. __While Lp-convolution (p=2) can be seen as reducing brightness, Foveation applies blurring.__\n\nThese differences, stemming from __the initial stages of human visual processing in Foveation__ and __the local connectivity patterns of the visual cortex in Lp-convolution__, raise an exciting question: ___Could a blend of these approaches further enhance visual processing of artificial models?___ We are excited to explore this possibility in the future direction of our research."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700485018614,
                "cdate": 1700485018614,
                "tmdate": 1700485018614,
                "mdate": 1700485018614,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0Xr3rzFrip",
            "forum": "jz35igczhm",
            "replyto": "jz35igczhm",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_oxDe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3144/Reviewer_oxDe"
            ],
            "content": {
                "summary": {
                    "value": "In this submission, the authors propose to bridge the gap between artificial and biological visual receptive fields by introducing $L_p$ convolutions implemented modeled using the multivariate p-generalized normal distribution (MPND). The authors claim that it is possible to model a spectrum of receptive fields with increasing resemblance to biological receptive fields by tuning the $p$ and $\\sigma$ parameters of MPND. On a Sudoku quiz benchmark, the authors show that L-p convolution is capable of learning diversely shaped receptive fields. On a couple of image classification benchmarks (CIFAR-100 and Tiny ImageNet), the authors show that tuning $p$ in various convolutional architectures integrated with $L_p$ convolution leads to classification performance gains. Representational similarity analysis testing the neural encoding ability of $L_p$ convolutional networks at different values of $p$ shows that networks with smaller $p$ (which are characteristic of biological RFs modeled with $L_p$ convolution) are better encoders of mouse visual representations."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ This submission proposes a very interesting characterization of the disparities between artificial and biological receptive fields using multivariate p-generalized normal distributions (MPNDs).\n+ The authors have worked rigorously on their model comparison experiments by testing all models with different random initializations and adequate statistical testing to highlight significant differences.\n+ It is really interesting that $L_p$ convolutions with smaller $p$ values are also better encoders of mouse visual representations recorded from V1 in response to natural images.\n+ Thanks to the authors for releasing code for reproducing their results."
                },
                "weaknesses": {
                    "value": "- The paper is quite hard to read. Especially the sections introducing $L_p$ convolution (sections 2 and 3) need to be written with much more clarity to make them more accessible. Currently, there are issues such as an abundance of notations, symbols being introduced after their first use, etc. that make it difficult to understand exactly how $L_p$ convolution works and models the spectrum from biologically resembling to artificial receptive fields. \n- I don't find the similarity of $L_p$ convolution with small p with mouse visual receptive fields to be very convincing. First of all, this seems like a qualitative comparison and is not an objective way to measure similarity to biological receptive fields. It also seems from Appendix A4 (Fig 7A) that the mouse functional synapses in V1 lack any visible structure representative of selectivity to low-level visual features. This is quite concerning as it makes one wonder whether these neurons are selective to low-level features as one would expect from V1 neurons. \n- There also seems to be an issue with both untrained and trained receptive fields of AlexNet's conv1 layer in the same figure. Untrained filters seem to have a peculiar checkerboard-like structure that one wouldn't expect in randomly-initialized kernels. Re. pretrained filters, in the AlexNet paper [1] the authors plot the filters in the first convolution layer of an AlexNet trained on ImageNet-1k in Figure 3 of their paper. There is a big gap in terms of how selective their filters are in comparison to the filters visualized in the current submission in Figure 7 of Appendix A4. Could the authors please explain this discrepancy?\n- Overall, I believe that in the current state, there are several open issues such as the (key) ones I highlighted here in my review that need to be fixed in order to push this paper above the acceptance threshold.\n\nReferences:\n1. Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25."
                },
                "questions": {
                    "value": "Please refer to the weaknesses section in my review above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 5,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3144/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698948877141,
            "cdate": 1698948877141,
            "tmdate": 1699636261494,
            "mdate": 1699636261494,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5D7SN8X2Vi",
                "forum": "jz35igczhm",
                "replyto": "0Xr3rzFrip",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback and guidance. We have significantly enhanced the clarity and readability of our work in response to the reviewers' comments. Below are our point-by-point responses to each suggestion.\n\n---\n> __Re.1)__ The paper is quite hard to read. Especially the sections introducing $L_p$ convolution (sections 2 and 3) need to be written with much more clarity to make them more accessible. Currently, there are issues such as an abundance of notations, symbols being introduced after their first use, etc. that make it difficult to understand exactly how $L_p$ convolution works and models the spectrum from biologically resembling to artificial receptive fields (RFs).  \n\nWe appreciate your review. We have revised Section 2 and Section 3.\nFirst, we have simplified the content by excluding notations that were previously unused, and have added clear explanations for all notations that are used. (e.g., we remove $\\varphi$, and we add description for $C$ and $W_i$) \nSecond, we clarify the relationship between RF and $L_p$-convolution in the paragraph below Equation 3.\n\n---\n> __Re.2)__ I don't find the similarity of $L_p$ convolution with small p with mouse visual RFs to be very convincing. First of all, this seems like a qualitative comparison and is not an objective way to measure similarity to biological RFs. It also seems from Appendix A4 (Fig 7A) that the mouse functional synapses in V1 lack any visible structure representative of selectivity to low-level visual features. This is quite concerning as it makes one wonder whether these neurons are selective to low-level features as one would expect from V1 neurons.\n\nThank you for your insightful feedback regarding the comparison of $L_p$-convolution with small $p$ to mouse visual RFs. We appreciate your concern about the qualitative nature of this comparison and the observations from Appendix A4 (Fig 7A).\nIn response to your comments, we would like to clarify our approach and make some adjustments to our manuscript for better clarity. ___We realize that our definition of \"receptive fields\" might have been misleading.___ Our definition aligns more with the engineering perspective prevalent in CNNs, especially for AI/ML audience at ICLR. Our adjustments in the manuscript are as follows:\n\n__Clarify the definition in the main text (Section 2):__ To clarify our definition of RF, we promoted footnote 1 to the main text, with bold highlighted at local connectivity patterns.\n- (new): While the concept of RF generally encompasses sensory-level inputs and adjacent layers, in this paper, we specifically refer to __RF as local connectivity patterns__ between neurons in adjacent layers.\n\n__Clarify the description in the appendix (Figure 7 legend):__ To further clarify, we have inserted a note in the figure legend.\n- (new): The receptive field discussed in this figure specifically refers to the spatial connectivity patterns of synapses. Note that this differs from receptive fields typically associated with low-level visual feature selectivity. \n\n---\n> __Re.3)__ There also seems to be an issue with both untrained and trained RFs of AlexNet's conv1 layer in the same figure. Untrained filters seem to have a peculiar checkerboard-like structure that one wouldn't expect in randomly-initialized kernels. Re. pretrained filters, in the AlexNet paper [1] the authors plot the filters in the first convolution layer of an AlexNet trained on ImageNet-1k in Fig. 3 of their paper. There is a big gap in terms of how selective their filters are in comparison to the filters visualized in the current submission in Fig. 7 of Appendix A4. Could the authors please explain this discrepancy?\n\nWe appreciate the thorough comments from the reviewer, grounded in deep insights. The visualization of kernels in Fig. 3 in the original AlexNet paper and our functional synapse connectivity pattern as RF differ due to methodological distinctions. \n\nTo clearly convey the main difference, we have added additional figures in revised manuscript __Appendix A.14 & A.15__. \n- Observing __Fig. 11 a&b__, one can see kernel RFs similar to those in the AlexNet paper Fig. 3. In this study, the functional RF we refer to is an effort to visualize and observe the functionally active spatial connectivity pattern when actual input is present. \n- __Fig. 11 d&e, and Fig. 12 d&e__ correspond to individual images in __Appendix A.4__. We hope our explanation sufficiently resolves the discrepancy between the original AlexNet RF and ours.\n\n---\n> __Re.4)__ Overall, I believe that in the current state, there are several open issues such as the (key) ones I highlighted here in my review that need to be fixed in order to push this paper above the acceptance threshold.\n\nWe believe the key issue arises from our definition of RFs in the context of CNNs from an engineering perspective. We hope that these revisions and clarifications will resolve any misunderstandings and align our findings more closely with the audience."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700484787781,
                "cdate": 1700484787781,
                "tmdate": 1700484787781,
                "mdate": 1700484787781,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sj2Olr6mvC",
                "forum": "jz35igczhm",
                "replyto": "0Xr3rzFrip",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3144/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A gentle reminder"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nWe've updated our manuscript in response to your valuable feedback, focusing on improving the accessibility of sections 2 and 3 and clarifying our definition of the receptive field. We're keen to know if these revisions align with your expectations. Your further thoughts would be greatly appreciated."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3144/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637680748,
                "cdate": 1700637680748,
                "tmdate": 1700645673185,
                "mdate": 1700645673185,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]