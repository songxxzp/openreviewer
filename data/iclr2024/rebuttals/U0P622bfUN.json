[
    {
        "title": "Federated Generative Learning with Foundation Models"
    },
    {
        "review": {
            "id": "2ZurMVHvCB",
            "forum": "U0P622bfUN",
            "replyto": "U0P622bfUN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1/Reviewer_zu8q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1/Reviewer_zu8q"
            ],
            "content": {
                "summary": {
                    "value": "The Federated Generative Learning (FGL) framework offers a novel approach to federated learning, leveraging foundational generative models like Stable Diffusion to generate training data from prompts shared by clients. Clients contribute class-level or instance-level prompts, encapsulating key features of their local data. The server, in turn, amalgamates these prompts and synthesizes corresponding training data for global model training. This approach trims down communication costs since only concise prompts, and not bulky gradients or models, are transferred. This system also boasts robustness to data diversity and has demonstrated superior performance \u2013 with just one communication round, it outdid FedAvg's 200 rounds in accuracy. When trialed on skewed ImageNet100 distributions, FGL exceeded FedAvg's performance by 30% in just five communication rounds. Apart from being efficient, FGL also enhances privacy, as prompts reveal lesser private data than traditional methods. Evaluations confirmed no private data memorization in the synthetic images and an enhanced resilience against membership inference attacks. However, challenges persist with non-IID data, intricate domains, and the potential risks associated with prompts."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tNovel idea of using foundation models to synthesize training data for federated learning, enabling low communication costs and better privacy.\n2.\tCompelling experimental results demonstrating accuracy improvements over traditional FedAvg, especially with skewed data distributions.\n3.\tThorough analysis and quantification of privacy benefits, showing reduced memorization and vulnerability to membership inference attacks."
                },
                "weaknesses": {
                    "value": "1.\tThe evaluation of the Federated Generative Learning (FGL) framework is limited to simpler domains like ImageNet and doesn't extend to other areas, casting doubt on whether prompts can encapsulate complexity.\n2.\tWhile FGL aids in data generation for non-IID data, achieving congruence with a global distribution is yet to be addressed. \n3.\tSecurity risks of prompts require more analysis. Could prompts be reverse-engineered to obtain private data?\n4.\tThe framework hasn't been benchmarked against other federated learning methods that employ generative models."
                },
                "questions": {
                    "value": "please refer to the weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698543827436,
            "cdate": 1698543827436,
            "tmdate": 1699635924030,
            "mdate": 1699635924030,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mofNXJXZ39",
                "forum": "U0P622bfUN",
                "replyto": "2ZurMVHvCB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer zu8q [1/2]"
                    },
                    "comment": {
                        "value": "Thank you for your constructive comments. We hope the following clarifications can address your concerns. \n\n**Q1: The evaluation of the Federated Generative Learning (FGL) framework is limited to simpler domains like ImageNet and doesn't extend to other areas, casting doubt on whether prompts can encapsulate complexity.** \n\n**A1**: To further validate the effectiveness of our method, we conducted experiments on several fine-grained image classification datasets, namely CUB-200, Stanford Cars, and also the satellite image dataset EuroSAT. CUB-200 is a challenging dataset consisting of 200 bird species, while Stanford Cars contains 16,185 images belonging to 196 classes of cars. As for EuroSAT, the official dataset did not provide predefined training and testing splits, so we performed a split in an 8:2 ratio. The size of fine-grained recognition datasets is typically smaller compared to general image classification datasets. In previous work, a common practice is to utilize a pretrained model that has been trained on the ImageNet dataset. In this study, we present two approaches: training the model from scratch and loading a pretrained ResNet34 model.\nAs shown in the table, our method achieves excellent performance even in these challenging domains. This can be attributed to the fact that regardless of the magnitude of domain differences, pretraining a well-performing model on our synthetic data is beneficial for the downstream federated tasks. We have added these results in the appendix.\n\n| |               |         |       |             |              ||  |             |       |  |\n|:---------------:|:-------------:|:-------:|:------------:|:-----------:|:------------:|:---------------:|:--------------:|:-----------:|:-----:|:-----------:|\n|   Prompt type   | Training type | Dataset | FedAvg,$\\beta=0.01$ |FedAvg, $\\beta=0.5$ | FedAvg (IID) |    Ours (one-shot)              |  Ours (5-round) ,$\\beta=0.01$  |Ours (5-round),$\\beta=0.5$ |  Ours (5-round),IID  |        Centralized     |\n|     instance    |    scratch    | CUB-200 |     35.04    |    36.61    |     36.62    |      44.17      |      64.53     |    69.19    | 71.01 |    48.31    |\n|     instance    |   pretrain    | CUB-200 |     78.98    |    79.08    |     78.48    |      54.02      |      75.13     |    78.96    | 80.72 |    81.77    |\n|      class      |    scratch    | CUB-200 |     35.04    |    36.61    |     36.62    |      45.34      |      67.66     |     71.9    | 73.33 |    48.32    |\n|      class      |   pretrain    | CUB-200 |     78.98    |    79.08    |     78.48    |      52.73      |      74.68     |     78.7    | 80.32 |    81.77    |\n|      class      |    scratch    |   Cars  |     55.18    |    42.43    |     44.48    |      54.48      |      83.31     |    87.22    | 88.07 |    64.72    |\n|      class      |   pretrain    |   Cars  |     87.71    |    88.91    |     88.96    |      60.55      |      87.31     |    90.05    | 90.73 |    91.21    |\n|      class      |    scratch    | EuroSAT |     43.94    |    74.48    |     84.87    |      38.37      |      37.59     |    82.94    | 91.01 |    94.31    |\n\n\n\n**Q2: While FGL aids in data generation for non-IID data, achieving congruence with a global distribution is yet to be addressed.**\n \n**A2**: Thank you for your valuable feedback. We acknowledge that FGL is effective in generating data for non-IID scenarios, aligning it with a global distribution (e.g., IID settings) also works in our experiments (see Table 1 for IID results). \n\n\n**Q3: Security risks of prompts require more analysis. Could prompts be reverse-engineered to obtain private data?**\n\n**A3**:  During the communication phase, traditional Federated Learning (FL) methods typically transmit model parameters or gradients. However, these parameters can be vulnerable to adversarial attacks and model inversion attacks if intercepted by an adversary. To enhance security, some FL methods utilize prompts for communication. However, the potential for attackers to reconstruct private data using prompts has received limited research attention, both in black-box and white-box scenarios.\nRecent work[1,2] has identified risks associated with the reconstruction of pretrained data in Diffusion models. Nevertheless, there is currently no available method that can solely reconstruct previously unseen private data in Diffusion models based solely on prompts. This presents an interesting and promising research direction for future investigations.\nConsequently, considering the lack of research in this area, our method can be regarded as relatively safe and privacy-preserving.\n\n[1]Shen, Xinyue, et al. \"Prompt Stealing Attacks Against Text-to-Image Generation Models.\" arXiv preprint arXiv:2302.09923 (2023).\n\n[2]Carlini, Nicolas, et al. \"Extracting training data from diffusion models.\" 32nd USENIX Security Symposium (USENIX Security 23). 2023."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700236063921,
                "cdate": 1700236063921,
                "tmdate": 1700236063921,
                "mdate": 1700236063921,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DMdGpc6aeM",
                "forum": "U0P622bfUN",
                "replyto": "2ZurMVHvCB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer zu8q [2/2]"
                    },
                    "comment": {
                        "value": "**Q4: The framework hasn't been benchmarked against other federated learning methods that employ generative models.**\n\n**A4**: Unfortunately, we were unable to find any existing methods in the literature that directly address our specific setting, making it difficult to perform a fair comparison. In light of this, and following the suggestions of other reviewers, we conducted experiments using various types of generative models to demonstrate the applicability of our proposed method. To investigate the impact of various generative models on the results, we followed the setting in [1]. Our experiments primarily focus on three prevalent conditional diffusion models: DiT[2], GLIDE[3], and Stable Diffusion. We use these off-the-shelf models to generate synthetic images. Specifically, for GLIDE and Stable Diffusion, the prompt was configured as \"a photo of {label name}, real-world images, high resolution.\" For DiT, the input comprised the label ID corresponding to the ImageNet1k dataset. The images synthesized by DiT and GLIDE are of dimensions 256x256, whereas those produced by Stable Diffusion are of dimensions 512x512. As shown in the following table, even when we vary the foundation models used in our method, FGL consistently outperforms FedAvg by a significant margin. This observation serves as evidence for the generality of our approach. We have added these results in the appendix.\n\n|           Method          | one-shot | 5-round, beta=0.01 | 5-round, beta=0.5 |    IID   |\n|:-------------------------:|:--------:|:------------------:|:-----------------:|:--------:|\n| Ours w/  Stable Diffusion | **85.2** |      **82.8**      |       **94.1**      | **95.6** |\n|       Ours w/ Glide       |    79.0    |        76.2        |        89.4       |   89.4   |\n|        Ours w/ Dit        |   76.2   |        74.6        |        90.2       |   92.8   |\n|     FedAvg (120-round)    |     -    |        51.6        |        75.1       |   79.2   |\n\n[1] Li, Zheng, et al. \"Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?.\" arXiv preprint arXiv:2305.12954 (2023).\n\n[2] Nichol, Alex, et al. \"Glide: Towards photorealistic image generation and editing with text-guided diffusion models.\" arXiv preprint arXiv:2112.10741 (2021).\n\n[3]Peebles, William, and Saining Xie. \"Scalable diffusion models with transformers.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700236100046,
                "cdate": 1700236100046,
                "tmdate": 1700236100046,
                "mdate": 1700236100046,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6JeFYeADhe",
                "forum": "U0P622bfUN",
                "replyto": "2ZurMVHvCB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "With the hope that our response addresses your concerns"
                    },
                    "comment": {
                        "value": "Dear Reviewer zu8q,\n\nAs the discussion period is closing, we sincerely look forward to your feedback. The authors deeply appreciate your valuable time and efforts spent reviewing this paper and helping us improve it.\n\nPlease also let us know if there are further questions or comments about this paper. We strive to improve the paper consistently, and it is our pleasure to have your feedback!\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700670736076,
                "cdate": 1700670736076,
                "tmdate": 1700670736076,
                "mdate": 1700670736076,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VulmbS3YYc",
            "forum": "U0P622bfUN",
            "replyto": "U0P622bfUN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1/Reviewer_ZNb2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1/Reviewer_ZNb2"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses efficiency and client-shift issues in federated learning by harnessing generative foundation models. Unlike traditional approaches that communicate model parameters, this work exploits clients to send instance-level or class-level prompts, generated by a pre-trained captioning model, to the server. The server aggregates these prompts to produce a proxy dataset via a pre-trained generative model, enabling standard federated learning on this dataset. The server then dispatches the refined weights back to the clients. Empirical evaluations underscore the efficacy of the proposed approach."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed approach significantly reduces communication costs compared to traditional parameter transmission.\n2. By leveraging foundation models to synthesize proxy data, the authors effectively mitigate the client-shift problem.\n3. A variety of experimental settings across four datasets demonstrate the robustness and effectiveness of the proposed method."
                },
                "weaknesses": {
                    "value": "1. The training framework is predominantly tailored for image datasets, limiting its applicability.\n2. The method heavily depends on the congruence between the captioning and generative models, making it challenging to ensure the proxy dataset's distribution aligns with the private data.\n3. The experimental setup, with only five clients, may not adequately represent real-world scenarios; expanding the evaluation to include 50 or 100 clients could provide more insightful results.\n4. The comparison to a single baseline, FedAvg, falls short; including comparisons to advanced Federated Learning frameworks could better highlight the proposed method's effectiveness.\n5. Table 2 shows the proposed method outperforming centralized learning significantly; a thorough explanation of this phenomenon is warranted."
                },
                "questions": {
                    "value": "1. I wonder if the approach cam be applied to other types of datasets, besides the image datasets.\n2. What the experimental results would be when the number of clients becomes bigger, e.g., 100."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698549593720,
            "cdate": 1698549593720,
            "tmdate": 1699635923922,
            "mdate": 1699635923922,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9l46wbVYfG",
                "forum": "U0P622bfUN",
                "replyto": "VulmbS3YYc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ZNb2 [1/2]"
                    },
                    "comment": {
                        "value": "Thank you for your valuable time in reviewing our paper. Below are responses to your concerns. Please let us know if you require any further information, or if anything is unclear. \n\n**Q1: The training framework is predominantly tailored for image datasets, limiting its applicability.** \n\n**A1**: Our approach is based on existing generative models that are widely used in various domains, such as Computer Vision with Stable Diffusion and Natural Language Processing with GPTs. This means that our framework can easily be applied to other domains, including NLP. However, due to time constraints, we were unable to conduct additional experiments on NLP tasks. We believe that further research in this area would be valuable and should be pursued in the future. \n\n**Q2: The method heavily depends on the congruence between the captioning and generative models, making it challenging to ensure the proxy dataset's distribution aligns with the private data.** \n\n**A2**: To further validate the effectiveness of our method, we conducted experiments on several fine-grained image classification datasets, namely CUB-200, Stanford Cars, and also the satellite image dataset EuroSAT. CUB-200 is a challenging dataset consisting of 200 bird species, while Stanford Cars contains 16,185 images belonging to 196 classes of cars. As for EuroSAT, the official dataset did not provide predefined training and testing splits, so we performed a split in an 8:2 ratio. The size of fine-grained recognition datasets is typically smaller compared to general image classification datasets. In previous work, a common practice is to utilize a pretrained model that has been trained on the ImageNet dataset. In this study, we present two approaches: training the model from scratch and loading a pretrained ResNet34 model.\nAs shown in the table, our method achieves excellent performance even in these challenging domains. This can be attributed to the fact that regardless of the magnitude of domain differences, pretraining a well-performing model on our synthetic data is beneficial for the downstream federated tasks. \n\n| |               |         |       |             |              ||  |             |       |  |\n|:---------------:|:-------------:|:-------:|:------------:|:-----------:|:------------:|:---------------:|:--------------:|:-----------:|:-----:|:-----------:|\n|   Prompt type   | Training type | Dataset | FedAvg,$\\beta=0.01$ |FedAvg, $\\beta=0.5$ | FedAvg (IID) |    Ours (one-shot)              |  Ours (5-round) ,$\\beta=0.01$  |Ours (5-round),$\\beta=0.5$ |  Ours (5-round),IID  |        Centralized     |\n|     instance    |    scratch    | CUB-200 |     35.04    |    36.61    |     36.62    |      44.17      |      64.53     |    69.19    | 71.01 |    48.31    |\n|     instance    |   pretrain    | CUB-200 |     78.98    |    79.08    |     78.48    |      54.02      |      75.13     |    78.96    | 80.72 |    81.77    |\n|      class      |    scratch    | CUB-200 |     35.04    |    36.61    |     36.62    |      45.34      |      67.66     |     71.9    | 73.33 |    48.32    |\n|      class      |   pretrain    | CUB-200 |     78.98    |    79.08    |     78.48    |      52.73      |      74.68     |     78.7    | 80.32 |    81.77    |\n|      class      |    scratch    |   Cars  |     55.18    |    42.43    |     44.48    |      54.48      |      83.31     |    87.22    | 88.07 |    64.72    |\n|      class      |   pretrain    |   Cars  |     87.71    |    88.91    |     88.96    |      60.55      |      87.31     |    90.05    | 90.73 |    91.21    |\n|      class      |    scratch    | EuroSAT |     43.94    |    74.48    |     84.87    |      38.37      |      37.59     |    82.94    | 91.01 |    94.31    |\n\n**Q3: The experimental setup, with only five clients, may not adequately represent real-world scenarios; expanding the evaluation to include 50 or 100 clients could provide more insightful results.** \n\n**A3**:Thanks for your suggestion. We extended our analysis to include the results obtained from the ImageNette dataset with 50 and 100 clients. As depicted in the table, our method continues to exhibit superior performance compared to FedAvg across all scenarios. Additionally, the improvements achieved by our method remain significant. See more details in the Appendix.\n\n| # Client | FedAvg, $\\beta$=0.5 | FedAvg, IID | Ours (one-shot) | Ours (5-round), $\\beta$=0.5 | Ours (5-round), IID | Centralized |\n|:--------:|:----------------:|:-----------:|-----------------|:------------------------:|:-------------------:|-------------|\n|     5    |        75.0        |     79.2    |       85.2      |            94.0            |         95.6        |     92.2    |\n|    50    |        72.1        |      77.0     |       85.2      |           93.8           |         91.2        |     92.2    |\n|    100   |        70.1        |     67.2    |       85.2      |           92.8           |         93.2        |     92.2    |"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700235412781,
                "cdate": 1700235412781,
                "tmdate": 1700235412781,
                "mdate": 1700235412781,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kIQR51kLqb",
                "forum": "U0P622bfUN",
                "replyto": "VulmbS3YYc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer ZNb2 [2/2]"
                    },
                    "comment": {
                        "value": "**Q4: The comparison to a single baseline, FedAvg, falls short; including comparisons to advanced Federated Learning frameworks could better highlight the proposed method's effectiveness.** \n\n**A4**: We have compared the two popular FL methods, Moon[1] and Fedopt[2]. We conducted experiments on the ImageNette and ImageNet100 datasets, considering a scenario with 50 clients under non-IID settings (beta=0.5). To the best of our knowledge, there is currently no federated learning method that surpasses centralized training. However, our proposed method even outperforms centralized trained models in many scenarios (see Table 1 in main text). Therefore, as shown in this table, our method still outperforms other federated learning approaches. \n\n| Method | FedAvg | FedOpt | Moon | Ours (one-shot) | Ours (5-round) | \n|:----------------------:|:------:|:------:|:-----:|:---------------:|:--------------:|\n | ImageNette (beta=0.5) | 72.01 | 73.21 | 74.27 | 85.21 | 93.80 | \n| ImageNet100 (beta=0.5) | 40.13 | 41.25 | 41.43 | 48.31 | 72.67 |\n\n[1]Li, Qinbin, Bingsheng He, and Dawn Song. \"Model-contrastive federated learning.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.\n\n[2]Reddi, Sashank J., et al. \"Adaptive Federated Optimization.\" International Conference on Learning Representations. 2020.\n\n**Q5: Table 2 shows the proposed method outperforming centralized learning significantly; a thorough explanation of this phenomenon is warranted.** \n\n**A5**: This is because our method synthesizes a balanced dataset using all collected prompts during the first round of communication. We then pretrain a \"well-initialized\" model on this dataset. Once we have this well-initialized model, several rounds of communication can quickly bring the model to a good performance. In the first table, we present the results of directly loading a pretrained model on ImageNet. It can be observed that directly loading a pretrained model on ImageNet reduces the gap between our method and FedAvg. This is because the pretrained model provides a good starting point. However, training a pretrained model on ImageNet requires a significant computational cost on a dataset of 1.3M samples. In contrast, our method only requires training on a small amount of synthesized data to provide a well-initialized model, hence achieving better performance than models trained in a centralized manner."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700235455263,
                "cdate": 1700235455263,
                "tmdate": 1700235455263,
                "mdate": 1700235455263,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rBIpJVtNpZ",
            "forum": "U0P622bfUN",
            "replyto": "U0P622bfUN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1/Reviewer_wnsW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1/Reviewer_wnsW"
            ],
            "content": {
                "summary": {
                    "value": "- The main idea of the paper is to use prompts to \u201csummarize\u201d the client-side data in federated learning. These prompts are then sent to the central server and fed to a foundation generative model, with the hope that the generated data distribution is close to the client data distribution.\n- With this idea, federated learning can be made one-round or few-round to drastically reduce communication costs, where clients can just send over the prompts one-shot to the server as the prompts and labels require very little communication.\n- The paper then evaluates on several natural image datasets (subsets from ImageNet) and show that the proposed technique can match FedAvg in performance.\n- The paper also performs some privacy analysis and shows that by transmitting prompts instead gradients/model updates/data, the membership inference attack success drops significantly."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed approach is interesting and novel to my understanding. Assuming the client data distributions can be well captured by the foundation generative model, the proposed technique can clear benefits in simplicity and reducing communication costs.\n- Putting aside the underlying assumptions of the proposed techniques (see weaknesses), the paper is overall well-executed in terms of the diversity of the experiments and visualizations.\n- The paper is generally well-written and easy-to-follow."
                },
                "weaknesses": {
                    "value": "[W1] The main weakness of the proposed method is the underlying assumption that client data can, in fact, be generated by foundational models. This sound obvious but is key to the applicability of the proposed approach in practice. To put it bluntly, is the proposed solution searching for a problem?\n\n1. Settings where FL is helpful\u2014such as medical images across hospitals [1], user-generated text across mobile phones [2]\u2014are often where the data distributions aren\u2019t covered by the pre-training data of foundational models. The datasets used by the experiments are all natural image datasets (ImageNette, ImageFruit, etc.), which can be well-represented in the pre-training dataset of foundation generative models. I would appreciate results on non-natural image datasets.\n2. In particular, if we consider horizontal FL settings (as with the paper), the server may even know about the possible classes / labels (e.g. federating binary classifiers) without communicating to the clients, in which case the \u201cclass-level prompts\u201d may not be needed at all since the server can just generate images by itself. \n\n[W2]  More broadly, the threat model of the paper may need to be defined more clearly.\n\n- What exactly is client privacy in this case? Can the client data be still considered \u201cprivate\u201d if you could already generate them with public foundation models (see also [3])? Does the privacy of the data lie in the pixels, or simply the description of the pixels?\n- In many cases, the descriptions of the images can already be leaking privacy. If we apply the proposed method to cross-device federated learning on user\u2019s photo data, the server could already learn a lot about the user data distribution and preferences. For example, following Sec 5.4 and Figure 6, knowing that a user have lots of golf photos (without knowing the pixels of the photos) already allows the FL service provider (e.g. Google) to sell targeted ads.\n\n[1] FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in Realistic Healthcare Settings. NeurIPS 2022 Datasets and Benchmark.  https://arxiv.org/abs/2210.04620 \n[2] https://research.google/pubs/pub47586/ \n[3] Considerations for Differentially Private Learning with Large-Scale Public Pretraining. https://arxiv.org/pdf/2212.06470.pdf"
                },
                "questions": {
                    "value": "- [Intro section] Why exactly does the proposed method provide robustness to data heterogeneity? Heterogeneity can still surface in the (instance-level) client prompts and subsequently the generated images.\n- Minor comment: consider using different citation commands `\\citet` , `\\cite`, etc. in LaTeX to make the formatting of the in-text references consistent."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Privacy, security and safety"
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1/Reviewer_wnsW"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698700659171,
            "cdate": 1698700659171,
            "tmdate": 1699635923758,
            "mdate": 1699635923758,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "fAydmWtaGN",
                "forum": "U0P622bfUN",
                "replyto": "rBIpJVtNpZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to wnsW [1/2]"
                    },
                    "comment": {
                        "value": "We thank Reviewer wnsW for the valuable feedback and insightful comments. Here, we answer your questions and provide more experimental evidence. \n\n**Q1: The datasets used by the experiments are all natural image datasets (ImageNette, ImageFruit, etc.), which can be well-represented in the pre-training dataset of foundation generative models. I would appreciate results on non-natural image datasets.**\n\n**A1:** Although the pretraining dataset and the private dataset may exhibit some domain similarities (e.g., both may contain common real-world scenes), the tasks of lmageSquawk (fine-grained bird classification) and QuickDraw (non-realistic domain) in DomainNet that we demonstrate in our experiments are inherently challenging. Training a model solely on synthetic data generated by foundation models to achieve high accuracy on the ImageNet or DomainNet test sets is a non-trivial task. \nTo further validate the effectiveness of our method, we conducted experiments on several fine-grained image classification datasets, including CUB, Cars, and the satellite image dataset EuroSAT. As the official EuroSAT dataset did not provide predefined training and testing splits, we performed a split in an 8:2 ratio. The size of fine-grained recognition datasets is typically smaller compared to general image classification datasets. In previous work, a common practice is to utilize a pretrained model that has been trained on the ImageNet dataset. In this study, we present two approaches: training the model from scratch and loading a pretrained ResNet34 model. As shown in the table, our method achieves excellent performance even in these challenging domains. Additionally, in the cross-silo federated learning scenario, when clients have strong computational capabilities, one can simply finetune the foundation models on these domains, achieving better performance than normal federated learning methods. We have added these results in the appendix. \n\n\n| |               |         |       |             |              ||  |             |       |  |\n|:---------------:|:-------------:|:-------:|:------------:|:-----------:|:------------:|:---------------:|:--------------:|:-----------:|:-----:|:-----------:|\n|   Prompt type   | Training type | Dataset | FedAvg,$\\beta=0.01$ |FedAvg, $\\beta=0.5$ | FedAvg (IID) |    Ours (one-shot)              |  Ours (5-round) ,$\\beta=0.01$  |Ours (5-round),$\\beta=0.5$ |  Ours (5-round),IID  |        Centralized     |\n|     instance    |    scratch    | CUB-200 |     35.04    |    36.61    |     36.62    |      44.17      |      64.53     |    69.19    | 71.01 |    48.31    |\n|     instance    |   pretrain    | CUB-200 |     78.98    |    79.08    |     78.48    |      54.02      |      75.13     |    78.96    | 80.72 |    81.77    |\n|      class      |    scratch    | CUB-200 |     35.04    |    36.61    |     36.62    |      45.34      |      67.66     |     71.9    | 73.33 |    48.32    |\n|      class      |   pretrain    | CUB-200 |     78.98    |    79.08    |     78.48    |      52.73      |      74.68     |     78.7    | 80.32 |    81.77    |\n|      class      |    scratch    |   Cars  |     55.18    |    42.43    |     44.48    |      54.48      |      83.31     |    87.22    | 88.07 |    64.72    |\n|      class      |   pretrain    |   Cars  |     87.71    |    88.91    |     88.96    |      60.55      |      87.31     |    90.05    | 90.73 |    91.21    |\n|      class      |    scratch    | EuroSAT |     43.94    |    74.48    |     84.87    |      38.37      |      37.59     |    82.94    | 91.01 |    94.31    |\n\n**Q2: the \u201cclass-level prompts\u201d may not be needed at all since the server can just generate images by itself.** \n\n**A2**: Yes, if the server-side has knowledge of the specific labels for the classification task, it can generate them directly. However, class-level is just a simple case. We propose the instance-level approach to address more complex domains, where client-side customized prompt generation is more advantageous in improving the performance of the overall model. \n\n**Q3: More broadly, the threat model of the paper may need to be defined more clearly.**\n\n**A3**: threat model: In traditional federated learning schemes that transmit model parameters/gradients, attackers can launch various attacks once they obtain the parameters/gradients, such as membership inference attacks, adversarial example attacks, and model inversion. In contrast, our approach significantly reduces potential security and privacy risks because users only transmit prompts in the first round of communication. To the best of our knowledge, there is no research indicating that using prompts alone can perfectly reconstruct private data. Therefore, our approach is more secure and privacy-preserving compared to FedAvg."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700234743826,
                "cdate": 1700234743826,
                "tmdate": 1700234743826,
                "mdate": 1700234743826,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ZKUIxB4P6Z",
                "forum": "U0P622bfUN",
                "replyto": "rBIpJVtNpZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to wnsW [2/2]"
                    },
                    "comment": {
                        "value": "**Q4: What exactly is client privacy in this case? Can the client data be still considered \u201cprivate\u201d if you could already generate them with public foundation models.**\n\n**A4**: client privacy: In this paper, similar to differential privacy, we primarily focus on individual privacy, as it is more challenging for attackers. For instance, Attack A perfectly targets a known subset of 0.1% of users in a client, but succeeds with a random 50% chance on the rest. Attack B succeeds with a 50.05% probability on any given user in a client. On average, these two attacks have the same attack success rate. However, the second attack is practically useless, while the first attack is much more powerful in the real-world. This is precisely what LiRA[1] emphasizes, as it evaluates the privacy attack by computing their true-positive rate at very low (e.g., \u2264 0.1%) false-positive rates (as illustrated in our experimental results in Figure 8), demonstrating that our method can better defend against privacy attacks. \n\n[1] Carlini, Nicholas, et al. \"Membership inference attacks from first principles.\" 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 2022.\n\n**Q5: In many cases, the descriptions of the images can already be leaking privacy.**\n\n**A5**:This could be the difference between individual privacy and group privacy. The majority of the current papers on data protection focuses on the individual \u2018user,\u2019 or \u2018data subject,\u2019 who\u2019s right to privacy will grow exponentially with the enforcement of the GDPR (General Data Protection Regulation). However, group privacy is not mentioned in the GDPR , which is not well-defined. Also, if the server knows some of the user data distribution means potential privacy risks, our proposed method does not introduce additional risk in this regard. This is because in traditional gradient/parameter-based methods, using model inversion, the server can still infer this information[1,2]. But for individual privacy, this information won't increase the leakage of membership in private data. \n\n[1] Geiping, Jonas, et al. \"Inverting gradients-how easy is it to break privacy in federated learning?.\" Advances in Neural Information Processing Systems 33 (2020): 16937-16947.\n\n[2] Hatamizadeh, Ali, et al. \"Do gradient inversion attacks make federated learning unsafe?.\" IEEE Transactions on Medical Imaging (2023).\n\n**Q6:Why exactly does the proposed method provide robustness to data heterogeneity? Heterogeneity can still surface in the (instance-level) client prompts and subsequently the generated images.**\n\n**A6**: For one-shot Federated Learning (FL), regardless of the extreme data distributions among different clients, the server can always collect prompts corresponding to all the data, thus obtaining a balanced synthetic dataset on the server. Therefore, compared to FedAvg, our method is not sensitive to data heterogeneity in the first round of communication. In the subsequent model updates, the clients are still affected by non-IID data. However, due to the well-trained initial model obtained in the first round of communication, only a few rounds of communication are needed for local updates, making it more robust to data heterogeneity. As shown in Table 1 in the main text, our method exhibits significantly smaller gaps compared to FedAvg under different non-IID scenarios. \n\n**Q7: Minor comment: consider using different citation commands \\citet , \\cite** \n\n**A7:** Thanks for pointing this out. we will check it in the updated version."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700234788720,
                "cdate": 1700234788720,
                "tmdate": 1700234788720,
                "mdate": 1700234788720,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "dFtawOvszo",
                "forum": "U0P622bfUN",
                "replyto": "rBIpJVtNpZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Reviewer_wnsW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Reviewer_wnsW"
                ],
                "content": {
                    "title": {
                        "value": "Response to author rebuttal"
                    },
                    "comment": {
                        "value": "### \n\nI appreciate the authors for providing a rebuttal. \n\n- A1: I appreciate the authors for putting efforts into the new results. I also appreciate pointing to the results on QuickDraw. However, my concern is not fully addressed since the datasets \u201cCUB-200\u201d (natural images of birds) and \u201cCars\u201d (natural images of cars) are very much still in-distribution for the pre-trained generative vision models.\n- A2: The authors responded to my question by pointing to the use of instance-level prompts, but this didn\u2019t quite address my concern that the significance of the class-level prompts is a bit overclaimed. Considering the default implementation of your experiments uses class-level prompts (page 6), I would suggest clearly spelling out the assumptions and weaknesses of class-level prompts in the updated paper.\n- A4/A5:\n    - (For clarity, the following discussions apply to \u201cinstance-level\u201d prompts)\n    - By explaining the LiRA paper on membership inference in A4, the authors imply that the paper cares about instance-level privacy \u2014 i.e. image-level privacy, where an attacker cannot confidently tell whether one image is or isn\u2019t used for training.\n    - I\u2019m definitely okay with the **privacy granularity** in this case; what I\u2019m uncertain about (with Q5) is whether **all the information contain within a single example (i.e. image-label pair)** is protected.\n    - A5 does not quite address my question. I do not agree that this is the difference between \u201cgroup privacy\u201d vs \u201cindividual privacy\u201d; rather it is that the instance-level prompts have provided **side channels into learning about the information of a single image.**\n    - Consider running local, image-level DP-SGD on a client when participating in a vanilla FedAvg task. All the information corresponding to a single example (pixel values and labels) are protected behind the \u201cprivacy barrier\u201d since privatized gradients are applied to the model. In contrast, instance-level prompts would leak information about the pixel values, and thus do not really satisfy instance-level privacy in the sense of \u201cattacker not being able to tell whether an image is used for training\u201d. I do acknowledge however that there is value in providing empirical privacy of the pixel values.\n- A6: Thanks for the clarification that the server can select/curate prompts to essentially manually mitigate the data heterogeneity. I would suggest highlighting this in the updated version.\n\nOverall, the technique proposed in the paper is interesting, though I feel the assumptions on client data distributions and privacy claims are too strong. Having read through other reviewers\u2019 comments, I\u2019m keeping my rating at 5."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700527427254,
                "cdate": 1700527427254,
                "tmdate": 1700527427254,
                "mdate": 1700527427254,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "uP676dsarr",
            "forum": "U0P622bfUN",
            "replyto": "U0P622bfUN",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1/Reviewer_HdAm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1/Reviewer_HdAm"
            ],
            "content": {
                "summary": {
                    "value": "This work introduces a novel federated learning framework called Federated Generative Learning, which addresses the inefficiency and privacy issues of existing solutions that transmit features, parameters, or gradients between clients and servers. In this framework, clients generate text prompts tailored to their local data and send them to the server, where informative training data is synthesized using stable diffusion. This approach offers enhanced communication efficiency, significant performance gains, and improved privacy protection, as demonstrated through extensive experiments on ImageNet and DomainNet datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- This work proposes a novel learning framework to train local data without accessing the raw data directly.\n\n- communication of prompts instead of model parameters addresses several issues of existing federated learning frameworks; high communication cost and potential privacy threats by attackers."
                },
                "weaknesses": {
                    "value": "- The proposed method may be highly dependent on the performance of both diffusion models and visual-captioning models. \n  - An ablation study of varying the foundation models is needed.\n\n- In a similar vein, the local training dataset should be unseen for pertaining foundation models and should be more difficult than ImageNet which is a standard image classification dataset. As mentioned in the Introduction section, the local training data are more likely to be privacy sensitive, so they are more likely to be unseen or not contained for pre-training foundation models such as BLIPv2 and Stable Diffusion. Evaluation on ImageNet or DomainNet implicitly uses the assumption that local data have a similar or subset domain to the pretraining dataset of foundation models, which are publically accessible or have no privacy issue.\n\n- Clients in federated learning are often assumed to have limited capacity in memory or computation. Generating prompts using a large visual captioning model in each client is impractical."
                },
                "questions": {
                    "value": "- The quality of synthetic data could be highly different according to domain discrepancy between the local training data and the pretraining data for the foundation model. Instead of using standard image classification datasets, does the proposed method work for federated learning on fine-grained classification such as CUB-200, Cars, and medical image datasets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824961127,
            "cdate": 1698824961127,
            "tmdate": 1699635923633,
            "mdate": 1699635923633,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YhuEd25YHs",
                "forum": "U0P622bfUN",
                "replyto": "uP676dsarr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response [1 / 2]"
                    },
                    "comment": {
                        "value": "We thank Reviewer HdAm for your valuable feedback and constructive comments. We have carefully answered all your questions and added extra experiment results in the following. \n\n**Q1: The proposed method may be highly dependent on the performance of both diffusion models and visual-captioning models. An ablation study of varying the foundation models is needed.**\n\n**A1**: Thanks for this insightful point. To investigate the impact of various generative models on the results, we followed the setting in [1]. Our experiments primarily focus on three prevalent conditional diffusion models: DiT[2], GLIDE[3], and Stable Diffusion. We use these off-the-shelf models to generate synthetic images. Specifically, for GLIDE and Stable Diffusion, the prompt was configured as \"a photo of {label name}, real-world images, high resolution.\" For DiT, the input comprised the label ID corresponding to the ImageNet1k dataset. The images synthesized by DiT and GLIDE are of dimensions 256x256, whereas those produced by Stable Diffusion are of dimensions 512x512. As shown in the following table, even when we vary the foundation models used in our method, FGL consistently outperforms FedAvg by a significant margin. This observation serves as evidence for the generality of our approach. We have added these results in the Appendix A.4.3.\n\n|           Method          | one-shot | 5-round, $\\beta$=0.01 | 5-round, $\\beta$=0.5 |    IID   |\n|:-------------------------:|:--------:|:------------------:|:-----------------:|:--------:|\n| Ours w/  Stable Diffusion | **85.2** |      **82.8**      |       **94.1**      | **95.6** |\n|       Ours w/ Glide       |    79.0    |        76.2        |        89.4       |   89.4   |\n|        Ours w/ Dit        |   76.2   |        74.6        |        90.2       |   92.8   |\n|     FedAvg (120-round)    |     -    |        51.6        |        75.1       |   79.2   |\n\n\n[1] Li, Zheng, et al. \"Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?.\" arXiv preprint arXiv:2305.12954 (2023).\n\n[2] Nichol, Alex, et al. \"Glide: Towards photorealistic image generation and editing with text-guided diffusion models.\" arXiv preprint arXiv:2112.10741 (2021).\n\n[3]Peebles, William, and Saining Xie. \"Scalable diffusion models with transformers.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.\n\n\n**Q2: Clients in federated learning are often assumed to have limited capacity in memory or computation.** \n\n\n**A2**: \n- First, compared to FedAvg, our method introduces only one additional operation on the client side, i.e., prompt generation, which involves only forward propagation and does not impose significant computational costs. All computational operations are executed on the server side during the initial communication. The server trains a model with an excellent initial state, and subsequently, the client performs regular model updates, which means no additional cost compared with FedAvg. \n- Secondly, our method is particularly well-suited for cross-silo FL, where the clients represent organizations or companies. In this context, the number of clients is typically small, but they possess substantial computational resources. Furthermore, this scenario emphasizes the importance of protecting clients' local data from potential leaks, which constitutes a significant contribution of our approach towards preserving privacy."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700233875070,
                "cdate": 1700233875070,
                "tmdate": 1700233875070,
                "mdate": 1700233875070,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5pE0TtLbRY",
                "forum": "U0P622bfUN",
                "replyto": "uP676dsarr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response [2 / 2]"
                    },
                    "comment": {
                        "value": "**Q3.Evaluation on ImageNet or DomainNet implicitly uses the assumption that local data have a similar or subset domain to the pretraining dataset of foundation models, which are publically accessible or have no privacy issue.**\n\n**A3**: Thanks for pointing this out. Here, we would like to address this from three aspects: \n- Although the pretraining dataset and private dataset may have some domain similarities (e.g., both may contain common real-world scenes), the tasks of lmageSquawk (fine-grained bird classification) and QuickDraw (non-realistic domain) in DomainNet that we show in our experiments are challenging. It is a non-trivial task to train a model only using synthetic data generated by foundation models to achieve good accuracy on the ImageNet or DomainNet test sets. \n\n- Furthermore, even when there are some domain similarities between the pretraining dataset and private dataset, does it mean that there is no need to discuss the privacy risk? Definitely not! Let's consider a scenario where a public dataset contains various images of cats, while a private dataset contains personal images of cats belonging to individual users. Although both datasets involve images of cats, the private dataset may contain users' personal information, such as their family photos or addresses. Therefore, even if the two datasets are similar in some aspects, the private data still carries privacy risks and needs to be properly protected. Taking Membership Inference Attack (MIA) as an example, consider an adversary that wants to probe a ML model to test membership of an individual's data in the model's training data. In this scenario, an adversary is more likely to have access to some representative images of the target individual, but not necessarily the ones used for training the model. As shown in Figure 8, we implemented the state-of-the-art LiRA algorithm in MIA. The experimental results demonstrate that our approach ensures the protection of sensitive information of the members in the clients' data (since the model training process has never been exposed to any private data). In contrast, traditional federated learning methods directly train on private data, posing a high risk of exposing the sensitive information of the members in the clients' data (i.e., for certain private data samples, attackers have a high confidence in identifying the client from which the sample originates). To the best of our knowledge, prior to our proposed approach, no one has put forth a training paradigm that effectively defends against LiRA while concurrently modeling utility (i.e., achieving high test accuracy). \n\n- Finally, even for particularly challenging domains such as remote sensing images or fine-grained classification datasets, our method can easily adapt to these scenarios. We conducted experiments on several fine-grained image classification datasets, namely CUB-200, Stanford Cars, and also the satellite image dataset EuroSAT. CUB-200 is a challenging dataset consisting of 200 bird species, while Stanford Cars contains 16,185 images belonging to 196 classes of cars. See more details in the `Appendix A.4.2`.\n\n| |               |         |       |             |              ||  |             |       |  |\n|:---------------:|:-------------:|:-------:|:------------:|:-----------:|:------------:|:---------------:|:--------------:|:-----------:|:-----:|:-----------:|\n|   Prompt type   | Training type | Dataset | FedAvg,$\\beta=0.01$ |FedAvg, $\\beta=0.5$ | FedAvg (IID) |    Ours (one-shot)              |  Ours (5-round) ,$\\beta=0.01$  |Ours (5-round),$\\beta=0.5$ |  Ours (5-round),IID  |        Centralized     |\n|     instance    |    scratch    | CUB-200 |     35.04    |    36.61    |     36.62    |      44.17      |      64.53     |    69.19    | 71.01 |    48.31    |\n|     instance    |   pretrain    | CUB-200 |     78.98    |    79.08    |     78.48    |      54.02      |      75.13     |    78.96    | 80.72 |    81.77    |\n|      class      |    scratch    | CUB-200 |     35.04    |    36.61    |     36.62    |      45.34      |      67.66     |     71.9    | 73.33 |    48.32    |\n|      class      |   pretrain    | CUB-200 |     78.98    |    79.08    |     78.48    |      52.73      |      74.68     |     78.7    | 80.32 |    81.77    |\n|      class      |    scratch    |   Cars  |     55.18    |    42.43    |     44.48    |      54.48      |      83.31     |    87.22    | 88.07 |    64.72    |\n|      class      |   pretrain    |   Cars  |     87.71    |    88.91    |     88.96    |      60.55      |      87.31     |    90.05    | 90.73 |    91.21    |\n|      class      |    scratch    | EuroSAT |     43.94    |    74.48    |     84.87    |      38.37      |      37.59     |    82.94    | 91.01 |    94.31    |\n\n**Q4: does the proposed method work for federated learning on fine-grained classification such as CUB-200, Cars, and medical image datasets?**\n\n**A4**: Please refer to the table in A3."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700233964709,
                "cdate": 1700233964709,
                "tmdate": 1700233964709,
                "mdate": 1700233964709,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]