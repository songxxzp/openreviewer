[
    {
        "title": "Improved Techniques for Training Consistency Models"
    },
    {
        "review": {
            "id": "nn6FvPo3PU",
            "forum": "WNzy9bRDvG",
            "replyto": "WNzy9bRDvG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8410/Reviewer_m7Dp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8410/Reviewer_m7Dp"
            ],
            "content": {
                "summary": {
                    "value": "Recently, consistency models were proposed. They can be used to either distill diffusion models into single- or few-step samplers (consistency distillation), or they also enable direct training of single- or few-step consistency models (consistency training). Previous work showed strong results primarily for the distillation setting. In this work the authors focus on the consistency training setting and propose multiple techniques to improve the performance of consistency training. For instance, the paper avoids the questionable use of LPIPS-based consistency matching, and employs a more general Huber loss. The authors also remove the exponential moving average and point out errors in previous theoretical analyses. Moreover, a new loss weighting function is proposed, the noise level embeddings are carefully analyzed and improved, the use of dropout is studied, and the discretization step curriculum is improved. The paper thoroughly ablates and analyzes all improvements and then evaluates the model on popular benchmarks, CIFAR10 and ImageNet64. It achieves very strong performance, significantly outperforming both previous consistency models and diffusion model distillation methods. The improved consistency models perform almost as good as state-of-the-art diffusion models and GANs, while being trained directly and only requiring a single or two synthesis steps."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper has several strengths:\n- The paper is well-written and easy to follow (good **clarity**).\n- The paper does not present a fundamentally new method (moderate **novelty**). However, it does significantly improve consistency models, a very novel and very promising class of generative models that enables single- or few-step sampling, in contrast to, for instance, diffusion models. I expect the insights provided by the paper to be used in follow-up work and I think that consistency models will find wide usage, too. This makes this work very **significant**\n- The paper presents thorough ablations and analyses of the proposed tricks and innovations. It is generally of high **quality**.\n- The final experimental results obtained when combining all modifications are very strong, and thoroughly compared to many and appropriate baselines."
                },
                "weaknesses": {
                    "value": "I think the paper has no major weaknesses. However, there would be opportunities to further improve the work:\n- I am wondering how scalable consistency models are with the proposed modifications. Can one train, for instance, text-to-image consistency models? Or how about training on higher-resolution images?\n- The new consistency models do not require LPIPS losses anymore and are thereby more general in that they are not limited to image synthesis anymore. It would be interesting to validate that consistency models can also be successfully trained on non-image data (e.g. audio, graphs, 3D, video, etc).\n\nConclusion: Overall, I think this is a good and solid paper. It significantly improves consistency models, a very promising new class of generative models, and the paper is overall well-written and of high quality. Hence, I recommend acceptance."
                },
                "questions": {
                    "value": "I only have some minor questions:\n- When the paper defines the ground truth consistency function in Section 3.2, is there a typo in the ground truth consistency function? Should it be $\\xi$ instead of $\\mu$ in the ground truth consistency function $f^{*}$ for the single data point data distribution?\n- What are $s_0$ and $s_1$ in Section 3.4? They are not properly explained when first introduced above Eq. (9).\n- Also in Section 3.4, the authors use an exponential discretization curriculum, which leads to the visualization in Fig. 3(a). Why is this exponential curriculum not included in the visualizations and ablations in Figs. 3(b) and 3(c)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8410/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698338925562,
            "cdate": 1698338925562,
            "tmdate": 1699637047737,
            "mdate": 1699637047737,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pfbPduEuF8",
                "forum": "WNzy9bRDvG",
                "replyto": "nn6FvPo3PU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8410/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8410/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful feedback. We address your questions or concerns below.\n\nQ1: I am wondering how scalable consistency models are with the proposed modifications. Can one train, for instance, text-to-image consistency models? Or how about training on higher-resolution images?\n\nA: We anticipate that improved consistency models will scale easily to larger datasets. Indeed, all generative models that perform well at the scale of 64x64 ImageNet have been successfully used for large-scale text-to-image generation and larger resolution images.\n\nQ2: It would be interesting to validate that consistency models can also be successfully trained on non-image data (e.g. audio, graphs, 3D, video, etc).\n\nA: We agree with the reviewer and plan to leave this as future work.\n\nQ3: When the paper defines the ground truth consistency function in Section 3.2, is there a typo in the ground truth consistency function?\n\nA: Thank you for pointing this out. We have corrected the typo in our revision.\n\nQ4: What are $s_0$ and $s_1$ in Section 3.4?\n\nA: $s_0$ and $s_1$ control the minimum and maximum number of discretization steps. We have added their definitions to the draft.\n\nQ5: In Section 3.4, the authors use an exponential discretization curriculum, which leads to the visualization in Fig. 3(a). Why is this exponential curriculum not included in the visualizations and ablations in Figs. 3(b) and 3(c)?\n\nA: In our latest revision, we have made the exponential discretization curriculum our default recommendation. We have also thoroughly compared all discretization curriculums in Figures 3b and 3c."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720657863,
                "cdate": 1700720657863,
                "tmdate": 1700720657863,
                "mdate": 1700720657863,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fCOpnfJTwV",
            "forum": "WNzy9bRDvG",
            "replyto": "WNzy9bRDvG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8410/Reviewer_3jcG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8410/Reviewer_3jcG"
            ],
            "content": {
                "summary": {
                    "value": "In this work, the authors enhanced the training of consistency model, initially introduced by Song et al. [1], by implementing improved weighting functions, a refined discretization curriculum, eliminating Exponential Moving Average (EMA), introducing a new loss function, and improving the noise schedule. These advancements enable the model to achieve state-of-the-art results in both one and two-step generation processes without relying on pre-trained diffusion models or learned metrics. Overall, the paper is well-written and organized, and the improving techniques are supported by convincing discussions.\n\n\n\n\n\n\n[1] Song, Y., Dhariwal, P., Chen, M. and Sutskever, I., 2023. Consistency models."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper presents compelling discussions on improved training schemes, which notably facilitate the development of a consistency model. This model impressively achieves state-of-the-art results in both one and two-step generation processes, uniquely independent of pre-trained diffusion models or learned metrics.\n\n2. The empirical results on CIFAR-10 and ImageNet 64\u00d764 datasets affirm the efficacy of these enhanced training methodologies.\n\n3. The research sets a new benchmark, providing a robust and successful framework for training consistency models. This paradigm holds potential for broader application in various one or two-step generalization models."
                },
                "weaknesses": {
                    "value": "1. This paper functions primarily as a technical exploration, compiling successful practices in training diffusion models. While it includes numerous ablation studies, it lacks sufficient theoretical backing to fully support these practices.\n\n2. The paper\u2019s improved training schemes do allow the consistency model to avoid relying on a pre-trained diffusion model. However, its theoretical basis still seems anchored in diffusion model principles. It would be beneficial if the authors explored the broader potential of the consistency training scheme. Specifically, whether this training would be effective when the generation process is not the reverse of a diffusion process but a more general corruption process, such as those described in [1] and [2].\n\n[1] Bansal, A., Borgnia, E., Chu, H.M., Li, J.S., Kazemi, H., Huang, F., Goldblum, M., Geiping, J. and Goldstein, T., 2022. Cold diffusion: Inverting arbitrary image transforms without noise. arXiv preprint arXiv:2208.09392.\n[2] Xu, Y., Liu, Z., Tegmark, M. and Jaakkola, T., 2022. Poisson flow generative models. Advances in Neural Information Processing Systems, 35, pp.16782-16795."
                },
                "questions": {
                    "value": "Could the author elaborate more on why higher discretization steps can reduce bias but increase variance?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8410/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8410/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8410/Reviewer_3jcG"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8410/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698710799166,
            "cdate": 1698710799166,
            "tmdate": 1699637047611,
            "mdate": 1699637047611,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "hJrJyiJnnj",
                "forum": "WNzy9bRDvG",
                "replyto": "fCOpnfJTwV",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8410/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8410/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful feedback. We address your questions or concerns below.\n\nQ1: This paper functions primarily as a technical exploration, compiling successful practices in training diffusion models. While it includes numerous ablation studies, it lacks sufficient theoretical backing to fully support these practices.\n\nA: We want to emphasize that this work focuses on consistency models, not diffusion models. Although theoretical backing would be beneficial, we don't believe it exists for all practical techniques, particularly those in deep learning.\n\nQ2: Whether this training would be effective when the generation process is not the reverse of a diffusion process but a more general corruption process, such as those described in [1] and [2].\n\nA: We believe consistency training can be easily generalized to flow matching, rectified flows, and improved Poisson flow. However, this is not the primary focus of this work.\n\nQ3: Could the author elaborate more on why higher discretization steps can reduce bias but increase variance?\n\nA: Higher discretization steps decrease bias, as consistency training theoretically holds in the limit of $N\\to\\infty$. The observation that higher discretization steps also cause larger variance is primarily empirical. This is because models trained with larger discretization steps typically converge slower than those trained with smaller ones (as shown in Figure 3d in [1])\n\nReference:\n\n[1] Song, Y., Dhariwal, P., Chen, M. and Sutskever, I., 2023. Consistency models."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720627398,
                "cdate": 1700720627398,
                "tmdate": 1700720627398,
                "mdate": 1700720627398,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "1BjwXopXgp",
            "forum": "WNzy9bRDvG",
            "replyto": "WNzy9bRDvG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8410/Reviewer_YvKM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8410/Reviewer_YvKM"
            ],
            "content": {
                "summary": {
                    "value": "\"The paper introduces a comprehensive set of techniques aimed at enhancing the efficacy of consistency training within few-shot diffusion models for image generation. The contributions are prioritized as follows:\n\n1. The elimination of the Exponential Moving Average (EMA) from the student model, a change supported by both theoretical arguments and empirical evidence, results in markedly improved consistency training performance.\n\n2. An improved framework that incorporates weighted timestep selection (inspired by EDM), time-step adaptive loss weighting, and the pseudo-Huber loss function to refine the training process.\n\n3. A refined schedule for discretization steps involved in computing the consistency loss, accompanied by a new heuristics curriculum that adjusts these steps throughout the training phases.\n\n4. Additional modifications to the network, such as the integration of dropout strategies and better time embeddings, to enhance model robustness and adaptability.\n\nCollectively, these advancements makes the consistency training model highly competitive, achieving performance on par with leading generative models on benchmarks like CIFAR-10 and ImageNet."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "S1: this model positions consistency models as competitive generative models. When the first consistency model was introduced, its performance was somewhat mediocre, especially on large datasets like ImageNet. The set of improvements proposed in this paper has made consistency training competitive, and it may become a leading approach in the future due to desirable properties such as stable training and accurate approximation of the probability flow ODE.\n\nS2: the technical contribution is robust. The theoretical analysis supporting the removal of the EMA is well-justified and is corroborated by experimental results.\n\nS3: Various other enhancements have also proven useful and are validated experimentally.\n\nS4: the paper is well-written and easy to follow"
                },
                "weaknesses": {
                    "value": "W1: The choice to use the pseudo-Huber loss is not entirely convincing, as its effectiveness appears sensitive to the chosen constant value, and it offers negligible improvements over the tuning-free LPIPS loss, which is known for its alignment with human perception and computational efficiency, especially in pixel-space models.\n\nW2: Apart from the significant change of removing EMA, the other enhancements resemble engineering optimizations rather than foundational advances. Their relevance to broader applications is questionable, especially since the empirical evaluation is limited to smaller datasets like CIFAR-10 and ImageNet-64x64. Expanding experiments to include higher-resolution images on ImageNet or more varied datasets such as COCO or LAION could substantiate the model's versatility.\n\nW3: The training speed for the consistency model is comparatively slow, especially when compared with models like GANs. It would be insightful if the authors could address this aspect and discuss its implications for scaling to larger datasets. \n\nW4: The applicability of consistency training appears confined to training unguided models, which significantly underperform in applications such as text-to-image generation."
                },
                "questions": {
                    "value": "I have several questions for the authors that could enrich the broader community\u2019s understanding:\n\nQ1: Does the current consistency training outperform consistency distillation when applying the enhancements presented in this paper to the latter?\n\nQ2: Given the apparent benefits of scaling up the network architecture for larger datasets (e.g., ImageNet as shown in Table 3), is there a risk that one(few)-step methods will be inherently limited by network capacity? In other words, can these methods directly approximate the ODE solution with a network of the same capacity as the original diffusion model, or would alternative approaches like RectFlow [1] provide a more viable solution?\n\n[1] Liu, Xingchao, Chengyue Gong, and Qiang Liu. \"Flow straight and fast: Learning to generate and transfer data with rectified flow.\" arXiv preprint arXiv:2209.03003 (2022)."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8410/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698779065330,
            "cdate": 1698779065330,
            "tmdate": 1699637047484,
            "mdate": 1699637047484,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jHtwXrmdmJ",
                "forum": "WNzy9bRDvG",
                "replyto": "1BjwXopXgp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8410/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8410/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful feedback. We address your questions or concerns below.\n\nQ1: Pseudo-Huber loss is not convincing compared to LPIPS\n\nA: We respectfully disagree with the reviewer. One major goal of this work is to eliminate LPIPS. Unlike LPIPS, Pseudo-Huber losses are not restricted to the image domain. Additionally, we have identified two other weaknesses of LPIPS in introduction: First, there could be potential bias in evaluation since the same ImageNet dataset trains both LPIPS and the Inception network in FID, which is the predominant metric for image quality. As analyzed in Kynk\u00e4\u00e4nniemi et al. (2023), improvements of FIDs can come from accidental leakage of ImageNet features from LPIPS, causing inflated FID scores. Second, learned metrics require pre-training auxiliary networks for feature extraction. Training with these metrics requires backpropagating through extra neural networks, which increases the demand for compute.\n\nQ2: Apart from the significant change of removing EMA, the other enhancements resemble engineering optimizations rather than foundational advances. Their relevance to broader applications is questionable, especially since the empirical evaluation is limited to smaller datasets like CIFAR-10 and ImageNet-64x64. Expanding experiments to include higher-resolution images on ImageNet or more varied datasets such as COCO or LAION could substantiate the model's versatility.\n\nA: We agree with the reviewer. This paper provides both foundational advances and engineering optimizations, not merely limited to the former. We plan to undertake large-scale consistency training on datasets such as COCO or LAION in future work.\n\nQ3: The training speed for the consistency model is comparatively slow, especially when compared with models like GANs.\n\nA: We respectfully disagree with the reviewer. Given the same model size, consistency training is faster than GANs. This is because GANs requires backpropagation through both the generator and discriminator, whereas consistency training only requires backpropagation through the student network.\n\nQ4: The applicability of consistency training appears confined to training unguided models.\n\nA: We leave generalization to guided models to future work.\n\nQ5: Does the current consistency training outperform consistency distillation when applying the enhancements presented in this paper to the latter?\n\nA: Yes. Consistency training surpasses consistency distillation, even when provided with the same enhancements.\n\nQ6: Given the apparent benefits of scaling up the network architecture for larger datasets (e.g., ImageNet as shown in Table 3), is there a risk that one(few)-step methods will be inherently limited by network capacity? In other words, can these methods directly approximate the ODE solution with a network of the same capacity as the original diffusion model, or would alternative approaches like RectFlow [1] provide a more viable solution?\n\nA: We anticipate that one-step models will be larger than multi-step ones. Consistency training can easily be generalized to rectified flows and may benefit from a similar reflow procedure."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720583089,
                "cdate": 1700720583089,
                "tmdate": 1700720583089,
                "mdate": 1700720583089,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PtfmnmxMaF",
                "forum": "WNzy9bRDvG",
                "replyto": "jHtwXrmdmJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8410/Reviewer_YvKM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8410/Reviewer_YvKM"
                ],
                "content": {
                    "title": {
                        "value": "Reply to Author"
                    },
                    "comment": {
                        "value": "Thank you for the response. They addressed my concerns and I will keep my original rating. One additional comment regarding PH loss.\n\nQ1: While I acknowledge that LPIPS may introduce bias, the Pseudo-Huber loss is not yet optimal for large-scale experiments due to its need for precise parameter tuning. It's important to note that the additional network requirements for LPIPS are minimal, as its backbone networks are significantly smaller than the consistency base model, resulting in a minor overhead. However, the computational concern is valid in cases involving latent space models, where a VAE is necessary to convert latent representations to pixel space for LPIPS loss calculation, leading to high memory usage. I recommend the authors to further explore and experiment in this specific context"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739368358,
                "cdate": 1700739368358,
                "tmdate": 1700739368358,
                "mdate": 1700739368358,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "H0DwvgkMhg",
            "forum": "WNzy9bRDvG",
            "replyto": "WNzy9bRDvG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8410/Reviewer_ceYg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8410/Reviewer_ceYg"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents improved techniques for training consistency models, which include 1) adopting better weighting function, noise embeddings, and dropout 2) eliminating Exponential Moving Average from the teacher model; 3) utilizing Pseudo-Huber loss instead of $l_2$ metric and learned metrics like LPIPS; 4) introducing a new noise schedule and proposing a new curriculum for discretization steps. These modifications enable much better consistency model training."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper is really well-written and easy to follow. Each component of the design space is carefully explained and well-presented. Most of the choices are accompanied by intuitive demonstrations, which provide insights that could translate to other methods. Most importantly, the empirical results are competitive against the SOTA methods, establishing consistency models as an attractive family of generative models."
                },
                "weaknesses": {
                    "value": "If I remember correctly, in the original consistency model, the teacher set to have EMA is more of an empirical decision. Using the same network as the student (with STOPGRAD operation) is definitely reasonable and even more intuitive (we want the model to be consistent with itself). Thus, I am not against dropping the EMA component, if it means better empirical performances.\n\nHowever, I do not feel the theoretical analysis presented in Sec.3.2 is justified. Note since I believe the main contribution of the paper is an empirical one, my complaint here does not change my assessment of the paper significantly. Still, I would appreciate it if the authors could clarify my concerns here.\n\n1. I think Eq.6 applies no matter the relation between $\\theta$ and $\\theta^-$, no?\n2. In Eq.7, why are we looking at the gradient scaled by $1/\\Delta\\sigma$? If we look at just the pure gradient, it should be 0 if $\\theta=\\theta^-$, and some finite value associated with their difference if not, and furthermore, the difference between $\\theta$ and $\\xi$ disappears. It may look like the loss function has nothing to do with learning the correct parameter $\\xi$ like the authors suggest in the second last paragraph in Sec.3.2. However, to me, this is not a surprise and totally expected. The self-consistency loss itself does not really force the network to learn anything correctly, i.e. the model could just predict a constant no matter the input and still be considered consistent with itself. In my understanding, it is really the boundary condition enforced through parameterizations that makes the model work, which is not a fact used in this toy example.\n3. In the current version, I am curious as to what the authors have in mind about \"if the consistency loss either does not exist or is unsuitable\". This notion does not seem to be explained well."
                },
                "questions": {
                    "value": "1. Do the authors have any insight as to why the Pseudo-Huber loss could bring this much improvement? I do not recall it utilized in any popular diffusion models. Could it be that consistency models, because of their unique features and training dynamics, benefit more from \"bounded\" gradients for all $t$?\n2. Do the authors have insights on why insensitive time embeddings are helpful or in this case crucial? There are similar design choices made in EDM: $1/4\\log(\\sigma)$ has a rather small range between $\\sigma_{\\textrm{min}}$ and $\\sigma_{\\textrm{max}}$.\n3. When examining the effects of different time embedding choices, positional embedding is mentioned. Given Fig.1 on the average $l_1$ distance, I assume the authors directly feed in $\\sigma$, rather than EDM's $1/4\\log(\\sigma)$? I think this needs to be clarified.\n4. In the paper, there are no explicit definitions of $s_0$ and $s_1$, which denote the start and end discretization steps.\n5. In Sec.3.2, third paragraph, the ground truth consistency function should have $\\xi$ rather than $\\mu$."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8410/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8410/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8410/Reviewer_ceYg"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8410/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698788914894,
            "cdate": 1698788914894,
            "tmdate": 1699637047352,
            "mdate": 1699637047352,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ZDgIPxXwrW",
                "forum": "WNzy9bRDvG",
                "replyto": "H0DwvgkMhg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8410/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8410/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Thank you for your thoughtful feedback. Please find our response to your questions below.\n\nQ1: Clarification on the theoretical analysis in Section 3.2.\n\nA: There are two competing theories justifying consistency training in previous work. As our analysis in Section 3.2 demonstrates, Argument (ii) is the correct one, requiring a zero EMA for the teacher network.\n\nWhile Equation (6) holds regardless of the relationship between $\\theta$ and $\\theta^-$ (as predicted by Argument (i)), it doesn't necessarily validate consistency training. This is because the training dynamics are defined by the gradient of the loss function due to the stop gradient operator in the consistency training objective, not the loss function itself. In fact, the gradient of Equation (6) is always zero, offering no training signal as $N\\to\\infty$.\n\nTo avoid degenerate gradients, the consistency training objective's gradient must be scaled by $1/\\Delta \\sigma$. This is demonstrated in Equation (7) and supported by Argument (ii). In this scenario, the gradient is finite only when $\\theta=\\theta^-$, which further validates Argument (ii) and justifies our decision to set the teacher EMA decay rate to zero.\n\nWe would like to emphasize that even if the consistency training objective doesn't exist, it's acceptable as long as its gradient is well-defined. Both conditions can occur simultaneously because the loss function includes the stop gradient operator.\n\nQ2: Do the authors have any insight as to why the Pseudo-Huber loss could bring this much improvement?\n\nA: As Figure 5(b) in Appendix B demonstrates, Pseudo-Huber loss leads to smaller variance in Adam updates, which leads to faster convergence in training. This is likely because Pseudo-Huber losses are less affected by outlier gradients in training data compared to l2.\n\nQ3: Do the authors have insights on why insensitive time embeddings are helpful or in this case crucial?\n\nA: As mentioned in Section 3.1, we believe it is essential that noise embeddings are sufficiently sensitive to minute differences to offer training signals, yet too much sensitivity can lead to training instability.\n\nQ4: How to feed noise level to positional embeddings.\n\nA: We followed EDM by feeding $0.25 \\log \\sigma$ to the positional embedding layer.\n\nQ5: No definitions of $s_0$ and $s_1$, and the typo in Section 3.2\n\nA: Thank you for the suggestions! Indeed, $s_0$ and $s_1$ represent the start and end discretization steps, and we have updated our draft with their definitions. We have also corrected the typo in Section 3.2."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8410/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700720523206,
                "cdate": 1700720523206,
                "tmdate": 1700720523206,
                "mdate": 1700720523206,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]