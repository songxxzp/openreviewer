[
    {
        "title": "Ligand Conformation Generation: from singleton to pairwise"
    },
    {
        "review": {
            "id": "Lk7R3AZXuN",
            "forum": "m9zWBn1Y2j",
            "replyto": "m9zWBn1Y2j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1743/Reviewer_yEdr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1743/Reviewer_yEdr"
            ],
            "content": {
                "summary": {
                    "value": "This work present PsiDiff, a new method for molecule conformation generation by given target proteins. The authors propose to use TLPE and graph prompts to model the ligand-target interactions into the generation task."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Conformation generation is an important task for drug discovery\n- The authors give details theory study to ensure invariance"
                },
                "weaknesses": {
                    "value": "- Novelty: the target information has already been considered in methods like TargetDiff [1].\n\n- Presentation: the explanation about how the \"prompt graph\" is build and used is not clear and hard to follow.\n\nRef:\n\n[1] 3D EQUIVARIANT DIFFUSION FOR TARGET-AWARE MOLECULE GENERATION AND AFFINITY PREDICTION, ICLR 2023."
                },
                "questions": {
                    "value": "- The concept of \"Graph Prompt\" is confusing. How is this related to the \"prompt\" in NLP?\n- Is the \"graph prompt\" and \"prompt graph\" the same thing?\n- It is not clear how the \"prompt graph\" is build. For nodes, while \"The number of tokens equals the number of down-sampled target graph nodes\"(line 199), how about their values? Meanwhile, how the edge set S are constructed?\n- In line 212, it says $Z = Concat(F_L, P)$. How they can be concated together as they may have difference number of nodes and feature dims? It will be better to show the shape of all tensors.\n- There are two insertion patterns. And seems they are both used in the method. Why they should be used at the same time?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1743/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698722558260,
            "cdate": 1698722558260,
            "tmdate": 1699636103106,
            "mdate": 1699636103106,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "oVKNrU2poU",
                "forum": "m9zWBn1Y2j",
                "replyto": "Lk7R3AZXuN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1743/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1743/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your advice.\n\nQ1:\nThe concept of \"Graph Prompt\" is confusing. How is this related to the \"prompt\" in NLP?\n\nA1:\nGraph prompts are concise instructions or starting points that leverage the power of graph-based representations to guide and structure the generation of creative and context-aware outputs. It comes form the \"prompt\" in NLP, utilized to guide the generation.\n\nQ2:\nIt is not clear how the \"prompt graph\" is build. For nodes, while \"The number of tokens equals the number of down-sampled target graph nodes\"(line 199), how about their values? Meanwhile, how the edge set S are constructed?\n\nA2:\nThe initialization of prompt graph nodes and edges is accomplished by utilizing the target graph node, which is encoded using dMaSIF, and further details regarding this process can be found in the appendix.\n\nQ3:\nIn line 212, it says \n. How they can be concated together as they may have difference number of nodes and feature dims? It will be better to show the shape of all tensors.\n\nA3:\nWe will show the shapes of the tensors.\n\nQ4:\nThere are two insertion patterns. And seems they are both used in the method. Why they should be used at the same time?\n\nA4:\nThe two approaches under consideration focus on different aspects. The first approach considers the ligand and target separately, emphasizing their interaction and primarily focusing on the ligand and target entity interaction, with more emphasis on pose. In contrast, the second approach considers the interaction between each pair of atoms in the ligand and target, placing greater emphasis on the shape of the ligand."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1743/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700534007409,
                "cdate": 1700534007409,
                "tmdate": 1700534007409,
                "mdate": 1700534007409,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "P50BSFw98u",
            "forum": "m9zWBn1Y2j",
            "replyto": "m9zWBn1Y2j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1743/Reviewer_crGs"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1743/Reviewer_crGs"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a ligand conformation generation model that takes into account both ligand features and features of the target protein. They infuse the ligand's embedding with the embedding of the target protein using a seemingly novel method termed \"Target-Ligand Pairwise Graph Encoder\". They claim to outperform GeoDiff and TankBind in aligned RMSD to crystal ligand poses in the PDBBind2020 data."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper proposes a seemingly novel way of infusing protein embeddings into ligand embeddings for the purpose of ligand conformation generation.\n2. The paper claims to outperform GeoDiff and TankBind in aligned RMSD to crystal ligand structures in PDBBind2020."
                },
                "weaknesses": {
                    "value": "Related Work:\n1. The paper criticizes models for predicting only a single binding pose but seems to ignore DiffDock's multiconformational capabilities.\n2. The paper questions RDKit initialization in DiffDock without explaining why it is problematic.\n3. The last sentence regarding the use of target information for molecular generation is unclear.\n4. The related work section is not sufficiently detailed, making it difficult to understand the paper's unique contributions and how it stands apart from previous works.\n\nResults:\n1. The metric is the aligned RMSD to crystal ligand structures in PDBBind2020, where the structures correspond to the ligand bound to the target protein. This is essentially the same as blind docking, thus the results are not convincing without a thorough comparison to DiffDock (current SOTA in blind docking)."
                },
                "questions": {
                    "value": "1. The paper seems to suggest that other embeddings of the protein could be used to condition the molecular generation model (i.e. other than dMaSIF). What other embeddings could be considered? And, why was dMaSIF chosen?\n2. How is the evaluation metric in this paper different from that of DiffDock?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1743/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698758102129,
            "cdate": 1698758102129,
            "tmdate": 1699636103022,
            "mdate": 1699636103022,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "jEklszgr4V",
                "forum": "m9zWBn1Y2j",
                "replyto": "P50BSFw98u",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1743/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1743/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your advice.\n\nQ1:\nThe paper criticizes models for predicting only a single binding pose but seems to ignore DiffDock's multiconformational capabilities.\nThe paper questions RDKit initialization in DiffDock without explaining why it is problematic.\n\nA1:\nOur method offers multiconformational capability, providing five ligand candidates for each pocket in the results. The RMSD calculations are then performed by taking the mean of these conformations. It's worth mentioning that while RDKit initialization is generally effective, it may encounter difficulties with certain ligands that the RDKit package cannot handle. In contrast, DiffDock addresses this problem by simply removing pairs that RDKit cannot process. However, this approach may lead to a loss of valuable information and potentially biased results.\n\nQ2:\nThe related work section is not sufficiently detailed, making it difficult to understand the paper's unique contributions and how it stands apart from previous works.\n\nA2:\nThe paper\u2019s unique contributions and how it stands apart from previous works are mostly in introduction parts. We will make the related work section more detailed.\n\nQ3:\nThis is essentially the same as blind docking, thus the results are not convincing without a thorough comparison to DiffDock (current SOTA in blind docking).\n\nA3:\nBlind docking does not given a fixed pocket but a protein and ligand initializtion, by slightly adjust the rotational bonds and pose, to get the best binding affinity. Unlike traditional docking projects, our model, PsiDiff, takes a distinct approach by assuming a random initialization for the ligand atoms, eliminating the need for prior coordinate information. Furthermore, we would like to highlight a concern regarding the comparison with Diffdock. While Diffdock reports results based on ligand RMSD, their code aligns the ligands to reference structures before evaluation. We believe this alignment step introduces bias and may not provide a fair comparison.\n\nQ4:\nThe paper seems to suggest that other embeddings of the protein could be used to condition the molecular generation model (i.e. other than dMaSIF). What other embeddings could be considered? And, why was dMaSIF chosen?\n\nA4:\nWe acknowledge that alternative embeddings can be considered for our model. In our experiments, we also explored using a graph convolutional network (GCN) as the structure-to-ligand encoder. While it showed improvements in the results, it did not outperform the performance achieved by dMaSIF. The reason we chose dMaSIF as our protein encoder is because it provides a robust and effective encoding while allowing for end-to-end training, eliminating the need for manual computation of chemical properties, which can be time-consuming. The use of dMaSIF streamlines the process and ensures efficient training and encoding of protein structures, contributing to the overall performance of our method.\n\nQ5:\nHow is the evaluation metric in this paper different from that of DiffDock?\n\nA5:\nIn our paper, we present the calculation of both ligand RMSD and aligned RMSD. The main distinction between these metrics lies in their treatment of the ligand's pose. Aligned RMSD places emphasis on the conformational shape of the ligand while disregarding its pose, including position and rotation. On the other hand, ligand RMSD is primarily influenced by the ligand's position."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1743/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533935386,
                "cdate": 1700533935386,
                "tmdate": 1700533935386,
                "mdate": 1700533935386,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lgFLBPSLGy",
            "forum": "m9zWBn1Y2j",
            "replyto": "m9zWBn1Y2j",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1743/Reviewer_6Z6H"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1743/Reviewer_6Z6H"
            ],
            "content": {
                "summary": {
                    "value": "The authors propose PsiDiff, a conditional diffusion-based model for ligand conformation generation, introducing a novel pairwise approach that incorporates ligand-target interactions and chemical properties. PsiDiff ensures rot-translational equivariance and employs a unique graph encoder, the Target-Ligand Pairwise Graph Encoder (TLPE), to implicitly extract ligand-target interactions throughout the diffusion process."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. PsiDiff exhibits a sophisticated approach in embedding chemical properties and information within the diffusion model.\n2. The methodology employed by PsiDiff in constructing graph prompt tokens, along with the strategic insertion into the ligand graph using two distinct insertion patterns, is noteworthy."
                },
                "weaknesses": {
                    "value": "1. Problem in contribution and novelty: The authors assert that existing methods in molecular conformation generation have tended to neglect vital pocket-ligand interaction information, positioning their work on transitioning from singleton to pairwise modeling as a key innovation. However, this claim warrants a critical examination. The task undertaken in this paper bears a strong resemblance to docking, a field in which the incorporation of pocket information is a fundamental aspect. Given this context, the purported novelty of integrating ligand-pocket interactions in PsiDiff appears less distinctive, as it aligns closely with established practices in other machine learning based docking methodologies.\n2. The data presented in Tables 1 and 5 highlight a pronounced enhancement in PsiDiff\u2019s performance subsequent to force field optimization. In its absence, however, PsiDiff does not exhibit competitive performance levels, particularly in docking tasks (as shown in Table 5 for the 25th percentile), lagging substantially behind methodologies such as GNINA, GLIDE, and EquiBind/TANKBind. To provide a comprehensive evaluation and fair comparison, it would be advantageous to present results for other baseline methodologies after undergoing force field optimization.\n3.  Some other recent competitive machine learning methods should be added as baselines,  like UniMol(https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/6402990d37e01856dc1d1581/original/uni-mol-a-universal-3d-molecular-representation-learning-framework.pdf),  Torsional Diffusion(https://arxiv.org/pdf/2206.01729.pdf), and DiffDock(https://arxiv.org/pdf/2210.01776.pdf), which gives much better docking performance compare to TANKBind as shown in https://arxiv.org/pdf/2302.07134.pdf."
                },
                "questions": {
                    "value": "please refer to the weakness part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1743/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698892932200,
            "cdate": 1698892932200,
            "tmdate": 1699636102940,
            "mdate": 1699636102940,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SHYqCi4arr",
                "forum": "m9zWBn1Y2j",
                "replyto": "lgFLBPSLGy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1743/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1743/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your advice. \n\nQ1:\nProblem in contribution and novelty: The authors assert that existing methods in molecular conformation generation have tended to neglect vital pocket-ligand interaction information, positioning their work on transitioning from singleton to pairwise modeling as a key innovation. However, this claim warrants a critical examination. The task undertaken in this paper bears a strong resemblance to docking, a field in which the incorporation of pocket information is a fundamental aspect. Given this context, the purported novelty of integrating ligand-pocket interactions in PsiDiff appears less distinctive, as it aligns closely with established practices in other machine learning based docking methodologies.\n\nA1:\nDocking projects optimize the binding affinity with a target, while generation methods focus on rational ligand conformations and can be evaluated independently of a specific target.\nUnlike traditional docking projects, our model, PsiDiff, takes a distinct approach by assuming a random initialization for the ligand atoms, eliminating the need for prior coordinate information. In contrast, docking methodologies primarily concentrate on the position and rotation of the ligand, making minor adjustments to the rotational bonds during conformational refinement, and relying on a rational initialization of the ligand coordinates. By starting from a random initialization, PsiDiff explores a wider range of conformational possibilities and generates diverse molecular conformations, setting it apart from docking approaches that rely on specific ligand orientations and positions.\n\nQ2:\nThe data presented in Tables 1 and 5 highlight a pronounced enhancement in PsiDiff\u2019s performance subsequent to force field optimization. In its absence, however, PsiDiff does not exhibit competitive performance levels, particularly in docking tasks (as shown in Table 5 for the 25th percentile), lagging substantially behind methodologies such as GNINA, GLIDE, and EquiBind/TANKBind. To provide a comprehensive evaluation and fair comparison, it would be advantageous to present results for other baseline methodologies after undergoing force field optimization.\n\nA2:\nAs our task is assigned to generation instead of docking without ligand coordiantes prior. We also provide the version without force field optimization.\n\nQ3:\nSome other recent competitive machine learning methods should be added as baselines, like UniMol, Torsional Diffusion, and DiffDock, which gives much better docking performance compare to TANKBind.\n\nA3:\nGiven that our task focuses on molecular generation rather than docking with prior ligand coordinates, it is important to note that our comparisons are primarily with other generation-related methods. Furthermore, we would like to highlight a concern regarding the comparison with Diffdock. While Diffdock reports results based on ligand RMSD, their code aligns the ligands to reference structures before evaluation. We believe this alignment step introduces bias and may not provide a fair comparison."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1743/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533779715,
                "cdate": 1700533779715,
                "tmdate": 1700533838878,
                "mdate": 1700533838878,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]