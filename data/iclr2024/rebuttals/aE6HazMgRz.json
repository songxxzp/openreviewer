[
    {
        "title": "Spatio-temporal Twins with A Cache for Modeling Long-term System Dynamics"
    },
    {
        "review": {
            "id": "X1m5ZHqF9A",
            "forum": "aE6HazMgRz",
            "replyto": "aE6HazMgRz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2441/Reviewer_UcXH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2441/Reviewer_UcXH"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a framework called Spatio-Temporal Twins with a Cache (STAC) for modeling long-term dynamics of physical systems. The key ideas are: 1) Using a frequency-enhanced spatial module and an ODE-enhanced temporal module to model spatial and temporal relationships from complementary perspectives; 2) Introducing a cache-based recurrent propagator to store historical feature maps; 3) Optimizing the model with techniques like teacher forcing, Mixup, and adversarial learning. The authors construct a new fire dynamics benchmark and evaluate STAC on 14 datasets, showing superior performance over baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The problem of modeling long-term dynamics is important with many applications. This paper provides a novel perspective by using a cache memory to enhance long-term dependencies.\n2. The motivation is intuitive and reasonable.\n3. This paper is well organized and clearly written.\n4. The new fire dynamics benchmark (FIRE) constructed in this work could facilitate future research in this domain.\n5. Comprehensive experiments on 14 datasets demonstrate the effectiveness and generalizability of the proposed STAC framework."
                },
                "weaknesses": {
                    "value": "1. Though this paper seems to be promising, I have to say that the novelty seems to be limited. The spatio-temporal twins are actually a two-branch model. Using frequency-based approaches in the spatial domain is nothing new. The temporal module is similar to SimVP v2's [1] but with an ODE solver. The cache memory [2] is also well developed. \n2. I really appreciate the experiments in this paper. However, the ablation study is not satisfying. The authors reported only one metric (RMSE) on only one dataset (Spherical Shallow Water). A more detailed ablation study is needed to figure out why this approach works.\n3. It lacks of complexity comparison. The authors should report the parameters and FLOPs of these baseline models.\n\n[1] Cheng Tan, Zhangyang Gao, Siyuan Li, and Stan Z Li. Simvp: Towards simple yet powerful spatiotemporal predictive learning. arXiv preprint arXiv:2211.12509, 2022.\n\n[2] Lee, Sangmin, et al. \"Video prediction recalling long-term motion context via memory alignment learning.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021."
                },
                "questions": {
                    "value": "1. Please discuss the differences between STAC and other similar models.\n2. Could you add a more detailed ablation study? Considering there are many components, a more detailed ablation study can provide more valuable insights.\n3. Please discuss the complexity of these models.\n\nI'm willing to raise my score once these issues have been well solved."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2441/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698720595604,
            "cdate": 1698720595604,
            "tmdate": 1699636180063,
            "mdate": 1699636180063,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Wux6hOpODu",
                "forum": "aE6HazMgRz",
                "replyto": "X1m5ZHqF9A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are truly grateful for the time you have taken to review our paper and your insightful review. Here we address your comments in the following.\n\n> Q1. Though this paper seems to be promising, I have to say that the novelty seems to be limited. The spatio-temporal twins are actually a two-branch model. Using frequency-based approaches in the spatial domain is nothing new. The temporal module is similar to SimVP v2's [1] but with an ODE solver. The cache memory [2] is also well developed.\n\nA1. Thank you for your comment. The novelty of this methodology comes from three parts.\n\n-  **New complementary perspective**, which explores spatio-temporal dynamics in both discrete and continuous manners. They are both closely related to our target long-term predictions.\n-  **Information fusion strategy**, which includes fine-grained fusion and coarse-grained fusion to tackle feature maps with different granularities.\n- **Cache mechanism**, which aims to store previous states, thus allowing the system to **remember** and **reuse** historical data for future predictions. Compared with E3D-LSTM storing predictions at different timesteps, our cache mechanism **stores feature maps** with a long interval for long-term spatio-temporal predictions. Moreover, we involve more complicated interaction among current states, short-term states, and long-term states by **involving short-term interaction** map $A_m$ and updated maps $Q_m$. In contrast, E3D-LSTM utilizes a simple recurrent architecture, which achieves much worse performance. \n\nThen, we describe the differences between STAC and the models mentioned in the paper [1,2].\n\n\nThe difference between SimVP-V2 and our STAC:\n- **Different objectives**. SimVP-V2 focuses on standard video prediction while our STAC focuses on long-term predictions. We also generate a dataset FIRE targetting our problem. \n- **Different methodology.** SimVP-V2 is entirely based on convolutional neural networks (CNNS) while we introduce complementary modules and cache mechanisms to benefit long-term predictions. \n- **Different performance.** From the performance comparison, our proposed method performs much better than SimVP-V2 by over 32.18%.\n\nThe difference between LMC-Memory and our STAC:\n\n- **Different objectives**. LMC-Memory focuses on video prediction while our STAC focuses on dynamics system modeling including temperature, velocity, and pressure. For example, we propose a new FIAR dataset. \n- **Different methodology.** LMC-Memory uses an external storage device to hold motion contexts while our cache-based propagator focuses on feature maps and incorporates the interaction with short-term prediction with restoring and reusing. \n- **Different performance.** From the performance comparison, our proposed method performs much better than LMC-Memory by over 3.84%."
                    },
                    "title": {
                        "value": "Response to Reviewer UcXH (I)"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405624341,
                "cdate": 1700405624341,
                "tmdate": 1700478599135,
                "mdate": 1700478599135,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cWGAmS7er3",
                "forum": "aE6HazMgRz",
                "replyto": "X1m5ZHqF9A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Q2. I really appreciate the experiments in this paper. However, the ablation study is not satisfying. The authors reported only one metric (RMSE) on only one dataset (Spherical Shallow Water). A more detailed ablation study is needed to figure out why this approach works.\n\nA2. Thanks for your comment. Our complete ablation experiments are as follows, verifying that each component of STAC complements each other. We have corrected this in the revised manuscript.\n\n| Model                                 | MSE (Fire 10 - 10) | SSIM (Fire 10 - 10) | MSE/100 (KTH 10 - 20) | SSIM (KTH 10 - 20) | MSE x 1000 (SWE 20 - 140) | SSIM x 1000(SWE 20 - 140) | Avg Training Time |\n| ------------------------------------- | ------------------ | ------------------- | --------------------- | ------------------ | ------------------------- | ------------------------- | ----------------- |\n| STAC                                  | 0.0487             | 92.87               | 0.2983                | 92.83              | 0.824                     | 97.68                     | 242s / epoch      |\n| STAC w/o FNO                          | 0.0756             | 84.54               | 0.3021                | 90.79              | 2.235                     | 79.43                     | 239s / epoch      |\n| STAC w/o Transformer                  | 0.0506             | 91.21               | 0.4765                | 83.72              | 1.093                     | 94.32                     | 192s / epoch      |\n| STAC w/o FSM                          | 0.0765             | 85.43               | 0.4893                | 82.9               | 2.352                     | 76.54                     | 187 / epoch       |\n| STAC (Replacing OTM with  ConvLSTM)   | 0.1723             | 65.69               | 1.2043                | 65.42              | 1.845                     | 83.43                     | 321s / epoch      |\n| STAC (Replacing OTM with  PredRNN)    | 0.3922             | 57.98               | OOM                   | OOM                | OOM                       | OOM                       | 654s / epoch      |\n| STAC w/o OTM                          | 0.0802             | 82.33               | 0.5644                | 78.43              | 2.153                     | 79.97                     | 209s / epoch      |\n| STAC w/o IFTM                         | 0.0596             | 90.33               | 0.7321                | 70.43              | 1.183                     | 91.23                     | 237s / epoch      |\n| STAC (Replacing CRP with Recall gate) | 0.0998             | 79.49               | 0.5145                | 80.39              | 5.986                     | 54.32                     | 598s / epoch      |\n| STAC w/o CRP                          | 0.0543             | 90.83               | 0.3343                | 87.38              | 6.322                     | 45.65                     | 200s / epoch      |\n\n\n\n> Q3. It lacks of complexity comparison. The authors should report the parameters and FLOPs of these baseline models.\n\nA3. Thank you for the valuable comments about comparing the complexity of our STAC framework with the baseline model. We have corrected this in the revised manuscript. The reason is that although we have a range of modules, the model depth is relatively small, which can save extensive computation costs. \n\n| Model      | Memory (MB) | FLOPs (G) | Params (M) | Training time |\n| ---------- | ----------- | --------- | ---------- | ------------- |\n| FNO        | 8.41        | 12.31     | 7.271      | 32s / epoch   |\n| F-FNO      | 12.3        | 13.12     | 11.21      | 76s / epoch   |\n| E3D-LSTM   | 2691        | 288.9     | 51         | 172s / epoch  |\n| MIM        | 2331        | 179.2     | 38         | 154s / epoch  |\n| PredRNN-V2 | 1721        | 117.3     | 23.9       | 126s / epoch  |\n| SimVP-V2   | 421         | 17.2      | 46.8       | 25s / epoch   |\n| LSM        | 10.21       | 14.31     | 9.002      | 37 s / epoch  |\n| U-NO       | 92          | 32.1      | 136        | 278 s / epoch |\n| STAC       | 578         | 22.81     | 25.4       | 98s / epoch   |\n\nIn light of these responses, we hope we have addressed your concerns, and hope you will consider raising your score. If there are any additional notable points of concern that we have not yet addressed, please do not hesitate to share them, and we will promptly attend to those points."
                    },
                    "title": {
                        "value": "Response to Reviewer UcXH (II)"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405686487,
                "cdate": 1700405686487,
                "tmdate": 1700452653192,
                "mdate": 1700452653192,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "j8vW6cCIHb",
                "forum": "aE6HazMgRz",
                "replyto": "X1m5ZHqF9A",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewers,\n\nThank you for your invaluable feedback. As the deadline for the author-reviewer discussion phase is approaching, we hope to make sure that our response sufficiently addressed your concerns regarding the novelty, as well as the revised version of our paper. We hope this could align with your expectations and positively influence the score. Please do not hesitate to let us know if you need any clarification or have additional suggestions.\n\nBest Regards,\n\nAuthors"
                    },
                    "title": {
                        "value": "Thank you for your invaluable feedback!"
                    }
                },
                "number": 32,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737710893,
                "cdate": 1700737710893,
                "tmdate": 1700741050021,
                "mdate": 1700741050021,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "AVDFdSF8oS",
            "forum": "aE6HazMgRz",
            "replyto": "aE6HazMgRz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2441/Reviewer_zrZ8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2441/Reviewer_zrZ8"
            ],
            "content": {
                "summary": {
                    "value": "This paper addresses the problem of modeling long-term dynamical systems in fields such as fluid dynamics, astrophysics, and earth science. Existing spatio-temporal forecasting approaches based on complex architectures like Transformers have limitations in long-term scenarios due to information loss during semantics exploration and iterative rollouts. To overcome these limitations, the paper proposes a new approach called Spatio-temporal Twins with a Cache (STAC) for long-term system dynamics modeling. STAC comprises a frequency-enhanced spatial module and an ODE-enhanced temporal module that investigates spatio-temporal relationships from complementary perspectives. The information from these twin modules is fused using channel attention to generate informative feature maps. To enhance long-term prediction, a cache-based recurrent propagator is introduced to store and utilize previous feature maps. The paper introduces a new flame flow field benchmark and conducts comprehensive validations across 14 benchmarks. Experimental results demonstrate that STAC outperforms other methods in long-term spatio-temporal prediction and partial differential equation-solving challenges. The contributions of the paper include the construction of a fire dynamics benchmark, the incorporation of cache memory concept into long-term system modeling, the proposal of a novel framework, and extensive experiments showcasing the effectiveness of STAC."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The strengths are as follows:\n\n1. Effective modeling of long-term dynamical systems: The proposed STAC approach overcomes challenges in long-term forecasting by capturing spatio-temporal relationships and leveraging historical information.\n\n2. Integration of cache memory: By incorporating a cache-based recurrent propagator, the model effectively stores and reuses informative feature maps, enhancing the accuracy of long-term predictions.\n\n3. Comprehensive experimental validation: The paper includes extensive experiments on various benchmarks, demonstrating the superior performance of STAC in long-term spatio-temporal prediction and partial differential equation-solving challenges.\n\n4. Information fusion: STAC combines complementary perspectives through twin modules, using channel attention to generate feature maps with rich semantics, leading to more informative predictions.\n\n5. Effective optimization strategies: The paper employs teacher forcing, adversarial learning, and mixup techniques to stabilize the learning process and improve the accuracy of iterative updating."
                },
                "weaknesses": {
                    "value": "My main concern about this paper is several potential drawbacks:\n\n1. Lack of truly innovative contributions: While the paper introduces several components and techniques, such as FSM, OTM, IFTM, CRP, Fourier-based Spectral Filters, teacher forcing, adversarial learning, and the new FIRE dataset, only CRP and IFTM can be considered as relatively novel contributions. The other techniques mentioned are already known and used in existing methods, which may limit the originality and novelty of the proposed approach.\n\n2. Limited explanation for the CRP technique: The paper mentions the use of a cache-based recurrent propagator (CRP) to prevent forgetting previous events and enhance long sequence prediction. However, it does not provide a clear explanation of the key parameter \"$\\alpha$\" and whether it is a learnable parameter. Additionally, CRP's similarity to traditional RNNs raises questions about its parallelization capabilities and potential limitations.\n\n3. Artificial handling and limited interpretability of IFTM: The separation of temporal and spatial processing, as well as the channel-independent merging in IFTM, appears to be a forced transformation without much interpretability. The lack of learnable factors and reliance on manual processing may hinder the scalability and extensibility of the method.\n\n4. Potential loss of spatial information in FSM: FSM applies different treatments to the same data and forcibly merges them, potentially leading to a loss of spatial information. Additionally, the direct fully connected mapping of the segmented data raises concerns about the preservation of spatial relationships and the possibility of information loss."
                },
                "questions": {
                    "value": "My questions and concerns about this paper are listed in the Weakness part. I will raise my rating if the author can address my concerns with reasonable evidence."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2441/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698743878471,
            "cdate": 1698743878471,
            "tmdate": 1699636179960,
            "mdate": 1699636179960,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "pyocT9tAQt",
                "forum": "aE6HazMgRz",
                "replyto": "AVDFdSF8oS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are truly grateful for the time you have taken to review our paper and your insightful review. Here we address your comments in the following.\n\n> Q1 . Lack of truly innovative contributions: While the paper introduces several components and techniques, such as FSM, OTM, IFTM, CRP, Fourier-based Spectral Filters, teacher forcing, adversarial learning, and the new FIRE dataset, only CRP and IFTM can be considered as relatively novel contributions. The other techniques mentioned are already known and used in existing methods, which may limit the originality and novelty of the proposed approach.\n\nA1. Thanks for your comment. The novelty of this methodology comes from three parts:\n\n-   **New complementary perspective**, which explores spatio-temporal dynamics in both discrete and continuous manners. They are both closely related to our target long-term predictions.\n-  **Information fusion strategy**, which includes fine-grained fusion and coarse-grained fusion to tackle feature maps with different granularities.\n- **Cache mechanism**, which aims to store previous states, thus allowing the system to **remember** and **reuse** historical data for future predictions. Compared with E3D-LSTM storing predictions at different timesteps, our cache mechanism **stores feature maps** with a long interval for long-term spatio-temporal predictions. Moreover, we involve more complicated interaction among current states, short-term states, and long-term states by **involving short-term interaction** map $A_m$ and updated maps $Q_m$. In contrast, E3D-LSTM utilizes a simple recurrent architecture, which achieves much worse performance. \n\nThen, the motivation for introducing these modules for dynamical system modeling is closely related to real-world data as follows:\n\n- Why FSM? FSM includes FNO and Transform to explore comprehensive semantics from complementary views. On the one hand, learning from the frequency domain is crucial for our problem. For example, ERA5 datasets containing **comprehensive atmospheric and ocean information** need to be analyzed in the **frequency domain** to discern complex climate patterns. Therefore, we design FNO in the FSM module to efficiently capture these complex data in the frequency domain. On the other hand, **mining Long-distance dependencies** is the key to our long-term prediction tasks. Especially, in **KTH datasets and FIRE dataset**s these dependencies are the key for accurate forecasting. With its self-attention mechanism, the Transformer effectively captures these long-distance dependencies and continuous actions in video sequences. Therefore, we design the Transformer in the FSM module to accurately identify and correlate distant frames in the video.\n\n- Why OTM? Still, **Long distance dependencies** are crucial for our long-term prediction tasks. Our ODE-based module can learn these naturally without increasing the depth, i.e., **infinite depth**. Moreover, **Turbulence data** contains complex dynamic information such as fluid velocity, pressure, and temperature. Therefore, we incorporate multi-scale convolution to fully understand the physical dynamic system.\n\n- Why IFTM? We design IFTM for **information fusion from previous modules** for comprehensive semantic learning. Moreover, our real datasets (e.g., SEVIR and Fire datasets) contain storm details and rapidly changing local extreme events such as flame and temperature fluctuations. Therefore, we generate informative feature maps with both coarse-grained and fine-grained semantics.\n\nThe above modules complement each other. We find from experiments that if a certain module is removed, the results will drop significantly, so we propose a unified model. Besides, this work also the contribution of new dataset and new benchmark. In the future, we will fully open-source the data sets of all working conditions and provide the code for reading and processing."
                    },
                    "title": {
                        "value": "Response to Reviewer zrZ8 (I)"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405371444,
                "cdate": 1700405371444,
                "tmdate": 1700478585660,
                "mdate": 1700478585660,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "AVpGIfuxBG",
                "forum": "aE6HazMgRz",
                "replyto": "AVDFdSF8oS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">Q2 . Limited explanation for the CRP technique: The paper mentions the use of a cache-based recurrent propagator (CRP) to prevent forgetting previous events and enhance long sequence prediction. However, it does not provide a clear explanation of the key parameter \"\u03b1\" and whether it is a learnable parameter. Additionally, CRP's similarity to traditional RNNs raises questions about its parallelization capabilities and potential limitations.\n\n\nA2. Thanks for your comment. We solve your concerns as follows:\n\n1. Description of parameter \"\u03b1\": \u03b1 is a fixed hyperparameter set to $0.2$. \n2. Parallelization strategy: The computational cost of our method mainly depends on the generation of feature maps, which is suitable for parallelization. Moreover, the complexity comparison of the proposed method is shown below. From the results, we can observe that the efficiency of our method is competitive. \n\n\n| Model      | Memory (MB) | FLOPs (G) | Params (M) | Training time |\n| ---------- | ----------- | --------- | ---------- | ------------- |\n| FNO        | 8.41        | 12.31     | 7.271      | 32s / epoch   |\n| F-FNO      | 12.3        | 13.12     | 11.21      | 76s / epoch   |\n| E3D-LSTM   | 2691        | 288.9     | 51         | 172s / epoch  |\n| MIM        | 2331        | 179.2     | 38         | 154s / epoch  |\n| PredRNN-V2 | 1721        | 117.3     | 23.9       | 126s / epoch  |\n| SimVP-V2   | 421         | 17.2      | 46.8       | 25s / epoch   |\n| LSM        | 10.21       | 14.31     | 9.002      | 37 s / epoch  |\n| U-NO       | 92          | 32.1      | 136        | 278 s / epoch |\n| STAC       | 578         | 22.81     | 25.4       | 98s / epoch   |\n\n3. When it comes to superlong prediction tasks, our cache-based design could suffer from low efficiency, which would be studied in our future works."
                    },
                    "title": {
                        "value": "Response to Reviewer zrZ8 (II)"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405404061,
                "cdate": 1700405404061,
                "tmdate": 1700452614510,
                "mdate": 1700452614510,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gk89VtWybU",
                "forum": "aE6HazMgRz",
                "replyto": "AVDFdSF8oS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Q3. Artificial handling and limited interpretability of IFTM: The separation of temporal and spatial processing, as well as the channel-independent merging in IFTM, appears to be a forced transformation without much interpretability. The lack of learnable factors and reliance on manual processing may hinder the scalability and extensibility of the method.\n\nA3. Thank you for your comment. We answer it point-by-point:\n\n1. **Why separation.** Compared with temporal signals, spatial signals include information from frequency domains, which cannot be considered simultaneously. Therefore, we separate the temporal and spatial processing. \n\n2. **Why transformation.** We do the transformation to align the dimensions of features from different sources, which is a popular strategy like padding. \n\n\n3. **Why deterministic operation**. Our Conv2d and FFN modules consist of extensive parameters, which allow our model with strong extensibility. Therefore, to increase efficiency, we utilize the deterministic operation for alignment. From the experiments, we can observe that our STAC performs better than baselines consistency across all datasets, which validate our scalability and extensibility. \n\n\n| Backbone| STAC MSE | STAC MAE | LSM MSE | LSM MAE | U-NO MSE | U-NO MAE | FNO MSE | FNO MAE | F-FNO MSE | F-FNO MAE | E3D-LSTM MSE | E3D-LSTM MAE | MIM MSE | MIM MAE | PredRNN-V2 MSE | PredRNN-V2 MAE | SimVP-V2 MSE | SimVP-V2 MAE |\n| ---------------- | -------- | -------- | ------- | ------- | -------- | -------- | -------------- | -------------- | ---------------- | ---------------- | ------------------- | ------------------- | -------------- | -------------- | --------------------- | --------------------- | ------------------- | ------------------- |\n| Turbulence       | 0.5123   | 0.5345   | 0.6412  | 0.7553  | 0.5654   | 0.6093   | 0.6567         | 0.7789         | 0.8124           | 0.9876           | 1.1234              | 1.4567              | 0.8321         | 0.9472         | 1.0163                | 1.0987                | 1.2765              | 1.4321              |\n| ERA5             | 1.9865   | 1.7791   | 3.9831  | 2.3132  | 3.4612   | 2.2931   | 2.8534         | 2.2983         | 8.9853           | 7.34317          | 3.0952              | 2.9854              | 3.3567         | 3.2236         | 2.2731                | 2.6453                | 3.0843              | 3.0743              |\n| SEVIR            | 1.9731   | 1.4054   | 2.9831  | 2.4431  | 2.2031   | 1.5632   | 3.0833         | 1.8831         | 10.9831          | 5.4432           | 4.1702              | 2.5563              | 3.9842         | 2.0012         | 3.9014                | 1.9757                | 2.9371              | 1.7743              |\n| Fire             | 0.5493   | 0.7217   | 1.2831  | 1.0932  | 1.5643   | 0.9853   | 0.9985         | 1.0432         | 2.7412           | 1.6557           | 1.0921              | 0.8731              | 1.8743         | 1.5324         | 0.7789                | 0.6863                | 1.7743              | 1.0321              |\n| KTH              | 28.8321  | 24.2216  | 39.9831 | 38.4432 | 35.8732  | 34.4322  | 33.1983        | 29.7421        | 31.8741          | 29.8753          | 86.1743             | 85.5563             | 56.5942        | 54.8426        | 51.1512               | 50.6457               | 40.8421             | 43.2931             |"
                    },
                    "title": {
                        "value": "Response to Reviewer zrZ8 (III)"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405462604,
                "cdate": 1700405462604,
                "tmdate": 1700452622259,
                "mdate": 1700452622259,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2h4YsSWe3b",
                "forum": "aE6HazMgRz",
                "replyto": "AVDFdSF8oS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">Q4 . Potential loss of spatial information in FSM: FSM applies different treatments to the same data and forcibly merges them, potentially leading to a loss of spatial information. Additionally, the direct fully connected mapping of the segmented data raises concerns about the preservation of spatial relationships and the possibility of information loss.\n\nA4. Thanks for your comment. The information fusion of different sources is very common in recent studies [1,2]. Since we have provided extensive learnable parameters in both parts, their fusion is adaptive and can enhance semantics learning. Moreover, we conduct ablation studies as below to show that removing either part decreases the performance.\n\n\nHere, we utilize fully connected mapping to make our spatial information more adaptive and more related to our target. Since we utilize an optimization process, our added parameters would be adaptively learned to provide more representation of learning capacity rather than information loss. \n\nAblation study, We have added four model variants as follows:\n\n- STAC w/o FNO, which removes FNO and only uses Transformer in our FSM module.\n- STAC w/o Transformer, which removes the Transformer module and only uses FNO in our FSM module.\n- STAC w/o FSM, which removes FSM.\n- STAC w/o FC, which removes the Fully Connected Layer.\n\n\n| Model                | MSE (Fire 10 - 10) | SSIM (Fire 10 - 10) | MSE/100 (KTH 10 - 20) | SSIM (KTH 10 - 20) | MSE x 1000 (SWE 20 - 140) | SSIM x 1000(SWE 20 - 140) | Avg Training Time |\n| -------------------- | ------------------ | ------------------- | --------------------- | ------------------ | ------------------------- | ------------------------- | ----------------- |\n| STAC                 | 0.0487             | 92.87               | 0.2983                | 92.83              | 0.824                     | 97.68                     | 242s / epoch      |\n| STAC w/o FNO         | 0.0756             | 84.54               | 0.3021                | 90.79              | 2.235                     | 79.43                     | 239s / epoch      |\n| STAC w/o Transformer | 0.0506             | 91.21               | 0.4765                | 83.72              | 1.093                     | 94.32                     | 192s / epoch      |\n| STAC w/o FSM         | 0.0765             | 85.43               | 0.4893                | 82.90              | 2.352                     | 76.54                     | 187s / epoch      |\n| STAC w/o FC          | 0.0794             | 80.85               | 0.4921                | 81.84              | 2.448                     | 74.32                     | 179s / epoch      |\n\n**Reference**\n\n[1] Peng, Zhiliang, Wei Huang, Shanzhi Gu, Lingxi Xie, Yaowei Wang, Jianbin Jiao, and Qixiang Ye. \"Conformer: Local features coupling global representations for visual recognition.\" In Proceedings of the IEEE/CVF international conference on computer vision, pp. 367-376. 2021.\n\n[2] Zhang, Jingyi, Jiaxing Huang, Zhipeng Luo, Gongjie Zhang, Xiaoqin Zhang, and Shijian Lu. \"DA-DETR: Domain Adaptive Detection Transformer With Information Fusion.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 23787-23798. 2023.\n\nIn light of these responses, we hope we have addressed your concerns, and hope you will consider raising your score. If there are any additional notable points of concern that we have not yet addressed, please do not hesitate to share them, and we will promptly attend to those points."
                    },
                    "title": {
                        "value": "Response to Reviewer zrZ8 (IV)"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405509825,
                "cdate": 1700405509825,
                "tmdate": 1700452628996,
                "mdate": 1700452628996,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "D7BsCW62kW",
                "forum": "aE6HazMgRz",
                "replyto": "AVDFdSF8oS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewers,\n\nThank you for your invaluable feedback. As the deadline for the author-reviewer discussion phase is approaching, we hope to make sure that our response sufficiently addressed your concerns regarding the contributions, as well as the revised version of our paper. We hope this could align with your expectations and positively influence the score. Please do not hesitate to let us know if you need any clarification or have additional suggestions.\n\nBest Regards, \n\nAuthors"
                    },
                    "title": {
                        "value": "Thank you for your invaluable feedback!"
                    }
                },
                "number": 31,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737683772,
                "cdate": 1700737683772,
                "tmdate": 1700741041933,
                "mdate": 1700741041933,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5ugEF0Uvus",
            "forum": "aE6HazMgRz",
            "replyto": "aE6HazMgRz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2441/Reviewer_CD63"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2441/Reviewer_CD63"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates the problem of modeling long-term dynamical systems, which are essential for understanding fluid dynamics, astrophysics, earth science, etc. The authors propose a new approach called STAC, which contains a discrete frequency-enhanced spatial module and an ODE-enhanced temporal module to capture spatial-temporal relationships of the observational data and employs a cache-based recurrent propagator to ensure the long-term prediction ability of the framework. They also utilize teacher forcing and semi-supervised adversarial learning to stabilize the learning process and enhance the reality of predicted trajectories, respectively. Moreover, the paper constructs a new benchmark (FIRE) to model fire dynamics for dynamics forecasting, which potentially benefits the research community. Extensive experiments on complex dynamics modeling, extreme local events sensing, and video prediction tasks demonstrate the superior performance of the proposed framework compared to other SOTA methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThis paper tackles an important research problem, complex dynamical system modeling, which benefits our understanding of fluid dynamics, astrophysics, earth science, etc.\n2.\tThis paper provides a well-prepared benchmark, FIRE, to facilitate the research in this field and benefit the community.\n3.\tThis paper proposes to consider spatial-temporal correlations in observational data during prediction by utilizing vision Transformer, Fourier neural operator, and neural ODEs, and incorporating cache memory concept into long-term system modeling.\n4.\tThe authors conduct extensive experiments to verify the performance of the dynamical modeling of the proposed methods from multiple perspectives."
                },
                "weaknesses": {
                    "value": "1.\tThe design of the whole framework is complicated. Although the author explains the reason why they design each module, it still lacks straightforward motivation. Do such challenges really exist in the real data? This straightforward utilization of existing techniques makes the paper novelty seem incremental.\n2.\tThe pictures in Figures 3, and 4 do not seem to show a significant improvement of STAC compared to other SOTA methods in terms of visualization.\n3.\tIn the part of the ablation study, some designs, for example, TF/M, CA, and SSAL, only contribute slightly improvement. However, SSAL may make the training of the framework become unstable. Others may increase the time complexity of the framework, which the authors do not report.\n4.\tSome notations in the paper are confusing. For example, in Section 4.3, the notation definitions of input, feature map, and output are hard to match the subsequent statement.\n\n## After Response\nI have read the response and found it addresses most of my concerns. However, I still think the straightforward utilization of existing techniques makes the paper's novelty seem incremental. Moreover, I also have concerns regarding the claimed advantage of using NODE, i.e., modeling long-distance dependencies, even with a learnable t."
                },
                "questions": {
                    "value": "1.\tCan authors provide their motivation for such complicated module design through data?\n2.\tCan authors provide the standard deviation of their experimental results?\n3.\tThe authors can conduct more persuasive experiments to address my concerns mentioned in the Weaknesses part."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Not applicable."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2441/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2441/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2441/Reviewer_CD63"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2441/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698947074398,
            "cdate": 1698947074398,
            "tmdate": 1700918349403,
            "mdate": 1700918349403,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FDo1LjwGKl",
                "forum": "aE6HazMgRz",
                "replyto": "5ugEF0Uvus",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are truly grateful for the time you have taken to review our paper and your insightful review. Here we address your comments in the following.\n\n> Q1. The design of the whole framework is complicated. Although the author explains the reason why they design each module, it still lacks straightforward motivation. Do such challenges really exist in the real data? This straightforward utilization of existing techniques makes the paper novelty seem incremental.\n\nA1. Thank you for your comment. The motivation for introducing these modules for dynamical system modeling is closely related to real-world data as follows:\n\n- Why FSM? FSM includes FNO and Transform to explore comprehensive semantics from complementary views. On the one hand, learning from the frequency domain is crucial for our problem. For example, ERA5 datasets containing **comprehensive atmospheric and ocean information** need to be analyzed in the **frequency domain** to discern complex climate patterns. Therefore, we design FNO in the FSM module to efficiently capture these complex data in the frequency domain. On the other hand, **mining Long-distance dependencies** is the key to our long-term prediction tasks. Especially, in **KTH datasets and FIRE datasets** these dependencies are the key for accurate forecasting. With its self-attention mechanism, the Transformer effectively captures these long-distance dependencies and continuous actions in video sequences. Therefore, we design the Transformer in the FSM module to accurately identify and correlate distant frames in the video.\n\n- Why OTM? Still, **long distance dependencies** are crucial for our long-term prediction tasks. Our ODE-based module can learn these naturally without increasing the depth, i.e., **infinite depth**. Moreover, **Turbulence data** contains complex dynamic information such as fluid velocity, pressure, and temperature. Therefore, we incorporate multi-scale convolution to fully understand the physical dynamic system.\n\n- Why IFTM? We design IFTM for **information fusion from previous modules** for comprehensive semantic learning. Moreover, our real datasets (e.g., SEVIR and Fire datasets) contain storm details and rapidly changing local extreme events such as flame and temperature fluctuations. Therefore, we generate informative feature maps with both coarse-grained and fine-grained semantics.\n\n\n- Why Cache? Still, **Long-term memories** are crucial for our long-term prediction tasks, especially in Fire datasets. The forgetting phenomenon is common in current methods, resulting in inferior performance. Therefore, we design a cache-based mechanism to store and **reuse** historical feature maps. \n\n\n- Why Optimization Objectives? Long-term predictions **could be unreliable**. Therefore, we introduce semi-supervised adversarial learning to improve the long-term predictive capacity of the model without the ground truth. \n\n\n**In summary, all these modules can benefit from modeling long-term dependencies for accurate long-term predictions from different perspectives (e.g., dependency mining, infinite depth, information fusion, memory reusing, and reliability).**\n\n> Q2. The pictures in Figures 3, and 4 do not seem to show a significant improvement of STAC compared to other SOTA methods in terms of visualization.\n\n\nA2. Thanks for your comment. We have revised the figure for better visualization. In Fig. 3, we use the red box to mark the local difference phenomenon and enlarge the area. in Fig. 4, we introduce a professional cartopy library to highlight the information on land, longitude, and latitude on the ERA5 dataset, which can better distinguish visual differences. We have updated the visualization results in Figure.3 and Figure.4 of the manuscript."
                    },
                    "title": {
                        "value": "Response to Reviewer CD63 (I)"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405237506,
                "cdate": 1700405237506,
                "tmdate": 1700452561100,
                "mdate": 1700452561100,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "psBfG40Vaa",
                "forum": "aE6HazMgRz",
                "replyto": "5ugEF0Uvus",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Q3. In the part of the ablation study, some designs, for example, TF/M, CA, and SSAL, only contribute slightly improvement. However, SSAL may make the training of the framework become unstable. Others may increase the time complexity of the framework, which the authors do not report.\n\nA3. Thanks for your comment. We have added more ablation studies on more datasets and the results are shown below. From the results, we can observe that the performance gain of our full model is between [1.27%, 14.5%] and over 5% in most cases, validating the effectiveness of every component. In addition, we include the variance of our model and STAC w/o SSAL. The results are shown below. From the results, we can observe the model is still stable comparably. Finally, we have completed experiments to verify the effectiveness of the proposed components.\n\n\n| Model                                   | MSE (Fire 10 - 10) (\u00b1std) | SSIM (Fire 10 - 10) (\u00b1std) | MSE/100 (KTH 10 - 20) (\u00b1std) | SSIM (KTH 10 - 20) (\u00b1std) | MSE x 1000 (SWE 20 - 140) (\u00b1std) | SSIM x 1000(SWE 20 - 140) (\u00b1std) | Avg Training Time |\n|-----------------------------------------|---------------------------|----------------------------|------------------------------|---------------------------|----------------------------------|-----------------------------------|-------------------|\n| STAC                                    | 0.0487 \u00b1 0.0003           | 92.87 \u00b1 0.6906             | 0.2983 \u00b1 0.0019               | 92.83 \u00b1 0.5481            | 0.824 \u00b1 0.004                    | 97.68 \u00b1 0.6655                    | 242s / epoch      |\n| STAC w/o FNO                            | 0.0756 \u00b1 0.0004           | 84.54 \u00b1 0.6287             | 0.3021 \u00b1 0.0019               | 90.79 \u00b1 0.536             | 2.235 \u00b1 0.0108                   | 79.43 \u00b1 0.5412                    | 239s / epoch      |\n| STAC w/o Transformer                    | 0.0506 \u00b1 0.0003           | 91.21 \u00b1 0.6783             | 0.4765 \u00b1 0.0031               | 83.72 \u00b1 0.4943            | 1.093 \u00b1 0.0053                   | 94.32 \u00b1 0.6426                    | 192s / epoch      |\n| STAC w/o FSM                            | 0.0765 \u00b1 0.0005           | 85.43 \u00b1 0.6353             | 0.4893 \u00b1 0.0031               | 82.9 \u00b1 0.4894             | 2.352 \u00b1 0.0113                   | 76.54 \u00b1 0.5215                    | 187s / epoch      |\n| STAC (Replacing OTM with ConvLSTM)      | 0.1723 \u00b1 0.001            | 65.69 \u00b1 0.4885             | 1.2043 \u00b1 0.0077               | 65.42 \u00b1 0.3862            | 1.845 \u00b1 0.0089                   | 83.43 \u00b1 0.5684                    | 321s / epoch      |\n| STAC (Replacing OTM with PredRNN)       | 0.3922 \u00b1 0.0023           | 57.98 \u00b1 0.4312             | OOM                    | OOM                | OOM                        | OOM                         | 654s / epoch      |\n| STAC w/o OTM                            | 0.0802 \u00b1 0.0005           | 82.33 \u00b1 0.6123             | 0.5644 \u00b1 0.0036               | 78.43 \u00b1 0.463             | 2.153 \u00b1 0.0104                   | 79.97 \u00b1 0.5448                    | 209s / epoch      |\n| STAC w/o IFTM                           | 0.0596 \u00b1 0.0004           | 90.33 \u00b1 0.6718             | 0.7321 \u00b1 0.0047               | 70.43 \u00b1 0.4158            | 1.183 \u00b1 0.0057                   | 91.23 \u00b1 0.6216                    | 237s / epoch      |\n| STAC (Replacing CRP with Recall gate)   | 0.0998 \u00b1 0.0006           | 79.49 \u00b1 0.5911             | 0.5145 \u00b1 0.0033               | 80.39 \u00b1 0.4746            | 5.986 \u00b1 0.0288                   | 54.32 \u00b1 0.3701                    | 598s / epoch      |\n| STAC w/o CRP                            | 0.0543 \u00b1 0.0003           | 90.83 \u00b1 0.6755             | 0.3343 \u00b1 0.0021               | 87.38 \u00b1 0.5159            | 6.322 \u00b1 0.0304                   |45.65 \u00b1 0.311                     | 200s / epoch      |\n| STAC w/o SSAL                           | 0.0632 \u00b1 0.0004           | 86.93 \u00b1 0.6465             | 0.3281 \u00b1 0.0021               | 87.89 \u00b1 0.5189            | 1.772 \u00b1 0.0085                   | 83.98 \u00b1 0.5722                    | 229s / epoch      |"
                    },
                    "title": {
                        "value": "Response to Reviewer CD63 (II)"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405248650,
                "cdate": 1700405248650,
                "tmdate": 1700452569381,
                "mdate": 1700452569381,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "ORVguCsDVm",
                "forum": "aE6HazMgRz",
                "replyto": "5ugEF0Uvus",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Q4. Some notations in the paper are confusing. For example, in Section 4.3, the notation definitions of input, feature map, and output are hard to match the subsequent statement.\n\n\nA4. Thanks for your comment. We have introduced a notation table as below to make the paper clear. \n\n| Symbol | Explanation |\n| ------ | ----------- |\n| $$ T $$ | Total length of the time series |\n| $$ T_{obs} $$ | Time interval of observed states |\n| $$ u(t) $$ | State at time step t |\n| $$ \\Omega $$ | Spatial coordinates |\n| $$ t $$ | Time coordinate |\n| $$ x $$ | Spatial position |\n| $$ R^{C\\times H \\times W} $$ | Tensor representation of the state |\n| $$ \\hat{I}_{in} $$ | Input tensor of the time series |\n| $$ F_0 $$ | Initial feature mapping |\n| $$ \\hat{I}_m $$ | Input for the time interval $$ [t_{m-1}, t_m] $$ |\n| $$ X_m $$ | Output feature mapping for the time interval $$ [t_{m-1}, t_m] $$ |\n| $$ Q_m $$ | Update mapping for the time interval $$ [t_{m-1}, t_m] $$ |\n| $$ A_m $$ | Auxiliary variables for the time interval $$ [t_{m-1}, t_m] $$ |\n| $$ W_m $$ | Weights for the time interval $$ [t_{m-1}, t_m] $$ |\n| $$ R $$ | Size of the cache |\n| $$ \\alpha $$ | Balance parameter |\n| $$ \\phi(\\cdot) $$ | Computes interactions between current and historical feature mappings |\n| $$ M $$ | The most recent R historical feature mappings stored in the cache |\n| $$ f(\\cdot) $$ | Function for updating the hidden state |\n| $$ g(\\cdot) $$ | Function for computing the update mapping |\n\n> Q5.  Can authors provide the standard deviation of their experimental results?\n\nA5. Thanks for your comment. We have added the standard deviation (SD) to the main table as shown in the table below.\n\n| **Backbone** | **STAC MSE \u00b1 SD** | **STAC MAE \u00b1 SD** | **FNO MSE \u00b1 SD** | **FNO MAE \u00b1 SD** | **F-FNO MSE \u00b1 SD** | **F-FNO MAE \u00b1 SD** | **E3D-LSTM MSE \u00b1 SD** | **E3D-LSTM MAE \u00b1 SD** | **MIM MSE \u00b1 SD** | **MIM MAE \u00b1 SD** | **PredRNN-V2 MSE \u00b1 SD** | **PredRNN- MAE \u00b1 SD** | **SimVP-V2 MSE \u00b1 SD** | **SimVP-V2 MAE \u00b1 SD** |\n| ------------ | ------------------ | ------------------ | ---------------- | ---------------- | ------------------ | ------------------ | --------------------- | --------------------- | ---------------- | ---------------- | ----------------------- | ---------------------- | --------------------- | --------------------- |\n| Turbulence   | 0.5123 \u00b1 0.05  | 0.5345 \u00b1 0.04  | 0.6567 \u00b1 0.06    | 0.7789 \u00b1 0.05    | 0.8124 \u00b1 0.07      | 0.9876 \u00b1 0.06      | 1.1234 \u00b1 0.08         | 1.4567 \u00b1 0.07         | 0.8321 \u00b1 0.05    | 0.9472 \u00b1 0.06    | 1.0163 \u00b1 0.09           | 1.0987 \u00b1 0.08          | 1.2765 \u00b1 0.10          | 1.4321 \u00b1 0.09          |\n| ERA5         | 1.9865 \u00b1 0.15  | 1.7791 \u00b1 0.12  | 2.8534 \u00b1 0.20    | 2.2983 \u00b1 0.18    | 8.9853 \u00b1 0.25      | 7.34317 \u00b1 0.22     | 3.0952 \u00b1 0.19         | 2.9854 \u00b1 0.18         | 3.3567 \u00b1 0.20    | 3.2236 \u00b1 0.19    | 2.2731 \u00b1 0.17           | 2.6453 \u00b1 0.16          | 3.0843 \u00b1 0.21          | 3.0743 \u00b1 0.20          |\n| SEVIR        | 1.9731 \u00b1 0.12  | 1.4054 \u00b1 0.10  | 3.0833 \u00b1 0.15    | 1.8831 \u00b1 0.14    | 10.9831 \u00b1 0.30     | 5.4432 \u00b1 0.25      | 4.1702 \u00b1 0.22         | 2.5563 \u00b1 0.20         | 3.9842 \u00b1 0.18    | 2.0012 \u00b1 0.17    | 3.9014 \u00b1 0.19           | 1.9757 \u00b1 0.18          | 2.9371 \u00b1 0.20          | 1.7743 \u00b1 0.15          |\n| Fire         | 0.5493 \u00b1 0.03  | 0.7217 \u00b1 0.02  | 0.9985 \u00b1 0.04    | 1.0432 \u00b1 0.03    | 2.7412 \u00b1 0.06      | 1.6557 \u00b1 0.05      | 1.0921 \u00b1 0.04         | 0.8731 \u00b1 0.03         | 1.8743 \u00b1 0.05    | 1.5324 \u00b1 0.04    | 0.7789 \u00b1 0.03           | 0.6863 \u00b1 0.02          | 1.7743 \u00b1 0.05          | 1.0321 \u00b1 0.04          |\n| KTH          | 28.8321 \u00b1 0.80 | 24.2216 \u00b1 0.70 | 33.1983 \u00b1 0.90   | 29.7421 \u00b1 0.85   | 31.8741 \u00b1 0.95     | 29.8753 \u00b1 0.90     | 86.1743 \u00b1 1.10        | 85.5563 \u00b1 1.05        | 56.5942 \u00b1 0.95   | 54.8426 \u00b1 0.90   | 51.1512 \u00b1 0.95          | 50.6457 \u00b1 0.90         | 40.8421 \u00b1 0.85         | 43.2931 \u00b1 0.80         |\n\nIn light of these responses, we hope we have addressed your concerns, and hope you will consider raising your score. If there are any additional notable points of concern that we have not yet addressed, please do not hesitate to share them, and we will promptly attend to those points."
                    },
                    "title": {
                        "value": "Response to Reviewer CD63 (III)"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700405263638,
                "cdate": 1700405263638,
                "tmdate": 1700452578937,
                "mdate": 1700452578937,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "O2GLbX73Rr",
                "forum": "aE6HazMgRz",
                "replyto": "5ugEF0Uvus",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewers,\n\nThank you for your invaluable feedback. As the deadline for the author-reviewer discussion phase is approaching, we hope to make sure that our response sufficiently addressed your concerns regarding the motivation and details, as well as the revised version of our paper. We hope this could align with your expectations and positively influence the score. Please do not hesitate to let us know if you need any clarification or have additional suggestions.\n\nBest Regards, \n\nAuthors"
                    },
                    "title": {
                        "value": "Thank you for your invaluable feedback!"
                    }
                },
                "number": 30,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737661821,
                "cdate": 1700737661821,
                "tmdate": 1700741030375,
                "mdate": 1700741030375,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "l1z3BCeXEN",
            "forum": "aE6HazMgRz",
            "replyto": "aE6HazMgRz",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission2441/Reviewer_rchA"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission2441/Reviewer_rchA"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on the long-term spatiotemporal dynamics modeling. They propose the STAC by combing the advanced spatial and temporal modeling backbones and presenting a cache-based recurrent propagator to store the previous feature maps to avoid information loss. Besides, the authors propose a compound training loss to optimize STAC. Experimentally, STAC shows favorable performance in a wide range of benchmarks, including the newly generated flame flow field benchmark."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThis paper presents the STAC model to tackle the problem in long-term dynamic prediction, which is technologically reasonable.\n\n2.\tThe authors experiment on a wide range of benchmarks to demonstrate the effectiveness of STAC.\n\n3.\tThis paper is clearly presented and well-written."
                },
                "weaknesses": {
                    "value": "1.\tAbout the novelty. \n\nGenerally, I think the technology design is reasonable. However, in my opinion, I think it is insufficient in novelty. STAC just combines a series of advanced models, including FNO, Vision Transformer, Neural ODE and a similar recall mechanism proposed by E3D-LSTM. The proposed training strategy is also in a combination style. For me, it is hard to find the novel part in this model.\n\nNote that I am not attempt to enforce the authors to build a completely new model or block. I just think they fail in illustrating their advantages beyond other models. For example, they should consider the following questions:\n\n-\tWhy should they combine vision transformer and FNO? FNet [1] has shown that the feedforward layer can perform like FFT. Why not just only use Transformer or FNO?\n\n-\tWhy can Neural ODE capture the continuous dynamics? I know that Neural ODE can achieves the adaptive depth or adaptive temporal interval. But according to the equation and code, I think the usage here is equivalent to a simple rk4 algorithm. It is hard to claim that they learn the continuous dynamic feature. Besides, They don\u2019t present the necessity in using Neural ODE.\n\n-\tAre the experimental datasets temporally irregular? According to the paper, I think the input sequences are equally collected along the temporal dimension.\n\n-\tAbout the cache-based design. I think it is necessary to demonstrate its advancement over the temporal recall gate in E3D-LSTM.\n\n[1] FNet: Mixing Tokens with Fourier Transforms, ACL 2022.\n\n2. About the experiment.\n\n(1) In addition to the performance, they should compare the efficiency with other baselines, including running time, GPU memory and parameter size.\n\n(2) In the current version, they only compare STAC with video prediction baselines. How about the advanced neural operators, such as LSM [2], U-NO [3]?\n\n(3) Are all the baselines trained by the same loss as STAC? This point is essential to ensure a fair comparison.\n\n(4) More detailed ablations are expected. They should also conduct the following experiments:\n\n- Removing FNO or Transformer in FSM.\n\n- Replacing OTM with ConvLSTM or PredRNN.\n\n- Replacing the CRP with the recall gate in E3D-LSTM.\n\n[2] Solving High-Dimensional PDEs with Latent Spectral Models, ICML 2023\n\n[3] U-NO: U-shaped Neural Operators, TMLR 2023"
                },
                "questions": {
                    "value": "All the questions are listed above, including novelty, experiment design. Here are several serious problems that should be clarified:\n\n(1) The acutal usage of OTM is inconsistent to their expection.\n\n(2) Are all the baselines trained by the same loss?\n\n(3) More neural operator baselines are expected.\n\n(4) Demonstrate the novelty of STAC.\n\nI think it is favorable that the authors experiment on extensive benchmarks. But I have some serious concerns. if the authors reply my questions properly, I am willing to raise my score."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission2441/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2441/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission2441/Reviewer_rchA"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission2441/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699534036587,
            "cdate": 1699534036587,
            "tmdate": 1700558200269,
            "mdate": 1700558200269,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Me4R8DEaDz",
                "forum": "aE6HazMgRz",
                "replyto": "l1z3BCeXEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We are truly grateful for the time you have taken to review our paper and your insightful review. Here we address your comments in the following.\n\n> Q1. However, in my opinion, I think it is insufficient in novelty. STAC just combines a series of advanced models, including FNO, Vision Transformer, Neural ODE, and a similar recall mechanism proposed by E3D-LSTM. The proposed training strategy is also in a combination style. For me, it is hard to find the novel part in this model.\n\nA1. Thanks for your comment. The novelty of this methodology comes from three parts.\n\n-  **New complementary perspective**, which explores spatio-temporal dynamics in both discrete and continuous manners. They are both closely related to our target long-term predictions.  \n-  **Information fusion strategy**, which includes fine-grained fusion and coarse-grained fusion to tackle feature maps with different granularities.\n- **Cache mechanism**, which aims to store previous states, thus allowing the system to **remember** and **reuse** historical data for future predictions. Compared with E3D-LSTM storing predictions at different timesteps, our cache mechanism **stores feature maps** with a long interval for long-term spatiotemporal predictions. Moreover, we involve more complicated interaction among current states, short-term states, and long-term states by **involving short-term interaction** map $A_m$ and updated maps $Q_m$. In contrast, E3D-LSTM utilizes a simple recurrent architecture, which achieves much worse performance. \n\nBesides, this work also the contribution of new dataset and new benchmark. In the future, we will fully open-source the data sets of all working conditions and provide the code for reading and processing.\n\n> Q2. Why should they combine vision transformer and FNO? FNet has shown that the feedforward layer can perform like FFT. Why not just only use Transformer or FNO?\n\nA2. Thanks for your comment. We have added four model variants as follows:\n\n- STAC w/o FNO, which removes FNO and only uses Transformer in our FSM module.\n- STAC w/o Transformer, which removes the Transformer module and only uses FNO in our FSM module.\n- STAC w/o FNO&Transformer +Fnet, which removes the FNO and Transformer modules and replaces them with Fnet.\n- Fnet, which only uses Fnet.\n\nThe compared performance is shown below. From the results, we can find that both mechanisms have a crucial effect on performance. The reason is that Transformer focuses on capturing the correlation between pixels, while FNO learns function mapping in the frequency domain. Combining them can provide a comprehensive for semantics learning. In addition, incorporating Fnet into STAC and the predictions alone cannot achieve superior performance as well.\n\n\n| Model                          | MSE (Fire 10 - 10) | SSIM (Fire 10 - 10) | MSE/100 (KTH 10 - 20) | SSIM (KTH 10 -20) |\n| ------------------------------ | ------------------ | ------------------- | --------------------- | ----------------- |\n| STAC                           | 0.0487             | 92.87               | 0.2983                | 92.83             |\n| STAC w/o FNO                   | 0.0756             | 84.54               | 0.3021                | 90.79             |\n| STAC w/o Transformer           | 0.0506             | 91.21               | 0.4765                | 83.72             |\n| STAC w/o FNO&Transformer +Fnet | 0.1281             | 79.48               | 0.7325                | 78.23             |\n| Fnet                           | 0.7641             | 45.43               | 24.5432               | 56.41             |\n\n> Q3. Why can Neural ODE capture the continuous dynamics? I know that Neural ODE can achieve the adaptive depth or adaptive temporal interval. However, I think the usage here is equivalent to a simple rk4 algorithm. It is hard to claim that they learn the continuous dynamic feature. Besides, They don\u2019t present the necessity in using Neural ODE.\n\nA3. Thanks for your comment. Our approach utilizes Neural ODE to explore spatiotemporal relationships in a continuous way, which can allow the capture of long-range correlations naturally without increasing the depth. This point is important for effective long-term predictions. We have added a model invariant STAC w/o OTM, which removes the ODE module. The performance is shown below. From the results, we can observe our ODE module is necessary for accurate long-term prediction. \n\n| Model        | MSE (Fire 10 - 10) | SSIM (Fire 10 - 10) | MSE/100 (KTH 10 - 20) | SSIM (KTH 10 - 20) | MSE x 1000 (SWE 20 - 140) |\n| ------------ | ------------------ | ------------------- | --------------------- | ------------------ | ------------------------- |\n| STAC w/o OTM | 0.0802             | 82.33               | 0.5644                | 78.43              | 2.153                     |\n| STAC         | 0.0487             | 92.87               | 0.2983                | 92.83              | 0.824                     |"
                    },
                    "title": {
                        "value": "Response to Reviewer rchA (I)"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404688091,
                "cdate": 1700404688091,
                "tmdate": 1700478560425,
                "mdate": 1700478560425,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cI4JJ4OlWZ",
                "forum": "aE6HazMgRz",
                "replyto": "l1z3BCeXEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "> Q4. Are the experimental datasets temporally irregular? According to the paper, I think the input sequences are equally collected along the temporal dimension.\n\nA4. Thanks for your comment. The dataset we use is temporally regular. The complete dataset statistics are as follows:\n\n  **Table: Dataset statistics.** *N_tr* and *N_te* denote the number of instances in the training and test sets. The lengths of the input and prediction sequences are *I_l* and *O_l*, respectively.\n\n  | **Dataset**     | **N_tr** | **N_te** | **(C, H, W)**  | **I_l** | **O_l** | **Interval** |\n  | --------------- | -------- | -------- | -------------- | ------- | ------- | ------------ |\n  | Turbulence      | 5000     | 1000     | (3, 300, 300)  | 50      | 50      | 1 second     |\n  | ERA5 (Global)   | 10000    | 2000     | (1, 1440, 720) | 10      | 10      | 1 day        |\n  | ERA5 (Local)    | 5000     | 1000     | (2, 200, 200)  | 8       | 8       | 1 hour       |\n  | KTH             | 108717   | 4086     | (1, 128, 128)  | 10      | 20      | 1 step       |\n  | SEVIR           | 4158     | 500      | (1, 384, 384)  | 13      | 12      | 5 mins       |\n  | Fire            | 6000     | 1500     | (2, 32, 480)   | 50      | 350      | 1 second     |\n  | SWE             | 2000     | 200      | (1, 128, 256)  | 20      | 140      | 1 second     |\n  | dynamics system | 6000     | 1200     | (3, 128, 128)  | 2       | 2       | 1 second     |\n\n> Q5. About the cache-based design. I think it is necessary to demonstrate its advancement over the temporal recall gate in E3D-LSTM.\n\nA5. Thanks for your comment. We have added a model variant STAC w/ E3D, which replaces our cache-based design with the temporal recall gate in E3D-LSTM. The compared results are shown below. From the results, we can observe that STAC performs the best in all cases. The reason is that our module not only stores feature maps with a long interval but also involves short-term interaction maps into spatio-temporal predictions. \n\n| Iuput-Output length                   | 50 - 400   | 50 - 400    | 20 - 140        | 20 - 140   | 10 - 40    | 10 - 40    |\n| ------------------------------------- | ---------- | ----------- | --------------- | ---------- | ---------- | ---------- |\n| Model                                 | MSE (Fire) | SSIM (Fire) | MSE x 100 (SWE) | SSIM (SWE) | PSNR (KTH) | SSIM (KTH) |\n| E3D-LSTM                              | 1.2983     | 75.8721     | 0.2298          | 76.3312    | 30.5931    | 87.4221    |\n| STAC                                  | 0.6631     | 88.8731     | 0.0824          | 97.6762    | 33.9831    | 92.1176    |\n| STAC w/ E3D | 0.9987     | 83.4730      | 0.1222          | 87.283     | 31.3984    | 88.3984    |\n\n> Q6. In addition to the performance, they should compare the efficiency with other baselines, including running time, GPU memory and parameter size.\n\nA6. Thanks for your comment. We have added the following table as follows. From the comparison, we can observe that our efficiency is competitive. The reason is that although we have a range of modules, the model depth is relatively small, which can save extensive computation costs. \n\n| Model      | Memory (MB) | FLOPs (G) | Params (M) | Training time |\n| ---------- | ----------- | --------- | ---------- | ------------- |\n| FNO        | 8.41        | 12.31     | 7.271      | 32s / epoch   |\n| F-FNO      | 12.3        | 13.12     | 11.21      | 76s / epoch   |\n| E3D-LSTM   | 2691        | 288.9     | 51         | 172s / epoch  |\n| MIM        | 2331        | 179.2     | 38         | 154s / epoch  |\n| PredRNN-V2 | 1721        | 117.3     | 23.9       | 126s / epoch  |\n| SimVP-V2   | 421         | 17.2      | 46.8       | 25s / epoch   |\n| LSM        | 10.21       | 14.31     | 9.002      | 37 s / epoch  |\n| U-NO       | 92          | 32.1      | 136        | 278 s / epoch |\n| STAC       | 578         | 22.81     | 25.4       | 98s / epoch   |\n\n>Q7. In the current version, they only compare STAC with video prediction baselines. How about the advanced neural operators, such as LSM [2], U-NO [3]?\n\nA7. Thanks for your comment. We have added LSM and U-NO for a more comprehensive evaluation. The experimental results show that the STAC model outperforms LSM and U-NO on different datasets, which validates the superiority of the proposed STAC.\n\n| Model      | STAC    | STAC    | LSM     | LSM     | U-NO    | U-NO    |\n| ---------- | ------- | ------- | ------- | ------- | ------- | ------- |\n| Dataset    | MSE     | MAE     | MSE     | MAE     | MSE     | MAE     |\n| Turbulence | 0.5123  | 0.5345  | 0.6412  | 0.7553  | 0.5654  | 0.6093  |\n| ERA5       | 1.9865  | 1.7791  | 3.9831  | 2.3132  | 3.4612  | 2.2931  |\n| SEVIR      | 1.9731  | 1.4054  | 2.9831  | 2.4431  | 2.2031  | 1.5632  |\n| Fire       | 0.5493  | 0.7217  | 1.2831  | 1.0932  | 1.5643  | 0.9853  |\n| KTH        | 28.8321 | 24.2216 | 39.9831 | 38.4432 | 35.8732 | 34.4322 |"
                    },
                    "title": {
                        "value": "Response to Reviewer rchA (II)"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404741458,
                "cdate": 1700404741458,
                "tmdate": 1700452489449,
                "mdate": 1700452489449,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gEohLdMch1",
                "forum": "aE6HazMgRz",
                "replyto": "l1z3BCeXEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">Q7. In the current version, they only compare STAC with video prediction baselines. How about the advanced neural operators, such as LSM [2], U-NO [3]?\n\nA7. Thanks for your comment. We have added LSM and U-NO for a more comprehensive evaluation. The experimental results show that the STAC model outperforms LSM and U-NO on different datasets, which validates the superiority of the proposed STAC.\n\n| Model      | STAC    | STAC    | LSM     | LSM     | U-NO    | U-NO    |\n| ---------- | ------- | ------- | ------- | ------- | ------- | ------- |\n| Dataset    | MSE     | MAE     | MSE     | MAE     | MSE     | MAE     |\n| Turbulence | 0.5123  | 0.5345  | 0.6412  | 0.7553  | 0.5654  | 0.6093  |\n| ERA5       | 1.9865  | 1.7791  | 3.9831  | 2.3132  | 3.4612  | 2.2931  |\n| SEVIR      | 1.9731  | 1.4054  | 2.9831  | 2.4431  | 2.2031  | 1.5632  |\n| Fire       | 0.5493  | 0.7217  | 1.2831  | 1.0932  | 1.5643  | 0.9853  |\n| KTH        | 28.8321 | 24.2216 | 39.9831 | 38.4432 | 35.8732 | 34.4322 |\n\n>Q8. Are all the baselines trained by the same loss as STAC? This point is essential to ensure a fair comparison.\n\nA8. Thanks for your comment. The loss function of the baseline follows the original paper, which is MSE loss. Considering fairness, we train STAC with only MSE loss. The experimental results are shown in the table below. It can be seen that with only MSE loss, our STAC can outperform the baselines, and adding our designed loss would further increase the performance. \n\n\n| Dataset             | Fire   | Fire    | ERA5   | ERA5    |\n| ------------------- | ------ | ------- | ------ | ------- |\n| Model               | MSE    | SSIM    | MSE    | SSIM    |\n| STAC                | 0.5493 | 92.3192 | 1.9865 | 87.4531 |\n| STAC(only MSE Loss) | 0.6432 | 90.8752 | 2.1129 | 85.4853 |\n| PredRNN-V2          | 0.7789 | 85.9743 | 2.2731 | 84.9853 |\n| SimVP-V2            | 1.7743 | 77.8654 | 3.0843 | 77.3212 |\n| FNO                 | 0.9985 | 82.2218 | 2.8534 | 79.3834 |\n| LSM                 | 0.9654 | 83.9482 | 2.9831 | 79.4393 |"
                    },
                    "title": {
                        "value": "Response to Reviewer rchA (III)"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404788210,
                "cdate": 1700404788210,
                "tmdate": 1700452497864,
                "mdate": 1700452497864,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QHHUC77Swe",
                "forum": "aE6HazMgRz",
                "replyto": "l1z3BCeXEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">Q9. More detailed ablations are expected. They should also conduct the following experiments:\n\n> Removing FNO or Transformer in FSM.\n\n> Replacing OTM with ConvLSTM or PredRNN.\n\n> Replacing the CRP with the recall gate in E3D-LSTM.\n\n\nA9. Thanks for your comment. We have added five model variants as follows:\n\n- STAC w/o FNO, which removes FNO and only uses Transformer in our FSM module.\n- STAC w/o Transformer, which removes the Transformer module and only uses FNO in our FSM module.\n- STAC (With ConvLSTM), which replaces the OTM module with ConvLSTM.\n- STAC (With PredRNN), which replaces the OTM module with PredRNN.\n- STAC (With Recall gate), which replaces the CRP with the Recall gate.\n\nExperiments show that removing FNO and Transformer from the STAC model reduces performance especially Transformer has a significant impact. Replacing OTM with ConvLSTM or PredRNN significantly degrades performance, especially PredRNN replacement leads to memory overflow. Replacing CRP with Recall gate also shows the importance of CRP, whose removal leads to performance loss. \n\n \n\n| Model                                 | MSE (Fire) | SSIM (Fire) | MSE/100 (KTH) | SSIM (KTH) |\n| ------------------------------------- | ---------- | ----------- | ------------- | ---------- |\n| STAC                                  | 0.0487     | 92.87       | 0.2983        | 92.83      |\n| STAC w/o FNO                          | 0.0756     | 84.54       | 0.3021        | 90.79      |\n| STAC w/o Transformer                  | 0.0506     | 91.21       | 0.4765        | 83.72      |\n| STAC (With ConvLSTM)    | 0.1723     | 65.69       | 1.2043        | 65.42      |\n| STAC (With PredRNN)     | 0.3922     | 57.98       | OOM           | OOM        |\n| STAC (With Recall gate) | 0.0998     | 79.49       | 0.5145        | 80.39      |\n\nIn light of these responses, we hope we have addressed your concerns, and hope you will consider raising your score. If there are any additional notable points of concern that we have not yet addressed, please do not hesitate to share them, and we will promptly attend to those points."
                    },
                    "title": {
                        "value": "Response to Reviewer rchA (IV)"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700404803191,
                "cdate": 1700404803191,
                "tmdate": 1700452507412,
                "mdate": 1700452507412,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XrPdv9SNd7",
                "forum": "aE6HazMgRz",
                "replyto": "QHHUC77Swe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Reviewer_rchA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Reviewer_rchA"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "I appreciate the authors' effort in clarifying their novelty and providing sufficient ablations and baselines. They made a great effort obviously.\n\nMost of my concerns are resolved. However, the questions about continuous modeling still remain (Q3 and Q4).\n\n(1) I don't think the usage in STAC is Neural ODE. It is just a rk4 algorithm. If you do want to claim that your model takes benefits from Neural ODE, you need to use the learnable temporal steps $t$.\n\n(2) Would you please clarify this comment \"which can allow the capture of long-range correlations naturally without increasing the depth\" in your rebuttal? What kind of long-range correlations do you mean?\n\nOverall, I think the ODE claim in this paper is not rigorous, which obviously requires a huge revision to the paper. Thus, I would like to raise my score to 5 but cannot give an acceptance recommendation."
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700558178415,
                "cdate": 1700558178415,
                "tmdate": 1700558178415,
                "mdate": 1700558178415,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DBzNgIxrkr",
                "forum": "aE6HazMgRz",
                "replyto": "l1z3BCeXEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your feedback and we are happy to resolve your further concerns as follows:\n\n> Q1. I don't think the usage in STAC is Neural ODE. It is just a rk4 algorithm. If you do want to claim that your model takes benefits from Neural ODE, you need to use the learnable temporal steps $t$.\n\nA1. Thanks for your comment. Clearly, the earliest neural ODE [1] also focuses on the fixed depth, but introduces the continuous propagation with benefits. Moreover, [2] also utilizes the fixed step $t$ with performance improvement, which shows the benefit of adopting neural ODE with fixed steps. Moreover, we would include learnable $t$ in our future work. \n\n> Would you please clarify this comment \"which can allow the capture of long-range correlations naturally without increasing the depth\" in your rebuttal? What kind of long-range correlations do you mean?\n\nA2. Thanks for your comment. Here, the long-range correlations mean the relationships of pixels far away in tensor $\\bar{I}^{in}$, which require a large receptive field to capture. Here, neural ODE utilizes continuous propagation to get rid of stacking a range of CNN blocks. \n\nThanks again for appreciating our work and for your constructive suggestions. Please let us know if you have further questions.\n\n[1] Chen et al. Neural Ordinary Differential Equations.\n\n[2] Jin et al., Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs"
                    },
                    "title": {
                        "value": "Thanks for your feedback!"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700637717809,
                "cdate": 1700637717809,
                "tmdate": 1700662384253,
                "mdate": 1700662384253,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4mXOI4Qe1e",
                "forum": "aE6HazMgRz",
                "replyto": "l1z3BCeXEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your reply !"
                    },
                    "comment": {
                        "value": "Dear Reviewer rchA,\n\nThank you very much again for the time and effort put into reviewing our paper. We believe that we have addressed all your concerns in our response. We have also followed your suggestion to improve our paper and have added additional experimental analysis. We kindly remind you that we are approaching the end of the discussion period. We would love to know if there is any further concern, additional experiments, suggestions, or feedback,  we kindly hope that you can consider increasing the score.\n\nBest regards,\n\nAll authors"
                    }
                },
                "number": 23,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700723241122,
                "cdate": 1700723241122,
                "tmdate": 1700723306473,
                "mdate": 1700723306473,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0XYluKG82w",
                "forum": "aE6HazMgRz",
                "replyto": "lKBJg0hOFY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Reviewer_rchA"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Reviewer_rchA"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your response"
                    },
                    "comment": {
                        "value": "Dear reviewer,\n\nThanks for your response and try the learnable t. But for me, the description of \"which can allow the capture of long-range correlations naturally without increasing the depth\" is still not well-supported. Even though you can \"increase\" the depth in favorable efficiency with NODE, the reception field may not increase as you want.\n\nConsidering the novelty and soundness of this paper, I would like to keep my original score."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700733297289,
                "cdate": 1700733297289,
                "tmdate": 1700733297289,
                "mdate": 1700733297289,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "g7xc02pBIx",
                "forum": "aE6HazMgRz",
                "replyto": "l1z3BCeXEN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission2441/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your invaluable feedback!"
                    },
                    "comment": {
                        "value": "Thanks for your feedback and we are happy to resolve your further concerns as follows:\n\n> Q1. The description of \"which can allow the capture of long-range correlations naturally without increasing the depth\" is still not well-supported.\n\nA1. Thanks for your comment. Here, we revised our statement into \"which can allow the capture of long-range correlations naturally with robustness\" since Neural ODE has the property of robustness with increased propagation depths, as stated in Sec. 5.4 of [1]. This is one of the most important properties of Neural ODE compared with discrete methods. We have revised the manuscript accordingly. \n\n[1] Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs\n\n> Q2. About the soundness.\n\nA2. Thanks for your comment. We have added extensive clarification and experiments to address all the concerns. Moreover, the other reviewers all give a \"3\" for soundness. If there are any remaining issues or if you require further clarification, please feel free to inform us.\n\n> Q3. About the novelty.\n\nA3. Thanks for your comment. As mentioned earlier, our method consists of three parts, i.e., complementary perspective, information fusion strategy and cache mechanism, which are novel compared with existing works. This work also the contribution of **new dataset and new benchmark in advancing the community**. And we are committed to **making our complete code and the dataset publicly available.**\n\nAs the deadline for the author-reviewer discussion phase is approaching, we hope to make sure that our response sufficiently addressed your concerns regarding the revised version. We hope this could align with your expectations and positively influence the score. Please do not hesitate to let us know if you need any clarification or have additional suggestions."
                    }
                },
                "number": 29,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission2441/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700735076946,
                "cdate": 1700735076946,
                "tmdate": 1700741072270,
                "mdate": 1700741072270,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]