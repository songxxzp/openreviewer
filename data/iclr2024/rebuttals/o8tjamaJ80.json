[
    {
        "title": "Adversarial AutoMixup"
    },
    {
        "review": {
            "id": "6NcpfhI1xc",
            "forum": "o8tjamaJ80",
            "replyto": "o8tjamaJ80",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6937/Reviewer_sHE4"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6937/Reviewer_sHE4"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a new augmentation technique. First it proposes hard samples to train and secondly a robustification of the classifier. The method is evaluated on 4 datasets"
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The idea to augment with hard examples is interesting. Furthermore, to iterate between augmentation and classifier is also interesting.\nShowed results are strong."
                },
                "weaknesses": {
                    "value": "I do not see any significant weakness. The method is harder to implement and it requires more resources that other augmentation techniques, but given the timeline of augmentation, it is expected"
                },
                "questions": {
                    "value": "None. I see this paper as a clear contribution."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6937/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698611244920,
            "cdate": 1698611244920,
            "tmdate": 1699636809037,
            "mdate": 1699636809037,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "BUiweEBkWd",
                "forum": "o8tjamaJ80",
                "replyto": "6NcpfhI1xc",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6937/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6937/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**A1:Thank you for your comments on our work.** \n\nIn line with the point you raise, we have added a plot of efficiency against accuracy in Figure 9 in the Appendix in page 16.  From Figure 9, we observe that our approach takes more time than AutoMix for training but it achieves the best performance w.r.t the existing approaches.  For testing, nonetheless, there is no difference between AutoMix and AdAutoMix in terms of time cost."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6937/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282887850,
                "cdate": 1700282887850,
                "tmdate": 1700282887850,
                "mdate": 1700282887850,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rmaDAurcs5",
            "forum": "o8tjamaJ80",
            "replyto": "o8tjamaJ80",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6937/Reviewer_xmzW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6937/Reviewer_xmzW"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an adversarial data augmentation strategy that builds on top of AutoMix. The framework alternates between training a mixed example generator and a target classifier. The mixed sample generator aims to produce hard examples and the target tries to improve generalization by learning robust features. With automatic mixup approaches (based on saliency or otherwise) the combination is deterministically selected, and there is no sample diversification. To mitigate this, the method proposes an adversarial generator instead. \nTo prevent a collapse from the generator, an EMA teacher and a weighted cosine similarity term between the mixed sample and individual samples is used for end-to-end learning."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Results are consistently better than AutoMixup and the evaluation (Table 1) is thorough.\n\n\n\n--------\nPost-rebuttal:\n\nThe authors have adequately addressed the concerns in the review. Useful experiments and ablations have been added as well. I'm still a little skeptical about the actual impact of the paper, from the methods and corresponding evaluation numbers in the paper I believe that we're at the point of diminishing returns. \n\nI've therefore increased my score to a 6."
                },
                "weaknesses": {
                    "value": "There is no evaluation compared to Adversarial data augmentation approaches [1, 2, 3, 4]. At least an introduction or related works section should be added as relevant approaches to the problem.\n\nThe term \u201ccross attention module\u201d (CAM) should not be used as it can be confused with \u201cclass activation mapping\u201d (CAM) which is generally used in saliency-based data augmentation methods. \n\nSome notation is confusing - the encoder weight is updated with an EMA of the weights of the classifier - $\\hat{\\phi} = \\xi \\hat{\\phi} + (1-\\xi) W$. Is it unclear if the encoder refers to the generator or the classifier. Later near Equation 12, $\\psi$ is referred to as a target classifier with weights $W$. \n\nEquation 7 and 8 refer to the same value of $y$ used in cross entropy. It is better to keep the form of the loss consistent, since $y_{mix} = \\sum_i y_i \\lambda_i$, implies \n\n$\\sum_i L_{ce}(\\psi(x_{mix}), y_i) \\lambda_i = \\sum_i -\\lambda_i y_i \\log(\\psi(x_{mix})) = \\log(\\psi(x_{mix})) \\sum_i -\\lambda_i y_i = -\\log(\\psi(x_{mix})) y_{mix} = L_{ce}((\\psi(x_{mix}), y_{mix}))$\n\n\nEquations 10 through 15 are badly formatted and hard to read. It is also unclear what the individual contribution of the four cross-entropy terms are, and a suitable way to choose $\\alpha$ and $\\beta$. \n\nSection 4.2 mentions the proposed method has the lowest calibration error, but there is no table showing the ECE of other baselines. Fig.4. shows the ECE of only the proposed method.\n\n\nTypos and minor mistakes:\n\u201cto facility representation\u201d\nMxiup \u2192 mixup\nbad formatting  in eq 5\nnotation in eq 6, 7 is unclear. is the $*$ scalar multiplication?\nwhat is meant by \u201cinherent meaning of images\u201d - this sounds slightly unscientific, this should be explained in a bit more detail \n\nCurrently, I think the paper needs a lot of work - both in terms of coherence and motivation for the method. There are too many elements all over the place and it is unclear what the improvement actually comes from. The evaluation criteria is not standard (see Questions) and needs more justification. Therefore, I recommend an initial reject.\n\n_______\n\n\n[1] Zhang, Jiajin, et al. \"Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation.\" International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer Nature Switzerland, 2023.\n\n[2] Xu, Minghao, et al. \"Adversarial domain adaptation with domain mixup.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 04. 2020.\n\n[3] Zhao, Long, et al. \"Maximum-entropy adversarial data augmentation for improved generalization and robustness.\" Advances in Neural Information Processing Systems 33 (2020): 14435-14447.\n\n[4] Antoniou, Antreas, Amos Storkey, and Harrison Edwards. \"Data augmentation generative adversarial networks.\" arXiv preprint arXiv:1711.04340 (2017)."
                },
                "questions": {
                    "value": "The method compares the median of the top-1 test accuracy in the last 10 training epochs. Since adversarial methods are generally brittle and have unstable training dynamics, does the mean test accuracy fluctuate a lot? Also, it seems that there is no validation set used to choose the best checkpoint. This evaluation criteria is not justified in the paper."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6937/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6937/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6937/Reviewer_xmzW"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6937/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698628653128,
            "cdate": 1698628653128,
            "tmdate": 1700490294500,
            "mdate": 1700490294500,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "89bjQax8iE",
                "forum": "o8tjamaJ80",
                "replyto": "rmaDAurcs5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6937/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6937/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W1: There is no evaluation compared to Adversarial data augmentation approaches [1, 2, 3, 4]. At least an introduction or related works section should be added as relevant approaches to the problem.**  \n\n**A1:** Thanks for your suggestions. We have included the performance of adversarial data augmentation approaches [1, 2, 3, 4] in comparison experiments. Also, we added them in the related works\u2019 section in subsection 2.3 in page 3.\nIn work[1], a Sensitivity-guided Spectral Adversarial MixUp (SAMix) method is proposed to generate target-style images for domain adaptation. Similarly, work[2]  proposes an adversarial learning framework which maps both domains to a common latent distribution by domain mixup, and efficiently transfer knowledge learned on the supervised domain to its unsupervised counterpart. Work[3] investigates adversarial data argumentation from an information theory perspective and proposes a maximum-entropy regularization in the maximization phase of adversarial data augmentation. In work[4], a novel Generative Adversarial Network(GAN) is investigated to learn a representation and generate samples for data augmentation.\nTu summarize, the adversarial mixup models in works[1][2] are proposed to generate mix features or images for unsupervised domain adaptation instead of classification. Work[3] investigates adversarial framework with maximum-entropy regularization to generate samples for classification.  Work[4] proposed a GAN for image generation and classification.  Therefore, we compared these works[3][4] with our model in terms of accuracy improvement. The classification accuracies are listed in Table 11 in Appendix in page 17. The results show that our approach outperforms the existing adversarial data augmentation approaches mentioned in the response.  \n\n***\n**W2:The term \u201ccross attention module\u201d (CAM) should not be used as it can be confused with \u201cclass activation mapping\u201d (CAM) which is generally used in saliency-based data augmentation methods.**  \n\n**A2:** Thanks for pointing this out. We have replaced the \u201ccross attention module (CAM)\u201d by \u201ccross attention block (CAB)\u201d in revised version.  \n\n***\n**W3: Some notation is confusing - the encoder weight is updated with an EMA of the weights of the classifier $\\widehat\\phi=\\xi\\widehat\\phi+(1-\\xi)W'$. Is it unclear if the encoder refers to the generator or the classifier. Later near Equation 12, $\\psi$ is referred to as a target classifier with weights $W$.**   \n\n**A3:** As shown in Figure 2, the generator consists of encoder $E_\\phi$ and Mixed module (Figure 3). Note that the weights of the encoder are updated by an exponential moving average (EMA) of the target classifier $\\widehat\\phi=\\xi\\widehat\\phi+(1-\\xi)W'$, where $W'$ is the partial weight of target classifier. In our experiments, existing classifiers such as ResNet18, ResNet34, and ResNeXt50 are employed as target classifiers, with the weights of the first three layers employed to update encoder $E_\\phi$ by EMA.  In this case, $W'$ is the weight of the first three layers in target classifier.  For target classifier  $\\psi_W$, $W$ is referred to the weight of all layers in the target classifier. For clarification, we have added the above contents in subsection 3.2 at page 4.\n\n***\n**W4: Equation 7 and 8 refer to the same value of y used in cross entropy. It is better to keep the form of the loss consistent.**\n\n**A4:** Thanks for your suggestions. We have modified Eq.3 to keep the form of the loss consistent in page 4.   \n***\n**Reference**  \n[1] Zhang, Jiajin, et al. \"Spectral Adversarial MixUp for Few-Shot Unsupervised Domain Adaptation.\" International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham: Springer Nature Switzerland, 2023.\n\n[2] Xu, Minghao, et al. \"Adversarial domain adaptation with domain mixup.\" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 04. 2020.\n\n[3] Zhao, Long, et al. \"Maximum-entropy adversarial data augmentation for improved generalization and robustness.\" Advances in Neural Information Processing Systems 33 (2020): 14435-14447.\n\n[4] Antoniou, Antreas, Amos Storkey, and Harrison Edwards. \"Data augmentation generative adversarial networks.\" arXiv preprint arXiv:1711.04340 (2017)."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6937/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282898643,
                "cdate": 1700282898643,
                "tmdate": 1700282898643,
                "mdate": 1700282898643,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6O7ge7Jufr",
                "forum": "o8tjamaJ80",
                "replyto": "IAj47TO6An",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6937/Reviewer_xmzW"
                ],
                "readers": [
                    "everyone",
                    "ICLR.cc/2024/Conference/Submission6937/Reviewers",
                    "ICLR.cc/2024/Conference/Submission6937/Area_Chairs"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6937/Reviewer_xmzW"
                ],
                "content": {
                    "title": {
                        "value": "Feedback to Rebuttal"
                    },
                    "comment": {
                        "value": "Dear authors,\n\nThank you for the (very) detailed feedback. Apologies for the late response as I'm travelling. I had a look at the revised paper and other reviews and feedback, and have decided to increase my score to weak accept.\n\nThe paper is highly reformatted as per the reviews, and reads much crisper. Experiment setup is as thorough as it can be.\n\nSmall Questions/Clarifications:\n\n1. The proposed module is motivated by the generation of robust samples using adversarial training, which AutoMix may not achieve. Is it feasible to show samples generated by the proposed method (over iterations), whose latents are farthest from the training set, and see how diverse these examples are. AutoMix would probably show examples that are very similar mixes."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6937/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700489986855,
                "cdate": 1700489986855,
                "tmdate": 1700489986855,
                "mdate": 1700489986855,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YJ5yQf8OwG",
            "forum": "o8tjamaJ80",
            "replyto": "o8tjamaJ80",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6937/Reviewer_vYYM"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6937/Reviewer_vYYM"
            ],
            "content": {
                "summary": {
                    "value": "Mixup data augmentations are widely used and usually require well-designed sample mixing strategies, e.g., AutoMix optimized in an end-to-end manner. However, using the same mixup classification loss as the learning objective for both the mixed sample generation and classification tasks might cause consistent and unitary samples, which lack diversity. Based on AutoMix, this paper proposes AdAutomixup, an adversarial automatic mixup augmentation approach that generates challenging samples to train a robust vein classifier for palm-vein identification by alternatively optimizing the classifier and the mixup sample generator. Meanwhile, the authors introduce an EMA teacher with cosine similarity to train AdAutomixup preventing the collapse of the inherent meanings of images. Extensive experiments on five mixup classification benchmarks demonstrate the effectiveness of the proposed methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* (**S1**) This paper provides an interesting view of improving mixed sample qualities through adversarial training in the close-loop optimized mixup augmentation framework. The overall presentation of the manuscript is easy to follow, and the proposed methods are well-motivated.\n\n* (**S2**) Extensive experiments on mixup benchmarks verify the performance gains of the proposed AdAutoMix compared to existing mixup methods. Popular Transformer architectures are included in experiments."
                },
                "weaknesses": {
                    "value": "* (**W1**) More empirical analysis of the proposed methods can be added. Despite the authors visualizing the mixed samples and CAM maps of various mixup methods, it can only reflect the overall performances and characteristics of different methods. I suggest the authors provide a fine-grained analysis of each proposed module to demonstrate its effectiveness, e.g., plotting the classification accuracy of using adversarial training or not.\n\n* (**W2**) Small-scale experiments. The authors only provide comparison results on CIFAR-10/100, Tiny-ImageNet, and fine-grained classification datasets. More experiments on ImageNet-1K or other large-scale datasets are required. Meanwhile, the evaluation tasks or metrics can be more diverse, such as more robustness evaluations with adversarial attacks and transfer experiments to downstream tasks.\n\n* (**W3**) Some minor drawbacks in writing formats, and I suggest the authors take more time to polish the writing. As for Section 3, the arrangement of Sec. 3.1 and Sec. 3.2 can be reversed. Or the authors can provide a Preliminary section to introduce the background knowledge (e.g., mixup classification problem). As for equations, the text subscripts (e.g., $argmin_{\\theta}$, $L_{amce}$) should be in bold format, i.e., using `\\mathrm{}` as $\\mathrm{argmin}_{\\theta}$. As for tables and figures, there are some untidy arrangements, like Table 3, 4, and 5, and Figure 5 and 6. The author might zoom in on Figure 1 to show the detailed improvement of AdAutoMix.\n\n================== Post-rebuttal Feedback ==================\n\nSince the rebuttal feedback and revised version have almost addressed the weaknesses and concerns I mentioned, I raise my score to 8 and encourage the authors to further polish the writing issues and add more discussion of the limitations & future works."
                },
                "questions": {
                    "value": "* (**Q1**) Do the authors provide the hyper-parameter settings of AdAutoMix (e.g., the mixing ratio $\\lambda$, the mixed sample number $N$, and $\\beta$ in Eq. (12)? The authors might provide a sensitivity analysis of the hyper-parameters in the Appendix."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6937/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6937/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6937/Reviewer_vYYM"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6937/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699236609127,
            "cdate": 1699236609127,
            "tmdate": 1700410011003,
            "mdate": 1700410011003,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xsqjfy4qr1",
                "forum": "o8tjamaJ80",
                "replyto": "YJ5yQf8OwG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6937/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6937/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**W1: More empirical analysis of the proposed methods can be added. Despite the authors visualizing the mixed samples and CAM maps of various mixup methods, it can only reflect the overall performances and characteristics of different methods. I suggest the authors provide a fine-grained analysis of each proposed module to demonstrate its effectiveness, e.g., plotting the classification accuracy of using adversarial training or not.**  \n\n**A1:** Thank your valuable suggestions. We have plotted the classification accuracy before and after using adversarial training. The classification accuracy is illustrated in Figure 10 in Appendix A.9 The experimental results imply that the proposed adversarial framework is capable of generating harder samples to improve the robustness of the classifier.\n|model|wo adversarial|w adversarial|\n|---|:--:|:--:|\n|ResNet-18|80.45|81.55|\n|ResNeXt-50|84.12|84.40|\n***\n**W2: Small-scale experiments. The authors only provide comparison results on CIFAR-10/100, Tiny-ImageNet, and fine-grained classification datasets. More experiments on ImageNet-1K or other large-scale datasets are required. Meanwhile, the evaluation tasks or metrics can be more diverse, such as more robustness evaluations with adversarial attacks and transfer experiments to downstream tasks.**  \n\n**A2:** According to your suggestions, we have carried out comparable experiments on the ImageNet-1K dataset to evaluate the performance of *AdAutoMix*, and the results are listed in Table 1 in page 7. Also, we have shown the robustness evaluations of our approach with adversarial attacks and transfer experiments. We have added a paragraph **\u201cOcclusion Robustness\u201d** in subsection 4.4 and the responding results are shown in Figure 5 in page 9 and Table 7 in Appendix A.6 in page 15. Also, we have done experiments to test our approach against **adversarial attacks** and the corresponding results are detailed in Table 4 in page 9. In addition, we have added **transfer learning** experiments in subsection 4.5, and the accuracy of various approaches are depicted in Table 3 in page 9. \n\n***\n**W3: Some minor drawbacks in writing formats, and I suggest the authors take more time to polish the writing. As for Section 3, the arrangement of Sec. 3.1 and Sec. 3.2 can be reversed. Or the authors can provide a Preliminary section to introduce the background knowledge (e.g., mixup classification problem). As for equations, the text subscripts (e.g., argmin\u03b8, Lamce) should be in bold format, i.e., using \\mathrm{} as argmin\u03b8. As for tables and figures, there are some untidy arrangements, like Table 3, 4, and 5, and Figure 5 and 6. The author might zoom in on Figure 1 to show the detailed improvement of AdAutoMix.**  \n\n**A3:** Thanks for your suggestions to help us improve the quality of our work.\n- We have polished the English writing and carefully checked the grammar errors through the whole manuscript.\n- Because of limited space, we did not add a new Preliminary section but have reversed Sec. 3.1 and Sec. 3.2  in the original version (at page 4).\n- We have marked text subscripts in all equations in bold format. Also, we have rearranged Table 3,  4, and 5, and Figure 5 and 6 in the revised version in pages 8 and 9. In addition, Figure 1 is zoomed in to clarify the performance improvement of our *AdAutoMix* in page 2.\n\n***\n**Q1:Do the authors provide the hyper-parameter settings of AdAutoMix (e.g., the mixing ratio $\\lambda$, the mixed sample number N, and $\\beta$ in Eq.(12)? The authors might provide a sensitivity analysis of the hyper-parameters in the Appendix.**  \n\n**A4:** In the previous version, we have shown the hyper-parameter settings of AdAutoMix with the mixed sample number N, $\\alpha$ and $\\beta$. In the revised version, we show the performance of our approach at different mixing ratio $\\lambda$ and provide a sensitivity analysis for all hyper-parameters. The experimental results are shown in Figure 6 in page 9, and Tables 9 and 10 in Appendix in page 16. \n|method/$\\lambda$ ratio|0.2|1.0|2.0|5.0|10.0|\n|---|:--:|:--:|:--:|:--:|:--:|\n|ResNet-18|82.27|82.32|81.73|80.02|81.05|\n|ResNeXt-50|84.22|84.40|83.99|84.31|83.63|\n\n|method/N samples|N=1|N=2|N=3|N=4|N=5|\n|---|:--:|:--:|:--:|:--:|:--:|\n|Top1-Acc|78.04|82.16|82.32|81.78|80.79|\n|Top5-Acc|94.60|95.88|95.92|95.68|95.80|"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6937/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700282879020,
                "cdate": 1700282879020,
                "tmdate": 1700282879020,
                "mdate": 1700282879020,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FD7TGx6c9p",
                "forum": "o8tjamaJ80",
                "replyto": "xsqjfy4qr1",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6937/Reviewer_vYYM"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6937/Reviewer_vYYM"
                ],
                "content": {
                    "title": {
                        "value": "Feedback to Authors' Rebuttal"
                    },
                    "comment": {
                        "value": "Thanks for the detailed rebuttal, and the weaknesses and concerns I mentioned have been addressed. The updated comparison experiments on ImageNet and empirical analysis (e.g., occlusion robustness and gradCAM visualizations) have shown the effectiveness of the proposed modifications in AdAutoMix. Overall, I appreciate the proposed AdAutoMix from the perspective of adversarial training and decided to raise my score to 8. Moreover, I encourage the authors to further polish the writing issues (e.g., arrangement of tables and figures) and discuss the limitations & future works in the manuscript to ensure completeness."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6937/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700409786858,
                "cdate": 1700409786858,
                "tmdate": 1700409786858,
                "mdate": 1700409786858,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]