[
    {
        "title": "A ROBUST DIFFERENTIAL NEURAL ODE OPTIMIZER"
    },
    {
        "review": {
            "id": "lM28CjpwoG",
            "forum": "zbOSJ3CATY",
            "replyto": "zbOSJ3CATY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6302/Reviewer_gukw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6302/Reviewer_gukw"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a robust optimization algorithm called GTSONO, designed to train Neural Ordinary Differential Equations (Neural ODEs) that are more resilient to adversarial attacks. Based on min-max Differential Dynamic Programming, the algorithm is not only computationally efficient but also guarantees convergence to local saddle points. Experimental results demonstrate its significant advantage in improving model robustness compared to benchmark optimizers. Overall, the paper offers a new and effective tool for enhancing the robustness of deep learning models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Originality:\nThe paper introduces a novel perspective by interpreting Neural ODE optimization as a min-max optimal control problem. GTSONO's approach, rooted in min-max Differential Dynamic Programming, showcases a creative amalgamation of existing concepts.\nQuality:\nOffering convergence guarantees to local saddle points signifies the robustness of GTSONO. Efficient matrix decompositions and strong empirical results further attest to the research's high quality.\nClarity:\nThe document articulately bridges intricate theoretical concepts with empirical findings. Despite some formatting issues, the presentation remains clear and coherent.\nSignificance:\nThis work addresses a pivotal challenge in neural ODEs, enhancing their robustness against adversarial attacks. The exploration of optimal control paradigms in adversarial training methods underscores its contributions in the domain."
                },
                "weaknesses": {
                    "value": "1. Although the GTSONO optimizer proposed in this paper can improve the robustness of the model to some extent, it adds too much extra computational overhead, which is unacceptable in the training of larger models.\n2. The paper's limited comparison with just one other optimizer that improves robustness diminishes the persuasiveness of the results, as a more comprehensive comparison would have strengthened the findings.\n3. One limitation of this paper is that the experiments are confined to the CIFAR10 and SVHN datasets, with no validation on more extensive datasets such as CIFAR100 and ImageNet. This restricts the applicability of the research to a certain extent."
                },
                "questions": {
                    "value": "1. Could the authors provide insights into the feasibility of applying GTSONO to larger and more complex datasets such as CIFAR100 and ImageNet?\n2. Given the focus on robustness improvement, could the authors consider including a more extensive comparison with various state-of-the-art optimizers that enhance robustness? \n3. Are there any further insights into the stability and convergence properties of GTSONO, especially under varying hyperparameters and different neural network architectures?\n4. In general, deep learning optimizers have used mini-batch size to obtain a partial batch of datasets, which means that random noise will be introduced, so the optimizer's parameter update rule should correspond to a stochastic differential equation instead of an ordinary differential equation. Therefore, why do the authors use an ODE rather than an SDE for their theoretical analysis?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "None"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6302/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6302/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6302/Reviewer_gukw"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6302/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698636410387,
            "cdate": 1698636410387,
            "tmdate": 1700618854948,
            "mdate": 1700618854948,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WhhLokesXB",
                "forum": "zbOSJ3CATY",
                "replyto": "lM28CjpwoG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer gukw"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for their positive remarks, as well as their useful comments and further suggestions for improving our work. In the following we address each of the concerns and suggestions of the reviewer.\n\n### **1.  Computational overhead**\n\n- While we admit that our method introduces a second set of weights, we highlight that most adversarial training methods typically include nested optimization schemes that are computationally demanding. The main advantage of our methodology is that the antagonizing weights  are updated through a *single* backpropagation, which reduces computational complexity while also achieving robustness even with natural training bypassing the computational burden of perturbing the input.  In addition, note that we also enhance computational efficiency by exploiting efficient matrix decompositions.\n    \n---\n\n### **2.Experiments on CIFAR-100 and Tiny ImageNet and a more extensive comparison with various state-of-the-art optimizers that enhance robustness**\n- Following the suggestions of the reviewer, we present further comparisons against the state-of-the-art optimizers that enhance robustness such as Lyanet[1], and FI-ODE[2]. Additionally, we also evaluate the all optimizers in additional datasets: CIFAR100 and TinyImageNet. These results in the Table below further indicate the robustness of our optimizer as it outperforms state-of-the-art robust optimizers in multiple datasets.  We also highlight the significantly shorter training time required by GTSONO in contrast to Lyanet and FI-ODE. \n    \n    | Optimizer | CIFAR100-PGD_20^0.03 | Tiny-ImageNet PGD_20^0.03 | Training TinyImageNet (min:sec) | # of Parameters |\n    | --- | --- | --- | --- | --- |\n    | Adam | $10.7\\pm1.1$ | $1.9\\pm0.1$ | 5:37 | 1.35 M |\n    | SNOpt | $19.7\\pm0.6$ | $3.6\\pm0.9$ | 5:41 | 1.35 M |\n    | SGD | $9.6\\pm0.5$ | $0.8\\pm0.2$ | 5:20 | 1.35 M |\n    | LyaNet^* | $20.1\\pm0.5$ | $5.4\\pm0.4$ | 313:21 | 19.6 M |\n    | FI-ODE^* | $15.4\\pm0.4  $ | $4.0\\pm0.2$ | 607:56 | 2.4 M |\n    | c-GTSONO | $23.5\\pm0.1$ | $9.1\\pm0.8$ | 6:35 | 1.47M |\n    \n    | CIFAR10-Optimizer | PGD_20^0.03 | PGD_20^0.05 | Time (min:sec) | # of Parameters |\n    | --- | --- | --- | --- | --- |\n    | LyaNet^* | $46.1\\pm0.4$ | $32.7\\pm0.6$ | 32:44 | 19.6 M |\n    | FI-ODE^* | $48.5\\pm0.3$ | $33.4\\pm0.6$ | 143:17 | 2.4 M |\n    | c-GTSONO | $50.6 \u00b1 0.3$| $35.0 \\pm 0.2$ | 3:53 | 1.35M |\n\n---\n    \n### **3. Insights into the stability and convergence properties of GTSONO, especially under varying hyperparameters and different neural network architectures?**\n\n- The convergence guarantees are agnostic of the architecture and hyperparameter configuration. The only necessary assumption for the convergence guarantees to hold should be that the function of our accumulated loss $Q$ is locally convex-concave - which can be imposed through appropriate selection of the regularization parameters $R_u, R_v$\n    \n---\n\n### **4. In general, deep learning optimizers have used mini-batch size to obtain a partial batch of datasets, which means that random noise will be introduced, so the optimizer's parameter update rule should correspond to a stochastic differential equation instead of an ordinary differential equation. Therefore, why do the authors use an ODE rather than an SDE for their theoretical analysis?**\n\n- We would like to kindly emphasize that the stochasticity comes from the input, however this does not affect the dynamics which remain deterministic. Therefore, the appropriate representation is through an ODE instead of an SDE. This allows us to employ deterministic optimal control which naturally leads to a deterministic update law."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700342644151,
                "cdate": 1700342644151,
                "tmdate": 1700342644151,
                "mdate": 1700342644151,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "29CcZ4iz1N",
                "forum": "zbOSJ3CATY",
                "replyto": "lM28CjpwoG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up to Reviewer gukw"
                    },
                    "comment": {
                        "value": "As we are approaching the end of author-reviewer discussion, we would appreciate the reviewer to clarify if our responses has sufficiently addressed the raised concerns, and, if so, we kindly appreciate the reviewer to re-consider their rating."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700610441704,
                "cdate": 1700610441704,
                "tmdate": 1700610441704,
                "mdate": 1700610441704,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sNgDvhjNXH",
            "forum": "zbOSJ3CATY",
            "replyto": "zbOSJ3CATY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6302/Reviewer_L7bT"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6302/Reviewer_L7bT"
            ],
            "content": {
                "summary": {
                    "value": "This paper interprets neural ODE optimization as a min-max optimal control problem, and proposed a second order optimizer. The proposed optimizer is computationally feasible by matrix decomposition. Empirically, the authors compare with other optimizers (Adam, SGD and another not min-max second order optimizer), and show it has improved adversarial robustness."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper proposes an interesting perspective of robust neural ODE optimization via min-max optimal control. \n\nThe authors make the proposed second order optimizer to be computational feasible: instead of back propagate coupled matrices, one can back propane a set of vectors. \n\nThe authors provide convergence guarantee of the proposed optimizer. \n\nExperiments show improved adversarial robustness comparing with other non-robust neural ODE optimizers."
                },
                "weaknesses": {
                    "value": "1. Although I think it is interesting to formulate robust neural ODE optimization as min-max OC, I feel there is gap why the formulation in (3) can be beneficial to the robustness problem in (1): in (3), the adversary is on neural network weights, and in (1), the adversary is on the inputs to the neural network. \n\n2. Despite the effort of reducing computational cost, the proposed method is still very expensive. It would be good to include a complexity comparison between other neural ODE optimizers: first-order adjoint and SNOpt.\n\n3. It is known that neural ODE tends to suffer from gradient obfuscation issue when being evaluated for empirical adversarial robustness. It would be beneficial to have some adaptive attacks or non-gradient based attacks to make sure the improved robustness is valid. For instance, the attacks used in [1]. Since the optimizer on its own has lower robustness accuracy than adversarial training methods, it is crucial to have solid experiments to show its benefits when combining with other robust training techniques. In general, I like the min-max OC perspective, but it may still lack evidence for its usefulness. Maybe the authors could also consider evaluating against adversary on neural network weights, which I think is more close to the formulation.\n\n[1] Kang, Qiyu, et al. \"Stable neural ode with lyapunov-stable equilibrium points for defending against adversarial attacks.\" Advances in Neural Information Processing Systems 34 (2021): 14925-14937."
                },
                "questions": {
                    "value": "1. My main question is as in weakness 1: the proposed optimizer seems to be beneficial to attacks on neural network weights rather than on the inputs. I hope the authors can clarify why they choose to demonstrate the effectiveness of their optimizer on input-robustness, and will the method be useful for attacks on system weights?\n\n2. In the experiments, it seems that only having adversarial control on convolution layers is much better than having them on all of the layers. From the theory parts it is not clear why this is the case. The authors should provide more analysis on this.\n\n3. When combing with adversarial training (table 4), why CW accuracy drops? This may indicate some gradient obfuscation issue, it will be good to include some stronger attacks in the evaluation (like AutoAttack, Square) as suggested in weakness 3."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6302/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698858899314,
            "cdate": 1698858899314,
            "tmdate": 1699636691978,
            "mdate": 1699636691978,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vqygBVa8Xc",
                "forum": "zbOSJ3CATY",
                "replyto": "sNgDvhjNXH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer L7bT"
                    },
                    "comment": {
                        "value": "We truly appreciate the encouraging comments of the reviewer, as well as their useful remarks.  In the following we address the points raised by the reviewer.\n\n### **1. Gap why the optimization of min-max optimal control can be beneficial to the robustness problem in the adversarial training problem**\n    \n- In our approach, we introduce the antagonizing set of controls to represent the disturbances in the system, inspired by game theoretic optimal control. This key representation enables us to utilize computationally efficient and scalable trajectory optimizers such as min-max Differential Dynamic Programming (DDP). In the realm of Optimal Control (OC), it has been demonstrated that game-theoretic formulation enables the model handling uncertainties and external disturbances [1].   \n- The key advantage of incorporating as adversarial control inputs lies in the fact that instead of typically obtaining nested optimization schemes that are computationally demanding, our algorithm updates the antagonizing weights with a *single* backward pass which reduces computational complexity while also achieving robustness even with natural training bypassing the need of perturbed input. **\n\n---\n\n### **2. Complexity comparison between GTSONO and other Neural ODE optimizers: first-order adjoint and SNOpt.**  \n\n- We updated the paper, in order to present better the complexity comparison between GTSONO and other Neural ODE optimizers, adding a pertinent table in the main part of the paper. For an extensive comparison with regards to the computational requirement of the optimizers, we refer the reviewer to Tables 8-12 in Appendix D, which show training time and memory consumption. \n\n---\n\n\n### **3. Clarification on the selection to demonstrate the effectiveness of our optimizer on input-robustness**\n    \n- While we mostly refer the reviewer in weakness 1, regarding our motivation to recast the optimization problem with input disturbance to a game theoretic formulation. We chose to demonstrate the effectiveness on input-robustness, given that this is the most widely used form of attack. We also appreciate the suggestions of the reviewer to include studies on systems weights which we intend to explore in our future work. \n  \n---\n\n### **4. In the experiments, it seems that only having adversarial control on convolution layers is much better than having them on all of the layers. From the theory parts it is not clear why this is the case. The authors should provide more analysis on this.**\n    \n- We provide some intuition for this phenomenon. To quantify the similarity between the feature vector of the models from attacked and clean images, we calculate the cosine similarity. We find that the model with adversary weights in the convolution layers evaluated with attacked images is significantly closer to the feature vector from the clean images (cosine_similarity=0.92), compared to the feature vector from attacked images in the model without adversary control in the convolution layers (cosine_similarity=0.21). Therefore, feeding a robust feature vector to the classifier is similar to feeding the feature vector from the clean images, which eliminates the need to include antagonizing weights in the last linear layers, as it is well known that they drop the natural accuracy of model. Therefore, since the disturbance is in the input, this implies that it suffices to add adversary control in the convolution layers in order to capture robust features for robustifying the model. We intend to to investigate more thoroughly the underlying theory in future work.\n\n---\n\n### **5. When combing with adversarial training (table 4), why CW accuracy drops? This may indicate some gradient obfuscation issue, it will be good to include some stronger attacks in the evaluation (like AutoAttack, Square) as suggested in weakness 3.**\n  \n- Based on the reviewer\u2019s recommendations we have also added AutoAttack and Square attacks to assess our optimizer.    In the tables below, we compare the robustness of GTSONO against the baseline classifiers on CIFAR-10 with natural training, and with TRADES adversarial training. These results provide further evidence for the robustness of our optimizer against multiple attack methods, both with natural and adversarial training. We also appreciate the insight of the reviewer regarding the issue with gradient obfuscation, which we intend to explore more thoroughly in our future work.\n\n| Optimizer | AutoAttack | Square |\n| --- | --- | --- |\n| Adam | 20.7 | 23.1 |\n| SNOpt | 16.5 | 19.8 |\n| SGD | 20.4 | 22.8 |\n| c-GTSONO | 26.8 | 29.4 |\n\n| TRADES-\u03bb=0.1 | AutoAttack | Square |\n| --- | --- | --- |\n| SGD | 20.1 | 21.4 |\n| c-GTSONO | 21.8 | 23.9 |\n\n---\n---\n\n### References\n1. Sun, W., Pan, Y., Lim, J., Theodorou, E. A., & Tsiotras, P. (2018). Min-max differential dynamic programming: Continuous and discrete time formulations. Journal of Guidance, Control, and Dynamics, 41(12), 2568-2580."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700342579121,
                "cdate": 1700342579121,
                "tmdate": 1700342637518,
                "mdate": 1700342637518,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ah5uuN5D3h",
                "forum": "zbOSJ3CATY",
                "replyto": "sNgDvhjNXH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up to Reviewer L7bT"
                    },
                    "comment": {
                        "value": "As we are approaching the end of author-reviewer discussion, we would appreciate the reviewer to clarify if our responses has sufficiently addressed the raised concerns, and, if so, we kindly appreciate the reviewer to re-consider their rating."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700610305385,
                "cdate": 1700610305385,
                "tmdate": 1700610305385,
                "mdate": 1700610305385,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "PRMRv72FU0",
                "forum": "zbOSJ3CATY",
                "replyto": "Ah5uuN5D3h",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Reviewer_L7bT"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Reviewer_L7bT"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the detailed reply. For weakness 1, I think it'd be good to write down the formulation in [1], where exactly are the uncertainties and disturbances added, on the system parameters, the states or the controls, and mapping the formulation with input adversarial robustness. As the authors mentioned, for input perturbations, it may be sufficient to only include antagonizing set of controls in the convolutional layers rather than including them for all the weights. I think decomposing the source of disturbances will also provide some insights on where we need the antagonizing set of controls."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700706170168,
                "cdate": 1700706170168,
                "tmdate": 1700706170168,
                "mdate": 1700706170168,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Ml56bBhTs2",
            "forum": "zbOSJ3CATY",
            "replyto": "zbOSJ3CATY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission6302/Reviewer_veDw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission6302/Reviewer_veDw"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies robust optimisation method for neural ODEs. The authors interpret Neural ODE optimization as a min-max optimal control problem, and then design a Game Theoretic Second-Order Neural Optimizer (GTSONO), based on min-max Differential Dynamic Programming, with convergence guarantees to local saddle points. The authors also conduct experiments to verify the performance of GTSONO."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "This paper is well motivated - addressing the vulnerability to adversarial attacks in neural network related methods, including neural ODE.\n\nThe authors design a Game Theoretic Second-Order Neural Optimizer as a robust optimiser for neural ODEs. \n\nThey also provide rigorous, theoretical analysis for the proposed method. The proofs are given in detail. \n\nThe paper is well written."
                },
                "weaknesses": {
                    "value": "I am worried about the novelty, after reading the calculations. Leveraging min-max methods for adversarial learning is a usual approach.  convergence. The calculations of gradients and backpropagation are simple calculus and linear algebra. The proof of convergence is a direct application of existing results in optimisation. I suggest the authors clarify the novelty of their algorithms and proofs, and discuss the differences and advantages of their method.\n\nThe experiments are only conducted on CIFAR-10 and SVHN. Experiments on CIFAR-100, and ImageNet (or at least TinyImageNet) are needed for comparison.\n\nFrom Tables 1 and 2, GTSONO has fairly bad performance in CIFAR-10 in term of natural accuracy. Please discuss why this happens.\n\nThe authors only compare with SGD, Adam, and a second order baseline SNOpt. It is not enough. Please compare your method with most existing methods. I list some below:\n\nhttps://proceedings.mlr.press/v162/rodriguez22a/rodriguez22a.pdf\n\nhttps://arxiv.org/pdf/2210.16940.pdf"
                },
                "questions": {
                    "value": "Please address the above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission6302/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6302/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission6302/Reviewer_veDw"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission6302/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699201062331,
            "cdate": 1699201062331,
            "tmdate": 1700674588604,
            "mdate": 1700674588604,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "o852Eaa3TM",
                "forum": "zbOSJ3CATY",
                "replyto": "Ml56bBhTs2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer veDw (part 1/2)"
                    },
                    "comment": {
                        "value": "We would like to thank the reviewer for their positive comments, as well as their constructive criticism and further suggestions for improving our work. In the following we address the points raised by the reviewer.\n\n### **1. Novelty of Proposed Approach**\n- We first emphasize that our approach differs considerably from conventional min-max methods for adversarial learning. While most min-max adversarial training methods consider the adversary input, our proposed method instead consider the disturbance being injected through the auxiliary **weights.** This, as also recognized by Reviewer gukw, offers a novel perspective by recasting the Neural ODE optimization as a robust trajectory optimization through the lens of min-max optimal control theory. This key reformulation enables computationally efficient and scalable trajectory optimizers (such as min-max Differential Dynamic Programming presented in our work) that is otherwise absent in prior adversarial formulations. We urge the reviewer to recognize the distinction.\n- The experiments empirically verify our choice as our algorithm converges to a saddle point even when trained with clean images, which is translated to an increased robustness of our model against adversarial attacks, even with natural training.\n---\n### **2. Convergence proof**\n    \n- While we do acknowledge that our convergence analysis is partly inherited from prior theoretical optimization tools, we emphasize that it holds merit to show that our optimizer has theoretical convergence guarantees to a local saddle point. This kind of (local) convergence analysis is crucial in characterizing training stability, especially in deep learning-based algorithms, yet are absent in those inspired by optimal-control methodologies. Furthermore, we highlight that the convergence of our algorithm is still not a direct application of the known convergence results as we need to leverage the formulation of our update law, and the preconditioning with the inverse of the Jacobian of G, for proving that the spectral norm of the Jacobian of our update law is guaranteed to be less than 1 - which implies stable convergence to the saddle point. \n---\n### **3. Experiments on CIFAR-100 and Tiny ImageNet and comparison with other methods**\n\n- Following the suggestions of the reviewer, we present further comparisons against the suggested optimizers  Lyanet[1], and FI-ODE[2], as well as on the additional datasets: CIFAR-100, and TinyImageNet. We observe that GTSONO outperforms all baselines , in every tested dataset, while taking slightly longer time to train than SGD. Furthermore, we observe that the next best in performance are LyaNet and FI-ODE, which however have significantly more parameters, leading to dramatically longer training time. Finally, we would like to emphasize that the experiments on the optimizers LyaNet, and FI-ODE are conducted with the architectures and hyperparmeter configurations selected by [1], and [2].\n    \n| CIFAR10-Optimizer | PGD_20^0.03 | PGD_20^0.05 | Time (min:sec) | # of Parameters |\n| --- | --- | --- | --- | --- |\n| LyaNet* | $46.1\\pm0.4$ | $32.7\\pm0.6$ | 32:44 | 19.6 M |\n| FI-ODE* | $48.5\\pm0.3$ | $33.4\\pm0.6$ | 143:17 | 2.4 M |\n| c-GTSONO | $50.6 \u00b1 0.3$| $35.0 \\pm 0.2$ | 3:53 | 1.35M |\n\n| Optimizer | CIFAR100-PGD_20^0.03 | Tiny-ImageNet PGD_20^0.03 | Training TinyImageNet (min:sec) | # of Parameters |\n| --- | --- | --- | --- | --- |\n| Adam | $10.7\\pm1.1$ | $1.9\\pm0.1$ | 5:37 | 1.35 M |\n| SNOpt | $19.7\\pm0.6$ | $3.6\\pm0.9$ | 5:41 | 1.35 M |\n| SGD | $9.6\\pm0.5$ | $0.8\\pm0.2$ | 5:20 | 1.35 M |\n| LyaNet* | $20.1\\pm0.5$ | $5.4\\pm0.4$ | 313:21 | 19.6 M |\n| FI-ODE* | $15.4\\pm0.4  $ | $4.0\\pm0.2$ | 607:56 | 2.4 M |\n| c-GTSONO | $23.5\\pm0.1$ | $9.1\\pm0.8$ | 6:35 | 1.47M |\n*: Different architecture"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700342500856,
                "cdate": 1700342500856,
                "tmdate": 1700342500856,
                "mdate": 1700342500856,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6MTVAWjfmP",
                "forum": "zbOSJ3CATY",
                "replyto": "Ml56bBhTs2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Author Response to Reviewer veDw (part 2/2)"
                    },
                    "comment": {
                        "value": "### **4. GTSONO natural accuracy in CIFAR-10**\n    \n-  We acknowledge that indeed GTSONO demonstrates a decrease in natural accuracy towards achieving high robustness. Note that this is a well-known trade-off between robustness and accuracy, as studied in [3].  Therefore since our focal focal point is the increased robustness of our optimizer it follows that a decrease in the natural accuracy of our optimizer may be observed. Another interpretation of this phenomenon is that the value function of GTSONO converges to a saddle point, due to the effect of the antagonizing control . This can be viewed as a compromise in the natural accuracy  of the optimizer when compared to other optimizers which converge to a local minimum. It should be noted that the value functions of GTSONO and the baseline optimizers are not the same, therefore this can not serve for direct comparisons, however it provides us with an intuition for this phenomenon.\n\n---\n\n### References\n1. Rodriguez, I. D. J., Ames, A., & Yue, Y. (2022, June). LyaNet: A Lyapunov framework for training neural ODEs. In International Conference on Machine Learning (pp. 18687-18703). PMLR.\n2. Huang, Y., Rodriguez, I. D. J., Zhang, H., Shi, Y., & Yue, Y. (2022). Fi-ode: Certified and robust forward invariance in neural odes. arXiv preprint arXiv:2210.16940.\n3. Zhang, H., Yu, Y., Jiao, J., Xing, E., El Ghaoui, L., & Jordan, M. (2019, May). Theoretically principled trade-off between robustness and accuracy. In International conference on machine learning (pp. 7472-7482). PMLR."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700342525316,
                "cdate": 1700342525316,
                "tmdate": 1700342560538,
                "mdate": 1700342560538,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iVYSxpU9lq",
                "forum": "zbOSJ3CATY",
                "replyto": "Ml56bBhTs2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Follow up to Reviewer veDw"
                    },
                    "comment": {
                        "value": "As we are approaching the end of author-reviewer discussion, we would appreciate the reviewer to clarify if our responses has sufficiently addressed the raised concerns, and, if so, we kindly appreciate the reviewer to re-consider their rating."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700610299638,
                "cdate": 1700610299638,
                "tmdate": 1700610299638,
                "mdate": 1700610299638,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1wV4CUvmKN",
                "forum": "zbOSJ3CATY",
                "replyto": "iVYSxpU9lq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission6302/Reviewer_veDw"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission6302/Reviewer_veDw"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your response.\n\nI really cannot find \"the disturbance being injected through the auxiliary weights\" in either your paper or Reviewer gukw's comment. I recognise the novelty of modelling neural ODE by mini-max optimal control, but some papers have modelling neural ODE by optimal control (see https://arxiv.org/pdf/2210.11245.pdf, https://arxiv.org/pdf/1912.05475.pdf).\n\nI appreciate the new experiments.\n\nMy concern on theory remains.\n\nOverall, I agree to raise the score to 6."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission6302/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674580080,
                "cdate": 1700674580080,
                "tmdate": 1700674580080,
                "mdate": 1700674580080,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]