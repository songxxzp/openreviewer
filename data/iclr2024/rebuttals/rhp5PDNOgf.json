[
    {
        "title": "Spaced Scheduling Enhances Instruction-Prompted Reasoning in Large Language Models"
    },
    {
        "review": {
            "id": "QhelRsXvHS",
            "forum": "rhp5PDNOgf",
            "replyto": "rhp5PDNOgf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3809/Reviewer_QXyK"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3809/Reviewer_QXyK"
            ],
            "content": {
                "summary": {
                    "value": "The authors argue that spaced scheduling (inspired by spaced repetition, a popular technique used by students to memorize content)\ncan be used to better instruction-tune LLMs. They aggregate existing\ninstruction tuning datasets into one training benchmark, Mercury-instruct.\nThey then verify, on this benchmark, that their technique outperforms\nrandom data selection when instruction tuning LLAMA-2 at model sizes 7B and 13B."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Motivating the technique with relevant psychology literature.\n\n1. Applying the technique to instruction tuning LLMs, which is a research\n  topic that is attracting considerable attention.\n\n1. Conducting an ablation analysis on the components of the proposed algorithm."
                },
                "weaknesses": {
                    "value": "* Discussion of related work. For example, spaced scheduling for deep\n  learning has been considered in **Hadi Amiri et. al**:\n  *Repeat before Forgetting: Spaced Repetition for Efficient and Effective\n  Training of Neural Networks (ACL 2017, see page 2404)*\n\n* The proposed method does not appear to be motivated with a memory model; compare\n  **Amiri et al.** or **https://arxiv.org/pdf/1602.07032.pdf**, both works seem to motivate\n  their proposals based on a memory model.\n\n* In my opinion, the empirical part should have at least a comparison to\n  another spaced scheduling method (compare **Amiri et al.**).\n\n* In my opinion, it is hard to conclude if one should use the proposed method\n  or some other online scheduling approach. For example, there is prior\n  relevant work on automated curriculum learning, see for example **Kreutzer et. al**: *Bandits Don\u2019t Follow Rules: Balancing Multi-Facet Machine Translation with Multi-Armed Bandits (ACL 2021)*. While I am **not necessarily** advocating direct comparison\n  to the algorithm of **Kreutzer et al.**, I think the empirical part would be\n  more solid by having a comparison to one or two additional approaches\n  that schedule the data dynamically."
                },
                "questions": {
                    "value": "My initial rating / recommendation is inclined towards rejection because:\n* the novelty claim needs a better positioning wrt. previous work\n* the empirical investigation feels limited. \n\nI am leaving some questions that would greatly help me to improve\nmy assessment and in case change the rating / recommendation towards acceptance.\n\n**Major Questions**\n1. Could you position your work wrt. to **Amiri et al.**? What makes this proposal\nof spaced scheduling novel wrt. prior work?\n\n1. Could you elaborate on why there is not a comparison to another spaced\n  scheduler or to other approaches that dynamically schedule the training examples? (e.g. **Kreutzer et al.**)\n\n**Minor Questions**\n* Table 1: The performance decrease on some tasks (e.g. World Knowledge)\nmight be due to instruction tuning on the Mercury dataset. Since one\nis interested in comparing instruction-tuning strategies, it might be\nworth considering using the **LLAMA-2 Mercury**, which is instruction-tuned without spaced scheduling, as the baseline and reporting the gains/losses wrt. to **LLAMA-2 Mercury**."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3809/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3809/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3809/Reviewer_QXyK"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3809/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698403739450,
            "cdate": 1698403739450,
            "tmdate": 1699636338320,
            "mdate": 1699636338320,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8Kd8EFSDMq",
                "forum": "rhp5PDNOgf",
                "replyto": "QhelRsXvHS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3809/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3809/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback"
                    },
                    "comment": {
                        "value": "First, we would like to thank you for the very valuable and relevant suggestion that directed the changes that needed to be done as part of this rebuttal, improving the paper. Amiri et. al, escaped our radar (spaced scheduling is in the title!!).\n\n- **Re: Discussion of related work** Based on your comment, we have reworked the entire related work and introduction section as we can't claim novelty on using Spaced Repetition in DL.\n\n- **Re: memory model motivation**: We have added the memory model discussion to both related work and the introduction.\n\n- **Re: Comparison to Amiri et al.**: We have added the suggested comparison. The results are in Table 1, and a detailed analysis is in Section 5.1 on page 8. Also, based on feedback from other reviewers, we've added 4 more baselines (Table 1 and section 4.4 for details), enhancing the demonstration of our work's benefits.\n\n- **Re: position your work**: We have added a full paragraph in the introduction (p2) to position our work wrt to Amiri et al.\n\n- **Re not comparing to other approaches**: The main reasons that we did not initially include a comparison to other CL or pruning work is: (1) most prior work either focuses on basic classification task or MNT. Thus comparing these methods means significant changes to \nthe original algorithm since older work uses LSTM (such as in Amiri et al.)  MLP, or encode-only transformer models (Bert, Roberta) which is different from decoder-only model used recently.  For example, the implementation of an entropy-based active learning with an \nencoder + classification head is almost distinct from implementing it for a decoder-only. (2) to the best of our knowledge, none of the existing work addresses large scale multitask  (e.g, Flan v2 has 1k+tasks). (3)  to the best of our knowledge, none of the existing work focuses on IFT with large-scale models (7B+) which present other challenges such as the possibility of erasing \nper-trained knowledge as opposed to training an LSTM from scratch to perform sentiment analysis. **However, we now have 5 baselines for comparison**.\n\n- **Re: Table 1** While that would make the result a bit easier to read, we believe that will hide the reduction of catastrophic forgetting of our approach. However, we have merged the table into one better clarity.\n\nWe hope that the major updated we made to the baseline, related work, introduction, and analysis are sufficient to steer our submission toward an acceptance. \n\nThank you!"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3809/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685309065,
                "cdate": 1700685309065,
                "tmdate": 1700685309065,
                "mdate": 1700685309065,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "IGUKQw8dfa",
            "forum": "rhp5PDNOgf",
            "replyto": "rhp5PDNOgf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3809/Reviewer_aAUa"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3809/Reviewer_aAUa"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes an adaptive scheduling strategy called spaced scheduling motivated by the spaced repetition learning method used by humans. The approach aims to perform the data mix selection process online during training, tailoring the training data composition to the chosen pre-trained model. In addition, the paper creates a new instruction meta-collection, i.e., Mercury-Instruct."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The introduction seems interesting. The analogy drawn to human learning processes is quite inspiring.\n- The author performed an ablation study to show the benefit of each main component of the proposed algorithm."
                },
                "weaknesses": {
                    "value": "- Some parts of the writing are ambiguous. I think it is better to provide a representative concept figure.\n- The experimental results are not so good. Stating that there is an overall performance improvement seems risky because there was a performance gain in four out of seven evaluations.\n- While there are numerous hyperparameters within the proposed algorithm, the impact of their variations on performance has not been analyzed. Some ablation studies on hyperparameters, e.g., $s_t$ and $\\rho_0$, seem necessary. This is necessary to determine whether this method is insensitive to hyperparameters.\n- There are often instances where explanations are missing. For instance, it would be advisable for the authors to explain why the formula for the minimum score threshold based on competency is $z_t \\leftarrow z_{max} - \\kappa -1$."
                },
                "questions": {
                    "value": "- How do you define the minimum score to deem a response good enough and the threshold repetitions to deem an example learned?\n- Could you explain in more detail how you define the data categories?\n- How do you define initial competency?\n- Could you please provide a more detailed explanation of the criteria used to construct the Mercury-Instruct collection?\n- Was there no paper using CL in instruction tuning for LLM previously? If there was, please explain the reason for not comparing with them."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3809/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698552528083,
            "cdate": 1698552528083,
            "tmdate": 1699636338236,
            "mdate": 1699636338236,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "uIF15KmRbz",
                "forum": "rhp5PDNOgf",
                "replyto": "IGUKQw8dfa",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3809/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3809/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback"
                    },
                    "comment": {
                        "value": "- **Re: parts of the writing are ambiguous**: We reworked all the methodology section (section 3) to make it as clear as possible, and split Algorithm 1 into multiple parts. While we agree that a figure could be better, the space does not permit especially with the additional baselines and analysis we performed. However, if you still think the update we made a still ambiguous, we will be happy to make the update for the camera-ready version.\n- **Re: the experimental results are not so good:**  The reason we claim the overall performance is better is that our method is better on 4 out of 7 tasks. While that might seem \"\"risky\"\" we believe that the method is showing signification improvement, because \n   - When our method improves a particular type of task, the gains are substantial. (e.g., 15 acc points for math)\n   - The values we show in Table 1 are averages across multiple datasets (e.g., reading comprehension contains \n8 datasets), thus an increase of 1.2 for example is very significant. \n   - On all the benchmarks where our method scored lower than the pre-trained model, our method is always better compared to the random training,  thus the claim that our method improves over random training remains valid. \n   -  On the main capabilities that our method improved (reasoning), we performed a paired t-test to prove the \nstatistical significance of our results. Since other reviewers saw our results as strengths  (e.g, Review 1: \"Spaced repetition consistently improves accuracy across all 5 benchmarks  and 2 models, demonstrating robust gains.\", Reviewer 2: \"quantitive results on 4 benchmark  suite show the effectiveness of the proposed methods versus baseline or random mixture methods;\"),  please let us know what parts we should clarify, and we will be happy to make the needed updates when we submit the camera-ready version\n\n- **Re: About the hyperparameters**: Thank you for the valuable suggestion we agree that this was indeed missing from the initial submission. We have added an ablation study of the hyperparameters in the appendix.\"\n- **Re: explanations are missing**: We clarified the score threshold as you suggested in section 3.2, phase 2. Further, we reworked the algorithm section to make sure that all the aspects are clear.\"\n- **Re: The minimum score value, and initial competency**: We clarified how we set that value  in section 4.1 (TLDR; it is based on SuperMemo default value)\"\n- **Re: the data categories**: We rely on any categorization that exists already in the dataset. A simple categorization is to use the dataset ID (since we only need the value for the stratification). Another possibility is to use categorization in the dataset. For example, the open orca dataset has GPT-4 and GPT-3.5 data splits. In such a case, we use the aforementioned categories\n rather than the dataset ID. We have added this clarification to section 3.2, phase 1.\n\n- **Re: Design choice of selected instruction dataset** Since our proposed method alleviates the need to select the datasets or their composition, we chose a dataset that contains the most used IFT dataset. We agree that this was missing from our dataset section and we have added it to our latest version of the work to section 4.2. However, note that we longer include Mercury as part of our contribution since the Tulu authors have released a V2 of their dataset that includes the dataset we added. Thus, we have \nupdated the dataset section to reflect this.\"\n\n- **Re CL prior work**: \"To our knowledge, there is no CL work for IFT. However, we have reworked the related work section\nto add additional studies that intersect with our work.\""
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3809/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686407525,
                "cdate": 1700686407525,
                "tmdate": 1700686407525,
                "mdate": 1700686407525,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "nrQrogXnoS",
            "forum": "rhp5PDNOgf",
            "replyto": "rhp5PDNOgf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3809/Reviewer_CD6W"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3809/Reviewer_CD6W"
            ],
            "content": {
                "summary": {
                    "value": "The paper discusses the advancement in instruction tuning for large language models, a method that has propelled their popularity. While most prior work has concentrated on the development or improvement of datasets, instruction tuning has sometimes led to a decline in performance. To address this, researchers have been carefully selecting the best dataset mixes through intensive ablation studies. The paper introduces a new adaptive scheduling strategy, termed \"spaced scheduling\", inspired by the spaced repetition learning method in humans. This approach dynamically selects the training data mix online, specifically tailored to the pre-trained model, eliminating the need for extensive studies on training data compositions. The results indicate that Spaced Scheduling surpasses random sampling, requires less training data, and prevents catastrophic forgetting. It also delivers balanced performance across all benchmark subcategories."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-written and clearly presented; \n- The paper tackled the important problem of data mixture & curriculum  learning of instruction tuning for large language model and proposed a novel method, \"space scheduling\", quantitive results on 4 benchmark suite show the effectiveness of the proposed methods versus baseline or random mixture methods; \n- Detailed ablation and qualitative examples w.r.t other scheduling variants have been presented to show the effectiveness of the proposed \n- It is great to show the proposed methods are based on LoRA, which offers extra accessibility to large research community;"
                },
                "weaknesses": {
                    "value": "- There is a missing comparison in Table 1 versus Tulu as mentioned in 4.2 for the effectiveness of MERCURY versus original Tulu paper. Besides, MT-Bench or other human-involved evaluations might also be good to show the comprehensive effectiveness of the proposed methods; \n- Another concern of the proposed method is that it seems the benefits are enlarged for Math/Code with both MERCURY / Space Scheduling. However, when adding OpenOrca dataset only will contribute to that effect should be ablated; \n- The scalability of the proposed method is questionable but it is great to show the purposed methods are based on LoRA;"
                },
                "questions": {
                    "value": "- Just wondering the performance based on OpenOrca / Tulu-only for 7B/13B models to show the comprehensive view of MERCURY\uff1b \n- Could the authors imply the decreased performance on MMLU / World-Knowledge, is that due to the introduce of OpenOrca or other datasets may pose negative impact on the overall performance? \n- Could the authors explain the design choice of selected instruction dataset more, since according to Tulu, different data mixture as well as each dataset may contribute to positive/negative effects on each domain;"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3809/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698792475136,
            "cdate": 1698792475136,
            "tmdate": 1699636338146,
            "mdate": 1699636338146,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "HKDLJIHt3J",
                "forum": "rhp5PDNOgf",
                "replyto": "nrQrogXnoS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3809/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3809/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback!"
                    },
                    "comment": {
                        "value": "- **Re missing comparison in Table 1 versus Tulu**: The only reason why we don't include comparison is Tulu in Table 1 is the fact that Tulu is based on Llama, and our model is based on  LLama2, which gives an unfair advantage to our method since Llama2 is superior to Llama1.  However, with the dataset changes described in the main comment, we have included a Tulu V2 comparison that \ncorresponds to training Llama2 on the tulu dataset.\"\n- **Re: the scalability of the method**: We've added section 3.3, which shows the math equations that govern the overhead, and complete details of how we derived the equation in Appendix A.6. Further, we added a paragraph (in section 5.1, page 8) in the quantitative results that shows the numerical values, proving that the proposed method is on part with random sampling for 7B and more efficient for the 13B for the tested setup.\n- **About ablating OpenOrca dataset**: We agree that ideally, we should ablate the addition of each dataset. However, due the amount of work we spent adding 5 baselines and reworking the related work and introduction and  we did not have enough time and compute budget to run these experiments. However, we will be happy to include this in the camera-ready version. Further, we believe that you are bringing up a valuable point and we think that supplementing our method with signals from evaluation sets during training might catch such an issue, where the dropping mechanism can remove examples that might degrade performance. \nHowever, due to the rebuttal time schedule, we were not able to experiment more with this. \n\n- **Re: Design choice of selected instruction dataset** Since our proposed method alleviates the need to select the datasets or their composition, we chose a dataset that contains the most used IFT dataset. We agree that this was missing from our dataset section and we have added it to our latest version of the work, section 4.2. However, note that we longer include Mercury as part of our contribution since the Tulu authors have released a V2 of their dataset that includes the dataset we added. Thus, we have \nupdated the dataset section to reflect this.\n- **Re: about the effect open orca** on MMLU, Looking at Table 1 in the Tulu paper, you can notice that Self-instruct is the dataset that affects negatively MMLU. However, we believe that the score drop on tasks that rely on latent knowledge decreases as a function of IFT dataset, that is, there is a point in time that will need to choose between teaching the model a new skill or keeping the world knowledge that might become stale."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3809/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700687113051,
                "cdate": 1700687113051,
                "tmdate": 1700687113051,
                "mdate": 1700687113051,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "pf64plMlP5",
            "forum": "rhp5PDNOgf",
            "replyto": "rhp5PDNOgf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3809/Reviewer_Q3ZP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3809/Reviewer_Q3ZP"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes an adaptive strategy for fine-tuning, where the fine-tuning algorithm actively decides which examples are worth training on based on whether they are too \"trivial\" or \"difficult\". This technique is inspired by results in psychology demonstrating how human learning benefits from the technique of spaced repetition. Across LLaMa-2 7B and 13B and 5 benchmark scores, the method outperforms vanilla fine-tuning by 0.6-5.8%. Across several ablations, it's found that every component of this method is needed."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Spaced repetition consistently improves accuracy across all 5 benchmarks and 2 models, demonstrating robust gains.\n2. The paper provides an ablation study for three components of the algorithm, and it seems that all 3 improve performance\n3. The paper spends time clearly outlining their precise algorithm"
                },
                "weaknesses": {
                    "value": "I overall would appreciate better contextualization/analysis of the method to prove that it's improving upon our current understanding/practice of fine-tuning.\n\n1. Baselines: Though it is encouraging that this model improves over vanilla fine-tuning, this is not the only work in improving data quality/curriculum for fine-tuning. In terms of static pruning methods, one naive baseline is to filter sentences with too high or low perplexity (similar to high/low difficulty), as done [for pretraining](https://arxiv.org/abs/2309.04564). In terms of active learning methods, [Data diets](https://arxiv.org/abs/2306.03208) performs a very similar algorithm to the one in this work, dynamically pruning based on a notion of sample importance (the related work of this paper also provides other references). I believe the paper should reflect this in two ways.\n    - The related work and contextualization of the current paper make it seem that this problem has not been studied before, which can be misleading. Better contextualizing the work in terms of prior research in this area will help highlight the novel contributions by this paper.\n    - Though the results provide an ablation study, it is unclear where prior work lies in this spectrum. Regardless of the motivation, this paper is providing a new method, and its important to contextualize its gains with respect to prior work. Though there are too many baselines to evaluate all, I would appreciate seeing a reasonable baseline to confirm that along some axis, this work pushes along various fine-tuning tradeoffs. \n2. Overhead: This algorithm should induce extra time overhead since examples have to be scored, and \"currently difficult\" examples may have to go through the model multiple times. The authors should report the time taken by both algorithms to evaluate this slowdown so one can evaluate whether this accuracy improvement is worth the additional cost.\n3. Connection to spaced repetition in psychology: From reading the paper, it is not clear to me how connected the algorithm is to spaced repetition learning for humans. According to the paper, spaced repetition says that \"brains retain information more effectively when we learn in multiple, spread-out sessions\". However, the actual algorithm proposed does not do this, and frames example selection under dynamic filtering based on example difficulty. Even if the analysis in Section 5.3 implies that the method is implicitly setting a curriculum, it is not clear to me how this connects to spaced repetition. I wonder what value the psychological motivation provides in the context of this work, and if there is a connection I'm missing in this regard.\n\nI am happy to adjust my score provided some further analysis along these axes."
                },
                "questions": {
                    "value": "1. Is it possible to see the ablation study for all the benchmarks, or is it only possible to report for MMLU and BBH?\n2. Is there any ablation result on the importance of (a) doing this dynamically instead of statically with the pretrained model and (b) adding backdropped data into the dataset?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3809/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3809/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3809/Reviewer_Q3ZP"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3809/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698794411627,
            "cdate": 1698794411627,
            "tmdate": 1700721905942,
            "mdate": 1700721905942,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SRp5A0cXjS",
                "forum": "rhp5PDNOgf",
                "replyto": "pf64plMlP5",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3809/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3809/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback!"
                    },
                    "comment": {
                        "value": "Thank you for your time and valuable feedback, which significantly contributed to enhancing the quality of our work.\n\nRe **1-Baselines**: Thanks for suggesting the naive baseline. We have a perplexity-based naive and the data diet baselines. The results are in Table 1, and a detailed analysis is in Section 5.1 on page 8. Also, based on feedback from other reviewers, we've added 4 more baselines (Table 1 and section 4.4 for details), enhancing the demonstration of our work's benefits.\"\n\nRe **' related work and contextualization**:  We've revised the related work section and parts of the introduction (2nd paragraph). This clarifies our work's position as an extension of existing CL and pruning research and emphasizes our novel contributions.\"\n\nRe **2-Overhead**: We've added section 3.3, which shows the math equations that govern the overhead, and complete details of how we derived the equation in Appendix A.6. Further, we added a paragraph (in section 5.1, page 8) in the quantitative results that shows the numerical values,  proving that the proposed method is on part with random sampling for 7B and more efficient for the 13B for the tested setup.\n\nRe **currently difficult examples** note that our dropping mechanism removes these as they become intractable examples if the model is \nfailing to predict them after many attempts properly. \n\nRe: **3 -Connection to spaced repetition in psychology**: We agree that this was not clear in our initial submission. We have updated the related work section (subset Spaced Repetition, 2nd page) to include the work that motivated using the human memory model in DL. We also reflected this in the introduction.\n\nRe: **Question 1** -We already provided the benchmarks' ablation. However, the results were split into two tables. For clarity, Table 1 now contains all the results.\n\nRe: **Question 2- (a)**: Due to the amount of work induced by adding the 4 baselines, we did not have a chance to add it. But we will happily include it in the camera-ready version.\n\nRe: **Question 2- (b)**: The backdropped data is added to a training set in the next epoch. However, we agree that this was not clear in the initial submission. We have updated the algorithm to make it more clear. You can see this in Algorithm 1, line 18; we the \nuseful examples used in the previous epoch.\n\nWe hope that our major update is sufficient to help adjust your score as you previously suggested."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3809/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700684018273,
                "cdate": 1700684018273,
                "tmdate": 1700684018273,
                "mdate": 1700684018273,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lNcgJiygPV",
                "forum": "rhp5PDNOgf",
                "replyto": "SRp5A0cXjS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3809/Reviewer_Q3ZP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3809/Reviewer_Q3ZP"
                ],
                "content": {
                    "comment": {
                        "value": "I commend the authors for their hard work during the rebuttal process. I am especially pleased with the baselines, which really demonstrate how this method pushes beyond current practice in this field. As such, I am changing my score from a 3 to a 6."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3809/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700721891498,
                "cdate": 1700721891498,
                "tmdate": 1700721891498,
                "mdate": 1700721891498,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]