[
    {
        "title": "Towards Transparent Time Series Forecasting"
    },
    {
        "review": {
            "id": "Sx1anjxc9g",
            "forum": "TYXtXLYHpR",
            "replyto": "TYXtXLYHpR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7585/Reviewer_pJsr"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7585/Reviewer_pJsr"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce TIMEVIEW, a top-down transparent framework designed for trajectory forecasting with static variables. They aim for two levels of transparency, explaining the forecasting through both its trends and properties. To formalize this approach, the authors introduce the concepts of motifs and compositions, avoiding the tracking of individual trajectory values. TIMEVIEW comprises two components: a predictive model based on B-Spline basis functions, and an algorithm for calculating the composition map to facilitate easy visualization. The efficacy of TIMEVIEW is assessed using four real-world datasets and three synthetic ones, and it is compared against several competitors. Transparency is demonstrated through a user-selected example on a synthetic dataset, with additional examples provided in the appendices."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The focus on transparency in forecasting is extremely important.\n- The paper is generally well-written and interesting.\n- The proposed framework appears sound and potentially useful in specific domains."
                },
                "weaknesses": {
                    "value": "- The limitation to static variables is a significant drawback. Additionally, the model can visualize the effects of only two variables, which is another strong limitation.\n- The paper should provide a more robust assessment of the model's transparency, rather than relegating this to the appendix.\n- No specific code references were found."
                },
                "questions": {
                    "value": "- The focus on static variables seems to limit the framework's utility in true time-series forecasting. Given that you claim to forecast time-dependent variables based solely on fixed attributes, isn't this more akin to regression analysis? This approach seems niche. \n- I order to avoid the two variables limit, have you considered visualizing the contour plot using techniques like t-SNE, PCA, UMAP, or similar?\n- Since transparency is the primary goal of your paper, more space should be devoted to proving this claim. For instance, I had difficulty understanding Figure 4.\n- Considering Table 2, which classifies types of motifs, have you evaluated how performance would change if motifs were characterized as sets of classes rather than as continuous values? If the end user ultimately requires such a table, perhaps classification would suffice.\n- In the related works, you distinguish your method from shapelet-based methods, stating that these are primarily used for data mining and classification tasks. However, if these shapelet methods are unsupervised (e.g., Karlsson, Isak, Panagiotis Papapetrou, and Henrik Bostr\u00f6m. \"Generalized random shapelet forests.\" _Data mining and knowledge discovery_ 30 (2016): 1053-1085.), they can also be applied to regression\u2014and consequently, forecasting through reduction."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7585/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698303951048,
            "cdate": 1698303951048,
            "tmdate": 1699636918828,
            "mdate": 1699636918828,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ezIHH2Rcb0",
                "forum": "TYXtXLYHpR",
                "replyto": "Sx1anjxc9g",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Dear Reviewer pJsr [1/2]"
                    },
                    "comment": {
                        "value": "Dear Reviewer pJsr,\n\nThank you for the time and attention you spent reviewing our work. We are encouraged by your kind words about an important problem we tackle, the presentation of our work, and the applications of our approach. Your insights are invaluable in helping us refine our work and better communicate its contributions.\n\nWe structure our response into four sections:\n1. Presentation\n2. Clarifications\n3. Limitations\n4. Extensions\n\n# 1. Presentation\nWe appreciate your comments about the presentation of our work, as they allow us to improve the manuscript further. In particular, we acknowledge your comment about moving some of the transparency assessment from the appendix into the main text. We have updated Figure 1 to show a snapshot of our interface applied to the tumor volume problem. We hope that this clarifies the advantage of our framework compared to other approaches and provides a more coherent narrative.\n\nWe acknowledge your comment regarding Figure 4. We have now added additional snapshots of the interface to Appendix E.4 which should help in understanding how our model can visualize the effect of perturbing two features at the same time.\n\n**Actions taken**\n- Exchanged Figure 1 for a different snapshot of the interface.\n- Added additional snapshots of the interface to Appendix E.4.\n# 2. Clarifications\n## TIMEVIEW works for more than two dimensions\nWe would like to thank you for your point about two dimensions. This allows us to clarify this point in the paper. TIMEVIEW can indeed show the effects of more than two variables. This can be seen on many snapshots of the interface (e.g., Figures 7-10 in Appendix E.1 and Figure 14 in Appendix E.4). We have replaced Figure 1 with a snapshot demonstrating this capability more clearly. \n\nAs we focus on how our interface can be used to answer specific questions (in particular, \"What if\", \"How to be that\", and \"How to still be this\" from the XAI question bank (Liao et al., 2020)) we consider scenarios when we are interested in understanding the change in the prediction as we change one or two of the covariates *at a time* (while all the other features are kept fixed). We note that, usually, people are interested in perturbing one or two features *at a time* as understanding change in more than two features would be cognitively very challenging. For instance, \"Would the tumor keep decreasing if we adjusted the dose of the drug?\" requires understanding the change in one dimension. \n## Code\nAs we say in the reproducibility statement,\n> The code to reproduce the results and for the visualization tool can be found in supplementary materials.\n## Terminology\nAs there are many conflicting terminologies used throughout the literature, we specify the exact setting in Section 2.1, where we contrast time series forecasting with regression and classification models. We further describe the specific problem formulation in Section 3. We identified one place where we used the term \"time series setting\" and updated it to \"time series forecasting\" to make it consistent with the rest of the paper.\n\n## Using shapelets for forecasting\nAlthough shapelets are becoming increasingly useful for many tasks, we are unsure how they can be currently leveraged for time series forecasting\u2014for predicting a whole trajectory rather than a single label. They are usually used as a feature extractor (e.g., for time series classification), whereas we are interested in predicting a whole function. We envision that, in future works, shapelets may become a part of a larger pipeline where interpretable features are extracted from additional time series input and passed to TIMEVIEW as static features. This would extend TIMEVIEW to more complex input types.\n\n**Actions taken**\n- Updated \"time series setting\" to \"time series forecasting\" for consistency.\n\n`rebuttal continues in the next comment...`"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700086604053,
                "cdate": 1700086604053,
                "tmdate": 1700086604053,
                "mdate": 1700086604053,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mKoox7ZAlC",
                "forum": "TYXtXLYHpR",
                "replyto": "Myih5j74vn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Reviewer_pJsr"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Reviewer_pJsr"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your responses and clarifications."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700645370011,
                "cdate": 1700645370011,
                "tmdate": 1700645370011,
                "mdate": 1700645370011,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "p6tdcFiGfm",
            "forum": "TYXtXLYHpR",
            "replyto": "TYXtXLYHpR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7585/Reviewer_PiQk"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7585/Reviewer_PiQk"
            ],
            "content": {
                "summary": {
                    "value": "This article discusses the importance of transparent machine learning models, particularly in high-stakes domains like healthcare, finance, and criminal justice. While transparent models have been proposed for classification and regression, time series forecasting poses unique challenges for transparency.\n\nThe article introduces a top-down framework for bi-level transparency in time series forecasting, aiming to understand both higher-level trends and lower-level properties of predicted time series. It emphasizes the need to comprehend changes in trajectory, which is more complex than single-label outputs.\n\nThe article contrasts this with the challenges of using a more traditional bottom-up approach that focuses on individual time points and values, which may not provide a holistic understanding of the entire time series.\n\nTo implement the proposed framework the article introduces TIMEVIEW, a transparent machine learning model for time series forecasting based on static features. The model uses B-Spline basis functions and an encoder to match feature vectors to trajectory descriptions."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The problem addressed in the article is important and under-developed in the existing literature.\n- The presentation is clear and intuitive.\n- The idea of a top-down framework in this context appears novel."
                },
                "weaknesses": {
                    "value": "- The main contribution in the method appears to be in suggesting a pre-determined dimension reduction to the time series and operating in that new space.\n- The framework appears limiting in applications where time series variability is an important aspect of the interpretation."
                },
                "questions": {
                    "value": "- How would your framework behave when one of the features influences the variability of the time series?\n- Are there alternatives to the cubic spline setup when using your framework?\n- Are there ways to incorporate domain knowledge/priors into this framework?\n- Does your framework seamlessly apply to the common time series setting of a single long sample, i.e. when predicting on overlapping chunks of the time series with a corresponding panel of features? Would there be a concern with the selection of nodes being non-congruent for the overlapping samples?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7585/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698674646638,
            "cdate": 1698674646638,
            "tmdate": 1699636918684,
            "mdate": 1699636918684,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "a6yLFPQi4a",
                "forum": "TYXtXLYHpR",
                "replyto": "p6tdcFiGfm",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Dear Reviewer PiQk [1/2]"
                    },
                    "comment": {
                        "value": "Dear Reviewer PiQk,\n\nFirstly, we express our deep gratitude for your thoughtful and constructive feedback and for recognizing our work's importance, clarity, and novelty. Your insights inspired us to consider new perspectives and potential improvements. We truly value your contributions as they enhance the quality and impact of our research. Below, we address your comments and questions, incorporating your valuable suggestions.\n\nWe structure our response into the following three sections.\n1. Contributions\n2. Clarifications\n3. Extensions\n\n# 1. Contributions\nWe appreciate your comments about our contributions as they allow us to further explain our work's main contributions. In particular, our contributions can be divided into four parts.\n- (a) conceptual\n- (b) theoretical\n- (c) methodological\n- (d) practical\n## (a) conceptual\nCurrent XAI approaches for time series forecasting explain individual time points (bottom-up). That may be sufficient in some settings, but often, we are interested in a more holistic understanding of the whole predicted trajectory (top-down). For instance, current approaches can answer the question, \"How would the predicted tumor volume at $t=1.5$ change if we adjusted the treatment?\". While somewhat informative, often\u00a0it is much more meaningful to answer questions such as \"Would the predicted tumor volume keep decreasing if we adjusted the treatment?\" (this is a question on level 1\u2014about the trend of the trajectory) or \"What feature changes would lower the minimum tumor volume?\" (this a question on level 2\u2014about the property of a particular trend). This approach allows us to introduce bi-level transparency that provides a more systematic and precise definition of a transparent forecasting model.\n## (b) theoretical\nBased on the conceptual framework developed in Section 2, we introduce a mathematical formalism that makes the concepts rigorous. This formal treatment and the theoretical results are necessary for the method we develop in Section 5. We aimed to make the formalism as general as possible so that many future methods can be developed for different choices of motifs (please look at Appendix A.4, where we discuss different examples of motifs).\n## (c) methodological\nTIMEVIEW consists of two parts: the predictive model and an algorithm for calculating the composition map. Both are driven by the conceptual and mathematical framework described earlier and constitute their particular instantiations. We note that the model's architecture is chosen precisely to ensure that the set of dynamical motifs is compatible with the class of the predicted trajectories and that the compositions can be calculated analytically and efficiently. We also ensured that much of the computation could be performed before the training. Thus, the actual training loop is no more complex than training a standard feed-forward neural network for multioutput regression, and the composition extraction can be performed in real-time. In addition, TIMEVIEW can work with observed trajectories containing different numbers of irregular measurements. While we chose to focus on prediction from static features, the conceptual framework is agnostic to the type of inputs.\n## (d) practical\nWe developed an interface that allows us to visualize the composition map and answer various questions about the model, both about the composition of the trajectory (level 1) and the coordinates of the transition points (level 2). Moreover, we show that our method performs much better than other transparent algorithms and achieves a comparable performance to black-box models.\n# 2. Clarifications\nWe assume that the setting you describe refers to a dataset where different samples are observed at different time intervals. For instance, $\\textbf{x}_1$ is observed only on $[0,1.5]$ and sample  $\\textbf{x}_2$ is observed only on $[1,2]$, etc. We want to clarify that TIMEVIEW applies to such settings as long as we can assume all samples have their underlying trajectories defined over some long interval (e.g., $[0,3]$) and are just measured in parts of it. The knots are global\u2014the same for all predicted trajectories\u2014so we do not observe an issue of incongruent knots. Theoretically, it does not matter whether the trajectories are measured at the same intervals or are regularly sampled (please see the loss function in Equation 4). In practice, it may be more difficult to correctly approximate the parts of the trajectory where the data is sparse.\n\n`rebuttal continues in the next comment...`"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700086342795,
                "cdate": 1700086342795,
                "tmdate": 1700086342795,
                "mdate": 1700086342795,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sNFRSjCR96",
                "forum": "TYXtXLYHpR",
                "replyto": "Myih5j74vn",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Reviewer_PiQk"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Reviewer_PiQk"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your clarifications and improvements. I will maintain my score."
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675410535,
                "cdate": 1700675410535,
                "tmdate": 1700675410535,
                "mdate": 1700675410535,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "N28mgul8rp",
            "forum": "TYXtXLYHpR",
            "replyto": "TYXtXLYHpR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7585/Reviewer_eJfZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7585/Reviewer_eJfZ"
            ],
            "content": {
                "summary": {
                    "value": "Interpretability in time series forecasting is typically regarded a post-hoc task, and takes a \"bottom-up\" approach that relies heavily on the observations at individual timestamps. In this paper, the authors argue that this view is overly granular and non-intuitive, whereas focusing on the trends and properties of the time series trajectory would be more informative. In the spirit of explainable ML, the authors then propose the notion of bi-level transparency, along with a framework (TIMEVIEW) that encodes time series are a composition of B-splines. The interpretability aspect is further complemented by the development of a UI tool that allows for further explainability, counterfactual reasoning and sensitivity analysis on the time series. The paper concludes with a comparison to other forecasting methods, where the authors note that predictive performance remains comparable with the aded benefit of enhanced interpretability."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-written, and a pleasure read. It is well structured, and the included visualisations successfully convey the paper\u2019s propositions. I commend the authors for their attention and care to detail when preparing this submission.\n- I appreciated how the authors considered different flavours of interpretability here, as illustrated in the Figure on Pg 2. The complete example presented in Appendix E also conveys the paper\u2019s contributions very effectively.\n- The inclusion of a notebook for executing the aforementioned analysis also serves as a useful guide for practitioners looking to experiment with this framework, and lays the foundations for future extensions of this work."
                },
                "weaknesses": {
                    "value": "- Although the authors already include a few examples of real-world problems where the tooling can be applied, I think that a more fleshed out experiment that runs throughout the whole paper can be especially helpful for conveying the contributions in a clearer manner (Appendix E accomplishes this very well).\n- The comparison to other methods towards the end of the paper addresses a question I had regarding the trade-offs between interpretability and performance, but this constraint could also be featured more prominently throughout the paper, such that the proposed methodology is consistently presented in light of this compromise.\n- I would be interested in learning more about instances where the proposed simulation is *not* suitable, and what properties of time series one would need to inspect before deciding to apply this technique (beyond the requirement for static features)."
                },
                "questions": {
                    "value": "See sections above.\n\n** Post-rebuttal Update **\n\nIncreased score from 6 to 8."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7585/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7585/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7585/Reviewer_eJfZ"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7585/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698704130624,
            "cdate": 1698704130624,
            "tmdate": 1700644731538,
            "mdate": 1700644731538,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UTX1PoQyMQ",
                "forum": "TYXtXLYHpR",
                "replyto": "N28mgul8rp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Dear Reviewer eJfZ"
                    },
                    "comment": {
                        "value": "Dear Reviewer eJfZ,\n\nThank you very much for your thoughtful and constructive feedback on our paper. We are delighted to hear that you found the paper well-written and the visualizations effective. Your insights have been invaluable in helping us refine our work.\n\nWe structured our response into two sections.\n1. Presentation\n2. Limitations\n\n# Presentation\n## Experiment that runs throughout the whole paper\nWe agree with your suggestion regarding the integration of a continuous example throughout the paper. While the detailed discussion in Appendix E.1 exemplifies our contributions effectively, we understand the impact of a coherent narrative in the main text. To address this, we have further developed the tumor volume example introduced in the beginning. We have integrated this theme more consistently across the paper, replacing Figure 1 with a more illustrative snapshot of the tumor volume interface. We have also ensured that this example is referenced in Section 2, further tying together the paper's various sections. Please let us know if you find that these revisions improves the clarity and exposition.\n## Trade-off between interpretability and performance\nThank you for your suggestion about a more prominent exposition of the trade-off between interpretability and performance. To address this, we have expanded our discussion on this aspect, now featuring it more prominently in the introduction (Contributions) and Section 5 (Implementation).\n\n**Actions taken**\n- Exchanged Figure 1 for a different snapshot of the interface.\n- Referred to the tumor example in Section 2.\n- Added discussion about the trade-off between interpretability and performance in the introduction and Section 5.\n\n# Limitations\nWe have already touched upon it in Appendix E.6 (Limitations and future works). Although it is not a limitation of our conceptual framework, TIMEVIEW may struggle to predict trajectories that cannot be well approximated using a cubic spline. For instance, curves with sharp changes in the derivative or discontinuities. This could be addressed by considering motifs that are not dependent on any smoothness constraints (for instance, monotonic motifs as in Example 3 in Appendix A.4) and by using a different space of predicted trajectories $\\hat{\\mathcal{Y}}$.\n\nWe hope this response adequately addresses your concerns. Should you have any additional questions or require further clarification, we are more than willing to engage in further discussion. Thank you again for your valuable feedback and the opportunity to improve our work."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700086231797,
                "cdate": 1700086231797,
                "tmdate": 1700086231797,
                "mdate": 1700086231797,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RkYhmxxExy",
                "forum": "TYXtXLYHpR",
                "replyto": "UTX1PoQyMQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Reviewer_eJfZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Reviewer_eJfZ"
                ],
                "content": {
                    "title": {
                        "value": "Acknowledgement of Rebuttal"
                    },
                    "comment": {
                        "value": "Thank you for detailed responses across all reviews. I still consider the paper to be well-written, and an interesting contribution to the literature. Crucially, the paper is also in a fairly \"complete\" stage and fit for publication. \nI am raising my score to an 8 to reflect this."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700644682246,
                "cdate": 1700644682246,
                "tmdate": 1700644682246,
                "mdate": 1700644682246,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "VDd4AWdFcr",
                "forum": "TYXtXLYHpR",
                "replyto": "N28mgul8rp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you!"
                    },
                    "comment": {
                        "value": "Dear Reviewer eJfZ,\n\nThank you very much for your positive and constructive feedback during the rebuttal period. We are deeply grateful for your recognition of our paper as a well-written and valuable contribution to the field. We appreciate your decision to increase your score.\n\nKind regards,\n\nAuthors"
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675845183,
                "cdate": 1700675845183,
                "tmdate": 1700675872826,
                "mdate": 1700675872826,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Q1ZSXaSByY",
            "forum": "TYXtXLYHpR",
            "replyto": "TYXtXLYHpR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7585/Reviewer_nunX"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7585/Reviewer_nunX"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, Authors propose a transparent model for Time Series Forecasting, which should provide direct explanation for the results generated by the model. They investigate a top-down approach that decompose a time series in trend and properties. \n\nThey demonstrate the efficiency of their platform TIMEVIEW with time series based on static characteristics. The proposal enables to explore the impact of varying the static characteristics onto the output, while demonstrating reasonable performances."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Lots of effort are made to describe the context, the goal and the importance of transparency. \n\nThe baselines models are well-presented, and all parameters are clearly defined, which will greatly help researchers reproduce these results."
                },
                "weaknesses": {
                    "value": "In my opinion, the writing style is not adapted and will confuse or have readers get lost. \nThere are too many references to future sections/definitions/details, which complexify the reading. For instance, Authors introduce some concept, but do not give further explanation (even simplified one), but rather referred to specific sections. Which makes readers go back and forth through the paper.\n\nIn addition, there is no conclusion to this paper, which should give readers the most important points to remember from this study.\n\nIt is surprising that in a paper oriented in TSF there is only one TSF baseline (RNN).\n\nFinally, I think that there are too many claims that are not referenced or back-up in this paper, which diminishes its credibility.\n\n(Note the introduction and discussion style are really unconventional for this type of paper)"
                },
                "questions": {
                    "value": "I had difficulties to fully understand the paper as I had to go back and forth during the reading. And I have a Time Series Forecasting (TSF) background and the I think the terminology used in the paper got me confused. However, the most important question I have is:\n\nWhere is the explainability? If I understand correctly, the proposal can help determine the impact of varying given static parameters (figure 4) on the output of the model. However, it does not infer on why it has this specific impact (the hidden relation in the model). Current, AI models are considered as black boxes because what is happening inside the model to link input and output is complex and too difficult for human to understand. But in my opinion the proposal is not different from such models. It does not give clear relation between input characteristics that generate a given output.  I am not an expert on XAI, but in my opinion, it looks like more to an exploratory platform than a XAI model.\nFurthermore, why is it more comprehensible than other baselines? Someone could set up a platform to visualize the impact of changing the input of a linear model on the produce output, but will it be a good XAI model?\n\nAnd here are some more comments that in my opinion would need to be treated to increase the current score.\n\n# Bottom-up versus Top-down\n\nThe bottom-up approach mentioned by the Authors is rather a \u201cbottom\u201d approach in my understanding. Meaning that models used the raw data (usually regularly spaced) to do TSF. Authors need to clarify this point what is the \u201cup\u201d especially for reader to understand the difference with the proposed approach.\nIs it the following:\n\n*Bottom-up*: from time points predict time points and define a trajectory, but \n\n> understanding trajectory from time points is not natural for human\n\nThen, why not from time point determine the trend (for instance with moving average), min, max and other statistics (with sliding window) that will make understanding \"simpler\"? Why the top-down approach is better?\n\n*Top-down*: Is this approach doing from time point define a trajectory then predict a trajectory for which we first look at trend and properties and then time points? Or from time point predict trajectory for which we first look at trend and properties and then time points?  \n\nIn addition, Authors never demonstrated the issue with the bottom-up approach and why do bottom-up approaches are not bi-level transparent. In related work, they say, \n\n# Terminology\n## Feature\nIn the example box in the introduction, what is the definition of feature? And instance? These terminologies are not clear and may confuse readers.\n\nIn usual TSF, feature (or variate) are other time series that support the prediction of the target (what Authors also called exogenous features). But it looks like a feature in the introduction example is a characteristic or a specific time step of the time series.  Authors would need to clarify these points to avoid confusion when reading.\n\nIn addition, does instance here mean an input sample of the model?\n\n## Regression versus Time series\nIn my opinion, __time series setting__ is not an appropriate terminology. \nit should be multistep forecasting or something similar.\n\n## Knots\nDefinition of knots should not be in appendix.\n\n\n# Continuous time series\n\n> interval [0, T] \u2282 R, where T \u2208 R is a time horizon, and the underlying trajectory is continuous\n\nEvery time series are discrete as values are points/snapshot taken at a given time. Authors might review this sentence or at least clarify their point.\n\n> Thus, understanding a (continuous) trajectory by individual values is unnatural for humans\n\nBut again, time series are never continuous. Even with a very low frequency sampling, it is still a set of points that, in the best scenario, can be matched or approximated by a function/trajectory.\n\n# Function versus trajectory\n\n> there are numerous ways a function can change\n\nI disagree for each time steps the function will either increase, decrease or remain constant, same as regression. Probably, Authors want to say that the function(trajectory?) on the prediction window, may have different shapes depending on different outputs.\n\n# Claims\n\n> often satisfy bi-level transparency but have poor performance\n\nBut where is the proof for that claim? Which model from the experiments are bottom-up approaches?\n\n> However, these methods are not directly applicable to time series forecasting\n\nIt should be backed up by some reference. Linear Regression can be applicable to time series forecasting. Indeed, Linear models such as proposed in [1] have proven to be competitive with latest Transformer-based models, which indeed are less explainable.\n\n# Comparison with decomposition proposal or multi-resolution\n\n[1] and [2] are proposal to decompose time series in trend and seasonality (with either transformer or linear based), why such method would be less explainable than the proposal?\n\n[1] https://arxiv.org/pdf/2205.13504.pdf\n\n[2] https://arxiv.org/pdf/2106.13008.pdf\n\nWhat are the differences of the proposal with multi-resolution solution such as [3] (learning from different temporal granularity)?\n\n[3] https://link.springer.com/chapter/10.1007/978-3-031-05933-9_6\n\n\n\n# Paper needs a proof-reading\n * \u201ddifferent prediction\u201d wrong opening brackets\n * Smoothing parameter is s and motif is also s change to avoid confusion"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7585/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698833358795,
            "cdate": 1698833358795,
            "tmdate": 1699636918387,
            "mdate": 1699636918387,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "D1CbFDEYUN",
                "forum": "TYXtXLYHpR",
                "replyto": "Q1ZSXaSByY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Dear Reviewer nunX [1/3]"
                    },
                    "comment": {
                        "value": "Dear Reviewer nunX,\n\nThank you for dedicating your time and expertise to review our paper thoroughly. We genuinely appreciate the detailed feedback. We have structured our response to address each point directly, reflecting our commitment to enhancing the clarity and quality of our manuscript. We structured our rebuttal into three sections:\n1. Clarifications\n2. Presentation\n3. Comparisons\n\nIn every section, we address all your comments point by point.\n\n# 1. Clarifications\nWe are afraid that some parts of our paper were misunderstood. We appreciate your remarks as they allow us to improve the clarity of our paper further. We provide clarifications about the following.\n- 1.1 Bottom-up versus top-down\n- 1.2 Explainability\n- 1.3 Continuous time series\n- 1.4 Trajectory changes\n- 1.5 Claims\n## 1.1 Bottom-up versus top-down\nWe first want to clarify that \"bottom-up\" and \"top-down\" refers to how the trajectory is comprehended, not how the prediction is generated. We use these terms to differentiate between XAI techniques rather than contrast model architectures. Your questions made us realize that this distinction can be made even more explicit in our paper, so we added a footnote in Section 2 to prevent any future confusion.\n\nCurrent XAI methods usually produce explanations for individual time points (\"bottom\"). These, in turn, have to be pieced together by a human to understand changes in trends (\"up\") from changes at individual time steps. Thus we call it \"bottom-up\". This is challenging, and we discuss the limitations of this approach in Section 2.2 and then demonstrate them experimentally in Figures 11-13 in Appendix E.3. As we describe, these explanations do not allow for answering essential questions such as \"Would the predicted tumor volume keep decreasing if we adjusted the treatment?\". In contrast, our top-down approach (explained in Section 2.3), where we understand the trend of the trajectory (\"top\") and then its properties (\"down\"), allows for answering such questions. We show it in Appendix E.1, where we review several questions and show how our interface allows us to answer them.\n\n## 1.2 Explainability\nOne of the goals of eXplainable Artificial Intelligence (XAI) is to create models or methods that answer meaningful questions about the models and their predictions (Liao et al., 2020). One of the biggest advantages of our approach compared to other techniques is the ability to answer many (often more meaningful) questions. Please look at Appendix E.1, where we demonstrate in detail how our model can be used to answer such questions, and Appendix E.3, where we demonstrate and discuss the limitations of current feature importance methods. In particular, all bottom-up approaches allow for answering questions about a particular time point. For instance, \"How would the predicted tumor volume at $t=1.5$ change if we adjusted the treatment?\". In specific scenarios, this may be sufficient. However, often it is much more meaningful to answer questions that require a different kind of interpretability. For instance, \"Would the predicted tumor volume keep decreasing if we adjusted the treatment?\" (this is a question on level 1\u2014about the trend of the trajectory) or \"What feature changes would lower the minimum tumor volume?\" (this a question on level 2\u2014about the property of a particular trend). We treat these exact questions in Appendix E.3. We have added explicit references to this section in the introduction and updated Figure 1, so that it corresponds to the questions about the tumor volume trajectory. We hope that by following through these multiple examples, a future reader will better grasp the significance of our approach. \n\n## 1.3 Continuous time series\nThank you for your question about continuous time series. It allows us to improve further our explanation of the setup, which is already included in the sentence directly following the one you quote:\n> Of course, in practice, we only observe discrete samples of y, which may be irregular and noisy.\n\nBy providing a stronger link between these two sentences, we hope to prevent future confusion about this issue. Modeling a phenomenon as a continuous system is an established practice in sciences and engineering. That includes settings mentioned in our paper, such as disease modeling or drug concentration in blood. It is also well represented in the machine learning literature (Brunton et al., 2016; Chen et al., 2018). We have also added a discussion to Appendix E about scenarios where the phenomenon cannot be studied as a continuous system. However, our conceptual framework in Section 2 still applies even in these settings.\n\n`rebuttal continues in the next comment...`"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700086752943,
                "cdate": 1700086752943,
                "tmdate": 1700086752943,
                "mdate": 1700086752943,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "K6kvs0viRb",
                "forum": "TYXtXLYHpR",
                "replyto": "Q1ZSXaSByY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7585/Reviewer_nunX"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7585/Reviewer_nunX"
                ],
                "content": {
                    "comment": {
                        "value": "I would like to thank the Authors for taking time in replying to my comments. However, I will maintain my current score as Authors did not manage to convince me with their answers.\n\nPlease find below additional comments based on Authors' rebuttal.\n\n## Bottom-up versus top-down\n> demonstrate them experimentally in Figures 11-13 in Appendix E.3\n\nAppendix says:\n> TIMEVIEW takes this analysis a step further by providing a comprehensive understanding of feature impacts on the entire trajectory [...]\n\nIt might be only me, but I don't see why TIMEVIEW is more comprehensive. Authors would need to provide the TIMEVIEW impact feature for these datasets (Appendix E1 is only Tumor example) for the readers to appreciate this \"comprehensive understanding\". As mentioned in my original review, this is another claim without rigorous proof.\n\n## Trajectory change\n> It is infeasible for a human to reason about all these different possibilities, which motivates our proposal of a top-down approach.\n\nWhy would TIMEVIEW make things easier then? Every time a human modifies a value from the parameters the potential trajectory change, but human still has no clue on the reason for the impact.\n\n## Claims\n>all trajectories predicted by linear regression and GAMs are parallel; [...]\n\nWhere can Authors see that? Section 7 is only a table with average (standard deviation) MSE...\n\n## Comparison with Transformers\n> It is impossible to understand how the change in the output will influence the trend and properties of the predicted trajectory. \n\nIn my opinion, it is also impossible to understand how the change in the input (Authors typo?) will influence the trend and properties with TIMEVIEW. You can visually see the impact of changing parameters values, but not understand the reason for these changes.\n\n## Comparison with Linear\n> but it would offer very poor performance.\n\nHow can you affirm that it will offer very poor performance without trying it? There are dozens of papers showing that Linear-based models are effective for TSF, so why it would be different for your datasets? Or is it that your proposal applied to only specific type of dataset? If so, you should revise paper to make clear that this method cannot be applied to any TSF."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7585/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700564290801,
                "cdate": 1700564290801,
                "tmdate": 1700564342606,
                "mdate": 1700564342606,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]