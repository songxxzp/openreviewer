[
    {
        "title": "Twinned Interventional Flows"
    },
    {
        "review": {
            "id": "OzkzwGM5m3",
            "forum": "N134PpnlKs",
            "replyto": "N134PpnlKs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7202/Reviewer_Tyhh"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7202/Reviewer_Tyhh"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a new method called twinned interventional flows (TIFs) for modeling complex dynamical systems with irregularly sampled partially missing observations and actions (interventions). To achieve this they modify continuous normalizing flows to augment them with history of latent variables that bridge the gap of partial observability and causal insufficiency (presence of hidden confounders). As a result, the model can allow counterfactual queries. Additionally, they introduce a proof that shows that training with observational and interventional data can improve performance as compared to training only on interventional data."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "## Originality\n- The setting (learning to model temporal potential outcomes in continuous space with partially missing observations) seems under-explored.\n\n## Significance\n- This work seems to be introducing some benefits on the tested experiments.\n- It suggests a novel penalty that improves in the stiff ODE case.\n- The work solves an important problem (learning to model temporal potential outcomes in continuous space with partially missing observations)"
                },
                "weaknesses": {
                    "value": "Weaknesses\n- It\u2019s poorly written and lacks coherence. The introduction doesn\u2019t motivate the problem sufficiently - what is the precise setting? This should be stated in the first paragraph and not scattered around two pages of introduction (leaving a feeling of lack of focus). For example paragraph three is motivating a setting but doesn\u2019t explicitly express it and then paragraph four start talking about something different (stiff ODE) without ever defining it or commenting on the relevance of stiff ODEs with this setting. After reading the paper several times, still cannot understand why this specific setting suffers from stiff ODEs.\n- The paper combines too many ideas and it doesn\u2019t spend much time to explain and study each of the ideas properly. For example, the penalty for mitigating stiffness is not ablated sufficiently (stiff ODEs are not even defined on the paper which makes it very hard to read)\n- Related work and background section is out of focus and missing key parts as well. For example, why is causal discovery discussed? How is causal inference relevant? Is it a causality paper, if so where is the background section introducing key concepts?\n- The paper is appendix heavy. A lot of the content should have been surfaced in the main text. For example, assumptions C.{1,2,3} are essential and should be surfaced on the main. Significance of theoretical results should be discussed in main as well."
                },
                "questions": {
                    "value": "- What are stiff ODEs and how are they related to this setting? is it a common problem in the setting you are studying? can you show visual examples in the main text? motivate and demonstrate the issue and then solve it, that way the reader can understand why things are happening.\n- What is the setting precisely? Please write a sentence explaining it as simple as possible. This shouldn't be guessed by the reader.\n- in paragraph 3, \"which can be counterproductive\" - it's not counterproductive only, it casts the problem non-identifiable. Can you please update the text?\n- What are stiff regions? This is a technical term and needs definition before used.\n- Unobserved confounders is an assumption and is not explicitly stated. Please put a list of the assumptions you are making (also this is known as causal sufficiency - i'd suggest to use terms known in the community if your audience is causality)\n- In related work, missing discussion on POMDPs for continuous time (e.g. \"POMDPs in Continuous Time and Discrete Spaces\" or \"Flow-based Recurrent Belief State Learning for POMDPs\"), can you please add or discuss relevance?\n- In related work, causal discovery discussion is unrelated, can you please discuss the relevance to your work or remove?\n- Also, are you focusing mostly on learning from offline data? If so, would discussion of offline RL be of relevance here?\n- In POMDP formulation you say that rewards are not required, however if you remove rewards from the POMDP then it's just a graphical model (Decision Process requires rewards). What does the POMDP formulation buy you?\n- What is the \"twinned space\"?\n- In 3.2 you stalk about the stability of Monte Carlo estimate. Where are you using MC?\n- You cite Manski 1989, can you please comment on the relevance of this paper to you work? It doesn't seem to comment on the use of \"observational data helping learning the dynamics of discrete interventional settings\".\n- Figure 6 - The plot doesn't match the performance of the baselines in the paper. Did you use the same code? Also, how many seeds did you run? Are you plotting the standard error? I don't see any variance on your method - is this because it's stable between seeds?\n- What is the take-away message from the half cheetah example? How is this experiment related to your setting?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7202/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698830137764,
            "cdate": 1698830137764,
            "tmdate": 1699636855629,
            "mdate": 1699636855629,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dsHGSiaoDC",
                "forum": "N134PpnlKs",
                "replyto": "OzkzwGM5m3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your feedback. We address your questions and concerns below.\n\n\n1. **Coherence and motivation behind the combination of ideas.** \n\n    We appreciate your feedback and understand the importance of clarity in our writing. Our objective is to address a combination of real-world problems, each of which is carefully chosen based on its relevance to applications such as medical decision-making. The selection of ideas is motivated by the need to integrate knowledge from different fields to tackle complex systems effectively.\n\n    The issue of stiffness, in particular, arose during the development of our method. Despite searching existing literature, we found no satisfactory solutions. Consequently, we devised our own approach, which demonstrated significant improvements in our experiments. Please see the visualization in Section 4.1, if it's sufficient to explain the problem.\n\n    We acknowledge the importance of conveying these motivations more explicitly, and we will make adjustments to the text to provide a clearer explanation of why these specific problems are included in the paper. If you have additional suggestions or specific areas you would like us to address, please let us know.\n\n\n2. **Regarding stiffness in ODEs.** \n\n    There is no clear measure of stiffness in the literature and our definition, \"Stiff ODEs are numerically difficult to invert,\" is derived from Ernst Hairer\u2019s observation that \"stiff equations are problems for which explicit methods do not work\" [1], combined with insights from [2] that errors can significantly magnify when ODEs are inverted.\n\n    To address your concern, we will refine our wording and explicitly reference [1] to provide a clearer foundation for our definition. If you have any further suggestions or specific areas you would like us to enhance, please let us know.\n\n    Regarding the visualization of stiffness, it is presented in Figure 4f compared to the performance when the penalty term is employed (4e).\n\n    How would you like us to further visualize these problems?\n\n3. **Focus of related work and background section.** \n\n    In our paper, we approach causality from a specific angle, choosing not to delve deeply into causal discovery. We mention it mainly due to its relevance to the intersection of reinforcement learning (RL) and causal fields. Instead, our primary focus lies in recognizing the causal properties of the system, particularly addressing challenges like unobserved confounders. We achieve this by incorporating these considerations into the model design, ensuring flexibility to tackle such complexities.\n\n    To accomplish our goals, we amalgamate tools from both the causal inference and RL domains. As a result, our background section delves into these topics, expecting a foundational understanding from the readers. We acknowledge the absence of exhaustive technical background knowledge in the paper, given its assumption of familiarity with these fields.\n\n    Nevertheless, we are open to adjusting our focus if you deem any particular aspect irrelevant or have specific topics in mind that should receive more attention. Your insights are valuable in shaping the paper to meet the expectations of our audience.\n\n4. **The balance between appendixes and main body.** \n\n   We share this concern with you, however the strict page limit forces us to make some compromises.\n\n    If there are specific sections in the appendix that you believe could be integrated into the main body or should be discarded, please let us know. We are open to reorganizing the content to enhance the overall flow while acknowledging to the page limit.\n\n5. **The setting summarized in a sentence.**\n    Our primary objective is to develop a predictive model that accurately captures the system\ndynamics under various interventions and possible (unobserved) confounders. This model should be versatile enough to estimate the likelihood of events and make use of both observational and interventional data. We believe this framework is applicable to various real-world scenarios, particularly in fields like medicine.\n\n6. **Wording and additions.**\nThank you for your detailed suggestions on the wording, (e.g. wording in paragraph 3, and adding the term causal sufficiency). We appreciate your feedback and will incorporate the necessary changes in the upcoming version, which we aim to upload shortly. Your understanding of the delay is much appreciated. We look forward to continuing the discussion.\n\n\n7. **Definition of stiff regions.**\n\n    We will add this definition to the text: By stiff regions we mean the regions of weight space where the corresponding NODE becomes stiff.\n\nThe response will be continued in the following message."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700407454287,
                "cdate": 1700407454287,
                "tmdate": 1700407454287,
                "mdate": 1700407454287,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6Sp6b9Xkkm",
                "forum": "N134PpnlKs",
                "replyto": "3yFP65Dgqv",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7202/Reviewer_Tyhh"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7202/Reviewer_Tyhh"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for taking the time to address many of my questions and concerns - I appreciate your effort. However, unfortunately I still have concerns and I'd like to keep my score. Details below.\n\nIf rewards are not of a concern or used for policy optimization, then POMDP might not the right abstraction. What's left is just a graphical model and i'm not saying this to devalue their importance, rather i'd like to emphasize that this should simplify your narrative as you could avoid the connection with RL which I'm still not convinced that it's the right way to describe your work - it would make sense to connect with RL if you care about the impact of the confounder in identifying the optimal policy. To be more clear, I think this is an important problem but I believe it would be more clear if the narrative structure was like the following:\n- Here's a graphical model describing our setting\n- We assume randomization as interventions (conencting with Rubin's potential outcomes framework rather than SCMs)\n- There are some latent / hidden confounders and we take care using our novelty.\n\nRegarding what should be put in the main vs appendix, these are some suggestions:\n- All of the assumptions should be stated clearly in the main and ideally in the intro.\n- Algorithm is of the main interest of the reader, shouldn't be left for the appendix (assume i didn't read the appendix, would the paper make sense without it?)\n\nStandard error in figure 6 is quite high and overlapping between the baselines thus it's difficult to make any reliable assessments about the additional benefit of TIF over VAE-RNNs (or even simple RNNs) (acknowledged by the authors already). Also you say, \"The crucial takeaway is that TIF integrates effectively into the RL framework, demonstrating its capability to handle real-world online data.\" - I'd avoid calling half-cheetah a real-world problem. Perhaps my hint here is that this experiment is more of a distraction than a meaningful experiment and you should save this space for adding more relevant things from the appendix.\n\nAlso regarding the focus of related work. I still believe that RL and causal discovery is irrelevant in the sense that you don't do causal discovery and you should constraint the related work in the intersection of RL and treatment effects, which has plenty of interesting work to cite."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700739166373,
                "cdate": 1700739166373,
                "tmdate": 1700739166373,
                "mdate": 1700739166373,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "drwTPsYCHY",
            "forum": "N134PpnlKs",
            "replyto": "N134PpnlKs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7202/Reviewer_dXx9"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7202/Reviewer_dXx9"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new time-varying generative model based on conditional continuous normalizing flows, namely, twinned interventional flows (TIF). TIF operates under the assumption of a partially observed Markov decision process (POMDP) with continuous time, can be fit with both observational and interventional data, and can handle irregular and missing data. The model promises to perform predictions in the presence of unobserved confounding, to detect anomalies, to do counterfactual inference, and to facilitate reinforcement learning and treatment effect prediction. To verify the claimed properties of the model, the authors provided experiments with different benchmarks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper develops a new flexible generative model for continuous-time irregularly-sampled data. It has many potential applications, as it offers a tractable log-probability at each time step and does not suffer from the limitations of fixed-dimensional embeddings. The paper also provides several important theoretical results, like the marginalisation of the infinitesimal change of variables theorem (3.1)."
                },
                "weaknesses": {
                    "value": "The main weakness of the paper, in my opinion, is that TIF aim at many different applications, but the lack of rigour and experimental evidence makes it unclear what this method is actually useful for. \n\n**Lack of rigour**. The paper positions itself as both a reinforcement learning and a (causal) time-varying treatment effect estimation method but makes little effort to explain the connections between both. It inherits the assumptions, typical for reinforcement learning, i.e., POMDP, but uses it for causal benchmarks, like interventional or counterfactual predictions. For example, benchmarks for interventional predictions (like the tumor generator) are based on a different set of assumptions, e.g., three assumptions from Seedat et al. (2022), and, thus, are not suitable for TIF. Importantly, the straight application of the method to interventional and counterfactual prediction tasks raises many identifiability questions. For example, is there a need to adjust for time-varying observed confounders or to perform propensity weighting to obtain unbiased interventional predictions? Also, what is the purpose of the data with the hidden confounding (I understand, that it does not harm performance, given infinite data, but I don\u2019t see how it could facilitate interventional predictions). Regarding counterfactual predictions, they would require even stronger identifiability assumptions [1], such as additive latent noise. Those assumptions are not properly discussed in the paper. The paper also claims to handle unobserved confounding, but in this case, without further assumptions, the causal effects are non-identifiable. \n\n**Lack of experimental evidence**. Some key statements in the paper were not supported by the experimental evidence, for example, the claim that TIF are better than methods with low-dimensional embeddings. Also, the authors claimed that the method provides accurate density estimates, but no comparison with other density estimators was provided. The same applies to the counterfactual benchmark, where no fair comparison with other existing baselines, e.g., [2], were provided, or anomaly detection benchmark. Regarding, the RL benchmark, it does not seem like TIF significantly outperformed VAE-RNN (see Fig. 6). Also, there are no implementation details provided for the benchmarks. Additionally, I found it unfair, that the authors did not provide details on the hyper-parameter tuning and did not provide the source code of the method. E.g., it is unclear, how to choose the latent dimensionality ($n - m$) or number of MC samples. For the same reason, I cannot verify, whether the comparison between TIF and TE-CDEs was fair for the interventional prediction benchmark.\n\nI also have several minor remarks, which are important for clarity and understanding of the paper:\n- Table 1 mixes up completely different methods, aka \u201ccompares apples with oranges\u201d, e.g., causal inference methods with reinforcement learning methods; time-varying methods and cross-sectional methods, etc. Also, it is unclear, what property \u201cmaking prediction in the presence of unobserved confounders\u201d means, as in this case, we would need to assume some sensitivity model and perform partial identification of causal effects. Additionally, there seem to be wrong entries, like the cross for De Brouwer et al. (2022) at \u201clogp\u201d column (this paper assumes a likelihood model, thus we can infer log-probability), or Seedat et al. (2022) at \u201cconf\u201d (TE-CDEs are not suitable for hidden confounding).\n- Some of the notation and definitions in the paper were not properly introduced. For example, a POMDP was never formally defined. Also, what is $\\hat{Q}_{t_j, t}$ in Eq. 1? What is the definition of the \u201cprivileged data\u201d? What are \u201csub-flows\u201d?\n- Some of the causal inference terminology is used inconsistently. For example, counterfactual prediction is sometimes used in the meaning of the interventional (Sec. 4.2), and \u201ccounterfactual trajectories\u201d are used instead of \u201cinterventional trajectories\u201d (Sec. 4.1 \u201cCounterfactual prediction\u201d). Notably, the terms \u201cinterventional\u201d and \u201ccounterfactual\u201d denote fundamentally different concepts of causal inference. \n- I found the usage of the terms \u201cobservational\u201d and \u201cinterventional\u201d data a bit confusing in this paper. Usually, the term \u201cobservational data\u201d is used for the data, where treatment assignment depends on other observed $o$ and unobserved \u201cl\u201d confounders, whereas \u201cinterventional data\u201d means a randomised control trial, i.e., no arrows leading to variables $a$ in Fig. 1. This paper, on the other hand, uses the term \u201cobservational\u201d for the data with unobserved confounders and \u201cinterventional\u201d for the data with all confounders observed.\n- Seems like the authors confused the causal Markov condition and Markov property of POMDP, which are two different things. \n\nreferences:\n[1] Nasr-Esfahany, Arash, Mohammad Alizadeh, and Devavrat Shah. \"Counterfactual identifiability of bijective causal models.\"\u00a0International Conference on Machine Learning. PMLR, 2023.\n[2] H\u0131zl\u0131, \u00c7a\u011flar, et al. \"Causal Modeling of Policy Interventions From Treatment-Outcome Sequences.\"\u00a0International Conference on Machine Learning. PMLR, 2023."
                },
                "questions": {
                    "value": "- What is exactly meant by the ability to perform \u201conline prediction\u201d?\n- Why is the concatsquash block important for the architecture of TIF? Couldn\u2019t it be done simpler?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7202/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7202/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7202/Reviewer_dXx9"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7202/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698880193955,
            "cdate": 1698880193955,
            "tmdate": 1699636855481,
            "mdate": 1699636855481,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "mruvFWvuVR",
                "forum": "N134PpnlKs",
                "replyto": "drwTPsYCHY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Many thanks for your thoughtful  feedback. We  address all your comments and suggestions below:\n\n1. **Causal reinforcement learning: connection between RL and treatment effect estimation.**\nThank you for your comment. The connection between causal inference and RL fields is well studied by Bareinboim [1]. In our setting, the reinforcement learning set up (POMDP) is closely tied with causal treatment effect prediction; and our work can be seen as addressing two of the six main tasks in causal reinforcement learning, namely, (a) Generalized policy learning and (b) Counterfactual decision-making. Additionally, deciding when and where to intervene could be addressed with a good predictor that is continuous in nature.  \n\n    Specifically, each action $a_t$ serves the role of a treatment, and time-varying confounders can be included in $l_t$. Effectively predicting treatment effects implies that the problem can be cast as an RL task, where the objective is to optimize the treatment based on the predictions. This perspective highlights the interplay between causal treatment effect prediction and RL, where a good predictor with continuous properties can inform decision-making in RL. Our POMDP formulation serves this purpose. \n\n    Hopefully this clarified the connections between these topics and we will make the according changes to the paper to highlight these topics.\n\n\n2. **Identifiability and our  assumptions.**\nWe understand your concerns about identifiability. Indeed, identifying the number of confounders or recovering a full causal graph in general is tedious and often infeasible. We also acknowledge that there are scenarios where data limitations may hinder learning of the true causal structure due to identifiability issues.\n\n    Our primary goal here is to develop a predictive model that accurately captures the system dynamics under various interventions and possible (unobserved) confounders in our setting that treats the size of the latent space as a tunable parameter, and abstracts many practical situations with confounders. We therefore appeal to an approach that does not constrain the causal hierarchy within observed and unobserved variables and can be described in terms of a continuous POMDP.  \n\n    Importantly, if desired, identifiability can be achieved with appropriate additional assumptions in our setting. Indeed, one way is identification via (weighted) time-independent sampling by adapting Tennenholtz et al (2020) [2]. This, however, is susceptible to the curse of dimensionality. Instead, one can invoke a (more amenable) reduction to proximal causal inference as illuminated by Bennett and Kallus [3].\n\n    The set of assumptions provided in the paper are also consequence of this approach. The Overlap assumption by Seedat et al. [4] is listed in our set of assumption in Appendix C, as it necessary for deriving our theoretical results. However the two other assumptions by [4] are more related to the identifiability of the problem, which is not our focus here, and so were not listed. However we are happy to add these assumptions with a discussion on identifiability based on your feedback. \n\n3. **Regarding the experimental evidence.**\n Our primary focus in the experimental section was to showcase the various  capabilities of the proposed methood TIF, but not to imply or assert its  superiority over low-dimensional embeddings like TE-CDE [4]. We emphasize the flexibility afforded by TIF due to its many strengths inherited from continuous normalizing flows, particularly in density estimation. In this context, it is crucial to note that while density estimation is primarily a theoretical framework, the stability of the Monte Carlo estimation algorithm, as outlined in Appendix D, requires further validation. Consequently, we refrained from making comparisons with, for example, Bayesian methods. \n\n    We are grateful to you for bringing the two new papers [5], [6] to our attention, which are important and highly relevant to our topic. Unfortunately these works were not published when we worked with the background study of TIF. We are happy the see that the field is evolving and we will cite and position these papers appropriately in the final version of the paper. However, due to time constraints, benchmarking against them is unfortunately not feasible during the response period.\n\n     We believe that this work already makes significant contributions, and lays the foundation to investigate aspects such as those pointed by you as future work. Based on your feedback, we will also be sure to underscore the motivation underlying each of our experiments.\n\nThe response will be continued in the following message."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700331346778,
                "cdate": 1700331346778,
                "tmdate": 1700331346778,
                "mdate": 1700331346778,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LBw3riJVCG",
                "forum": "N134PpnlKs",
                "replyto": "drwTPsYCHY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer, we are grateful for your constructive feedback that helped us elucidate some important aspects of this work. We hope our response has sufficiently addressed your concerns, and hope it translates into an increased score. We are also happy to discuss further if you have any further questions before the discussion window ends tomorrow. Many thanks!"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700674548372,
                "cdate": 1700674548372,
                "tmdate": 1700674548372,
                "mdate": 1700674548372,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jXMWiZJIzg",
                "forum": "N134PpnlKs",
                "replyto": "LBw3riJVCG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7202/Reviewer_dXx9"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7202/Reviewer_dXx9"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors, I appreciate your effort in trying to address my comments. Yet, there are still many unresolved concerns.\n\n'1'. Thank you for providing a reference to [1] Elias Bareinboim (2020). Still, I think that the Related Work section lacks structure and the contrast between what is novel in the paper vs what was already in the literature. Also, it is still unclear to me, what is the main contribution of the paper wrt. previous works. For example, the authors claimed \n> We focus on motivating the benefits of flow models for POMDPs.\n\n   Does this imply that the approach of the paper is simply to select the RL tasks, where normalizing flows perform well? If so, this paper needs to provide a rigorous comparison with **all the existing baselines** for **each** specific RL task (or at least one).\n\n'2'. What exactly do you mean here: \n> However the two other assumptions by [4] are more related to the identifiability of the problem, which is not our focus here, and so were not listed.\n\n   How is the identifiability of the problem not important for this paper?\n\n'3'. I acknowledge, that the provided by me examples are very recent and according to the ICLR policy are allowed not to be mentioned in the current paper. Nevertheless, [6] \u00c7a\u011flar H\u0131zl\u0131 et al. provided a related works table (Table 3), where there are methods, published before May 2023. For example, \"Noorbakhsh, K. and Rodriguez, M. G. Counterfactual temporal point processes. In Advances in Neural Information Processing Systems, volume 35, 2022.\" and  \"Hua, W., Mei, H., Zohar, S., Giral, M., and Xu, Y. Personalized dynamic treatment regimes in continuous time: A Bayesian approach for optimizing clinical decisions with timing. Bayesian Analysis, 1(1):1\u201330, 2021.\" It seems to me that those methods are relevant to the current paper and have to be properly discussed in the related work and included in the experiments.\n\n'4'. Thank you for the brief explanation, but I would still like to know the exact tuning ranges and tuning criteria. This is very important, as I cannot verify the transparency and reproducibility of the results.\n\n'5'. To the best of my knowledge, TE-CDE considers all the confounders to be observed (see Assumption 3 (Continuous-time sequential randomization)). \n\n'9'. Under the causal Markov condition, I meant that there is no hidden confounding in the causal diagram (Fig. 1). And under the Markov property of POMDP, I implied that the future states are independent of the past, given the most recent state. Correct me if I am wrong, but those two assumptions are in general different. Specifically,  we can have the causal Markov condition, but dependencies between the future states and the whole history given the current state, and vice versa,  a POMDP with Markov property but with hidden confound and, thus, non-Markovian SCM.\n\n'11'. \"Indeed, our framework does not necessitate its use.\" By the principle of Occam's razor, shouldn't simpler architecture be considered then? At least I would expect some form of the ablation study.\n\nAs there are still many unresolved issues, I tend to keep my score the same."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700698186295,
                "cdate": 1700698186295,
                "tmdate": 1700698186295,
                "mdate": 1700698186295,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FoMwvorUFk",
                "forum": "N134PpnlKs",
                "replyto": "drwTPsYCHY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "1.  Thank you - we'll structure the related section better based on your comments.\n    Our main contribution is to use flow models in an augmented space that couples observations and latent variables including unknown confounders, to enable exact (not just lower bounds on the) log-likelihood estimates as well as predict treatment effects.\n    We're not aware of any previous work in literature that can handle both these tasks simultaneously in the presence of unknown confounders. Since we do not observe the unknown variables only part of the information is visible and the state evolves continuously  over time, so the problem can be investigated in a POMDP  setting.\n    We would like to emphasize that our goal is not to cherrypick any RL tasks, but to motivate this work as a generic framework that can also be leveraged in RL settings. \n    **In our RL task, we already compare with Latent-ODE which is a strong normalizing flow-based baseline.**\n2. Identifiability is certainly important, however, identifiability results in our POMDP setting can be derived using e.g., proximal causal inference with additional assumptions. Since such theoretical results on identifiability are already known, and these additional assumptions do not play any role otherwise in the entire setup (e.g., for the purpose of likelihood estimation), we did not elaborate on these to keep the exposition focused.  We will make this clear based on your comments.\n3. Thank you for pointing these papers to us. We will appropriately position the contributions of these works. Please note that neither of these papers allow for exact log-likelihood estimation in the presence of unknown confounders\n4. The fine tuning of the learning rate for the tumor effect prediction was done with values 0.01- 0.0001 for TIF and the values reported in literature were used for TE-CDE. **Based on your comment, we have now also shared the code of this experiment for reproducibility**.\n5. To our understanding the assumption 3 by Seedat et.al. means that the current history is sufficient for making accurate counterfactual predictions without incorporating the information about the potential factual outcomes. This does not mean that there is no confounding effect in the system, but rather that the history observations are sufficient to accurately model them. But we will re visit this and make corrections if needed.\n---\n9.\n    Thank you for elaborating this. We see it as: there is unobserved confounding in causal diagram (see $l$ in in Figure 1 and observe that red arrow is present only in the observational data) however the markovian assumption in POMDP is satisfied in respect to the full state $s=[l,o]$, thus if we obtain accurate estimate of $l$ we can make accurate predictions based on the current state. The parental markovian condition follows from the structure of of the DAG, that is, each variable is independent on all its nondescendants, given its parents (Pearl & Verma 1995).\n    However, we will revisit our wording and make sure that there is no ambiguity and the terms are conveyed correctly.\n---\n11. Thank you.  Finding simpler components that could be alternatives to concatsquash block is certainly an interesting direction, but requires further research. In general, beyond Occam's razor (as often implemented e.g., by instantiating the minimum description length principle - which loosely speaking amounts to choosing a simple hypothesis from a set of candidate hypotheses that all fit the training data well), we know from learning theory foundations that there is an inherent tension between expressivity and generalization when considering different families of architectures (or class of hypotheses) and the sweet-spot lies where the two are roughly balanced.\n    Unfortunately, the generative ML community is still trying to work out the generalization bounds for flow based models, so a detailed principled analysis of the impact of different components is very much an open question that this work inherits.\n    Please do note that several works have shown the empirical merits of using concatsquash block in similar settings, i.e., for embedding in dynamic systems, so we adopted this choice to be consistent with the prevailing paradigm.\n\n\nBased on your comments, we'll be happy to include a discussion on this in the Supplementary section as well.\nThank you again for your thoughtful comments, and we hope our response here satisfactorily addresses your concerns and translates into an improved score."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700737244439,
                "cdate": 1700737244439,
                "tmdate": 1700738557831,
                "mdate": 1700738557831,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fNK6jnrIgK",
            "forum": "N134PpnlKs",
            "replyto": "N134PpnlKs",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7202/Reviewer_ELA6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7202/Reviewer_ELA6"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel approach called Twinned Interventional Flows for estimating causal effects of interventions in continuously evolving systems, based on a modified conditional normalized flow model. The authors introduce the concept of \"twinning\" and use conditional continuous normalizing flows to model system dynamics, obtaining accurate density estimates. The proposed method is flexible and can be applied to various tasks, especially for counterfactual prediction while combining both experimental and observational data. The paper also presents theoretical and empirical results demonstrating the efficacy of the proposed framework."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- (Originality & Quality) This paper presents an interesting and novel concept, \"twinning\", which augments partial observations with additional latent variables including confounders as a state and treats interventions as actions in a POMDP setting.\n    - The proposed approach is based on a modified conditional normalized flow (CNF) model with bijective mapping that incorporates the twinning of observation and unobserved latent representation. This naturally can be extended to address counterfactual inference problem.\n    - This approach seems pretty versatile. Apart from addressing counterfactual inference, it also generalizes to data with missingness or irregular sampling.\n    - The paper presents a solid theoretical analysis on the property of the proposed approach. This further justifies the technical soundness.\n\n- (Significance & Potential Impact) Since the focus of this work is to generalize the conventional CNF model to the counterfactual inference setting where experimental and observational data can be use in conjunction. This work can be used in many continuous causal inference problems. The versatility in its design can potentially contribute to a broad impact."
                },
                "weaknesses": {
                    "value": "- (Presentation & Clarity) Despite the technical soundness, the paper seems difficult to follow, in lack of intuitive illustration of both newly introduced concepts or adopted approaches & notations. This makes it hard for readers to follow the logical reasoning and motivation for each specific modeling proposal.\n    - The method section mainly focuses on \"what\" -- what was designed in the proposed approach, however without enough high-level intuitive illustration of \"why\". Similarly, in experiment section, the purpose, tasks and characteristics of the chosen dataset were not clearly presented, which makes it difficult to understand the motivation and analysis along without checking the external references.\n    - The above could be partially due to limited space. But i believe the presentation can be improved.\n\n- (Complexity and Limitation in Scaling) Bounded by the invertibility design, the proposed normalized flow based model TIF does not abstract input data into lower-dimensional latent space with encoder. All transformation/mapping happens in the same dimensions. This would limit generalizing the model to complex data with high dimensionality (e.g, clinical data, EHR, images). Due to the high time complexity of matrix inversion (in general O(n^3)), the computation cost would be significantly heavy for either large sample size or high data dimensionality."
                },
                "questions": {
                    "value": "- What's the overall time complexity of TIF?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7202/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699376181595,
            "cdate": 1699376181595,
            "tmdate": 1699636855373,
            "mdate": 1699636855373,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3zcg1lrZJJ",
                "forum": "N134PpnlKs",
                "replyto": "fNK6jnrIgK",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7202/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Many thanks for your constructive feedback. We address all your concerns and questions below:\n\n1. **Improving presentation and clarity.**\n\n    Thank you for your inputs. We appreciate your insights, and are currently working on enhancing readability, including, by incorporating more intuitive reasoning into the methods section and elucidating the experimental section as suggested. The revised version will be uploaded shortly.\n\n2. **Time complexity and scaling.**\n\n    Thank you for the opportunity to shed light on the computational aspects of the proposed method.  We would like to emphasize that TIF does not necessitate full matrix inversion (which would indeed have been computationally expensive with a complexity of $O(D^3)$, where $D$ denotes the data dimension), instead inheriting the more tractable computation needs of continuous normalizing flows that can be solved more efficiently by integrating backward in time [1].\n\n    Furthermore TIF inherits from the continuous flows normalizing a more efficient way of estimating the log likelihood.\n\n    If the cost of evaluating TIF is $O(DH)$ where $D$ is the dimensionality of the data, and $H$ is the largest hidden dimension in the concatsquach block, then the time complexity of one transformation using a naive normalizing flow approach would be $O(DH + D^3)$\n\n    The cubic format arises from using the change of variables to obtain complex densities $z \\sim p_z(z)$ from a simple distribution $u \\sim p_u(u)$ with transformation $T(u) =x$, as described in [1,2]\n\n    $log(p_z(z))=log(p_u(u)) - log(|det J_T(u)|) ~, $\n\n    where $J_T$ is the corresponding Jacobian matrix ($n \\times n$), and the time complexity of computing the log determinant is $O(n^3)$.\n\n\n    With continuous normalizing flows the complexity can be reduces to $O(DH + D^2)$, as the change in log probabilities can be written as [3, 2]\n\n     $log (p(z_{t_1}))= log (p(z_{t_0})) - \\int_{t_0}^{t_1} Tr \\{J_{T}(z_t) \\} dt~,$\n\n    Where the time complexity of obtaining the exact Trace is $O(n^2)$ [1].\n\n    Instead of exact Trace computation, we further reduce the time complexity to $O(DH + D)$ using \\textit{Hutchinson\u2019s trace estimator} to obtain an estimate of the trace [1,2,3].\n\n    $Tr \\{ J_{T}(z_t) \\} = E_v [ v^T  J_{T}(z_t) v ]$\n\n    where $v$ is a random vector with zero mean and unit covariance. We draw binary values for $v$ from a Rademacher Distribution. Reducing the time complexity to $O(n)$ [2].\n\n    However the use of numerical ODE solvers introduces an additional cost as the transformation needs to be performed $L$ times, leading to an overall time complexity of $O(L(DH + D))$.  The impact of $L$ is significant in TIF, especially as the discontinuities of the derivative at the intervention points increase the number of steps taken by the numeric solver. Additionally, for the log likelihood sample, the model needs to be run forwards and backwards in time, i.e., $O(2L(DH + D))$. Finally, to obtain the Monte Carlo estimate (Appendix D), several samples are needed, which can, however, be computed in parallel.\n\n\nThank you once again for your valuable comments. We will incorporate the discussed topics into the updated version, scheduled for upload by Monday at the latest. We appreciate your engagement and are open to continuing this discussion with you.\n\n\n## References\n\n[1] Papamakarios, G., Nalisnick, E. T., Rezende, D. J., Mohamed, S. \\& Laksh minarayanan, B. (2021), \u2018Normalizing flows for probabilistic modeling and\ninference.\u2019, Journal of Machine Learning Research 22(57), 1\u201364.\nURL: https: // jmlr. org/ papers/ v22/ 19-1028. html\n\n[2] Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. Ffjord:\nFree-form continuous dynamics for scalable reversible generative models. In International\nConference on Learning Representations, ICLR 2019, 6-9 May, New Orleans, USA, Conference\nTrack Proceedings, 2019. URL https://openreview.net/forum?id=rJxgknCcK7.\n\n[3] Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural\nordinary differential equations. In Advances in Neural Information Processing Systems,\nNeurIPS 2018, 2-8 December, Montr\u00b4eal, Canada, volume 31. Curran Associates, Inc.,\n2018. URL https://proceedings.neurips.cc/paper_files/paper/2018/\nfile/69386f6bb1dfed68692a24c8686939b9-Paper.pdf"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7202/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700408687457,
                "cdate": 1700408687457,
                "tmdate": 1700408687457,
                "mdate": 1700408687457,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]