[
    {
        "title": "Counterfactual Fairness for Predictions using Generative Adversarial Networks"
    },
    {
        "review": {
            "id": "jOusL1ACsA",
            "forum": "b7bilXYHgG",
            "replyto": "b7bilXYHgG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5631/Reviewer_Bc4s"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5631/Reviewer_Bc4s"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a method that learns predictor under counterfactual fairness. It first learns the counterfactual distribution of mediator (variables that are causally affected by sensitive attribute), based on which establish counterfactual mediator regularizer. Finally, the predictor is trained by enforcing such a regularizer. The paper conducts experiments to validates the proposed method on three datasets (sythentic, Adult, COMPAS)."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Learning counterfactual fair predictors is an important problem. Unlike existing methods that learn counterfactual samples, the paper learns counterfactual distributions which are novel to my knowledge.\n2. The paper is in general well-written and organized."
                },
                "weaknesses": {
                    "value": "1. The paper focuses on binary-sensitive attributes. It is unclear whether the proposed method is applicable to settings where sensitive attribute has multiple categories. Specifically, for each $a$ sensitive attribute may take, do we need a GAN to learn the corresponding counterfactual distribution? Or do we only need a single GAN to learn \u201caveraged counterfactual distribution?\u201d \n2. While the paper establishes an upper bound on the violation of fairness, the bound seems to be very trivial. The strength of fairness is controlled empirically by hyper-parameter $\\lambda$.    \n3. The paper claims that existing works that rely on inferring latent variables may hurt prediction performance by introducing bias, and it argues the proposed method can mitigate such an issue. However, learning counterfactual distribution is often more challenging than generating counterfactual samples, and it can also be hard to stabilize the training of GAN. Although the paper empirically shows on synthetic data that the proposed method can attain a better utility-fairness trade-off than baselines, it is unclear how it performs in more complicated settings."
                },
                "questions": {
                    "value": "1. Because only factual mediators are observable, how can the generator ensure the generated counterfactual mediators are accurate? To my understanding, the generator\u2019s accuracy is ensured via construction loss between generated factual mediators and actual factual mediators. Can it imply the accuracy of counterfactual mediators?\n2. How can the method be generalized to settings with more than 2 social groups?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5631/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698070125071,
            "cdate": 1698070125071,
            "tmdate": 1699636583948,
            "mdate": 1699636583948,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SYht6T6T5L",
                "forum": "b7bilXYHgG",
                "replyto": "jOusL1ACsA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Bc4s"
                    },
                    "comment": {
                        "value": "We greatly appreciate your insightful feedback! We are thankful that you find our method important and novel. \n\n### Responses to \"Weaknesses\"\n\n **1. Applicability beyond binary sensitive attributes**\n\nThank you. Our method can **easily extended to scenarios where the sensitive attribute has multiple categories**. (We only opted for the binary case for ease of readability.) To this end, we improved our paper in the following ways: \n\n* We added a **new description of how our method can be applied to a sensitive attribute with multiple categories** (see our **new Appendix G**). Importantly, we do **not** need several GANs for each category $a$. Instead, we show how a single GAN is sufficient. The reason for that is that we can learn the joint distribution for all counterfactuals. \n* We added a **mathematical proof** that a single GAN can effectively learn the joint distribution for all counterfactuals (see our **new Corollary 1**). \n* We added **new experiments** to show that our method is also effective in settings with multiple categories (see our **new Appendix G.4**).   \n\n\n**2. New theoretical guarantees beyond Lemma 1**\n\nThank you. We have greatly reworked our theoretical analysis: \n* We added a **new Lemma 2** with **theoretical guarantees** to show that our generator provides **consistent estimates** of the counterfactual distribution of mediators. This ensures that we learn the **correct** counterfactuals. Together with Lemma 1, this ensures mathematically that we achieve counterfactual fairness. \n\n* Importantly, the proof of our new Lemma 2 is **non-trivial**. We kindly refer to our **extensive proof in Supplement D.2**, where we leverage ideas from [1,2] that were published only recently at NeurIPS 2023. \n\n* The hyperparameter $\\lambda$ controls the strength of counterfactual fairness. Hence, by $\\lambda$->$\\infty$, we ensure that the predictions adhere to counterfactual fairness more strictly. One may think that one could make the hyperparameter $\\lambda$ similarly arbitrarily large to ensure counterfactual fairness. However, this would undermine the accuracy of the predictions. Rather, $\\lambda$ is a hyperparameter that is used to trade-off counterfactual fairness vs. accuracy. \n\n* To the best of our knowledge, ours is the **first** neural method that offers theoretical guarantees that the method is effective in learning counterfactual fairness. In fact, many baselines (e.g., [CFGAN]) have even been shown to learn incorrect objectives that act as heuristics but fail to recover counterfactual fairness. To the best of our knowledge, our method is the first neural approach that ensures to correctly learn counterfactual fairness predictions with theoretical guarantees.\n\nReferences:\n\n[1] Arash Nasr-Esfahany, Mohammad Alizadeh, and Devavrat Shah. Counterfactual identifiability of bijective causal models. In ICML, 2023\n\n[2] Valentyn Melnychuk, Dennis Frauen, and Stefan Feuerriegel. Partial counterfactual identification of continuous outcomes with a curvature sensitivity model. In NeurIPS, 2023."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700440271605,
                "cdate": 1700440271605,
                "tmdate": 1700440486656,
                "mdate": 1700440486656,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DUuK6R2c3Q",
                "forum": "b7bilXYHgG",
                "replyto": "jOusL1ACsA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Bc4s"
                    },
                    "comment": {
                        "value": "### Responses to \"Weaknesses\"\n\n**3. Methods inferring latent variables may hurt prediction performance by introducing bias**  \n\nThank you for giving us the opportunity to clarify the benefits of our methods over the baselines. Below, we first explain why even the baseline methods with latent variables are fairly tricky, and we then discuss why our GAN-based approach is superior. \n\n*Why is the use of baseline methods based on latent variables tricky?*\n\nImportantly, even the baselines for counterfactual fairness are far from being easy as they do not rely on off-the-shelf methods. Rather, they also learn a latent variable in non-trivial ways. More specifically, the inferred latent variable $U$ should be independent of sensitive attribute $A$ while representing all other useful information from the observation data. However, there are two main challenges: (1) The latent variable $U$ is **not** identifiable. (2) It is very hard to learn such $U$ to satisfy the above independence requirement, especially for high-dimensional or other more complicated settings. Hence, we argue that baselines based on some custom latent variables are highly challenging. \n\nBecause of (1) and (2), there are **no** theoretical guarantees for the VAE-based methods. Hence, it is mathematically **unclear** whether they actually learn the correct counterfactual fair predictions. In fact, there is even rich empirical evidence that VAE-based methods are often **suboptimal**. VAE-based methods use the estimated variable $U$ in the first step to learn the counterfactual outcome $\\mathbb{P}\\left(\\hat{Y}_{ a'}(\\mathbf{U}) \\mid X=x, A=a, M=m \\right).$ The inferred, non-identifiable latent variable can be correlated with the sensitive attribute which may harm fairness, or it might not fully represent the rest of the information from data and harm prediction performance.  \n\nHow our method overcomes the above challenges: We address the above challenges by learning the counterfactuals directly. Thus, our method eliminates the need for a two-step process that learns $U$. To this end, we avoid the complexities and potential inaccuracies of inferring and then using latent variables. More formally, we generate counterfactual samples from the learned counterfactual distribution. For each specific input data $(X=x, A=a,M=m)$, we then generate the counterfactual mediator from the distribution $\\mathbb{P}(M_{a'} \\mid X=x, A=a, M=m)$. This results in overall more accurate and robust predictions. \n\nMore importantly, our **new Lemma 2** even provides **theoretical guarantees** that we learn the correct counterfactual mediators and, therefore, ensure counterfactual fair predictions. To the best of our knowledge, none of the baselines based on latent variables have such guarantees. \n\nAs for GAN training, we followed best practices to ensure stability. For example, we employed common techniques for GAN training such as batch normalization, label smoothing, etc. On top of that, counterfactual mediators are commonly low-dimensional in practice. Recall that only a subset of all variables are outputs of our GAN (i.e., the mediators but not the covariates, not the treatment, and not the target variable). This is a crucial difference from many other applications of GANs where the outputs are high-dimensional data such as images and videos. This is one reason why we find our GAN framework to perform well throughout all of our experiments."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700440438679,
                "cdate": 1700440438679,
                "tmdate": 1700612043640,
                "mdate": 1700612043640,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "7JXTkVYraP",
                "forum": "b7bilXYHgG",
                "replyto": "jOusL1ACsA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Bc4s"
                    },
                    "comment": {
                        "value": "### Responses to \"Questions\":\n\n**1. Correctness of counterfactual mediators** \n\nThank you for raising this important question. You are right in pointing out that, during training, we cannot directly learn the counterfactual mediators in a supervised way as they are unobservable. Instead, we can only leverage the reconstruction loss on the factual mediators. The reason why we can still learn the correct counterfactual mediators is due to the adversarial training process of the generator. By training the discriminator to differentiate between factual and generated counterfactual mediators, the generator is guided to learn the correct counterfactual distribution.\n\nMotivated by your question, we now added a **new Lemma 2** where we **show theoretically that we learn the correct counterfactual mediators**. Specifically, our new Lemma 2 offers a theoretical guarantee that our generator consistently estimates the counterfactual distribution of the mediator. This first provides a theoretical justification behind the design of our generator for the counterfactual mediators. On top of that, Lemma 2 addresses your question by establishing convergence to the correct counterfactual distribution (point mass distribution).\n\n**2. Generalization to multiple social groups** \n\nThank you. Our method can **easily extended to scenarios with multiple social groups.** To demonstrate this, we improved our paper in the following ways: \n\n* We added a description of **how our method can be applied to a sensitive attribute with multiple categories** (see our **new Appendix G**). Importantly, we do not need several GANs for each category $a$. Instead, we show how a single GAN is sufficient. The reason for that is that we can learn the joint distribution for all counterfactuals.  \n\n* We **added mathematical proof** of how a single GAN learns the joint distribution for all counterfactuals (see our **new Corollary 1**). \n\n* We added **new experiments** to show that our method is also effective in settings with multiple categories (see our new Appendix G4).\n\nWe also updated the codes in our anonymous GitHub repository accordingly."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700440730164,
                "cdate": 1700440730164,
                "tmdate": 1700440730164,
                "mdate": 1700440730164,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "9J2tRfzP7Q",
            "forum": "b7bilXYHgG",
            "replyto": "b7bilXYHgG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
            ],
            "content": {
                "summary": {
                    "value": "The paper \"Counterfactual Fairness for Predictions using Generative Adversarial Networks\" tackles one of the most challenging definition of fairness from the fair ML community, the counterfactual fairness, which is also probably the most conceptually appealing if effective. The goal is to insure for any individual that the outcome would be the same if the individual has a different value of a sentifive attribute (e.g., gender). As many attributes of the individual can be influenced by the sensitive, it implies to build a mechanism to imagine how the individual would look like for the other - counterfactual - sensitive value. Authors of the paper propose to build on a GAN architecture, which has already been employed for that purpose, but in a different way where the approach was to generate causal and interventional data, from which counterfactual fairness could be achieved. The proposed approach is more simple, proposing to generating a counterfactual representation of individual more directly, with a specific min max objective."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "Clarity : I feel the paper very well-written and structured (maybe some introductional discussion and examples  could be given to help a uneducated reader with challenges with counterfactual fairness), very easy to read from the clear definitions of every component. It is nice to read such a self-contained paper, many papers I had to review recently had a lot of ill-defined notations, I was happy to read this one. \n\nThe tackled setting is also very appealing and challenging. \n\nThe method looks to achieve interesting results."
                },
                "weaknesses": {
                    "value": "I have some concerns about soundness of the approach, positioning and the experiments. see questions below."
                },
                "questions": {
                    "value": "Positioning w.r.t. state of the Art\n\n1. Related work say that VAE based methods fail because they capture correlations between the sensitive and the latent representation. Authors should at least mention that most cited approaches (e.g. Grari et al.2023) have regularizers that seek at removing these correlations. I cannot see why the proposed approach would be really better on that point, as I feel the discriminator makes some similar job as, for instance, VAE with adversarial loss that seek at reducing mutual information between the latent and the sensitive of these approaches. \n\n2. One mentioned limitation of VAE is \"It is commonly assumed that the prior distribution of latent variables follows a standard Gaussian in VAEs\", that would hinder the prediction ability. While I agree that VAE is more constrained than GAN since there is a need for choosing a distribution family that strongly affects the results if is does not well fit the data, this problem is about the decoding distribution, not the encoding one, as having a latent space structured using a gaussian is something usually desirable. Note that GAN also use a  sampling from a standard gaussian in the latent space... What do you think ?   \n\n3. CFGAN: In appendix B3, authors point out than one of the main difference with CFGAN is that this approach only achieves interventional fairness, not counterfactual. From my point of view this is not true since, as explained in their section 3.5 counterfactual samples are generated by 1) generating samples from the causal model  2) selecting the z that led to the generation of a given class of the sensitive and finally 3) generate a new sample for each selected z, by interventioning on the sensitive, to get a counterfactual sample for each of them. Thus, a predictor can be learned on that data, with a regularization that ensures that both versions of individual lead to similar outputs. It is countefactual fairness as every varariables depending on the sensitive can be impacted. That is not only P(Y|X,do(A=a))=P(Y|X,do(A=a') since X and Y are regenerated after intervention (using the same z in factual and interventional world allows to follow the counterfactual fairness objective that is mentioned in the paper).          \n\nSoundness of the objectives\n\n1. Authors consider a causal graph where X->A, but suggest in fig1 that there can exist some correlations between X and A, implying some cofounder that causes both. If there are in the data distribution for instance more old women than old men, and assuming Y is lower for women than for men, then I suspect that the regularization term in (7) cannot have any strong impact on that bias. X remains the same for factual and counterfactual, only M changes, which can be ignored by h if most of the information for outputting Y is in X. Please discuss that remark. \n\n2. I am surprised to see that the proposed adversarial objective is greatly asymmetric, as it never considers counterfactuals produced for individuals from the A=1 class. The adversarial loss is indeed weighted by A for the factual part and 1-A for the counterfactual one (which is 0 in the case A=1). Denoting as M_{i,j} the output of the generator for an individual from class i and intervention using j as the sensitive value, we M_1,1 steered toward M from Lf and far from M from Ladv; M_0,1   steered toward M from Ladv; M_1,0   steered toward M from Lf; and M_1,0 is totally free... Isn't it a problem ? I suspect that it can report most of the fairness effort on the A=0 class. Also, I am not sure if this does correspond to a well-defined optimization problem since there may exist many equivalent optima, no ? having M_1,1 = M   looks very likely at the end of the optimization (with G  outputting a very different value for M_1,0 which is unconstrained).  \n\n\nExperiments\n\n1. Comparative experiments are performed on semi-synthetic datasets, where we can get both factual and counterfactual versions of the data. However, I feel that the generative process that are considered are too easy to fully analyze, as 1) there is not correlation between X and A (which can be unfair regarding the previous remarks above) and 2) M is deterministically deduced from X and A, which appears as a really easy setting : First,  authors show in table 1 that counterfactual M can be generated accurately from their generator. However, this is not fully convincing (and does not reassure me about the asymmetry issue mentioned above), as it is easy to fully understand the relation between (X,A) and M only from samples from the 0 class (A=0). M_A' is well generated for the class A=1 thanks to this, but I am really not sure that is would applied in more difficult settings. Second, for such a setting we could design a very simpler approach that learn h(X,A) to be close to Y while limiting the distance between h(X,A) and h(X,A'), which would be at least as effective. \n\n2. Comparison with competitors only performed on semi-synthetic- not fully convincing - datasets. I know that countefactual fairness is difficult to fully evaluate, but wouldn't it be possible to conduct some analysis on the results of some competitors also, to see if there is impact of the improvements observed on synthetic data ? \n\n3. To be fully self-contained and reproducible, as every competitor has many variants inside their paper, with sometimes non trivial application for the considered setting, it would be nice to have in appendix the pseudo-code of each of the considered approach, at least ADVAE and CFGAN.      \n\nMinor : the \",\" should be replaced by a \"-\" in every regularization (7) or metric (9) formulations."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "The paper is about removing biases."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5631/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5631/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5631/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698403574335,
            "cdate": 1698403574335,
            "tmdate": 1700578620148,
            "mdate": 1700578620148,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "5Kfk55SkmR",
                "forum": "b7bilXYHgG",
                "replyto": "9J2tRfzP7Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RxKF"
                    },
                    "comment": {
                        "value": "We appreciate the positive feedback on our paper as well as the suggestions for further improvement! As you will see below, we took your feedback at heart and have carefully and thoroughly revised our paper to incorporate your comments.\n\nIn addition to comments, we have also added a **new theoretical analysis**. Specifically, we added a **new Lemma 2** to show that our method correctly identifies the counterfactual mediators. Specifically, we prove that our method allows for **consistent estimation of the counterfactual distribution**. The lemma thus gives a guarantee on the correctness of the generated counterfactual mediators and, therefore, also a guarantee on the upper bound in Lemma 1.\n\nOur new theoretical analysis is important for two reasons. First, it provides a **theoretical justification behind the design of our method**. Second, it ensures that we correctly learn counterfactual fairness. To the best of our knowledge, ours is the **first** neural method that offers such guarantees.  Note that the VAE-based baselines do **not** have similar theoretical support, which provides an additional theoretical explanation why our method is effective and even superior. \n\n### Responses to \"Positioning w.r.t. state of the Art\":\n\n* Questions related to the baselines\n\n**1. Addressing concerns about the VAE-based methods**\n\nThank you. We followed your suggestion and added the reference to VAE-based methods with regularization (e.g. Grari et al.2023) that seek to remove correlations. However, we would still clarify why VAE-based methods for our task can be problematic and why our proposed method is superior \u2013 both theoretically and numerically. \n\n*Why are VAE-based methods not optimal? *VAE-based methods learn a latent variable in non-trivial ways. More specifically, the inferred latent variable $U$ should be independent of sensitive attribute $A$ while representing all other useful information from the observation data. However, there are two main challenges: (1) The latent variable $U$ is not identifiable. (2) it is very **hard** to learn such $U$ to satisfy the above independence requirement, especially for high-dimensional or other more complicated settings. As a result, VAE-based methods act as heuristics, and, hence, there is no theoretical guarantee that VAE-based methods are actually effective. That means, there is **no theoretical guarantee** on the fairness level in the final prediction.\n\nBecause of (1) and (2), there are **no** theoretical guarantees for the VAE-based methods. Hence, it is mathematically **unclear** whether they actually learn the correct counterfactual fair predictions. In fact, there is even rich empirical evidence that VAE-based methods are often **suboptimal**. VAE-based methods use the estimated variable $U$ in the first step to learn the counterfactual outcome $\\mathbb{P}\\left(\\hat{Y}_{ a'}(\\mathbf{U}) \\mid X=x, A=a, M=m \\right).$ The inferred, non-identifiable latent variable can be correlated with the sensitive attribute which may harm fairness, or it might not fully represent the rest of the information from data and harm prediction performance.  \n\nHow our method overcomes the above challenges: We address the above challenges by learning the counterfactuals directly. Thus, our method eliminates the need for a two-step process that learns $U$ but, instead, we learn $U$ directly in a single step through our GAN. To this end, we avoid the complexities and potential inaccuracies of inferring and then using latent variables. More formally, we generate counterfactual samples from the learned counterfactual distribution. For each specific input data $(X=x, A=a,M=m)$, we then generate the counterfactual mediator from the distribution $\\mathbb{P}(M_{a'} \\mid X=x, A=a, M=m)$. This results in overall more accurate and robust predictions. Further, our **new Lemma 2** even shows that we correctly learn the counterfactual mediators and, unlike VAE-based methods, **we thereby prove that our method is effective in achieving counterfactual fairness.**"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700441196106,
                "cdate": 1700441196106,
                "tmdate": 1700441273587,
                "mdate": 1700441273587,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "a5dWHCqg5B",
                "forum": "b7bilXYHgG",
                "replyto": "9J2tRfzP7Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RxKF"
                    },
                    "comment": {
                        "value": "### Responses to \"Positioning w.r.t. state of the Art\":\n\n* Questions related to the baselines\n\n **2. Addressing concerns about the VAE-based methods**: \n\nThank you. Although a standard Gaussian is a common choice for the prior in VAEs, recent research, such as [2,3], has highlighted that this choice can be **suboptimal**. The standard Gaussian prior can lead to over-regularization, contributing to poorer density estimation performance. This issue is often referred to as the posterior-collapse phenomenon, as discussed by [4].\n\nRegarding GANs, it is true that they often utilize sampling from a standard Gaussian in the latent space. However, this is not a strict requirement. Various studies have demonstrated effective GAN models that operate without sampling from a Gaussian distribution [5]. Our method diverges from the standard practice as well; in our GAN model, we do not rely on sampling from a standard Gaussian. Instead, we focus on generating counterfactuals based on the learned counterfactual distribution. Thus, our method is more robust by directly learning the transformation.\n\nMotivated by your question, we **added a new Lemma 2**, which provides **theoretical justification for our method**. Therein, we prove that our method allows for **consistent estimation of the counterfactual distribution**. This is important for two reasons. First, it provides a theoretical justification behind the design of our GAN method. Second, it ensures that we correctly learn counterfactual fairness. To the best of our knowledge, ours is the **first** neural method for counterfactual fairness that offers such guarantees. Importantly, this is a major difference to the VAE-based baselines, which do **not** have similar guarantees.\n\n\nReferences:\n\n[1] Depeng Xu, Yongkai Wu, Shuhan Yuan, Lu Zhang, and Xintao Wu. Achieving causal fairness through generative adversarial networks. In IJCAI, 2019.\n\n[2] Takahashi, Hiroshi and Iwata, Tomoharu and Yamanaka, Yuki and Yamada, Masanori and Yagi, Satoshi. \"Variational autoencoder with implicit optimal priors.\" In AAAI, 2019.\n\n[3] Hoffman, Matthew D., and Johnson, Matthew J. ELBO surgery: yet another way to carve up the variational evidence lower bound. In Workshop in Advances in Approximate Bayesian Inference,  NeurIPS. 2016.\n\n[4] Aaron van den Oord, Oriol Vinyals, koray kavukcuoglu. Neural Discrete Representation Learning. In  In NeurIPS.2017\n\n[5] Ledig C, Theis L, Husz\u00e1r F, et al. Photo-realistic single image super-resolution using a generative adversarial network. Proceedings of the IEEE conference on computer vision and pattern recognition. 2017"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700441765956,
                "cdate": 1700441765956,
                "tmdate": 1700441765956,
                "mdate": 1700441765956,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yEUcJOOh4r",
                "forum": "b7bilXYHgG",
                "replyto": "9J2tRfzP7Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RxKF"
                    },
                    "comment": {
                        "value": "### Responses to \"Positioning w.r.t. state of the Art\":\n\n\n**3. Addressing concerns about the CFGAN [1]**:\n\nThank you. In response to the query regarding CFGAN and its relation to interventional versus counterfactual fairness, we would like to direct the reviewer's attention to the paper [6]. Therein, the authors show that CFGAN actually satisfies the definition of Discrimination avoiding through causal reasoning. This means: a generator is said to be fair if the following equation holds  $P(Y=y \\mid X=x, d o(A=a))=P\\left(Y=y \\mid X=x, d o\\left(A=a^{\\prime}\\right)\\right)$. This is **different from counterfactual fairness**. In counterfactual fairness, a generator producing samples $(X, A, Y)$ with distribution $P$ is said to be counterfactually fair if: $P\\left(Y_{a}=y \\mid X=x, A=a\\right)=P\\left(Y_{a\u2019 }=y \\mid X=x, A=a\\right),$ for all $y \\in \\mathcal{Y}, x \\in \\mathcal{X}, a, a\u2019 \\in \\mathcal{A}$. As such, CFGAN actually considers **interventional queries** (=**level 2** in Pearl\u2019s causality ladder), while counterfactual fairness involves **counterfactual queries** (=**level 3** in Pearl\u2019s causality ladder).\n\nFor details of the above, we kindly refer to paper [6], which provides a comprehensive explanation of the actual distribution CFGAN learns and the distinction between counterfactual fairness, along with detailed proofs. \n\nReassuringly, we remind that CFGAN is **vastly different from our method** (see our discussion in **Appendix B.2**). (1) Different tasks:  CFGAN is designed for fair data generation tasks, while our model is designed for learning predictors to be counterfactual fairness. Hence, both address **different tasks**. (2) Different architectures: CFGAN employs two generators, while our method has a single generator and discriminator. Further, fairness enters both architectures at **different** places. In CFGAN, fairness is ensured through the GAN setup, whereas our method ensures fairness in a second step through our counterfactual mediator regularization. (3) Different training objectives: The training objectives are **different**: CFGAN learns to mimic factual data. In our method, the generator learns the counterfactual distribution of the mediator through the discriminator distinguishing factual from counterfactual mediators. (4) No theoretical guarantee for CFGAN: Unlike our method, CFGAN does not have theoretical guarantees to correctly learn counterfactual fair predictions. **Only our method** offers theoretical guarantees for the task at hand. In sum, even though CFGAN also employs GANs, it is vastly different from our method.\n\n\nReference:\n\n[6] Mahed Abroshan, Mohammad Mahdi Khalili, and Andrew Elliott. Counterfactual fairness in synthetic data generation. In Neurips 2022 SyntheticData4ML Research, 2022."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700441859431,
                "cdate": 1700441859431,
                "tmdate": 1700441859431,
                "mdate": 1700441859431,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3AC6qIFGnD",
                "forum": "b7bilXYHgG",
                "replyto": "9J2tRfzP7Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RxKF"
                    },
                    "comment": {
                        "value": "### Responses \u201cSoundness of the objectives\u201d\n\n**1.Addressing concern about the spurious effect**\n\nThank you for asking questions about the potential spurious effects in the correlation between $X$ and $A$, which can have an impact on $Y$ We welcome the opportunity to provide a clarification. It is true that if $X$ and $A$ are correlated, there would occur a spurious effect ($A$->$X$->$Y$) in our causal graph. However, note that the counterfactual fairness notion [8] only addresses direct effect ($A$->$Y$) and indirect effect ($A$->$M$->$Y$), but does not include the spurious effect ($A$->$X$->$Y$). This is because the spurious effect ($A$->$X$->$Y$) does not influence the counterfactual fairness in the prediction. \n\nWe kindly refer to paper [9], which provides an in-depth and detailed discussion of the difference between various fairness notions and causal effects. Figure 4.5 in paper [9] explains clearly that counterfactual fairness is the unit-level fairness notion and, thus, does not include spurious effects. This makes counterfactual fairness different from other fairness notions (such as causal fairness). \nTo illustrate the above, let us draw upon your example. In the given scenario, $X$ represents age, and $A$ represents gender. We further assume that there is correlation between them ( typically, women are older than men). A company aiming for gender fairness, thus chooses not to use gender directly in its hiring decisions. Since age is not a sensitive attribute, they use age for making decisions, preferring younger candidates. This method, although seemingly unbiased w.r.t gender, inadvertently leads to a higher number of male employees than female employees due to the correlation between age and gender. This example points to the reviewer's concern: such correlations do indeed influence outcomes at the population level, creating an average effect.\n\nHowever, from the perspective of counterfactual fairness, the focus is on the individual level. For each person, it examines the situation where altering an individual's gender (e.g., from male to female) wouldn't change the employment outcome of this person. Thus, even though a correlation between age and gender exists, it does not affect each individual's final employment decision. \nTherefore, having correlations between $X$ and $A$ does not affect the counterfactual level in our prediction in Y, which is consistent with our setting. \n\n\n**2.Addressing concerns about the adversarial loss**\n\nThank you. We would like to clarify that our adversarial objective is indeed **symmetric**, addressing counterfactual scenarios for both $A=1$ and $A=0$ classes. There is no preference for the class and the loss formula is correct. Since the sum of the discriminator output is 1 (i.e., a sum of the probability), we merge the two items in the original version of the loss equation into one (see our updated Eq. 6 for the loss). If you view $A$ as the true label, it is exactly how cross-entropy loss is computed. The counterfactual output of the generator is always fed into the discriminator. The generator of the GAN then minimizes the conditional propensity-weighted Jensen\u2013Shannon divergence (JSD). \nTo show the above more explicitly, we also added a new Lemma 2 and a corresponding proof. We kindly refer the reviewer to our proof, which should make the above more clear.  (see Eq. (31) in Appendix D.2).\n\nReferences:\n\n[9] Drago Plecko and Elias Bareinboim. Causal fairness analysis. In arXiv preprint, 2022."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700442096828,
                "cdate": 1700442096828,
                "tmdate": 1700442241807,
                "mdate": 1700442241807,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "w6QbYXORLT",
                "forum": "b7bilXYHgG",
                "replyto": "9J2tRfzP7Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer RxKF"
                    },
                    "comment": {
                        "value": "### Responses to \u201cexperiments\u201d\n\nThank you. We followed your suggestions and included several new experiments (see **new Appendix X.1 and X.2**).\n\n**1**.\n*(a). Correlation Between $X$ and $A$:*\n\nWe added a new experiment where we included correlation between $X$ and $A$. The experiment results show again that we achieved the best performance (see our **new Appendix H.1**). Importantly, these results confirm that introducing a correlation between $X$ and $A$ does not adversely affect the counterfactual level of our predictions for $Y$. This finding aligns with our above response to the initial concern on spurious effects, showing that having correlation between X and A does not affect the counterfactual fairness level in our prediction in Y. \n\n*(b). Generation of M from X and A*:\n\nThank you for asking the questions. We would like to clarify that $M$ is **not** deterministically deduced from $X$ and $A$. In our dataset, the generation of $M$ incorporates stochastic elements, specifically through the inclusion of noise $U_M$, which makes the process non-deterministic. We have thus revised our paper to spell out explicitly that the generation of $M$ is non-deterministically. \nIn response to your query regarding the evaluation of counterfactual fairness: This limitation is widely recognized in the field, and as a result, the use of synthetic or semi-synthetic datasets for such evaluations is a well-established norm, as is the quasi-standard in the literature [7,8,10]. \n\nRegarding the simplicity of the setting: our setting is intentionally designed **analogous to prior research** [8, 10] and especially [7]. Therein, the setting for modeling fairness violations is similar to ours, so that we allow for better comparability. \nLastly, it is crucial to note that our prediction model **does** not explicitly utilize the sensitive attribute. The inputs for our predictor $h$ are $X$ and $M$. This is done to adhere to ethical guidelines in practice and to reduce the risk of biased outcomes. We have revised our paper to spell out clearly that **we follow your comment and do not use the sensitive attribute in our predictor**. \n\n**2**.  We followed your suggestion and **added new performance comparisons** for our real-world dataset (see our **new Appendix H.2**). Due to the unavailability of counterfactuals for real-world data, we use our generated counterfactual as the ground-truth counterfactual and show the utility function value as on synthetic datasets. As a result, we find that our proposed method is highly effective. \n\n**3**. Thank you. We paid great attention to make our work self-contained and reproducible. Wherever possible, we used the original source codes from the authors for fair comparison (and we contacted all authors whenever the code was not public in the first place). To address your comment, we have improved our papers as follows: \nWe extended our implementation details and now state clearly where the baseline codes are from (see our revised **Appendix F.1**). \nWe have also added detailed descriptions including pseudocode for ADVAE and CFGAN (see our new materials in **Appendix I**).\nWe have made both our code and all datasets publicly available (see the GitHub link in our paper). Thereby, we ensure that all experiments reported in our study are indeed self-contained and reproducible. \n\nReference:\n\n[7] Ioana Bica, James Jordon, and Mihaela van der Schaar. Estimating the effects of continuous-valued interventions using generative adversarial networks. In NeurIPS, 2020.\n\n[8] Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. Counterfactual fairness. In NeurIPS, 2017.\n\n[10] Francesco Quinzan, Cecilia Casolo, Krikamol Muandet, Niki Kilbertus, and Yucen Luo. Learning counterfactually invariant predictors. In arXiv preprint, 2022."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700442654543,
                "cdate": 1700442654543,
                "tmdate": 1700477474489,
                "mdate": 1700477474489,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mWUjXTzMZv",
                "forum": "b7bilXYHgG",
                "replyto": "9J2tRfzP7Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "disagree on cfgan interpretation"
                    },
                    "comment": {
                        "value": "Thanks for this reference but I stil think that CFGAN proposes a way to achieve counterfactual fairness, not only interventional one, as they produce both versions of the individuals, with modified Y and X according to the sensitive attribute (using same Z as seed of the generation). From this it is possible to learn a predictor that achieves comparable outcomes for both versions..."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700556321349,
                "cdate": 1700556321349,
                "tmdate": 1700556349245,
                "mdate": 1700556349245,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "xFOzsTwaHQ",
                "forum": "b7bilXYHgG",
                "replyto": "5Kfk55SkmR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "Cannot see why U in VAE would not be identifiable, while the mediator in the proposed approach would"
                    },
                    "comment": {
                        "value": "I cannot see why U in VAE would not be identifiable, while the mediator in the proposed approach would. You still need to learn a counterfactuel distribution, which looks to me at least as hard as inferring U decorrelated from A and the generate counterfactuals from this...."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700556572201,
                "cdate": 1700556572201,
                "tmdate": 1700556572201,
                "mdate": 1700556572201,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Ggx3hX6oES",
                "forum": "b7bilXYHgG",
                "replyto": "3AC6qIFGnD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "1.Addressing concern about the spurious effect"
                    },
                    "comment": {
                        "value": "ok my example was maybe bad. \nThanks for this answer"
                    }
                },
                "number": 20,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700577656178,
                "cdate": 1700577656178,
                "tmdate": 1700577656178,
                "mdate": 1700577656178,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "n6eBwbAn0H",
                "forum": "b7bilXYHgG",
                "replyto": "3AC6qIFGnD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "2.Addressing concerns about the adversarial loss"
                    },
                    "comment": {
                        "value": "Thanks, but from my point of view the current presentation (which is very different from the former one) is even worse: nothing considers counterfactuals in that new formulation  of (6), I suspect there is a mistake like a A in place of a A' ?"
                    }
                },
                "number": 21,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700578473113,
                "cdate": 1700578473113,
                "tmdate": 1700578473113,
                "mdate": 1700578473113,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Z6y6JJ63IT",
                "forum": "b7bilXYHgG",
                "replyto": "w6QbYXORLT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "thanks for new experiments"
                    },
                    "comment": {
                        "value": "thanks for new experiments that look very useful to me. \n\nI slightly increased my score consequently, but still have some concerns with the paper (see my other comments)."
                    }
                },
                "number": 22,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700578597821,
                "cdate": 1700578597821,
                "tmdate": 1700578597821,
                "mdate": 1700578597821,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mK2pVW93fD",
                "forum": "b7bilXYHgG",
                "replyto": "9J2tRfzP7Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Addressing concern on \"identifiable for VAE-based method\u201d (Response to Reviewer RxKF)"
                    },
                    "comment": {
                        "value": "### Addressing concern on \u201cidentifiable for VAE-based method\u201d:\n\nWe break down the reviewer's questions and answer it point by point below:\n\n**1. What does identification mean**: \n\nFirst, \u201cidentification\u201d does **not** mean \u201cestimation\u201c. In causal inference, you can think about identifiability as the mathematical condition that permits a causal quantity to be measured from observed data. We kindly refer to papers [2][3] which all discuss clearly what identification means in causality. Importantly, identification is different from estimaton because methods that act as heuristics may return estimates but they do not correspond to the true value. (see paper [1] where the authors provide several concerns that, if it is not unique, it is possible to have local minima, which leads to unsafe results. \n\n**2. Non-identifiable for VAE based methods have been shown in prior works of literature**: \n\nWe kindly refer the reviewer to this paper [7] [Neural Causal Models for Counterfactual Identification and Estimation] \u201d In this paper, the authors show that VAE-based counterfactual inference do not allow for identifiability. The results directly apply to variational inference-based methods they listed (VACA Sanchez-Martin et al. (2021), DeepSCM Pawlowski et al. (2020)), which do not have proper identification guarantees. Also, the result from non-linear ICA (which is the task of variational autoencoders) shows that the latent variables are non-identifiable [6]. In simple words, VAE-based methods **can estimate the latent variable but it is not guaranteed that it can be correctly identified**, leading to risks that the latent variable is often estimated incorrectly. \n\n **3. Non-identifiability of the latent variables means non-identifiability of the counterfactual queries:**\n\nWe kindly refer to paper [4] (Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model. ) which says that the **non-identifiability of the latent variables means non-identifiability of the counterfactual queries**. Hence, VAE-based methods can **not** ensure that they correctly learn counterfactual fairness, **only our method does so**. \n\n **4. Regarding our method**\n\nWe diverge from the above practices. Instead, we focus on generating counterfactuals based on the learned counterfactual distribution. Thus, our method is more robust by directly learning the transformation. More importantly, we provide theoretical guarantees in our paper that we correctly learn counterfactual fairness (see **Lemma 1** and **Lemma2**)\n\n* How our method overcomes the above challenges: \n\nWe address the above challenges by learning the counterfactuals directly. Thus, our method eliminates the need for a two-step process that learns $U$. To this end, we avoid the complexities and potential inaccuracies of inferring and then using latent variables. More formally, we generate counterfactual samples from the learned counterfactual distribution. For each specific input data $(X=x, A=a,M=m)$, we then generate the counterfactual mediator from the distribution $\\mathbb{P}(M_{a'} \\mid X=x, A=a, M=m)$. This results in overall more accurate and robust predictions. Further, our **new Lemma 2** even shows that we correctly learn the counterfactual mediators and, unlike VAE-based methods, **we thereby prove that our method is effective in achieving counterfactual fairness.**\n\n**Action (in blue font):** We added a clarification to our paper to distinguish identifiability vs. estimatability (see our revised **Section 2** and **Appendix B.1**). We further spell out clearly that one weakness of the VAE-based methods is that they are non-identifiability, while our method allows for identifiability.\n\n\nWe are again thankful for your question. We hope that our answer helped in addressing your questions satisfactorily. Please let us know if there are further things in our presentation that should be improved.  \n\nReference: \n\n[1] D\u2019Amour A. On Multi-Cause Causal Inference with Unobserved Confounding: Counterexamples[J]. Impossibility, and Alternatives, 2019.\n\n[2] Pearl, Judea. Causal inference in statistics: An overview. 2009\n\n[3]Peters, Jonas, Dominik Janzing, and Bernhard Sch\u00f6lkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017.\n\n[4]Melnychuk, Valentyn, Dennis Frauen, and Stefan Feuerriegel. Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model.  Neurips 2023.\n\n[5]De Brouwer, Edward. \"Deep Counterfactual Estimation with Categorical Background Variables.\" Neurips. 2022.\n\n[6]Khemakhem I, Kingma D, Monti R, et al. Variational autoencoders and nonlinear ica: A unifying framework. International Conference on Artificial Intelligence and Statistics. 2020.\n\n[7]Xia, Kevin, Yushu Pan, and Elias Bareinboim. \"Neural causal models for counterfactual identification and estimation.\" arXiv 2022."
                    }
                },
                "number": 25,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700610907816,
                "cdate": 1700610907816,
                "tmdate": 1700611578486,
                "mdate": 1700611578486,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "y38fIbP8Ej",
                "forum": "b7bilXYHgG",
                "replyto": "9J2tRfzP7Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Addressing concerns about the adversarial loss (Response to Reviewer RxKF)"
                    },
                    "comment": {
                        "value": "### Addressing concerns about the adversarial loss\n\nThank you for your question. We would like to clarify that the updated version of adversarial loss in Eq.6 is **exactly the same as* the original version (but with better notation). We would also like to explain below why our formalization of the loss is correct.\n \n\nIn the original version, our adversarial loss is written as ${L}\\_{adv}=\\mathbb{E}\\_{({X,A,M)\\sim \\mathbb{P}\\_\\mathrm{f}}}\\left[A \\log\\big( {D}(X, \\tilde{G}\\left(X,A,M \\right))\\_{A}\\big)+A^{\\prime} \\log \\big( 1-{D}(X, \\tilde{G}\\left(X,A,M \\right))_{A'}\\big)\\right]$. \n\nOur current loss is ${L}\\_{adv} = \\mathbb{E}\\_{({X,A,M)\\sim \\mathbb{P}\\_\\mathrm{f}}}\\left[\\log\\big( {D}(X, \\tilde{G}\\left(X,A,M \\right))_{A}\\big) \\right ]$. \n\nIt might not look that straightforward to see the updated version is exactly the same (just merge the original two terms into one),  but it is actually **the same as the previous one**. Let us clarify that step by step.\n\n\nIn binary setting, $1-{D}(X, \\tilde{G}\\left(X,A,M \\right))_{A'}$ is actually equal to ${D}(X, \\tilde{G}\\left(X,A,M \\right))\\_{A}$  . This because the sum of ${D}(X, \\tilde{G}\\left(X,A,M \\right))\\_{A\u2019}$ and ${D}(X, \\tilde{G}\\left(X,A,M \\right))\\_{A}$ should be 1 (i.e., he discriminator $D$ outputs the probability and the sum of the total probability is 1).\n\nLet\u2019s consider $A=1$ and $A=0$ respectively, for the original version of loss. \n\n- When $A=1$, $A\u2019 = 0$ makes the second term vanish, then the only thing left is \n$\\log({D}(X, \\tilde{G}\\left(X,A,M \\right))\\_{A})$, which is $\\log({D}(X, \\tilde{G}\\left(X,1,M \\right))\\_{1})$. \n\n- When $A=0$, then the first term turns to  0 and the second term is $ \\log(1-{D}(X, \\tilde{G}\\left(X,A,M \\right))_{A'})$, which is equal to $\\log({D}(X, \\tilde{G}\\left(X,A,M \\right))\\_{A})$ , and the loss now is $\\log({D}(X, \\tilde{G}\\left(X,0,M \\right))\\_{0})$ .\n\n\nOur current loss is $\\mathbb{E}\\_{({X,A,M)\\sim \\mathbb{P}\\_\\mathrm{f}}}\\left[\\log\\big( {D}(X, \\tilde{G}\\left(X,A,M \\right))_{A}\\big) \\right ]$.  Let\u2019s consider $A=1$ and $A=0$ respectively, for the current version of loss. \n\n\n- When$A=1$, the loss is $\\log({D}(X, \\tilde{G}\\left(X,1,M \\right))\\_{1})$ \n\n- When $A=0$, the loss is $\\log({D}(X, \\tilde{G}\\left(X,0,M \\right))\\_{0})$.\n\nSo our updated version is **exactly the same as** the original version. \n\n\nWe want to clarify it considers the counterfactual in our formula. **The output of the generator $\\tilde{G}\\left(X,A,M \\right)$ is always fed into the discriminator**. Besides, we consider both classes for $A=1$ and $A=0$.  The generator of the GAN actually minimizes the conditional propensity-weighted Jensen\u2013Shannon divergence (JSD). To show the above more explicitly, we kindly refer the reviewer to our proof, which should make the above more clear.  (see **Eq. (31) in Appendix D.2**).\n\n\nFor ease of understanding, one can simply view $A$ as the true label in a classification class, and our loss is no different from the normal **cross-entropy loss** for the classification task.\n\n**Action (in blue font):** We added a brief intuition along the above lines to explain our loss in greater detail.\n\nWe are again thankful for your question. We hope that our answer helped in addressing your questions satisfactorily. Please let us know if there are further things in our presentation that should be improved."
                    }
                },
                "number": 26,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700611388384,
                "cdate": 1700611388384,
                "tmdate": 1700611550125,
                "mdate": 1700611550125,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Pfo9UdqA1i",
                "forum": "b7bilXYHgG",
                "replyto": "uKXSuQi5eq",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "Addressing concern about CFGAN interpretation 2/2"
                    },
                    "comment": {
                        "value": "Many thanks to the authors for their detailed answers. I acknowledge that maybe I miss something, but I still think that CFGAN could be applied for counterfactual fairness, although I agree that in their paper authors use it differently, by considering groups of individuals defined according to a subset of variables o, that remain unchanged in the factual and counterfactual world (o is not necessarily the sensitive contrary to what authors indicate, at least I did not understand it like this).\n\nI previously spent time to capture how we could leverage CFGAN for counterfactual fairness from this, and my understanding was that if you consider the generation seed z as o, you can generate all variables for the same individual with a=1 and a=0, and then regulate to achieve counterfactual fairness. z is the essence of the individual, which controls everything given the sensitive A. So, while it is true that CFGAN only reports results that compare outcomes for groups of individual that have similar properties o in both world, reducing o to the generation seed would comes down to consider CFGAN for counterfactual fairness no ? From my point of view, this is like this that it should be considered in experiments to get a comparable setting as yours."
                    }
                },
                "number": 28,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700651771086,
                "cdate": 1700651771086,
                "tmdate": 1700651771086,
                "mdate": 1700651771086,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Btb3XzrVDK",
                "forum": "b7bilXYHgG",
                "replyto": "y38fIbP8Ej",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "Addressing concerns about the adversarial loss"
                    },
                    "comment": {
                        "value": "Sorry but, if I see the equivalence you detail, I still feel there remains something missing in your formulation. In particular, I cannot see what prevents G to output the trivial solution M for both cases, which prevents D to well distinguish, but does not produce any counterfactual (M never modified)...  please clarify"
                    }
                },
                "number": 30,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700664540243,
                "cdate": 1700664540243,
                "tmdate": 1700664540243,
                "mdate": 1700664540243,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3UUzJXKlLb",
                "forum": "b7bilXYHgG",
                "replyto": "VB8h1Dsjbg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "Further discussion on CFGAN"
                    },
                    "comment": {
                        "value": "Thanks for considering the proposal. But I still have some concerns : \n- authors set cfgan in the pre-processing category of fairness approaches. From my point of view, this is not fully true as they generate data that are not fair but which can be leveraged in counterfactual or interventional fairness by getting both versions of each individual z or group o. The bias mitigation is performed afterwards, on that dataset, as any in-processing approach\n- I cannot understand how the original CFGAN is used by authors. you use the sensitive as o that's it ? you generate many samples from the generator with both versions of the sensitive and then mitigate biases between s=0 and s=1 ? indeed, that is group fairness, not individual, so I don't think this baseline is really relevant\n- Thanks having considered (very quickly !) my proposal of using z as o. But I am surprised of such so bad results. You generate a dataset with both versions of each individual using same z for s=0 and s=1. Then you train a predictor that considers a regularization constraint that minimizes $|P(y_0|s_0, x_0)-P(y_1|s_1, x_1)|^2$ ? If yes, what could explain as bad results, I do not feel this process very different from what authors propose, except the use of a mediator that is the only changing part while cfgan can change everything acting on s..."
                    }
                },
                "number": 34,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740070037,
                "cdate": 1700740070037,
                "tmdate": 1700740070037,
                "mdate": 1700740070037,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9QqF52oIz1",
                "forum": "b7bilXYHgG",
                "replyto": "2QnsNmW9Iy",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_RxKF"
                ],
                "content": {
                    "title": {
                        "value": "Further discussion on adversarial loss"
                    },
                    "comment": {
                        "value": "ok in practice you do not observe such convergence toward trivial solutions of G, thanks to an alternated optimization by gradient steps I suppose. \n\nHowever, you agree that max_D L_{adv}(G,D) is minimal when $G$ maxmizes the uncertainty of $D$, that is to say, when $D=0.5$ for any training sample. no ?   So theoretically I cannot see what prevents from this trivial generation that simply copies the M input... \n\nLastly, I cannot see why VAE non identifiability of the latent Z would be problematic, while this problem would be miraculously solved in GAN approaches. You could see the parameters of your generator as a random variable $\\Theta$ that is driven by $p(\\Theta|X,Y,M)$. This variable, as Z for VAE approaches, is not identifiable, since the optimum is not unique. I understand that you can still converge to the true counterfactual when an infinity of data is observed, but sorry I cannot see why the decoder of a VAE couldn't as well..."
                    }
                },
                "number": 35,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700741135976,
                "cdate": 1700741135976,
                "tmdate": 1700741135976,
                "mdate": 1700741135976,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "BsbLdFMghh",
            "forum": "b7bilXYHgG",
            "replyto": "b7bilXYHgG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5631/Reviewer_5wUi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5631/Reviewer_5wUi"
            ],
            "content": {
                "summary": {
                    "value": "The paper studies the issue of counterfactual fairness. It\u2019s concerned with making predictions that are fair towards individuals, ensuring that the prediction would remain the same if the individual belonged to a different demographic group defined by sensitive attributes like gender or race. The proposed method use GAN for counterfactual mediator generation to ensure fairness while maintaining high prediction performance. Experiments are conducted to evaluate the method, including a real-world case study on recidivism prediction."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper addresses an important aspect of fairness in machine learning, ensuring that predictions are fair at an individual level.\n\n2. The paper presentation includes rich contents, with tables and figures well organized. The writing is generally easy to follow.\n\n3. The proposed method is validated through various experiments, including synthetic datasets and a real-world case study. The paper claims to achieve sota performance, and code is provided."
                },
                "weaknesses": {
                    "value": "1. The theoretical analyses in 4.3 does not provide much insight or guarantee. The lemma states that the level of counterfactual fairness is upper-bounded by the performance of the counterfactual mediator generation and the counterfactual mediator regularization. This does not really takes an equation to be concluded, and it cannot say anything about whether the method would be effective or not.\n\n2. Following the above point, the method does not have guarantee in achieving counterfactual fairness.\n\n3. Though the authors compare this work with CFGAN, the use of GAN for generation-based counterfactual fairness makes the technical contributions largely alike, which impairs the the novelty of the proposed method."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5631/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698810751294,
            "cdate": 1698810751294,
            "tmdate": 1699636583759,
            "mdate": 1699636583759,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "V9AWd7uwxI",
                "forum": "b7bilXYHgG",
                "replyto": "BsbLdFMghh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5wUi"
                    },
                    "comment": {
                        "value": "Thank you for your helpful review! We appreciate that you find our paper important, rich, and well-organized. We have carefully addressed your comments below to improve our work. \n\n### Responses to \"Weaknesses\"\n\n* **Response to: New theoretical guarantees**\n\nThank you for your suggestion. We have **entirely reworked our theoretical analyses**: \n\nWe now added a new theoretical analysis to show our method\u2019s effectiveness (see our **new Lemma 2**). Our new Lemma 2 states that our method correctly identifies the counterfactual mediators. Specifically, we prove that our method allows for **consistent estimation of the counterfactual distribution**, $\\mathbb{P}(M_{a'} \\mid X=x, A=a, M=m)$. Lemma 2 thus gives a guarantee on the correctness of the generated counterfactual mediators and, therefore, also a guarantee on the upper bound in Lemma 1, which thus confirms the effectiveness of our method. \n\nWe added a new **Corollary 1** to show that the above theoretical results also **generalize to high-dimensional settings**. \nOur new theoretical analysis is important for two reasons. First, it provides a **theoretical justification behind the design of our method**. Second, it ensures that we correctly learn counterfactual fairness. To the best of our knowledge, ours is the **first** neural method for counterfactual fairness that offers such guarantees.\n\n* **Response to: Theoretical guarantee to show our method\u2019s effectiveness**\n\nThank you for your helpful comment. We added a **new Lemma 2** to give a guarantee on the error of the generated counterfactual ($||M_{A'} - \\hat M_{A'}||^2_2$), which is the first term of upper bound terms in Lemma 1. Therefore, when the counterfactual mediator regularization ${R}_\\mathrm{{cm}}$ (=the second term of the upper bound), is minimized, the counterfactual fairness level is guaranteed through Lemma1. As such, we achieve a **theoretical guarantee that our method is effective in achieving counterfactual fairness**. To the best of our knowledge, ours is the **first** neural method for counterfactual fairness that offers such guarantees."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700439120871,
                "cdate": 1700439120871,
                "tmdate": 1700439120871,
                "mdate": 1700439120871,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "wF4SurG8xv",
                "forum": "b7bilXYHgG",
                "replyto": "BsbLdFMghh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 5wUi"
                    },
                    "comment": {
                        "value": "### Responses to \"Weaknesses\"\n\n* **Response to: Differences from CFGAN [1]**\n\nWe appreciate the opportunity to clarify that our method is **significantly different** from CFGAN (in terms of task, architecture, learning objectives, etc.). We highlight these differences below:\n\n**Different tasks**:  \n\nCFGAN is designed for fair data generation tasks, while our model is designed for learning predictors to be counterfactual fairness. Hence, both address **different tasks**. \n\n**Different architectures**: \n\nCFGAN employs **two** generators, each aimed at simulating the original causal model and the interventional model, and two discriminators, which ensure data utility and causal fairness. We only employ a streamlined architecture with a **single** generator and discriminator. Further, fairness enters both architectures at **different places**. In CFGAN, fairness is ensured through the GAN setup, whereas our method ensures fairness in a second step through our counterfactual mediator regularization.\n\n**Different training objectives**: \n\nThe training objectives are **different**: CFGAN learns to **mimic factual data**. In our method, the generator **learns the counterfactual distribution of the mediator** through the discriminator distinguishing factual from counterfactual mediators. \n\n**No theoretical guarantee for CFGAN**: \n\nCFGAN is proposed to synthesize a dataset that satisfies counterfactual fairness. However, a recent paper [2] has shown that CFGAN is actually considering interventions (=level 2 in Pearl\u2019s causality ladder) and **not** counterfactuals (=level 3). Hence, CFGAN does not fulfill the counterfactual fairness notion, but a different notion based on do-operator (intervention). For details, we refer to reference [2], Definition 5 therein, called ``Discrimination avoiding through causal reasoning''): A generator is said to be fair if the following equation holds: for any context $A=a$ and $X=x$, for all value of $y$ and $a' \\in \\mathcal{A}$, $P(Y=y \\mid X=x, d o(A=a))=P\\left(Y=y \\mid X=x, d o\\left(A=a' \\right)\\right)$, which is different from the counterfactual fairness \n$P(Y_a=y \\mid X=x, A=a)=P\\left(Y_{a'}=y \\mid X=x, A=a\\right)$. (We also discuss CFGAN considers interventions not counterfactual in our paper see **Appendix. I.1**) Moreover, **CFGAN lacks theoretical support** for its methodology (no identifiable guarantee or counterfactual fairness level). In contrast, our method strictly satisfies the principles of counterfactual fairness and provides theoretical guarantees on the counterfactual fairness level. In sum, **only our method offers theoretical guarantees** for the task at hand. \n\n**Suboptimal performance of CFGAN**: \n\nEven though CFGAN can, in principle, be applied to counterfactual fairness prediction, it is **suboptimal**. The reason is the following. Unlike CFGAN, which generates complete synthetic data under causal fairness notions, our method only generates counterfactuals of the mediator as an intermediate step, resulting in minimal information loss and better inference performance than CFGAN. Furthermore, since CFGAN needs to train the dual-generator and dual-discriminator together and optimize two adversarial losses, it is more difficult for stable training, and thus its method is less robust than ours.\n\nIn sum, even though CFGAN also employs GANs, it is **vastly different from our method**.\n\n**Action**: We carefully discuss the differences between CFGAN and our method in our revised paper (see **Appendix B.2 and I.1**). Therein, we spell out clearly that CFGAN is different in terms of task, architecture, and theoretical guarantees.  \n\nReferences\n\n[1] Depeng Xu, Yongkai Wu, Shuhan Yuan, Lu Zhang, and Xintao Wu. Achieving causal fairness through generative adversarial networks. In IJCAI, 2019.\n\n[2] Mahed Abroshan, Mohammad Mahdi Khalili, and Andrew Elliott. Counterfactual fairness in synthetic data generation. In Neurips 2022 SyntheticData4ML Research, 2022."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700439759259,
                "cdate": 1700439759259,
                "tmdate": 1700612265922,
                "mdate": 1700612265922,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "rrErKTGmBg",
            "forum": "b7bilXYHgG",
            "replyto": "b7bilXYHgG",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5631/Reviewer_Aquc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5631/Reviewer_Aquc"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes to use GAN to estimate counterfactual mediators. Although the method is shown to have strong empirical performance, there is no theoretical guarantee on the error of estimated counterfactual mediators, which can lead to arbitrarily unfair predictors given the proposed regularization relies on the generated counterfactual mediators."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- Empirically, the authors show, in some synthetic/semi-synthetic settings, their method can magically infer counterfactual mediators by learning from observational data. In addition, their method outperforms various baselines from the counterfactual fairness literature.\n- Paper is well written, it is easy to read."
                },
                "weaknesses": {
                    "value": "- There is no discussion on the identification of counterfactual mediators. The authors need to show this before developing estimators for counterfactual mediators.\n- The generator is trained on factual data only, there is no guarantee on the error of its generated counterfactuals. This would further lead to ineffectiveness of the discriminator as it is trained on generated counterfactuals. Similarly, In Lemma 1, the upperbound has a term ||M_{A'},\\hat{M}_{A'}|| which is not computable, so, the minimizing the loss function Eq.(8) cannot guarantee the LHS of Eq.(9) is minimized."
                },
                "questions": {
                    "value": "- In the literature, there are works on issues of methods that learn a ML model to predict counterfactuals for counterfactual fairness [1,2]. [1] points out that one can learn a model to predict counterfactuals iff a specific strong ignorability holds, i.e., A is independent of potential mediators M_a. In another words, the dataset is collected without selection bias, which is represented by a collider S \\in \\{0,1\\} s.t. A->M, A->S, M->S and we can only observe samples from P(A,M|S=1). [2] argues counterfactual fairness is similar to demographic parity as (1) any predictor satisfying counterfactual fairness also satisfies DP and (2) any predictor satisfying DP can be modified trivially to satisfy counterfactual fairness. The authors may want to add a discussion about them.\n\n- It is vague in Fig. 1 that whether the authors allow just correlation between X and A or there has to be a causal relationship X->A.\n\n- The claim that one can include anything in the mediator if the domain knowledge is missing sounds not solid.\n\n- Inconsistent notations: If M_a is the potential outcome, why do we need M_{A-\\leftarrow a}?\n\n- Parenthesis mismatch in Eq.(9).\n\n- For Adult, how do the authors know marital status, education level, occupation, hours per week, and work class are mediators? How is the counterfactual fairness metric computed without knowing ground truth counterfactuals?\n\n- [1] Fawkes, Jake, Robin Evans, and Dino Sejdinovic. \"Selection, ignorability and challenges with causal fairness.\" In Conference on Causal Learning and Reasoning, pp. 275-289. PMLR, 2022.\n- [2] Rosenblatt, Lucas, and R. Teal Witter. \"Counterfactual fairness is basically demographic parity.\" In Proceedings of the AAAI Conference on Artificial Intelligence, vol. 37, no. 12, pp. 14461-14469. 2023."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5631/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5631/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5631/Reviewer_Aquc"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5631/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698835231688,
            "cdate": 1698835231688,
            "tmdate": 1700564969420,
            "mdate": 1700564969420,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "udN6XAzkoG",
                "forum": "b7bilXYHgG",
                "replyto": "rrErKTGmBg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Aquc"
                    },
                    "comment": {
                        "value": "Thank you for your thorough and insightful feedback! We are glad to hear that you appreciate the strong empirical performance and the clear presentation of our paper.\n\n\n### Response to Weaknesses\n\n**Identification of counterfactual mediators**\n\nThank you. We recognize the importance of discussing the identification of counterfactual mediators. To address your point, we have added a **new theoretical analysis**. Specifically, we have revised our manuscript in the following ways: \n* We added a **new Lemma 2** to show that our method correctly identifies the counterfactual mediators. Specifically, we prove that our method allows for **consistent estimation of the counterfactual distribution**. The lemma thus gives a guarantee on the correctness of the generated counterfactual mediators and, therefore, also a guarantee on the upper bound in Lemma 1.\n\n* We added a new **Corollary 1** to show that the above theoretical results also **generalize to high-dimensional settings**. \nOur new theoretical analysis is important for two reasons. First, it provides a **theoretical justification behind the design of our method**. Second, it ensures that we correctly learn counterfactual fairness. To the best of our knowledge, ours is the **first** neural method that offers such guarantees.\n\n**Theoretical Guarantee and Counterfactual Estimation**\n\nThank you. We address your comment point-by-point\u3002\n\n*Response to: No theoretical guarantee*\n\nTo address your point, we now provide **new theoretical guarantees** of the correctness of the generated counterfactual mediators (see our **new Lemma2**). Our new Lemma 2 shows that our generator consistently estimates the counterfactual distribution of the mediator. It gives a guarantee on the correctness of the generated counterfactual mediators. Together with Lemma 1, it provides theoretical results that our method is effective. \n\n*Response to: Correctness of the generated counterfactual mediator*\n\nOur **new Lemma 2** states that our GAN-based approach consistently estimates the counterfactual distribution of mediators. By converging to the counterfactual distribution (point mass distribution), our generator actually learns a deterministic function that transforms from factual to counterfactual: $\\mathbb{P}(M_{a'} \\mid X=x, A=a, M=m)$. Under consistency, the generated counterfactual can converge to the ground-truth counterfactual.  This confirms the effectiveness and validity of the generated counterfactual mediators.\n\n*Response to: Addressing the upper bound in Lemma 1*\n\nWe acknowledge that Lemma 1 was not sufficient to show the effectiveness of our method. As a remedy, our new Lemma 2 gives a guarantee on the error of the generated counterfactual ($||M_{A'} - \\hat M_{A'}||^2_2$), which is the first term of upper bound terms in Lemma 1. Then, by minimizing the loss function ${L}(h)=L_{ce}(h)+\\lambda R_{cm}(h)$\n, the counterfactual mediator regularization $R_{cm}$ is minimized accordingly, which is the second term in the of upper bound terms in Lemma 1. As a result, we can successfully address your comment: by minimizing the loss, we can guarantee that the counterfactual fairness level is minimized."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700437451531,
                "cdate": 1700437451531,
                "tmdate": 1700437451531,
                "mdate": 1700437451531,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "BIm9w1wRP6",
                "forum": "b7bilXYHgG",
                "replyto": "rrErKTGmBg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Aquc"
                    },
                    "comment": {
                        "value": "### Response to Questions\n\n* **Discussion regarding the literature [1] & [2]:**\n\nThank you. We appreciate the opportunity to spell out how our work is **different** from [1] and [2]. We also have **included references** to papers [1] & [2] in our revised paper together with a brief discussion. Both [1] & [2] make important contributions to our theoretical understanding of causal fairness. As such, they are **orthogonal** to our work where we develop a new learning algorithm for counterfactual fair predictions with theoretical guarantees. \n\nRegarding [1]: \n\nThe setting of the paper [1] is similar to ours, only some notations are different. In [1], what is referred to as $X(a)$ aligns with $M_a$ in our paper. However, there are **several differences in the assumptions** that distinguish [1] from our paper. \n\n1. Confounder inclusion: \n\nOur model allows for the existence of the confounders between the sensitive attribute $A$ and its descendant $M$, denoted as $X$ in our paper. This is **unlike** [1], where such variables are not explicitly considered, so that our setting can be considered to be more general, For example, consider Figure 1 in reference [1]. Therein, the authors aim to handle additional variables (\u201ccovariates\u201d) that are not the sensitive attribute but also can affect the mediators like \"Age\u201d. The \u201cAge\u201d variable, even when there are no other sensitive attributes such as \u201crace\u201d or \u201cgender\u201d there, still impacts mediators like \u201cGPA\u201d, \u201cLSAT\u201d, and \u201cFYA\u201d. However, such variables are **not** considered in [1] setting. In contrast, we can put such variables into our covariate $X$. Therefore, we argue that our setting is applicable to a wider range of scenarios.\n\n2. Selection bias: \nIf there exists a collider $S$ between $A$ and $M$ (such that $A \\rightarrow M$, $A \\rightarrow S$, $M \\rightarrow S$), then conditioning on $S$ introduces a correlation between $A$ and $M$. This can be interpreted as the presence of a confounder (such that $A \\rightarrow M$, $X \\rightarrow A$, $X \\rightarrow M$). In [1], the dataset is collected **without** selection bias, which implies that $A$ and $M$ are unconfounded. This is consistent with our assumptions. In [1], structural counterfactuals satisfy ignorability ($ M_a \\perp\\kern-5pt\\perp A $). In our work, since we allow for covariates $X$, the potential outcome $M_a$ is conditionally independent of $A$ given the covariates $X$  ($M_a \\perp\\kern-5pt\\perp A | X$) .  \n\nRegarding [2]: \n\nWe highly appreciate the theoretical insights from [2], yet there are significant **differences** in our work. \nDP is a non-causal fairness notion. Specifically, DP says the target $Y$ should satisfy the conditional distribution $P(Y \\mid A=a)=P(Y \\mid A=a\u2019)$, and, thereby, it essentially prohibits the use of any variable correlated with the sensitive attribute $A$ for predictions. This includes $A$ itself, its descendants, causes, and any correlated variables. As we discuss below, prohibiting the use of any variable correlated with the sensitive attribute may be fairly restrictive in practice.  \n\nIn our causal graph, to achieve fairness under DP, one must exclude not only the sensitive attribute $A$ and mediators $M$ but also any variables in $X$ that directly cause or correlate with A. For instance, consider an employment system in a company. If \u2018'gender' is the sensitive attribute and 'age' correlates with gender due to regional cultural norms, DP would forbid the use of 'age' for fair decision-making. Our method, however, allows for such usage.\n\nConsequently, achieving DP often results in a significant loss of predictive accuracy. In contrast, our method ensures counterfactual fairness, while not being bound by these strict restrictions, so that our method can achieve a better prediction performance. We performed a few tests using datasets where $X$ and $A$ are uncorrelated. We used the same classifier for better comparability. A method that needs to achieve DP only records an accuracy of 0.76 (i.e., by only using $X$). In contrast, our method achieves an accuracy 0.94 (by allowing the use of $X$ and $M$). In summary, DP has more strict requirements for using variables, thus sacrificing the accuracy of predictions. This is especially relevant when $M$ contains a lot of useful information for prediction. We thus believe that our method is therefore of great value in practice where not only counterfactual fairness but also a good prediction performance is important. \n\nReference\n\n[1] Fawkes, Jake, Robin Evans, and Dino Sejdinovic. \"Selection, ignorability and challenges with causal fairness.\" In Conference on Causal Learning and Reasoning. PMLR, 2022.\n\n[2] Rosenblatt, Lucas, and R. Teal Witter. \"Counterfactual fairness is basically demographic parity.\" In AAAI. 2023."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700438033854,
                "cdate": 1700438033854,
                "tmdate": 1700438704780,
                "mdate": 1700438704780,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "f8szpiIgR9",
                "forum": "b7bilXYHgG",
                "replyto": "rrErKTGmBg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Aquc"
                    },
                    "comment": {
                        "value": "### Response to Questions\n\n\n* **Fig.1 Interpretation:**\n\n The dashed line in Fig.1 illustrates that a correlation between $X $ and $A$ is permissible/allowed in our framework, but a direct causal relationship $X$->$A$ is not a necessity. Note that, if there is no dashed edge between $X$ and $A$, it is actually a stronger assumption, because it forbids the edge between $X$ and $ A$ to have any hidden confounders. However, our setting is more general and allows the existence of the confounders. Notwithstanding, we added new experimental results (see new results in Appendix H.1), where we analyze the performance of our method in the presence of confounders, finding that our method is highly effective.\n\n* **Choice of mediator variables:**\n\n The selection of mediator variables, $M$, typically relies on domain knowledge, following established practices in literature such as [3, 4, 5, 6, 7]. We fixed that sentence in our revised paper.\n\n* **Inconsistent notation:** \n\nThank you! The notation $M_{A-\\leftarrow a}$ was an error. We have streamlined our notation so that we now consistently use $M_a$ as the potential outcome in the updated manuscript. \n\n* **Parenthesis mismatch in Eq. (9)**: \n\nThank you. We fixed this. \n\n* **Adult dataset:**\n\nThank you for your suggestions. We added a more detailed discussion of our setting to **Appendix E.3**. Below, we discuss how we selected mediators and the counterfactual fairness metric. \n\n*Mediator selection*: \n\nWe follow common choices in prior research (such as [3, 4, 5, 6]). We consider 'gender' as a sensitive attribute. Mediators are variables that can potentially be influenced by the sensitive attribute. The  'marital status', 'education level', 'occupation', 'hours per week', and 'work class' are all known to be influenced by \u2018gender\u2019, and, therefore, we treat them as \u2018mediators\u2019. We classified all other variables as covariates. \n\n*Counterfactual fairness metric*: \n\nWe use the Adult dataset to demonstrate the applicability of our method to real-world data, where ground-truth counterfactuals are unavailable. Nevertheless, to understand the implications for counterfactual fairness empirically, we use the generated counterfactuals to measure counterfactual fairness on the test dataset. This allows us to explore the accuracy-fairness trade-off. We have revised our paper to spell out clearly how we computer the counterfactual fairness metric for real-world data. Thereby, we further highlight that our choice is in line with other works from causal fairness as the purpose of the Adult dataset is to demonstrate real-world applicability (and not benchmarking). \n\n\nReference\n\n[3] Razieh Nabi and Ilya Shpitser. Fair inference on outcomes. In AAAI, 2018.\n\n[4] Hyemi Kim, Seungjae Shin, JoonHo Jang, Kyungwoo Song, Weonyoung Joo, Wanmo Kang, and Il.Chul Moon. Counterfactual fairness with disentangled causal effect variational autoencoder. In AAAI, 2021.\n\n[5] Depeng Xu, Yongkai Wu, Shuhan Yuan, Lu Zhang, and Xintao Wu. Achieving causal fairness through generative adversarial networks. In IJCAI, 2019.\n\n[6] Francesco Quinzan, Cecilia Casolo, Krikamol Muandet, Niki Kilbertus, and Yucen Luo. Learning counterfactually invariant predictors. arXiv preprint, 2022.\n\n[7] Drago Plecko and Elias Bareinboim. Causal fairness analysis. In arXiv preprint, 2022."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700438666392,
                "cdate": 1700438666392,
                "tmdate": 1700438666392,
                "mdate": 1700438666392,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "g7AyISwX2E",
                "forum": "b7bilXYHgG",
                "replyto": "rrErKTGmBg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_Aquc"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_Aquc"
                ],
                "content": {
                    "title": {
                        "value": "Lemma 2"
                    },
                    "comment": {
                        "value": "Thanks for the revision. I updated my score. But I still have some questions.\n\n1. Can the authors make it clear whether the first statement of Lemma 2 is their contribution or from existing work? With statement 1, the counterfactual distribution is identified. Then it is not surprising we can fit a GAN or other generative models to estimate the counterfactual mediators.\n\n2. Intuitively, I still think the proposed GAN can only generate good factual data as it is never trained on counterfactual data just like the original GAN can only generate good data from the original training distribution. This implies that the strategy of this work is to mak the distribution of counterfactual mediators equivalent to its corresponding conditional distribution with a different value of $A$. With Lemma 2, it basically says, if the conditional $P(M|X=x,A=a')$ can be estimated precisely, then the counterfactual $P(M_{a\\leftarrow a'}|X=x,A=a)$ can be estimated accurately because they are the same thing under the assumptions. In this case, my question is, if we can observe enough samples with $(X=x,A=a')$, why is $M_{a\\leftarrow a'}|X=x,A=a$ still a counterfactual quantity?"
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700564946773,
                "cdate": 1700564946773,
                "tmdate": 1700565016359,
                "mdate": 1700565016359,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uCBkBV20HS",
                "forum": "b7bilXYHgG",
                "replyto": "w0J6mzg4lM",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_Aquc"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5631/Reviewer_Aquc"
                ],
                "content": {
                    "title": {
                        "value": "Continue on Lemma 2"
                    },
                    "comment": {
                        "value": "Thanks for the reply.\n\nI do not agree that the first statement of Lemma 2 is related to GAN.\nCould the authors explain what is the difference between their first statement in Lemma 2 and the Lemma B.2 in (Nasr-Esfahany et al., 2023) and Corollary 3 in (Melnychuk et al.)? Since there is no complete proof of this statement in Appendix C.2 and the RHS of Eq.(21) is from (Melnychuk et al.)."
                    }
                },
                "number": 29,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5631/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700652460175,
                "cdate": 1700652460175,
                "tmdate": 1700652460175,
                "mdate": 1700652460175,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]