[
    {
        "title": "Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement"
    },
    {
        "review": {
            "id": "zTiP8B336e",
            "forum": "RDSTjtnqCg",
            "replyto": "RDSTjtnqCg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission783/Reviewer_5qNg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission783/Reviewer_5qNg"
            ],
            "content": {
                "summary": {
                    "value": "This paper investigates modern deep learning systems' ability to identify out-of-distribution (OOD) samples. It critically analyzes the extremely simple activation shaping (ASH) method, finding that activation pruning hinders, while activation scaling improves OOD detection. The authors propose two methods: SCALE, a post-training enhancement that boosts OOD detection without affecting in-distribution accuracy, and Intermediate Tensor SHaping (ISH), a training-time method for enhancing OOD detection. These methods show significant performance improvements on the OpenOOD v1.5 ImageNet-1K benchmark."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The analysis of ASH looks reasonable.\n2. SCLAE and ISH are easy to reproduce and use.\n3. It is commendable that similar ideas can be applied simultaneously to post-hoc and training time OOD detection."
                },
                "weaknesses": {
                    "value": "1. Incorrect Motivation: The author seems to have not conducted sufficient research in the field of OOD detection. Generally, OOD detection requires the model to identify OOD data without affecting the accuracy of ID classification. Hence, there should not be a trade-off between ID classification accuracy and OOD detection performance. Post-hoc OOD detection refers to performing OOD detection through post-processing algorithms without altering the model parameters. Consequently, React, Dice, and ASH  utilize the original classifier for ID classification tasks and a modified classifier for OOD detection tasks, introducing a very minimal computational overhead. Therefore, I believe there is a problem with the motivation presented in the introduction section of the paper.\n2. Limited Novelty: SCALE and ISH are incremental works of ASH. Thus, I attribute the commendable performance of ISH and SCALE mainly to the superior performance of ASH. The performance improvement over ASH is quite minimal.\n3. Unsubstantiated Claim on React: The author claims that React \u201chinders the OOD detection process.\u201d However, this analysis is solely theoretical and lacks experimental validation. I think the results from SCALE+React or ISH+React could potentially validate this point.\n4. Minimal Performance Gain: As observed from Table 5, the performance improvement brought by combining ISH and SCALE compared to using SCALE alone is extremely minimal. I am curious to know if combining ISH with other OOD detectors (e.g., ISH+MSP/ODIN/Energy/React/ASH) could yield any performance improvement.\n5. Lack of Ablation Study: The paper is missing an ablation study related to the placement of SCALE, specifically, how its performance varies when placed after different stages of ResNet50."
                },
                "questions": {
                    "value": "see Weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission783/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698226293655,
            "cdate": 1698226293655,
            "tmdate": 1699636005728,
            "mdate": 1699636005728,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "YHpYMm4hj9",
                "forum": "RDSTjtnqCg",
                "replyto": "zTiP8B336e",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission783/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission783/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We express our appreciation to reviewer 5qNg for your insightful review and comprehensive suggestions. \n- **Incorrect Motivation: ID-OOD accuracy trade-off:**\n\nThanks for highlighting this confusion. Indeed the ID accuracy drop can be avoided through a separate classifiers with minimal computational cost. We will emphasize this point more in the introduction. We note that ID-OOD accuracies trade-offs are also reported in ReAct Table 2 and DICE Table 5, and further explored in ASH where they argue that an ideal OOD detection pipeline \"should not deteriorate ID task performance, nor should it require a cumbersome parallel setup that handles the ID task and OOD detection separately\". We will clarify this point.\nWe note that our motivation is not only achieving a better tradeoff between OOD detection and ID classification but also achieving higher OOD detection performance than others. We do this in a principled way through theoretical analysis, giving explanations and insights into the working mechanisms of existing works before making our proposal.\n\n- **Limited Novelty of SCALE and ISH:**\n\nThank you for your comments. The main contribution is providing a theoretical understanding of the current state-of-the-art method ASH. Our development of SCALE is directly born out of this analysis and verifies that it is only the scaling operation which benefits OOD detection (as pointed out by reviewer AeGx). \nFurthermore, we propose to leverage scores as ID-ness in extra training, which further improves OOD detection without the need for extra OOD validation data.\nFor experimental results. Compared to ASH-S, we achieved 1.73+ on near-OOD, +0.06 on far-OOD, and +0.67 on ID accuracy for SCALE, and achieved 4.83+ on near-OOD, 0.32+ on far-OOD, and 0.56+ on ID accuracy for ISH+SCALE. We note that current methods are already good for easier far-OOD detection so the improvement room is smaller.\n\n- **Unsubstantiated Claim on ReAct:**\n\nThanks for your suggestions. Our statement in the introduction is that \u201dthe lower-part pruning approach, in contrast to ReAct, hinders the OOD detection process\u201d. ReAct is a higher-part pruning. In our original paper, we provide an analysis that ASH pruning impedes the OOD process because lower-part pruning brings ID and OOD data closer in the logits space. For ReAct, higher-part pruning enlarges the distance between ID and OOD and this provides an explanation for its effectiveness.\n\n\n- **Minimal Performance Gain and combination of ISH with other OOD detector:**\n\nThanks for your suggestions. For the experiments results, ISH + SCALE improves an additional notable 1.34 on SCALE, which has 21% improvement than AugMix with less training efforts. We provide results for ISH + MSP/ODIN/Energy/ReAct/ASH in the following table and show that ISH increases all results. \n\n|            | Near-OOD AUROC | Far-OOD AUROC |\n|------------|----------------|---------------|\n| MSP        |    76.03       |     85.23     |\n| MSP+ISH    |    **76.87**       |     **85.86**     |\n| ODIN       |     74.75      |     89.47     |\n| ODIN+ISH   |     **76.51**          |    **90.18**        |\n| Energy     |    75.89       |     89.47     |\n| Energy+ISH |     **77.62**      |     **90.06**     |\n| ReAct      |     77.38      |     93.67     |\n| ReAct+ISH  |     **78.99**      |     **93.96**     |\n| ASH-S        |     79.63      |     96.47     |\n| ASH-S+ISH    |     **82.26**      |     **96.61**     |\n\n- **Ablation Study for the placement of SCALE :**\n\nWe appreciate your valuable suggestions and provide the ablation study on the following table:\n\n\n|             | Near-OOD AUROC | Far-OOD AUROC |\n|-------------|---------------|---------------|\n| Block1      |  48.62  |  64.09  |\n| Block2      |  62.79  |    62.06 |\n| Block3      | 70.08   |  62.27  |\n| Block4      | 78.86   |  90.65  |\n| Penultimate | **81.36** | **96.53**   |\n\nAs the stage becomes shallower, the performance decreases. This is because the early stages tend to learn low-level features that are common to both the ID and OOD datasets."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission783/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700664314880,
                "cdate": 1700664314880,
                "tmdate": 1700704775106,
                "mdate": 1700704775106,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "giCP6YqUPH",
            "forum": "RDSTjtnqCg",
            "replyto": "RDSTjtnqCg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission783/Reviewer_AeGx"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission783/Reviewer_AeGx"
            ],
            "content": {
                "summary": {
                    "value": "This work studies the problem of OOD detection. It starts by analyzing a recent SOTA method, ASH, where the analysis successfully disentangles the effect of ASH's two building components, namely pruning and scaling. Surprisingly, it is found that while scaling benefits the separation of ID and OOD score, pruning actually adversely hurts it. Based on this analysis, a new post-hoc method named SCALE is proposed. Furthermore, a training-time regularization that echoes the working mechanism of SCALE is also proposed (ISH). Both SCALE and ISH achieves improvements over closely-related and competitive baselines on multiple benchmarks."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1. The written and presentation quality of this manuscript is good. Easy to follow, and the logic is smooth and sound.\n2. The analysis of ASH and the insights originate from the analysis are valuable for two reasons. First, ASH indeed leads to superior performance (a recent SOTA), and thus understanding why it works is of course important. Second, the finding that scaling actually benefits OOD detection the most is surprising. In a bigger picture, I think this finding contradicts the common belief that pruning / rectifying is the (only) right direction (this can be evidenced by that many methods, e.g., ReAct, DICE, ASH, adopt such general design idea).\n3. The analysis is backed up by both theoretical investigation (Proposition 3.1) and empirical evidences (Table 1 and Figure 2 - 4).\n4. The developed method is motivated by the analysis, making it sound and valid.\n5. The empirical improvement on OpenOOD ImageNet-1K benchmark is convincing. In the first place, I also like it that the authors consider a unified benchmark for evaluation, which many works failed to do. This will definitely encourage follow-up works to continue making fair and straight comparison, which would benefits the whole OOD detection community."
                },
                "weaknesses": {
                    "value": "I have two minor comments.\n\n1. For CIFAR experiments, I strongly encourage the authors to refrain from using LSUN-Crop and LSUN-Resize as OOD datasets, if they are directly taken from the ODIN paper. LSUN-Resize has been shown to exhibit obvious resizing artifacts [1], which make the detection trivially easy. LSUN-Crop is 32x32 crops from images with larger resolution, and arguably the resulting samples will have unnaturally different distribution compared to CIFAR's 32x32 natural images, which again makes the evaluation less meaningful.\n\n2. The \"Comparison with OOD traning methods.\" subtitle in Sec. 4.3 has a typo (\"traning\" -> \"training\"), and should be placed in the same line as the leading sentence of the next paragraph. There also should be a blank space in \"LogitNorm(Wei et al., 2022)\". I would suggest a proof-reading to further improve the quality.\n \n[1] CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances"
                },
                "questions": {
                    "value": "I was wondering if the analysis provided in this work can also help explain ReAct's effect. Some elaboration or discussion on this can help provide even a more complete picture."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission783/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698621623626,
            "cdate": 1698621623626,
            "tmdate": 1699636005656,
            "mdate": 1699636005656,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FJe9fple2N",
                "forum": "RDSTjtnqCg",
                "replyto": "giCP6YqUPH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission783/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission783/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We extend our gratitude to RAx2 for the insightful review and suggestions.\n\n- **LSUN-Crop and LSUN-Resize results**: \nThanks for pointing this out. In our revision, we will remove LSUN-Crop and LSUN-Resize from the main text and place the original table in the Supplementary for consistent comparison to ODIN; and provide discussion to give awareness to the reader.\n\n  \n\n- **Typos and mistakes**: Thank you for pointing out these. We will fix them in the revision and proofread  them in the future carefully.\n\n  \n\n- **Explanation of ReAct**:\nOur analysis is relevant to ReAct, a higher-part pruning approach. In our original paper, we provide an analysis that ASH pruning impedes the OOD process because lower-part pruning brings ID and OOD data closer in the logits space. For ReAct, higher-part pruning enlarges the distance between ID and OOD and this provides an explanation for its effectiveness."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission783/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663984060,
                "cdate": 1700663984060,
                "tmdate": 1700663984060,
                "mdate": 1700663984060,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "e5A0vhE3V0",
                "forum": "RDSTjtnqCg",
                "replyto": "FJe9fple2N",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission783/Reviewer_AeGx"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission783/Reviewer_AeGx"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the rebuttal"
                    },
                    "comment": {
                        "value": "I have read the authors' response. I maintain my score of 8 and definitely recommend for acceptance."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission783/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700686553347,
                "cdate": 1700686553347,
                "tmdate": 1700686553347,
                "mdate": 1700686553347,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Hd2jLHqAgh",
            "forum": "RDSTjtnqCg",
            "replyto": "RDSTjtnqCg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission783/Reviewer_DQbC"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission783/Reviewer_DQbC"
            ],
            "content": {
                "summary": {
                    "value": "The authors present Intermediate Tensor SHaping (ISH) method for efficient OOD detection."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "The method presented in this work is interesting and innovative. I appreciate the idea and encourage authors to further the work along this domain."
                },
                "weaknesses": {
                    "value": "The method is tested only in Imagenet. The authors should use it for OOD detection in other kinds of datasets to ensure that the method is applicable in various domains."
                },
                "questions": {
                    "value": "How does the method generalize to other types of data e.g. tabular, time-series etc.?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission783/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698891493609,
            "cdate": 1698891493609,
            "tmdate": 1699636005546,
            "mdate": 1699636005546,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "nw3LMj9lqb",
                "forum": "RDSTjtnqCg",
                "replyto": "Hd2jLHqAgh",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission783/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission783/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank reviewer DQbC for your insightful review.\n- **The method is tested only in Imagenet:** \nTable 3 shows experiments on CIFAR-10 and CIFAR-100.\n- **Other Data Domains:**  \nOur method, like prevailing ad-hoc methods for OOD (EBO, ReAct, ASH) are intended for already-trained networks by design. The readily available off-the-shelf image backbones is why we and others work primarily in the image domain, extending it to other domains like time series and tabular data which do not have analogous backbones will likely need fundamental changes in the assumptions and approach beyond our current scope; we leave this for future work.\nWe strongly support the point that OOD for other domains is a worthwhile focus and we leave it for future research.\n\nEBO: Liu, Weitang, Xiaoyun Wang, John Owens, and Yixuan Li. \"Energy-based out-of-distribution detection.\" _Advances in neural information processing systems_ 33 (2020): 21464-21475.\n\nReAct: Sun, Yiyou, Chuan Guo, and Yixuan Li. \"React: Out-of-distribution detection with rectified activations.\" _Advances in Neural Information Processing Systems_ 34 (2021): 144-157.\n\nASH: Djurisic, Andrija, Nebojsa Bozanic, Arjun Ashok, and Rosanne Liu. \"Extremely simple activation shaping for out-of-distribution detection.\" _arXiv preprint arXiv:2209.09858_ (2022)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission783/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663828989,
                "cdate": 1700663828989,
                "tmdate": 1700663828989,
                "mdate": 1700663828989,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "hL9befuUK6",
            "forum": "RDSTjtnqCg",
            "replyto": "RDSTjtnqCg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission783/Reviewer_RAx2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission783/Reviewer_RAx2"
            ],
            "content": {
                "summary": {
                    "value": "The authors first analyze the OOD detection method ASH and then propose a post-hoc network enhancement method for OOD detection, namely SCALE. Besides, they propose a Intermediate Tensor Shaping method for training time OOD detection enhancement."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe proposed method is simple and easy to implement.\n2.\tThe results of the proposed method are better than the SOTA method ASH."
                },
                "weaknesses": {
                    "value": "1.\tCould the authors provide an algorithm to demonstrate the overall pipeline of the proposed method? I am confused about when we should invoke the method in Section 3.4.\n2.\tRecently, Transformer-based models become more and more popular. Could the proposed method be applied to these models?"
                },
                "questions": {
                    "value": "I am not familiar with this OOD detection field. However I think the proposed method is simple and effective based on the current manuscript."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission783/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699017961170,
            "cdate": 1699017961170,
            "tmdate": 1699636005471,
            "mdate": 1699636005471,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3hrnRZYBSz",
                "forum": "RDSTjtnqCg",
                "replyto": "hL9befuUK6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission783/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission783/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We extend our gratitude to RAx2 for the insightful review.\n- **Algorithm for ISH pipeline**: \nThanks for your suggestion. We provide pseudo-code of the algorithm here and will add it to Sec. 4.3 in the revision.\n```\nfunction ISH(pretrained_model M, data D, learning_rate L, epochs I)\n\tfor input, label in D: \n\t\t# forward pass get predicted results and intermediate activations.\n\t\tactivation_1, ...,  activations_p, predicted = forward_pass(M, input)\n\t\tgradient_z = loss(predicted-input)\n\t\t\n\t\t# get scaling s for the activations of for penultimate layer:\n\t\ts = SCALE(activations_p) # as defined in equation (7)\n\t\t\n\t\t# for penultimate layer:\n\t\t# scale activations_p by s for gradient computation\n\t\tgradient_weights = dot_product(s  * activations_p^T, gradient_z)\n\t\tgradient_biases = gradient_z\n\t\t\n\t\tupdate_parameters(gradient_weights, gradient_biases, learning_rate) \n\t\t\n\t\tupdate other parameters\n\t\t\n\t\treturn weights, biases\n```\n- **Applicability to Transformers**: \nOur current assumption and analysis is made in light of the ReLU because ResNet 50 is still the prevailing architecture of choice for other works in OOD [EBO, ReAct, ASH]. However, similar ideas could be applied to transformers, and we are looking into this for future work.\n\n**References**\n\nEBO: Liu, Weitang, Xiaoyun Wang, John Owens, and Yixuan Li. \"Energy-based out-of-distribution detection.\" _Advances in neural information processing systems_ 33 (2020): 21464-21475.\n\nReAct: Sun, Yiyou, Chuan Guo, and Yixuan Li. \"React: Out-of-distribution detection with rectified activations.\" _Advances in Neural Information Processing Systems_ 34 (2021): 144-157.\n\nASH: Djurisic, Andrija, Nebojsa Bozanic, Arjun Ashok, and Rosanne Liu. \"Extremely simple activation shaping for out-of-distribution detection.\" _arXiv preprint arXiv:2209.09858_ (2022)."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission783/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700663732056,
                "cdate": 1700663732056,
                "tmdate": 1700663732056,
                "mdate": 1700663732056,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "rA50NcKlOK",
                "forum": "RDSTjtnqCg",
                "replyto": "3hrnRZYBSz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission783/Reviewer_RAx2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission783/Reviewer_RAx2"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Authors"
                    },
                    "comment": {
                        "value": "I have no more questions and keep my scoring."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission783/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700709059433,
                "cdate": 1700709059433,
                "tmdate": 1700709059433,
                "mdate": 1700709059433,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]