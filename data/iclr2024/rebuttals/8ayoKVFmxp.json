[
    {
        "title": "QualEval: Qualitative Evaluation for Model Improvement"
    },
    {
        "review": {
            "id": "1M4bG75dGK",
            "forum": "8ayoKVFmxp",
            "replyto": "8ayoKVFmxp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7901/Reviewer_hZVP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7901/Reviewer_hZVP"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a technique/toolkit to enrich qualitative evaluations with assessments that use qualitative methods. The introduced QUALEVAL technique/toolkit provides a dashboard whose visualisations that help understand a given model and interrogate its performance. The QUALEVAL is evaluated using three models on three datasets. Quantitative evaluation metrics were included to supplement the evaluation."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper introduces a technique/toolkit to enrich qualitative evaluations with assessments that use qualitative methods. The introduced QUALEVAL technique/toolkit provides a dashboard whose visualisations that help understand a given model and interrogate its performance. The QUALEVAL is evaluated using three models on three datasets. Quantitative evaluation metrics were included to supplement the evaluation."
                },
                "weaknesses": {
                    "value": "Although I am not an expert in introducing qualitative methods for evaluating models or algorithms, the paper seems to be somewhat lacking in scientific rigor in study design and reporting. I am not convinced that the contribution is complete what comes to its approach to providing evidence to validate the introduced technique/toolkit as a scholarly contribution. For example, what are the existing visualisation and dashboarding methods, how does the technique/toolkit go beyond them, and how is the experimental setup of the paper justifiable in connection with other similar studies? \n\nSome more careful attention to detail is needed to perfect the paper. I found some typos (e.g., evalaute), missing punctuation marks (e.g., in equations), and incomplete/inconsistently formatted references (e.g., OpenAI. Introducing chatgpt, 2023. URL https://openai.com/blog/chatgpt). Also, text in some images is too small to read (e.g., Fig. 2 and 5)."
                },
                "questions": {
                    "value": "What are the existing visualisation and dashboarding methods?\n\nHow does the technique/toolkit go beyond them?\n\nHow is the experimental setup of the paper justifiable in connection with other similar studies?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698761219836,
            "cdate": 1698761219836,
            "tmdate": 1699636969407,
            "mdate": 1699636969407,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "PFWtMVuFPw",
            "forum": "8ayoKVFmxp",
            "replyto": "8ayoKVFmxp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7901/Reviewer_BTXw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7901/Reviewer_BTXw"
            ],
            "content": {
                "summary": {
                    "value": "This work proposes the idea of \u201cquality over quantity\u201d and designs a pipeline to analyze the quantitative results of LLMs and visualize the results with human-readable information. The empirical study shows the visualization and human-readable information can provide insights for developers to improve model performance further."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The research question of this work is important. If there is a way to go beyond quantitative results and provide insights of model performance, it will certainly reduce human effort on model analysis and improvement"
                },
                "weaknesses": {
                    "value": "The description of the pipeline is either ambiguous or problematic, and I have questions for basically every component described in section 2.2 \n\n- About attribute discovery\n    - What is the definition of \u201cdomain\u201d and \u201csub-task\u201d, what is the difference between these two, and why these two are both called \u201cattributes\u201d?\n    - While prompting LLM to list attributes, how do we know the results are reasonable and reliable? In other words, if we change the prompt a little bit, will we get different results? If the answer is yes, then how should we trust these results?\n    - Given the procedure of iteratively getting more attributes, it sounds like there is a pre-defined number of attributes that we would like to get. Then, how to select this number? Does it depend any the specific dataset or task?\n- About attribute assignment\n    - Why two domains and sub-tasks for each instance? What do you mean by \u201cconcrete insights\u201d? Are they the same \u201cinsights\u201d that will later be generated by LLMs?\n    - How to define the prior probability of an attribute?\n    - I am not sure I understand this statement \u201cTo accommodate for the noisiness in an automated method, we make the prior probability constraint flexible by adding some slack \u2026\u201d\n- About measuring sub-task skill alignment\n    - Where we get the sub-tasks of the model prediction unless the model is working in a way that is similar to the chain of thoughts. However, this is unclear from the paper.\n- About insight generation\n    - I am seriously concerned about the reliability of generated \u201cinsights\u201d. First of all, it is not clear to me what can be called an insight. Second, if this is similar to a summarization task, is hallucination an issue here, or is it not a problem at all?"
                },
                "questions": {
                    "value": "Please refer to the previous section"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "1: strong reject"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698814623950,
            "cdate": 1698814623950,
            "tmdate": 1699636969281,
            "mdate": 1699636969281,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "TIoMBFMcYQ",
            "forum": "8ayoKVFmxp",
            "replyto": "8ayoKVFmxp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7901/Reviewer_2Tzm"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7901/Reviewer_2Tzm"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a qualitative evaluation framework, called QUALEVAL, to better understand 1) different subtasks and domains in a training or a validation sets, and 2) how LLMs perform on them. Insights from these analysis can help improve 1) finetuning with additional data for tasks/domains where models were underperforming, or 2) few-shot prompts targeting examples from those domains. The paper demonstrates the efficacy of their framework on three datasets. \n\n\nIt is not clear whether or not the authors plan to release the code or the framework from this work."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "QualEval clearly provides a more insightful analysis of the model performance on an eval set, rather than quantitative metrics such as Bleu or Rouge.\n\n\nIf the code/framework is made available, I can clearly see that the users will benefit from using this to automate the adaptation of LLMs for their usecases."
                },
                "weaknesses": {
                    "value": "First of all, it is not clear whether or not the authors plan to release the code or the framework from this work.\n\nAs mentioned earlier, I believe that the framework will be valuable to analyze LLMs\u2019 performance on a certain usecase and use the insights to better adapt them. However, I am afraid that the paper might not be a good fit for ICLR. Some of the findings that the model performance will improve with targeted in-context examples or finetuning data are not surprising and have been demonstrated before. \n\nAlso different eval sets annotated with ground truths are used to investigate LLMs performance. And then the same set is used to report the improvements which are not surprising as we are optimizing for these evalsets. I would be careful when referring to these improvements as model improvements, rather, we are adapting our models to do better on known use cases."
                },
                "questions": {
                    "value": "Please see my comments in the Weakness section. Please address them if possible.\n\nFor the prompts in Figure 8 and 9, how much expert knowledge and prompt engineering are required? Is the framework flexible to allow such interventions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7901/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699401249507,
            "cdate": 1699401249507,
            "tmdate": 1699636969164,
            "mdate": 1699636969164,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "COPT5TMn4N",
            "forum": "8ayoKVFmxp",
            "replyto": "8ayoKVFmxp",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7901/Reviewer_hZVP"
            ],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7901/Reviewer_hZVP"
            ],
            "content": {
                "title": {
                    "value": "Summary"
                },
                "comment": {
                    "value": "Based on the received reviews and having not received author response, I cannot support accepting the paper. I do not see a reason to revise my original review either."
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7901/-/Official_Comment"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1700440056759,
            "cdate": 1700440056759,
            "tmdate": 1700440056759,
            "mdate": 1700440056759,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]