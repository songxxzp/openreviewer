[
    {
        "title": "Find Your Optimal Assignments On-the-fly: A Holistic Framework for Clustered Federated Learning"
    },
    {
        "review": {
            "id": "kTJzh8axsr",
            "forum": "QJvUyuwjsf",
            "replyto": "QJvUyuwjsf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4329/Reviewer_fHet"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4329/Reviewer_fHet"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on a comprehensive investigation into current clustered federated learning methods and proposes a four-tier framework,  to encompass and extend existing approaches. Based on this method, the authors identify the remaining challenges associated with current clustering methods in each tier and propose an enhanced clustering method to address these problems."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper is well-written and easy to follow.\n\n2. The algorithm derivation looks correct for the proposed method."
                },
                "weaknesses": {
                    "value": "1. The proposed method doesn't really have the convergence guarantee. The paper only discusses a simple case in proof.\n\n2. The proposed method could be sensitive the initialization. The clustering and EM algorithms could easily stuck at bad local solution.\n\n3. The experiments only compared the proposed method to other clustered federated learning approaches. But many other models have been proposed to address the heterogeneity problem."
                },
                "questions": {
                    "value": "Please address the issues listed in weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4329/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698644567173,
            "cdate": 1698644567173,
            "tmdate": 1699636403395,
            "mdate": 1699636403395,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "2XymusXWwF",
            "forum": "QJvUyuwjsf",
            "replyto": "QJvUyuwjsf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4329/Reviewer_8sHW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4329/Reviewer_8sHW"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a generic algorithm, termed HCFL, which is based on combining specific design choices for four tiers. The authors then discuss challenges associated with HFCL and proposes an improvement termed HCFL+."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Authors propose a generic formulation that unifies many different clustering methods. I also appreciate the discussion of specific challenges for the basic framework."
                },
                "weaknesses": {
                    "value": "* The significance/novelty of the proposed 4 tier framework is unclear. The definition of the four tiers seems somewhat arbitrary. Can you show that HCFL or HCFL+ is optimal in some relevant settings. One way to verrify optimality is e.g. by comparing the estimation error with minimax bounds (see [Ref1] for an implementation of this technique for studying optimality of dictionary learning methods) \n\n* There is little analysis of the computational and statistical properties of the proposed methods. How quickly do the iterations of Algorithm 1 converge to solutions of Eq. (1). Under shich conditions are the learnt model parameters clustered according to a ground-truth partition (see [Ref2] for an analysis of the clustering structure delivered by Total Variation minimization methods) \n\n[Ref1] A. Jung, Y. C. Eldar and N. G\u00f6rtz, \"On the Minimax Risk of Dictionary Learning,\" in IEEE Transactions on Information Theory, vol. 62, no. 3, pp. 1501-1515, March 2016, doi: 10.1109/TIT.2016.2517006.\n\n[Ref2] Y. SarcheshmehPour, Y. Tian, L. Zhang and A. Jung, \"Clustered Federated Learning via Generalized Total Variation Minimization,\" in IEEE Transactions on Signal Processing, doi: 10.1109/TSP.2023.3322848."
                },
                "questions": {
                    "value": "* \"...we aim to introduce a more interpretable approach here..\" why is this approach more interpretable ? \n\n* Would it be possible to formulate precise probabilistic models for the observed data such that the challenges in Sec. 4.1. are present ?\n\n* Does the optimization formulation (1) also include total variation based approaches to clustered federated learning, such as [Ref2] and \n\n[Ref3] David Hallac, Jure Leskovec, and Stephen Boyd. 2015. Network Lasso: Clustering and Optimization in Large Graphs. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '15). Association for Computing Machinery, New York, NY, USA, 387\u2013396. https://doi.org/10.1145/2783258.2783313"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4329/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698685845981,
            "cdate": 1698685845981,
            "tmdate": 1699636403320,
            "mdate": 1699636403320,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "xOBNZXahku",
            "forum": "QJvUyuwjsf",
            "replyto": "QJvUyuwjsf",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4329/Reviewer_PAju"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4329/Reviewer_PAju"
            ],
            "content": {
                "summary": {
                    "value": "The paper combines and applies various existing clustering methods for federated learning under non-iid setting. The two main objectives are to determine (1) (hard and soft) cluster assignments for clients, and (2) number of clusters. The paper uses the terminology *tiers* to organize these two main objectives."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Explores the idea of clustering for federated learning, which is a viable approach in non-iid or concept drift data situations.\n2. Provides some ablation studies."
                },
                "weaknesses": {
                    "value": "1. Novelty is incremental (combines various existing clustering methods with additional parameters to optimize)\n2. Not clear on how the proposed method scales.\n3. Paper needs better organization. Notation not clearly explained.\n4. Experiments in paper limited to vision datasets. More impact if evaluated on others such as Reddit or Stackoverflow."
                },
                "questions": {
                    "value": "The paper mentions using 100 clients for experiments. However, it is not clear on what the client participation percentage rate is. How many trials were used to determine $\\pm$ information? Roughly, how long (running time) does each communication round take?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4329/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699146289823,
            "cdate": 1699146289823,
            "tmdate": 1699636403010,
            "mdate": 1699636403010,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]