[
    {
        "title": "Unsupervised Federated Graph Matching with Graphlet Feature Extraction and Separate Trust Region"
    },
    {
        "review": {
            "id": "XSqInxzgaJ",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8315/Reviewer_3NNH"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8315/Reviewer_3NNH"
            ],
            "forum": "kVj2uyytyg",
            "replyto": "kVj2uyytyg",
            "content": {
                "summary": {
                    "value": "This paper proposes a method for unsupervised federated graph matching, i.e. matching node pairs that correspond to the same entity across different networks. The authors focus on the unsupervised setting in that it complies better with the privacy requirement. To address the problem of no ground truth matched pairs, the authors compute graphlet degree vectors of each node and use it to match cross network nodes. In addition, to ensure that clients do not know the matching information, the authors design a separate trust region algorithm, such that servers know the matching but does not know embeddings, and for clients vice versa. Some acceleration techniques are used to speedup the computation of Hessians (used in the trust region algorithm) and graphlet degree sampling. \n\nExperiments are done over real-world network pairs, where the proposed method outperforms various FGL baselines. Parameter analysis experiments are also done."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The studied problem is new, novel and challenging. Graph node matching is an important task, and when it is put in federated learning, the authors made a good observation that supervised methods may compromise privacy. The observation is valid, and thus the studied problem, unsupervised federated graph matching, is of good practical value. \n\n2. The design is also reasonable and practical. To ensure that the pseudo-matching information is not disclosed to clients, the authors design a separate trust region algorithm to split optimizations between client and server. Also, some acceleration techniques are proposed with theoretical results (although I did not thoroughly check their correctness). \n\n3. The paper is well organized and states its design rationale in a clear manner. I have no problem following the paper. \n\n4. Experiments are extensive considering the fact that the work does not have many baselines. The results are promising."
                },
                "weaknesses": {
                    "value": "1. Despite the promising result, I have some questions regarding the fundamental assumption of this paper. The assumption is that, nodes across networks with similar graphlet degree vectors are likely to be the same nodes. However, as graph structures are different in different networks, it may well happen that a node's structure changes a lot, e.g. an author who changes his main research focus. Thus, I would like to know how accurate the assumption is. Maybe the authors can provide some numbers to show. \n\n2. I wonder whether a split-learning technique can achieve the goal of the separate trust region algorithm. From my understanding, the separate trust region algorithm is designed so that the pseudo matchings are kept at servers and not exposed to clients. This may well be achieved with some kind of split learning, where clients maintain their graph feature encoders, and a matching unit is trained at the server with the pseudo labels. In this case, there would be even no requirement of the Hessian matrices. Can the authors justify the necessity of using the separate trust region algorithm and the Hessian? \n\n3. I wonder what the effect is of the number of pseudo labels to the overall algorithm. Intuitively, this seems like a tradeoff, as when you include more pseudo labels, they tend to be less accurate and bring noise to the overall learning. I would like to see a result of such tradeoff.\n\n4. I also wonder what are the effects of the monte-carlo markov chain sampling methods and the quasi-Newton methods on the overall method runtime/efficiency. The authors made no experiments to analyze the effectiveness either design. \n\n5. It seems that the loss function is operated on the 'encrypted' embeddings $\\hat{v}$ instead of $v$. At this time, a normal non-singular matrix $K$ may just twist some dimensions of the vectors, while shrink some other dimensions. Or in other worlds, a normal non-singular matrix $K$ does not preserve distance (which is exactly the loss function). Thus, how does the loss work on encrypted vector embeddings when they are applied a transformation that does not maintain distance is a little beyond me. Do you need orthogonal ones (those that maintain distance)?"
                },
                "questions": {
                    "value": "Q1. How accurate are the pseudo labels from graphlet degrees? \n\nQ2. How necessary is the Hessian matrix? What if we use some sort of split learning? \n\nQ3: What is the effect of the number of pseudo labels?\n\nQ4: What are the effects of the MCMC and the quasi-Newton method on the overall efficiency?\n\nQ5: Does a random non-singular method suffice in privacy-preservation and loss computation? Or do we need an orthogonal one?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8315/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8315/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8315/Reviewer_3NNH"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8315/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697140513783,
            "cdate": 1697140513783,
            "tmdate": 1700680715568,
            "mdate": 1700680715568,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "w4DM0enu6z",
                "forum": "kVj2uyytyg",
                "replyto": "XSqInxzgaJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-by-point response to the comments made by Reviewer 3NNH"
                    },
                    "comment": {
                        "value": "We thank this reviewer for the great suggestion! \n\n**Weakness 1:** Despite the promising result, I have some questions regarding the fundamental assumption of this paper. The assumption is that, nodes across networks with similar graphlet degree vectors are likely to be the same nodes. However, as graph structures are different in different networks, it may well happen that a node's structure changes a lot, e.g. an author who changes his main research focus. Thus, I would like to know how accurate the assumption is. Maybe the authors can provide some numbers to show.\n\n**Answer:** Thanks for the constructive comments. \nA graphlet is a small graph of size up to $k$ nodes of a larger graph, such as triangle, wedge, or $k$-clique, which describes the local topology of a larger graph.\nA node's local topology can be measured by a graphlet feature vector, where each component denotes the frequency of one type of graphlets. Thus, a graphlet feature vector is one of node structure representation (Shervashidze et al., 2009; Kondor et al., 2009; Soufiani \\& Airoldi, 2012; Jin et al., 2018; Tu et al., 2019). \nBased on structure, attribute, or embedding features, existing graph matching efforts often choose the node pairs with the smallest distances or largest similarities across the graphs are selected as the matching results (Man et al., 2016; Zhou et al., 2018a; Yasar \\& Catalyurek, 2018; Li et al., 2019b;a; Chu et al., 2019; Fey et al., 2020).\nThis submission just follows this mainstream strategy for structure-based graph matching to conduct graph matching based on the graphlet features.\nThis work explores a general solution of federated graph matching for addressing the most common graph matching question: structure-based graph matching without considering other types of features.\n\nFor the case of the graphs with quite different structures, a popular method is to combine other types of features to alleviate the structure inconsistency issue, say attribute-based graph matching. When other types of features are similar with only dissimilar structure, it is still possible that two copies of the same nodes in different graphs are still most similar to each other and can be identified as the matching results, as long as more other features are integrated or by reducing the weight of structure features.\n\n\n\n\n**Weakness 2 / Question 2:** I wonder whether a split-learning technique can achieve the goal of the separate trust region algorithm. From my understanding, the separate trust region algorithm is designed so that the pseudo matchings are kept at servers and not exposed to clients. This may well be achieved with some kind of split learning, where clients maintain their graph feature encoders, and a matching unit is trained at the server with the pseudo labels. In this case, there would be even no requirement of the Hessian matrices. Can the authors justify the necessity of using the separate trust region algorithm and the Hessian?\n\nHow necessary is the Hessian matrix? What if we use some sort of split learning?\n\n**Answer:** Thanks for the kind suggestion. \nThe time complexity of multiple graph matching typically increases exponentially with the number of graphs to be matched. If we choose to conduct both evaluation and optimization of the graph matching model at the server, then the computational capability of each client are idle. This will dramatically degrade the algorithm efficiency, especially large-scale graph matching is often time-consuming.\n\nThus, we separate model optimization from model evaluation in the trust region algorithm: (1) the server aggregates the local model parameter on each client into a global model parameter, runs and evaluates the global parameter, and computes the individual loss and the first-order gradient for each client; (2) each client computes the second-order Hessian and optimizes the local model.\nThe reason of using the second-order Hessian in the trust region algorithm is that the second-order Hessian can provide fast convergence in terms of number of training steps.\nThe second-order Hessian computation and the local model optimization are most compute-intensive over large graphs. Thus, we move these two operations to the clients for making full use of the computational capability of each client to improve the efficiency, while maintaining the privacy constraints."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646155485,
                "cdate": 1700646155485,
                "tmdate": 1700646155485,
                "mdate": 1700646155485,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "L5fiMItow5",
                "forum": "kVj2uyytyg",
                "replyto": "XSqInxzgaJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Reviewer_3NNH"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Reviewer_3NNH"
                ],
                "content": {
                    "title": {
                        "value": "Response acknowledged."
                    },
                    "comment": {
                        "value": "I have read the author response and find that they provide necessary information for me to answer my questions. \n\nI find that most of my questions are well answered. I am willing to recommend a weak accept at this point. \n\nI am still not fully convinced that split learning cannot do the job. As the authors say, the proposed method can utilize client side computation resources, but in the meantime, extra computation of Hessian is involved. Thus I still think that a well-designed split learning can achieve the goal without needing to compute Hessian. Yet this is just a minor question about the design choice, rather than the method itself."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700680695076,
                "cdate": 1700680695076,
                "tmdate": 1700688228810,
                "mdate": 1700688228810,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "6vhbofSunb",
            "forum": "kVj2uyytyg",
            "replyto": "kVj2uyytyg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8315/Reviewer_SCKR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8315/Reviewer_SCKR"
            ],
            "content": {
                "summary": {
                    "value": "This paper is the first unsupervised federated graph matching solution for inferring matched node pairs on different graphs across clients while maintaining the privacy requirement of federated learning. The technical contributions of this work are very extensive/impressive. A key to the federated graph matching method is to secure data privacy. It proposes the data encryption and unsupervised learning to provide strong privacy protection. To enhance the matching quality, it develops the graphlet feature extraction and separate trust region for pseudo supervised learning for the problem of federated graph matching. Both theoretical and experimental analyses are shown to demonstrate the computation effectiveness of the proposed method. The paper is well-organized, contains enough information in a limited number of pages, and is easy to understand."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "1.\tSolving the graph matching problem in the environment of federated learning is of great importance in social networks and financial crime detection.\n2.\tThe paper is the first to explore the potential of introducing federated learning to graph matching.\n3.\tTheoretical analysis about graphlet estimation and separate trust region within this work is novel and requires numerous technical developments.\n4.\tThe experiments in the paper are extensive and convincing. The experimental results justify the effectiveness of the proposed method.\n5.\tThe paper evaluates both centralized and federated variants of the method and most of federated results achieve comparable results to centralized baselines."
                },
                "weaknesses": {
                    "value": "1.\tThe scale of the experiment is a bit small. What will the performance look like on large-scale dataset?\n2.\tAnother concern is the benchmark comparison. Authors claim it is the first algorithm for federate graph matching, so it is better to emphasize how innovative compared with peer works.\n3.\tA minor issue is that the small font in the figure legend decreases the paper's readability."
                },
                "questions": {
                    "value": "Scalability test and more discussions."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8315/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698739542821,
            "cdate": 1698739542821,
            "tmdate": 1699637034220,
            "mdate": 1699637034220,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Pg3N3orhqg",
                "forum": "kVj2uyytyg",
                "replyto": "6vhbofSunb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-by-point response to the comments made by Reviewer SCKR"
                    },
                    "comment": {
                        "value": "We thank this reviewer for the encouraging comments. We are delighted to hear your positive comments on our contribution to the valuable research problem with significant real-world applications, such as financial crime detection, and the technical novelties in the FGM. The core requirement of FL is the privacy protection. The paper proposed model graphlet feature extraction and separate trust region optimization  and combine two techniques into a unified UFGM model. The proposed method capture nodes' graphlet features to generate pseudo matched node pairs on different graphs across clients as the pseudo training data for leveraging the strength of supervised graph matching  for improving the algorithm effectiveness. On the other hand, the combination of the unsupervised FGM and the encryption of local raw graph data is able to provide strong privacy protection for sensitive local data. In addition, the separate trust region for pseudo supervised FGM is helpful to enhance the efficiency while maintaining the privacy constraints.\n\n**Weakness 1:** The scale of the experiment is a bit small. What will the performance look like on large-scale dataset?\n\n**Answer**: Thanks for your great comments. In the appendix, in order to validate the scalability of our UFGM method for the problem of unsupervised federated graph matching on large-scale datasets, we selected and split the original DBLP dataset into 20 graphs by publication year, ranging from 2002-2022, such that each graph has around 100,000 and 200,000 authors as nodes and coauthor relationships as edges respectively. We have reported the $Hits@K$ scores in Table 5. The experiment results exhibit that our UFGM method scales well on different datasets . This demonstrates that our UFGM method is scalable for addressing the problem of unsupervised federated graph matching, while maintaining the privacy requirement of FL.\n\n**Weakness 2:** Another concern is the benchmark comparison. Authors claim it is the first algorithm for federate graph matching, so it is better to emphasize how innovative compared with peer works.\n\n**Answer**: Graph matching (i.e., network alignment) is one of the most important research topics in the graph domain, which aims to match the same entities (i.e., nodes) across two or more graphs. There is still a paucity of techniques of effective federated graph matching (FGM), which is much more difficult to study and has many real applications, such as user account linking in different social networks and financial crime detection. However, directly sharing and inferring matched node pairs on different graphs across clients and local graphs over multiple clients gives rise to a serious privacy leakage concern, which is the motivation of this work, compared with centralized graph matching methods.\n\nTo our best knowledge, this work is the first to offer an unsupervised federated graph matching solution for inferring matched node pairs on different graphs across clients while maintaining the privacy requirement of FL, by leveraging the graphlet theory and trust region optimization. Our UFGM method exhibits three compelling advantages: (1) The combination of the unsupervised FGM and the encryption of local raw graph data is able to provide strong privacy protection for sensitive local data; (2) The graphlet feature extraction can leverage the strength of supervised graph matching with the pseudo training data for improving the matching quality; and (3) The separate trust region for pseudo supervised FGM is helpful to enhance the efficiency while maintaining the privacy constraints."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700645827750,
                "cdate": 1700645827750,
                "tmdate": 1700645827750,
                "mdate": 1700645827750,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5BdD5THMJg",
                "forum": "kVj2uyytyg",
                "replyto": "Pg3N3orhqg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Reviewer_SCKR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Reviewer_SCKR"
                ],
                "content": {
                    "title": {
                        "value": "Official Comments by Reviewers"
                    },
                    "comment": {
                        "value": "The reviewer would like to thank the authors for their detailed responses. Most of my concerns have been addressed, therefore I will keep my original score and vote for the acceptance."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700649007346,
                "cdate": 1700649007346,
                "tmdate": 1700649007346,
                "mdate": 1700649007346,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Bbf0iQFnWS",
            "forum": "kVj2uyytyg",
            "replyto": "kVj2uyytyg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8315/Reviewer_TsnJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8315/Reviewer_TsnJ"
            ],
            "content": {
                "summary": {
                    "value": "This manuscript works on the first federated learning mechanism for graph matching with privacy maintainance that supports effective and efficient graph matching at the client and server level, by designing a fast approximate method for graphlet feature extraction for pseudo supervised learning, and by combining separate trust region algorithm with data encryption that satisfy with the privacy requirement of the federated learning. Specifically, the new method samples a small number of graphlets to capture graphlet features of each node as pseudo training data. At last, the method separates model optimization from model evaluation in the federated learning. In the empirical studies, results show it can achieve better performance than all federated learning baselines in all tests and obtain close or better performance than centralized graph matching method."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "+Using graphlet feature extraction to generate pseudo training data is helpful to maintain the privacy constraint in the federated learning as well as leaverage the power of supervised learning for better quality.\n\n+The incorporation of separate trust region into the federated learning algorithm for graph matching is interesting. The fact that convergence is also achieved in theory is well-done.\n\n+The theoretical analysis of the approximation error and the convergence analysis seems novel and interesting. These theoretical resluts guranttee the effectiveness of federated graph matching in the context of unsupervised learning.\n\n+The proposed task is well-motivated, the experiment result is promising, and the authors compare several different types of baselines to validate the superior performance of the proposed techniques."
                },
                "weaknesses": {
                    "value": "-It seems the scope of the proposed method is specific as it seems to only be designed for federated graph matching. I wonder how hard it will be to generalize the proposed method to general federated learning.\n\n-I can understand the limitations on the experimental side, however, it would be great to hear from authors regarding how the performance of the centralized variant of the proposed federated graph matching approach (i.e., no federated learning)? Does this approach have much better performance?\n\n-Experiment figures are hard to follow due to small font size."
                },
                "questions": {
                    "value": "See the weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8315/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698855823024,
            "cdate": 1698855823024,
            "tmdate": 1699637034110,
            "mdate": 1699637034110,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UsTC7o9pP3",
                "forum": "kVj2uyytyg",
                "replyto": "Bbf0iQFnWS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-by-point response to the comments made by Reviewer TsnJ"
                    },
                    "comment": {
                        "value": "We thank this reviewer for the helpful comments. We are delighted to hear your positive comments on our contribution to the unsupervised federated graph matching with privacy preservation and good performance. Following your precise assessment, we believe that our work makes a solid step to offer an unsupervised federated graph matching solution for inferring matched node pairs on different graphs across clients while maintaining the privacy requirement of federated learning. We also want to remark that the utilization of the pseudo supervised FGM is able to significantly improve the performance of FGM models. \n\n**Weaknesses 1:** It seems the scope of the proposed method is specific as it seems to only be designed for federated graph matching. I wonder how hard it will be to generalize the proposed method to general federated learning.\n\n**Answer**: Thanks for your helpful comments. Different from the FL for computer vision and other graph learning tasks, such as image classification and graph classification, where the data on a client are often independent of the data on another client and stochastic gradient descent (SGD) optimization can be used to evaluate and optimize the local FL models without the need of accessing the data on other clients. However, graph matching aims to match the same entities (i.e., nodes) across two or more graphs. Thus, the FGM needs to infer matched node pairs on different graphs across clients. Directly accessing and sharing local graphs over multiple clients gives rise to a serious privacy leakage concern.\nTherefore, the SGD optimization widely used in deep learning and FL fails to work on the clients in the FGM, since each client can access only its own local graph data and thus cannot update local loss based on the pseudo matched node pairs. We propose a separate trust region algorithm to separate local model optimization from model evaluation in the trust region algorithm for pseudo supervised FGM while maintaining the privacy constraints.\n\n**Weaknesses 2:** I can understand the limitations on the experimental side, however, it would be great to hear from authors regarding how the performance of the centralized variant of the proposed federated graph matching approach (i.e., no federated learning)? Does this approach have much better performance?\n\n**Answer**: Thanks for the kind suggestion. In the appendix, we evaluate two versions of UFGM to show the strength of our UFGM method for federated graph matching. UFGM is the federated version with graph data encryption, graphlet feature extraction, model evaluation on the server, model optimization with the trust region on the clients, and Hessian approximation. UFGM-C is the centralized version with raw graph data uploaded to the server, graphlet feature extraction, model evaluation and model optimization with the standard stochastic gradient descent on the server. The experiment results in Table 4 exhibit that the performance of the centralized version, UFGM-C, is close to our federated version, UFGM, over all three datasets. This further validates that our UFGM algorithm can achieve superior performance for the federated graph matching.\nIn addition, the performance of our UFGM-C method is close to (NextAlign, NetTrans, and SeedGNN) or better than (CPUGA, ASAR-GM, and SIGMA) among six centralized graph matching methods. Notice that NextAlign, NetTrans, and SeedGNN are semi-supervised or supervised methods with 20\\% training data."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700645635586,
                "cdate": 1700645635586,
                "tmdate": 1700645635586,
                "mdate": 1700645635586,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "eReIrGyzYP",
            "forum": "kVj2uyytyg",
            "replyto": "kVj2uyytyg",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8315/Reviewer_D7Az"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8315/Reviewer_D7Az"
            ],
            "content": {
                "summary": {
                    "value": "The paper works on unsupervised federated graph matching. It proposes UFGM, where clients first train locally, then send encrypted node embeddings to the central server for aggregation. Theoretical analysis shows it can maintain good performance without expensive costs. Experiments show its performance."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The proposed method can solve such federated unsupervised graph matching problems.\n2. Theoretical analysis is provided.\n3. Experiments show its performance."
                },
                "weaknesses": {
                    "value": "1. The challenges and applications of applying federated training on unsupervised graph matching are not clear.\n2. The technical advancement of the method is unclear. Traditional graph-matching algorithms with encrypted aggregation on the server side can solve such a problem. Such encryption can be a huge computation and communication cost during training.\n3. The algorithm comparison is unreasonable. There is an unreasonable number of comparison methods. All these federated methods are used for supervised training and should not be compared methods with unsupervised training."
                },
                "questions": {
                    "value": "1. What is the key takeaway of the theoretical analysis? Can it guide the experiments?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission8315/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission8315/Reviewer_D7Az",
                        "ICLR.cc/2024/Conference/Submission8315/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8315/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698899630451,
            "cdate": 1698899630451,
            "tmdate": 1700777511515,
            "mdate": 1700777511515,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gtEegIIsfI",
                "forum": "kVj2uyytyg",
                "replyto": "eReIrGyzYP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Point-by-point response to the comments made by Reviewer D7Az"
                    },
                    "comment": {
                        "value": "We thank this reviewer for the constructive comments.\n\n**Weakness 1:** The challenges and applications of applying federated training on unsupervised graph matching are not clear.\n\n**Answer:** Thanks for the thoughtful comment. Since FedAvg was proposed by Google in 2017 [1], federated learning (FL) has been a hot research topic in the field of machine learning.\nWith the increasing regulation restrictions, user concerns, and commercial competition, the government agencies limit data collection and the users are not willing to share the data.\nThe original intention of FL proposed by Google is to reduce privacy and security risks by limiting the attack surface to only the device, rather than the device and the cloud [1]. \nFederated graph learning (FGL) has led to state-of-the-art innovations in various applications, such as node classification, graph classification, network embedding, and link prediction. There is still a paucity of techniques of effective federated graph matching (FGM), which is much more difficult to study.\n\nA good real-world application of FGM is that financial crime detection on transaction networks with millions to billions of bank customers and transactions [2-4]. Data exchange among clients and server about sensitive bank customer and transfer data should be limited for privacy risks.\nEspecially, US and UK governments launched a privacy-enhancing technology (PET) challenge about federated learning for financial crime detection in July 2022 [5,6]. The dataset contains SWIFT transfer data between bank accounts and individual bank account transaction data. Frequent interbank transactions between the same or affiliated entities may be potential money laundering activities.\nAnother real application is user account linking in different networks, since the user information contain many sensitive information. Directly collecting and uploading the raw user data to the server for centralized graph matching (CGM) gives rise to a serious privacy concern.\n\n[1] Communication-Efficient Learning of Deep Networks from Decentralized Data. AISTATS 2017.\n\n[2] Towards federated graph learning for collaborative financial crimes detection. CoRR, abs/1909.12946, 2019.\n\n[3] A semi-supervised graph attentive network for financial fraud detection. ICDM 2019.\n\n[4] Federated graph learning - A position paper. CoRR, abs/2105.11099, 2021.\n\n[5] https://research.ibm.com/blog/privacy-preserving-federated-learning-finance\n\n[6] https://www.drivendata.org/competitions/group/nist-federated-learning/\n\nThe unsupervised graph matching fails to employ the strength of training data and thus often leads to sub-optimal solutions, compared with supervised graph matching. However, the latter using the pre-matched node pairs as the training data is improper for the FGM scenarios due to privacy risks of direct cross-graph information exchange. \n\nThus, we propose to capture nodes' graphlet features to generate pseudo matched node pairs on different graphs across clients as the pseudo training data for leveraging the strength of supervised graph matching and improving the quality of unsupervised graph matching.\nHowever, graphlet enumeration one by one on large graphs is impossible due to expensive cost. We propose to leverage Monte Carlo Markov Chain (MCMC) technique for sampling a small number of graphlets. \n\nStochastic gradient descent (SGD) optimization widely used in deep learning fails to work on the clients in the FGM, since each client can access only its own local graph data and thus cannot update local loss based on the pseudo matched node pairs.\nWe propose a separate trust region algorithm for pseudo supervised FGM while maintaining the privacy constraints.\nWe separate model optimization from model evaluation in the trust region algorithm: (1) the server aggregates the local model parameter on each client into a global model parameter, runs and evaluates the global parameter, and computes the individual loss and the first-order gradient for each client; (2) each client computes the second-order Hessian and optimizes the local model."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700645415729,
                "cdate": 1700645415729,
                "tmdate": 1700645415729,
                "mdate": 1700645415729,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vB2YfMaoDB",
                "forum": "kVj2uyytyg",
                "replyto": "eReIrGyzYP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Reviewer_D7Az"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Reviewer_D7Az"
                ],
                "content": {
                    "comment": {
                        "value": "I highly appreciate the point-by-point response!\n1. The example \u201cuser account linking in different networks, since the user information contains many sensitive information\u201d is reasonable for the motivation of federated graph matching.\n2. The MCMC for graphlet feature extraction and separate trust regions can definitely solve such a problem.\n\nHowever, my concern about experiments is not resolved.\n1. Could the authors elaborate more on why UFGM can be better than (semi)-supervised federated graph matching? Semi-supervised federated graph matching (eg. FL+NextAlign) should have the same accuracy as the centralized semi-supervised training by a few tricks (e.g. encrypts the node pairs). Could the authors elaborate more on how they run FedGraphNN, FKGE, SpreadGNN, SFL, FederatedScope-GNN, and FedStar?\n2. Minor thing about the ablation study: Is graphlet feature extraction+separate trust regions (UFGM) better than graphlet feature extraction+fedavg?\n\nI increase my rating from 3 to 4 since the theory is definitely complete."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700685928487,
                "cdate": 1700685928487,
                "tmdate": 1700685963791,
                "mdate": 1700685963791,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "jbl3SxE6IJ",
                "forum": "kVj2uyytyg",
                "replyto": "a7j1SQzNiw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Reviewer_D7Az"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Reviewer_D7Az"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the further clarification!\n\nAccording to \"We can obtain the node embeddings by all these baselines.\", how do these methods get such node embeddings? Is it just passing the local graph into a random GNN and getting such embedding? I would suggest author remove these baselines or clearly describe the implementation. The proposed method cannot directly compare with those methods. \n\nI would suggest author remove the statement that the unsupervised federated method can be better than the semi-supervised federated graph matching method (also there is no such method). It can be misleading for future researchers.\n\nI understand that the authors added those federated graph learning methods since there is no method for federated graph matching. I will lean to accept the paper if the authors remove those methods and those statements about supervised federated graph matching."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700710055135,
                "cdate": 1700710055135,
                "tmdate": 1700710055135,
                "mdate": 1700710055135,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "FLDBypWYeH",
                "forum": "kVj2uyytyg",
                "replyto": "eReIrGyzYP",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8315/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Post-rebuttal Comments"
                    },
                    "comment": {
                        "value": "Thanks for the consideration of our comments!\n\nIn previous versions of the submission, we use **federated graph learning** baselines to describe FedGraphNN, FKGE, SpreadGNN, SFL, FederatedScope-GNN, and FedStar, instead of term **federated graph matching**. Since these **federated graph learning** baselines are originally designed to address other graph learning tasks, such as node classification, graph classification, and network embedding., our UFGM achieves better performance than these **federated graph learning** baselines.\n\nIn the current version of the submission, we have re-drawn Figures 1-8, updated Tables 1-3, and 6, and modified the corresponding descriptions to remove all experiment results of these **federated graph learning** baselines and all the statements about them. In order to satisfy the ICLR requirement that reflects new changes to the revision against the original submission, we currently use strikethroughs to represent the contents to be removed. We will physically remove the contents with the strikethrough representation in this version into the next revision.\n\nThanks again for taking the time to review our submission!"
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8315/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700732483272,
                "cdate": 1700732483272,
                "tmdate": 1700732854896,
                "mdate": 1700732854896,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]