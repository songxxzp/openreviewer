[
    {
        "title": "Adversarial Feature Map Pruning for Backdoor"
    },
    {
        "review": {
            "id": "ew7KuBtYQN",
            "forum": "IOEEDkla96",
            "replyto": "IOEEDkla96",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7515/Reviewer_gATw"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7515/Reviewer_gATw"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes Adversarial Feature Map Pruning for Backdoor (FMP), a new method for backdoor mitigation in neural networks. FMR does not require access to the trigger or poisoned data. Based on a clean data sample, the method reverse-engineers poison triggers from each feature map in the model (at multiple layers) based on back-propagation. The weights determined to be connected to the triggers are reinitialized and fine-tuned on clean data. Experiments are performed on CIFAR-10, CIFAR-100 and GTSRB against a wide range of attacks and defenses."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper provides an extensive evaluation using the standard BackdoorBench benchmark, against multiple attacks and compared to multiple defenses.\n- The proposed FMT seems to perform well on average.\n- The source code was provided and is pledged to be available open-source upon paper acceptance."
                },
                "weaknesses": {
                    "value": "# Novelty and prior work\n\n- The novelty of the paper seems limited. The ideas of using adversarial examples to reverse engineer triggers (e.g., [ANP](https://arxiv.org/pdf/2110.14430.pdf), [AEVA](https://openreview.net/forum?id=OM_lYiHXiCL)) or pruning and retraining trigger weights ([RNP](https://proceedings.mlr.press/v202/li23v.html)) are not themselves novel. The paper does not cite most of these very close prior results and does not provide a conceptual comparison to them.\n- The prior art section mainly addresses defenses from different categories than the present one, which are then easy to dismiss. Outside the specific ideas used in FMT, there are many methods that address the same setup as the current paper and operate without knowledge of the trigger (e.g., [DeepInspect](https://www.ijcai.org/proceedings/2019/647), [TABOR](https://arxiv.org/pdf/1908.01763.pdf), [ABS](https://dl.acm.org/doi/10.1145/3319535.3363216), [[Fu et al., 2020](https://arxiv.org/pdf/2011.02526.pdf)]). These could be included in the experimental comparison.\n\n# Performance\n\n- Tab. 1 shows that the proposed method is only the best on average, but not doing so well on individual benchmarks (i.e., for each attack and dataset). The commentary section also fail to quantify how many benchmarks are actually won by the proposed method.\n\n# Clarity\n\n- Certain points in the paper are not clear, see also the questions below. Moreover, the components of the method are rather explained in an algorithm than in the text.\n- Assumptions should be clear earlier in the paper, e.g. the fact that a clean input sample is required.\n- The typography of the paper could be improved, please see some suggestions below. The paper could also use additional proofreading.\n- Tab. 1 is very dense and lacking highlights of the best values for each attack. As such, it is currently difficult to interpret.\n\n# Minor remarks\n\n- It is unclear why the feature maps are summed in the Notations paragraph (Sec. 3).\n- Some numerical results are typeset with spaces before the decimals (e.g., 2. 86%). These spaces should be removed\n- Consider using `\\citep` when the cited references are not part of the sentence (see [here](https://www.overleaf.com/learn/latex/Natbib_citation_styles))."
                },
                "questions": {
                    "value": "1. What is the distinction the paper makes between a neural network layer output and a feature map?\n2. What does it mean in Alg. 1 that `Correct_list` is sorted in ascending order? According to which criterion?\n3. Are all the weights of the model refined during the fine tuning step or just those detected as being part of backdoors (i.e., the weights that are reset to zero)?\n4. Why is the backdoor feature initialization done by setting weights to zero, instead of using the same initialization strategy as when training the model for the first time (i.e., various random sampling strategies)? Has this alternative been considered?\n5. What is the impact of varying method parameters $\\epsilon$ and $p$ under other attacks than BadNets?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7515/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698760800938,
            "cdate": 1698760800938,
            "tmdate": 1699636907521,
            "mdate": 1699636907521,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "gp1z2k2LmJ",
                "forum": "IOEEDkla96",
                "replyto": "ew7KuBtYQN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7515/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7515/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to Reveiwer gATw"
                    },
                    "comment": {
                        "value": "Thanks for the reviewer's comments on FMP.\n\nFor Q1, in DNN, each layer contains multiple channels, whereas in FMP, we define the feature map as a channel in the neural network layer.\n\nFor Q2, first, the correct_list can also represent the accuracy list of the deep neural network for different feature maps attacked by FRG. Next, once FRG is conducted, each feature map may have different accuracy. Our motivation is that in the backdoor model, once the backdoor trigger has been added to the input (the backdoor feature map reproduces the backdoor information with an adversarial attack), the DNN will have lower accuracy compared to attacking other feature maps. Then, we will ArgSort the correct_list and obtain the N/p feature maps that have lower accuracy on the left N/p (that's why we use ascending order).\n\nFor Q3 and Q4, all feature maps are fine-tuned (but only backdoor feature maps will be initially set to zero). To address the reviewer's concern about the training strategies, we evaluatedte how the initialization and tuning methods affect FMP's effectiveness in the table below:\n\n| Backdoor           | BadNets Acc | BadNets ASR | BadNets RA | Blended Acc | Blended ASR | Blended RA | Frequency Acc | Low Frequency ASR | Frequency RA | SSBA Acc | SSBA ASR | SSBA RA | WaNet Acc | WaNet ASR | WaNet RA |\n| ------------------ | ----------- | ----------- | ---------- | ----------- | ----------- | ---------- | ------------- | ----------------- | ------------ | -------- | -------- | ------- | --------- | --------- | -------- |\n| All\\_tuning        | 91.67       | 1.67        | 91.71      | 91.85       | 6.44        | 74.43      | 91.77         | 1.90              | 90.52        | 91.92    | 2.89     | 88.59   | 93.42     | 1.38      | 88.98    |\n| vulnerable feature map tuning               | 91.54       | 1.6         | 91.63      | 91.94       | 6.32        | 74.19      | 92.02         | 2.02              | 90.36        | 91.97    | 3.16     | 88.75   | 93.49     | 1.12      | 91.86    |\n| Zexavier\\_uniform  | 91.68       | 1.84        | 91.81      | 91.84       | 6.33        | 74.28      | 91.81         | 1.81              | 90.47        | 92.02    | 2.95     | 88.48   | 93.61     | 1.38      | 92.03    |\n| kaiming\\_uniform   | 91.62       | 1.56     | 91.71      | 91.7        | 6.3         | 74.54      | 91.75         | 1.95              | 90.55        | 91.78    | 2.88     | 88.44   | 93.41     | 1.34      | 92.13    |\n\n*Table 1: Performance comparison (%) of backdoor defense methods on CIFAR10, CIFAR100, and GTSRB datasets under PreActResNet18, under different attack strategies with a poison rate of 10% and retraining data ratio of 100%. We set the $\\epsilon$ to 1/255, and the $p$ is set to 64.*\n\nAnswer to Q5: Thanks for reviewer's concern for the $\\epsilon$ and $p$ under other attacks. \nTo address reviewer's concern, we conduct experiment for LowFrequency and WaNet with different $\\epsilon$ and $p$ in the following tables:\n| $\\epsilon$ | 1/255 | 4/255 | 16/255 |\n|------------|-------|-------|--------|\n| Acc        | 91.77 | 90.32 | 88.59  |\n| ASR        | 1.90  | 1.46  | 1.31   |\n| RA         | 90.52 | 90.17 | 89.10  |\n\n*Table 1: FMP's effectiveness under different $\\epsilon$ in CIFAR10 dataset under Low Frequency attack.*\n| $p$ | 4    | 16   | 64   |\n|-----|------|------|------|\n| Acc | 84.98| 89.41| 91.77|\n| ASR | 1.79 | 1.92 | 1.90 |\n| RA  | 83.27| 88.64| 90.52|\n\n*Table 2: FMP's effectiveness under different $p$ in CIFAR10 dataset under Low Frequency attack.*\n| $\\epsilon$ | 1/255 | 4/255 | 16/255 |\n|------------|-------|-------|--------|\n| Acc        | 93.42 | 91.07 | 89.78  |\n| ASR        | 1.38  | 1.35  | 1.39   |\n| RA         | 92.13 | 91.14 | 89.53  |\n\n*Table 3: FMP's effectiveness under different $\\epsilon$ in CIFAR10 dataset under WaNet attack.*\n| $p$ | 4    | 16   | 64   |\n|-----|------|------|------|\n| Acc | 86.17| 90.82| 93.42|\n| ASR | 1.64 | 1.81 | 1.38 |\n| RA  | 85.31| 89.87| 92.13|\n\n*Table 4: FMP's effectiveness under different $p$ in CIFAR10 dataset under WaNet attack.*\n\nWe canfind that in different $\\epsilon$ and $p$ configuration, FMP has same behaviors in BadNets. Hope these experiments can address reviewer's concern for the affect of hyper-parameters in our experiments.\n\nNotes: we will address all minor comments in our final version. For the provided related works, we will also add it in our final version."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7515/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699707223629,
                "cdate": 1699707223629,
                "tmdate": 1700652536504,
                "mdate": 1700652536504,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "cHj62m7OVk",
            "forum": "IOEEDkla96",
            "replyto": "IOEEDkla96",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7515/Reviewer_x3Nd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7515/Reviewer_x3Nd"
            ],
            "content": {
                "summary": {
                    "value": "In this manuscript, the authors propose a DNN pruning method called FMP to mitigate backdoors. While adding adversarial attacks to feature maps, their method prunes the features weak to the attacks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "I find this paper interesting. It's important to understand the relationship between pruning and backdoors, and the authors explored this in a systematic way."
                },
                "weaknesses": {
                    "value": "While reading the authors' method, it looks similar to Adversarial Neuron Pruning (ANP) by We and Wang (2021). However, the authors don't describe it in the related work, though they compare it with the proposed method in the result section. Discussing the methodological differences between them would help readers understand more."
                },
                "questions": {
                    "value": "When the authors have parametric variables in a table, it should be better to draw these results with figures."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7515/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7515/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7515/Reviewer_x3Nd"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7515/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698763250370,
            "cdate": 1698763250370,
            "tmdate": 1699636907406,
            "mdate": 1699636907406,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "bzjNCb5etC",
                "forum": "IOEEDkla96",
                "replyto": "cHj62m7OVk",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7515/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7515/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to reviewer x3Nd"
                    },
                    "comment": {
                        "value": "**Thanks for the reviewer's comments on FMP and ANP.**\n\nFirstly, as illustrated in Table 1 in the paper, it is evident that in the majority of experimental results, FMP consistently outperforms ANP. For instance, on average, FMP reduces the ASR from 68.27% to 2.86% in the CIFAR10 dataset. The key reasons for FMP achieving higher performance and the observed differences between FMP and ANP can be simply concluded that **FMP focuses on the feature map level, aligning with the backdoor trigger's focus on the DNN feature map, rather than specific neurons within the DNN~(e.g., ANP),** where we have added this to our revised paper now.\n\nsome other attributes can considered as the following aspects:\n\n**1. Feature Map Level Focus:**\n   - *FMP:* Concentrates on the feature map level, aligning with the backdoor trigger's focus on the DNN feature map, rather than specific neurons within the DNN.\n   - *ANP:* During the pruning procedure, ANP may only prune a subset of backdoor-related neurons within the backdoor feature map, potentially leaving some undetected. This results in a higher ASR after the defense procedure.\n\n**2. Extraction of Backdoor Trigger Information:**\n   - *FMP:* Aims to identify the backdoor feature map extractor/learner that captures backdoor trigger information.\n   - *FMP:* Utilizes each feature map to ascend the gradient and reproduce learned features. If the reproduced feature map is linked to the backdoor, there is a significant decrease in DNN prediction. Robust feature maps that are less influenced by the backdoor trigger are not pruned during the FMP pruning procedure.\n\n**On the other hand:**\n**1. Direct Perturbation of Neuron's Bias and Weights:**\n   - *ANP:* Directly perturbs the neuron's bias and weights, impacting both normal and backdoor-related neurons.\n   - *ANP:* Unlike FMP's focus on input sample perturbation, ANP's direct perturbation can cause neurons with a higher impact on DNN predictions to be represented as backdoor neurons. This may affect the backdoor neuron detector.\n   - *ANP:* If ANP attempts to protect these neurons (i.e., does not remove them), some backdoor neurons may also remain, leading to a higher ASR.\n\nIn summary, while both FMP and ANP aim to defend against backdoor attacks, FMP's emphasis on the feature map level and the specific way it reproduces learned features contribute to its higher performance compared to ANP in mitigating backdoor attacks, as observed in experimental results.\n\n\n**Q1: When the authors have parametric variables in a table, it should be better to draw these results with figures.**\nThanks for the reviewer's recommendation, we are now adding the figures to the **appendix**. Due to page limitations, we will reorganize it in our final version."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7515/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699687876929,
                "cdate": 1699687876929,
                "tmdate": 1700477958701,
                "mdate": 1700477958701,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qYmdAkxBpP",
                "forum": "IOEEDkla96",
                "replyto": "bzjNCb5etC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7515/Reviewer_x3Nd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7515/Reviewer_x3Nd"
                ],
                "content": {
                    "title": {
                        "value": "Responses to Authors"
                    },
                    "comment": {
                        "value": "I appreciate the responses from the authors. My concerns were addressed in the author's reply."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7515/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646550600,
                "cdate": 1700646550600,
                "tmdate": 1700646550600,
                "mdate": 1700646550600,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "65aVTdWkHA",
            "forum": "IOEEDkla96",
            "replyto": "IOEEDkla96",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7515/Reviewer_W4kG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7515/Reviewer_W4kG"
            ],
            "content": {
                "summary": {
                    "value": "This paper attempts to mitigate the backdoor model by generating all possible adversarial feature maps. Each generated adversarial feature map is fed to the model to test whether it will misclassify data samples, aiming to identify malicious feature maps that may be caused by a trigger. The innovation of the proposed algorithm lies in the fact that it does not require prior knowledge of the trigger pattern through reverse engineering, and it does not impose constraints on the trigger pattern size, as seen in other defense algorithms like Neural Cleanse. The proposed algorithm was evaluated on three datasets: CIFAR-10, CIFAR-100, and GTSRB."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe proposed algorithm is effective for large trigger backdoored models.\n2.\tThe proposed algorithm mitigates the backdoored model without the need for reverse engineering the trigger.\n3.\tIt has been evaluated on three datasets."
                },
                "weaknesses": {
                    "value": "1.\tThe presentation needs improvement as there are many confusing descriptions, referring to the Question section.\n2.\tThe three datasets appear to contain a relatively small number of classes. It would be more convincing if the algorithm could be evaluated on more complex datasets, such as ImageNet."
                },
                "questions": {
                    "value": "1.\tThere are several confusing descriptions. For instance, 'f' and 'F' represent the model and feature map, as described in the Notations section. However, in Section 3.2 and Algorithm 1, 'f' has a mixed meaning.\n2.\tShould the second 'for' loop in Algorithm 1 return '\\hat{x'}? Is that correct?\n3.\tThe logic of 'inference()' in Algorithm 1 appears to be incorrect. If a feature map does not change the classification of 'x,' it is a normal feature map and should be retained. However, in Algorithm 1, it is pruned. Why is this the case?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7515/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698817348111,
            "cdate": 1698817348111,
            "tmdate": 1699636907282,
            "mdate": 1699636907282,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wPUtIqfPoX",
                "forum": "IOEEDkla96",
                "replyto": "65aVTdWkHA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7515/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7515/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Answer to reviewer W4kG"
                    },
                    "comment": {
                        "value": "We deeply appreciate the feedback from Reviewer W4kG on our paper.\n\nWe have revised the paper for the comments provided by Reviewer W4kG.\n\nSpecifically:\n\nFor Q1: Thank you for pointing out the confusing descriptions in our paper. Specifically, both $F_{\\theta}^{i}$ and $f_{\\theta}^{i}$ refer to the i-th feature map in the DNN. We will replace $F_{\\theta}^{i}$ to $f_{\\theta}^{i}$ and clarify this in our final version.\n\nFor Q2: Regarding the returned FRG-generated adversarial sample $x'$, Reviewer W4kG can also consider it as $\\hat{x'}$, consistent with $\\hat{y}$ in Algorithm 1, line 8. We acknowledge the confusion caused by using $x$ in Algorithm 1, line 7.\nTo avoid misunderstanding, the our revised version, we use the $x'$, $y'$ to replace Algorithm 1, lines 7 and 8 now.\n\nFor Q3: Normal feature maps will not be pruned. To clarify, \"If a feature map does not change the classification of 'x,' is it a normal feature map and should be retained?\" is accurate. In other words, robust/normal feature maps will not be pruned, **meaning we will only prune feature maps with lower accuracy in the Correct\\_List.** This is why we use ascending order and then prune the left N/p feature maps.\n\nWe also acknowledge Reviewer W4kG's suggestion to conduct experiments on a more complex dataset, such as ImageNet. Unfortunately, due to the extended training time required for ImageNet, we can only provide experimental results on Tiny-ImageNet now. However, we commit to presenting results on ImageNet in our final version.\n\nThe experiment results are presented below:\n\n| Attack   | Benign ACC | Benign ASR | FP ACC | FP ASR | ANP ACC | ANP ASR | FMT ACC | FMT ASR |\n|----------|------------|------------|--------|--------|---------|---------|---------|---------|\n| BadNet   | 55.13      | 99.92      | 51.28  | 99.37  | 51.38   | 1.39    | 55.24   | 0.08    |\n| Blended  | 55.03      | 99.85      | 51.84  | 93.28  | 52.07   | 19.35   | 53.81   | 0.01    |\n| WaNet    | 54.73      | 99.32      | 52.17  | 65.32  | 51.09   | 8.92    | 53.54   | 1.37    |\n\nIt's noteworthy that FMT performs better than baseline approaches. For instance, in BadNet, FMT reduces the ASR from 1.39% to 0.08%.\n\nIf Reviewer W4kG has any questions, feel free to provide them, and we would be more than happy to address and clarify any queries or concerns."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7515/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699677886660,
                "cdate": 1699677886660,
                "tmdate": 1700314948040,
                "mdate": 1700314948040,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]