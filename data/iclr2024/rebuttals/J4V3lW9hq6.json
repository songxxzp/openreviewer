[
    {
        "title": "A Multi-Grained Group Symmetric Framework for Learning Protein-Ligand Binding Dynamics"
    },
    {
        "review": {
            "id": "wK83B8ad1Q",
            "forum": "J4V3lW9hq6",
            "replyto": "J4V3lW9hq6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3731/Reviewer_oR9H"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3731/Reviewer_oR9H"
            ],
            "content": {
                "summary": {
                    "value": "This paper aims to learn a 2nd order neural ODE which emulates molecular dynamics trajectories of ligand-protein interactions from the Misato dataset. The force prediction is done via a new architecture called BindingNet, which is based on 3 levels of frames (ligand, protein atom, protein residue) and which is claimed to be SE(3)-equivariant. The method is shown to be more accurate than diffusion-based next-step predictors and more stable than simulating the dynamics with a learned force field."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "* It is encouraging to see the first works make use of the MISATO dataset, which contains a wealth of information about the very difficult problem of protein-ligand binding.\n* Directly learning the long-timescale dynamics with a neural ODE rather than a fixed-timestep next-step predictor is an interesting idea which merits broader exploration."
                },
                "weaknesses": {
                    "value": "* Problem formulation. Although learning a neural ODE for long-timescale dynamics is an interesting idea, the deterministic problem formulation seems inappropriate as MD simulation itself is not necessarily deterministic. Thermostats and barostats typically introduce stochasticity, and even in their absence the removal of water molecules (which are explicit in the MISATO simulations) injects intrinsic uncertainty into the modeling problem. Hence, the dynamics are fundamentally stochastic and I am skeptical that any neural ODE can faithfully capture the long-timescale dynamics of these protein-ligand systems.\n\n* Performance and baselines. Even in the single-trajectory setting, the MAE for the ligand coordinates seems rather large, in the range of 2-6 angstroms. This is perhaps due to the suboptimal problem formulation already discussed. However, the numbers provided are not meaningful because we do not know what the RMSF is in these simulations. The RMSF is the best result that can be achieved by a single static structure and is an essential missing baseline. The MAE in the multi-trajectory setting is even larger (7 anstroms) and suggests a complete dissociation of the ligand from the binding pocket. Finally, the stability metrics are only marginally better than DenoisingMD and do not represent a qualitative resolution of the problem.\n\n* Misleading title. \u201cGroup symmetric\u201d suggests a much more general framework than SE(3)-equivariance, and the key contribution of the paper is not the equivariant architecture in my opinion.\n\n* Mathematical errors. Although the paper places much emphasis on SE(3)-equivariance, the construction of the atom-level and residue-level frames appears to be non-equivariant. Specifically, the cross product is not translation equivariant since\n$$(x_i + t) \\times (x_j + t) = (x_i \\times x_j) +  (x_i - x_j) \\times t$$\nis not a function of $(x_t\\times x_j)$ and $t$. Noticeably, the appendix claims the cross-product to be SE(3)-equivariant but only establishes rotation equivariance. Further, while I agree that the local frame construction described in the appendix is equivariant, this is different from what is done in the main text, since there is no nearest-neighbor atom $x_k$ and absolute positions $x_i, x_j$ are used.\n\nJustification for score. Although the paper is a commendable attempt to learn from MD data, I am not convinced that the problem formulation makes sense, and the experimental results are rather weak. The frame based architecture is not a significant technical advancement over existing frame architectures and appears to have flaws."
                },
                "questions": {
                    "value": "* The architectural details in Eq 5 and Fig 4 are very unclear, with several ambiguous uses of the dot product. Please label the embeddings with the dimensionality (so it is clear if they are scalars or vectors) and define symbols before they are used (for example $h_i$). It is also not clear what kind of MPNN is used and what is the meaning of the number of \"layers.\"\n* Please clarify if by MAE you mean RMSD or some alternative definition of positional error (with or without a factor of $\\sqrt{3}$)\n* \"We keep the same backbone model (BindingNet) for energy or force prediction for all the baselines.\" If so, please provide significantly more details about how these baselines were retrained.\n* If this work considers the semi-flexible, how did you deal with the protein movement that is present in the MISATO MD trajectories?\n* What is your integration timestep? If it is adaptive, please provide more details about how many timesteps are required for a typical 8ns simulation.\n* In the single-trajectory setting, how is the temporal division carried out?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3731/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3731/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3731/Reviewer_oR9H"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3731/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698165348430,
            "cdate": 1698165348430,
            "tmdate": 1699636329229,
            "mdate": 1699636329229,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "aYa2LKTZAJ",
                "forum": "J4V3lW9hq6",
                "replyto": "wK83B8ad1Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (1/3)"
                    },
                    "comment": {
                        "value": "Thank you for raising your comments. There is one critical comment and some misunderstandings, and we hope we have addressed them in our rebuttal. If there are any other follow-up questions, we will be happy to address them. \n\n\n**Math is correct. BindingNet is SE(3)-equivariant because the mass center is removed.**\n\nThank you for raising this concern. However, we mentioned that all the atom and backbone residue positions are reduced by the mass point of the molecular system in the first version, thus it is translation equivariance. We have described this in **line 3 of Algorithm 1**. Further for clarification, we have highlighted this in the revised version, especially in the proof (Sec C).\n\n\n**Correction on problem formulation**\n\nThank you for raising this question.\n- First on the solvent molecules. The ideal case is that the MISATO authors can provide them in the dataset. We contacted the authors and tried to extract the dynamics of solvent molecules, but such information is still missing in the dataset (we are waiting for the replies now).\n- However, such missing information can be easily captured using our NeuralMD framework.\n    - Current in Newtonian dynamics: $F = \\text{BindingNet(protein-ligand)}$\n    - Add random terms to mimic solvent molecules as Langevin dynamics: $F = \\text{BindingNet(protein-ligand)} - \\gamma m v + \\sqrt{2m \\gamma k_BT} R(t)$. We have this explained in the revised manuscript (the colored text at the end of Section 3.3), please feel free to check. For the rest part of the manuscript (e.g., Abstract and Sec 1), we can change it from ODE to SDE easily in the final version.\n- The results of *single trajectory* and *multiple trajectories* are attached below. You can also find them in the revised manuscript.\n- MISATO is under the NVT configuration, and it uses thermostats, then Langevin dynamics can capture such stochasticity [1].\n    - Besides, these two (thermostats or barostats) are used on **velocity** to guarantee that the simulated trajectories (**coordinates/positions** ) follow the configuration. In this way, we are using NeuralMD to learn the **coordinates/positions** directly. By expectation, we want to claim that such an implicit bias can be learned by our models, especially after we introduce using the Langevin dynamics.\n    - There are also variants of thermostats, e.g., the Nose-Hoover thermostat is deterministic, while the Langevin thermostat is stochastic. Thus, it highly depends on the dataset generation process. To verify it, we have sent emails to the authors of MISATO, and still waiting for their response.\n\n\n|                     | 100-MAE            | 100-MSE            | 100-Stability       | 1k-MAE            | 1k-MSE            | 1k-Stability       | All-MAE            | All-MSE            | All-Stability       |\n|---------------------|----------------|----------------|-----------------|----------------|----------------|-----------------|----------------|----------------|-----------------|\n| VerletMD            | 90.326         | 56.913         | 86.642          | 80.187         | 53.110         | 86.702          | 105.979        | 69.987         | 90.665          |\n| GNN-MD              | 7.176          | 4.726          | 35.431          | 7.787          | 5.118          | 33.926          | 8.260          | 5.456          | 32.638          |\n| DenoisingLD         | 7.112          | 4.684          | 29.956          | 7.746          | 5.090          | 18.898          | 15.878         | 10.544         | 89.586          |\n| NeuralMD-ODE | **6.852** | **4.503** | **19.173** | **7.653** | **5.028** | **15.572** | **8.147** | **5.386** | **17.468** |\n| NeuralMD-SDE  | 6.869          | 4.514          | 19.561          | 7.665          | 5.037          | 16.501          | 8.165          | 5.398          | 19.012          |"
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116340182,
                "cdate": 1700116340182,
                "tmdate": 1700153093388,
                "mdate": 1700153093388,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XIuxIuttey",
                "forum": "J4V3lW9hq6",
                "replyto": "wK83B8ad1Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (2/3)"
                    },
                    "comment": {
                        "value": "| PDB ID | Metric    | VerletMD | GNN-MD    | DenoisingLD | NeuralMD-ODE | NeuralMD-SDE |\n|--------|-----------|----------|-----------|-------------|--------------|--------------|\n| 5WIJ   | MAE       | 9.618    | 2.319     | 2.254       | 2.118        | **2.109**    |\n|        | MSE       | 6.401    | 1.553     | 1.502       | 1.410        | **1.408**    |\n|        | Stability | 79.334   | 45.369    | 18.054      | **12.654**   | 13.340       |\n| 4ZX0   | MAE       | 21.033   | 2.255     | 1.998       | **1.862**    | 1.874        |\n|        | MSE       | 14.109   | 1.520     | 1.347       | **1.260**    | 1.271        |\n|        | Stability | 76.878   | 41.332    | 23.267      | **18.189**   | 18.845       |\n| 3EOV   | MAE       | 25.403   | 3.383     | 3.505       | 3.287        | **3.282**    |\n|        | MSE       | 17.628   | 2.332     | 2.436       | 2.297        | **2.294**    |\n|        | Stability | 91.129   | 57.363    | 51.590      | **44.775**   | 44.800       |\n| 4K6W   | MAE       | 14.682   | 3.674     | 3.555       | 3.503        | **3.429**    |\n|        | MSE       | 9.887    | 2.394     | 2.324       | 2.289        | **2.234**    |\n|        | Stability | 87.147   | 57.852    | 39.580      | 38.562       | **38.476**   |\n| 1KTI   | MAE       | 18.067   | **6.534** | 6.657       | 6.548        | 6.537        |\n|        | MSE       | 12.582   | 4.093     | 4.159       | 4.087        | **4.085**    |\n|        | Stability | 77.315   | 4.691     | 7.377       | 0.525        | **0.463**    |\n| 1XP6   | MAE       | 13.444   | 2.303     | 1.915       | **1.778**    | 1.822        |\n|        | MSE       | 9.559    | 1.505     | 1.282       | **1.182**    | 1.216        |\n|        | Stability | 86.393   | 43.019    | 28.417      | **19.256**   | 22.734       |\n| 4YUR   | MAE       | 15.674   | 7.030     | 6.872       | **6.807**    | 6.826        |\n|        | MSE       | 10.451   | 4.662     | 4.520       | **4.508**    | 4.526        |\n|        | Stability | 81.309   | 50.238    | 32.423      | **23.250**   | 25.008       |\n| 4G3E   | MAE       | 5.181    | 2.672     | 2.577       | 2.548        | **2.478**    |\n|        | MSE       | 3.475    | 1.743     | 1.677       | 1.655        | **1.615**    |\n|        | Stability | 65.377   | 16.365    | 7.188       | **2.113**    | 2.318        |\n| 6B7F   | MAE       | 31.375   | 4.129     | 3.952       | 3.717        | **3.657**    |\n|        | MSE       | 21.920   | 2.759     | 2.676       | 2.503        | **2.469**    |\n|        | Stability | 87.550   | 54.900    | 16.050      | **3.625**    | 22.750       |\n| 3B9S   | MAE       | 19.347   | 2.701     | 2.464       | **2.351**    | 2.374        |\n|        | MSE       | 11.672   | 1.802     | 1.588       | **1.527**    | 1.542        |\n|        | Stability | 41.667   | 43.889    | 8.819       | **0.000**    | **0.000**    |\n\n[1] Allen, Michael P., and Dominic J. Tildesley. Computer simulation of liquids. Oxford university press, 2017.\n\n\n**About performance and baselines**\n\n- First, we want to mention that our model is achieving almost consistently better performance, compared to all the baselines. This is definitely not a perfect solution, but it represents a novel scientific progress in the ML community. \n- Then we want to emphasize that, one insight/goal of this work is to open a novel physics-inspired research line of ML for binding MD prediction, and please allow progressive updates on this.\n- We also have certain questions about RMSF. (1) We do not understand the following sentence: `The RMSF is the best result that can be achieved by a single static structure and is an essential missing baseline.` (2) By RMSF, if you mean `root mean square fluctuation`, then it\u2019s a metric, not a method/baseline. (3) RMSF, as a metric, tells the fluctuation of every single trajectory, thus, it is an unsupervised metric and is not easy to compare with. On the other hand, the stability (proposed by Fu. et al.) metric measures the fluctuation between the predicted trajectory and the ground-truth trajectory, and we want to argue that it is a more comparable metric that includes the fluctuation/stability.\n- Comparison between NeuralMD and DenoisingLD. (1) According to Table 3, NeuralMD is better than DenoisingLD by 10%, 3%, and 70% on three datasets, respectively. We want to argue that this is a consistent and stable improvement. (2) Besides, DenoisingLD is overdamped Langevin dynamics, which is inappropriate for the general MD estimation unless under specific conditions. We leave more details in Sec G in the revised manuscript."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116356815,
                "cdate": 1700116356815,
                "tmdate": 1700116356815,
                "mdate": 1700116356815,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "thgMJNJPzj",
                "forum": "J4V3lW9hq6",
                "replyto": "wK83B8ad1Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (3/3)"
                    },
                    "comment": {
                        "value": "**Changed title**\n\nWe are happy to change the title from `group symmetric` to `SE(3)-equivariance`. And we want to point out that the SE(3)-equivariant model for interaction, especially the multi-granularity,  is indeed one core contribution of our work. We spent the whole Sec 3.1 and 3.2 discussing the details.\n\n\n**Answers to the Questions**\n- Clarifications on ML terminologies.\n    - In this work, our usage of the dot product is the same, and you can check [this wiki page](https://en.wikipedia.org/wiki/Dot_product).\n    - We only have scalars and vectors in the input and output, the representations (e.g., $h_i$) are invariant/equivariant representations. We have added the dimension of each variable in Sec E in the revised manuscript.\n    - The number of layers means how many times we repeat the MPNN layer (we omitted the index of layer for simplicity).\n    - The MPNNs are defined in Sec 3.2 explicitly:\n        - The MPNN in BindingNet-Ligand corresponds to Eq 5.\n        - The MPNN in BindingNet-Protein corresponds to the last line of paragraph **Backbone-Level Protein Modeling**.\n        - The MPNN in BindingNet-Complex corresponds to Eq 6.\n- MAE is short for ``mean absolute error\u2019\u2019. We have shown its equation in Sec 3.3 below Eq (8) when it first shows up.\n- When we mean we keep the same backbone, that means we use the BindingNet to provide atom-wise energy/force prediction. This will be fed into the Gaussian distribution in GNN-MD or scoring function in DenoisingLD to learn/estimate $p(x_{t+1}|x_t)$. If readers are interested in these works, we refer to the Related Work paragraph in our manuscript (with references) for an in-depth read. BTW. In ML papers, we often refer the baseline papers to the audience for them to get the details, and leave the main content for our paper\u2019s novel algorithm (Sec 3 in our paper).\n- We had this in the first version. We have mentioned this under **Ablation Study on Flexible Setting** in Sec 4.1, and please check Sec F for more details.\n- The timesteps in the current experiment are fixed (not adaptive) so as to fit the MISATO dataset.\n- Training on the first 80 snapshots, and testing on the last 20 snapshots. The 80th snapshot is given in inference."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116376535,
                "cdate": 1700116376535,
                "tmdate": 1700116376535,
                "mdate": 1700116376535,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "3MuBuw1FDT",
                "forum": "J4V3lW9hq6",
                "replyto": "wK83B8ad1Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Reviewer_oR9H"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Reviewer_oR9H"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the detailed response.\n\n(1) Thanks for clarifying the SE(3) equivariance. However, the Appendix refers to a nearest-neighbor algorithm $x_k$ to construct equivariant frames, deviating from the exposition in the main text. This misalignment should be remedied. I'm also unconvinced by this kind of equivariance accomplished by removing the center of mass as we lose the ability to locally learn equivariant features.\n\n(2) I appreciate the attempt to justify the ODE formulation; however, these are unconvincing as the evaluation metrics are still based on the assumption that one wants to learn an MAE-minimizing simulator. The authors have claimed to capture stochastic dynamics by learning the best deterministic simulator and adding random noise after the fact. This is very different from learning stochastic dynamics.\n\n(3) The RMSF gives an idea of the intrinsic variance of the trajectories and hence the MAE obtained by the best dummy predictor which always predicts a static frame for all timesteps.\n\nBecause the problem formulation remains unconvincing and the experimental results remain unimpressive, I will keep the current score."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700519874067,
                "cdate": 1700519874067,
                "tmdate": 1700519874067,
                "mdate": 1700519874067,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WnJE91Tt8o",
                "forum": "J4V3lW9hq6",
                "replyto": "wK83B8ad1Q",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "Hi reviewer oR9H, thank you for the follow-up. We're pleased to delve deeper into addressing your concerns.\n\n**Q: SE(3)-equivariance**\n\n1. Thank you for the confirmation. The proof and the main body can match. If you read through Sec C, then you may find that $x_k$ acts as the anchor point. This can hold for the atom nearest to the center of $(x_i, x_j)$, or by the backbone structure of the protein, and the proof still holds. Now in the latest version, we just make $x_i, x_j, x_k$ in Eq 11 exactly the same as the one in Eq 3. The proof of other frames, as highlighted in green in the revised version, is straightforward.\n\n2. Also, we didn\u2019t claim that we follow a locally equivariant approach for building our method. We are wondering why you insist that we should locally learn equivariant features?  Making our method local is quite straight, we only need to move the local mass center of a subgraph (vectors in each frame) to zero, but the motivation for doing so is unclear to us.\n\n\n**Q: Clarification of algorithm and metric**\n\nThank you for asking these questions. There are some gaps in the discussion, and we are happy to clarify further.\n- Both the learning and inference of NeuralMD-SDE are stochastic, and it is learning **stochastic dynamics**. We added the random noise and then learned the **stochastic simulator**. The previous revision contained the words 'obtain trajectories' which is confusing, and we have modified it to 'train and sample trajectories`. Please check Sec 3.3 in the latest version, *From Newtonian dynamics to Langevin dynamics*.\n- We are not certain about what this sentence means: `however, these are unconvincing as the evaluation metrics are still based on the assumption that one wants to learn an MAE-minimizing simulator`. Yet, we have tried our best to provide our understanding to you, as follows.\n- All of the works along this research line use MAE as the loss function (related works section), and we added stability metric, following Xiang et al.\u2019s most recent benchmark paper on ML for MD simulation. If you think these are unconvincing, can you provide more insightful explanations on why this is so? This would be appreciated, and then we can know how to solve this issue.\n\n\n**Q: About RMSF**\n\nFirst thank you for agreeing that RMSF is a metric, not a baseline. In the previous round of discussion, we explained why using RMSF is not ideal as a single-trajectory metric, and why **using stability is a good replacement**. Feel free to check *About performance and baselines* above."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700549666605,
                "cdate": 1700549666605,
                "tmdate": 1700664806391,
                "mdate": 1700664806391,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "WRMRIas1oA",
            "forum": "J4V3lW9hq6",
            "replyto": "J4V3lW9hq6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3731/Reviewer_ZPQv"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3731/Reviewer_ZPQv"
            ],
            "content": {
                "summary": {
                    "value": "The work proposes a fast numerical MD method for simulating the protein-ligand binding dynamics in a large time interval. This method consists of two main modules: (1) a physics-informed multi-grained group symmetric network to model the protein-ligand complex, and (2) a second-order ODE solver to learn Newtonian mechanics. The proposed method can achieve 2000\u00d7 speedup compared to the numerical MD methods and outperforms other ML methods on 12 tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe author proposed NeuralMD, an ML framework that incorporates a novel multi-grained group symmetric network architecture and second-order ODE Newtonian dynamics, enabling accurate predictions of protein-ligand binding dynamics in a larger time interval. \n2.\tThe authors are the first to explore a large-scale dataset with binding dynamics released in May 2023.\n3.\tNeuralMD offers a 2000\u00d7 speedup over standard numerical MD simulation and outperforms other ML approaches by up to ~80% under the stability metric.\n4.\tNeuralMD not only achieves good performance in single-trajectory binding dynamics predictions, but also has good generalization ability among multiple trajectories."
                },
                "weaknesses": {
                    "value": "1.\tThis work is based on the first large-scale dataset with binding dynamics, which may have its own limitations.\n2.\tThe paper does not provide a direct comparison with other state-of-the-art methods in terms of computational efficiency.\n3.\tThe article briefly mentions protein-ligand binding dynamics but does not further explain their importance and how such dynamics can be modeled. In addition, the article does not adequately discuss the interactions between proteins and ligands and how these interactions can be incorporated into the simulations.\n4.\tThe paper does not discuss the potential limitations or drawbacks of the NeuralMD framework.\n5.\tThe paper does not delve deeply into the practical implications or real-world applications of the proposed method.\n6.\tThe language of the article is somewhat poorly formulated, with some grammatical errors and spelling mistakes."
                },
                "questions": {
                    "value": "1.\tThe paper states that the speed of this method is superior to standard numerical MD simulation methods, but this method is only compared with one method and is not compared with ML-based MD simulation methods. Please explain the reasons for this and compare it with more methods to prove the efficiency of the proposed method.\n2.\tThe title of the article mentions a \"multi-grained group symmetric framework\", but not enough experimental results were provided to prove its effectiveness.\n3.\tThe methods section of the article mentions \"BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions\" but does not explain in detail how this model captures the multi-level interactions. interactions\", but does not explain in detail how this model captures the multi-level interactions. Could you provide more details or examples to illustrate this point?\n4.\tThe proposed method only is evaluated on one dataset, which might be specific to the used dataset. The authors need to evaluate their method on other datasets and compare it with more methods.\n5.\tHow does the ML approach discussed in the article compare with other ML methods used for simulating protein-ligand binding dynamics? What is the advantage of the ML method used in this work compared to others? \n6.\tThe article does not describe in detail the specific methods used for the experiments; for example, in the case of protein-ligand binding dynamics simulations, no specific information on the simulation software used, simulation conditions, model parameters, etc. is mentioned. This makes it difficult for the reader to understand and assess the feasibility of the experimental methods."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3731/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698500075987,
            "cdate": 1698500075987,
            "tmdate": 1699636329128,
            "mdate": 1699636329128,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "euAXlWzkm6",
                "forum": "J4V3lW9hq6",
                "replyto": "WRMRIas1oA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (1/3)"
                    },
                    "comment": {
                        "value": "Thank you for acknowledging our work as the first to explore large-scale binding MD datasets, solid performance, and efficiency. We believe that we have attempted to solve your concerns during the rebuttal and in the revised manuscript. We have listed the details below.\n\n**Dataset limitations**\n\nThe binding dynamics dataset issue is out of the scope of our work. We also want to mention that this is actually the most critical bottleneck that prevents ML researchers from developing tools for domain-specific tasks. If there exist any other public binding MD datasets, we are happy to use them.\n\n**Efficiency with other DL models**\n\nThank you for raising this. We have now added them below (FPS, corresponding to Table ). The main bottleneck of using ML for binding MD simulation is on the backbone model, and since we are using the same backbone model in our experiments, i.e., the running time of these DL models is on the **same order of magnitude**. That\u2019s why we didn\u2019t highlight the time comparison among different DL models in the first version.\n\n| PDB ID          | 5WIJ   | 4ZX0   | 3EOV   | 4K6W   | 1KTI   | 1XP6   | 4YUR   | 4G3E   | 6B7F   | 3B9S   | Average |\n|-----------------|--------|--------|--------|--------|--------|--------|--------|--------|--------|--------|---------|\n| VerletMD        | 12.564 | 30.320 | 29.890 | 26.011 | 19.812 | 28.023 | 31.513 | 29.557 | 19.442 | 31.182 | 25.831  |\n| GNN MD          | 22.639 | 41.083 | 26.219 | 26.798 | 22.435 | 35.406 | 25.370 | 36.677 | 42.018 | 40.339 | 31.898  |\n| Denoising LD    | 37.047 | 39.764 | 38.232 | 32.222 | 22.181 | 34.501 | 41.498 | 38.003 | 42.261 | 41.867 | 36.758  |\n| NeuralMD (Ours) | 33.164 | 39.415 | 31.720 | 31.909 | 24.566 | 37.135 | 39.365 | 39.172 | 20.320 | 37.202 | 33.397  |\n\n\n**How to model the protein-ligand interactions**\n\nThis is an important module, and we have shown it in Sec 3.1 and 3.2 in the first version. To be more specific:\n- In Eq 4 (Sec 3.1), we illustrated how the vector frame ($F_{complex}$) is constructed for protein-ligand interactions.\n- In Eq 6 (Sec 3.2), we showed the MPNN module for protein-ligand binding, based on $F_{complex}$.\n- We also showed the pipeline in Figure 4 & 5 (appendix).\n- We discussed how the interacted forces can be used for the binding MD estimation in Eq 6 and the following paragraph (Sec 3.2). So the output is atom-level forces, which will be fed into the Newtonian dynamics (Eq 8) for trajectory estimation.\n- We added the model architecture in more detail in Sec E in the revised version."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116140691,
                "cdate": 1700116140691,
                "tmdate": 1700116140691,
                "mdate": 1700116140691,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "MjJCaRa012",
                "forum": "J4V3lW9hq6",
                "replyto": "WRMRIas1oA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (2/3)"
                    },
                    "comment": {
                        "value": "**Potential limitation**\nOne potential limitation, which has been raised by reviewer oR9H is that we didn\u2019t consider the solvent molecules in the MD system. This is because the public dataset does not include this information. Meanwhile, we are still able to handle such a limitation by adding random terms into the predicted forces, i.e., the Langevin dynamics. We have added the results of *single trajectories* below. Further in the revised manuscript, we added one paragraph in Sec 3.3 for a detailed explanation and the results of *multiple trajectories* in Sec 4. We can observe that the performance of ODE and SDE are very close to each other.\n\n| PDB ID | Metric    | VerletMD | GNN-MD    | DenoisingLD | NeuralMD-ODE | NeuralMD-SDE |\n|--------|-----------|----------|-----------|-------------|--------------|--------------|\n| 5WIJ   | MAE       | 9.618    | 2.319     | 2.254       | 2.118        | **2.109**    |\n|        | MSE       | 6.401    | 1.553     | 1.502       | 1.410        | **1.408**    |\n|        | Stability | 79.334   | 45.369    | 18.054      | **12.654**   | 13.340       |\n| 4ZX0   | MAE       | 21.033   | 2.255     | 1.998       | **1.862**    | 1.874        |\n|        | MSE       | 14.109   | 1.520     | 1.347       | **1.260**    | 1.271        |\n|        | Stability | 76.878   | 41.332    | 23.267      | **18.189**   | 18.845       |\n| 3EOV   | MAE       | 25.403   | 3.383     | 3.505       | 3.287        | **3.282**    |\n|        | MSE       | 17.628   | 2.332     | 2.436       | 2.297        | **2.294**    |\n|        | Stability | 91.129   | 57.363    | 51.590      | **44.775**   | 44.800       |\n| 4K6W   | MAE       | 14.682   | 3.674     | 3.555       | 3.503        | **3.429**    |\n|        | MSE       | 9.887    | 2.394     | 2.324       | 2.289        | **2.234**    |\n|        | Stability | 87.147   | 57.852    | 39.580      | 38.562       | **38.476**   |\n| 1KTI   | MAE       | 18.067   | **6.534** | 6.657       | 6.548        | 6.537        |\n|        | MSE       | 12.582   | 4.093     | 4.159       | 4.087        | **4.085**    |\n|        | Stability | 77.315   | 4.691     | 7.377       | 0.525        | **0.463**    |\n| 1XP6   | MAE       | 13.444   | 2.303     | 1.915       | **1.778**    | 1.822        |\n|        | MSE       | 9.559    | 1.505     | 1.282       | **1.182**    | 1.216        |\n|        | Stability | 86.393   | 43.019    | 28.417      | **19.256**   | 22.734       |\n| 4YUR   | MAE       | 15.674   | 7.030     | 6.872       | **6.807**    | 6.826        |\n|        | MSE       | 10.451   | 4.662     | 4.520       | **4.508**    | 4.526        |\n|        | Stability | 81.309   | 50.238    | 32.423      | **23.250**   | 25.008       |\n| 4G3E   | MAE       | 5.181    | 2.672     | 2.577       | 2.548        | **2.478**    |\n|        | MSE       | 3.475    | 1.743     | 1.677       | 1.655        | **1.615**    |\n|        | Stability | 65.377   | 16.365    | 7.188       | **2.113**    | 2.318        |\n| 6B7F   | MAE       | 31.375   | 4.129     | 3.952       | 3.717        | **3.657**    |\n|        | MSE       | 21.920   | 2.759     | 2.676       | 2.503        | **2.469**    |\n|        | Stability | 87.550   | 54.900    | 16.050      | **3.625**    | 22.750       |\n| 3B9S   | MAE       | 19.347   | 2.701     | 2.464       | **2.351**    | 2.374        |\n|        | MSE       | 11.672   | 1.802     | 1.588       | **1.527**    | 1.542        |\n|        | Stability | 41.667   | 43.889    | 8.819       | **0.000**    | **0.000**    |\n\n\n\n**Practical implications**\n\nThe experiments of binding MD estimation on MISATO (a subset of PDB) have practical implications. If we want to extend this to other real-world applications, that means we need other binding MD datasets, and we are happy to check if the reviewer can provide specific references.\n\n**Effectiveness of multi-grained**\n\nThe proof of this is trivial because, without the multi-grained modeling, the model cannot fit into the GPU memory.\n\n**Multi-level interactions**\n\nSo we have the multi-grained modeling discussed in Sec 3.1 & 3.2.\n- In Sec 3.1, we have shown three levels of vector frames in Eq 2, 3, 4.\n- In Sec 3.2, we have shown how to do MPNN on these three vector frames, respectively.\n- Finally, the atom forces are used to get the trajectory following Newtonian dynamics, $a = F/m$.\n- This is also illustrated in Figure 4.\n- We added more details in Sec E of the revised manuscript."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116187940,
                "cdate": 1700116187940,
                "tmdate": 1700116187940,
                "mdate": 1700116187940,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "il0zdy7GaP",
                "forum": "J4V3lW9hq6",
                "replyto": "WRMRIas1oA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response (3/3)"
                    },
                    "comment": {
                        "value": "**More binding datasets and more methods**\n\n- Thank you for raising this question. First, we want to highlight that we are not just using one dataset. As also confirmed by your comments, we include 10 single binding trajectories and 3 datasets on multiple trajectories. These trajectories are from PDB, the most comprehensive dataset for protein (binding), thus, we aim to assert that the experiments conducted in this study are indicative and representative of a substantial volume of binding MD data.\n- Then as also confirmed by your comments, the dataset is one limitation in AI for binding MD estimation, and MISATO is the first large-scale binding MD dataset released in May 2023. If you can provide other existing public large-scale binding MD datasets, we are happy to try them in future work.\n- For baselines, if the reviewer can list the specific papers, we are happy to compare.\n\n**Model difference with existing works**\n\nThe other models for binding MD trajectory prediction can be categorized into two venues:\n- No incorporation of physics rules, like GNN-MD.\n- Inappropriate incorporation of physical rules, like overdamped Langevine dynamics in the DenoisingLD papers. We provide more details in Sec G of the revised manuscript. Feel free to check.\n- Thus, in comparison, we can better incorporate the physical rules (Newtonian dynamics and the newly added Langevin dynamics), and such inductive bias can help better model the binding MD.\n\n**Dataset simulation illustration is out of the scope of this work**\n\nWe confirmed that MISATO uses the Amber20 software suite and NVT, and we provide more dataset statistics (number of atoms and number of residues, etc.) in Sec D. However, we want to highlight that doing simulation is beyond the scope of our work, because we are not the authors of MISATO. The credit for the binding MD dataset generation goes to the MISATO paper."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700116217173,
                "cdate": 1700116217173,
                "tmdate": 1700116879814,
                "mdate": 1700116879814,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "kbooxGJLVG",
            "forum": "J4V3lW9hq6",
            "replyto": "J4V3lW9hq6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3731/Reviewer_582T"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3731/Reviewer_582T"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a geometric deep learning framework for MD simulation of protein-ligand complexes. It is composed of a BindingNet model to represent a protein-ligand complex at multiple levels and a neural ordinary differential equation (ODE) solver to predict the trajectory under Newtonian mechanics. The method is evaluated on a recent large-scale MD simulation benchmark MISATO and shows state-of-the-art performance on multiple benchmarks. Importantly, it achieves a 2000x speedup over standard numerical MD simulation methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "* This paper proposes a physics-informed architecture that involves Newtonian mechanics in trajectory inference. \n* This paper presents a comprehensive evaluation on protein-ligand binding MD simulation benchmarks.\n* The proposed model shows state-of-the-art performance on multiple benchmarks.\n* The proposed method is scalable, with 2000x speed up compared to standard MD simulation tools."
                },
                "weaknesses": {
                    "value": "* This paper lacks ablation studies illustrating the benefit of different components.\n* The description of evaluation metric is not crystal clear (see questions below)"
                },
                "questions": {
                    "value": "1. Can you present ablation studies by replacing your BindingNet architecture with other existing geometric architectures such as EquiFormer and EGNN? \n2. Can you conduct ablation studies to understand the benefit of multi-level protein-ligand representation? I am not sure if having multi-level representation is helpful\n3. For the MAE and MSE metric, is the MAE/MSE calculated over the whole trajectory (every time step) or only the final step?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3731/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698783337200,
            "cdate": 1698783337200,
            "tmdate": 1699636329022,
            "mdate": 1699636329022,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9pHhgxiznB",
                "forum": "J4V3lW9hq6",
                "replyto": "kbooxGJLVG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "We appreciate your recognition of our work on physics-inspired architecture, comprehensive evaluation, and efficiency. Your primary concerns are about backbone models and ablation studies. We believe that the following explanations adequately address the points of concern you raised.\n\n**Ablation studies on different components**\n\nThank you for raising this question. We assume that your question is about if we can test the three components of BindingNet separately, as shown in Figure 4. The answer is no, because separating them would destroy the physical rules in MD. Let us explain in more detail:\n- The BindingNet-Ligand models the interactions within the ligand itself.\n- The BindingNet-Protein and BindingNet-Complex learn the atom-level forces induced by the proteins.\n- By combining these modules, we can learn the atom forces from all the other atoms, which is the physical-inspired MD estimation. \n- On the other hand, we also added an ablation study on introducing stochastic terms induced by the solvent molecules (they were considered in the dataset generation, but not provided to the public). We have attached the results in the revised manuscript. Please feel free to check it.\n\n**Can we replace BindingNet with Equiformer and EGNN, and why multi-level?**\n\nThese two questions are highly connected, so we answer them together. In practice, the multi-grained modeling is appealing from the engineering perspective. If we model the large molecular systems, even for one ligand-protein complex, there are on average 1k residues (around 20k-30k atoms) in the MISATO dataset. Thus, modeling such a big molecular system is challenging for GPU memory. This means:\n- We cannot replace BindingNet with Equiformer or EGNN.\n- The multi-grained (or multi-level) modeling is motivated by reducing the computational cost, and without it, the GPU memory cannot hold for such a large molecular system.\n- Actually, even in our current system, we are taking batch size with 2 so as to fit the GPU memory.\n\n**Clarification on evaluation**\n\nYes, both the MAE and MSE are calculated over the whole trajectory snapshots in the test set, not only the final snapshot. We have this highlighted in Sec 4."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700115948880,
                "cdate": 1700115948880,
                "tmdate": 1700115948880,
                "mdate": 1700115948880,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "w8Em6q8Jwu",
                "forum": "J4V3lW9hq6",
                "replyto": "kbooxGJLVG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Reviewer_582T"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Reviewer_582T"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your response"
                    },
                    "comment": {
                        "value": "I would like to thank the reviewers for their response. I have two comments:\n\n1. I would probably disagree that one cannot replace BindingNet with EGNN because we have been training EGNN internally on the MISATO dataset and it runs pretty fast. Due to the lack of baselines, it is a bit unclear whether BindingNet is superior than existing geometric encoders.\n\n2. I initially thought that MAE/MSE was calculated at the last snapshot. If it was calculated over the whole trajectory (every snapshot), I would imagine the MAE/MSE to be substantially lower (currently MAE is around 8.1 for MISATO-all) because a ligand wouldn't move that much during MD simulation. What's the MAE if you just use the ligand pose at time 0? (meaning, the ligand doesn't move at all during MD simulation). This is probably related to RMSF metric the other reviewer brought up"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598353685,
                "cdate": 1700598353685,
                "tmdate": 1700598476451,
                "mdate": 1700598476451,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "vgYv1TUqV7",
                "forum": "J4V3lW9hq6",
                "replyto": "kbooxGJLVG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "Hi reviewer 582T,\n\nThank you for the follow-up. We are happy to address your questions in more detail.\n\n1. We list the main reasons why EGNN is not a good fit below.\n    - [Memory] We agree that EGNN is efficient, but the bottleneck here is the computational memory. (The original EGNN is connecting all atoms)\n    - [Math correctness] EGNN is E(3)-equivariant. However, when the protein is fixed, the modeling of the ligand needs to be SE(3)-equivariant and reflection-antisymmetric. We explained more details in Sec C.\n    - [Performance] Further on the performance, the Geom3D benchmark has provided around 50 geometric tasks, showing how the SE(3)-equivariant models outperform EGNN / GVP.\n\n2. Thank you for raising this question, and let's explain more insights to you.\n    - If we focus on the **single-trajectory** setting (Table 1), then you can see that the MAE and MSE are comparatively small. This is also the setting that most baseline papers are working on.\n    - In this paper, we introduce another challenging task of generalization among **multiple trajectories** (Table 2), this is where you see that the MAE & MSE are much larger. Notice that here, the MAE & MSE are the averages of all the snapshots and all the testing trajectories.\n    - Thank you for raising this question on **RMSF**. RMSF is the metric of a single trajectory, and if we want to compare the fluctuation between the predicted trajectories and ground-truth trajectories, then that is the **stability** metric. In other words, we have already included the RMSF on prediction-and-true trajectories.\n\nHope this answers your questions, and we are happy to provide more insights."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700601139506,
                "cdate": 1700601139506,
                "tmdate": 1700602727534,
                "mdate": 1700602727534,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "QausOR2OVl",
                "forum": "J4V3lW9hq6",
                "replyto": "vgYv1TUqV7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Reviewer_582T"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Reviewer_582T"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "Thank you for your reply. I agree with you on E(3) vs SE(3) equivariance. It would be nice to compare with other SE(3)-equivariant models, nevertheless.\n\nI totally understand that multi-trajectory evaluation is much more challenging (imo, this is much more useful in practice). Still, what's the performance if your model just do nothing and output the ligand pose at time 0?"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700601442366,
                "cdate": 1700601442366,
                "tmdate": 1700601442366,
                "mdate": 1700601442366,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "uBGWQECKFR",
                "forum": "J4V3lW9hq6",
                "replyto": "kbooxGJLVG",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Reply"
                    },
                    "comment": {
                        "value": "Hi Reviewer 582T,\n\nThank you for the follow-up!\n\n1. Yes, we are definitely going to explore more SE(3)-equivariant models in the future. BTW. We also share some insights that another motivation for using vector frame modeling is for certain tasks (e.g., protein representation), the vector frame modeling outperforms other methods by a large margin. You can check this [CDConv paper](https://arxiv.org/abs/2210.08511) in case interested.\n\n2. Thank you for the suggestion. So we called this baseline `Void MD` since we are just taking the first frame as the prediction for the rest frames for each trajectory. We got some interesting results, as shown below. As you can see, our NeuralMD is still reaching the best performance, while all the existing/published baselines are worse than Void MD. We also acknowledge the marginal performance improvement, but we want to point out the challenge of this task, and we reach a **consistent** improvement. This is a promising sign to prove the better generalization ability of NeuralMD, especially compared to the published baselines.\n\n| | GNN MD| DenoisingLD | Void MD | NeuralMD (Ours) |\n| :--:| :--:| :--:| :--:| :--:|\n| MISATO-100 | 7.176 | 7.112 | 7.048 | **6.852** |\n| MISATO-1000 | 7.787 | 7.746 | 7.723 | **7.653** |\n| MISATO-All | 8.260 | 15.878 | 8.206 | **8.147** |\n\n\nWe hope this answers your questions, and any re-evaluation is appreciated.\n\nRegards,\n\nAuthors of NeuralMD"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700626002150,
                "cdate": 1700626002150,
                "tmdate": 1700626208513,
                "mdate": 1700626208513,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ttApUHuAFE",
            "forum": "J4V3lW9hq6",
            "replyto": "J4V3lW9hq6",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3731/Reviewer_K9WG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3731/Reviewer_K9WG"
            ],
            "content": {
                "summary": {
                    "value": "Authors  propose a principled approach that incorporates a novel physics-informed multi-grained group symmetric framework. Specifically, we propose (1) a BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions, and (2) an augmented neural ordinary differential equation solver that learns the trajectory under Newtonian mechanics.\n\nAuthors devised NeuralMD, an ML framework that incorporates a novel multi-grained group symmetric network architecture and second-order ODE Newtonian dynamics, enabling accurate predictions of protein-ligand binding dynamics in a larger time interval."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Authors have quantitatively and qualitatively verifed that NeuralMD achieves superior performance on 13 binding prediction tasks.\n2. Authors showed the efficiency and effectiveness of NeuralMD, with a 2000\u00d7 speedup over standard numerical MD simulation and outperforming all other ML approaches by up to ~80% under the stability metric."
                },
                "weaknesses": {
                    "value": "One potential limitation of this work is the dataset. Currently, authors are using the MISATO dataset, a binding simulation dataset with a large timescale. However, NeuralMD is agnostic to the time interval, and it can also be applied to binding dynamics datasets with time interval as a femtosecond."
                },
                "questions": {
                    "value": "1. Authors qualitatively show that NeuralMD reaches more stable binding predictions. Is there a way to shoe quantitatively as well.\n2."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3731/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699104868297,
            "cdate": 1699104868297,
            "tmdate": 1699636328959,
            "mdate": 1699636328959,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "dHCybJx8NL",
                "forum": "J4V3lW9hq6",
                "replyto": "ttApUHuAFE",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3731/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response"
                    },
                    "comment": {
                        "value": "We appreciate your positive comments on our work. Your primary concerns are about the dataset and evaluation, and we have explained them below.\n\n1. **[regarding the dataset limitation]** We agree that the dataset is one of the potential limitations here; as highlighted in the conclusion section, making more datasets available may need help and support from the whole community. Creating such a dataset not only is very costly, but also requires sufficient domain expertise from different domains, which makes it challenging. As stated in the paper, MISATO dataset is the only publicly available large-scale dataset, and that is why we empirically showed the potential of our NeuralMD method using this dataset. Regarding its effect on femtosecond MD, we unfortunately can\u2019t perform any empirical studies at this stage, although we theoretically show that our method is agnostic to the MD time interval. \n\n2. **[regarding quantitative evaluation]** Yes, we followed the *stability metric* from previous work, and reported those quantitative results in Tables 1 & 3."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3731/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700115868740,
                "cdate": 1700115868740,
                "tmdate": 1700115868740,
                "mdate": 1700115868740,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]