[
    {
        "title": "SEEKER: Semi-Supervised Knowledge Transfer for Query-Efficient Model Extraction"
    },
    {
        "review": {
            "id": "4upQPfE8wH",
            "forum": "lygdvIKDxi",
            "replyto": "lygdvIKDxi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission898/Reviewer_8x4q"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission898/Reviewer_8x4q"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the vulnerability of Deep Neural Networks (DNNs) to model extraction attacks, even when the models are accessed in a black-box manner. These attacks allow adversaries to create a substitute model that mimics the original model by querying the black-box model with unlabeled inputs. The paper introduces SEEKER, a query-efficient model extraction framework that leverages semi-supervised public knowledge transfer. The framework incorporates an offline stage for pre-training the substitute model without any query costs, a semantic alignment scheme, and a multi-encoder query generator. Experimental results indicate that SEEKER significantly improves query efficiency while maintaining high accuracy and attack success rate (ASR) compared to state-of-the-art methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. SEEKER introduces a novel approach to model extraction that combines offline pre-training with semantic alignment, reducing the need for extensive querying. The paper claims that SEEKER can reduce the query budget by over 50 times compared to existing methods while achieving comparable or better accuracy.\n2. The experimental results are thorough and clearly presented."
                },
                "weaknesses": {
                    "value": "I like the technical merit in this paper. My major concerns are around the presentation that might require significant modification of the main body. I'm willing to raise the score if the following concerns are addressed.\n1. In the methodology part, there is no explicit discussion or intuition why the proposed method can improve the query efficiency, i.e., reduce the number of queries. If so, what is the query efficiency just a side effect? We need more justification that only experimental results. \n2. The paper presents a complex methodology without providing much intuition. I can get a main idea of whole methodology. But the motivation of each part is not clear. For example, in section 3.2, why a good framework should be designed this way."
                },
                "questions": {
                    "value": "Is it possible to provide a simpler graph than Figure 1 for illustrating the main idea?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission898/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698697071463,
            "cdate": 1698697071463,
            "tmdate": 1699636016462,
            "mdate": 1699636016462,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6qGXhK21UW",
                "forum": "lygdvIKDxi",
                "replyto": "4upQPfE8wH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8x4q (1/2)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for acknowledging the technical merits of our manuscript and pointing out the problems in the presentation. We would like to make the following clarification on our contribution and make corresponding modifications to the manuscript.\n\n> 1. Give explicit discussion or intuition why the proposed method can improve the query efficiency.\n\nWe appreciate the suggestion of the reviewer.\nOur work improves the query-efficiency of model extraction attacks by proposing a *query-free self-supervised* scheme and a *query-efficient supervised* approach.\nBoth methods are aimed at extracting the knowledge from the public dataset effectively to reduce the query cost.\nWe would like to discuss the motivation of each method as follows.\n\n**Query-free Self-supervised Scheme.**\nWe note that the conventional public dataset based model extraction attacks only use public data for crafting queries to the victim model.\nIn contrast, we develop a self-supervised training scheme to optimize the substitute model exclusively based on the public dataset, which does not require any queries to the victim model.\nOur approach builds on the assumption that a well-trained victim model\nmaintains semantic consistency, i.e., outputs similar representations for different images featuring the same object.\nUsing this semantic consistency as an additional prior, our method optimizes the substitute model to learn similar encoding patterns to the victim model.\nWe also design different variants of the scheme according to the characteristics of offline and online stages that reduce the query cost of both stages.\n\n**Query-efficient Supervised Scheme.**\nTo further improve the query-efficiency of the supervised learning stage of conventional attacks, we focus on synthesizing queries with richer information.\nWe point out that most existing model extraction methods based on public data feature a one-to-one correspondence between the public data and the generated query, which limits the information density in the query.\nTo increase the information diversity in the query generation process, we propose to parallelly process different public data when synthesizing a single query.\nWe design a multi-encoder aggregation design and reconstruction loss to merge the information from different public data, and develop inconsistency and diversity loss to ensure such information is fully leveraged for minimizing the gap between the substitute and the victim models.\n\nIn our revised manuscript, we also made major revisions to the overview of our method (Section 3.2), the semantic alignment scheme (Section 3.3), and the aggregated generation method (Section 3.4), including a more detailed discussion of how our attack reduces the query cost of the model extraction process."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission898/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493058225,
                "cdate": 1700493058225,
                "tmdate": 1700493058225,
                "mdate": 1700493058225,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "OW1hqklwQV",
                "forum": "lygdvIKDxi",
                "replyto": "4upQPfE8wH",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8x4q (2/2)"
                    },
                    "comment": {
                        "value": "> 2. Explain the motivation behind each part of the framework.\n\nWe appreciate the suggestion of the reviewer.\nHere, we would like to introduce how each component of the method contributes to the overall performance and how they are incorporated into the framework.\n\nOur framework comprises four main procedures: offline semantic alignment, online semantic alignment, query generation, and supervised training.\nThe offline semantic alignment belongs to an independent offline pre-training stage, and the adversary iterates through the online semantic alignment, query generation, and supervised training procedures during the online stage.\nAmong these procedures, conventional model extraction attacks only include query generation and supervised training procedures in the online stage, i.e., generate query inputs, query the victim model, and use the victim feedback to optimize the query generation process.\nOur framework improves the existing pipeline by 1) introducing an offline stage (offline semantic alignment), 2) designing the online semantic alignment to assist the conventional supervised training scheme, and 3) proposing a novel aggregation generator for the query generation process.\n\n\n**Offline semantic alignment.**\nIn contrast to existing online attacks, we design an offline stage to pre-train the substitute model.\nDuring this stage, the adversary can not directly interact with the victim, but have access to a public dataset.\nUnder such circumstances, we design an offline semantic alignment strategy that leverages the public dataset to optimize the encoding layers of the substitute model in a self-supervised manner.\nNotably, we identify semantic consistency as a common property in neural networks and utilize the prior to train the substitute model.\nWe also design a symmetric network architecture and projection layers that are suitable for the offline stage.\n\n**Online semantic alignment.**\nIn addition to the offline semantic alignment, we further develop a self-supervised learning scheme to augment the online stage.\nDifferent from the offline stage, the substitute model in the online stage is trained with the victim output, and has similar outputs to the victim model.\nTherefore, the online semantic alignment scheme is aimed at further improving the performance of the substitute.\nOnline semantic alignment uses weak augmentations for the substitute to produce pseudo labels, and aligns the substitute output of strongly augmented data with the pseudo labels.\nThis approach gains extra accuracy increase for the substitute model over the original supervised training scheme.\n\n**Informative query generation.**\nWe also make an important contribution to the conventional model extraction framework by designing a query generation procedure with richer information.\nOur proposed query generation process achieves three main goals to increase the information density of synthesized queries:\n1) *Aggregating*: the generator can effectively merge information from multiple public data, \n2) *Informative*: the generator can produce information-extracting queries that minimize the gap between the substitute and the victim,\n3) *Stealthy*: the synthesized queries maintain the structure of a natural image instead of collapsing into indistinguishable patterns.\nWe propose\nan aggregation architecture and three loss functions for the query generator to achieve all three goals at the same time.\n\nWe have also modified our manuscript to provide an overall discussion on the design of the framework (Section 3.2), and provide more motivation for each main component of our framework (Section 3.3, Section 3.4). \n\n> 3. Is it possible to provide a simpler graph than Figure 1 for illustrating the main idea?\n\nWe thank the reviewer for the suggestion.\nWe have modified Figure 1 to provide a clearer illustration of our two main contributions.\nSpecifically, we have simplified the illustration of our proposed aggregated query generation to highlight the novel aggregation design."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission898/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700493110488,
                "cdate": 1700493110488,
                "tmdate": 1700493110488,
                "mdate": 1700493110488,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "P97l2HxcOr",
            "forum": "lygdvIKDxi",
            "replyto": "lygdvIKDxi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission898/Reviewer_WA7v"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission898/Reviewer_WA7v"
            ],
            "content": {
                "summary": {
                    "value": "Model extraction attacks focus on creating a substitute model whose performance resembles a victim model\u2019s performance; this is achieved by querying the victim model with a selection of samples and observing the output behavior. Among other things, doing so allows whitebox adversarial attacks to be used to target the victim model. This particular paper proposes two major components for improving such attacks. The first is a semantic alignment, done both as offline pre-training and during querying. The second is a way of parallelizing the query generation process by encoding the information of multiple samples into a single sample. The result is a method that is much more query-efficient than prior methods, gaining high substitute model, fidelity, and attack success rate with far fewer queries, while also being strong in the large query regime as well."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "## S1. Query efficiency\nA central claim of this paper is that the proposed method reduces the number of queries needed to perform a successful attack. This is important as a large number of queries renders a method slow and computationally expensive, while also significantly raising the risk of being detected (and stopped) by the target system. Figure 5 effectively illustrates how much faster the substitute model\u2019s metrics can improve using the proposed approach vs the baseline methods. Highlight claim is that this can be up to 50x more query efficient.\n\n## S2. Empirical Results\nThe empirical results of this paper are generally strong. Again, Figure 5 provides an excellent summary, showing higher accuracy, fidelity, and ASR vs competing methods, with fewer number of queries. At the (very) high query range, the proposed approach also shines (Table 2), barely edging out DFMS-SL. Results also appear to generalize to other model architectures (Table 3).\n\n\n## S3. Generally clearly written\nThe paper is clearly written and easy to understand. That said, the paper could still use another round of editing: there are a few typos, some potential improvements to the technical notation, and a number of other issues to fix (see Miscellaneous under Weaknesses). Overall though, this paper was easy to read."
                },
                "weaknesses": {
                    "value": "## W1. Novelty\nSemantic consistency is presented as one of the two methodological improvements proposed by the authors. The concept, however, doesn\u2019t strike me as particularly new. Offline semantic alignment is simply self-supervised pre-training on a different dataset (very reminiscent of [b], in fact); it\u2019s not particularly surprising that this is helpful, as that\u2019s more or less the whole point of self-supervised learning. The similarities in Grad-CAM visualizations doesn\u2019t necessarily have much to do with model extraction: it may be more due to having stronger features, which presumably the victim model also has, resulting in strong correlation. Online semantic consistency is more or less just knowledge distillation [d] with augmentations.\n\n## W2. Aggregation Design\na) Why the query perturbation/residual is added to the first input sample $x_{pub,1}$ (as opposed to, say, $x_{pub,2}$) isn\u2019t clear and seems like an arbitrary choice. It would seem like there could be a smarter way to select which of the $m$ samples to chose as the base sample. \\\nb) It\u2019s also not clear to me why there is a separate encoder per query index. As far as I can tell, the relative ordering of queries within a parallel batch is not meaningful, so there doesn\u2019t seem to be any added value behind having separate encoders, vs just having a single shared encoder or some other permutationally invariant design (e.g. a transformer).\\\nc) I don\u2019t fully understand the design of the reconstruction loss. Why do we care about reconstructing the input data? We already have the input data. Rather than generating new images through an encoder and decoder, what about simpler methods like MixUp or CutMix? The formulation in Equation 3 also involves a significant number of hyperparameters $\\alpha_j$ to tune, and it\u2019s not clear why they should be meaningfully different; as in b) above, it doesn\u2019t seem like the order of the samples have any inherent meaning, so why for example should $\\alpha_2 \\neq \\alpha_3$?\n\n## W3. Source of empirical improvements\nThe ablation study in Section 4.4 is very helpful, but it\u2019s also somewhat concerning too. From this table, it appears that the offline semantic alignment is the bulk of the source of improvements. While doing this offline semantic alignment is reasonable, as stated in W1 above, it\u2019s really another name for starting off with a stronger substitute model through standard self-supervised pre-training, which is already well known by the community to be generally effective for many downstream tasks. The form of self-supervised learning used by the authors is fairly standard, so it\u2019s not clear to me if this really can be counted as the authors\u2019 contribution.\n\n## W4. Section 4.5\nAnalysis of the proposed method\u2019s performance against defense mechanisms is welcome, but most of the actual results (particularly the paragraph on \u201cPassive Defenses\u201d) appear to be absent from the main paper and deferred to the Appendix. If these analyses are going to be introduced in the main paper, then at least some quantitative results should be included.\n\n## Miscellaneous:\n- pg 2: \u201cMosafi et al.(Mosafi et al., 2019)\u201d <= use in-text citation\n- pg 3: \u201cwith [a] generative adversarial network\u201d\n- Section 2.2: This section leaves out transfer-based blackbox attacks, which generate attacks on the attacker\u2019s own model, which are then given to the target (victim) model. Such approaches have also been combined with query-based attacks, with very low query requirements, e.g. [a].\n- pg 4: \u201ca[n] aggregated\u201d\n- pg 4: Why not denote $x_{pub}$ as $x_p$ instead, to match $D_P$?\n- pg 4: \u201c$i$-th query dataset\u201d <= isn\u2019t this just a sample and label, not a dataset?\n- pg 4: \u201cthat share the same weight[s]\u201d\n- pg 4: This is a standard Siamese network approach to self-supervised learning; more such methods should be cited: e.g. [b,c]\n- pg 5: \u201cwe [a] propose aggregated query generator\u201d\n- Eq 5: If I\u2019m understanding this loss correctly, I think this is for the $i+1$th iteration, not $i$th. Also, as written, this implies we only care about a new query sample not resembling the immediately previous query; this doesn\u2019t prevent a query for example from flipping back and forth between two queries.\n- pg 6: \u201cSecond, [w]e design\u201d\n- Fig 5: Caption should mention what dataset this is on. Text doesn\u2019t mention it either.\n- Table 2: What dataset is this? Text doesn\u2019t say either.\n- Table 3: What dataset is this? Text doesn\u2019t say either.\n- Table 4: What dataset is this? Text doesn\u2019t say either.\n\n\n[a] Inkawhich, Nathan, et al. \"Perturbing across the feature hierarchy to improve standard and strict blackbox attack transferability.\" NeurIPS 2020. \\\n[b] Chen, Xinlei, and Kaiming He. \"Exploring simple siamese representation learning.\" CVPR 2021.\\\n[c] He, Kaiming, et al. \"Momentum contrast for unsupervised visual representation learning.\" CVPR 2020.\\\n[d] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \"Distilling the knowledge in a neural network.\" 2015.\\"
                },
                "questions": {
                    "value": "Q1. How does the similarity of the public dataset to the target model\u2019s dataset affect results? The main results in Table 1 show significant overlap: CIFAR-10 is used as the public dataset when CIFAR-100 is the hidden dataset, and vice versa, and even Tiny-ImageNet has strong similarities compared to CIFAR 10/100.\\\nQ2. Is the substitute model the same architecture as the victim model? Is that a reasonable assumption to make? What if they\u2019re different?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "Although I answered \u201cNo\u201d above, this paper does deal with subject matter model extraction and adversarial attacks. Obviously, these such approaches can be applied for nefarious purposes, including theft or causing systems to behave in unexpected ways, leading to negative outcomes. With that said though, I don\u2019t believe this paper doesn\u2019t necessarily introduce any ethical concerns beyond what is common for other works working on this problem."
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission898/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698708280825,
            "cdate": 1698708280825,
            "tmdate": 1699636016364,
            "mdate": 1699636016364,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vC1Amx6g9s",
                "forum": "lygdvIKDxi",
                "replyto": "P97l2HxcOr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WA7v (1/3)"
                    },
                    "comment": {
                        "value": "We appreciate the reviewer for making detailed reviews and insightful comments on our work. \nIn this response, we have made several clarifications for our work and made some modifications to our manuscript according to the valuable suggestions of the reviewer.\nThe revised parts are marked as blue.\n\n## W1. The novelty of semantic alignment.\n\nWe thank the reviewers for the questions. We would like to make the following clarifications. \n\n\nFirst, we point out that no existing work in the field of model extraction has explored self-supervised learning.\nAlthough the Siamese design is common in self-supervised learning, we are the first to find that the design can be effective in model extraction, and adapt it with specific modules that are suitable for both the offline and online stages of the model extraction process.\nMoreover, we are the first to design an offline pre-training stage for model extraction.\nWhen designing the offline stage, we note that simply using *supervised* pre-training method for extracting *supervised* models has two major disadvantages: 1) supervised pre-training makes a strong and impractical assumption that the public dataset is annotated, and 2) such scheme performs worse that the proposed self-supervised scheme.\nIn contrast, we demonstrate the *self-supervised* learning approach not only eliminates the need for public annotation, but also demonstrates superior performance in extracting *supervised* models, as shown in Tab. R1.\nAdditionally, we would like to clarify that knowledge distillation is not applicable for online self-supervised training.\nKnowledge distillation minimizes the distance between the outputs of the teacher and student model, but the two models are the same in a self-supervised setting.\nTherefore, we design weak and strong augmentations to introduce semantic consistency as an extra prior that optimizes the substitute model in a self-supervised manner.\n\nTable R1. Comparisons between supervised pre-training and our proposed self-supervised pre-training\n\n|Pre-training strategy|Acc (\\%)|Fid (\\%)|ASR (\\%)|\n|---|---|---|---|\n|Baseline|74.30|75.87|46.92|\n|Baseline+supervised pre-training|81.56|82.02|78.31|\n|Baseline+self-supervised pre-training (ours)|85.11|86.26|84.74|\n\nFinally, we kindly point out that we carefully design the self-supervised approach according to the characteristics of the offline and online extraction stages.\nSpecifically, we would like to highlight the following contributions in designing self-supervised methods for two stages.\n\n* Network architecture:\nIn the offline stage, the adversary does not have any knowledge of the victim model, so we design a symmetric architecture for this stage.\nIn the online stage, as the substitute model already has similar prediction scores to the victim, we design a weakly augmented branch without backpropagation to produce pseudo labels and a strongly augmented branch to learn richer semantic information.\nWe also design different levels of augmentations accordingly for each stage.\n\n* Feature space for semantic alignment:\nIn the offline stage, we perform semantic alignment in a high-dimensional feature space to transfer representational information from the public dataset.\nIn the online stage, we directly optimize semantic consistency loss on the classification scores, as the substitute predictions are relatively accurate in this stage."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission898/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492768064,
                "cdate": 1700492768064,
                "tmdate": 1700492768064,
                "mdate": 1700492768064,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SstgSFgrrF",
                "forum": "lygdvIKDxi",
                "replyto": "P97l2HxcOr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WA7v (2/3)"
                    },
                    "comment": {
                        "value": "## W2 Concerns regarding the designs of aggregated query generator\n> a) Is there a way to select the best base image out of $m$ images instead of using $x_{pub, 1}?$\n\nWe thank the reviewer for the valuable suggestion.\nWe would like to point out that selecting the most suitable public data as the base image requires comparing the $m$ images based on the return of $V$, which causes extra queries and does not align with our goal of query efficiency.\nIn such a case, there is an exploration-utilization tradeoff between high query-efficiency and finding the theoretically optimal base image.\nTherefore, we choose to achieve higher query-efficiency by randomly selecting a base image.\n\n> b) Why not use encoders with shared weights in the aggregated design?\n\nThis is a very insightful comment, and we have also considered the shared encoder design when designing the aggregated query generator.\nAs shown in Tab. R2, we have found that using a shared encoder performs slightly worse than using different encoders for different indexes, and finally, we chose the latter as the current design.\n\nTable R2. Comparisons between Encoder Architecture\n\n|Encoder Architecture|Acc (\\%)|Fid (\\%)|ASR (\\%)|\n|---|---|---|---|\n|shared encoder|86.72|88.26|94.82|\n|different encoders (ours)|88.01|88.94|96.43|\n\nA potential explanation for this observation is that the encoders for the base image (i.e., $x_{pub,1}$) and the merged images  (i.e., $x_{pub,2}, ..., x_{pub,m}$) learn different parameters for encoding different inputs.\n\n\n> c) Explain the reconstruction loss: why use it, how to tune $\\alpha_j$, and if simple aggregation operations work. \n\nWe design the reconstruction loss that optimizes the query generator to effectively merge the information from different images, and we introduce $\\alpha_j$ to ensure the generated image largely resembles the base image instead of collapsing into unnatural patterns.\nTherefore, we set the $\\alpha_1$ to be larger for the base image and $\\alpha_2,...,\\alpha_m$ to be smaller for the other images.\nEmpirically, we find setting $\\alpha_2=...=\\alpha_m$ achieves a good performance, and did not carefully tune $\\alpha$ for each image.\n\nAs for simple aggregations,  \nwe have considered a few basic aggregation operations when choosing the aggregation design.\nWe found that such aggregations have two shortcomings: 1) such methods produce unnatural query images that can be easily detected by the victim, and 2) such methods provide no significant improvements or even worse results when compared to the baseline.\nAs shown in Tab. R3, we have found our proposed aggregated generator performs significantly better than simple linear combinations, such as average, MixUp (weighted average with a random probability), or CutMix.\n\nTable R3. Comparisons among different aggregation strategies\n|Aggregation Strategy|Acc (\\%)|Fid (\\%)|ASR (\\%)|\n|---|---|---|---|\n|Baseline|74.30|75.87|46.92|\n|Average|72.77|73.65|56.32|\n|MixUp|73.79|74.37|62.83|\n|CutMix|75.41|76.49|64.47|\n|Aggregated generator (ours)|84.75|86.23|94.33|\n\n\n## W3. Source of empirical improvements\n\nWe demonstrate that simply using supervised pre-training is much less effective than our offline self-supervised pre-training.\nMore importantly, we develop offline and online self-supervised training schemes according to the characteristics of the two stages, and the combination of both methods results in a strong overall performance.\nFinally, we note that our proposed aggregated generator not only contributes to the overall accuracy at a comparable level when compared to offline semantic alignment, but also makes a more significant boost in ASR (11.69\\%+) than offline semantic alignment.\n\n\n## W4 Section 4.5\nWe thank the reviewer for the suggestion, and we move more detailed quantitative results of the appendix to the main manuscript.\nThe modified content is marked as blue in paragraph 3, Section 4.5 in the revised paper."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission898/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492835874,
                "cdate": 1700492835874,
                "tmdate": 1700492835874,
                "mdate": 1700492835874,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "1eezZ8FjGA",
                "forum": "lygdvIKDxi",
                "replyto": "P97l2HxcOr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer WA7v (3/3)"
                    },
                    "comment": {
                        "value": "## Miscellaneous\nWe thank the reviewer for checking our manuscript in detail and proposing issues for us to further improve the quality of the manuscript.\nWe have made the following modifications:\n\n* Section 2.1, used in-time citation: \"Mosafi et al. (2019)\"\n* Fixed the typo in Section 2.2: \"with [a] generative adversarial network\"\n* We have added the following description regarding transfer-based attacks in Section 2.2: \"Generally speaking, we can classify black-box adversarial attacks into two categories:\nsubstitute-based, transfer-based, and query-based. \nFirst,\na number of substitute-based attacks have already demonstrated the effectiveness\nof using the extracted substitute model as a base for launching black-box \nadversarial attacks. \nAdditionally, transfer-based attacks assume the adversary can obtain a substitute model trained on the same dataset as the victim model, and focus on improving the transferability of the adversarial samples synthesized based on the substitute model.\nTherefore, substitute-based and transfer-based attacks are generally complementary to each other.\"\n* Fixed the typo in Section 3.2: \"a[n] aggregated\"\n* We denote the public dataset as $\\mathcal{D}\\_{pub}$ to match $x_{pub}$, which is clearer to read. We also denote the secret dataset as $\\mathcal{D}\\_{secret}$ in our revised manuscript.\n* We use a new index $j$ for a more clear description in Section 3.2: \"Here, we take the $i$-th iteration with the query number of $n_i$ as \nan example...the adversary obtains the $i$-th query dataset $\\mathcal{Q}\\_i=\\{(x\\_{query}^{i,j}, y\\_{query}^{i,j} = V(x\\_{query}^{i,j}) | j = 1, ..., n_i\\}$ by querying the victim.\"\"\n* Fixed the typo in Section 3.3.1: \"that share the same weight[s]\"\n* We have cited more papers for Siamese network architecture in Section 3.3.1.\n* Fixed the typo in Section 3.4: \"we propose [an] aggregated query generator\"\n* We have changed the notation $x_{query}^i$ to $x_{query}$. In the diversity loss, we are aimed at reducing the distance between the queries in the $i$-th iteration and all past queries. We thank the reviewer for pointing out the typo in the index.\n* Fixed the typo in Section 3.5: \"Second, [w]e design\"\n* Denoted the experimental setting for Fig.5, Tab.2, Tab.3, and Tab.4 in Section 4.1:  \"In Figure 5, Table 2,\nTable 3 and Table 4, we use CIFAR-10 as $\\mathcal{D}\\_{secret}$ and CIFAR-100 as $\\mathcal{D}\\_{pub}$ \"\n\n## Q1. How does the similarity of the public dataset to the victim model\u2019s dataset affect results? \nWe thank the reviewer for the question. We would like to point out that our attacks can still achieve state-of-the-art performance when the two datasets are very dissimilar in distribution.\nAs shown in Tab. 1 of the main manuscript, we have tested the performance of different attacks when the secret dataset is CIFAR-100, and the public dataset is ImageNet.\nThe CIFAR-100 and ImageNet datasets are collected independently, have distinctive classes without overlap, and also have different resolutions.\nWith such different distributions between the two datasets, our attack is able to demonstrate significantly stronger performance than the existing attacks.\n\n## Q2. What if the substitute model has a different architecture from the victim model?\nWe kindly point out that our attack obtains better accuracy and ASR than the best-performing attack across different substitute model architectures, as shown in Tab. 3 of the main manuscript.\nMoreover, we have compared the performance of our attack across more substitute model architectures in Tab. A2 of our appendix."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission898/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492967681,
                "cdate": 1700492967681,
                "tmdate": 1700492967681,
                "mdate": 1700492967681,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HTTBfFpmmj",
                "forum": "lygdvIKDxi",
                "replyto": "P97l2HxcOr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission898/Reviewer_WA7v"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission898/Reviewer_WA7v"
                ],
                "content": {
                    "comment": {
                        "value": "I thank the authors for their responses, as well as the updates they've made to the paper. I've also read the other reviewers comments.\n\nDespite the authors' arguments, I'm still not entirely convinced by the novelty here. The field as a whole is well-aware at this point that self-supervised learning is effective, and I don't believe that \"Self-supervised Learning Applied to X\" for every problem setting is necessary or novel. I understand that there are some nuances to the method beyond that, but I find these modifications relatively small. While novelty is not the sole basis of my score, it's something that I consider as part of my holistic evaluation.\n\nI also remain concerned about the methodology. I strongly believe we should not add ordering dependencies into a method where there are none. I accept that choosing a base image without increasing query count is nontrivial (although perhaps some comparison between images offline without querying the victim may be possible). However, the use of separate encoders is not something that makes sense to me, as again, the order of the images here is completely random and does not contain any learnable patterns. Perhaps there's some tangible benefit from having a different encoder for the base image given its distinct role compared to the others, but the method could still benefit from some re-thinking to make it more permutationally invariant.\n\nQ1: As I stated in my original question, while yes, there are some differences, CIFAR and TinyImageNet are both object-centric RGB datasets, and features will tend to transfer relatively well between them. There are much more different image datasets out there.\n\nQ2: For the different architectures in Table 3 and A2, what is the victim model architecture?"
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission898/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700611712133,
                "cdate": 1700611712133,
                "tmdate": 1700611712133,
                "mdate": 1700611712133,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "f9LiFY4SSr",
                "forum": "lygdvIKDxi",
                "replyto": "P97l2HxcOr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "content": {
                    "comment": {
                        "value": ">  I don't believe that applying \"Self-supervised Learning Applied to X\" for every problem setting is necessary or novel. I understand that there are some nuances to the method beyond that, but I find these modifications relatively small.\n\nWe thank the question of the reviewer regarding the novelty of self-supervised model extraction. \nWe would like to clarify that it is necessary and novel to design self-supervised learning approach for model extraction.\nAs most existing model extraction attacks only focus on information-extracting **data synthesis**, we point out a different approach regarding the **training procedure** of the substitute model.\nOur self-supervised approach is orthogonal to existing studies on supervised model extraction, and our proposed offline and online self-supervised methods can be combined with existing supervised learning attacks for significantly improved accuracy, ASR, and query-efficiency without extra query cost.\nWe believe this finding is impactful on the topic of model extraction, uncovering a different research direction for this field.\nFurthermore, by proposing the self-supervised model extraction, we reveal an important finding that the utilization of public data can pose serious security threats to private training data and confidential models, raising concerns about the protection of AI privacy and robustness.\n\nAdditionally, we kindly point out that the modifications we made for the original self-supervised framework are novel and effective for model extraction.\nParticularly, we have designed the stage-specific architecture, the feature space for alignment, and different semantically equivalent branches, all of which contribute to the strong overall performance.\n\n> Although there's some tangible benefit from having a different encoder for the base image given its distinct role compared to the others, the method could still benefit from some re-thinking to make it more permutationally invariant.\n\nWe thank the reviewer for the suggestion. \nWe have designed another architecture for the aggregated generator that both identifies the difference in the encoding of the base image and ensures the permutational invariance of the other images. Specifically, we design a *base encoder* for encoding the base image and a shared *merge encoder* to encode the other images. Also, we adopt a new formulation of the reconstruction loss with only two weight hyperparameters, one for the base image and one for the other merged images:\n$$\\mathcal{L}\\_R = \\frac{1}{m}(\\alpha_1||G(x\\_{pub,1}, x\\_{pub,2}, ..., x\\_{pub,m}) -  x\\_{pub,1}||\\_2+\\sum_{j=2}^m\\alpha_2||G(x\\_{pub,1}, x\\_{pub,2}, ..., x\\_{pub,m}) -  x\\_{pub,j}||\\_2),$$\n\nHere, we assign $\\alpha_1>\\alpha_2$ to ensure that the generated query preserves the structure of the base image. \nThis new formulation explicitly constrains the permutational invariance of the merged images and also gives a higher weight for the base image.\nThe above design ensures that the structure of the base image is better preserved while encoding the other images in a permutationally invariant manner.\n\nTable R1 shows this design obtains slightly better performance than the original design with different encoders. We have also included this design and results in Section D of our revised appendix and the new formulation of reconstruction loss in Section 3.4.2 of our revised manuscript.\n\nTable R1. Accuracy, fidelity, and ASR of two aggregation designs\n\n|Encoder Architecture|Acc (\\%)|Fid (\\%)|ASR (\\%)|\n|---|---|---|---|\n|different encoders|88.01|88.94|96.43|\n|Base encoder+Merge encoder|88.36|89.73|98.40|\n\n> Q1: Provide the results for more different public datasets.\n\nWe thank the suggestion of the reviewer. We have compared our method with the best-performing attack, Knockoff Nets, on different public datasets. \nAs shown in Table R2,\nwe have found that our method generalizes significantly better than the state-of-the-art attack on different datasets.\nHere, the secret dataset is CIFAR-10.\nWe have also included the results in Section J of our revised manuscript.\nAdditionally, we are running experiments with more public datasets, which will be provided in the final version of the paper.\n\nTable R2. Accuracy, fidelity, and ASR of different attacks across diverse public datasets.\n\n|Dataset|Method|Acc (\\%)|Fid (\\%)|ASR (\\%)|\n|---|---|---|---|---|\n|Caltech256 (Training set)|Knockoff Nets|50.05|50.75|42.63|\n|Caltech256 (Training set)|SEEKER (ours)|65.71|66.54|78.26|\n|STL10 (Unlabeled set)|Knockoff Nets|78.74|79.84|52.36|\n|STL10 (Unlabeled set)|SEEKER (ours)|88.57|89.89|98.97|\n\n\n> Q2: For the different architectures in Table 3 and A2, what is the victim model architecture?\n\nWe thank the reviewer for the question. The victim model architecture is ResNet-34 in Table 3 and A2 (changed to A3 for the revised version).\nWe have also provided this information in Section 4.1 of our revised manuscript and Section I of our revised appendix."
                    },
                    "title": {
                        "value": "Response to Reviewer WA7v"
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission898/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700740308457,
                "cdate": 1700740308457,
                "tmdate": 1700740690117,
                "mdate": 1700740690117,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "YMuI8SvpJt",
            "forum": "lygdvIKDxi",
            "replyto": "lygdvIKDxi",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission898/Reviewer_c2Ta"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission898/Reviewer_c2Ta"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a query-efficient model extraction framework including query-free self-supervised training and query-efficient query generator. The proposed SEEKER method shows superior experimental results on multiple benchmark datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well written and easy to understand. The idea of applying self0supervised training for model extraction is interesting."
                },
                "weaknesses": {
                    "value": "The method itself, although works great, seems a bit ad-hoc. It will be great to see some theoretical justifications behind the framework."
                },
                "questions": {
                    "value": "See weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission898/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699090865570,
            "cdate": 1699090865570,
            "tmdate": 1699636016280,
            "mdate": 1699636016280,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tSVVId0WzZ",
                "forum": "lygdvIKDxi",
                "replyto": "YMuI8SvpJt",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission898/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer c2Ta"
                    },
                    "comment": {
                        "value": "> Although the method works great, it will be great to see some theoretical justifications behind the framework.\n\nWe really appreciate the positive comments and valuable suggestions of the reviewer.\nWe would like to provide the following theoretical justifications for our proposed semantic alignment in this response.\nWe have also included this content in Section C of our revised Appendix.\n\nThe key insight of our semantic alignment approach is that the adversary can optimize a substitute model $S$ on a public dataset $\\mathcal{D}\\_{pub}$ to learn features that are similar to the victim model $V$, which is trained on a secret dataset $\\mathcal{D}\\_{secret}$.\nWithout loss of generality, we assume the substitute model $S$ is composed of an encoding function $f$ and a fully connected layer $W$.\nIn such a case, our observation can be reformulated as follows: if $f$ has a low semantic consistency loss and $W$ is trained on  $\\mathcal{D}\\_{secret}$ to evaluate the classification performance of $f$, $S$ has a low average classification loss on $\\mathcal{D}\\_{secret}$.\nTo prove this observation, we first formally define the notations.\n\nThe encoding function of $S$ belongs to $\\mathcal{F}$, a class of representation functions $f: \\mathcal{X} \\rightarrow \\mathbb{R}^d$, such that $||f(\\cdot)||\\leq R$ for some $R > 0$.\nWe denote the set of all classes in $\\mathcal{D}\\_{pub}$ as $\\mathcal{C}$, and each $c\\in\\mathcal{C}$ follows a probability distribution $\\mathcal{D}\\_c$.\nThe supervised classification loss of $S$ on $\\mathcal{D}\\_{secret}$ can be defined as \n$$\\mathcal{L}\\_{\\text{sup}}(S):= \\mathbb{E}\\_{(x,c)\\in\\mathcal{D}\\_{secret}} \\left[ l\\left(S(x)\\_c - S(x)\\_{c'\\neq c} \\right) \\right],$$\nwhere $l$ is a standard hinge loss or logistic loss, and $S=Wf$.\nWhen evaluating $S$, the best $W$ can be found by fixing $f$ and finetuning $W$. Therefore, we only denote the supervised loss of $f$ on $\\mathcal{D}\\_{secret}$ as:\n$$\\mathcal{L}\\_{\\text{sup}}(f) =\\inf_W \\mathcal{L}\\_{\\text{sup}}(Wf).$$\nAlso, our offline semantic consistency loss can be formalized as\n$$\n        \\mathcal{L}\\_C = -\\mathbb{E}\\_{x\\in\\mathcal{D}\\_{pub}}\\left[{\\rm log}\n        \\frac{{\\rm sim}(S({\\rm aug_{M}^1}(x)),S({\\rm aug_{M}^2}(x)))}\n        {\\sum_{x'\\in\\mathcal{D}\\_{pub}, x' \\neq x} {\\rm sim}(S(x),S(x'))} \\right],\n$$\nThe loss term can be simplified as \n$$\n\\mathcal{L}\\_C  = \\frac{1}{M} \\sum_{i=1}^{M} l\\left(f(x_j)^{T}(f(x_j^+) - f(x_j'))\\right),\n$$\nHere, $x_j$ and $x_j^+$ are semantically equivalent data constructed by augmentations.\nWith the notations above, we formalize a proposition as follows.\n\n**Proposition 1.**  *For a substitute model $S$ composed of an encoding function $f$ and a fully connected classification layer $W$, $S$ has a low average linear classification loss on $\\mathcal{D}\\_{secret}$ if $f$ has a low offline semantic consistency loss on $\\mathcal{D}\\_{pub}$.*\n\n\nWe use a theorem proposed in [1] (Theorem 4.1 of the original paper) to prove this proposition.\nLet $\\mathcal{S}=\\lbrace x_j, x_j^+, x_j' \\rbrace_{j=1}^M$ be the triplets sampled from $\\mathcal{D}\\_{pub}$ to optimize semantic consistency loss, \n$f\\_{|\\mathcal{S}} = \\left(f_t(x_j), f_t(x_j^+), f_t(x_j')\\right)\\_{j\\in[M],t\\in[d]}\\in \\mathbb{R}^{3dM}$ be the restriction for $\\mathcal{S}$ for any $f\\in \\mathcal{F}$, and we have a complexity measure with the following Rademacher average\n$$\n\\mathcal{R}(\\mathcal{F}) = \\mathbb{E}\\_{\\sigma\\in\\lbrace\\pm 1\\rbrace^{3dM}}\\left[\\sup_{f\\in \\mathcal{F}}<\\sigma, f\\_{|\\mathcal{S}}>\\right].\n$$\nLet $\\tau=\\mathbb{E}\\_{c,c'\\sim\\rho^2}\\lbrace c=c'\\rbrace$, and we have the following theorem[1]:\n\n**Theorem 1.** *With probability at least $1-\\tau$, for all $f\\in F$*\n$$\\mathcal{L}\\_{\\text{sup}} (\\widehat{f}) \\leqslant \\frac{1}{(1-\\tau)} \\mathcal{L}\\_C(f) - \\frac{\\tau}{(1-\\tau)} + \\frac{1}{(1-\\tau)} Gen_{M}$$\n*where*\n$$\\ Gen_{M} = O\\left(R \\frac{R_{s}(F)}{M} + R^{2} \\sqrt{\\frac{\\log \\frac{1}{d}}{M}}\\right)$$\nHere, we have $Gen_{M} \\rightarrow 0$ as $M\\rightarrow \\infty$, and when $\\rho$ is uniform and the number of classes $|C|\\rightarrow \\infty$, we have that $\\frac{1}{(1-\\tau)}\\rightarrow 0, -\\frac{\\tau}{(1-\\tau)}\\rightarrow 0$.\nTherefore, when the number of sampled training triplets is large and $f$ has a low offline semantic consistency loss on $\\mathcal{D}\\_{pub}$, then $S$ has a low average linear classification loss on $\\mathcal{D}\\_{secret}$.\n\n[1] Saunshi, Nikunj, et al. \"A theoretical analysis of contrastive unsupervised representation learning.\" International Conference on Machine Learning. PMLR, 2019."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission898/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700492595303,
                "cdate": 1700492595303,
                "tmdate": 1700492595303,
                "mdate": 1700492595303,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]