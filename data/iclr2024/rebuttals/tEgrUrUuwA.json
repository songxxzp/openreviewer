[
    {
        "title": "Partitioning Message Passing for Graph Fraud Detection"
    },
    {
        "review": {
            "id": "CZAynB3brp",
            "forum": "tEgrUrUuwA",
            "replyto": "tEgrUrUuwA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9114/Reviewer_wN2Y"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9114/Reviewer_wN2Y"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses the challenges in applying Graph Neural Networks (GNNs) to Graph Fraud Detection (GFD) tasks, specifically the issues of label imbalance and the mixture of homophily and heterophily. While existing GNN-based GFD models typically exclude heterophilic neighbors during message passing, the authors argue for distinguishing neighbors with different labels instead of exclusion. They introduce a new approach called Partitioning Message Passing (PMP), which adapts the information aggregated from heterophilic and homophilic neighbors, preventing the model gradient from being dominated by benign nodes. Theoretical connections and extensive experiments demonstrate that PMP significantly enhances GFD task performance, effectively addressing these challenges."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. This paper maintains a high level of self-containment and coherence, as the authors support the claims made within the manuscript through detailed explanations and experimental validation.\n2. This paper addresses the issues of label imbalance and the mixture of homophily-heterophily by introducing a new approach that assigns distinct parameter matrices to neighbors from different classes.\n3. The comparison algorithms used in experiments are state-of-the-art."
                },
                "weaknesses": {
                    "value": "1. There are some reservations regarding the novelty of this paper for the following reasons:\n\n     a) The issues of label imbalance and homophily-heterophily have been effectively addressed in the past. Notably, Tang et al. [1] offered a theoretical explanation for these concerns using spectral graph analysis.\n     \n     b) Building upon the findings of [1], this paper makes incremental enhancements in the field of fraud detection while questioning the complexity of earlier algorithms. Nonetheless, this paper does not provide comprehensive comparison of time and space complexities with previous works.\n\n2. The approach of treating fraud detection as a binary classification problem has inherent limitations. Real-world scenarios often involve anomalies that cannot be neatly classified into a single class and that do not adhere to clustering assumptions. Given the multitude of existing papers that have already presented effective solutions to address the challenges of imbalance and homophily-heterophily by binary classification algorithms, it raises questions about the need for publishing similar articles at the cutting-edge conference ICLR.\n\n3. An analysis about the labeled neighborhoods\u2019 label distributions of central nodes in the training dataset is necessary. This is crucial as the proposed method relies heavily on the labels of neighboring nodes. Furthermore, it is important to emphasize the ratio of normal nodes to anomaly nodes in the training data.\n\n4. Concerns have been raised about the correctness of equation (7).\n\n[1] Tang, Jianheng, et al. Rethinking graph neural networks for anomaly detection. ICML, 2022."
                },
                "questions": {
                    "value": "Please refer to the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9114/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9114/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9114/Reviewer_wN2Y"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9114/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698044210007,
            "cdate": 1698044210007,
            "tmdate": 1699637147006,
            "mdate": 1699637147006,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "6eqUG2NJ3S",
                "forum": "tEgrUrUuwA",
                "replyto": "CZAynB3brp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer wN2Y (part 1/3)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for providing insightful and constructive comments. We address the reviewer's comments/concerns as follows. \n\n**Q1.1: The issues of label imbalance and homophily-heterophily have been effectively addressed in the past. Notably, Tang et al. [1] offered a theoretical explanation for these concerns using spectral graph analysis.**\n\n**A1.1:** In our opinion, BWGNN proposed by Tang et al. [1] aims to preserve or emphasize information from certain frequencies based on the PDF of Beta distribution, so BWGNN acts as a band-pass spectral graph filter, which has been proved effective for graph with heterophily. However, BWGNN does not specifically cater to the label imbalance challenge. There are two key reasons for this. Firstly, BWGNN use Beta wavelets as propagation matrix, which is predefined and only related to the graph Laplacian, thus the propagation matrix of BWGNN is label-agnostic. Secondly, the feature transformation matrices of BWGNN is uniformly  shared across all nodes, so it is also label-agnostic. These two factors indicate that the training process of BWGNN does not  explicitly account for the label imbalance inherent in certain graphs. The empirical evidence presented in Table 4 of Section 5.3 illustrates that our approach more effectively mitigates problems arising from label imbalance compared to BWGNN. This is achieved by  investigating the influence distribution from neighbors on minority  class nodes and tailoring the message passing process accordingly.\n\n**Q1.2\uff1aBuilding upon the findings of [1], this paper makes incremental  enhancements in the field of fraud detection while questioning the  complexity of earlier algorithms. Nonetheless, This paper does not provide comprehensive comparison of time and space complexities with  previous works.**\n\n**A1.2:** We first show a detailed comparison of the time and space complexities in the following table (PC-GNN is built upon Care-GNN, and GHRN is an extension of BWGNN. They share similar complexity profiles with their respective base models), where $|E| \\ll N^2$ is the number of edges, $d$ is the feature dimension and $C$ is the number of spectral filter in BWGNN. Usually, $N > |E|$, thus our model demonstrates optimal time and space complexities compared to these baselines. We have updated it in the Appendix A of the revised manuscript.\n\n|              | Time Complexity | Storage Cost        |\n| ------------ | --------------- | ------------------- |\n| Care-GNN     | $O(Nd + \\|E\\|)$   | $O(Nd + N^2 + \\|E\\|)$ |\n| H2-FDetector | $O(N^2)$        | $O(Nd + N^2)$       |\n| BWGNN        | $O(C\\|E\\|)$       | $O(Nd + C\\|E\\|)$      |\n| PMP (Ours)   | $O(\\|E\\| + N)$    | $O(Nd + \\|E\\|)$       |\n\nBesides, we would like to explain that our PMP is not built upon the findings of BWGNN. PMP and BWGNN have different motivation, methodology, and theoretical insights. So we think BWGNN cannot hide our contributions. The main differences between PMP and BWGNN are summarized as follows:\n\n**[Motivation]** PMP is motivated by investigating the influence propagation during message passing (Section 2.2 in the updated version), which leads us to propose a fundamental principle for the  successful application of GNNs in GFD: distinguishing between neighbors with different labels during the message passing. However, BWGNN is motivated by the 'right-shift' phenomenon of the spectral energy distribution, which inspires the BWGNN to define a band-pass graph filter based on beta wavelet. \n\n**[Methodology]** \uff081\uff09**Label Utilization**: PMP is spatial and label-aware,  using distinct weight matrices for different labels. BWGNN, a spectral  model, has shared, label-agnostic parameters.(2). **Weight Matrix Design**: PMP's weight matrices are root-specific (See Section 3), tailored for each node. BWGNN uses randomly initialized weights. (3) **Unlabeled Nodes Handling**: PMP treats unlabeled nodes as a mix of benign and fraud labels (See Section 3),  while BWGNN treats all nodes uniformly, regardless of their labeled or unlabeled status."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700339061409,
                "cdate": 1700339061409,
                "tmdate": 1700339087810,
                "mdate": 1700339087810,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iYkACkgPiE",
                "forum": "tEgrUrUuwA",
                "replyto": "CZAynB3brp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer wN2Y (part 2/3)"
                    },
                    "comment": {
                        "value": "**Q2: The approach of treating fraud detection as a binary classification problem has inherent limitations. Real-world scenarios often involve anomalies that cannot be neatly classified into a single class and that do not adhere to clustering assumptions. Given the multitude of existing papers that have already presented effective solutions to address the challenges of imbalance and homophily-heterophily by binary classification algorithms, it raises questions about the need for publishing similar articles at the cutting-edge conference ICLR.**\n\n**A2:** We acknowledge that the binary classification framework has its limitations in capturing the full spectrum of real-world frauds. However, in real-world application, due to the large scale and strong heterogeneity of the network, we usually need to extract all potential fraud nodes first, and then do a more detailed classification and analysis of the extracted fraud nodes. Thus, modeling GFD problem as a binary classification is usually the first step. Besides, to our best knowledge, all the datasets publicly available and commonly used in research, including those we have utilized, are modeled for binary classification. This modeling choice reflects the practical realities of many real-world applications, where a binary approach remains a fundamental and highly effective method for initial fraud detection. We still greatly appreciate your valuable suggestion. Considering the current limitation of most works focusing on binary classification, we plan to explore the issue of multi-classification in our subsequent work.\n\nGiven the practical importance of graph fraud detection task, we agree that this problem has been studied in many past work. However, we do not think research in this area have converged because this problem is highly relevant to industrial applications. This requires that the model can capture the essence of the problem and be simple enough to make it easy to deploy in industrial environment. In our paper, we try to explore the key to solving this problem, rather than blindly designing complicated algorithms. Based on the motivation study, we propose that the key to successfully applying GNNs for GFD is to distinguish neighbors with different labels during message passing, instead of excluding heterophilic neighbors used in most prior work. Our proposed PMP is built upon this finding, and maintains simplicity to facilitate ease of deployment in industrial applications. To verify this point,  in Appendix E.2 of our paper, we present experiments conducted on datasets provided by our industrial collaborators. These experiments demonstrate the applicability and effectiveness of our method in real-world industrial scenarios, affirming its practical relevance. Thus, we believe our paper offers valuable insights for future research in  this domain."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700339143535,
                "cdate": 1700339143535,
                "tmdate": 1700339143535,
                "mdate": 1700339143535,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RtOPC9lrar",
                "forum": "tEgrUrUuwA",
                "replyto": "CZAynB3brp",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer wN2Y (part 3/3)"
                    },
                    "comment": {
                        "value": "**Q3: An analysis about the labeled neighborhoods\u2019 label distributions of  central nodes in the training dataset is necessary. This is crucial as  the proposed method relies heavily on the labels of neighboring nodes.  Furthermore, it is important to emphasize the ratio of normal nodes to anomaly nodes in the training data.**\n\n**A3:** Your suggestion is indeed crucial.  Therefore, we present the label distributions of the labeled neighborhoods of the training nodes in the **Appendix D.2** of the revised paper. Here, we present these distributions in it in tabular form. More details and distribution diagram can be found in the Appendix D.2.\n\nTo analyze the label distributions of the labeled neighborhoods of training nodes, we use $\\frac{|\\mathcal{N}\\_{fr}|}{|\\mathcal{N}\\_{be}|}$ to represent the number of fraud neighbors relative to benign neighbors for a central node. $\\frac{|\\mathcal{N}\\_{fr}|}{|\\mathcal{N}\\_{be}|} <1$  indicates that the number of labeled fraud neighbors is fewer than benign neighbors. Specifically, if $\\frac{|\\mathcal{N}\\_{fr}|}{|\\mathcal{N}\\_{be}|} <0.5$, it  indicates that the central node has far fewer fraud neighbors compared  to benign ones, denoting a highly imbalanced neighborhood.  Consequently, the smaller the value of $\\frac{|\\mathcal{N}\\_{fr}|}{|\\mathcal{N}\\_{be}|}$, the more imbalanced the label distribution of neighbors of a given central node is. We use $|V_{\\frac{|\\mathcal{N}\\_{fr}|}{|\\mathcal{N}\\_{be}|} < 1}|$ to represent the number of training center nodes with $\\frac{|\\mathcal{N}\\_{fr}|}{|\\mathcal{N}\\_{be}|} < 1$, allowing us to assess the label distribution relative to this ratio.\n\n|                                                              | Yelp  | Amazon | T-Finance |\n| ------------------------------------------------------------ | ----- | ------ | --------- |\n| $\\frac{\\|V_{\\frac{\\|\\mathcal{N}\\_{fr}\\|}{\\|\\mathcal{N}\\_{be}\\|} < 1}\\|}{N}$ | 98.7% | 99.9%  | 100%      |\n| $\\frac{\\|V_{\\frac{\\|\\mathcal{N}\\_{fr}\\|}{\\|\\mathcal{N}\\_{be}\\|} < 0.5}\\|}{N}$ | 97.2% | 99.7%  | 100%      |\n\nOur results show that commonly used datasets such as Yelp, Amazon, and T-Finance suffer from significant label imbalance in the neighborhoods, which could lead to the general vanishing of the general GNN model with respect to the minority class neighbors, as we state in Section 2.2. Thus, since the model trained under the condition of imbalanced neighborhood label distribution, the ideal model needs to enhance the influence from the minority class neighbors on the center nodes. As demonstrated in Section 5.3, our PMP method effectively achieves  this, enhancing the influence from minority class neighbors more  efficiently than traditional GNN approaches.\n\nRegarding your query about the ratio of normal to anomaly nodes in the training data, this ratio in the training set is the same as the ratio in the whole graph. Specifically, in the following table, we show the ratio of fraud nodes in the whole graph. For example, 14.53% of nodes in the Yelp are fraud nodes, so in the training set, the fraud nodes also occupy 14.53% of the training set. \n\n|           | % Fraud Nodes |\n| --------- | ------------- |\n| Yelp      | 14.53%        |\n| Amazon    | 6.87%         |\n| T-Finance | 4.58%         |\n| T-Social  | 3.01%         |\n\n**Q4: Concerns have been raised about the correctness of equation (7).**\n\n**A4:** Based on your concerns, we re-examined the derivation process of Theorem 1 and equation (7). The proof of equation (7) is similar to the spectral analysis flow of traditional GCN, and the detailed proof can be found in Appendix B. We're sure it's correct."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700339319348,
                "cdate": 1700339319348,
                "tmdate": 1700339319348,
                "mdate": 1700339319348,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "WFaViBjeXu",
                "forum": "tEgrUrUuwA",
                "replyto": "RtOPC9lrar",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Reviewer_wN2Y"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Reviewer_wN2Y"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thank you for the author's response. While your reply has addressed some of my concerns, I still find this article slightly below the borderline accept threshold. The reasons are outlined below:\n\n1. The main concept of creating a spatial graph convolution as a high- and low-pass filter is intriguing, but the methodology appears somewhat rough. For instance, relying on the output of the $f_{self}$ function as input for an MLP to learn $\\alpha^{l}_i$ lacks convincing rationale, particularly since the authors did not analyze the characteristics of node features for normal and abnormal nodes.\n\n2. In the industry, treating fraud detection as a binary classification problem may lead to model failure, as fraud patterns are not static. The binary classification model can become invalid when the characteristics of new fraudsters differ significantly from those of old fraudsters.\n\n3. Equation 12 in Algorithm A reveals that the model still grapples with imbalance issues. While the author addresses the problem of unbalanced label distribution among neighbouring nodes through PARTITIONING MESSAGE PASSING, the imbalance of the central node persists. While PARTITIONING MESSAGE PASSING may alleviate the negative impact of label imbalance to some extent, it does not provide a direct solution.\n\n4. In real-world scenarios, it is possible that many labelled central nodes may lack labelled fraudulent neighbours, due to the scarcity of fraud nodes. I am uncertain if this situation affects the model's performance. I previously suggested that the author analyse the labelled neighbourhood of the central node to address this concern.\n\nTo sum up, I will keep the score 5."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700449222841,
                "cdate": 1700449222841,
                "tmdate": 1700449222841,
                "mdate": 1700449222841,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "bHaxHFYUBA",
            "forum": "tEgrUrUuwA",
            "replyto": "tEgrUrUuwA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9114/Reviewer_XqA8"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9114/Reviewer_XqA8"
            ],
            "content": {
                "summary": {
                    "value": "This work addresses the challenges of label imbalance and the complex interplay between homophily and heterophily in Graph Neural Networks for Graph Fraud Detection. It introduces a novel approach called Partitioning Message Passing (PMP). In this method, neighboring nodes of different classes are processed using distinct, node-specific aggregation functions. Furthermore, the central node has the ability to adaptively fine-tune the information it gathers from both its heterophilic and homophilic neighbors. Empirical results reveal that the PMP method outperforms other competitive algorithms across a range of datasets, including Yelp, Amazon, and T-Finance, while maintaining an optimal balance between performance and computational time."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The PMP method is well-designed, offering a straightforward solution that is easy to understand and implement.\n2. The article employs a comprehensive analytical framework to validate the effectiveness of the PMP method, adding to its credibility."
                },
                "weaknesses": {
                    "value": "1. The primary innovation in the PMP method lies in the use of different weighting matrices for aggregating nodes of various classes. While effective, this focus may be perceived as lacking in breadth in terms of overall innovativeness.\n2. The article would benefit from a more meticulous attention to the use of symbols and language. Ensuring consistent and clear terminology and notation would contribute to the paper's readability and accessibility."
                },
                "questions": {
                    "value": "1. On Page 2, in the penultimate line of \"where each node v_i is assigned a binary label y_i\u2208Y\", please confirm whether it is \"Y\" or \"fi\"?\n2. In the description of Eq.(4) on page 4, it is mentioned that \"In other words, a small \u03b1_i^((l)) means that the model treats unlabeled neighbors more similarly to fraud nodes\". In conjunction with Eq.(4), shouldn't it be the case that a smaller \u03b1_i^((l)) makes unlabeled neighbors more biased to benign nodes?\n3. Throughout the paper, sections 2, 3, and 7 are more similar to one part of the content, related work, could they be synthesized into one section?\n4. When introducing PMP, the article mentions the use of one layer of MLP in the generation of \u03b1_i^((l)). Still, it does not note how many layers of MLP are used in the subsequent \"Root-specific weight matrices generation.\n5. In the experimental results for the T-Social dataset, the AUC value is much higher than that of the comparative algorithm, close to 100%, is it possible to analyze the reason for this excellent result?\n6. In the last sentence of Section 6.4, \"wherein each of these designs brings more than a 1% improvement across most metrics\", does that mean that each approach delivers at least a 1% improvement over GraphSAGE, or does it mean that it provides a 1% improvement over the previous pivotal components? Please be as precise as possible."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9114/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9114/Reviewer_XqA8",
                        "ICLR.cc/2024/Conference/Submission9114/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9114/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698721224300,
            "cdate": 1698721224300,
            "tmdate": 1700710887285,
            "mdate": 1700710887285,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "vsJ8aqbNqJ",
                "forum": "tEgrUrUuwA",
                "replyto": "bHaxHFYUBA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XqA8 (part 1/2)"
                    },
                    "comment": {
                        "value": "We thank you for your time and effort in reviewing our paper. Below, we respond to address your concerns.\n\n**Q1: The primary innovation in the PMP method lies in the use of different weighting matrices for aggregating nodes of various classes. While effective, this focus may be perceived as lacking in breadth in terms of overall innovativeness.** \n\n**A1:** We understand that our embarrassingly simple model may give rise to concerns about its innovativeness. We respectfully argue that our work is novel, and we highlight our technical novelty as follows: \n\n1. **[High-level insight]** We propose that the key to successfully applying GNNs for GFD relies not on excluding which used in most prior work, but on distinctly recognizing and processing neighbors with different labels during message passing.  Thus, our approach is a fundamental departure from existing methodologies.\n\n2. **[Strong practical implications in applying GNN to GFD Applications]**  Graph fraud detection is a practical problem, especially in the industrial application. Thus, it is crucial to capture the essence of the problem, and design a simple and easy-to-deploy model. Our PMP method is designed with these requirements in mind. Through the motivation study, theoretical analysis and strong empirical results, we demonstrate PMP's effectiveness. The simplicity of our model does not diminish its impact; rather, it enhances its practical utility, making it a valuable tool in real-world applications. \n\nWhile PMP's design is straightforward in form, it represents a meaningful step forward in the field, offering both a novel perspective and a practical solution. We believe that PMP has a certain guiding role in future work.\n\n**Q2: The article would benefit from a more meticulous attention to the use of symbols and language. Ensuring consistent and clear terminology and  notation would contribute to the paper's readability and accessibility.**\n\n**A2:** Thanks for your valuable feedback. We have undertaken a thorough review of our manuscript with a focus on standardizing the terminology and symbols used throughout the paper. The modifications have been highlighted in blue in the resvised manuscript.\n\n**Q3: On Page 2, in the penultimate line of \"where each node v_i is assigned a binary label $y_i\\in Y$\", please confirm whether it is \"Y\" or \"fi\"?** \n\n**A3:** In our paper, $\\mathcal{Y} = \\{y_1, y_2, \\cdots, y_N\\}$ represents the set of node labels, where $y_i \\in \\mathcal{Y}$ means the label of node $v_i$. $y_i$ has two possible values, i.e., $y_i = 1$ denotes $v_i$ is a fraud node $0$ denotes benign node.\n\n**Q4:  In the description of Eq.(4) on page 4, it is mentioned that \"In other words, a small $\\alpha_i^{(l)}$ means that the model treats unlabeled neighbors more similarly to fraud nodes\". In conjunction with Eq.(4), shouldn't it be the case that a smaller $\\alpha_i^{(l)}$ makes unlabeled neighbors more biased to benign nodes?**\n\n**A4:** Thanks for pointing this out. Upon re-examination, we agree that there was an error in our description of how $\\alpha^{(l)}\\_{i}$ influences the treatment of unlabeled neighbors in our model. As you correctly noted, a small $\\alpha^{(l)}\\_{i}$ should indeed indicate that the model treats unlabeled neighbors more similarly to benign nodes due to the larger weight placed on $\\mathbf{W}\\_{\\text{be}}^{(l)}$. We have corrected the text in the manuscript to accurately reflect this relationship. \n\n**Q5: Throughout the paper, sections 2, 3, and 7 are more similar to one part of the content, related work, could they be synthesized into one section?**\n\n**A5:** We agree your suggestion that enhances the readability. We have merged Sections 2, 3, and 7 into a single cohesive section titled \"Background and Motivation\" in new Section 2.\n\n**Q6:  When introducing PMP, the article mentions the use of one layer of MLP in the generation of $\\alpha^{(l)}_{i}$. Still, it does not note how many layers of MLP are used in the subsequent \"Root-specific weight matrices generation\".**\n\n**A6:** To maintain simplicity in the model design, we also apply the single-layer MLP in the \"Root-specific weight matrices generation\" to define the weight generators $\\Psi_{\\text{fr}}$ and $\\Psi_{\\text{be}}$. We have clarified this point in the revised manuscript. Moreover, we show influence of the number of MLP layers on the final results (AUC). We can find that the number of MLP layers does not drastically affect the performance of the model.\n\n| #layers | Yelp  | Amazon |\n| ------- | ----- | ------ |\n| 1       | 93.97 | 97.57  |\n| 2       | 93.95 | 97.51  |"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338768731,
                "cdate": 1700338768731,
                "tmdate": 1700338768731,
                "mdate": 1700338768731,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XqdDbtXHWb",
                "forum": "tEgrUrUuwA",
                "replyto": "bHaxHFYUBA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer XqA8 (part 2/2)"
                    },
                    "comment": {
                        "value": "**Q7:  In the experimental results for the T-Social dataset, the AUC value is much higher than that of the comparative algorithm, close to 100\\%, is it possible to analyze the reason for this excellent result?**\n\n**A7:** Referring to Table 2, our PMP model shows substantial improvements compared to other baselines. Specifically, it surpasses the current state-of-the-art by 4.9% in AUC and achieves an 11.21% relative increase in Macro-F1 score.\n\nWe analyze the characteristics of the T-Social dataset. From the global perspective, as shown in Table 4, T-Social is an exceptionally large-scale dataset, having over 5 million nodes.This size is roughly 100 times greater than other datasets used in our study, presenting a unique scalability challenge for GNNs. Some baselines (Care-GNN, PC-GNN, H2-FDetector, GHRN) focus on augmenting graph structure by resampling neighbors, reweighting or pruning edges for each node to balance the message passing. However, given the immense size of T-Social, coupled with its diverse local patterns (where node degrees range from 1 to 3217), it becomes challenging to learn or define a general and shared strategy for local structure augmentation applicable to all nodes. Consequently, these models are less effective on large scale graphs. Differently, PMP and BWGNN do not make any assumptions about the local structure at the node level. They learn directly from the original graph without implementing any node-level augmentations. These approaches effectively alleviates the scalability challenges posed by the size and complexity of T-Social.\n\nThen we would like to analyze the reason why PMP is better than BWGNN from the perspective of label imbalance. As shown in Table 4, T-Social exhibits a higher imbalance level, with only 3% of its nodes labeled as fraud. This leads to benign nodes overwhelmingly dominate the dataset, both in number and proportion. For BWGNN, the propagation matrix is predefined by Beta wavelet matrix, which is label-agnostic, and the feature transformation matrix is shared across all nodes, it leads to label imbalance knowledge can not be encoded into the model parameters during message passing. For our PMP, our model encode label information into the trainable parameter by utilizing distinct transformation matrices for different classes during the aggregation process, By processing nodes of different classes independently, the overfitting of the model to the class is alleviated. We believe that this is the key factor contributing to the excellent results achieved by our PMP.\n\n**Q8: In the last sentence of Section 5.4, \"wherein each of these designs brings more than a 1% improvement across most metrics\", does that mean that each approach delivers at least a 1% improvement over GraphSAGE, or does it mean that it provides a 1% improvement over the previous pivotal components? Please be as precise as possible.**\n\n**A8:** Thanks for pointing out our imprecise description. The \"+partition\" serves as the foundational element and is responsible for the major improvements observed, because it yields more than 3% improvement compared to GraphSAGE on most metrics. The subsequent components, \"++adaptive combination\" and \"+++root-specific weights\", are developed upon the \"+partition\" base. 1% improvement here means \"++adaptive combination\" and \"+++root-specific weights\" bring a cumulative improvement of more than 1% to \"+partition\". Both  components provide useful contributions, but the amount of contribution provided by the two components differs depending on the datasets. For example, \"++adaptive combination\" bring a small improvement while \"+++root-specific weights\" provide more, such as in T-Finance dataset, while in Amazon dataset, \"++adaptive combination\" brings more improvement. We recognize that our initial expression in the paper might have been  imprecise, and we have now amended as:\n\n**The \"++adaptive combination\", building upon the \"+partition\", brings incremental improvements across all datasets. The \"+++root-specific weights\", further extending the preceding component, enhances performance on most metrics in most datasets. Combined, these two components contribute to a cumulative improvement of more than 1% over the \"+partition\" baseline.**\n\nThe modification has been marked as blue in Section 5.4 in the revised manuscript."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338847741,
                "cdate": 1700338847741,
                "tmdate": 1700338847741,
                "mdate": 1700338847741,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iynQYtvE6S",
                "forum": "tEgrUrUuwA",
                "replyto": "bHaxHFYUBA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your response"
                    },
                    "comment": {
                        "value": "Dear Reviewer XqA8,\n\nWe appreciate your valuable feedback on our paper. With the discussion period nearing its end, we've compiled a succinct summary of our responses to your comments for ease of reference in your final evaluation:\n\n**Part 1**: We highlight our contribution from the perspectives of high-level insight and practical value.\n\n**Part 2**: The manuscript have been revised to ensure consistency and enhance its readability and accessibility.\n\n**Part 3**: We have corrected an inaccurate description of $\\alpha$.\n\n**Part 4**: The sections of the paper have been reorganized based on your suggestions.\n\n**Part 5**: We have added detailed hyperparameter settings. \n\n**Part 6**: We analyzed the experimental results on T-Social datasets, and modified  imprecise descriptions in the experiment analysis.\n\nWarm regards,\n\nThe Authors of Submission 9114."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700676018968,
                "cdate": 1700676018968,
                "tmdate": 1700676018968,
                "mdate": 1700676018968,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rmv1UfSCBW",
                "forum": "tEgrUrUuwA",
                "replyto": "iynQYtvE6S",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Reviewer_XqA8"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Reviewer_XqA8"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors, \nThank you for your response and pardon my late reply. I appreciate the time and efforts you put on rebuttal. The response is clear and well addressed my concerns. Therefore, I am amending my score upward."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700710857278,
                "cdate": 1700710857278,
                "tmdate": 1700710857278,
                "mdate": 1700710857278,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "oYlUll4x3b",
            "forum": "tEgrUrUuwA",
            "replyto": "tEgrUrUuwA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9114/Reviewer_8onS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9114/Reviewer_8onS"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors address fundamental challenges faced in applying Graph Neural Networks (GNNs) to Graph Fraud Detection (GFD) tasks, namely, label imbalance and the mixture of homophily-heterophily. Existing GNN-based GFD models modify graph structures to accommodate GNNs' homophilic bias by excluding heterophilic neighbors during message passing. However, the authors propose a novel perspective: instead of excluding, they advocate for distinguishing neighbors with different labels. They introduce a method called Partitioning Message Passing (PMP), a message passing paradigm tailored for GFD. In PMP, neighbors with different classes are aggregated using distinct node-specific aggregation functions. This approach allows the central node to adaptively adjust the information gathered from both heterophilic and homophilic neighbors. By doing so, PMP prevents the model gradient from being dominated by benign nodes, which constitute the majority of the population. The authors establish a theoretical connection between the spatial formulation of PMP and spectral analysis, characterizing PMP as an adaptive node-specific spectral graph filter. This demonstrates PMP's ability to handle graphs with mixed heterophily and homophily. Extensive experiments validate the effectiveness of PMP, showing significant performance improvements in Graph Fraud Detection tasks. PMP's innovative approach of distinguishing rather than excluding neighbors with different labels showcases its potential in enhancing the capabilities of GNNs for fraud detection on graphs."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The solution to adaptively learn from heterophilous and homophilous nodes for fraud detection is interesting and the theoretical analysis is sound.\n\n- The paper is generally well-written and almost clear everywhere.\n\n- Experiments conducted on datasets with different sizes show the effectiveness and efficiency of the proposed method in graph fraud detection."
                },
                "weaknesses": {
                    "value": "- The relationships between heterophily and imbalance (which is specific in fraud detection) are not clear. This is important to understand the problem.\n\n- The relationships between the proposed method and some previous spectral GNNs, e.g., [1], have not been discussed. A lack of discussions about differences may limit the novelty of the proposed method.\n\n- A minor issue: repeated references 2nd and 3rd articles.\n\n[1] Is Heterophily A Real Nightmare For Graph Neural Networks on Performing Node Classification? 2021"
                },
                "questions": {
                    "value": "- The strategy of partitioning message passing is very similar to GNNs with adaptive channel mixing used in [1] although [1] is from the spectral perspective. It will be interesting to discuss the differences and relationships between your proposed method and [1].\n\n- The discussion on the relationships between heterophily and imbalance is not detailed. A detailed empirical and/or theoretical analysis of relationships between heterophily and imbalance on graphs should be conducted to better understand the problem.\n\n[1] Is Heterophily A Real Nightmare For Graph Neural Networks on Performing Node Classification? 2021"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9114/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9114/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9114/Reviewer_8onS"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9114/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698801112085,
            "cdate": 1698801112085,
            "tmdate": 1700701103760,
            "mdate": 1700701103760,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "KUbXUmu6YA",
                "forum": "tEgrUrUuwA",
                "replyto": "oYlUll4x3b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8onS (Part 1/2)"
                    },
                    "comment": {
                        "value": "We thank you for your time and effort in reviewing our paper. Below, we respond to address your concerns.\n\n**Q1: The relationships between heterophily and imbalance (which is specific in fraud detection) are not clear. This is important to understand the problem.**\n\n**A1:** In the context of network fraud detection, attackers strategically inject fraud nodes sparsely within benign communities to camouflage fraudulent activities and spread their influence to normal nodes. As a result, these fraud nodes frequently establish connections with benign nodes, leading to a network characterized by heterophily -- where connections are predominantly between nodes with dissimilar labels (i.e., fraud nodes connecting with benign nodes). In the **Table 5 of Appendix D.1**, we show the heterophily level with measure $\\hat{\\eta}$ of real-world datasets , which clearly demonstrate the heterophilic nature of such networks. \n\nFurthermore, the injection of fraud nodes into the network is deliberately kept to a minimum to conceal their fraudulent activities. This results in a significantly smaller population of fraud nodes compared to benign ones, thus engendering a label imbalance in the fraud graph. As evidenced in Table 5 of Appendix D.1, less than 10% of nodes in commonly used datasets are labeled as fraud nodes. Here we show the statistical data of the benchmark datasets as follows:\n\n|           | Imbalance Level (% Fraud Nodes) | Homophily ratio ($\\hat{\\eta}$) |\n| --------- | ------------------------------- | ------------------------------ |\n| Yelp      | 14.53%                          | 0.0538                         |\n| Amazon    | 6.87%                           | 0.0512                         |\n| T-Finance | 4.58%                           | 0.4363                         |\n| T-Social  | 3.01%                           | 0.1003                         |\n\nOverall, such a sparse distribution of fraud nodes not only confirms the label imbalance but also contributes to the network's heterophilic characteristics. Such interplay of heterophily and label imbalance in fraud graphs provides a unique challenge for GNNs."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338350694,
                "cdate": 1700338350694,
                "tmdate": 1700338350694,
                "mdate": 1700338350694,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Rq3PEczgah",
                "forum": "tEgrUrUuwA",
                "replyto": "oYlUll4x3b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 8onS (Part 2/2)"
                    },
                    "comment": {
                        "value": "**Q2: The strategy of partitioning message passing is very similar to GNNs with adaptive channel mixing used in [1] although [1] is from the spectral perspective. It will be interesting to discuss the differences and relationships between your proposed method and [1].**\n\n**A2:** Thanks for your suggestions, which inspire us to rethink our Partitioning Message Passing (PMP) and Adaptive Channel Mixing (ACM) [1]. We agree that our work does indeed share similarities with ACM. However, the motivation, methodology, theoretical insights still differ. We provide a detailed comparison from these perspectives as follows: \n\n**[Motivation]** In our paper, we contend that the key to successfully applying GNNs for GFD task lies not in the exclusion of neighbors but in the ability to *distinguish* between them based on their labels during the neighborhood aggregation. This core belief is operationalized in our proposed PMP framework, which integrates this motivation into the traditional message passing paradigm. By partitioning neighbors during the aggregation phase using distinct transformation matrices, PMP effectively discriminates between different classes of neighbors, ensuring that the message passing mechanism is both simple and highly effective in addressing the unique challenges of GFD. \n\nContrastingly, ACM is motivated by the concept of \"*Diversification Distinguishability*\", which primarily involves attributing negative weights to heterophilic neighbors through a spectral synthesis of low-pass and high-pass filters. This technique fundamentally differs from our PMP. It is because the use of negative weights in ACM is indicative of removing (or subtracting) the heterophilc components from the homophilic neighbors. This can be interpreted as a form of information '*forgetting*' where heterophilic features are de-emphasized in favor of homophilic features. It is different from PMP which preserves and utilizes all available information. \n\n**[Methodology]** ACM is rooted in spectral graph theory, while PMP is spatially oriented. This difference is not just theoretical but has practical implications. The spectral nature of ACM inherently influences its scalability, particularly in the context of large graphs. Typically, spectral-based models, including ACM, require the entire graph as input, which can pose challenges for mini-batch training and thereby limit scalability. In contrast, our PMP model, with its spatial-based framework, inherently supports mini-batch training and is thus more adaptable to large-scale graphs. Furthermore, considering the application of ACM in GFD tasks, its formulation, with removed nonlinearity for simplicity's sake, can be expressed as $H_{\\textbf{ACM}}^{(l+1)} = \\alpha F_{L}\\begin{bmatrix}H^{(l)}\\_{fr} \\\\\\ H^{(l)}\\_{be} \\\\\\ H^{(l)}\\_{un}\\end{bmatrix} W_{1}^{(l)} + \\beta F_{H}\\begin{bmatrix}H^{(l)}\\_{fr} \\\\\\ H^{(l)}\\_{be} \\\\\\ H^{(l)}\\_{un}\\end{bmatrix} W_{2}^{(l)}$ where $F_L$ and $F_H$ are distinct spectral filters. We can observation that the trainable weight matrix $W_{L}^{(l)}$ and $W_{H}^{(l)}$ are both shared across all nodes. In contrast, our PMP model, when represented in matrix form, can be rewritten as $H_{\\textbf{PMP}}^{(l+1)} = F \\begin{bmatrix}H^{(l)}\\_{fr} W_1\\\\\\ H^{(l)}\\_{be} W_2 \\\\\\ H^{(l)}\\_{un} (\\alpha W_1 + (1-\\alpha)W_2)\\end{bmatrix}$ where $F$ is the normalized adjacency matrix. Unlike ACM, trainable weight matrices in PMP, $W_1$ and $W_2$ , are specifically applied to nodes with different labels, where $W_1$ and $W_2$ captures the information of fraud nodes and benign nodes respectively, reflecting a more label-aware and adaptive approach to message passing in the context of GFD.\n\n**[Theoretical Insights]** The theoretical insights of PMP and ACM reveal a significant divergence in their spectral capabilities, highlighting a fundamental difference in how they process graph signals. Specifically, ACM predominantly operates as a combination of low-pass and high-pass filters, which (de)emphasizing high or low frequency signal components can not control the information from other spectrum, i.e., ACM does not equate to the functionality of a band-pass filter. Differently, our theoretical analysis and visualization in Section.4 proves that our PMP operates as an adaptive graph filter which cover all frequencies in the spectral domain.\n\nWe also think such comparisons are very meaningful for a deeper understanding of our work, thus we include them in **Appendix C** of the revised manuscript.\n\n**Q3: A minor issue: repeated references 2nd and 3rd articles.**\n\n**A3:** Thank you for pointing out the repeated references. We have carefully reviewed the manuscript and rectified the referencing. This correction has been reflected in the revised manuscript."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338545164,
                "cdate": 1700338545164,
                "tmdate": 1700338545164,
                "mdate": 1700338545164,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "J1XUYPTb4I",
                "forum": "tEgrUrUuwA",
                "replyto": "oYlUll4x3b",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your response"
                    },
                    "comment": {
                        "value": "Dear Reviewer 8onS,\n\nThank you again for your thoughtful feedback on our submission. As the discussion period draws to a close, we have prepared a brief summary  below that encapsulates our responses to your points for your convenience in the final review:\n\n**Part 1**: We have explained the relationship between homophily and label imbalance under the fraud detection task.\n\n**Part 2**: We have provided a detailed comparison between PMP and ACM from the perspectives of motivation, methodology, theoretical insights.\n\n**Part 3**: We have corrected the repeated references.\n\nWarm regards,\n\nThe Authors of Submission 9114."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675982923,
                "cdate": 1700675982923,
                "tmdate": 1700675982923,
                "mdate": 1700675982923,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Zgl0YAynQ9",
                "forum": "tEgrUrUuwA",
                "replyto": "J1XUYPTb4I",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Reviewer_8onS"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Reviewer_8onS"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response"
                    },
                    "comment": {
                        "value": "Thanks for the author's response especially the detailed discussion on the differences between ACM and the proposed PMP. These answers addressed my concerns, so I would like to increase my rating."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701086597,
                "cdate": 1700701086597,
                "tmdate": 1700701086597,
                "mdate": 1700701086597,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "QlUncxLps7",
            "forum": "tEgrUrUuwA",
            "replyto": "tEgrUrUuwA",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9114/Reviewer_69ev"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9114/Reviewer_69ev"
            ],
            "content": {
                "summary": {
                    "value": "This paper describes a variant of GNN trained for graph fraud detection tasks.\nApparently, previously existing GNN's efficacy suffer due to label imbalance (a common occurrence with fraud data). \nThe authors' solution to this problem was in label-aware partitioning of aggregated contributions during message passing stage. Instead of aggregating contribution from all nodes from a given root node's neighborhood the proposed method would aggregate label-aware contributions separately which would include separate weight matrices for benign nodes and for fraud-related nodes.\nThe algorithm's theoretical examination shows that it independently learns an adaptive spectral filter for each node in the graph. The model also proved to outperform existing state-of-art solutions on publicly available datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This paper is very well motivated and clearly written. The idea seems to be simple enough yet previous researchers' work focused on augmenting graph structure and label-augmented features and have not augmented message passing process only.\n\nI found the visualization of the difference between the influence of fraud nodes in neighborhood of a given node and influence of benign nodes from the same neighborhoods to be very persuasive when using this metric for comparing minority class contribution with various GNN models."
                },
                "weaknesses": {
                    "value": "I did not find any glaring weaknesses. I would just mention that it would be easier for a reader to follow if the same notation would not be used for different purposes.\nh (page 15) - class homophili metric\nh_{i}^{(l)} (page 3) - l-th layer hidden representation of v_i"
                },
                "questions": {
                    "value": "On page 4, equation 4: Shouldn't a small \\alpha^{(l)}_{i} indicate that the model should treat unlabeled neighbors more similarly to benign nodes (instead of fraud nodes as written in the paper)?\n\nOn Figure 4 (page 8): Influence distribution: why GCN (and not R-GCN) was chosen as one of the methods for comparison? My understanding is that GCN cannot distinguish between diffenent relations and both Yelp and Amazon datasets include multiple relationship types. May be that is why GCN did better at T-Finance (with only one relation type)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9114/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698820703635,
            "cdate": 1698820703635,
            "tmdate": 1699637146668,
            "mdate": 1699637146668,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "8M7lkQrEfV",
                "forum": "tEgrUrUuwA",
                "replyto": "QlUncxLps7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 69ev"
                    },
                    "comment": {
                        "value": "We appreciate your detailed suggestions for our work. We provide the response to your concerns point by point as follows:\n\n**Q1: It would be easier for a reader to follow if the same notation would not be used for different purposes.  $h$ (page 15) - class homophily metric $h_{i}^{(l)}$ (page 3) - $l$-th layer hidden representation of $v_i$.**\n\n**A1:** Thank you for pointing out the confusion caused by the overlapping use of the notation $h$. To address this, we have revised the notation to eliminate any ambiguity. The class homophily metric previously denoted by $h$ on page 15 will now be denoted by $\\eta$ throughout the paper. We have marked these changes in blue in the revised manuscript.\n\n**Q2: On page 4, equation 4: Shouldn't a small $\\alpha^{(l)}\\_{i}$ indicate that the model should treat unlabeled neighbors more similarly to benign nodes (instead of fraud nodes as written in the paper)?**\n\n**A2:** Thank you for pointing out the inconsistency regarding the interpretation of the parameter $\\alpha^{(l)}\\_{i}$ in equation 4 on page 4. Upon re-examination, we agree that there was an error in our description of how $\\alpha^{(l)}\\_{i}$ influences the treatment of unlabeled neighbors in our model.\n\nAs you correctly noted, a small $\\alpha^{(l)}\\_{i}$ should indeed indicate that the model treats unlabeled neighbors more similarly to benign nodes due to the larger weight placed on $\\mathbf{W}\\_{\\text{be}}^{(l)}$. We have corrected the text in the manuscript to accurately reflect this relationship. \n\n**Q3: On Figure 4 (page 8): Influence distribution: why GCN (and not R-GCN) was chosen as one of the methods for comparison? My understanding is that GCN cannot distinguish between diffenent relations and both Yelp and Amazon datasets include multiple relationship types. May be that is why GCN did better at T-Finance (with only one relation type)**\n\n**A3:** Thanks for your deep insights. Our aim is to provide a comprehensive comparison across a spectrum of GNNs, ranging from the most basic GCN to the more advanced and fraud-specific model, BWGNN. These methods are selected as the most representative baselines for different classes of GNNs. We agree that the Yelp and Amazon datasets contain multiple relationship types and that GCN\u2019s inability to differentiate between these may impact its performance. In the single-relational dataset T-Finance, the disadvantages of GCN are reduced because other methods no longer have the advantage of handling multiple relations, which is a logical result. \n\nWe appreciate the suggestion that including R-GCN, which is designed to handle multiple types of relationships, could provide a more direct comparison for datasets with such complexity. To address this, we have conducted additional experiments with R-GCN, which we have included in the **Appendix E.3** of the revised manuscript. From the extended experiments with R-GCN in **Appendix E.3**, we include R-GCN due to its ability to handle multiple types of relationships within a graph. R-GCN extends the GCN model to account for different types of relations in the graph. Results illustrate the influence distributions for the multi-relational Yelp and Amazon datasets. It is evident that accounting for multiple relationships results in a rightward (positive) shift in the influence distributions."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700338146009,
                "cdate": 1700338146009,
                "tmdate": 1700338146009,
                "mdate": 1700338146009,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CAgYfo1nbg",
                "forum": "tEgrUrUuwA",
                "replyto": "QlUncxLps7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9114/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Looking forward to your response"
                    },
                    "comment": {
                        "value": "Dear Reviewer 69ev,\n\nThank you once again for your insightful feedback on our submission. We would like to remind you that the discussion period is concluding. To facilitate your review, we have provided a concise summary below, outlining our responses to each of your concerns:\n\n**Part 1**: We have carefully checked the manuscript to ensure that all notations are now distinct and consistently applied throughout the paper. \n\n**Part 2**: We have corrected an inaccurate description of $\\alpha$.\n\n**Part 3**: We compare our model with R-GCN and analyze their relationships.\n\nWarm regards,\n\nThe Authors of Submission 9114."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9114/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675929720,
                "cdate": 1700675929720,
                "tmdate": 1700675929720,
                "mdate": 1700675929720,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]