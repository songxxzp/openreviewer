[
    {
        "title": "Selective Mixup Helps with Distribution Shifts, But Not (Only) because of Mixup"
    },
    {
        "review": {
            "id": "bkvSfoV9v6",
            "forum": "NqQjoncEDR",
            "replyto": "NqQjoncEDR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission498/Reviewer_Cy8e"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission498/Reviewer_Cy8e"
            ],
            "content": {
                "summary": {
                    "value": "This paper attempts to show the equivalence between selective mixup, where the pairwise samples are selected according to a specific distribution and are mixed up for training and resampling based on the derived sample distribution in the batches for the selective mixup. \nThe authors argue that such mixups shift the underlying training distribution to a more uniform one and can show performance improvements when the test distribution is uniform in nature. The authors also show results for cases where there are multiple domains in the data."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The authors present a simple analysis of an intuitively known effect of the mixup on training data where there is an imbalance in the training data. They provide mathematical proof that such selective increases the entropy of the training distribution"
                },
                "weaknesses": {
                    "value": "1. The authors claim that the selective mixup yields a training distribution over those classes that is closer to the uniform distribution. The authors do not provide results for the imbalanced classification on standard datasets such as CIFAR-10LT, CIFAR-100 LT, and imagenet1k-LT. \n2. Since the authors claim that an equivalent resampling is just as good, an important baseline in long-tail would be to compare against MiSLAS.\n3. Could you an analysis where the test distribution is also skewed, independent of the training distribution? How is the performance of existing methods and the derived resampling distribution from Selective Mixup one of the claims made is that these methods are useful because the balancing effect on the training distribution performs well when the testing data is uniform.\n4. I find a lack of novelty in the finding that mixup yields a training distribution with higher entropy, i.e., closer to the uniform distribution, Could you provide any strong theoretical justification that the actual mixup is not contributing to an improvement in the performance since existing works such as MiSLAS do show superior performance to vanilla classifier retraining on training with class balanced samplers."
                },
                "questions": {
                    "value": "See weakness"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Reviewer_Cy8e"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission498/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698586146467,
            "cdate": 1698586146467,
            "tmdate": 1699635976725,
            "mdate": 1699635976725,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "TcUhxL8hjZ",
                "forum": "NqQjoncEDR",
                "replyto": "bkvSfoV9v6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission498/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission498/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer Cy8e"
                    },
                    "comment": {
                        "value": "Thanks for your time. The review seems to use a few incorrect assumptions, e.g. the paper makes zero claims about long-tail scenarios (c.f. comparison with MiSLAS). We propose to clarify the paper with the points below.\n\n--------------\n> Evaluation datasets The authors do not provide results for the imbalanced classification on standard datasets such as CIFAR-10LT, CIFAR-100 LT, and imagenet1k-LT.\n\n- The 5 datasets we use come directly from the most directly-relevant prior work (selective mixup for distribution shifts).\n\n- Our main claim is that this prior work missed important ablations, hence our priority is to perform the missing experiments on the same datasets.\n\n- The point of this paper is to improve our scientific understanding of selective mixup with distribution shifts. Experiments on *-LT could be interesting but would add little value to the main claims.\n\n\n\n\n--------------\n> Could you do an analysis where the test distribution is also skewed, independent of the training distribution? (...)\n\nThe test distribution is skewed \"*independent of the training distribution*\" (?) as our default setting since the whole paper is about distribution shifts. If the question is specifically about shift of the label distribution, this is exactly what is investigated with the yearbook/MIMIC/arxiv datasets (see Fig. 10; the test distribution is not uniform).\n\n\n\n--------------\n> I find a lack of novelty in the finding that mixup yields a training distribution with higher entropy\n\nNot sure what \"*lack of novelty*\" means (??). Prior work missed this as an explanation for the effects of selective mixup. **This is exactly why this paper is important: it highlighting an effect that has been in plain sight but missed in highly-cited prior work.**\n\n--------------\n> Could you provide any strong theoretical justification that the actual mixup is not contributing to an improvement\n\nThe paper never makes this claim, which is factually incorrect from our experiments. The paper states the exact opposite multiple times:\n\n- yearbook dataset: \"*(...) confirms the complementarity of the effects of resampling and within-class selective mixup*\"\n- arxiv dataset: \"*the performance of selective mixup is explained by cumulative effects of vanilla mixup and resampling effects*\"\n- civilComments dataset: \"*the performance of selective mixup is the result of the independent effects of vanilla mixup and resampling*\"\n\nDifferent datasets benefit differently from mixup and/or resampling. This is why there is no single simple story, and why the results are analyzed on each dataset separately."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699949009484,
                "cdate": 1699949009484,
                "tmdate": 1699949009484,
                "mdate": 1699949009484,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "gQSbWRl1rs",
            "forum": "NqQjoncEDR",
            "replyto": "NqQjoncEDR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission498/Reviewer_pzjf"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission498/Reviewer_pzjf"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the mechanism of selective Mixup, with a particular emphasis on its resampling aspect. The authors suggest that the resampling effect plays a crucial role in achieving the notable performance. Furthermore, the paper provides theoretical results, demonstrating that specific selection criteria exhibit a \"regression toward the mean\" bias or help mitigate class imbalance bias. The study includes many empirical results, and the authors propose a novel combination of selective Mixup and resampling to boost the performance beyond that of the original selective Mixup."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The resampling effect of Selective Mixup has not been investigated in previous literature, which is definitely a crucial aspect to uncover the mysteries of Selective Mixup. Additionally, the authors introduce a novel technique to improve the performance of selective Mixup by enhancing the resampling effect."
                },
                "weaknesses": {
                    "value": "A notable weakness is the misalignment between the explanations and claims provided and the empirical observations. Additionally, the paper appears to overlook certain important and interesting discussions based on observations. \n\nFurther details can be found in the questions outlined below."
                },
                "questions": {
                    "value": "1. In Figure 2, the authors mention that ''The ranking of various criteria for selective sampling is similar whether with or without Mixup''. However, claiming that the performance between selective sampling is similar to that of selective Mixup seems somewhat strained. For instance, in the case of \"Diff. domain+ Same class,\" selective Mixup demonstrates a $6\\%$ higher accuracy than selective sampling. What accounts for the superiority of selective Mixup over selective sampling in this scenario?\n\n2. Similarly, in Figure 2, for ''Same domain'', ''Diff. class'' and ''Diff. domain + Diff. class'', selective sampling is much better than selective Mixup, does this indicate that vanilla Mixup is harmful in this case? Such observations are more evident in Figure 8. The authors have not discussed the reasons behind the occasional superiority of selective Mixup over selective sampling.\n\n3. In Figure 6, given the effective performance of vanilla Mixup, it appears that vanilla Mixup is the main driver for the improvement in selective Mixup, even with the optimal criteria. This observation contradicts the third point outlined in the summarized contributions in the Introduction.\n\n4. In Figure 6, it is observed that for the case of ''Diff. domain + Same class,'' selective Mixup performs worse than vanilla Mixup. Does this observation imply that the resampling effect may have a degrading impact on the performance of Mixup?\n\nI would be willing to increase my score if the authors addressed my concerns."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission498/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698631702370,
            "cdate": 1698631702370,
            "tmdate": 1699635976629,
            "mdate": 1699635976629,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Zwlu68Lmc7",
                "forum": "NqQjoncEDR",
                "replyto": "gQSbWRl1rs",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission498/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission498/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer pzjf"
                    },
                    "comment": {
                        "value": "Thanks for your time. These comments are very helpful for improving the paper. We propose to clarify the points below in the text, and make this general message clearer upfront: **different datasets benefit differently from mixup and/or resampling.** This is why there is no single simple story and why each dataset is best analyzed individually.\n\n-----------------------------\n> In Figure 2, the authors mention that ''The ranking of various criteria for selective sampling is similar whether with or without Mixup''. However, claiming that the performance between selective sampling is similar to that of selective Mixup seems somewhat strained. For instance, in the case of \"Diff. domain+ Same class,\" selective Mixup demonstrates a higher accuracy than selective sampling. What accounts for the superiority of selective Mixup over selective sampling in this scenario?\n\nThere are indeed small differences (<5%), which we propose to mention in the caption. We will clarify that the key observation **is correct for the best-performing version** (same domain/diff. class, and resampling for uniform combinations), which is >25% above the baseline and the version that most will care about.\n\n\n-----------------------------\n> Similarly, in Figure 2, (...) does this indicate that vanilla Mixup is harmful in this case?\n\nYes indeed. One can see it just by observing that vanilla mixup is worse than the baseline on this dataset. Prior work has indeed shown that mixup is not always beneficial.\n\n-----------------------------\n> The authors have not discussed the reasons behind the occasional superiority of selective Mixup\n\nWe already acknowledge that some cases benefit from selective mixup in the way proposed by Yao et al. For example see Fig.4 (yearbook): \"*it indicates a genuine benefit from mixup restricted to pairs of the same class*\". This is also exactly what the title of the paper says (\"not always\"). We propose to highlight this takeaway in the caption of Fig.4.\n\n\n-----------------------------\n> In Figure 6, given the effective performance of vanilla Mixup, it appears that vanilla Mixup is the main driver for the improvement in selective Mixup, even with the optimal criteria. This observation contradicts the third point outlined in the summarized contributions in the Introduction.\n\nThe reviewer is absolutely correct. On this dataset, 4/5 of the improvement over the baseline can be attributed to vanilla mixup, and 1/5 to resampling. We propose to tone down the third summary point (\"*resampling is SOMETIMES the main driver*\").\n\n-----------------------------\nDoes this address your concerns? Happy to take other suggestions for improvement."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699953409099,
                "cdate": 1699953409099,
                "tmdate": 1699953435332,
                "mdate": 1699953435332,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "fjBMcDfocT",
                "forum": "NqQjoncEDR",
                "replyto": "Zwlu68Lmc7",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission498/Reviewer_pzjf"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission498/Reviewer_pzjf"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the response."
                    },
                    "comment": {
                        "value": "I would like to thank the authors for their response, and apologize for my delayed reply. I also have read all the reviews and the author responses.\n\n>- Yes indeed. One can see it just by observing that vanilla mixup is worse than the baseline on this dataset. Prior work has indeed shown that mixup is not always beneficial.\n\nTo clarify, note that in Figure 8, vanilla mixup outperforms the baseline, but selective mixup is much worse than the corresponding selective sampling. The authors briefly mention this in the caption, but additional insights or discussions on this discrepancy would be appreciated.\n\nRegarding the potential drawbacks of vanilla mixup, I am aware of two relevant works, namely [1,2], which are cited in the \"Explaining the benefits of mixup\" paragraph in your paper. Both of these papers suggest that if early stopping is applied, mixup does not harm performance. Could the less satisfactory performance of vanilla mixup be attributed to the long training time? While [1,2] primarily focus on in-distribution generalization, it's possible that we're dealing with a different scenario, but such considerations are currently missing from the discussion.\n\n[1] Liu et al. Over-training with mixup may hurt\ngeneralization. ICLR 2023.\n\n[2] Zou et al. The benefits of mixup for feature learning. ICML 2023.\n\n>- different datasets benefit differently from mixup and/or resampling. This is why there is no single simple story and why each dataset is best analyzed individually.\n\nI agree with the authors that there is no single simple story based on your experiments. However, this has left me somewhat puzzled about the key message of the paper. Claims in the introduction, such as the highlighted text on the first page, \"The non-random selection of pairs ... completely unrelated to the mixing,\" seem to suggest a clear message that resampling is the key factor behind mixup. Yet, after reviewing all the empirical results, the conclusion seems less definitive, especially considering that vanilla mixup can be a dominant factor (e.g., Figure 6).\n\nThis is my personal feeling and my viewpoint can be subjective. I will leave this point to the discussion with AC and other reviewers.\n\n\nOn a separate note, I want to mention that ICLR allows authors to modify their paper submission during the rebuttal period. Therefore, if the authors propose changes in their responses, updating the PDF accordingly might be more convincing. If the authors are already aware of this, please disregard this comment."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700598084346,
                "cdate": 1700598084346,
                "tmdate": 1700598084346,
                "mdate": 1700598084346,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0IfyAYvIWD",
            "forum": "NqQjoncEDR",
            "replyto": "NqQjoncEDR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission498/Reviewer_sizd"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission498/Reviewer_sizd"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies the problem of selective mixup, where the sample and labels are paired based on a certain criteria and the risk is minimised on the mixed up samples. The paper then demonstrates that when samples from different classes are mixed up the overall data distribution regresses towards a uniform distribution. Hence, the success of mixup under distribution shift  is attributed to both the resampling effect and regularization effect, where it is argued that resampling plays an important role. Some theoretical results are shown, which are supplemented with empirical results."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "Relevant problem to be studied in detail.\n\nExtensive experiments have been conducted for analysis."
                },
                "weaknesses": {
                    "value": "Weak Theoretical Results: I find the theoretical result to be weak, as it only considers the mixup of the labels. For appropriate analysis of the mixup, the mixing of data points (x) should also be considered (i.e. covariates) to get the complete picture of the problem.\n\nEmpirical Results are Scattered: The authors explain the results of each of the datasets independently, which is a source of confusion due to the complexity involved. The datasets often demonstrate conflicting conclusions, for example, results on Arxiv are much different from the Waterbird. Hence, it\u2019s hard to obtain final conclusions. The results on various datasets can be combined which contain similar problem settings and demonstrate consistent results.\n\nInconsistency in Experimental Setups: There is a difference between the number of methods considered for each dataset. Hence, it\u2019s hard to parse which combination of methods is most effective on average across all the datasets.\n\nNovelty: However, the authors have done a considerable amount of experiments. I find that the content is scattered and insufficient, to meet the bar for novelty and doesn\u2019t provide insights different than existing works (Yao et al. 2023)"
                },
                "questions": {
                    "value": "As the method mainly considered label shift, have the authors considered the setting of long-tailed label shift mixup?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Reviewer_sizd"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission498/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698831876101,
            "cdate": 1698831876101,
            "tmdate": 1699635976562,
            "mdate": 1699635976562,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "zqC9hPOczO",
                "forum": "NqQjoncEDR",
                "replyto": "0IfyAYvIWD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission498/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission498/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer sizd"
                    },
                    "comment": {
                        "value": "Thanks for your time. These comments are very helpful by showing that the significance of our findings was not sufficiently highlighted. We propose to clarify the paper with the following points.\n\n------------------\n> novelty / doesn\u2019t provide insights different than existing works (Yao et al. 2023)\n\nOn the contrary, this work overturns part of Yao et al. We show that the widely-accepted explanation of their method is incomplete or even incorrect in some cases.\n\nThis paper is important because it improves the scientific understanding of this highly-cited method. Incorrect explanations will derail future work that builds upon current knowledge. And getting to such deep understanding is the whole point of science. \n\n\n------------------\n> only considers the mixup of the labels (...) the mixing of data points (x) should also be considered (i.e. covariates)\n\nThis is indeed an interesting question that we openly discuss p.4. The proposed formalization with labels does not readily extend (e.g. a uniform distribution over covariate isn't well defined) but the extensive experiments suggest that the same mechanism is at play with labels and covariates. We propose to make it clear that this is a limitation of our formalization.\n\n\n------------------\n> The authors explain the results of each of the datasets independently (...) it\u2019s hard to obtain final conclusions\n\nThere is a simple conclusion: there is no simple conclusion :)\n\n**Different datasets benefit differently from mixup and/or resampling.** This is why there is no single simple story and why each dataset is best analyzed individually. We propose to make this message clearer upfront in the paper.\n\n\n------------------\nDo these clarfifications address your concerns? We are grateful for your contribution to the improvement of this paper!"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699955973490,
                "cdate": 1699955973490,
                "tmdate": 1699955973490,
                "mdate": 1699955973490,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "RfUgTwtino",
                "forum": "NqQjoncEDR",
                "replyto": "0IfyAYvIWD",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission498/Reviewer_sizd"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission498/Reviewer_sizd"
                ],
                "content": {
                    "title": {
                        "value": "Response by Reviewer sizd"
                    },
                    "comment": {
                        "value": "Thanks to the authors for the rebuttal. I have read other reviews and rebuttal responses. After this, my major concern regarding the claim of \"resampling being the main reason for mixup\" (i.e., empirical results scattered) being not supported by sufficient experiments still persists. Further, no revision has been submitted by the authors, which improves the clarity of the results. Hence, at this point, I will maintain my rating and leave further discussion to AC."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700659276219,
                "cdate": 1700659276219,
                "tmdate": 1700659276219,
                "mdate": 1700659276219,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5aCQK5FBvR",
            "forum": "NqQjoncEDR",
            "replyto": "NqQjoncEDR",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission498/Reviewer_4eUi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission498/Reviewer_4eUi"
            ],
            "content": {
                "summary": {
                    "value": "This paper examines the success of selective mixup on the out-of-distribution generalization problem and finds out that the effect of mixup and resampling due to selective mixup can be decoupled. They conduct several experiments and find that the main contribution to the effectiveness of selective mixup may result from resampling."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper is easy to follow\n2. Conduct results on many ood datasets and compare the results of selective sampling without mixup with the selective mixup method. And figures like Figure 7 and Figure 15 is insightful for noting the decoupling between mixup and resampling."
                },
                "weaknesses": {
                    "value": "1. Some of the notations are not so clear. Like in Table 1, what's the definition of Resampling (uniform cl.) + concatenated pairs, and why it has different proportion of majority class compared with \"Resampling (uniform classes)\"?"
                },
                "questions": {
                    "value": "1. What makes the difference in the sampling ratio between the selective sampling without mixup and resampling? Is this determined by the hyperparameter of mixup? When changing the lambda for the beta distribution of mixup, are similar results as Fig 15 hold? \n2. For this finding, what about using another mixup method like manifold mixup, which may help the old generalization ability by connecting samples from different domains/classes in the representation space?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission498/Reviewer_4eUi"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission498/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699258503314,
            "cdate": 1699258503314,
            "tmdate": 1699635976500,
            "mdate": 1699635976500,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ueAp7Ffadb",
                "forum": "NqQjoncEDR",
                "replyto": "5aCQK5FBvR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission498/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission498/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 4eUi"
                    },
                    "comment": {
                        "value": "Thanks for your time. These comments are very useful. We propose to clarfiy the following points in the paper.\n\n-------------\n> Some of the notations are not so clear. Like in Table 1, what's the definition of Resampling (uniform cl.) + concatenated pairs, and why it has different proportion of majority class compared with \"Resampling (uniform classes)\"?\n\n> What makes the difference in the sampling ratio between the selective sampling without mixup and resampling?\n\nThis can indeed use a formal explanation:\n\n- **Resampling (uniform cl.) + mixup** uses paired instances such as:\n{$ \\textrm{mix}(x_1, \\tilde{x}_1), \\textrm{mix}(x_2, \\tilde{x}_2), \\textrm{mix}(x_3, \\tilde{x}_3), ... $}\nwhere $x_i$ are sampled with uniform classes (50% proportion) and $\\tilde{x}_i$ are sampled indiscriminatively (hence with the original 78% proportion). Overall we get something inbetween (64%).\n\n- **Resampling (uniform cl.) + concatenated pairs** uses the same instances as above without the mixing:\n{$ x_1, \\tilde{x}_1, x_2, \\tilde{x}_2, x_3, \\tilde{x}_3, ... $}\nThe proportion of labels is thus also ~64%.\n\n\n-------------\n> When changing the lambda for the beta distribution of mixup, are similar results as Fig 15 hold?\n\nYes, we performed experiments on datasets with various $\\lambda$ and found very little impact.\n\n\n-------------\n> For this finding, what about using another mixup method like manifold mixup, which may help the old generalization ability by connecting samples from different domains/classes in the representation space?\n\nIndeed, we follow Yao et al. and use manifold mixup (which is the only sensible option for the NLP and MIMIC tasks). We made this clearer in the text.\n\n-------------\nDoes this properly address your questions? We are grateful for your contribution to the improvement of this paper!"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1699959083295,
                "cdate": 1699959083295,
                "tmdate": 1699959083295,
                "mdate": 1699959083295,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Lm7zfYQzbx",
                "forum": "NqQjoncEDR",
                "replyto": "ueAp7Ffadb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission498/Reviewer_4eUi"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission498/Reviewer_4eUi"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your reply. I think further formal explanations of the notations like the author mentioned in the response are needed to make the paper clearer. And it\u2019s better for the author to provide some of the sensitive analysis of parameter $\\lambda$ formally to show that it has little impact. Besides, I also agree with the opinion to tone down the summary point and point out that mixup still plays an important role in some datasets. I will keep my score."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission498/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700545815138,
                "cdate": 1700545815138,
                "tmdate": 1700545815138,
                "mdate": 1700545815138,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]