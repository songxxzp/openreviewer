[
    {
        "title": "Generative Modeling of Individual Behavior at Scale"
    },
    {
        "review": {
            "id": "98aHB0HT9s",
            "forum": "pTqmVbBa8R",
            "replyto": "pTqmVbBa8R",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7455/Reviewer_rXFi"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7455/Reviewer_rXFi"
            ],
            "content": {
                "summary": {
                    "value": "This paper scales up the individual-level behavior simulation at scale using Parameter Efficient Fine-Tuning (specifically Poly LoRA). This has significantly scaled up the simulation, with the neat addition of new capabilities such as individual-style generation and style analysis. This work demonstrates how the latest PEFT methods can significantly scale up fine-grained human behavior simulation. The authors use chess game analysis as an example, but similar simulations could be possible in other domains."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* By combining multiple of the latest scalability fine tuning techniques, the authors were able to successfully scale up the individual-level simulation in unprecedented ways.\n* Authors provide interesting observations from the simulation proving the individual models are indeed helpful for the scaled analysis of human behavior. e.g. Figure 5"
                },
                "weaknesses": {
                    "value": "* Besides the interesting adaptation in the fine-grained human behavior analysis, the actual technical contribution is quite limited because they are simple extensions of the previous work on the chess domain.\n* Even considering limited work in the chess game simulation, the empirical comparison is pretty weak. They could have considered other baselines such as ones with standard DNNs for example from one model.\n* Technical contribution to the machine learning communities seems to be limited since the work is a straightforward extension o f the Maia model with small modifications."
                },
                "questions": {
                    "value": "Please take a look at the weakness section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7455/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698717842413,
            "cdate": 1698717842413,
            "tmdate": 1699636895613,
            "mdate": 1699636895613,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "COINCLlD43",
                "forum": "pTqmVbBa8R",
                "replyto": "98aHB0HT9s",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7455/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7455/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback, and for appreciating our scalable analysis of individual behavior. Although our model architecture builds on existing PEFT methods and the base Maia architecture, we believe our technical contributions go well beyond this architecture, as we explain in our general response above. We address the remaining points you raised below. \n\n## On empirical comparisons and baselines:\n\nAlthough the set of comparisons made within our paper are limited, we believe they are sufficient to show the efficacy of our method. The models which we test against represent the state-of-the-art in their respective domains, and also in other domains. For example, we compare against individual model fine-tuning (McIlroy-Young et al., 2022) and to a Transformer-based method (McIlroy-Young et al., 2021); we achieve superior results to both, at much larger scale, while providing *generative* models. In their paper, McIlroy-Young et al. (2021) include comparisons of their Transformer encoder, which is a modified version of the Vision Transformer (ViT) architecture, to other architectures within the stylometry domain. The ViT architecture has been shown to perform at state-of-the-art levels in many other domains. Additionally, Maia is based on the Squeeze-and-Excitation Residual Network, which has been shown to perform well in image classification. Given the strength of these base models in both chess and other domains, and the fact that we compare against state-of-the-art methods that build upon them, we believe that adding weaker models would not yield significant added value to our analysis.  \n\nHowever, it is possible that we are misunderstanding the comparison the reviewer had in mind; if the reviewer could clarify what they meant by standard DNN architecture, we would be happy to include this comparison in our evaluation."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7455/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700449070043,
                "cdate": 1700449070043,
                "tmdate": 1700449070043,
                "mdate": 1700449070043,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "XaFni87fDg",
            "forum": "pTqmVbBa8R",
            "replyto": "pTqmVbBa8R",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7455/Reviewer_XeAJ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7455/Reviewer_XeAJ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a novel method to model individual behavioral stylometry. Specifically, the authors take it as a multi-task learning problem where each task refers to a distinct person. The method is parameter-efficient and thus can perform stylometry at an unprecedented scale with few-shot learning enabled. Experimental results on chess data show the effectiveness of the method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The topic is interesting and the proposed way for modeling human individual behavior looks novel to me.\n\n2. Overall the paper is clearly written and easy to follow."
                },
                "weaknesses": {
                    "value": "1. The method looks to some extent incremental to me: some existing techniques such as Lora and Polytropon are combined and employed for a specific task. \n\n2. Currently, the empirical result is only on a chess dataset. As the paper aims at modeling human behavior, it would be good if more related datasets could be considered. See question 4.\n\nminors:\n\nTypos: \"we use this to to evaluate few-shot learning ...\" and \"we run a simulated tournament between the them\"."
                },
                "questions": {
                    "value": "1. What is the intuition behind to model each player as a task? \n\n2. Is there any data imbalance / long tail problem under this setting?\n\n3. Can we have a fig5-like result for interpolation over the style space?\n\n4. Can the method be applied to games with asymmetric information like poker?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7455/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698808884743,
            "cdate": 1698808884743,
            "tmdate": 1699636895488,
            "mdate": 1699636895488,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "WdOB2Q3ub3",
                "forum": "pTqmVbBa8R",
                "replyto": "XaFni87fDg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7455/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7455/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback, and for appreciating the novel aspects of our approach. Although our work applies existing PEFT methods (e.g., Polytropon and MHR) to the domain of chess, our technical contributions go beyond this application, as we explain in our general response above. We address the remaining points you raised below. \n\n## On the intuition behind modelling each player as a task:\n\nIn multi-task learning, there is a trade-off between sharing information across (similar) tasks and differentiating between (dissimilar) tasks. Given any two tasks, some aspects will be similar and some will be different. We realized that the same is true of players in a game: many players share similar strategies or aspects of their playing style, but each player is still unique. Thus, we saw the potential of modeling shared characteristics across the players (e.g., through skill modules), while allowing them to express their peculiarities (e.g., through style vectors). This paradigm mapped well to recent PEFT approaches used in multi-task learning, which inspired us to make the conceptual connection between gaming and this field. \n\n## On the issue of data imbalance and the long tail problem:\n\nChess player data does have some significant data imbalance, but we do not believe this is a significant issue for our method given our few-shot learning results on <= 100 games. In Table 2, for example, we show that training on completely unseen players using just 100 games is enough to identify them from a set of 10,000 other players. Additionally, Figure 2 shows that our method can model a player with as few as 50 games and achieve nearly 60% move-matching accuracy. Finally, we include a chart linked below showing the cosine similarity of style vectors generated using different sizes of disjoint subsets of games, compared to a style vector trained on 10,000 games. Observe that even with just 10 games, the cosine similarity is 0.422, which is over two standard deviations (sd=0.103) above the average pairwise cosine similarity across the population (0.188). We have added some discussion regarding data imbalance and players with lower game counts to our paper. \n\n[Link to Figure] https://imgur.com/a/lqt9eiZ\n\n\n## Figure 5-like chart for interpolation on the style space:\n\nThis is a great question. Below is a link to the requested chart, where we produce a new player (labeled Interpolated) by averaging the style vectors of two random players from our dataset. While the interpolated player isn\u2019t an exact average, it aligns quite well in most dimensions. We have added this example to our paper. \n\n[Link to Figure] https://imgur.com/a/NcxRQcI\n\n## On applications to games with asymmetric information:\n\nThis is an interesting question to explore. In principle our approach could extend to games with asymmetric information, because aspects of a player\u2019s strategy or playing style can still be learned from their actions. When applying our approach to visual 1-vs-1 games, asymmetry arises due to partial observability of the state space, such as a player only seeing what is in their field of view. In poker, the current state would not include the specific cards held by other players. Nevertheless, such partially observed states can still be encoded and provided as input to the base model, atop which our adapter architecture is applied (see Fig. 1). Also see our general response for further comments on generalizing our work beyond the domain of chess."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7455/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700448991629,
                "cdate": 1700448991629,
                "tmdate": 1700633076955,
                "mdate": 1700633076955,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "heOeJQ7Qmm",
                "forum": "pTqmVbBa8R",
                "replyto": "WdOB2Q3ub3",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7455/Reviewer_XeAJ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7455/Reviewer_XeAJ"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your response. After reading all the review comments, I tend to keep my rating unchanged. The paper focuses on modeling individual behavior, which is itself a rather narrow domain. Therefore, it would be good if at least one more dataset could be included in the experiments."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7455/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700551167683,
                "cdate": 1700551167683,
                "tmdate": 1700551167683,
                "mdate": 1700551167683,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "lHaf3EF0NU",
            "forum": "pTqmVbBa8R",
            "replyto": "pTqmVbBa8R",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7455/Reviewer_RNKg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7455/Reviewer_RNKg"
            ],
            "content": {
                "summary": {
                    "value": "The paper proposes a method to model individual behavior in chess using a multi-task learning framework that leverages parameter-efficient fine-tuning (PEFT) methods. The paper introduces a style vector for each player that captures their distribution over latent skills learned from a shared inventory of adapters. The style vector enables generative modeling, stylometry, and style analysis and synthesis of players.\nThe paper evaluates the method on a large-scale dataset of over 47,000 players and 244 million games, and shows that it can perform stylometry with high accuracy, predict Elo ratings, probe player styles, and create novel human-like styles."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The paper proposes a novel and rigorous method to model individual behavior in chess using a multi-task learning framework that leverages parameter-efficient fine-tuning methods.\n2. The paper introduces a style vector for each player that captures their distribution over latent skills learned from a shared inventory of adapters. The style vector enables generative modeling, stylometry, and style analysis and synthesis of players.\n3. The paper evaluates the method on a large-scale dataset of over 47,000 players and 244 million games, and shows that it can perform stylometry with high accuracy, predict Elo ratings, probe player styles, and create novel human-like styles."
                },
                "weaknesses": {
                    "value": "1. The paper focuses on modeling individual behavior in chess, which is a specific and narrow domain. The method may not generalize well to other domains or tasks that have different characteristics or constraints.\n2. The paper assumes that the players\u2019 styles are stationary and independent of the context or the opponent. However, in practice, players may adapt their styles to the situation or the opponent, which could affect the accuracy and validity of the method."
                },
                "questions": {
                    "value": "How do you see this method to generalize beyond a game setting, e.g., to role-play text generation (e.g., Character AI)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "Yes, Privacy, security and safety"
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "The paper does not address the ethical implications of using generative models to mimic human behavior, such as privacy, security, fairness, and accountability. The method could be used for malicious purposes, such as impersonation, fraud, manipulation, or surveillance, which could harm individuals or society."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7455/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698824655235,
            "cdate": 1698824655235,
            "tmdate": 1699636895337,
            "mdate": 1699636895337,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "CNQEddPJ5Q",
                "forum": "pTqmVbBa8R",
                "replyto": "lHaf3EF0NU",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7455/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7455/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable feedback, and for appreciating the rigor in our work. We address your first question in the general response; we address your second point below.  \n \n\n## On implicit stationarity assumptions of our approach:\n \nIt is true that our approach marginalizes over player opponents/contexts and a player\u2019s evolution over time. This is a standard assumption (also made in previous work) which does not affect the validity of our method, in that it is valid to treat each player holistically and see how the method performs. In fact, we achieve strong results when viewing each player holistically: e.g., over 94% stylometry accuracy over a reference set of ~48K players. However, the reviewer is absolutely right that changing the granularity of our analysis\u2014such as accounting for opponent style, in-game context, or a player\u2019s temporal evolution\u2014are possible with our method and depending on the downstream applications, could be desirable. Here are some relevant observations along these lines: \n\n- When excluding the opening part of the games (e.g., the first 15 moves) from our analysis, stylometry accuracy reduces, indicating that the opening has an outsized effect on style identification relative to the middlegame and endgame. This phenomenon was also observed by McIlroy-Young et al. (2021).  \n\n- A few players in our dataset open a second account after a certain time period, creating a natural temporal split in their data. When comparing the style vectors across these time periods, we observe that they have very high cosine similarity and achieve almost identical move-matching accuracy on each other\u2019s datasets. This is partly because most players exhibit stationary performance (in terms of Elo/playing strength) over time, and because some elements of style persist across playing strength increases. \n\n- One of our experiments (Fig. 4) merges the datasets of two random players\u2014in effect forcing a non-stationarity\u2014and compares the resulting style vector to the arithmetic mean of the individual style vectors, showing they have high cosine similarity.  \n\n\nIn general, we can segment our dataset in a variety of ways and readily apply our method to train a separate style vector for each segment. *If the reviewer has a particular segmentation in mind, we would be happy to implement it*. We have also added this discussion to our paper."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7455/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700448893220,
                "cdate": 1700448893220,
                "tmdate": 1700633013523,
                "mdate": 1700633013523,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]