[
    {
        "title": "Neural Neighborhood Search for Multi-agent Path Finding"
    },
    {
        "review": {
            "id": "KcBNU53zrZ",
            "forum": "2NpAw2QJBY",
            "replyto": "2NpAw2QJBY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4163/Reviewer_pDBe"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4163/Reviewer_pDBe"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel approach for leveraging machine learning in multi-agent path planning (MAPF) based on large neighbor search (LNS). Given an initial solution for a MAPF problem instance, LNS selects a subset of agents and optimizes their solution paths, treating the paths of other agents as spatiotemporal obstacles. \n\nTraditionally, subset selection has relied on heuristic rules or linear models with hand-crafted features. However, the method proposed here integrates a deep neural network into the agent subset selection process. This network predicts the performance gain achievable by selecting a particular subset, using a tensor that encapsulates the agents' current paths, potential shortest paths, and the layout of other obstacles. To manage the computational expense of applying this procedure to various subsets, the proposed method initially extracts features from all agents' paths and predicts the final gain from the feature map slices corresponding to the subset, facilitated by the deep network.\n\nThe method's effectiveness has been validated on MAPF problems involving hundreds of agents."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "**Clarity**: The paper is very well-written overall, and it accurately positions the proposed method against various related studies.\n\n**Novelty**: The structure of the network used to estimate performance gain for agent subset selection and the method of constructing input tensors are new and intriguing.\n\n**Quality**: Overall, the work is of high quality. The proposed method appears solid and technically sound. The authors have implemented numerous techniques to reduce computational costs, a critical factor in MAPF where execution time is crucial.\n\n**Significance**: The method's significance has been evaluated across multiple MAPF problems, and it has been tested on scenarios involving hundreds of agents. It is commendable that the proposed method can handle hundreds of agents, though I still have some concerns about experimental results, as shown below."
                },
                "weaknesses": {
                    "value": "Despite the paper's strengths, it could benefit from a more persuasive quantitative evaluation, which would likely enhance its impact.\n\nIn Table 1, the difference between the Linear baseline and the proposed method appears relatively marginal. While the proposed method outperforms the Linear baseline in terms of average gap and final gap scores, the Linear baseline requires less runtime overhead. Given this trade-off between computation time and solution quality, how can the benefits of the proposed method be demonstrated?\n\nAdditionally, it is unclear what computational resources the proposed method and baseline methods require. The paper suggests that both the proposed method and Linear baseline were tested on a GPU, but it doesn't specify the details of GPU specs required. In practical scenarios, not all environments have access to high-end GPUs, and being able to execute path planning on affordable entry-level GPUs or standard CPUs could be a significant advantage."
                },
                "questions": {
                    "value": "While the paper is well-written and the proposed method is clearly explained, there are some uncertainties regarding the evaluation experiments.\n\nSpecifically, how can we demonstrate the effectiveness of the proposed method over the Linear baseline? While the solution quality obtained by the proposed method is better, the Linear baseline can run faster instead. Moreover, I wonder if the proposed method may require much more GPU resources than other methods and could be much slower when performed on CPUs.\n\nFor example, is it possible to reduce the model capacity for the proposed method so that it can run as approximately fast as the Linear baseline, and compare the solution quality under such conditions?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "N/A"
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4163/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4163/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4163/Reviewer_pDBe"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4163/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697958358167,
            "cdate": 1697958358167,
            "tmdate": 1700604405005,
            "mdate": 1700604405005,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "SixgUD88rQ",
                "forum": "2NpAw2QJBY",
                "replyto": "KcBNU53zrZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the feedback and suggestions and encourage the reviewer to view our general response to all reviewers, which contain significant improvements to our paper. Here are our specific responses to each concern:\n\n**Weaknesses**\n\n1. We would like to clarify that the Average Gap (%), Win / Loss, and Final Gap (%) in Table 1 **already** include the stated model overhead in the 60s runtime (they are exactly the solid curves in Figure 5). Thus, our Multi-subset architecture outperforms Linear in all settings (especially in empty, random, warehouse, and ost003d), even with higher overhead. We believe that this fairly demonstrates the benefits of our method.\n2. Linear, Per-subset, and Multi-subset all use a single NVIDIA V100 GPU (released in 2017, Volta architecture) rather than more recent top-end GPUs. Our understanding is that recent affordable commodity GPUs such as NVIDIA RTX 3060 (released in 2021, Ampere architecture) perform similarly to the NVIDIA V100.\n\n**Questions**\n\nAs mentioned above, we do include inference overhead for both our method and the Linear baseline. We agree that our method would be slower than Linear if executed on a CPU. We agree that standard model compression techniques may reduce our model overhead significantly to be more runnable on a CPU, but this is orthogonal to our proposed method and can be further investigated by practitioners. For example, we could imagine that our Multi-subset model could serve as a teacher model for a Linear student model during model distillation.\n\nWe thank the reviewer for their time. We hope that the reviewer could update our score if we have further strengthened our paper through our additional rebuttal efforts."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700030793060,
                "cdate": 1700030793060,
                "tmdate": 1700030793060,
                "mdate": 1700030793060,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "yMciSUXt1T",
                "forum": "2NpAw2QJBY",
                "replyto": "SixgUD88rQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_pDBe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_pDBe"
                ],
                "content": {
                    "title": {
                        "value": "Thank you"
                    },
                    "comment": {
                        "value": "Thank you for the response!\n\nOk I understood that from Fig 5 the proposed method is more efficient than Linear in terms of how quickly the gap is improved.\nMy points have been resolved, but I just wanted to make clear what the \"Overhead (s)\" in Table 1 actually means, as it seems to be less explained in the main text. For example, for the \"empty\" result, the overhead is +0.002 for Linear and +0.013 for Multi-Subset, which I understood that the Linear baseline has lower overhead."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700031437895,
                "cdate": 1700031437895,
                "tmdate": 1700031437895,
                "mdate": 1700031437895,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "iSxhTHtTxs",
                "forum": "2NpAw2QJBY",
                "replyto": "yMciSUXt1T",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_pDBe"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_pDBe"
                ],
                "content": {
                    "title": {
                        "value": "Rating"
                    },
                    "comment": {
                        "value": "Based on the clarification above I have updated my rating."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700604510038,
                "cdate": 1700604510038,
                "tmdate": 1700604510038,
                "mdate": 1700604510038,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "wfACgcrAXf",
            "forum": "2NpAw2QJBY",
            "replyto": "2NpAw2QJBY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4163/Reviewer_TyGL"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4163/Reviewer_TyGL"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses Large Neighborhood Search (LNS) for Multi-Agent Pathfinding (MAPF) using deep learning. Starting with a feasible (but suboptimal) solution, LNS can solve MAPF in an anytime manner by iteratively destroying and repairing parts, i.e., the neighborhood, of the incumbent solution to improve the solution quality over time. The neighborhoods are determined by using some heuristics from the literature. Given a set of neighborhood candidates, the paper proposes to use deep learning to select a suitable neighborhood via score prediction. The deep learning approach exploits the spatio-temporal structure of the MAPF problem by encoding the paths and obstacles in separate tensors, which are processed by a series of 3D and 2D convolutional layers as well as an attention mechanism. The approach performs well compared to state-of-the-art approaches in selected problems and displays some generalization capabilities for maps of the same size."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The paper addresses an interesting application area that is well-known in the AI community.\n\nThe paper is well-written and easy to understand."
                },
                "weaknesses": {
                    "value": "**Novelty**\n\nThe main contribution of the paper is the application of standard deep learning techniques to 2D grid world MAPF. Since tensor encoding of grid worlds is common practice [1,2,3], I do not consider the approach as particularly novel. The architecture is common practice as well (standard convolutional layers and attention), where the application to a new domain seems to be the main contribution to me.\n\n[1] D. Silver et al., \"Mastering the Game of Go with Deep Neural Networks and Tree Search\", Nature 2016\n\n[2] J. Leibo et al., \"Multi-Agent Reinforcement Learning in Sequential Social Dilemmas\", AAMAS 2017\n\n[3] M. Dennis et al., \"Emergent Complexity and Zero-shot Transfer via Unsupervised Environment Design\", NeurIPS 2020\n\n**Soundness**\n\nAs noted in the paper, MAPF-LNS relies on fast operations (like prioritized planning/PP for repairing and linear models for neighborhood scoring) to ensure its success as an anytime algorithm. However, the paper proposes several modifications to the standard/default setting of the MAPF-LNS or MAPF-ML-LNS paper, which actually increase runtime:\n- A relatively large model for score prediction compared to simple linear models\n- Generation of several neighborhoods at each iteration (which requires the invocation of the destroy heuristics several times)\n- Priority-based planning (PBS) for repairing, which is slower than the default PP due to backtracking in the tree search\n\nMAPF-LNS and MAPF-ML-LNS rely on a large number of iterations to achieve a good solution quality. Therefore, I am not sure if the addition of several more expensive operations actually pays off since it should significantly limit the number of possible iterations.\n\nThe generalization depends on the map size. A model trained on $32 \\times 32$ maps cannot be straightforwardly used on, e.g., $24 \\times 64$ maps and is therefore limited.\n\n**Significance**\n\nThe paper evaluates with different hyperparameters than suggested in the original literature [4,5]. Thus, I am\n1. uncertain about the fairness of the evaluation and\n2. skeptical about the effectiveness, since some changes increase runtime that would limit the number of iterations for sufficient search (see above).\n\nI am also not sure if the modifications used in the deep learning variant are also applied to the linear version. If so, the comparison might be unfair since MAPF-ML-LNS uses some mechanisms, e.g., random neighborhood sizes, that are seemingly important for its success. \n\nThe experiments only report relative numbers, which makes it difficult to relate to the performance reported in prior work, e.g., do the baselines still perform similarly? In that case, fairness could be confirmed, at least.\n\nThe evaluation only considers maps with a fixed number of agents; therefore, I have no intuition on how the average/final gap would scale, e.g., with an increasing number of agents.\n\n[4] J. Li et al., \"Anytime Multi-Agent Path Finding via Large Neighborhood Search\", IJCAI 2021\n\n[5] T. Huang et al., \"Anytime Multi-Agent Path Finding via Machine Learning-Guided Large Neighborhood Search\", AAAI 2022\n\n**Evaluation**\n\nTo decide whether I raise my score or not, I first need to check the following:\n- Since MAPF algorithms are generally very implementation-dependent (as stated in the appendix), I need to confirm the validity of the proposed mechanisms by viewing and running the code myself (with a provided trained model).\n- I need to see plots or tables with the absolute performance, i.e., the sum of delays, for different numbers of agents per map. The evaluation can be easily done by running the experiments with the neural LNS on the exact same setting as [5] and comparing it with the performance of MAPF-LNS and MAPF-ML-LNS reported in that paper.\n- I need to see plots or tables with the number of iterations and success rate per iteration for different time budgets. If the approach was valid, we should see a lower iteration count than the state-of-the-art but a higher success rate."
                },
                "questions": {
                    "value": "- *\u201cwe perform parameter sweeps detailed in Appendix A.2 to first identify the strongest possible configuration for the Unguided baseline\u201d* - The original MAPF-LNS paper already reported extensive hyperparameter experiments to determine good hyperparameters. Why was it necessary to tune them again?\n- I wonder why deep learning was only used for neighborhood selection via scoring, while the neighborhood generation is still based on the handcrafted destroy heuristics. Wouldn't it make sense to address the generation via deep learning as well to make the approach more end-to-end [6]?\n\n[6] Y. Wu et al., \"Learning Large Neighborhood Search Policy for Integer Programming\", NeurIPS 2021"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission4163/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4163/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission4163/Reviewer_TyGL"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4163/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698559435850,
            "cdate": 1698559435850,
            "tmdate": 1700704501739,
            "mdate": 1700704501739,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "tD06y7rDc8",
                "forum": "2NpAw2QJBY",
                "replyto": "wfACgcrAXf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response Part 1/3"
                    },
                    "comment": {
                        "value": "We are very grateful for the reviewer\u2019s suggestions to improve the rigor and soundness of our experiments by providing additional perspectives of performance. We encourage the reviewer to first examine our general response to all reviewers, where we summarize major rebuttal updates. Here we focus on each comment in more detail:\n\n**Novelty**: We discuss the novelty of our proposed intra-path attention in the general response and its aptness for multi-agent path planning. We encourage the reviewer to view updated architectural figure (Figure 3) as well as additional ablation (Appendix A.6).\n\n**Soundness**:\nRegarding the reviewer\u2019s comments about sources of increase in runtime:\n\n1. Model overhead: the neural network overhead is indeed larger than Linear. However, what\u2019s important is the *relative overhead*; that is, the model overhead is insignificant when it is small compared to the repair heuristic. In Table 1, we observe this phenomenon in many cases for the Multi-Subset network, especially in large settings like den520d (256x257). In real-world deployment settings, the repair heuristic used could incorporate continuous robot dynamics and thus take even longer than the repair heuristics used in our discrete setting; this would further reduce the relative model overhead.\n2. Both MAPF-ML-LNS and our work requires multiple calls to the destroy heuristic. However, the destroy heuristic takes 3-4 orders of magnitude less time than the repair heuristic, and thus is insignificant in the overall runtime.\n3. PBS is indeed slower than PP, but offers significantly stronger improvements per call, especially as we show in parameter sweeps in Appendix A.2. The slower runtime of PBS is actually synergistic with our neural network approach (see Bullet 1).\n\nRegarding the reviewer\u2019s concerns about generalization, our generalization experiments are grounded in multi-robot warehousing applications, where it would be uncommon (and expensive!) to have large deviations in floor maps (especially size) or warehouse operating conditions (e.g. 5x fewer robots). Under such circumstances, we presume it would be common practice to train separate models rather than rely on generalization. On the other hand, obstacle locations, number of agents, and subset construction could change on a minute-by-minute or week-by-week basis, and thus we felt that this warranted an investigation into generalization. The results of our generalization analysis is summarized in Table 2 and are favorable: we found that models trained on both the random and empty floor maps could generalize better than Linear to different number of agents and/or different subset construction heuristics/sizes in the empty floor map."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700030456304,
                "cdate": 1700030456304,
                "tmdate": 1700030456304,
                "mdate": 1700030456304,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "DeOQit4c3z",
                "forum": "2NpAw2QJBY",
                "replyto": "wfACgcrAXf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response Part 2/3"
                    },
                    "comment": {
                        "value": "**Significance/Evaluation**: We acknowledge that our original submission lacks direct comparisons that invites concerns regarding fairness/significance, especially the relative metrics that we used and the lack of per-iteration performance comparisons. We thus provide additional results which addresses these concerns and allow direct comparisons with MAPF-LNS and MAPF-ML-LNS.\n\nOur Linear baseline also uses the best fixed neighborhood size and destroy heuristic. As we explain in detail in updated Appendix A.2, neither our work nor MAPF-ML-LNS is designed to choose between subsets with different sizes in a principled manner. E.g. a subset of size 50 would take significantly longer time to repair than a subset of size 5, but neither our work nor MAPF-ML-LNS considers the runtime of repairing the subsets. Thus, to keep the experimental setting controlled, we do not consider subsets with different size. We note that any future linear-model work proposing a principled way to consider subsets of different size is also applicable to our neural method. Moreover, when comparing absolute performance below, MAPF-ML-LNS does not outperform our Linear (and we could not find their code for comparison). Thus, we believe that our implementation of linear guided LNS is fair to previous work.\n\nRegarding absolute performance, this is a great point which we aim to convincingly address here. We compile the best \u201csums of delays\u201d for each of our studied settings from MAPF-LNS and MAPF-ML-LNS into Appendix A.7. We show that except for the empty (32x32) setting studied by MAPF-LNS, our sums of delays are significantly lower than both previous works. Unclear to us, MAPF-ML-LNS often reports significantly higher sums of delays than the original MAPF-LNS. While compute resources may be different, we believe that our sums of delays are reasonable or better compared to MAPF-LNS and MAPF-ML-LNS. The better solution qualities that we see may be explained by the difference between using PBS vs PP as the subproblem solver, as illustrated in Appendix A.2. Unfortunately, we could not compare AUC directly with either work, as they do not report absolute AUCs. We believe that our sums of delays are worse in the empty (32x32) setting than MAPF-LNS because this is the only setting where MAPF-LNS finds it advantageous to use EECBS [1] as the initialization algorithm (see MAPF-LNS Table 2), while we only use PP and PPS as the initialization algorithms. \n\n[1] Li, Jiaoyang, Wheeler Ruml, and Sven Koenig. \"Eecbs: A bounded-suboptimal search for multi-agent path finding.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 14. 2021.\n\nRegarding generalization performance to different number of agents, in Table 2 we show that our models are reasonably generalizable, as demonstrated between different number of training ($|A| = 350$ or $|A| = 250$) and testing agents ($|A| \\in \\\\{250, 300, 350\\\\}$). \n\nRegarding reporting performance vs number of iterations, we indeed show that our method uses significantly fewer LNS iterations than baselines to attain a given sum of delays. In new Appendix A.8, we graph the sum of delays vs iteration for all settings. We find that the conclusions here are similar to Appendix A.7, and that our method reduces both the number of LNS steps and the runtime needed to attain a given solution quality.\n\nRegarding the reviewer\u2019s request for code, we hope that the concern for reproducibility is alleviated by our additional analysis: 1) the absolute sums of delays comparisons with MAPF-LNS and MAPF-ML-LNS and 2) the per-iteration comparisons of learned vs unguided selection. We are committed to releasing full code and trained models for reproducibility upon publication. We are averse to releasing code before then, especially because the public nature of ICLR review process leaves some room for abuse of released material if our paper were not accepted. Please let us know if the reviewer has further concerns regarding this point, and we will be happy to see how we can address the concerns."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700030520869,
                "cdate": 1700030520869,
                "tmdate": 1700030520869,
                "mdate": 1700030520869,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "kilBpdAmX3",
                "forum": "2NpAw2QJBY",
                "replyto": "wfACgcrAXf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response Part 3/3"
                    },
                    "comment": {
                        "value": "**Questions**\n\nWe study PBS as a repair heuristics because it is one of the state-of-the-practice solvers which is more scalable than CBS and offers much better solution qualities than PP. We are unclear on why MAPF-LNS and MAPF-ML-LNS do not study PBS, even though it is used in other papers by the same authors [2]. Thus, as MAPF-LNS only sweeps for PP from $k = 2$ to $k = 16$ and differs in compute resources from us, we must sweep hyperparameters ourselves with both PBS and PP. Indeed, our hyperparameter search finds that larger neighborhood sizes (e.g. $k = 25$) tend to be the best for PBS.\n\n[2] Li, Jiaoyang, et al. \"Lifelong multi-agent path finding in large-scale warehouses.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 13. 2021.\n\nIn general, it also could make sense to use deep learning as the destroy heuristic for LNS and this could be explored by future work in the MAPF domain. [3, 4, 5] use deep learning as the destroy heuristics. On the other hand, [MAPF-ML-LNS, 6] are similar to ours and perform subset selection. In general, we find that deep learning works in (mixed) integer (linear) programming like [3, 4] tend to learn the destroy heuristic.\n\n[3] Y. Wu et al., \"Learning Large Neighborhood Search Policy for Integer Programming\", NeurIPS 2021\n\n[4] Huang, Taoan, et al. \"Searching large neighborhoods for integer linear programs with contrastive learning.\" International Conference on Machine Learning. PMLR, 2023.\n\n[5] Zong, Zefang, et al. \"Rbg: Hierarchically solving large-scale routing problems in logistic systems via reinforcement learning.\" Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. 2022.\n\n[6] Li, Sirui, Zhongxia Yan, and Cathy Wu. \"Learning to delegate for large-scale vehicle routing.\" Advances in Neural Information Processing Systems 34 (2021): 26198-26211.\n\nWe again thank the reviewer for taking the time to help us strengthen our work, and we truly believe that the reviewer\u2019s suggestions has led to a more grounded perspective of our work. We hope that the reviewer will consider increasing our score accordingly if we have appropriately alleviated the reviewer's concerns."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700030619423,
                "cdate": 1700030619423,
                "tmdate": 1700030619423,
                "mdate": 1700030619423,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9U2zwsEpLN",
                "forum": "2NpAw2QJBY",
                "replyto": "wfACgcrAXf",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_TyGL"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_TyGL"
                ],
                "content": {
                    "title": {
                        "value": "Follow-Up"
                    },
                    "comment": {
                        "value": "Thank you for the rebuttal (and apologies for the time it took me to read through it). Most concerns are addressed, and I will slightly raise my score.\n\nHowever, I do not acknowledge the lack of code. Since reproducibility and implementation details (especially regarding MAPF/search algorithms) are important in our community, the concerns regarding abuse should be outweighed by an adequate review since any code may have flaws. Thus, allowing independent checks can improve the overall quality of the work."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700542774059,
                "cdate": 1700542774059,
                "tmdate": 1700542856487,
                "mdate": 1700542856487,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ZSJyz8xiDR",
            "forum": "2NpAw2QJBY",
            "replyto": "2NpAw2QJBY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4163/Reviewer_TxMF"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4163/Reviewer_TxMF"
            ],
            "content": {
                "summary": {
                    "value": "This paper is a study that utilizes a neural network structure based on 3D convolution to perform multi-agent path finding from a spatial-temporal perspective. Unlike previous research that used linear feature-based machine learning structures, this paper eliminates the feature dependency through 3D convolution-based architecture.\n\nBy selecting a subset of k diverse combinations of agents from the entire agent set and comparing the changes in cost, it distinguishes between the multi-subset approach, which aims to find the optimal subset structure, and the per-subset approach, which uses only a single subset. Through testing, it confirms that the multi-subset approach performs better. Furthermore, it also demonstrates performance improvements when comparing with the Unguided method, which extracts subsets using predefined rules, and the traditional Linear method."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "By utilizing 3D convolution to consider spatial and temporal information simultaneously, the authors have proposed a method for enabling appropriate path finding for multi-agents without collision in situations involving a large number of agents at higher speed. Furthermore, through the Multi-subset structure, they solve multiple subproblems in a \"batch\" format, which has the advantage of quickly verifying better paths using this batch structure."
                },
                "weaknesses": {
                    "value": "The key point of this paper is the rapid resolution of Guiding LNS using 3D convolution without the need for separate feature design in the network structure. However, the author has only applied 3D convolution without providing further theoretical proof or proposing new methods. Therefore, while it is acknowledged that there is an improvement in performance through the application of deep learning structures, the paper has limitations in terms of its overall value.\n\nAdditionally, the MAPF the author aimed to address only holds significance when applied to real robots. However, the author tested the proposed method in a simplified simulation environment for performance verification. This aspect restricts the paper's value to the theoretical domain. To give this research more meaning, it would have been beneficial to include tests involving the use of robots in real-world environments, such as logistics robots."
                },
                "questions": {
                    "value": "Overall, the representation through diagrams is lacking. First, this paper places significant importance on the Time dimension. However, it merely mentions the T dimension without providing any illustrative examples of path changes in this time domain direction, which made it challenging to comprehend. It would have been easier to understand if a few examples of images with different appearances in the T dimension were shown.\n\nAdditionally, it would have been helpful for understanding if the paper had diagrammatically represented the network in Figures 2 and 3. The section regarding the network is written with text such as \"3D CNN\" and \"2D CNN,\" making it difficult to intuitively grasp. Visualizing the network, as done in other papers that use convolution layers, would have aided in conveying the content.\n\nFurthermore, in Section 4.3, two types of transformers are utilized: Light-weight and Heavy-weight. It would be beneficial if the differences between these two structures were more explicitly mentioned."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No concern."
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4163/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698684717599,
            "cdate": 1698684717599,
            "tmdate": 1699636381973,
            "mdate": 1699636381973,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "p9hjT6TOvb",
                "forum": "2NpAw2QJBY",
                "replyto": "ZSJyz8xiDR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We very much thank the reviewer for alerting us to the deficiencies of our current architectural Figures 2 and 3, which we have completely revamped during the rebuttal. We would appreciate the reviewer taking some time to examine our new Figures 2 and 3, which can be viewed by re-downloading the paper from OpenReview. Furthermore, we encourage the reviewer to view our general response to all reviewers, where we also discuss other major rebuttal additions. Here we address some of the reviewer\u2019s comments.\n\n**Weaknesses**\n\n1. We acknowledge that our work does not aim for theoretical impact; however, we believe that our work provides a new and valuable empirical method. The integration of intra-path attention with 3D convolution is the core aspect of our neural method, and is broadly applicable to general multi-path problems, which occur in multi-agent or combinatorial problems that consider spatiotemporal interactions. Though we focus on LNS, we envision that the same architecture may improve the performance on classification, regression, generative, and decision tasks in these domains.\n2. While we do not consider real-world robot experiments in this work, it is a great direction for future work (we have added it to the conclusions). Even without such experiments, our work informs practitioners (e.g., logistics companies) of the potential and limitations of deep neural approaches for LNS-based methods.\n\n**Questions**\n\n1. We have significantly updated our Figures 2 and 3 to better illustrate the time dimensions. We would appreciate any additional feedback on the new figures!\n2. Similarly, please let us know if the updated Figures 2 and 3 allow readers to better visualize the convolutional structures.\n3. In our updated Figure 3, we have better illustrated \u201clight-weight\u201d vs \u201cheavy-weight\u201d. The \u201cheavy-weight\u201d transformer attention operations attends across each agent\u2019s entire path (and is thus proportional to the number of agents and T); these operations are contained within the \u201cConvolution-attention block\u201d and are shared across all subsets. The \u201clight-weight\u201d attention operation only operates on the **first** tensor along each subset agent\u2019s path rather than the entire path, and thus does not depend on T. Thus, both \u201cheavy-weight\u201d and \u201clight-weight\u201d attention utilize the standard transformer architecture, but differ in the size of the inputs, and thus their computational cost.\n\nBy following the reviewer's suggestions, we believe we have significantly strengthened our submission. If we have addressed the reviewer's concerns, we hope that the reviewer will consider increasing their score accordingly."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700030164788,
                "cdate": 1700030164788,
                "tmdate": 1700030164788,
                "mdate": 1700030164788,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "lXZOzqwhvp",
                "forum": "2NpAw2QJBY",
                "replyto": "p9hjT6TOvb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_TxMF"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_TxMF"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the rebuttal. Firstly, I appreciate the clear representation of the Time dimension in Figures 2 and 3, which was helpful for understanding. However, it seems necessary to maintain a consistent arrangement of columns in the figures. They are arranged irregularlly now. Additionally, the previous use of opacity to depict paths in the figures was helpful for comprehension, but it seems to be missing in the current illustration, leading to a decrease in clarity. Due to the absence of paths and the representation of only nodes, it is challenging to distinguish between the current path and the shortest path. If the paths were removed due to complexity, reducing the number of layers in the Time dimension direction and using opacity for each layer to represent the entire path might enhance understanding.\n\nAdditionally, in Figure 3, the proximity between the upper and lower rows causes confusion. It would be beneficial to add a slight margin between them. Moreover, the figure is too small, and the text is not easily visible unless enlarged. Eliminating the left and right margins and increasing the figure size would likely improve visibility."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700601725470,
                "cdate": 1700601725470,
                "tmdate": 1700601725470,
                "mdate": 1700601725470,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "7QOOIJoOqZ",
            "forum": "2NpAw2QJBY",
            "replyto": "2NpAw2QJBY",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission4163/Reviewer_CV86"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission4163/Reviewer_CV86"
            ],
            "content": {
                "summary": {
                    "value": "1The paper proposes to use a deep learning-based framework to select agent subsets to destroy in LNS for the problem of multi-agent path finding (MAPF). Two architectures are proposed: per-subset and multi-subset methods. In experiment, two architectures are tested on five maps of different sizes. In particular, multi-subset performs a lot better than the other approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The deep neural network architecture that incorporates spatiotemporal information seems to be a good contribution to the MAPF community. \n\n2. Empirical results demonstrate the usefulness of the multi-subset architecture."
                },
                "weaknesses": {
                    "value": "1. The description of the runtime overhead is a bit unclear. I just want to confirm since this is important: when you run your method for 60 seconds, this includes the machine learning inference overhead, right? Though, from the plot it is clear your approach is still the best when the overhead is included. \n\n2. Have you tried generalizing your model to other agent sizes on the same map as training (similar to what Huang et al show in their paper)?\n\n3. It seems unfair to restrict the unguided approach to use only one destroy heuristic, this restriction is made mainly for the benefit of the ML-guided approaches. In the MAPF-LNS paper, it has been shown that the adaptive destroy heuristic is much better for the unguided approach."
                },
                "questions": {
                    "value": "You mentioned two challenges in the intro with the second one being the overhead of machine learning inference time. Can you elaborate more on how you address this issue with your model?\nThere is a short paragraph in section 5 that describes some of the engineering details. Do you use other techniques behind the scenes?\n\n\nYou use c_min to compute the gap, which is the solution found by the baseline within 10 minutes. Could this lead to a negative gap when your method finds better solutions within just 1 minute? (though it is unlikely to happen)"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission4163/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698813871169,
            "cdate": 1698813871169,
            "tmdate": 1699636381886,
            "mdate": 1699636381886,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "ifKIoqvkHI",
                "forum": "2NpAw2QJBY",
                "replyto": "7QOOIJoOqZ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank the reviewer for the feedback and suggestions. Here are our responses to each concern:\n\n**Weaknesses**\n\n1. Yes, the Average Gap (%), Win / Loss, and Final Gap (%) in Table 1 already include the stated model overhead in the 60s runtime (they are exactly the solid curves in Figure 5).\n2. Yes, in Table 2, we did indeed find that our method generalizes better than Linear to different warehouse obstacle layouts (random (32x32) during training and empty (32x32) during testing), different destroy heuristics (agent-local $k=25$ during training and uniform $k=50$ during testing), and different number of agents ($|A| = 250$ or $|A| = 350$ during training and $|A| \\in \\\\{250, 300, 350\\\\}$ during testing). Regarding how we chose these generalization configurations: our generalization experiments are grounded in multi-robot warehousing applications, where it would be uncommon (and expensive!) to have large deviations in floor maps (especially size) or warehouse operating conditions (e.g. 5x fewer robots). Under such circumstances, we presume it would be common practice to train separate models rather than rely on generalization. On the other hand, obstacle locations, number of agents, and subset construction could change on a minute-by-minute or week-by-week basis, and thus we felt that this warranted an investigation into generalization.\n3. Adaptive LNS (ALNS), which is used by MAPF-LNS and MAPF-ML-LNS to adaptively adjust subset construction method (destroy heuristic), does not offer significant difference in performance compared to the **best** fixed subset construction method used in our paper. Indeed, examining Table 2 in the original MAPF-LNS paper, ALNS is often worse than the best fixed destroy heuristic. We also demonstrate this in our sweep experiments in Appendix A.2, Table 7 and Table 6. Therefore, we believe that it is fair to restrict our focus to the best fixed destroy heuristics.\n\n**Questions**\n\n1. As suggested by reviewers, we revamped illustrations of our architectures in updated Figures 2 and 3 in the paper (please see the updated pdf on OpenReview). Comparing Figure 2 and Figure 3, the Multi-subset architecture shares much of the computation across all $J$ subsets, and the computation specific to each subset is relatively minimal and requires no 3D convolution or attention across space and time. As discussed in Section 5, we may use spatiotemporal pooling for all agent locations and obstacles for both Multi-subset and Per-subset. We also use fp16 precision instead of fp32 precision. Other than these techniques already stated in our paper, we have not used additional techniques behind the scene, though we believe that the model overhead can be further improved if needed with traditional model compression techniques like distillation, pruning, and/or quantization. \n2. Indeed, this could lead to the gap turning negative, but that would require a more than 10x speedup over the Unguided LNS baseline.\n\nWe hope that we have addressed the reviewer\u2019s concerns here, and we encourage the reviewer to additionally take into account new results presented in our general rebuttal to all reviewers. We hope that the reviewer will consider increasing our score if they agree that we have strengthened the work."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700030122129,
                "cdate": 1700030122129,
                "tmdate": 1700030335855,
                "mdate": 1700030335855,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "IMLJpRD38K",
                "forum": "2NpAw2QJBY",
                "replyto": "ifKIoqvkHI",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_CV86"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission4163/Reviewer_CV86"
                ],
                "content": {
                    "comment": {
                        "value": "I have read the rebuttal and read the other discussions. I trust the results but strongly encourage the authors to fully open-source the code should it get accepted."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission4163/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700704793942,
                "cdate": 1700704793942,
                "tmdate": 1700704793942,
                "mdate": 1700704793942,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]