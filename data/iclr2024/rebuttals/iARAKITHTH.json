[
    {
        "title": "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text"
    },
    {
        "review": {
            "id": "jZ7XPzPN3L",
            "forum": "iARAKITHTH",
            "replyto": "iARAKITHTH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8248/Reviewer_CMmZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8248/Reviewer_CMmZ"
            ],
            "content": {
                "summary": {
                    "value": "The paper describes a method to detect text generate by an LLM. The method can be applied to text generated by any LLM without fine-tuning and it is based on the perplexity of the text according to a an observer LLM, but normalized by the perplexity of the text generated by another LLM using the same input string, The method is evaluated on several public datasets and compared to some other machine-generated detectors."
                },
                "soundness": {
                    "value": "1 poor"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "The proposed method is simple and the rationale behind the proposed normalized perplexity is well motivated and seems to be appropiate. It does not require any specific training and can be used with text generated by any LLM and also with any LLM to compute the perplexity."
                },
                "weaknesses": {
                    "value": "I have several concerns regarging the experimental validation and the presentatation of the results:\n- In section 4.2 it is argued that TPR@FPR is a better metric than F1 score or AOU, and particularly TPR at 0.01% of FPR. However TPR at 0.01 FPR is never used in the results presented afterwards and mainly F1, AUC, precision and recall are used in most of the figures. Only in figures 4 and 6 TPR vs FPR is plot, but without specifically analyzing TPR at 0.01% FPR as claimed in section 4.2. Related to this, in the abstract it is claimed that \"On news documents Binoculars detect 95% of synthetic samples at a false positive rate of 0.01%\". In the results only figure 4 for the student essay dataset seems to show a result similar to this one, but it is very specific to only of the datasets used in the experiments.\n- Evaluation should be done in a more systematic and coherent way among different datasets to be able to better compare the performance of the proposed method with SoA. As long as it is possible the same methods should be used for comparison. However, the set of methods used to compare with in figures 2, 4, 5 and 6 are different, and even methods used in figure 6 are not mentioned or discussed in the text.\n- The selection of the methods used to compare with is not clearly motivated. In section 2 many methods are described and categorized in different categories. I would be nice to have a systematic comparison with more methods of each of the categories defined in section 2. \n- I miss an ablation study analyzing some of the choices made in the design of the method. For instance, the contribution of using \tthe proposed detection score vs. simple perplexity or the effect of the LLMs used both to compute perplexity and to generate the text to be classified. Is there any difference in performance (positive or negative) if the observer LLM is the same LLM used to generate the text under analysis?\n- It is not clear what figure 3 is showing. Also, in the caption of figure 5 it is said that the comparison is on LLaMa text while in the text referring to the figure it is mentioned text generated by LLaMa, but also by Falcon. Not clear exactly whaat figure 5 is showing. \n- There is no comparison of the results obtained in the Orca dataset with results obtained by other methods. \n- The description of M4 datasets in section 4.3 would fit better in section 4.1 with the description of the rest of the datasets. \n\nAnd finally, a minor comment with respect equation (3): shouldn't it be log(M_2(T(s))_i) instead of log(M_2(T(s))_j)?"
                },
                "questions": {
                    "value": "See above in weaknesses"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8248/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698789832885,
            "cdate": 1698789832885,
            "tmdate": 1699637025866,
            "mdate": 1699637025866,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "eFvK4cD9c8",
                "forum": "iARAKITHTH",
                "replyto": "jZ7XPzPN3L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer CMmZ (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable time and effort in providing this constructive review. We used collective feedback from reviewers and conducted additional experiments with results in Figure 3 (per-token detection performance), Figure 4 (open-source generation detection), Figure 9 (detecting different prompting strategies), and Figure 17 (ablation). Below is our response with a point-by-point note for the questions/weaknesses listed.\n\nFirstly, we highlight that the \u201ccross-perplexity\u201d definition is a novel concept in NLP to the best of our knowledge. Its usage in perplexity-detectors for normalization is motivated in section 3.3, resulting in a significant increase in performance by addressing the perplexity-only-detectors limitations (as shown in Figure 17 in Appendix A5). The definition and use of x-PPL came about after viewing the perplexity-only-detector (and its limitation)  from a specific lens as mentioned in \u201cCapybara problem\u201d (section 3.2) important for motivating this work.\n\nBased on the feedback, we have updated the draft highlighting our changes with blue text. \n\n__1. Usage of TPR @ low-FPR across experiments__\n- In the metrics section, we discuss how detectors\u2019 performance should be evaluated under a low-false-positive regime (which can be realized by many metrics) since type 1 errors are significantly more costly than type 2 in downstream tasks. We also argue that typically reported metrics like standalone AUC values, as in other baselines, don\u2019t translate into real-life performance sufficiency (as shown in Table 2: AUCs are uncorrelated with TPR at low FPR). Below is our rationale for metrics in figures:\n  - Figure 1 reports TPR @ 0.01% FPR and Figure 2 reports F1-Score on the identical dataset as Figure 1 (ChatGPT benchmark by [1])\n  - Figure 3 is updated to have TPR @ 0.01% FPR at the varying sizes of samples (# of tokens)\n  - Figure 4 reports TPR observed at different FPR levels (on log scale) for LLaMA-2-13B generations over 3 datasets\n  - Figure 5, 6, and 7 reports how Binoculars maintain high precision (with varying recall) over multiple generators, languages and domains respectively.\n  - Figure 9's dataset contains only machine-generated samples and hence only reports an error rate.\n\n__2. The abstract claim of detecting news documents Binoculars detect 95% of synthetic samples at a false positive rate of 0.01%__\n- This figure is from the first column in Figure 1 (News, ChatGPT dataset [1]). We updated the abstract to replace the previously rounded number to 94.92%.\n\n__3. Document size impact figure only contains the Student dataset__\n- We updated Figure 3 to include all 3 datasets from [1] and also added another baseline method (GPTZero).\n\n__4. Performance comparison with state-of-the-art and using the same methods should be used for comparison__\n- Our emphasis is directed toward baselines that function within post hoc, out-of-domain (zero-order), and black-box detection scenarios. We use state-of-the-art Ghostbuster (Verma et al., 2023), the commercially deployed GPTZero, and DetectGPT to compare detection performance over various datasets in Section 4.\n- Performance Benchmark: As per above, on all benchmark datasets in section 4, we use these baselines (which include the ChatGPT benchmark dataset competing baseline in [1]). To align our experiments better, we have updated the figure as mentioned above in this note. We thank you for your feedback on this.\n- Reliability: In Section 5, we evaluate the reliability of Binoculars in various settings that constitute edge cases and interesting behaviors of our detector. With the exception of Figure 9 (modified prompting strategies), we report these numbers as absolute to aide understanding of Binoculars specifically. \n\n__5. Methods in Figure 6 are not mentioned or discussed in the text__\n- Thank you for this feedback. We have added a paragraph in section 5.1 for these methods. \n\n__6. The selection of the methods used to compare with is not motivated.__\n- We updated the draft to motivate our choice of baselines (also mentioned in the previous point) (section 2). To reiterate, we focus on evaluating baselines designed for post hoc, out-of-domain (zero-order), and black-box detection scenarios. which includes state-of-the-art Ghostbusters (Verma et al., 2023), the commercially deployed GPTZero, and DetectGPT.\n\n__7. Ablation study to ascertain the contribution of using the proposed detection score vs. simple perplexity__\n- Due to the page limit we have this study in Figure 12 + Table 3 in Appendix A. We compare PPL, xPPL, and Binoculars (Falcon and LLaMA variants) performance over the ChatGPT dataset from 1]. We see how Binoculars perform better than its components to detect machine text."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700533313262,
                "cdate": 1700533313262,
                "tmdate": 1700535910268,
                "mdate": 1700535910268,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "JBXs4wE1K2",
                "forum": "iARAKITHTH",
                "replyto": "jZ7XPzPN3L",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Gentle Reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer CMmZ,\n\nAs the discussion period ends, we would like to kindly ask for your reply to our remarks. We feel we have addressed your concerns and we look forward to further discussions and guidance. Please let us know if there is anything else we can do or other questions we can answer."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700582598840,
                "cdate": 1700582598840,
                "tmdate": 1700582598840,
                "mdate": 1700582598840,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "HDMidEXvcR",
                "forum": "iARAKITHTH",
                "replyto": "JBXs4wE1K2",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Reviewer_CMmZ"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Reviewer_CMmZ"
                ],
                "content": {
                    "comment": {
                        "value": "Dear authors,\nthank you for your detailed response, addressing most of my concerns. I do not require further clarifications. I will carefully review your response along with the other reviewer's comments before making my final recommendation."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700643877706,
                "cdate": 1700643877706,
                "tmdate": 1700643877706,
                "mdate": 1700643877706,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "5xBFwbPRMJ",
            "forum": "iARAKITHTH",
            "replyto": "iARAKITHTH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8248/Reviewer_M521"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8248/Reviewer_M521"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a simple method to detect machine-generated text, based on measures of perplexity of two independent LMs.\nThe score is derived from the assumption that a texts generated by two LMs are more similar with each other than with human text.\nA comprehensive evaluation is carried out to show that the proposed method has a high detection rate at a low false positive rate. \nThis remains true for various models used for generating texts. The proposed method gives competitive or superior results compared \nto several other methods. Finally, the authors discuss the potential limitations of their method when used in practice"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper is well written, easy to follow and to understand. \nThe proposed method looks very simple and quite easy to implement. It is well evaluated and seems to give good results, which is a nice combination.\nIt extends perplexity-based method in a simple and well motivated way.\nThe paper makes a number of good/interesting points (e.g. the motivation to measure the True Positive Rate at low FPRs, the remark on memorization/randomization in Section 5, the one on LLM similarity).\nMost questions that arise when reading the paper are actually answered in the appendix (e.g. how about using different LLM for the score computation, how does the text length affect the detection).\nThe discussion of limitations in sections 5 and 6 is particularly appreciated: it is still too rarely seen in papers. They naturally raise questions about the potential weaknesses of the approach but the transparency is valuable."
                },
                "weaknesses": {
                    "value": "The paper is quite nice in terms of contents, presentation and evaluation of the proposed method for the 10-page limit. \n\nFurther analysis of some aspects could add value to the presented work, although I acknowledge that not everything can fit in the paper (some of which will be asked in the \"Questions\" section:\n\n  - In section 2, it could be clearer how the proposed method relates to other PPL-based ones\n  - In Table 2, we see that the performance can vary a lot depending on the chosen LLM for scoring: what makes a good LLM for the method? Why other choices reach lower TPR?\n  - The point about similarity of LLMs is interesting. What would happen if the LM (evaluated or chosen for scoring) is less similar, e.g. different training set, different kind of model, etc.\n\nMinor remarks:\n\n  - in 5.1, mention that Table 4 is in the appendix\n  - 4.3 \"Fig. 3\" -> Figure 3"
                },
                "questions": {
                    "value": "Most of the questions I had while reading the manuscript were answered in the appendix.\n\nSome other aspects that I would be curious about following the read of this paper:\n\n  - The point made at the end of 5.1 is interesting but it is not so clear what should be concluded from that remark. It also begs the question of how would the training set of the LLMs (mostly written by humans I guess) be detected\n  - The point made in 5.4 (randomization) is interesting as well. It would be interesting to see if the detector could be fooled by randomly changing \"some\" words in the generated text. I guess the remark made in 5.1 about the desirability of outcome is relevant here too (= how to consider human-edited machine-generated text)\n  - The point of 5.2 is interesting and we could also wonder how robust this detection method is. For example, is it easy to tweak existing LLMs to fool the detector (other than prompt), or during training, how easy would it be to integrate the detection score to fool the detector."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8248/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698848935855,
            "cdate": 1698848935855,
            "tmdate": 1699637025764,
            "mdate": 1699637025764,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3O4nZlcRyJ",
                "forum": "iARAKITHTH",
                "replyto": "5xBFwbPRMJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer M521"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable time and effort in providing this constructive review. We are glad that you found our paper well-written, and easy to follow. We used collective feedback from reviewers and conducted additional experiments with results in Figure 3 (per-token detection performance), Figure 4 (open-source generation detection), Figure 9 (detecting different prompting strategies), and Figure 17 (ablation). Below is our response with a point-by-point note for the questions/weaknesses listed.\n\n__1. In section 2, it could be clearer how the proposed method relates to other PPL-based ones__\n- One difference between Binoculars and some other perplexity-based detectors is in the number of forward passes required to compute a discriminative score. For example, DetectGPT is built on a similar motivation -- that perplexity alone is insufficient for classification -- but to overcome the weakness in the signal, DetectGPT utilizes the perplexity of several perturbations to the input. In addition to the overhead of generating perturbations, it also requires computing many perplexities and thus it can be far more computationally expensive. So there may be various ways to extract meaningful information from perplexity, ours is less computationally demanding than some others.\n\n__2. In Table 2, we see that the performance can vary a lot depending on the chosen LLM for scoring: what makes a good LLM for the method? Why other choices reach lower TPR?__\n- This is more because of how stringent TPR @ 0.01% FPR as a performance metric is than instability of performance. We updated the table 2 to include TPR @ 0.1% FPR. F1-Score and AUC. As you may see, the performances are \"stable\" through the lens of F1-Score and AUC - which are fine metrics to use when the costs of type 1 and 2 errors are uniform. \n- However, in problems with the severely skewed cost of error towards FP (like detection), metrics like (vanilla) F1-score and AUC don\u2019t provide downstream safety in the deployment of these systems. \n- We also note (in section 4.2) \u201cthat AUC scores are often uncorrelated with TRP@FPR when the FPR is below 1%.\u201d (as seen in the updated Table 2).\n- Moreover, we see saturation of performance using Binoculars (at least in its current format) irrespective of the scorers used. However, with the surge in open-source LMs, we do not claim an exhaustive search of scoring models to be used.\n\n__3. What would happen if the LM (evaluated or chosen for scoring) is less similar, e.g. different training set, different kind of model, etc.__\n- Please note, by our x-PPL definition, we have an implicit constraint of having to use two models to share a tokenizer, and most available open-source models have a high degree of training set overlap (eg. Falcon, Llama families, etc.). \n- The cross-perplexity measures the degree to which two models' next-token distributions overlap. We suspect cross-ppl from two models trained on dissimilar datasets would provide more noise than the signal we want to detect (see updated text section 3.3 for motivation of x-PPL). \n- The similar behavior of the transformers model is what we depend on for cross-ppl and Binoculars score definition. Thank you for mentioning this important point. We expanded the definition section to mention the impact of different training sets and will be happy to provide any more information required. \n- In the ablation experiment (in Figure 17), we see how x-PPL and PPl alone aren't enough for reliable detection performance.\n\n__4. How would the training set of the LLMs (mostly written by humans I guess) be detected__\n- Training samples are a super-set of memorized strings in Section 5.3 (i.e. strings that were part of training but may or may not be re-generated by LLM). \n- For a perplexity-based detector, memorized/famous text is more difficult to classify in comparison to samples from larger training sets (since the famous text is expected to be in the training set multiple times). \n- Also, the classification of such samples is domain-specific since both humans and machines can be deemed to have produced it in different domains (eg. plagiarism detection v/s  removal of LLM-generated text from a training corpus). \n- With this understanding and performance on memorized text, we believe that our detector would score samples from the training set towards the human side of the threshold and should be leveraged accordingly in downstream tasks."
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700537918369,
                "cdate": 1700537918369,
                "tmdate": 1700537918369,
                "mdate": 1700537918369,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "9Bmyw9UNpy",
                "forum": "iARAKITHTH",
                "replyto": "5xBFwbPRMJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Gentle Reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer M521,\n\nAs the discussion period ends, we would like to kindly ask for your reply to our remarks. We feel we have addressed your concerns and we look forward to further discussions and guidance. Please let us know if there is anything else we can do or other questions we can answer."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700582493815,
                "cdate": 1700582493815,
                "tmdate": 1700582493815,
                "mdate": 1700582493815,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "0sejDPGKxw",
            "forum": "iARAKITHTH",
            "replyto": "iARAKITHTH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8248/Reviewer_iAnY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8248/Reviewer_iAnY"
            ],
            "content": {
                "summary": {
                    "value": "To detect text generated by large language models, the authors propose in this work a method called Binoculars. Different from previous methods for separating human-generated and machine-generated text, Binoculars utilize two models instead of one, to compute two scores: perplexity and cross-perplexity. The ratio of perplexity to cross-perplexity is defined as the Binocular score. The proposed does not need training examples and works in the zero-shot setting."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The idea of using two large language models to compute a score to distinguish between human-generated and machine-generated text is novel and seems to be effective to certain extent.\n2. The paper is overall well-written, and the core idea and technical details are clearly presented."
                },
                "weaknesses": {
                    "value": "1. The experiments are insufficient in that: (1) The experiments and comparisons in Figure 5 are crucial, but the authors only compared with Ghostbuster and the analyses are too brief; (2) According to the ablation study in A.1 in the APPENDIX, the authors actually only conducted experiments using the models from the Falcon and Llama-2 families. Why other types of open-source or closed-source large language models (such as ChatGPT, GPT-4 and Baichuan 2) are not adopted?\n2. The reason behind the effectiveness of the proposed Binoculars method is not fully explained."
                },
                "questions": {
                    "value": "The authors should resolve the questions in the Weaknesses section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8248/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698896128574,
            "cdate": 1698896128574,
            "tmdate": 1699637025662,
            "mdate": 1699637025662,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3kFl7CWmrg",
                "forum": "iARAKITHTH",
                "replyto": "0sejDPGKxw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer iAnY"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable time and effort in providing this constructive review. Based on the feedback, we have updated the draft highlighting our changes with blue text. We used collective feedback from reviewers and conducted additional experiments with results in Figure 3 (per-token detection performance), Figure 4 (open-source generation detection), Figure 9 (detecting different prompting strategies), and Figure 17 (ablation). Below is our response with a point-by-point note for the questions/weaknesses listed.\n\n__1. Only Ghostbusters used as a baseline in open-source language models text detection (LLaMA-2-13B)__\n- We add baseline experiments in Figure 4. The performances on Falcon-7B generations can be found in Figure 13 in Appendix A3.\n\n__2. Only models from Falcon and Llama-2 families used for computing x-PPL__\n- Thanks for noting this. This is because of the following:\n- Implicit constraint of x-PPL computation which requires two models to have identical tokenizer (we mention in section 3.1)\n- As per our intuition (and motivation, section 3.3), our detector's performance is dependent on having two _similar_ (by training set) models for computing x-PPL and would only cause a marginal change in performance across different scoring model pairs. We show this in the updated Table 2 in Appendix A1, how F1-Score and AUC metrics (which weigh type 1 and type 2 error equally) are stable across multiple pairs of scoring models only resulting in a marginal change in the performance of the detector. Please note, that we do not claim our scoring models search to be exhaustive.\n\n__3. The reason behind the effectiveness of Binoculars__\n- In the updated draft, we develop on motivation behind our detector (use of x-PPL) in section 3.3: \"Language models are known for producing low-perplexity text relative to humans and thus a perplexity threshold classifier makes for an obvious detecting scheme. However, in the LLM era, the generated text may exhibit a high perplexity score in the absence of the prompt (\u201cCapybara Problem\u201d in Table 1). To calibrate for prompts that yield high-perplexity generation, we use cross-perplexity introduced in Equation (3) as a normalizing factor that roughly encodes the perplexity level of next-token predictions from two models.\"\n- We employ this cross-perplexity, which encodes the degree with which two models' next-token distributions overlap, as our normalizing mechanism to solve the \"Capybara Problem.\" The similar behavior of the transformers model is what we depend on for the x-PPL and Binoculars score definition. Thank you for mentioning this important point. We expanded the definition section to mention the impact of different training sets and will be happy to provide any more information required. \n\nTo summarize, we present a novel detector that is able to maintain high efficacy in a false-positive regime under various domains/datasets/baselines, using only open-source components to detect in zero-shot settings. Broadly, we highlight the need to evaluate detectors in terms of low-false positive metrics and showcase how our method is performative in this regime (note: in principle, by lowering the threshold even further we can virtually eliminate any false positives). We further study our detector\u2019s reliability in settings that constitute edge cases to understand interesting behaviors, abilities, and limitations of our detector.\n\nWe are happy to take on any follow-up questions or other feedback.\n\nAgain, we thank you for your time and contribution to this key area of secure and safe machine learning in the generative AI era."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700527383822,
                "cdate": 1700527383822,
                "tmdate": 1700527771517,
                "mdate": 1700527771517,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "sX7RHYIyNJ",
                "forum": "iARAKITHTH",
                "replyto": "0sejDPGKxw",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "A Gentle Reminder"
                    },
                    "comment": {
                        "value": "Dear Reviewer iAnY,\n\nAs the discussion period ends, we would like to kindly ask for your reply to our remarks. We feel we have addressed your concerns and we look forward to further discussions and guidance. Please let us know if there is anything else we can do or other questions we can answer."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700582446483,
                "cdate": 1700582446483,
                "tmdate": 1700582446483,
                "mdate": 1700582446483,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "puoIDllz01",
            "forum": "iARAKITHTH",
            "replyto": "iARAKITHTH",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission8248/Reviewer_FmjG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission8248/Reviewer_FmjG"
            ],
            "content": {
                "summary": {
                    "value": "This paper presents a novel machine-generated text detector that is based on a simple metric that can be obtained from existing pre-trained LLMs. The proposed metric (Binoculars score) is computed as the ratio between the perplexity and cross-perplexity of a given sample text for two pre-trained LLMs. Using the Binoculars score they build a simple threshold-based classifier to separate machine-generated and human text."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The proposed Binoculars score for machine-generated text detection can be computed from pre-trained LLM models without any re-training/finetuning.\n+ The obtained results are promising on a variety of machine-generated text detection scenarios, including text generated with different generators, and in a variety of domains."
                },
                "weaknesses": {
                    "value": "The authors claim their method is a zero-shot detector, but they \"optimize and fix the detection threshold globally using these datasets\". The fact that the used pre-trained LLMs are not retrained/fine-tuned does not imply the proposed method is zero-shot, as they optimize the detection threshold for the target task with (in most of the cases) some in-domain data.\n\nI have several concerns regarding the experimental section of this paper.\n\n- Several of the baseline models are not explained in the text: Zero-shot (in Figure 1) and Roberta, LR GLTR, Stylistic, Nela (in figure 6).\n- The comparison with baselines is not consistent across experiments, in some Figures/Tables the proposed method is compared with a set of baselines while in others the baselines are different. The choice of baselines seems quite trivial and makes it difficult to assess the contribution of proposed method:\n- In Figure 5, Ghostbuster (Verma et al., 2023) is not trained for this dataset, while the detection threshold of the roposed method seems to be optimized on it. Why no other baselines are shown in this plot?\n- The results on the M4 Datasets (Figures 3 and 6) are not well explained in my opinion and seem to be not consistent with the results in (Wang et al., 2023). In (Wang et al., 2023) the authors present results on different settings: same-generator cross-domain experiments, same-domain cross-generator experiments. In here it is not specified whether the numbers shown in Figure 6 come from one or the other setting, and the values provided for the baselines' results do not match (at least for what I can appreciate) with the ones found in the tables of (Wang et al., 2023).\n- The numbers in Figure 3 are not compared with any baselines. This comparison would be highly relevant due to the authors claim on being able to detect text generated with any text-generator.\n- For the Orca Dataset no baselines' results are provided. Same for all the experiments in section 5. Not having any baseline results on these experiments makes it very difficult to quantify the quality of the proposed solution.\n\nWhen showing FPR/TPR plots, how are these plots generated? by changing the detection threshold? I do not understand why you say 0.01% FPR threshold is \"The smallest threshold we can comprehensively evaluate with our limited compute resources.\"\n\n\nApart from all this, it seems to me that the formulation/notation of the Binoculars score is confusing in some aspects.\n\n- $L$ (in eq. 2 and 3) is not defined anywhere in the text, I assume it is the sentence-length.\n- The subindex $j$ in eq. 3 is not defined. (Maybe it is a typo?)\n- In eq.3 it would be better to use $\\overrightarrow{x}$ (as defined before) instead of $T(s)$. It would make the equation more readable.\n- If I'm not missing something, the measure expressed in eq. 3 is the $log XPPL$ not $XPPL$. At least it looks consistent with the $log PPL$ definition in eq.2.\n- Although the authors first define $log PPL$ in eq. 2, they use $PPL$ instead in the formulation of the Binocular score in eq. 4.\n\nMoreover, since cross-perplexity ($XPPL$) is not a standard term in NLP or machine learning, I would expect to see a bit more of discussion on its interpretation and its effects on the proposed Binoculars score: what are the upper/lower bounds of B? what happens when M_1 and M_2 are the same pre-trained model? what if they are trained in two totally different domains? I appreciate the effort made in section 3.2 (Capybara problem) for the case of \"hand-crafted prompts\", but other aspects of the Binoculars score should be discussed as well."
                },
                "questions": {
                    "value": "Please clarify those aspects mentioned in the weaknesses section of my review that do not imply new experiments: zero-shot claim, choice of baselines, Binoculars score formulation and interpretation, etc."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission8248/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698924147182,
            "cdate": 1698924147182,
            "tmdate": 1699637025532,
            "mdate": 1699637025532,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "yhlbBS0vqI",
                "forum": "iARAKITHTH",
                "replyto": "puoIDllz01",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer FmjG (Part 1)"
                    },
                    "comment": {
                        "value": "We thank the reviewer for their valuable time and effort in providing this constructive review. Based on the feedback, we have updated the draft highlighting our changes with blue text. Driven by your feedback we have conducted additional experiments with results in Figure 3 (per-token detection performance), Figure 4 (open-source generation detection),  Figure 9 (detecting different prompting strategies), and Figure 17 (ablation). Below is our response with a point-by-point note for the questions/weaknesses listed. \n\n__1. Zero-shot Detection Claim.__\n- We would like to clarify that we do not optimize the threshold for the target task (in all cases/experiments), but use a global threshold obtained from Binoculars. As mentioned in section 4.3: since our global threshold is tuned on a ChatGPT benchmark dataset (News, Creative Writing, Essay) by [1] (Ghostbusters method), we make an exception \"to be sure that we meet the OOD criteria, we do not include the ChatGPT datasets in the threshold determination, and only use samples from CC News, CNN, and PubMed (generated via LLaMA and Falcon) to determine threshold to do predictions/evaluation on ChatGPT benchmark dataset (Figure 1, 2, & 3). For open-source datasets (CC News, CNN, and PubMed), we report AUC plots for all methods that are threshold-invariant for all methods (Figure 4). With this OOD threshold, we demonstrate that reliably detects texts generated by different LMs and from different domains.\n\n\n__2. Roberta, LR GLTR, Stylistic, Nela not explained.__\n- Thank you for pointing out, that we have added a note in the M4 Datasets note in section 5.1\n\n__3. Choice of baselines and across experiments__\n- In this work, our emphasis is directed toward baselines that function within post hoc, out-of-domain (zero-order), and black-box detection scenarios. We use state-of-the-art Ghostbusters [1], GPTZero, and DetectGPT to compare detection performance over various datasets in section 4.\n- In section 5, we evaluate the reliability of Binoculars in various settings that constitute edge cases and\ninteresting behaviors of our detector (multi-domain, languages, non-native English text, etc.)\n- We updated the draft to mention our choice of baselines and rationale towards the end of Section 2.\n\n__4.  Methodology Results of M4 Datasets [2]__\n- From Wang et al., we use ChatGPT vs Human performance table. To aid OOD comparison between Binoculars and other baselines, we use the mean of OOD-reported performances by Wang et al. For each baseline, for the \"arXiv\" domain for example, we use the mean of performance when the respective baseline is trained on {Wikipedia, WikiHow, Reddit, ELI5, PeerRead}.\n- We update the caption Figure 7 to clarify this.\n\n__5. Absence baseline comparison on M4 dataset__\n- Rationale: As mentioned above, in Section 4 we use baseline methods to compare our performance with established zero-shot, OOD domain detectors on various known benchmark datasets. Our intent for M4 datasets is to study our detector's performance in multiple domains, languages, and text generators and report non-relative claims.\n-  Constraint: Unlike other feedback, we could not run other methods on M4 datasets which consist of 39 datasets with 3k samples each due to sizable constraints: a) Ghostbusters require approx $1150 OpenAI credits to get log-probs for 46 million tokens (512 per sample), b) computational constraint for DetectGPT which requires computing multiple perturbations. \n- Thus, we move M4 datasets experiments to Section 5 (reliability).\n\n__6. Baselines in Orca Dataset__\n- We run other methods to append baselines in Figure 9 to show our method is more robust than other methods.\n\n__7. Inconsistency/typos in formulation/notation.__\n- We thank you for the detailed feedback and have updated to fix all pointers.\n\n__8. Intuition on x-PPL, its interpretation, and its effect on the detection method__\n- __Lower/Upper Bound:__ Binoculars score are ratios of two cross-entropy measures (both being positive) and is a positive number\n- __Impact of using identical models for scoring__: We perform this experiment and report the findings in Figure 17 in Appendix A5. We observe using Falcon-7B as $M_1$ and $M_2$ comes close to Binocular's performance.\n\n\n\n[1] Vivek Verma, Eve Fleisig, Nicholas Tomlin, and Dan Klein. Ghostbuster: Detecting Text Ghost-\nwritten by Large Language Models. arxiv:2305.15047[cs], May 2023. doi: 10.48550/arXiv.2305.\n15047. URL http://arxiv.org/abs/2305.15047.\n[2] Yuxia Wang, Jonibek Mansurov, Petar Ivanov, Jinyan Su, Artem Shelmanov, Akim Tsvigun,\nChenxi Whitehouse, Osama Mohammed Afzal, Tarek Mahmoud, Alham Fikri Aji, and Preslav\nNakov. M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated\nText Detection. arxiv:2305.14902[cs], May 2023. doi: 10.48550/arXiv.2305.14902. URL\nhttp://arxiv.org/abs/2305.14902"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700523737283,
                "cdate": 1700523737283,
                "tmdate": 1700523737283,
                "mdate": 1700523737283,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "taN9MQByiw",
                "forum": "iARAKITHTH",
                "replyto": "puoIDllz01",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission8248/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer FmjG (Part 2)"
                    },
                    "comment": {
                        "value": "__9. Use of scoring models trained on different domains and other aspects of Binoculars.__\n- Please note, by our x-PPL definition, we have an implicit constraint of having to use two models to share a tokenizer, and most available open-source models have a high degree of training set overlap (eg. Falcon, Llama family). \n- The cross-perplexity measures the degree to which two models' next-token distributions overlap. We suspect cross-ppl from two models trained on dissimilar datasets would provide more noise than the signal we want to detect (see updated text section 3.3 for motivation of x-PPL). The similar behavior of the transformers model is what we depend on for cross-ppl and Binoculars score definition. Thank you for mentioning this important point. We expanded the definition section to mention the impact of different training sets and will be happy to provide any more information required. \n- In the ablation experiment (in Figure 17), we see how x-PPL and PPl alone aren't enough for reliable detection performance.\n- We are happy to answer any further or follow-up questions on this.\n\n__10. When showing FPR/TPR plots, how are these plots generated? by changing the detection threshold? I do not understand why you say 0.01% FPR threshold is \"The smallest threshold we can comprehensively evaluate with our limited compute resources.\"__\n- Yes, for each method we move the threshold to achieve 0.01% FPR and report the TPR figures to compare performance in low false positive regime. \n- The FPR rate we can achieve on a log scale is a function of the number of samples. For all our experiments, we use a balanced dataset (50-50 human and LM samples). At 0.01% FPR, we would need 10k samples per class, and at 0.001% we would need 100k samples per class.\n\nTo summarize, we present a novel detector that is able to maintain high efficacy in a false-positive regime under various domains/datasets/baselines, using only open-source components to detect in zero-shot settings. Broadly, we highlight the need to evaluate detectors in terms of low-false positive metrics and showcase how our method is performative in this regime (note: in principle, by lowering the threshold even further we can virtually eliminate any false positives). We further study our detector\u2019s reliability in settings that constitute edge cases to understand interesting behaviors, abilities, and limitations of our detector.\n\nWe are happy to take on any follow-up questions or other feedback.\n\nAgain, we thank our reviewers for their time and contribution to this key area of secure and safe machine learning in the generative AI era."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission8248/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700524236135,
                "cdate": 1700524236135,
                "tmdate": 1700547322792,
                "mdate": 1700547322792,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]