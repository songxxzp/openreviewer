[
    {
        "title": "HyperMask: Adaptive Hypernetwork-based Masks for Continual Learning"
    },
    {
        "review": {
            "id": "ymS2QZKSNT",
            "forum": "LhNZqkuVte",
            "replyto": "LhNZqkuVte",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1307/Reviewer_1qn2"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1307/Reviewer_1qn2"
            ],
            "content": {
                "summary": {
                    "value": "The authors are proposing a CIL method that can make use of a single network for multiple tasks. Based on the lottery ticket hypothesis, the proposed method only modifies the weights related to the specific task and this preserves the performance of previous tasks. Even though the hyper network consumes extra memory, it can keep the base network from growing over tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "- The method itself is technically reasonable and the details of the method are well described in the paper."
                },
                "weaknesses": {
                    "value": "- Baselines suggested in this paper are relatively outdated. I understand that incremental architecture methods are no longer dominating this field of research but it does not mean that they can ignore regularization or representation based methods. For example, FeCAM [1] does not even need to know the task index and it still outperforms the author's method.\n- The amount of experimental result is severely insufficient. According to the paper, HyperMask is superior to other methods only in Split-Cifar100 and in my knowledge this is not the best one in continual learning. Please refer to [1].\n- Almost all techniques utilized in this paper are brought from previous works and I'm not sure if this is something new in CIL. Also if the authors were to mention about Lottery-ticket hypothesis, I think there should be something more than this. This method looks like a combination of HAT and PackNet to me.\n\n[1] Goswami, Dipam, et al. \"FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning.\" arXiv preprint arXiv:2309.14062 (2023)."
                },
                "questions": {
                    "value": "- I would be appreciated if the comments above are resolved."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Reviewer_1qn2"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1307/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698716622838,
            "cdate": 1698716622838,
            "tmdate": 1699636057929,
            "mdate": 1699636057929,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "e6lpHNgxuP",
                "forum": "LhNZqkuVte",
                "replyto": "ymS2QZKSNT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1qn2, part 1/3"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the comments related to our manuscript. We refer to your remarks in the text below.\n\n*Q1*: Baselines suggested in this paper are relatively outdated. I understand that incremental architecture methods are no longer dominating this field of research but it does not mean that they can ignore regularization or representation based methods. For example, FeCAM [1] does not even need to know the task index and it still outperforms the author's method.\n\n*R1*: \n* **HyperMask lies in a completely different category of continual learning methods**. Therefore, its comparison with FeCAM is not trivial. FeCAM is dedicated to a different setting where we have a pre-trained backbone, which does not change during the next training iterations. Authors use pre-trained architectures, like ResNet-18 and ViT-B/16, to generate class prototypes. They model the feature covariance relations using Mahalanobis distance to determine decision boundaries. FeCAM is not an architecture-based method since the architecture is not changed during training. We want to highlight that a setting with a frozen backbone and prototypes is important but is not dedicated to architecture-based approaches. Nevertheless, FeCAM is a good benchmark for the prototypical methods.\n\n* Consequently, **no experiment from our paper matches any experiment in FeCAM**. By comparing the results from HyperMask and FeCAM, it is impossible to say which model works better because the evaluation strategies of the methods are different. Authors of FeCAM state, as follows:\n> We experiment with three different incremental settings for CIFAR100 and ImageNet-Subset: 1) 50 initial classes and 5 incremental learning (IL) tasks of 10 classes; 2) 50 initial classes and 10 IL tasks of 5 classes; 3) 40 initial classes and 20 IL tasks of 3 classes. For TinyImageNet, we use 100 initial classes and distribute the remaining classes into three incremental settings: 1) 5 IL tasks of 20 classes; 2) 10 IL tasks of 10 classes; 3) 20 IL tasks of 5 classes.\n\n* In HyperMask, **we followed the experimental scenarios from architecture-based methods like HNET [1] and WSN [2]**. In the case of CIFAR-100, the dataset was divided into 10 tasks with 10 classes per task, as in [2]. Similarly, we added experiments for TinyImageNet according to the strategy described in [2] or [3], i.e. we created 40 tasks with 5 classes in a single task. It means that the evaluation criteria are different and there is no possibility of comparing the results for the experiments mentioned above.\n\n* We also think that models that do not use a pre-train backbone are still very important. We compare our model with **WSN (published in ICML 2022)** in a similar setting to the depicted one. We also compare our results with two strong algorithms: La-MaML [3] from 2020 and FS-DGPM [4] from 2021.\n\n* In the paper, in Table 2, **we described results for a continual learning setting in which the task identity has to be recognized by the model itself**. The results are presented for Permuted MNIST and Split MNIST datasets. The method applied was very simple because it was based on the entropy calculation, and still, the results were competitive. It suggests that the application of the more advanced approach (for instance, based on clustering methods used for the target network classification layer) should lead to high performance. It is part of our future work.\n\n[1] J. von Oswald et al., Continual learning with hypernetworks, ICLR 2020.\n\n[2] H. Kang et al., Forget-free Continual Learning with Winning Subnetworks, ICML 2022.\n\n[3] G. Gupta et al., La-MAML: Look-ahead Meta Learning for Continual Learning, Advances in NeurIPS, 2020.\n\n[4] D. Deng et al., Flattening sharpness for dynamic gradient projection memory benefits continual learning, In Advances in NeurIPS, 2021."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700262706515,
                "cdate": 1700262706515,
                "tmdate": 1700329521487,
                "mdate": 1700329521487,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "tOFFbqVfoL",
                "forum": "LhNZqkuVte",
                "replyto": "ymS2QZKSNT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer 1qn2, part 2/3"
                    },
                    "comment": {
                        "value": "*Q2*: The amount of experimental result is severely insufficient. According to the paper, HyperMask is superior to other methods only in Split-Cifar100 and in my knowledge this is not the best one in continual learning. Please refer to\n> Goswami, Dipam, et al. \"FeCAM: Exploiting the Heterogeneity of Class Distributions in Exemplar-Free Continual Learning.\" arXiv preprint arXiv:2309.14062 (2023).\n\n*R2*:\n* We performed experiments on TinyImageNet, a demanding dataset consisting of 40 continual learning tasks with 5 classes. A single image has a shape of 64 x 64 x 3. We prepared experiments using ResNet-20 architecture with an embedding vector of 96, \u03b2 and \u03bb equalling 1 and 0.1, respectively. Furthermore, p was set to 0, batch size to 16 and learning rate to 0.0001. Similar to WSN, the number of training epochs for each task was 10, and 50 validation samples from each class were selected in each CL task.\n\n* **We achieved state-of-the-art results, outperforming all reference methods.** The mean classification accuracy for 5 runs of HyperMask was equal to **76.22%**, while the best baseline, WSN, reached 71.96% using the architecture with 4 convolutional and 3 fully connected layers. Full results for **TinyImageNet** are depicted in the following table:\n\n## Results for TinyImageNet\n| Method        | Mean classification accuracy in % (with std dev.) |\n|---------------|---------------------------------------------------|\n| La-MaML [3]   | 66.90 +/- 1.65                                    |\n| GPM           | 67.39 +/- 0.47                                    |\n| FS-DGPM [4]   | 70.41 +/- 1.30                                    |\n| PackNet       | 55.46 +/- 1.22                                    |\n| SupSup        | 59.60 +/- 1.05                                    |\n| WSN, c = 3%   | 68.72 +/- 1.63                                    |\n| WSN, c = 5%   | 71.22 +/- 0.94                                    |\n| WSN, c = 10%  | 71.96 +/- 1.41                                    |\n| WSN, c = 30%  | 70.92 +/- 1.37                                    |\n| WSN, c = 50%  | 69.06 +/- 0.82                                    |\n| **HyperMask** | **76.22 +/- 1.06**                                |"
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700263453715,
                "cdate": 1700263453715,
                "tmdate": 1700329537308,
                "mdate": 1700329537308,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "qFQ3z1Xcmm",
                "forum": "LhNZqkuVte",
                "replyto": "ymS2QZKSNT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Reviewer_1qn2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Reviewer_1qn2"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Thanks for the prompt response of the authors. Here are several issues I still have.\n\n1.\n- FeCAM can be used upon a pre-trained network but the main method described in the paper is training on the first task and keep it frozen during the remaining training phases. Therefore it's not a method that makes use of something more than this paper.\n- I do know the difference of experimental settings but the one from FeCAM is **far more difficult** because the task index is not given during the evaluation. Furthermore, FeCAM has demonstrated on a smaller architecture and it's hard to find the benefit of this method then.\n- But as the authors say, considering the difference on settings and setting limits on the range of baselines, the performance seems to be reasonable\n\n2.\n- I think it's a difference of a perspective but in my opinion, HAT trains individual embedding vectors for each task through a learnable module and I don't see the difference from the hypernetwork in terms of controlling the main network from outside. Accordingly, the contibutions the authors are claiming does not seem to be valid."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700555269926,
                "cdate": 1700555269926,
                "tmdate": 1700555285660,
                "mdate": 1700555285660,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "pYyvMtZDdB",
                "forum": "LhNZqkuVte",
                "replyto": "WLT1INu7Ks",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Reviewer_1qn2"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Reviewer_1qn2"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "- Thanks for correcting me about not using the task index during inference. However if so, there is even no reason to exclude FeCAM for comparison. In my perspective, HyperMask and FeCAM are just solving CIL without task index and methods such as HAT and PackNet should not be in the same category since they require task index.\n- I still think the experiment result is not enough to convince me and I leave the score as is."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700662216837,
                "cdate": 1700662216837,
                "tmdate": 1700662216837,
                "mdate": 1700662216837,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "le22djMTkA",
            "forum": "LhNZqkuVte",
            "replyto": "LhNZqkuVte",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1307/Reviewer_uLSz"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1307/Reviewer_uLSz"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a novel method, HyperMask, which leverages hypernetwork paradigms to model lottery ticket-based subnetworks.\nHyperMask retains the ability to reuse weights from the lottery ticket module and adapt to new tasks, inheriting the strengths of both approaches. The semi-binary masks generated by HyperMask enhance the target network's ability to discriminate between classes in consecutive continual learning tasks. The paper offers a promising solution to the issue of catastrophic forgetting by combining two existing paradigms in a novel way, demonstrating potential significance in the field of continual learning."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. The paper introduces an innovative approach, HyperMask, that combines the concepts of hypernetworks and the lottery ticket hypothesis. This unique combination leads to a novel method for addressing catastrophic forgetting in continual learning. \n2. The idea of using semi-binary masks generated by a hypernetwork to create target subnetworks is a fresh and creative approach to tackling the challenges of continual learning. \n3. The paper demonstrates a high level of quality in the experimental evaluation of HyperMask. It provides a comprehensive set of experiments on multiple benchmark datasets, comparing HyperMask against various state-of-the-art baseline methods."
                },
                "weaknesses": {
                    "value": "1.The primary contribution of HyperMask, which involves using hypernetworks to produce semi-binary masks for continual learning, may not be considered highly novel in the field of continual learning and neural network architectures. Hypernetworks have been explored in prior research as a means to generate task-specific weights for neural networks [1][2], and the concept of using masks or pruning for model adaptation is not entirely new.\n2. The paper lacks a deeper theoretical analysis of the proposed HyperMask method. It would be beneficial to include a more comprehensive theoretical foundation for the approach, explaining why semi-binary masks generated by hypernetworks are effective in minimizing forgetting. \n3. The paper could benefit from providing more detailed guidelines for selecting hyperparameters. HyperMask involves parameters such as \u03b2, \u03bb, and p, and while the authors mention the hyperparameter optimization process, they do not offer specific recommendations or insights on how to choose these hyperparameters effectively. \n4. The paper could expand the comparison to include other hypernetwork variants or architectures that have been proposed in the literature. Specifically, discussing how HyperMask compares to variations of hypernetwork-based approaches.\n5. The paper does not provide detailed information on the computational resources required for training HyperMask, including information on training time, memory usage.\n\n[1] PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning (CVPR2018)\n[2] Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights (ECCV2018)"
                },
                "questions": {
                    "value": "1. Can the authors provide a more detailed discussion of the novelty of their proposed method compared to prior work in the field of continual learning and hypernetwork-based approaches? \n2. The paper mentions that HyperMask has some limitations in terms of memory consumption due to the requirement for the hypernetwork's output layer to match the number of parameters in the target network. Are there any potential strategies or approaches to mitigate this memory consumption issue?\n3. The paper mentions that HyperMask has some limitations in terms of memory consumption due to the requirement for the hypernetwork's output layer to match the number of parameters in the target network. Are there any potential strategies or approaches to mitigate this memory consumption issue?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Reviewer_uLSz"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1307/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698752781381,
            "cdate": 1698752781381,
            "tmdate": 1700660331619,
            "mdate": 1700660331619,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "3l1n7wqchj",
                "forum": "LhNZqkuVte",
                "replyto": "le22djMTkA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uLSz, part 1/2"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the feedback regarding our paper and constructive remarks.  We are glad that you appreciate our approach. We respond to your questions in the points below.\n\n*Q1*: Can the authors provide a more detailed discussion of the novelty of their proposed method compared to prior work in the field of continual learning and hypernetwork-based approaches?\n\n*R1*: The model combines two continual learning (CL) methodologies and provides a new concept using a meta-model to produce subnetworks. **The masks produced by the hypernetwork modulate the weights of the main network and act like dynamic filters, enhancing the target weights important for a given task and decreasing the importance of the remaining weights.**\n\n### Architecture-based CL methods\n+ To the best of our knowledge, our model is the first architecture-based CL model that uses hypernetwork, or, in general, any meta-model, for producing masks for other networks. \n+ Hypernetwork is a meta-model that builds masks by sharing information across subsequent tasks in the meta-model\u2019s weights. Therefore, knowledge from previous tasks is stored in the hypernetwork weights and the masks produced are not completely independent.   \n+ In consequence, we do not freeze any target model weights like in many architecture-based models.\n\n### Hypernetwork-based methods\n+ A single hypernetwork model produces sets of weights dedicated to each CL task. **Updates of hypernetworks are prepared not directly for the weights of the main model, like in HNET [1], but for masks modulating the target model.**\n+ HyperMask, unlike most of the methods used, produces trainable updates for a trainable model without freezing in any part.\n+ We show that hypernetworks may be used completely differently than classical hypernetwork CL models like HNET [1]. \n\n[1] J. von Oswald et al., Continual learning with hypernetworks, ICLR 2020.\n\n*Q2*: The paper mentions that HyperMask has some limitations in terms of memory consumption due to the requirement for the hypernetwork's output layer to match the number of parameters in the target network. Are there any potential strategies or approaches to mitigate this memory consumption issue?\n\n*R2*: \n* We currently require that the hypernetwork output layer should match the number of parameters in the target network. Applying **chunked hypernetworks** similarly to [1] may mitigate this issue. In this architecture, the weights of the target model are created partially through so-called chunks; the number of chunks is another hyperparameter. Furthermore, other embedding vectors related to the chunk position must be created because the hypernetwork has to get information on which part of the target model weights will be produced. Similarly to the task embedding vectors, they are learned through back-propagation. Chunked hypernetworks will contribute to memory saving due to a lower number of hypernetwork weights (the smaller number of output neurons than in the case of the full hypernetwork architectures). Our initial experiments with chunked hypernetworks did not produce sufficient enough results in terms of classification accuracy but a more thorough analysis may solve this problem.  \n\n* We need a similar calculation time as in HNET [1] and more detailed results for calculations performed on a single GPU card are presented in the following table:\n\n| Dataset              | Mean calculation time (with std dev.) in HH:MM:SS |\n|----------------------|---------------------------------------------------|\n| Split MNIST          | 00:21:06 +/- 00:02:37                             |\n| Permuted MNIST       | 01:45:14 +/- 00:04:07                             |\n| CIFAR 100 (ResNet)   | 10:26:37 +/- 00:10:05                             |\n| CIFAR 100 (ZenkeNet) | 06:02:25 +/- 00:01:54                             |"
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261967513,
                "cdate": 1700261967513,
                "tmdate": 1700474916338,
                "mdate": 1700474916338,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "flOsljPkxh",
                "forum": "LhNZqkuVte",
                "replyto": "le22djMTkA",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer uLSz"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your time and effort in reading our response! We hope our response has addressed your concerns. If you still feel unclear or worried, please let us know; we would be happy to clarify further and discuss any additional questions. If you feel your concerns have been addressed, please kindly consider if it is possible to update your score.\n\nThank you!"
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646582338,
                "cdate": 1700646582338,
                "tmdate": 1700646582338,
                "mdate": 1700646582338,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "zF7xQuTzxW",
                "forum": "LhNZqkuVte",
                "replyto": "3l1n7wqchj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Reviewer_uLSz"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Reviewer_uLSz"
                ],
                "content": {
                    "title": {
                        "value": "Response to authors"
                    },
                    "comment": {
                        "value": "Firstly, I appreciate your efforts and prompt responses. However, there are a few concerns that need to be addressed:\n1. I respectfully disagree with the assertion that the proposed method can be considered as the first architecture-based CL model utilizing hypernetworks. There have been previous architecture-based CL models [1][2]. But you ignore my questions about discussion with these popular method.\n[1] PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning (CVPR2018) \n[2] Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights (ECCV2018)\n2. I fully support Reviewer 1qn2's suggestion regarding comparing our approach with FeCAM, which is the latest research in the field of continual learning.\n\nConsequently, I will lower my score."
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700660307725,
                "cdate": 1700660307725,
                "tmdate": 1700660307725,
                "mdate": 1700660307725,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "saiKP8ix9W",
            "forum": "LhNZqkuVte",
            "replyto": "LhNZqkuVte",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission1307/Reviewer_G6Eq"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission1307/Reviewer_G6Eq"
            ],
            "content": {
                "summary": {
                    "value": "The paper works on continual learning with hypernetworks. The main idea is to generate masks to obtain a subnetwork for the new task. The experiments are conducted on Permuted MNIST, Split MNIST and Split CIFAR-100."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "(1) The hypernetworks are used for continual learning in a different way of generating hypermasks for each task.\n(2) It connects to lottery ticket theory with a single network for continual learning.\n(3) The method is easy to follow in general."
                },
                "weaknesses": {
                    "value": "(1) There are some works mentioned in the related work using masks as an extension of the whole network, it is unclear what benefits hypernetwork can bring.\n(2) There are several common loss functions are used in the method, and it is unclear if the improvements are from the proposed hypernetworks or the additional regularizations. There is no ablation study on these components.\n(3) The experimental evaluation is very limited. It only compares with other methods on very tiny benchmarks. The performance gain from Table 1 seems not very significant. And it is hard to know how much more computation and complexity the method needs."
                },
                "questions": {
                    "value": "The superiority of the method is not clear compared to other existing methods and the evaluation section is weak."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission1307/Reviewer_G6Eq"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission1307/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698804093831,
            "cdate": 1698804093831,
            "tmdate": 1700647130030,
            "mdate": 1700647130030,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9v1KbHOmQm",
                "forum": "LhNZqkuVte",
                "replyto": "saiKP8ix9W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer G6Eq, part 1/2"
                    },
                    "comment": {
                        "value": "We thank the reviewer for the remarks regarding our paper, which will improve its quality. We answer all of your questions as follows.\n\n*Q1*: There are some works mentioned in the related work using masks as an extension of the whole network, it is unclear what benefits hypernetwork can bring.\n\n*R1*: The model combines two continual learning (CL) methodologies and provides a new concept using a meta-model to produce subnetworks. **The masks produced by the hypernetwork modulate the weights of the main network and act like dynamic filters, enhancing the target weights important for a given task and decreasing the importance of the remaining weights.**\n\n### Architecture-based CL methods\n+ To the best of our knowledge, our model is the first architecture-based CL model that uses hypernetwork, or, in general, any meta-model, for producing masks for other networks. \n+ Hypernetwork is a meta-model that builds masks by sharing information across subsequent tasks in the meta-model\u2019s weights. Therefore, knowledge from previous tasks is stored in the hypernetwork weights and the masks produced are not completely independent.   \n+ In consequence, we do not freeze any target model weights like in many architecture-based models.\n\n### Hypernetwork-based methods\n+ A single hypernetwork model produces sets of weights dedicated to each CL task. **Updates of hypernetworks are prepared not directly for the weights of the main model, like in HNET [1], but for masks modulating the target model.**\n+ HyperMask, unlike most of the methods used, produces trainable updates for a trainable model without freezing in any part.\n+ We show that hypernetworks may be used completely differently than classical hypernetwork CL models like HNET [1]. \n\n[1] J. von Oswald et al., Continual learning with hypernetworks, ICLR 2020.\n\n*Q2*: There are several common loss functions are used in the method, and it is unclear if the improvements are from the proposed hypernetworks or the additional regularizations. There is no ablation study on these components.\n\n*R2*: \n* Hypernetwork regularization using previously trained embeddings is a classical approach in hypernetwork models, while L1 regularization of the target model is an often used approach in CL. These two components are combined with the model and together form the presented method consisting of two trainable networks. **The first component is responsible for the regularization of the hypernetwork weights producing masks, while the second one accounts for the target network weights.** Therefore, both parts are necessary for HyperMask because it consists of two trainable networks and we have to prevent radical changes in their weights. In HNET [1], hypernetworks directly produce the target model\u2019s weights and additional regularization is unnecessary because only one model is trained.\n\n* When we do not regularize the hypernetwork or main model, the weights are changed too drastically and catastrophic forgetting occurs. We present an ablation study for different hyperparameter settings responsible for the regularization strength (3 runs per one setup) on the Permuted MNIST dataset with 10 tasks using the same architecture, for which we presented results in Table 1 in our paper.\n\n| beta | lambda | Mean accuracy (with std dev.) |\n|------|--------|-------------------------------|\n| 0.01 | 0      | 84.18 +/- 0.18                |\n| 0.1  | 0      | 80.31 +/- 1.11                |\n| 1    | 0      | 73.68 +/- 0.31                |\n| 0    | 0.01   | 37.82 +/- 1.72                |\n| 0    | 0.1    | 46.32 +/- 1.07                |\n| 0    | 1      | 11.35 +/- 0.00                |"
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700260812293,
                "cdate": 1700260812293,
                "tmdate": 1700260812293,
                "mdate": 1700260812293,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Z0JQKrYyTb",
                "forum": "LhNZqkuVte",
                "replyto": "saiKP8ix9W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer G6Eq, part 2/2"
                    },
                    "comment": {
                        "value": "*Q3*: The experimental evaluation is very limited. It only compares with other methods on very tiny benchmarks. The performance gain from Table 1 seems not very significant. And it is hard to know how much more computation and complexity the method needs.\n\n*R3*: \n* We followed the evaluation protocols from HNET [1] and WSN [2]. Also, we performed experiments on TinyImageNet, a demanding dataset consisting of 40 continual learning tasks with 5 classes. A single image has a shape of 64 x 64 x 3. We prepared experiments using ResNet-20 architecture with an embedding vector of 96, \u03b2 and \u03bb equalling 1 and 0.1, respectively. Furthermore, p was set to 0, batch size to 16 and learning rate to 0.0001. Similar to WSN, the number of training epochs for each task was 10, and 50 validation samples from each class were selected in each CL task.\n\n* **We achieved state-of-the-art results, outperforming all reference methods.** The mean classification accuracy for 5 runs of HyperMask was equal to **76.22%**, while the best baseline, WSN, reached 71.96% using the architecture with 4 convolutional and 3 fully connected layers. Full results for **TinyImageNet** are depicted in the following table:\n\n## Results for TinyImageNet\n| Method        | Mean classification accuracy in % (with std dev.) |\n|---------------|---------------------------------------------------|\n| La-MaML [3]   | 66.90 +/- 1.65                                    |\n| GPM           | 67.39 +/- 0.47                                    |\n| FS-DGPM [4]   | 70.41 +/- 1.30                                    |\n| PackNet       | 55.46 +/- 1.22                                    |\n| SupSup        | 59.60 +/- 1.05                                    |\n| WSN, c = 3%   | 68.72 +/- 1.63                                    |\n| WSN, c = 5%   | 71.22 +/- 0.94                                    |\n| WSN, c = 10%  | 71.96 +/- 1.41                                    |\n| WSN, c = 30%  | 70.92 +/- 1.37                                    |\n| WSN, c = 50%  | 69.06 +/- 0.82                                    |\n| **HyperMask** | **76.22 +/- 1.06**                                |\n\n* In addition to the results for Split CIFAR-100 and Tiny ImageNet, we show in the paper results for Permuted MNIST in 100 tasks with 10 classes and they are presented in Figure 2. **It confirms that our model may be trained on continual learning datasets with many tasks.** Especially interesting is the high result for the first task despite learning 99 of the subsequent ones. We additionally analyze this phenomenon with the t-SNE method for Permuted MNIST with 10 tasks (Figure 3) and Split MNIST with 5 tasks (Figure 6).\n\n* The classical continual learning benchmarks are quite old and we think that state-of-the-art CL models are close to optimal results in such tasks. Our results are strong because we have two best results and two the second ones. We also achieved competitive results in a larger benchmark, i.e. TinyImageNet.\n\n* We need a similar calculation time as in HNET [1] and more detailed results for calculations performed on a single GPU card are presented in the following table:\n\n| Dataset              | Mean calculation time (with std dev.) in HH:MM:SS |\n|----------------------|---------------------------------------------------|\n| Split MNIST          | 00:21:06 +/- 00:02:37                             |\n| Permuted MNIST       | 01:45:14 +/- 00:04:07                             |\n| CIFAR 100 (ResNet)   | 10:26:37 +/- 00:10:05                             |\n| CIFAR 100 (ZenkeNet) | 06:02:25 +/- 00:01:54                             |\n\n* According to the memory consumption, currently, we require that the hypernetwork output layer should match the number of parameters in the target network. Applying **chunked hypernetworks** similarly to [1] may mitigate this issue. In this architecture, the weights of the target model are created partially through so-called chunks; the number of chunks is another hyperparameter. Furthermore, other embedding vectors related to the chunk position must be created because the hypernetwork has to get information on which part of the target model weights will be produced. Similarly to the task embedding vectors, they are learned through back-propagation. Chunked hypernetworks will contribute to memory saving due to a lower number of hypernetwork weights (the smaller number of output neurons than in the case of the full hypernetwork architectures). Our initial experiments with chunked hypernetworks did not produce sufficient enough results in terms of classification accuracy but a more thorough analysis may solve this problem.  \n\n[2] H. Kang et al., Forget-free Continual Learning with Winning Subnetworks, ICML 2022.\n\n[3] G. Gupta et al., La-MaML: Looking ahead meta learning for continual learning, In Advances in NeurIPS, 2020.\n\n[4] D. Deng et al., Flattening sharpness for dynamic gradient projection memory benefits continual learning, In Advances in NeurIPS, 2021."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700261445021,
                "cdate": 1700261445021,
                "tmdate": 1700475024337,
                "mdate": 1700475024337,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "mrGW3aixdi",
                "forum": "LhNZqkuVte",
                "replyto": "saiKP8ix9W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer G6Eq"
                    },
                    "comment": {
                        "value": "Dear Reviewer,\n\nThank you for your time and effort in reading our response! We hope our response has addressed your concerns. If you still feel unclear or worried, please let us know; we would be happy to clarify further and discuss any additional questions. If you feel your concerns have been addressed, please kindly consider if it is possible to update your score.\n\nThank you!"
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700646553194,
                "cdate": 1700646553194,
                "tmdate": 1700646553194,
                "mdate": 1700646553194,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "2lPi4DTUXW",
                "forum": "LhNZqkuVte",
                "replyto": "Z0JQKrYyTb",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission1307/Reviewer_G6Eq"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission1307/Reviewer_G6Eq"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for your efforts in providing more detailed results and explanations."
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission1307/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700647081085,
                "cdate": 1700647081085,
                "tmdate": 1700647081085,
                "mdate": 1700647081085,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]