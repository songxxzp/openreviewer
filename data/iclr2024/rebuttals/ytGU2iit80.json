[
    {
        "title": "From Fourier to Neural ODEs: Flow matching for modeling complex systems"
    },
    {
        "review": {
            "id": "JrTCMTQhPR",
            "forum": "ytGU2iit80",
            "replyto": "ytGU2iit80",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7598/Reviewer_Xqgc"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7598/Reviewer_Xqgc"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose a new method called Fourier NODEs (FNODEs). A key novelty of this work is that Fourier analysis is employed to estimate both temporal and spatial gradients of the noisy data. The estimated spatial gradients are fed into a neural network trained to estimate temporal gradients to assist the prediction of the temporal signals. In addition, the trained neural network could generate more data points through an ODE solver (like up-sampling). Comparisons with state-of-the-art methods showed efficacy of the proposed method regarding training time, accuracy and robustness."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. The proposed method combines Fourier analysis with NODE and utilizes spatial gradients to improve temporal gradient estimations which looks novel.\n2. By utilizing spatial gradients, it could up-sample training data and augment existing training data for model training (potentially improve model performance with more training data).\n3. Experimental results look promising."
                },
                "weaknesses": {
                    "value": "1. Novelty may be limited due to existing work. The authors may want to cite the following paper which also combines Fourier analysis with NODE and clarify their contributions: Hybrid Physical-Neural ODEs for Fast N-body Simulations. \n2. Regarding architecture of the whole system, it\u2019s not clear to me how the feedback loop works. For example, how the predicted data as feedback are combined with the observed data and used by the Fourier analysis? Why not encode the prediction error from ODESolver in the loss function of the neural network F_{\\theta} as shown in the diagram of Fig. 1? The authors are encouraged to illustrate more on the motivations and methodology."
                },
                "questions": {
                    "value": "1. In Sec. 1, the authors claim that Fourier analysis provides theoretical guarantees for accurately estimating the gradient flows of dynamical systems. Are there any citations to support this claim? Also are there any restrictions of the dynamical systems to make this claim work? e.g. continuity, differentiability and stochasticity of the dynamic system?\n2. What\u2019s the general guidance on selection of the cutoff in approximation of spatial gradients of PDEs. Same question goes to the control function u. For example, how to choose hyper parameters of the Gaussian random fields?\n3. In the evaluation section, baseline methods are limited to ODE based methods. Would it make sense to compare it with state-of-the-art time series prediction methods like transformer, n-beats and deepar?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7598/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698208239938,
            "cdate": 1698208239938,
            "tmdate": 1699636921124,
            "mdate": 1699636921124,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "9IMVft3DNG",
                "forum": "ytGU2iit80",
                "replyto": "JrTCMTQhPR",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We sincerely appreciate your insightful comments and valuable suggestions. We kindly recommend that the reviewer carefully reads the \"**General response**\". In response to the individual comments, we have thoroughly considered your suggestions and addressed all concerns in a point-by-point manner as outlined below. We hope that the reviewer recognizes the efforts and improvements we have made in both the methodology and experimental aspects.\n\n```\nW1: Novelty may be limited due to existing work...\n```\n**Response**:  Thank you for your suggestion, and we supplement this work as a reference. While both our work and theirs utilize Fourier analysis, our approaches differ fundamentally. Firstly, our study focuses primarily on a family of parametric ODE/PDE systems, which exhibit unique properties distinct from N-body simulations. Secondly, while they add the power spectral error to their loss function, our approach involves matching the gradient flow. Lastly, building on the powerful NODE framework, we propose an efficient and robust training strategy that is widely applicable, even extending to PDE systems.\n\n```\nW2: Regarding architecture of the whole system, it\u2019s not clear to me how the feedback loop works...\n```\n**Response**:  Thank you for your careful reading and valuable comments. The feedback loop illustrated in Fig. 1 can be interpreted as a form of data augmentation, integrating the dynamics data predicted by the neural network with the original data. This strategy significantly expands the number of sample points, thereby enhancing the precision of Fourier analysis. For a more in-depth procedural understanding, please refer to Fig. 1 in the main text and Algorithm 1 in the appendix.\n\u00a0\nMoreover, the use of gradient flow error as the loss function constitutes the focal point of our research. This choice is advocated due to the fact that in the classical NODE framework, utilizing prediction error as the loss function frequently leads to some challenges involving high computational costs and the propensity for finding local optima, rather than the global optimum.\n\n```\nQ1: In Sec. 1, the authors claim that Fourier analysis provides theoretical guarantees...\n```\n**Response**: Many thanks for your valuable comments. The theoretical guarantees of our method stem from Theorem 1 of the main text (proof in Appendix A.1), which provides conditions under which the gradient estimated via Fourier analysis consistently converges to the actual system gradient.\n\u00a0\nIt is noteworthy that our approach retains its efficacy even in scenarios where these conditions are not strictly met. For instance, many systems exhibit non-periodic behavior, and Fourier analysis, by default, assumes a periodic extension of the input discrete data. This may result in certain estimation errors at the boundaries. In practical implementation, we bypass this issue through disregarding the error at a small segment of the boundary and utilize the remaining error as the loss function (refer to code for details).\n\nFurthermore, as mentioned in the Point 1 of the \"**General Response**\", Fourier analysis and neural network complement each other by matching gradient flows from two distinct perspectives: spectral decomposition and dynamical modeling. In a statistical context, even with certain systematic errors in gradient estimation, this combination allows for robust dynamical modeling. Additionally, our experiments indicate that our method delivers satisfactory performance in modeling tasks for systems that do not strictly adhere to Theorem 1.\n\n```\nQ2: What\u2019s the general guidance on selection of the cutoff in approximation of spatial gradients of PDEs...\n```\n**Response**: Thank you for your comment. In fact, our experimentation includes all common partial derivatives up to fifth order, without any prerequisite knowledge of dynamical equations. Through the neural network, our approach can automatically learn the complex interaction among the spatial derivatives, system state, and parameter values.\n\u00a0\nAs for the hyperparameters in GRF, similar to the articles on FNO and DeepONet methods, these hyperparameters are pre-established. And the variations within a reasonable range are acceptable for these parameters. Detailed configurations can be found in Appendix B and the code for data generation.\n\n```\nQ3: In the evaluation section, baseline methods are limited...\n```\n**Response**: Thanks for your instructive comment. In fact, our goal is to introduce a novel training strategy for NODE via flow matching, not to focus on achieving SOTA performances on various tasks compared with numerous baselines. Therefore, we employ the common baselines to validate the effectiveness of our proposed approach. For further reasons, please refer to the Point 3 of the \"**General Response**\".\n\nIn addition, the methods like transformer, n-beats and deepar indeed perform well in some tasks of time series prediction, but it is not equipped to handle the parametric systems."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7598/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700314926939,
                "cdate": 1700314926939,
                "tmdate": 1700314926939,
                "mdate": 1700314926939,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "sGn9J6ielN",
            "forum": "ytGU2iit80",
            "replyto": "ytGU2iit80",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7598/Reviewer_533P"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7598/Reviewer_533P"
            ],
            "content": {
                "summary": {
                    "value": "The authors introduce a method to model forced time-dependent ODEs/PDEs. The method involves approximating the spatial and temporal derivatives with discrete Fourier transforms (DFTs) and use the applicable spatial derivatives as features to predict the temporal dynamics. The authors also use a data augmentation scheme to handle irregularly sampled data. Results are compared to baseline models for several common ODE/PDE benchmarks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "1 poor"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "* Some level of novelty in using DFT to approximate derivatives and data augmentation to address data sparsity/irregularity.\n* Experiments performed over a variety of systems."
                },
                "weaknesses": {
                    "value": "* Clarity is really lacking - in general I feel that many important details are either explained in a confusing way or simply glossed over. I try to ask some of the questions below but overall they held me back from understanding the idea quite a bit.\n* It is unclear how the model performs over longer periods of time, especially for the more complex benchmarks in KS and NS. This is what truly shows if the proposed model is competitive with existing methods.\n* The baselines do not seem very competitive. The setup is not perfectly aligned but one should be able to adapt and compare baselines in [1].\n\n\nReferences:\n\n[1] Stachenfeld, Kimberly, et al. \"Learned coarse models for efficient turbulence simulation.\" arXiv preprint arXiv:2112.15275 (2021)."
                },
                "questions": {
                    "value": "* How do you decide what spatial derivatives to pass as arguments to your model? How robust is the model if you do not get the terms exactly right?\n* Does your training loss only involve predicting a single-step forward in time (based on equation 5)? Recent results (see [1] for example) suggest that using multiple steps improve performance significantly. This is also what the original NODE entails (computes multi-step error using continuous adjoint).\n* For the data augmentation scheme, do you iteratively update the augmented data at every training step? The quality of the augmented data would obviously not be very good at the beginning of training. Do you take any special measures to account for such?\n* Using DFT to approximate derivatives instead of finite difference obviously has its convenience but also comes with drawbacks. One of the more notable ones is the requirement that the underlying function should be smooth and periodic. It does not seem the periodic assumption is satisfied in your applications, which may lead to approximation errors (i.e. Gibbs phenomenon), especially at the boundaries. Do you use any strategies to address this?\n* Are you only using DFT to compute derivatives but transform everything back in the real space when computing loss? This seems to be what's indicated in the text but then I see (page 6, fifth line from the bottom) reference to complex valued spatial derivatives in Fourier space.\n* What is your exact definition of the error? Are you averaging everywhere (i.e. time, dimensions)? It would also be useful to show how the error accumulates as you roll out the model for longer times.\n* How does your models do in terms of long-term error and stability? \n* Figure 5 - equation (12) is not present in the text\n\nReferences:\n\n[1] Dmitrii Kochkov, Jamie A. Smith, Ayya Alieva, Qing Wang, Michael P. Brenner, and Stephan Hoyer. Machine learning\u2013accelerated computational fluid dynamics. Proceedings of the National Academy of Sciences, 118 (21):e2101784118, 2021."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7598/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7598/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7598/Reviewer_533P"
                    ]
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7598/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698698890916,
            "cdate": 1698698890916,
            "tmdate": 1699636921011,
            "mdate": 1699636921011,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "lNpNPN5pBg",
                "forum": "ytGU2iit80",
                "replyto": "sGn9J6ielN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for your valuable comments and helpful suggestions on the proposed framework. We kindly recommend that the reviewer reads the \"**General response**\" for a comprehensive overview of our main changes and clarifications.  We address each minor and major points raised in the review point by point as follows. We sincerely hope that the reviewer recognizes the efforts and improvements we have made, and reassess the presentation and contribution of our work.\n\n```\nW1: Clarity is really lacking...\n```\n**Response**:  Many thanks for your careful reading and helpful advice. We have conducted a comprehensive review and revision of the paper to enhance the readability and rigor. In what follows, we provide some explanations regarding the 8 detailed questions you care about.\n\nQ1: In fact, our experimentation includes spatial derivatives of up to fifth order, but without any prerequisite knowledge of dynamical equations. Leveraging the power of neural networks, our approach can robustly and automatically learn the complex interactions among the spatial derivatives, system state, and parameter values.\n\nQ2: Traditional NODE methods typically utilize the multi-step prediction error for training. However, our training strategy is different. As demonstrated in Eq. (5), we employ the Fourier analysis on a segment of training data to generate the temporal gradient estimate, denoted as $\\bf{\\hat{h}}\u2019(t_n)$ at all sample points. The gradient errors at all points within this data segment then serve as the basis for our training loss.\n\nQ3: Prior to the implementation of the data augmentation scheme, we fully train the neural network using the existing data to acquire an optimal proxy model of the system dynamics. Subsequently, we further refine our model by training it with augmented data, thereby improving the accuracy of our modeling. The detailed implementation process can be found in the code file \"multi_training.ipynb\".\n\nQ4: In fact, many systems exhibit non-periodic behavior, and Fourier analysis, by default, assumes a periodic extension of the input discrete data. This assumption may introduce estimation errors, particularly at the boundaries. In practical implementation, we bypass this issue by disregarding the error at a small segment of the boundary and utilize the remaining error as the loss function to update neural network (refer to code for details). Furthermore, as mentioned in Point 1 of the \"General Response,\" Fourier analysis and neural network complement each other by directly matching gradient flows from two distinct perspectives: spectral decomposition and dynamical modeling. In a statistical context, despite potential systematic errors in gradient estimation, this combination enables robust dynamical modeling.\n\nQ5: We apologize for any confusion in our earlier explanation. After computing the spatial derivatives in Fourier space, we proceed to transform them back to real space using the Inverse Discrete Fourier Transform. This conversion is essential before feeding the data into the neural network for the computation of temporal gradients.\n\nQ6: In the training phase, we consider the temporal gradient error in the response to Q2. When evaluating testing data, our metric involves calculating the mean prediction error across all sampling points. The accumulation of prediction errors over time is illustrated in Figs. 3-5 of the main text and Figs. S1-S3 in the appendix.\n\nQ7: Our experimental results, detailed in both the main text and the appendix, highlight the superior long-term stability of our method compared to the classical NODE. This enhanced stability is primarily attributed to our approach of directly incorporating the gradient error across the entire data segment into the loss function. This inclusion significantly improves the numerical integration stability of the neural network.\n\nQ8: We sincerely appreciate your comment and have addressed the identified error.\u00a0\n\n```\nW2: It is unclear how the model performs over longer periods...\n```\n**Response**: Many thanks for your valuable comments. In fact, for complex systems, especially chaotic ones, almost all methods struggle to achieve long-term predictions. This is due to error accumulation through iterative predictions. Therefore, to assess various methods more effectively, appropriate extrapolation prediction times are set up for different systems.\n\n```\nW3: The baselines do not seem very competitive...\n```\n**Response**: Thanks for your instructive comment. In fact, our goal is to introduce a novel training strategy for NODE via flow matching, not to focus on achieving SOTA performances on various tasks compared with numerous baselines. Therefore, we employ the common baselines to validate the effectiveness of our approach. For further reasons, please refer to the Point 3 of the \"**General Response**\".\n\u00a0\nIn addition, the method from paper [1] does indeed perform well in the NS system, but it is not equipped to handle the parametric systems."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7598/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700314904699,
                "cdate": 1700314904699,
                "tmdate": 1700314904699,
                "mdate": 1700314904699,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "O7l4FH6zLL",
                "forum": "ytGU2iit80",
                "replyto": "sGn9J6ielN",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe hope this message finds you well! Thanks again for your valuable comments. We kindly remind you that the Author-Reviewer discussion is coming to an end and we would like to know if there are any remaining changes or questions you would like us to answer. We're more than happy to address these issues (before the rebuttal deadline). Otherwise, could you take this opportunity to re-evaluate our paper and update your score accordingly? Thanks!\n\nBest,\n\nAuthors"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7598/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700576093128,
                "cdate": 1700576093128,
                "tmdate": 1700576093128,
                "mdate": 1700576093128,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "6Y3j0CPeie",
                "forum": "ytGU2iit80",
                "replyto": "O7l4FH6zLL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7598/Reviewer_533P"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7598/Reviewer_533P"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for the response."
                    },
                    "comment": {
                        "value": "I want to thank the authors for the detailed response. After revision clarity has definitely improved. I still have reservations with regards to W2 and W3. In terms of W2, I agree that error accumulation is hard to handle, but it is extremely relevant for the method to be practically useful and precisely for this reason I would be more convinced to see where the proposed method stands with respect to the SOTA methods in this department. The arguments for W3 are also hard for me to buy in - since the authors are considering physics problem as the main selling point, NODE is not the most performant method and showing a strategy that improves upon that does not warrant significance in my opinion (i.e. one needs to show either an improvement on something NODE is SOTA or compare against SOTA for physics problems)."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7598/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700604246263,
                "cdate": 1700604246263,
                "tmdate": 1700604246263,
                "mdate": 1700604246263,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "RccatUrYbg",
            "forum": "ytGU2iit80",
            "replyto": "ytGU2iit80",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7598/Reviewer_PMhg"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7598/Reviewer_PMhg"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduced a way to improve the modeling of differential equations/dynamical systems with neural netwok. More precisely, it focuses on improving Neural Ordinary Differential Equation (Neural ODE), one of the popular frameworks in deep learning for dynamical systems in recent years. However, the training of Neural ODE is heavily computationally with the bottleneck in the backpropagation through nummerical ODE solver, and also often demonstrates undesired effects. To solve this, the authors of this work propose to incorporate Fourier analysis to approximate the ODE/PDE gradients, then use l2 loss to train this approximation with a parameterized neural network. The latter loss is taken from flow matching, a recent framework that shows promises in the generative modeling context. Evaluations on toy datasets show the gains in (decreased) training time and better MSE compared to Neural ODE."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "1 poor"
                },
                "strengths": {
                    "value": "The paper is in general based on solid theory and well-written."
                },
                "weaknesses": {
                    "value": "* I have concern about the novelty of this paper: it is rather a combination of the flow matching framework for functional/time series data, with the closed-form velocity approximated by discrete Fourier transform.\n* Since this leans on more methodological/empirical paper, I will comment more on the evaluation part. I do not think the authors have done a thorough literature survey. For example the related works/baselines comparison lack Physical Informed neural network [1], a rather popular framework that have performed some of the very similar tasks presented in the current paper. I am aware that for the modeling of time series/PDE. there are also score-based diffusion models that show competitive results, such as [2] and [3]. \n* To continue on the empirical evaluation, I do not understand why the authors did not include benchmarks on some of the realistic datasets, such as modeling time series. This is one of the main motivation of the paper, and I think stopping the evaluation at generated data in section 4.3 is inadequate.\n\n[1] Raissi, Maziar, Paris Perdikaris, and George E. Karniadakis. \"Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.\" Journal of Computational physics 378 (2019): 686-707.\n\n[2] Li, Y., Lu, X., Wang, Y., & Dou, D. (2022). Generative time series forecasting with diffusion, denoise, and disentanglement. Advances in Neural Information Processing Systems, 35, 23009-23022.\n\n[3] Apte, R., Nidhan, S., Ranade, R., & Pathak, J. (2023). Diffusion model based data generation for partial differential equations. arXiv preprint arXiv:2306.11075."
                },
                "questions": {
                    "value": "See weaknesses."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7598/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698757448152,
            "cdate": 1698757448152,
            "tmdate": 1699636920907,
            "mdate": 1699636920907,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "7wDtA0obdh",
                "forum": "ytGU2iit80",
                "replyto": "RccatUrYbg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We thank you for your valuable comments and helpful suggestions on the proposed framework. We kindly recommend that the reviewer reads the \"**General response**\" for a comprehensive overview of our main changes and clarifications. Regarding the individual comments, we carefully consider your suggestions and address all the concerns point by point as follows. We sincerely hope that the reviewer recognizes the efforts and improvements we have made, and reassess the novelty and contribution of our work.\n\n```\nW1: I have concern about the novelty of this paper: it is rather a combination of the flow matching framework for functional/time series data, with the closed-form velocity approximated by discrete Fourier transform.\n```\n**Response**: Thank you for your comment. It is important to highlight that our approach should not be simplistically regarded as a fitting of the closed-form velocity. In fact, there is no definite closed-form Fourier function for the systems with variable parameters. Our approach, rooted in the NODE framework, introduces a novel strategy for effective and robust dynamical system modeling. In our framework, we leverage both Fourier analysis and neural networks synergistically, matching the gradient flows from two distinct perspectives: spectral decomposition and dynamical modeling. This integrated approach enhances the robustness of dynamic modeling a statistical sense. Additionally, we conducted comprehensive experiments across diverse systems, demonstrating consistently satisfactory performance in modeling tasks. For a thorough exploration and clarification of the novelty and contribution of our method, please refer to Point 1 in the \"General Response\".\u00a0\n\n```\nW2: Since this leans on more methodological/empirical paper, I will comment more on the evaluation part. I do not think the authors have done a thorough literature survey...\n```\n**Response**: Thanks for your instructive comment. Indeed, there are numerous methods for modeling dynamical systems and predicting time series, each possessing distinct strengths and weaknesses in different application scenarios. In our work, our goal is to introduce a novel training strategy for NODE via flow matching, not to focus on achieving SOTA performances on various tasks compared with numerous baselines. Therefore, we employ the common baselines to validate the effectiveness of our proposed approach. For further reasons, please refer to the Point 3 of the \"**General Response**\".\n\nIn addition, we did not consider the methods requiring additional system information or deep learning methods that rely on extensive training data as baselines. For example, the PINN method [1] necessitates the incorporation of dynamical equations for the computing the loss function, rendering it incompatible with the data-driven modeling objectives in our study. Regarding the score-based diffusion models, we acknowledge that these models, as purely data-driven black-box models, can exhibit commendable performance in certain time-series prediction tasks. However, our hypothesis that the underlying systems can be modeled by differential equations with time-varying parameters, and the proposed method and baselines considered in this study are more suited to these characteristics. \n\nTherefore, our proposed framework can be viewed as grey-box models, demanding less training data than deep black-box models, while concurrently offering enhanced the interpretability of the underlying dynamics. \n\n```\nW3: To continue on the empirical evaluation, I do not understand why the authors did not include benchmarks on some of the realistic datasets...\n```\n\n**Response**: Thanks for your careful reading and instructive advice. In this work, we primarily focus on introducing a novel approach for efficient and robust dynamical system modeling. In line with many method-centric investigations, such as DeepONet, PDE-Net, and some extensions of NODE, we primarily conduct preliminary validation on synthetic dataset. To further substantiate the potential applicability of our method in real data, we conducted an additional experiment on a real-world system. Detailed information can be found in the Point 2 of the \"**General Response**\" and Appendix C.4."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7598/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700314887330,
                "cdate": 1700314887330,
                "tmdate": 1700314887330,
                "mdate": 1700314887330,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "KNAacQrUmN",
                "forum": "ytGU2iit80",
                "replyto": "RccatUrYbg",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7598/Reviewer_PMhg"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7598/Reviewer_PMhg"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your rebuttal."
                    },
                    "comment": {
                        "value": "While I appreciate the efforts of the authors for improving their works and delivering the rebuttals, I still have major concern regarding the weak baselines. I also see that other reviewers agree with me on this point, and therefore decide to keep my current evaluation."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7598/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700622006692,
                "cdate": 1700622006692,
                "tmdate": 1700622021052,
                "mdate": 1700622021052,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ueaxQ7ss1P",
            "forum": "ytGU2iit80",
            "replyto": "ytGU2iit80",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission7598/Reviewer_X9WB"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission7598/Reviewer_X9WB"
            ],
            "content": {
                "summary": {
                    "value": "The authors present a method that leverages flow matching loss for the learning of dynamical systems. Notably, the proposed algorithm does not require simulation, leading to a significant reduction in computational cost when modeling dynamical systems. The authors also introduce a novel augmentation strategy."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The paper is well-written.\n- The idea is simple and clear. It is supported by experimental results."
                },
                "weaknesses": {
                    "value": "- Examples in the experimental part are a bit synthetic."
                },
                "questions": {
                    "value": "1. Have you conducted an ablation study for the augmentation strategy?\n2. What was the reason behind introducing the control functions? Does it simply add to the complexity of potential tasks?\n3. Is the method applicable if the requirements in Theorem 1 are not satisfied? \n4. Have you tried to apply this algorithm to real-life time series that are sampled from an unknown equation?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission7598/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7598/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission7598/Reviewer_X9WB"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission7598/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698804999750,
            "cdate": 1698804999750,
            "tmdate": 1699636920648,
            "mdate": 1699636920648,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "UXUAvRTxUz",
                "forum": "ytGU2iit80",
                "replyto": "ueaxQ7ss1P",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission7598/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We would like to thank the reviewer for the overall positive feedback and helpful suggestions. We revised the paper carefully according to the reviewer\u2019s comments. Our major changes and clarifications are listed in \u201c**General response**\u201d.\n\n```\nQ1: Have you conducted an ablation study for the augmentation strategy?\n```\n**Response**:  Thank you for your comment. We have undertaken the ablation experiments as detailed in Section 4.3, and the comprehensive results are presented in Figure 5 of the main text. Notably, Figs. 5(b)-(e) demonstrate that the data augmentation training strategy significantly improves the modeling performance without requiring additional data samples. Furthermore, an ablation study on the newly incorporated real-world experiment has also been carried out, and further details can be found in Appendix C.4.\u00a0\n\n```\nQ2: What was the reason behind introducing the control functions? Does it simply add to the complexity of potential tasks?\n```\n**Response**:  Many thanks for your valuable comment. In practical applications, it is essential to acknowledge that the underlying systems commonly involve time-varying control (external) parameters. Investigating such systems not only enhances the complexity of modeling tasks but also brings the modeling process into closer alignment with real-world scenarios. Of course, our method can be naturally applied to systems without control parameters.\n\n```\nQ3: Is the method applicable if the requirements in Theorem 1 are not satisfied?\n```\n**Response**: Thank you for your insightful comments. Indeed, when Theorem 1 is satisfied, the gradient estimation from Fourier analysis can consistently converge to the system's actual gradient, thereby enhancing the learning of underlying system dynamics. It is noteworthy that our approach maintains effectiveness even in scenarios where Theorem 1 is not strictly met. For instance, many systems exhibit non-periodic behavior, and Fourier analysis, by default, assumes a periodic extension of the input discrete data. This can result in certain estimation errors at the boundaries. In practical implementation, we disregard the error at a small segment of the boundary. The remaining errors are then utilized as the loss function to update the parameters of the neural network, a process detailed in the accompanying code.\n\nFurthermore, as highlighted in the Point 1 of the \"**General Response**\", Fourier analysis and neural network complement each other by directly matching the gradient flows from two distinct perspectives: spectral decomposition and dynamical modeling. In a statistical context, despite potential systematic errors in gradient estimation, this combination allows for robust dynamical modeling. Additionally, our experiments indicate that our method delivers satisfactory performance in modeling tasks for systems that do not strictly adhere to Theorem 1.\n\n```\nQ4: Have you tried to apply this algorithm to real-life time series that are sampled from an unknown equation?\n```\n**Response**: Thanks for your careful reading and instructive advice. In this work, we primarily focus on introducing a novel approach for efficient and robust dynamical system modeling. Aligning with numerous method-centric investigations, such as DeepONet, PDE-Net, and various extensions of NODE, we primarily conduct preliminary validation on synthetic data. To further substantiate the potential applicability of our method, we conducted an empirical experiment on a real-world system. Detailed information can be found in the Point 2 of the \"General Response\" and Appendix C.4."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission7598/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700314873699,
                "cdate": 1700314873699,
                "tmdate": 1700314873699,
                "mdate": 1700314873699,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]