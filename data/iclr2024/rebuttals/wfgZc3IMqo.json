[
    {
        "title": "Robust Classification via Regression-Based Loss Reweighting and Label Correction"
    },
    {
        "review": {
            "id": "sHsp83idlY",
            "forum": "wfgZc3IMqo",
            "replyto": "wfgZc3IMqo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9158/Reviewer_prcP"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9158/Reviewer_prcP"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes an approach for the task of classification with noisy labeled training data. \nThe proposed method first uses a bijective function $f$ to map the discrete labels into a continuous label space. \nWith continuous labels, the method can be naturally formulated as a regression problem, the loss reweighting and label correction techniques are used for the regression task to uncover the true continuous label. \nLastly, the inverse of bijective function $f$ is used to transform the predicted true label to true discrete label.\nEmpirical experiments are conducted to show the effectiveness of the proposed method in comparison to existing approaches."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The paper's presentation of the proposed method is straightforward and easy to follow.\n\n- The empirical experiments are relatively comprehensive."
                },
                "weaknesses": {
                    "value": "- The primary limitation of the paper is the absence of a clear rationale behind the decision to transform the classification problem into a regression problem. The paper would significantly benefit from a more in-depth analysis of why this transformation is considered a \"better\" approach for handling noisy labels. Currently, the proposed method appears to be a compilation of established techniques, and addressing this aspect could enhance the quality and impact of the paper.\n\n- The reviewer has a general impression that some key details are missing in the description of the method and the experiments, the reviewer will point them out below.\n\n- Method description\n    - P4: The use of an equal weight vector $u$ in (4) for label smoothing should be clarified. What would be the effect of using a vector of all 1s scaled by other factors? Is this equivalent to adjust $\\gamma\"? The authors are encouraged to provide further clarification on this matter.\n    \n    - P4: Regarding loss reweighting via a Gaussian noise model, there may be a computational challenge with evaluating the density function of a multivariate normal due to the inversion of covariance matrices, especially in high-dimensional cases. It appears that the matrix inversion lemma might have been employed as a workaround. Can the authors please confirm and elaborate on this technique? Additionally, it is not entirely clear how $\\mu_{\\theta}$ and $r_{\\theta}$ correspond to the output of the neural network. Are they concatenated as a long vector, or are they separate outputs with distinct final linear layers?\n\n- Experiments:\n    - In Table 1, it is unclear why the symmetric and asymmetric noise rates are different. Moreover, it does not make sense to the reviewer that a noise rate is more than 50%, please clarify. \n\n    - While Table 1 presents interesting results, there remains a degree of skepticism regarding its persuasiveness. As the authors pointed out that \"SGN significantly outperforms CE when there is no added label noise.\" This prompts a reasonable inquiry into whether the relatively good performance of the proposed method is contingent on the suboptimal performance of the baselines. The authors posit that the EMA framework may contribute to this observed improvement. Consequently, the reviewer suggests conducting an additional experiment similar to the one presented in Table 4 under a noise-free setting to validate this conjecture and bolster the credibility of the results. Such an addition would further fortify the paper's empirical foundation.\n\n    - The description of the experiments could benefit from more clarity. While the reviewer understands there is a space limit for conference paper, providing essential details in the appendix, especially for a paper predominantly reliant on empirical results, is advisable. For instance:\n    \n        - A brief overview of the datasets would greatly assist readers who are new to the field of noisy label classification.\n        \n        - The authors should point out aggregate, random, worst corresponding to three sets of noisy labels in Table 2. Otherwise, the table is difficult to understand for people who does not know the dataset well.\n\n- Minor issues:\n    - P2: The last two sentences in the \"compositional data\" paragraph lack clarity regarding what \"several problems\" and \"this problem\" refer to.\n    - P2: The final sentence in the \"transforms\" paragraph could be more informative. Instead of stating that \"several solutions exist,\" the authors could refer to the specific technique employed later in the paper for a more insightful description.\n    - The expression in (2) on P3 is statistically incorrect. The conditional distribution of the transformed continuous label given features is a normal distribution rather than the mariginal distribution of the label itself.\n    - P5: The first sentence \"we describe our experimental setup of our experiments\" in Section 4, appears redundant.\n    - The LaTeX formatting for quotes, as exemplified by \"worst\" on P7, may require adjustment."
                },
                "questions": {
                    "value": "Please refer to the questions in the previous section."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9158/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1697620821056,
            "cdate": 1697620821056,
            "tmdate": 1699637152815,
            "mdate": 1699637152815,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "qZLPAf3EAv",
                "forum": "wfgZc3IMqo",
                "replyto": "sHsp83idlY",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback. [1/2]"
                    },
                    "comment": {
                        "value": "Thank you for the time and effort you put into the detailed review of our work. Our goal with this work is to introduce an adaptation of the well-founded log-ratio transform approach to the classification with noisy labels literature, and show the promise of the direction by devising a method unifying the ideas of loss reweighting and label correction from classification. We are glad you found the explanation of our method to be straightforward and easy to follow.\n\n**Rationale for transforming classification to regression**\n\nWe agree that the motivation for transforming classification to regression could be improved, which is why we have now provided a detailed discussion on this in Section A.7. We do not claim this view by default is a \u201cbetter\u201d approach for handling noisy labels in classification. However, we do claim the regression view that our adapted log-ratio transform approach provides, opens up a new research direction to leverage sound and time-tested methods from the (robust) regression literature. Please also see the \u201cClarification on our contributions and novelty\u201d paragraph in the response to Reviewer U8oG.\n\n**Clarification of label smoothing**\n\nAs the log-ratio transform is only defined for categorical distributions inside the probability simplex (no component can be zero), we need a way to transform class IDs from classification to the interior probability simplex. We achieve this by using the simple and common regularization technique called label smoothing [1], and we provide the original definition in Equation 4 (see Section 7 in the original paper). The idea is to smooth the original one-hot encoded version of the label by interpolating it with the uniform distribution over K classes (all components equal to 1/K).\n\nThe reviewer wants a clarification if it is possible to replace the uniform distribution with a vector of ones scaled by other factors than 1/K. An important property that is exploited in label smoothing is that interpolating two categorical distributions is another categorical distribution, for interpolation weights in $\\[0,1\\]$. So to clarify if we can use other scale factors, the answer is in general no, as a vector of ones can only be scaled by 1/K to be a valid categorical distribution (sum of components are one). However, it is possible to generalize label smoothing by replacing the uniform distribution with any other categorical distribution. For our purposes, the uniform distribution is a good choice though, as we require the interpolated distribution to have non-zero probability in all components and, a priori, we have no way of justifying putting more probability in any particular class.\n\n**Efficient evaluation of loss function**\n\nThe reviewer brings up an interesting question about how the negative log-likelihood of the Gaussian distribution can be efficiently evaluated. In short, to evaluate the loss function, inverses, and determinants of the covariance/scale matrices have to be calculated, which for general matrices are computationally heavy. Indeed, the parameterization we use makes inverse and determinant computations efficient through the Woodbury matrix identity, and the matrix determinant lemma, respectively. This is a common parameterization for the covariance/scale matrix of Gaussian distributions, that is implemented in probabilistic frameworks such as Tensorflow Probability. We agree that a motivation for the particular covariance/scale matrix parameterization was missing, which we have now added to Section A.1.\n\nRegarding $\\mu_\\theta$ and $r_\\theta$, we use a standard neural network (WideResNet 28-2, ResNet 50, or InceptionResNetV2) and replace the last linear layer with two linear layers (heads), one for predicting $\\mu$ and one for predicting the rank-one factor $r$ of the scale matrix."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700178135816,
                "cdate": 1700178135816,
                "tmdate": 1700178135816,
                "mdate": 1700178135816,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gXCep4gvWm",
                "forum": "wfgZc3IMqo",
                "replyto": "pL0CmJk6lJ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_prcP"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_prcP"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you for the rebuttal, most of my concerns are addressed. However, I would like to highlight that my comments regarding the necessity for a clearer description of some key components within the manuscript have not been addressed in the revised version. I am considering increasing my rating to 6, contingent upon the satisfactory resolution of the aforementioned concerns in the manuscript's writing."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700624686287,
                "cdate": 1700624686287,
                "tmdate": 1700624686287,
                "mdate": 1700624686287,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "Lq5YWDgOuz",
            "forum": "wfgZc3IMqo",
            "replyto": "wfgZc3IMqo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9158/Reviewer_U8oG"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9158/Reviewer_U8oG"
            ],
            "content": {
                "summary": {
                    "value": "To address overfitting to label noise, this paper proposes to combine two popular methods together, namely loss reweighting and label correction. Specifically, the approach firstly uses isometric log-ratio transform to convert a classification task to a regression task, which is then solved with a shifted Gaussian Noise Model. The loss reweighting is achieved when learning sigma in the Gaussian Noise Model, and the label correction is implemented by adding a shift to the noise model to make up the difference between the noise target and the correct label. Experiments show that the proposed method outperform previous baselines and related works on both synthetically and naturally noisy datasets."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. It is interesting and meaningful to use a (shifted) Gaussian Noise Model to achieve loss reweighting and label correction at the same time, which is very different from previous methods, where the two tasks are considered separately.\n2. The experiments show the effectiveness of the method on both CIFAR-10 and CIFAR-100 with both synthetic noise and natural noise."
                },
                "weaknesses": {
                    "value": "1. The contribution is limited or needs refinement. To me, the log-ratio transformation, the Gaussian Noise Model for loss reweighting, and the estimation of the shift are all previous works. The authors should be more explicit on the novelty and contributions.\n2. The reason for the choice of the orthonormal basis for the Isometric Log-Ratio Transform is absent. The authors should explain why choosing the Helmert matrix as the basis, and better for analyzing the influence or conducting comparative experiments with different basis.\n3. The experiment results on Clothing1M and WebVision dataset with natural noise seem to fail compared with NAL, which though with a different evaluation setup, as Tabel 3 shows.\n4. As Figure 2 shows, it takes around 400 epochs for the model to converge. However, figure 2 just depicts the train accuracy, and there can be a potential overfitting problem that the authors should consider."
                },
                "questions": {
                    "value": "1. It is not very clear to me that \"The authors propose to have a two-layer neural network with parameters \u03b8 to output \\mu and \\sigma per example\" in 3.3. How is the two-layer network trained and how does it work?\n2. The method converts the classification task to a regression task using isometric log-ratio transformation. When optimizing, the gradient is computed in the transformed space instead of the origin space. Under this condition, is the optimization still consistent with usual methods where no such transformation is used?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9158/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698469076691,
            "cdate": 1698469076691,
            "tmdate": 1699637152697,
            "mdate": 1699637152697,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "PHUAkpbK0a",
                "forum": "wfgZc3IMqo",
                "replyto": "Lq5YWDgOuz",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback. [1/3]"
                    },
                    "comment": {
                        "value": "We would like to thank you for your time and energy in reviewing our work. In this work, we introduce an adaptation of the well-founded log-ratio transform approach to the literature on classification with noisy labels, and show the promise of the direction by devising a method unifying the ideas of loss reweighting and label correction. We are glad you found this approach interesting, meaningful, and novel. Furthermore, we are glad the reviewer recognizes the effectiveness of our simple method on synthetic and natural noise.\n\n**Clarification on our contributions and novelty**\n\nThanks for giving us the opportunity to more explicitly describe the novelty and contributions of our work. As the reviewer mentions, our use of a shifted Gaussian noise model for unified loss reweighting and label correction is interesting, meaningful and very different from previous methods. This is a novel contribution, despite building on existing notions such as the log-ratio transform and Gaussian noise models. All novel methods build upon existing mathematical notions.\n\nWe introduce and adapt the well-founded log-ratio transform to the modern problem of noisy labels in classification. Our approach makes it possible to view classification as regression, opening up a new research direction to leverage sound and time-tested methods from the (robust) regression literature that spans centuries. One of our contributions is to open up this research direction that we believe has immense potential, as we discuss in the added section in Section A.7. To the best of our knowledge, this is the first time the log-ratio transform has been used for this purpose.\n\nFurthermore, we propose a specific method in this adapted log-ratio transform approach, which is a combination of the ilr transform with a shifted Gaussian noise model, that achieves loss reweighting and label correction in a single simple and unified approach. To the best of our knowledge, this is the first unified method for loss reweighting and label correction for label noise robustness in classification. In Section A.6 (referenced in the baselines paragraph in Section 4.2), we described, in detail, the connections to the most related works. As Reviewer QVE6 found this discussion interesting and valuable for understanding our method in the context of related work, we believe you will too. The closest work to the log-ratio transform approach we could find is the recent work on the loss reweighting using the Logistic-Normal (LN) distribution, which is a distribution over categorical distributions, similar to the Dirichlet distribution. We discuss LN in Section A.6, and even have it as a baseline. In short, LN can be seen as a special case of the more general log-ratio transform approach, corresponding to a particular transform (alr) and a Gaussian likelihood (zero-mean). In contrast, our adapted log-ratio transform approach, makes it possible to use any log-ratio transform (e.g., the ilr transform that does not suffer from the asymmetry issues of the alr transform), and also incorporate any regression technique, e.g., a shifted Gaussian noise model as in SGN, or Gaussian Processes, Student-T distributions, etc. Hence, in addition to the novelty of the adapted log-ratio transform, we propose the SGN method corresponding to the ilr transform and the shifted Gaussian noise model. Furthermore, we theoretically link the shift to changing the label, and propose to exploit this to achieve effects similar to the label correction methods from classification. To the best of our knowledge, this connection between the shift in the Gaussian noise and label correction is novel and one of our contributions. \n\nAnother contribution is the practical algorithm for estimating the shift that differs from common label correction methods in classification that use buffers (e.g., ELR, SOP, NAL). In our work, we take a different approach, instead of using buffers, we use EMA networks to directly predict the labels/$\\Delta$. Due to the memory requirements, we believe buffers do not scale to large datasets and or large number of classes, while our approach of using EMA networks do. Another limitation with the use of buffers is the storing of a single estimated label per example. This poses challenges, e.g., when using strong augmentation strategies. For example, with CutOut, there is a risk that a crucial part of the image is removed, leading to an unreliable prediction that still affects the estimate of the true label in the buffer. Similarly, the widely-used mixup technique encourages the prediction to have confidence in both of the mixed classes, potentially adding confidence in the wrong class, but the prediction still affects the buffer estimate for the example. This is not an issue of our approach, as the EMA network predicts labels for each augmented input separately. Furthermore, the buffers are useless at test time, whereas EMA networks can generalize significantly better than the original network."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700177806303,
                "cdate": 1700177806303,
                "tmdate": 1700177806303,
                "mdate": 1700177806303,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "TibitBFieB",
            "forum": "wfgZc3IMqo",
            "replyto": "wfgZc3IMqo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9158/Reviewer_h549"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9158/Reviewer_h549"
            ],
            "content": {
                "summary": {
                    "value": "This paper first uses log-ratio transformation to convert the classification data set into a regression data set. It treats the regression target as a Gaussian distribution with noise, learns the mean and variance of the Gaussian distribution, and then indirectly weights the loss through the variance. Secondly, this paper gives the above noise a shift and treats the regression target as a Gaussian distribution with offset (non-zero mean) noise to estimate the shift. This method indirectly corrects the labels when converting the regression task into a classification task.\n\nThe contributions of this paper include:\n(1) It turns loss reweighting and label correction into a unified method instead of being two independent processes.\n(2) It uses statistics and regression perspectives to look at the label noise problem in classification tasks, which is relatively novel."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- The perspective of the paper is novel, using a regression perspective to perform classification tasks. The unified process of loss reweighting and label correction can also be understood as modeling noise.\n- The experiments in the paper are relatively sufficient."
                },
                "weaknesses": {
                    "value": "- The experimental results is lower than SOTA performance, e.g., DivideMix, ELR, etc.\n- There exist some unified methods that combines loss reweighting and label correction to enhance robustness against label noise, e.g., CMW-Net [1]. \n-  What's merit of the regression task. Some strong results and theoretical explanations are necessary.\n-  The hyperparameter $\\alpha$ is sensitive in Fig.2(c).\n\n[1] Shu J, Yuan X, Meng D, et al. Cmw-net: Learning a class-aware sample weighting mapping for robust deep learning[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023."
                },
                "questions": {
                    "value": "- $\\sigma^2$ of formula 6 should be written as $\\sigma_\\theta^2$.\n- What are the advantages of using regression to solve classification tasks rather than directly solving classification tasks? Would it be too cumbersome to convert the classification problem into a regression problem, and then convert the regression problem into a classification problem?\n- The previous methods regard loss reweighting and label correction as two independent processes. So what is the advantage of treating them as a unified method in this paper?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9158/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9158/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9158/Reviewer_h549"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9158/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698678910720,
            "cdate": 1698678910720,
            "tmdate": 1700577050468,
            "mdate": 1700577050468,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "H6xliybHrm",
                "forum": "wfgZc3IMqo",
                "replyto": "TibitBFieB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback. [1/3]"
                    },
                    "comment": {
                        "value": "We greatly appreciate your time and effort in reviewing our work. We are glad you find our approach of using regression to solve classification tasks to be novel. We are happy the reviewer recognizes that our proposed shifted Gaussian noise model directly leads to a unified method for loss reweighting and label correction, and that the experiments are deemed relatively sufficient. Thanks again, and next we address your concerns and questions.\n\n**State-of-the-art Performance**\n\nOur goal with this work is to introduce an adaptation of the well-founded log-ratio transform approach to the classification with noisy labels literature, and show the promise of the direction by devising a method unifying the ideas of loss reweighting and label correction from classification. Despite its simple design, our method empirically performs well against many strong and recent baselines, such as GCE, ELR, SOP, NAL, etc. The reviewer claims a weakness of our paper is that our method has lower performance compared to SOTA methods, and gives the example of DivideMix and ELR. In fact, we do compare with ELR, and our method achieves as good or better performance on CIFAR-10 and CIFAR-100 with synthetic noise, and on natural noise on the CIFAR-N datasets, Clothing1M, and WebVision, see Tables 1, 2, and 3.\n\nWe believe comparing SGN with DivideMix is unfair as it is a significantly more complex method as it combines ideas from sample selection GMMs to identify noisy labels (e.g., [1]), with a semi-supervised learning method [2], with co-training of two networks at the same time (e.g., [3]), and also use stronger data augmentation like mixup. Please see the \u201cRationale for chosen baselines\u201d paragraph in the response to Reviewer QVE6 for a longer discussion.\n\nWe believe achieving strong performance is one important point of comparison, but does not take into account other possible empirical/practical advantages. Although DivideMix achieves excellent empirical performance, which is incredibly important for practitioners, we argue it is hard to fully understand due to all the different components. Our method is simpler in that it follows directly from a Gaussian noise model, leading to an interpretable robustness mechanism in terms of loss reweighting and label correction. Furthermore, DivideMIx was specifically created to be excellent at this particular task, but due to its complexity we believe it can be hard to extend/generalize to other problems. We believe our well-founded probabilistic method is easier to extend, e.g., it can naturally incorporate epistemic uncertainty (e.g., through Monte-Carlo Dropout [4] or Gaussian Processes [5]), making it interesting to both the noisy labels and the uncertainty communities.\n\nFinally, we would like to point out that the reviewing guidelines (https://iclr.cc/Conferences/2024/ReviewerGuide) are clear that a lack of state-of-the-art results does not by itself constitute grounds for rejection, see the FAQ.\n\n**Missing related work**\n\nWe performed a thorough literature study to select relevant baselines from the loss reweighting and or label correction categories of methods from top conferences and journals. Unfortunately, we missed this very recent work proposing the meta-learning based CMW-Net method.\n \nCMW-Net is motivated in the context of the exciting research direction into learning loss weights using meta learning. Based on the title, abstract, introduction, and most of the method section, the main novelty seems to extend the meta-learned weight network of MW-Net [6] to also consider extra (task/class) information, leading to more flexibility in learning weighting schemes. However, in the last subsection of the method section (Section 3.6), CMW-Net is enhanced with label correction (denoted CMW-Net-SL). Instead of learning a loss weight, the CMW-Net now learns an interpolation parameter between the original one-hot label and a soft label estimate (Equation 14 can be rewritten to the form in Equation 13, in the same way as Equation 12 was), and the new interpolated label is then used in a standard CE loss (no loss reweighting). Therefore, although the proposed approaches are interesting and novel, we argue neither CMW-Net (loss reweighting) nor CMW-Net-SL (label correction) unifies loss reweighting and label correction. In future work, it would be interesting to explore ideas from CWM-Net-SL to learn $\\Delta$ in SGN. Thank you for bringing our attention to this recent related work, which we will describe and reference as there are clear connections."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700176431935,
                "cdate": 1700176431935,
                "tmdate": 1700176431935,
                "mdate": 1700176431935,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "8TziIFevvg",
                "forum": "wfgZc3IMqo",
                "replyto": "0cEkPFOX4i",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_h549"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_h549"
                ],
                "content": {
                    "title": {
                        "value": "The concerns are addressed"
                    },
                    "comment": {
                        "value": "Thanks for your detailed response, most of them has addressed the concerns. A confused point is the insight of label correction. The label correction of CMW-Net-SL seems promising. Previous works can be special cases of label correction of CMW-Net-SL."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700555896752,
                "cdate": 1700555896752,
                "tmdate": 1700555896752,
                "mdate": 1700555896752,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "0ZtpPKImqa",
                "forum": "wfgZc3IMqo",
                "replyto": "4KVnyOarVj",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_h549"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_h549"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for your detailed and timely response!"
                    },
                    "comment": {
                        "value": "All concerns are addressed. I tend to accept this manuscript. I think this manuscript will bring some novel understanding of robust classification."
                    }
                },
                "number": 17,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700576954739,
                "cdate": 1700576954739,
                "tmdate": 1700576954739,
                "mdate": 1700576954739,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fYNkPapkML",
            "forum": "wfgZc3IMqo",
            "replyto": "wfgZc3IMqo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9158/Reviewer_QVE6"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9158/Reviewer_QVE6"
            ],
            "content": {
                "summary": {
                    "value": "The paper presented a method adapted from log-ratio transform approach from compositional data analysis for classification with label noise. The method can be viewed as a combination of two widely studied categories of approaches in the field: loss reweighting and label correction. The authors performed extensive experiments and achieved competitive performance across several synthetic and real-world datasets."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed method is a refreshing adaptation of a well-founded statistical technique (log-ratio transform) in a modern research problem in machine learning (classification with label noise). It should inspire a new line of work to the research area while adding a competitive baseline to other future work. The writing is well done and very easy to follow. The contribution is clearly presented and justified by drawing comparison to related work."
                },
                "weaknesses": {
                    "value": "My main criticism is on the paper is in its experimental setup and results. First of all, I absolutely do not believe a paper deserves to be published only if it achieves SOTA results. But unless I missed something important (e.g., did the authors reimplement the method and rerun the numbers perhaps?) it seems that the selected baselines to report in the paper are a very biased set in an attempt to make the method look SOTA. More details in the Questions section below."
                },
                "questions": {
                    "value": "#### Major comments:\n\nThe proposed method appears in most result tables as the best-performing method. However, a closer look raises a few questions regarding selection bias in the reported baselines. Taking ELR (Liu 2020) as an example (as I did not go through all the baselines).\n(a) At 60% symmetric noise in CIFAR10, Table 1 in the original ELR paper reports 86.12% mean accuracy while Table 1 in the current paper 81.87% which is significantly lower than the original authors' numbers.\n(b) The original ELR paper proposes a variant with a few add-ons, ELR+, which can outperform ELR but the current authors did not include. Admittedly such tricks should not be the main contribution of the ELR, but the reported SGN in the current paper also employed a few tricks (e.g., EMA) to improve upon its vanilla version. According to Table 5 of the original ELR paper, by adding some form of weight averaging alone, ELR's vanilla performance can be boosted by a few percentage points too.\n(c) There are many other baselines in learning with label noise, such as DivideMix, which can achieve much higher accuracy. For reasons that are not disclosed, such methods are simply not included in the current paper. If comparison to these methods do not make sense or is unfair, disclosing the rationale behind why some methods are selected over others as baselines in the paper still makes sense to me.\n\n#### Minor comments:\n\nAppendix A.6 is a very interesting discussion and adds a lot of value to the understanding of the method in the context of related works. I'd argue that it should be moved to the main text, while some results/tables can be moved to appendix."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9158/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698690885103,
            "cdate": 1698690885103,
            "tmdate": 1699637152461,
            "mdate": 1699637152461,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "Qf3IyCECeu",
                "forum": "wfgZc3IMqo",
                "replyto": "fYNkPapkML",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Thank you for your feedback. [1/2]"
                    },
                    "comment": {
                        "value": "Thank you for dedicating your time and effort to review our work. We appreciate your thoughtful feedback and the recognition of our approach as a fresh adaptation of the well-established log-ratio transform approach, applied innovatively to classification with label noise. As we carefully wrote our paper, we greatly appreciate the positive comments on our paper being well-written and easy to follow. We are excited that you believe our work should inspire new research directions in the area of label noise robustness in classification. Once again, thank you for your time and support. Next, we address your concerns, questions, and suggestions.\n\n**Training and Evaluation Setup**\n\nIndeed, to have fair and conclusive experiments, we _reimplement all baseline methods_ into a shared code base where we have full control over the training and evaluation setup. This is mentioned in the first sentence in Section 4.1 and in the captions of Tables 1 & 2, but unfortunately the reviewer missed this. We have gone to great lengths to achieve the best possible results for the baselines. For example, in the literature, it is common to directly use the optimal hyperparameters reported in the baselines\u2019 original papers. Instead, for our method and all baselines, we do a method-specific hyperparameter search (that includes the reported optimal HP) to find what works best in our training setup. Furthermore, to have conclusive results, we report the mean and standard deviation of five runs with different random seeds, and do statistical significance tests when comparing results. Due to the shared code base, all methods are equally affected by the random seed, leading to using the same weight initialization, data order in SGD, data augmentation, synthetic noisy labels, etc. \n\nAlthough we believe this setup leads to fair and conclusive results, training and evaluating all these methods require a lot of computational resources, which leads us to limit our studies to a smaller WideResNet 28-2 on the CIFAR datasets. As all methods use this network, our results are still fair and conclusive, but at the expense of a higher test error. Achieving excellent empirical performance is important for practitioners, but this was not the goal in this work. Our goal is to develop a simple well-founded statistical method that is still easy to implement, understand, extend, debug, and use in practice, and to compare this with existing related methods in an as fair and conclusive way as possible.\n\n**Rationale for chosen baselines**\n\nWe agree that justifying the choice of baselines is important, we will add discussion similar to the one below to the final submission. Thanks for letting us clarify our rationale for choosing baselines.\n\n_Methods that build on similar ideas._ We have tried our hardest to find relevant and recent baselines that are related to loss reweighting and label correction from top conferences and journals. For example, in Section A.6, we argue there are clear connections between our work and methods like ELR, SOP, LN, and NAL, that can either be seen as loss reweighting and or label correction methods. We argue this is the most important comparison, as we see how our method currently compares with the methods that have taken a similar approach.\n\n_Other noisy labels methods._ Furthermore, we compare with many strong and commonly used baselines outside the loss reweighting and label correction categories, e.g., GCE from the robust loss functions category, and LS and NAN from the regularizations methods. This is informative to understand how our categories currently compare in terms of performance to other categories of algorithms to improve robustness against label noise. In our view, performing worse than baselines from other categories is not necessarily negative, as the research is in different stages of development, and categories of methods performing poorly today could achieve SOTA performance in the future. Therefore, these comparisons are intended for laying out context, and we believe it is important to consider and spread a diverse set of ideas and not limit the research field to what currently achieves the best performance. \n\n_SOTA methods._ Our goal in this work is to adapt the well-founded log-ratio transform approach to classification and apply it to the problem of label noise robustness by proposing a simple and unified method for loss reweighting and label correction. If our goal instead had been to achieve the current SOTA performance (a different but also important goal), we would have taken a different empirical direction. In general, the current SOTA methods are complex and compute-intensive that typically combine several methods. For example, in our training setup, our method has comparable training time to ELR, while ELR is twice and five times faster to train compared to ELR+ and DivideMix (Table I.1 in the appendix of the ELR paper), respectively."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700176030263,
                "cdate": 1700176030263,
                "tmdate": 1700176030263,
                "mdate": 1700176030263,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4y5zW2ut07",
                "forum": "wfgZc3IMqo",
                "replyto": "kG5c7dl7S6",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_QVE6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_QVE6"
                ],
                "content": {
                    "title": {
                        "value": "Thanks for the detailed rebuttal."
                    },
                    "comment": {
                        "value": "Thank you for the detailed rebuttal. I do think that most of my concerns are addressed, however I'd like to offer just a few paragraphs to the discussion.\n\n**Re-implementation of other baselines**\n\nI did notice the reimplementation remark in Sec 4.1 but it is hard to grasp the nuanced differences (e.g., how close the re-implementation matches the original implementation) since it is practically _almost_ impossible to re-implement any other paper. This could add to the impression of a _conflict of interests_ when the current paper proposes a competing method and the baseline numbers in the current paper appear to be _somewhat consistently_ lower than those in the original papers. Having said that, I do think it is incredible that the authors re-implemented the other baselines in a single codebase for as conclusive a comparison as possible. I do hope that the codebase will be published if the paper gets accepted. I also hope our discussion about this can help any future reader clear some of their doubts, if they may fall under the same impression as I did.\n\n**Training tricks/add-ons**\n\nLet me try to rephrase where my concerns lie.\n\n1. Since the paper is IMHO a practical adoption of well-established statistical techniques, an interested reader may wonder why they should use SGN and not other SOTA. So I agree with the authors that a comparison without any add-ons is crucial, but I do not think it is as clear as the current form of comparison. For instance, the authors had EMA as part of SGN natively, but not part of vanilla ELR due to the fundamental difference in their methodological design. If we know EMA alone can boost ELR by a substantial margin, one may wonder how much the claimed improvement of SGN is due to the EMA part of SGN, despite it is an inherent part of SGN. I do not think it is necessary the authors do such additional experiments, but just to lay out some counter arguments.\n\n2. I do believe that keeping a few ablations with add-ons are also important. It is not a showcase of how many add-ons one can find or how those powerful add-ons are standalone. But it helps the readers understand how much improvement they can expect to push if they would like to adopt the proposed method in practice, as well as how extendable the current work is (with codebase released). It also offers a more SOTA comparison since many other papers employ different sets of add-ons to boost the performance."
                    }
                },
                "number": 14,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700564539307,
                "cdate": 1700564539307,
                "tmdate": 1700564539307,
                "mdate": 1700564539307,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "5fgWRbXlu0",
                "forum": "wfgZc3IMqo",
                "replyto": "c4N4wJDhBe",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_QVE6"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission9158/Reviewer_QVE6"
                ],
                "content": {
                    "title": {
                        "value": "Question"
                    },
                    "comment": {
                        "value": "Why are top-5 accuracy lower with mixup than without for both datasets? Do the authors have an intuition?"
                    }
                },
                "number": 15,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission9158/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700564669168,
                "cdate": 1700564669168,
                "tmdate": 1700564669168,
                "mdate": 1700564669168,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]