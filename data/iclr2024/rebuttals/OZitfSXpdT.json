[
    {
        "title": "Less or More From Teacher: Exploiting Trilateral Geometry For Knowledge Distillation"
    },
    {
        "review": {
            "id": "5CJ2Mv7qVL",
            "forum": "OZitfSXpdT",
            "replyto": "OZitfSXpdT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission288/Reviewer_aFDp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission288/Reviewer_aFDp"
            ],
            "content": {
                "summary": {
                    "value": "In this paper, the authors propose an adaptive method for learning a sample-wise knowledge fusion ratio. Specifically, the proposed method captures intra-sample and inter-sample trilateral geometric relations among the student prediction, teacher prediction, and ground truth. A simple network further learns the implicit mapping from the intra- and inter-sample relations to the fusion ratios in a bilevel-optimization manner. The proposed method is validated on three various tasks: image classification on CIFAR-100 and ImageNet, attack detection on HIL, and CTR prediction on Criteo."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1.\tThe paper is well motivated by clearly illustrating the valuable insights of incorporating additional ST prediction discrepancy for determining the fusion ratio.  \n2.\tAlthough KD methods have been widely studied, the investigation of the knowledge learning potential on different samples has received less attention. With the learned sample-wise fusion ratio, this paper showcases that the student and teacher can provide specific knowledge learning potential for each sample based on the ST prediction discrepancy and the teacher\u2019s correctness. \n3.\tThis paper proposes a novel and interesting method to capture relations among the student prediction, teacher prediction, and ground truth by exploiting their trilateral geometry at both intra- and inter-sample levels. \n4.\tThe experiments and analysis on three different tasks are comprehensive and demonstrate the effectiveness of the proposed method. \n5.\tThe paper is well written and easy to follow."
                },
                "weaknesses": {
                    "value": "The paper is overall readable and proposes an innovative idea. However, there are some weaknesses that the authors can improve. \n\n1.\tThe experimental results show improved performance on the HIL and Criteo datasets. However, the paper does not clarify if this is due to the adopted sampling method. The oversampling of the minority class as a preprocessing step is mentioned, but its direct influence is not explored.\n\n2.\tIn Section 4.3, this paper analyzes the effectiveness of incorporating ST by comparing the learned fusion ratio distributions across four scenarios. With ST, the proposed TGeo-KD reduces the fusion ratio on L_kd, thereby encouraging the student to acquire more knowledge from ground truths when the teacher predictions are incorrect on samples (e.g., outliers). However, more experiments should be conducted to investigate that the exploitation of inter-sample relations on these incorrectly predicted samples does not contribute significantly to decreased fusion ratios. \n\n3.\tThe fusion ratio is learned through a neural network, which is unclear to explain how the learning process unfolds, such as which samples are assigned larger/smaller fusion ratios."
                },
                "questions": {
                    "value": "1.\tWhy do the authors choose to model the relation in Euclidean space? \n2.\tGiven that this paper proposes an adaptive learning method for sample-wise fusion ratio, does the proposed method demonstrate consistent performance across different numbers and categories of samples?\n3.\tIs there a specific reason to formulate this work into bilevel optimization? Will it lead to less efficient training? The motivation is note quite clear to me."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission288/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission288/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission288/Reviewer_aFDp"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission288/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698401168979,
            "cdate": 1698401168979,
            "tmdate": 1700665617776,
            "mdate": 1700665617776,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "NYiRYCmj2f",
                "forum": "OZitfSXpdT",
                "replyto": "5CJ2Mv7qVL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your time and feedback. We would also appreciate your agreement on the novelty, effectiveness, robustness, and adaptability of our method. Our reply to your questions is as follows.\n\n**Q1: Impact of oversampling on the performance.**\n\n**A1:** We employ oversampling when the dataset is imbalanced, which is a widely accepted practice in the research community, especially for classification tasks. To analyze the impact of oversampling on performance, we compare our TGeo-KD with five other baselines across varying imbalance ratios on the HIL and Criteo datasets. The imbalance ratio $\\rho$ is defined as the proportion between the sample sizes of the most prevalent class and the least prevalent class, where $\\rho=1$ represents a balanced setting. As shown in the tables below (Table 11 in the manuscript), we calculate the average classification accuracy (with standard deviation) over 5 repeated runs. TGeo-KD consistently outperforms all the baselines (e.g., the improved accuracy of 2.24% and 3.15% over the best baseline ADA-KD with $\\rho=1$ and without oversampling on HIL dataset, respectively), which underscores the robustness of our TGeo-KD on imbalanced datasets. We have also provided the results in Appendix A.4 of the manuscript.\n\n*Table: Top-1 ACC on HIL.*\n|Method|$\\rho=1$|$\\rho=5$ |w/o oversampling|\n|:-:|:-:|:-:|:-:|\n|Vanilla KD|87.55\u00b10.56|81.72\u00b10.66|72.07\u00b10.71|\n|ANL-KD|87.27\u00b10.23|81.33\u00b10.30|71.82\u00b10.29|\n|ADA-KD|90.15\u00b10.34|83.49\u00b10.22|75.23\u00b10.28|\n|WLS-KD|90.05\u00b10.28|82.83\u00b10.24|74.77\u00b10.27|\n|RW-KD|89.40\u00b10.45|82.22\u00b10.59|73.91\u00b10.58|\n|**TGeo-KD**|**92.39\u00b10.49**|**85.65\u00b10.27**|**78.38\u00b10.21**|\n\n*Table: Top-1 ACC on Criteo.*\n|Method|$\\rho=1$|$\\rho=5$| w/o oversampling |\n|:-:|:-:|:-:|:-:|\n|Vanilla KD|71.08\u00b10.48|67.32\u00b10.56|61.01\u00b10.39|\n|ANL-KD|72.71\u00b10.35|68.03\u00b10.38|62.18\u00b10.32|\n|ADA-KD|72.15\u00b10.33|67.74\u00b10.42|61.35\u00b10.46|\n|WLS-KD|75.30\u00b10.38|71.21\u00b10.55|64.52\u00b10.43|\n|RW-KD|75.05\u00b10.44|70.58\u00b10.37|63.90\u00b10.38|\n|**TGeo-KD**|**77.80\u00b10.29**|**74.09\u00b10.32**|**67.77\u00b10.30**|\n\n**Q2: Impact of ST and inter-sample relations on the fusion ratio.**\n\n**A2:** To analyze the impact of prediction discrepancy $\\mathcal{ST}$ and inter-sample relations $\\Delta^{\\mathcal{S\\bar{T}G}}$ on the fusion ratios for incorrectly predicted samples, we have added the following table (Table 14 in the main manuscript), indicating the mean and standard deviation of the fusion ratios across these samples when learning fusion ratio with and without the consideration of $\\mathcal{ST}$ and $\\Delta^{\\mathcal{S\\bar{T}G}}$. When considering both $\\mathcal{ST}$ and $\\Delta^{\\mathcal{S\\bar{T}G}}$, our TGeo-KD demonstrates the fusion ratios below 0.3 for incorrectly predicted samples. This suggests that the student acquires more knowledge from the ground truth, leading to decreased fusion ratios on $\\mathcal{L}^{KD}$. Furthermore, in comparison to solely exploiting $\\Delta^{\\mathcal{S\\bar{T}G}}$ when learning fusion ratios, $\\mathcal{ST}$ contributes more effectively to the decreased fusion ratios across incorrectly predicted samples. We have also provided the results in Appendix A.4 of the manuscript.\n\n|Method|$\\mathcal{SG+TG}$|$\\mathcal{ST}$|$\\Delta^{\\mathcal{S\\bar{T}G}}$|Final fusion ratio on incorrectly predicted samples|\n|:-:|:-:|:-:|:-:|:-:|\n|TGeo-KD|\u2713|-|-|0.58\u00b10.29|\n|TGeo-KD|\u2713|\u2713|-|0.32\u00b10.15|\n|TGeo-KD|\u2713|-|\u2713|0.43\u00b10.18|\n|TGeo-KD|\u2713|\u2713|\u2713|0.12\u00b10.07|\n\n**Q3: Fusion ratio across different samples.**\n\n**A3:** Section 4.3 and Section 4.4 provide the analysis regarding the learning process of fusion ratios across normal samples and outliers. Specifically, Figure 4 shows the final fusion ratio distributions among sample-wise based baselines and our TGeo-KD on CIFAR-100. In comparison to the two baselines, our TGeo-KD increases the final fusion ratios for normal samples within the range of 0.4 and 0.6, which signifies the effective guidance of the student by valuable supervision signals from both the ground truth and the teacher. Additionally, as the teacher may make incorrect predictions on outliers, imparting misleading knowledge to the student, our TGeo-KD decreases the final fusion ratios below 0.3 for outliers. This indicates that the student is encouraged to learn more informative knowledge from the ground truth, resulting in decreased fusion ratios on $\\mathcal{L}^{KD}$. \n\nTable 4 illustrates the average fusion ratios during the training. With the incorporation of $\\mathcal{ST}$, our TGeo-KD consistently reduces the fusion ratios for incorrectly predicted samples as the training progresses. In cases where the teacher predicts accurately, the fusion ratio is increased in scenarios with a significant discrepancy between the student and teacher. This implies that the student is expected to emulate the teacher more closely, as the teacher possesses greater potential for offering valuable knowledge. On the contrary, when the discrepancy is smaller, the student is encouraged to rely more on the ground truth, resulting in a decline in the fusion ratio."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700413830559,
                "cdate": 1700413830559,
                "tmdate": 1700413830559,
                "mdate": 1700413830559,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "cgNGQehAvd",
                "forum": "OZitfSXpdT",
                "replyto": "5CJ2Mv7qVL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q4: The choice of  Euclidean space.**\n\n**A4:** Our proposed method can model the sample-wise trilateral geometric relations in various spaces, including hyperbolic space and Euclidean space. Considering that Euclidean distance is a commonly used metric to model the relations among samples in knowledge distillation studies [6,7,8], we take Euclidean space as an illustrative example to represent the sample-wise trilateral geometry encompassing the student predictions, teacher predictions, and ground truth. \n\n**Q5: Generalization across different datasets.**\n\n**A5:** Our method showcases robust adaptability and generalization across a spectrum of datasets, each with its own unique characteristics in terms of sample categories and numbers.\n* ***CIFAR-100***: This dataset is a staple in the realm of knowledge distillation, encompassing 60,000 color images categorized into 100 distinct classes.  CIFAR-100 includes a wide variety of objects, animals, and scenes, standing as an excellent benchmark for the development and testing of models and algorithms. In comparison to the best baseline WLS-KD [5],  our method consistently exhibits performance enhancements of 1.37% and 1.26% across homo- and hetero-architectures knowledge distillation scenarios.  \n* ***ImageNet***: ImageNet is a large-scale dataset commonly used for image classification, containing millions of labeled images spanning thousands of categories, such as animals and scenes, etc.  In comparison to the best baseline WLS-KD [5], our method consistently exhibits performance enhancements of 1.10% and 0.94% across homo- and hetero-architectures knowledge distillation scenarios.  \n* ***HIL***: Primarily used for conceptualizing attack detection in industrial IoT systems, HIL emerges from a real-world transmission network, offering a tabular structure with 128 diverse features. Notably, it covers three event categories\u2014normal operation (label 0), natural fault (label 1), and malicious attack (label 2) \u2014with an inherent data imbalance among these classes (4,405, 18,309, and 55,663, respectively). In comparison to the best baseline ADA-KD [4], our method consistently exhibits performance enhancements of 2.24%. \n* ***Criteo***: This dataset is a benchmark for CTR prediction challenges. With a whopping 45 million user interactions, it features a mix of integer and categorical data attributes. It contains the majority (74.25%) of samples belonging to the \"no-click\" class (0) and a minority (25.75%) to the \"click\" class (1). In comparison to the best baseline WLS-KD [5], our method consistently exhibits performance enhancements of 2.50%. \n\n**Q6: Reason of formulating the problem into bilevel optimization.**\n\n**A6:** Our ultimate objective is to find the optimal sample-wise ratios $\\alpha_{i}=f_{\\omega}(\\Delta_{i})$ that enable the student network parameterized by  to generalize well on test data. This naturally implies a bilevel optimization problem [1] with  as the outer level variable and  as the inner loop variable. \n\nIn Appendix A.5 of the manuscript, the computational cost comparison of our proposed TGeo-KD with the baselines is provided in the table below. We run experiments on CIFAR-100 and report the mean training time (in second) on a batch of 128 images per iteration. The student network is ResNet-32. The experiment is conducted on one NVIDIA RTX-3090 GPU. As shown in the table below (Table 15 in the manuscript), TGeo-KD increases marginal training costs with significant accuracy improvement compared to other methods.\n\n*Table: Mean training time (in seconds) on a batch for CIFAR-100 per iteration.*\n||Vanilla KD [2]|ANL-KD [3]|ADA-KD [4]|WLS-KD [5]|**TGeo-KD (ours)**|\n|:-:|:-:|:-:|:-:|:-:|:-:|\n|Training time (sec)| 0.095|0.095|0.101| 0.097|**0.097**|\n|ACC (%)|74.07|72.08|71.45|75.46|**76.83**|\n\nRef:\n* [1] Franceschi, et al. Bilevel programming for hyperparameter optimization and meta-learning. ICML, 2018.\n* [2] Hinton et al. Distilling the knowledge in a neural network. NeurIPS, 2014. \n* [3] Clark et al. BAM! born-again multi-task networks for natural language understanding. ACL, 2019.\n* [4] Lukasik et al. Teacher\u2019s pet: understanding and mitigating biases in distillation. TMLR, 2022. \n* [5] Zhou et al. Rethinking soft labels for knowledge distillation: A bias-variance tradeoff perspective. ICLR, 2021.\n* [6] Liu et al. Knowledge distillation via instance relationship graph. CVPR, 2019.\n* [7] Park et al. Relational knowledge distillation. ICCV, 2019.\n* [8] Romero et al. Fitnets: Hints for thin deep nets. ICLR, 2015."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700413850328,
                "cdate": 1700413850328,
                "tmdate": 1700413850328,
                "mdate": 1700413850328,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "hY7HyghdHt",
                "forum": "OZitfSXpdT",
                "replyto": "cgNGQehAvd",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Reviewer_aFDp"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Reviewer_aFDp"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for the authors' detailed response. After reading the rebuttal and other reviewer's comments, my concerns have been well addressed. Overall, I think this is a good work. Thus, I will increase my score correspondingly."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700665596124,
                "cdate": 1700665596124,
                "tmdate": 1700665596124,
                "mdate": 1700665596124,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "vijrgPDPUB",
            "forum": "OZitfSXpdT",
            "replyto": "OZitfSXpdT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission288/Reviewer_iMjj"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission288/Reviewer_iMjj"
            ],
            "content": {
                "summary": {
                    "value": "This paper focuses on data-wise adaptive knowledge fusion ratio in knowledge distillation. They find that the discrepancy of the predictions from teacher and student plays an important role, and they design a novel KD method based on this. Experiments show the effectiveness of their proposed method."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "- They propose a novel KD method to exploit the discrepancy of the prediction logits from S and T to adaptively learn the knowledge fusion rate, offering an valuable view for KD.\n- The experiments are solid and achieve good performance.\n- More significantly, the proposed sample-wise operation introduces little additional training time, making this method useful in practice."
                },
                "weaknesses": {
                    "value": "- How do the outliers hurt KD? As a key motivation, the corresponding empirical evidence seems lacking.\n- In addition, the teacher model indeed may underperform on the outliers. According to previous discussion, directly decreasing the $\\alpha$ also can solve this issue. Thus, why to introduce the inter-sample relations? This motivation needs to be further claified.\n- Evaluating this method on real OOD datasets, like DomainNet, will be more convicing."
                },
                "questions": {
                    "value": "- As far as I know, the computation of similarities of class probability distribution vectors often adopts the cosine similarity. Why do they use the Euclidean distance here? Are there some advantages over cosine similarity?\n- As they state that Eq. 4 is an implicit function of \u03c9 as \u03b8* depends on \u03c9, how to perform alternately optimization?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission288/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698490090559,
            "cdate": 1698490090559,
            "tmdate": 1699635954874,
            "mdate": 1699635954874,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "4B7IDUNfhs",
                "forum": "OZitfSXpdT",
                "replyto": "vijrgPDPUB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your time and feedback. We would also appreciate your agreement on the novelty, effectiveness, robustness, and adaptability of our method. Our reply to your questions is as follows.\n\n**Q1: Empirical evidence of addressing outliers when learning fusion ratio.**\n\n**A1:** Given the substantial divergence between outliers and normal training data, the teacher network may perform poorly on these outliers, even with high absolute values of confidence margin. As illustrated in our motivation experiment presented in Figure 1 of the manuscript, the subset $D\u2019$ includes samples on which the teacher makes inaccurate predictions. Notably, an increased fusion ratio  degrades the student\u2019s performance across all $g\u2019$ groups $(D\u2019={g\u2019_1, g\u2019_2, g\u2019_3, g\u2019_4, g\u2019_5})$. This observation underscores the risk of the teacher transferring misleading knowledge to the student when relying on the teacher\u2019s prediction as the supervisory signal, ultimately leading to a decline in the student\u2019s performance. Therefore, it is crucial to determine an appropriate sample-wise fusion ratio to effectively guide the student training process, particularly when addressing outliers. \n\n**Q2: Reason to introduce inter-sample relations.**\n\n**A2:** We argue that directly decreasing the same alpha value across all samples oversimplifies the varied impact of different outliers. Each outlier can uniquely influence the learning process, and a blanket reduction in alpha fails to address these nuances. We lack clarity on the extent of alpha value reduction needed for different samples without other guidance and signals.\n\nOur approach, which factors in inter-sample relations, aligns more closely with the principles of Knowledge Distillation, which is to understand the dynamics among the teacher, student, and ground truth. By examining these relationships, we can adjust the alpha value more precisely, tailoring the learning process to accommodate the diverse nature of outliers. Adopting this sophisticated, context-aware strategy is crucial for optimizing model performance, ensuring each outlier's impact is individually assessed and addressed, rather than resorting to a generalized, less effective solution.\n\n**Q3: Experiment on real OOD datasets.**\n\n**A3:** To better show the effectiveness of our method on Out-of-Distribution Detection (OOD) dataset, we conduct experiments on DomainNet. DomainNet [1] is a domain adaptation dataset with six domains (including Clipart, Real, Sketch, Infograph, Painting, and Quickdraw) and 0.6 million images distributed across 345 categories. In the experiment setup, we adopt a standard leave-one-domain-out manner, and train our student (teacher: ResNet-50 and student: ResNet-18) on the training set of the source domains and evaluate the trained student on all images of the held-out target domain. All results are reported in terms of average classification accuracy (with standard deviation) over 5 repeated runs. As reported in the table below (Table 8 in the manuscript), our TGeo-KD can outperform all the relevant KD-based baseline methods. We have also added the experimental results in Appendix A.3 of the manuscript. \n\n*Table: Classification accuracy (\\%) on DomainNet.*\n\n\n||Clipart|Real|Sketch|Infograph|Painting|Quickdraw|Avg|\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|Vanilla KD|50.6\u00b10.2|55.1\u00b10.3|40.7\u00b10.3|17.9\u00b10.2|42.5\u00b10.4|9.8\u00b10.3|34.3\u00b10.3|\n|ANL-KD|52.5\u00b10.4|57.0\u00b10.3|41.9\u00b10.3|19.6\u00b10.2|44.6\u00b10.3|11.3\u00b10.3|37.8\u00b10.3|\n|ADA-KD|53.6\u00b10.2|57.9\u00b10.4|42.3\u00b10.3|20.5\u00b10.2|45.1\u00b10.3|12.4\u00b10.4|38.7\u00b10.4|\n|WLS-KD|53.1\u00b10.4|57.7\u00b10.3|42.8\u00b10.2|21.1\u00b10.1|45.3\u00b10.2|12.0\u00b10.2|38.5\u00b10.3|\n|RW-KD|51.3\u00b10.3|56.2\u00b10.3|41.2\u00b10.2|18.8\u00b10.3|43.7\u00b10.2|10.6\u00b10.3|37.1\u00b10.2|\n|**TGeo-KD**|**55.2**\u00b10.3|**59.3**\u00b10.4|**44.6**\u00b10.1|**21.7**\u00b10.3|**46.9**\u00b10.3|**14.1**\u00b10.3|**40.2**\u00b10.3|"
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700413396512,
                "cdate": 1700413396512,
                "tmdate": 1700413396512,
                "mdate": 1700413396512,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "bexKoK2cQQ",
                "forum": "OZitfSXpdT",
                "replyto": "vijrgPDPUB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q4: The choice of  Euclidean space.**\n\n**A4:** Our proposed method can model the sample-wise trilateral geometric relations in various spaces, including Euclidean space and other measures. Considering that Euclidean distance is a commonly used metric to model the relations among samples in knowledge distillation studies [2,3,4], we take Euclidean space as an illustrative example to represent the sample-wise trilateral geometry encompassing the student predictions, teacher predictions, and ground truth. Our approach certainly accommodates the use of cosine similarity. However, we have not extensively explored this option, as it falls outside the central focus of our paper.\n\n**Q5: Iterative optimization procedure.**\n\n**A5:** To conduct the optimization for the bilevel optimization problem in Eq. 4, we speed up the training by using an approximation that has been validated in [5,6,7]. The key idea is to define a proxy function to link $\\omega$ to the outer objective as follows: $\\tilde{\\theta}(\\omega) := \\theta - \\alpha \\nabla_{\\theta}\\mathcal{J}^{\\text{inner}}(\\theta, \\omega)$, where $\\alpha$ is the learning rate.\n\nThen the iterative optimization process from step $t$ to step $t+1$ can be illustrated as follows:\n* $\\theta$ update: $\\theta^{t+1} \\leftarrow OPT_{\\theta}\\Big(\\theta^t, \\nabla_{\\theta^t}\\mathcal{J}^{\\text{inner}}(\\theta^t, \\omega^t)\\Big)$\n* Proxy: $\\tilde{\\theta}^{t+1}(\\omega^t) := \\theta^t - \\alpha \\nabla_{\\theta^t}\\mathcal{J}^{\\text{inner}}(\\theta^t, \\omega^t)$\n* $\\omega$ update: $\\omega^{t+1} \\leftarrow OPT_{\\omega}\\Big(\\omega^t, \\nabla_{\\omega^t}\\mathcal{J}^{\\text{outer}}(\\tilde{\\theta}^{t+1}(\\omega^t))\\Big)$\n\nRef:\n* [1] Peng et al. \u201cMoment matching for multi-source domain adaptation.\u201d ICCV, 2019.\n* [2] Liu et al. \"Knowledge distillation via instance relationship graph.\" CVPR, 2019.\n* [3] Park et al. \"Relational knowledge distillation.\" ICCV, 2019.\n* [4] Romero et al. \u201cFitnets: Hints for thin deep nets.\u201d ICLR, 2015\n* [5] Liu et al. \"Darts: Differentiable Architecture Search.\" ICLR, 2019. \n* [6] Chen et al. \"\u03bbOpt: Learn to Regularize Recommender Models in Finer Levels.\" KDD, 2019.\n* [7] Ma et al. \"Probabilistic Metric Learning with Adaptive Margin for Top-K Recommendation.\" KDD, 2020."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700413404229,
                "cdate": 1700413404229,
                "tmdate": 1700413404229,
                "mdate": 1700413404229,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "4m3JO27Y2Z",
                "forum": "OZitfSXpdT",
                "replyto": "bexKoK2cQQ",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Reviewer_iMjj"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Reviewer_iMjj"
                ],
                "content": {
                    "comment": {
                        "value": "Thank you very much for the your detailed clarification. I have gone through your responses and other reviewer's comments, my concerns have been well addressed. Overall, I am willing to support this paper and keep my current score."
                    }
                },
                "number": 12,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700671398260,
                "cdate": 1700671398260,
                "tmdate": 1700671398260,
                "mdate": 1700671398260,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "o3X9ZMO39T",
                "forum": "OZitfSXpdT",
                "replyto": "vijrgPDPUB",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear reviewer,\n\nThank you again for your time and constructive comments. Your thoughtful evaluation and encouraging feedback significantly enhance the overall quality of our work.\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 16,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700675588946,
                "cdate": 1700675588946,
                "tmdate": 1700675608322,
                "mdate": 1700675608322,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "3uCcfEcuFS",
            "forum": "OZitfSXpdT",
            "replyto": "OZitfSXpdT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission288/Reviewer_UyVS"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission288/Reviewer_UyVS"
            ],
            "content": {
                "summary": {
                    "value": "This paper studies a less explored topic in Knowledge Distillation that of finding the optimal parameter/weight alpha for combining the distillation loss with the standard cross entropy loss when training the student. The authors first motivate the impact of appropriately learning the weight parameter with a well-designed experiment and then they propose a practical method to estimate it using a small network that uses as input features geometric features computed from the teacher's and student's logit and the ground truth one-hot vectors. They show good results on a variety of standard KD benchmarks"
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Paper is well-written and motivating example makes sense\n2. Problem tackled is not well-studied and the solution proposed is simple and effective\n3. Results carried out on standard benchmarks show that the method is effective on these benchmarks"
                },
                "weaknesses": {
                    "value": "1. My main concern is related to the impact of the proposed solution. Like most distillation papers conclusions are drawn based on CIFAR-100 experiments using same network architecture. Claims made by the authors could substantiate better if they are shown to hold on bigger datasets like ImageNet.\n2. Tasks other than classification should be considered (e.g. detection). Experiments on HIL and Criteo datasets are of low impact \n3. Important references/comparison with SOTA is insufficient. Authors should have included comparisons with Decoupled Knowledge Distillation, CVPR'22 and KNOWLEDGE DISTILLATION VIA SOFTMAX REGRESSION REPRESENTATION LEARNING, ICLR'21. From my preliminary checking, the improvements of the proposed method are not always so significant if the aforementioned methods are considered."
                },
                "questions": {
                    "value": "Inter sample relations are used to model outliers. But how do you define outliers in the datasets you're using for your experiments (i.e. imagenet and cifar)?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission288/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698497228638,
            "cdate": 1698497228638,
            "tmdate": 1699635954787,
            "mdate": 1699635954787,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "I2dGmQlLQu",
                "forum": "OZitfSXpdT",
                "replyto": "3uCcfEcuFS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your time and feedback. We would also appreciate your agreement on the novelty, effectiveness, robustness, and adaptability of our method. Our reply to your questions is as follows.\n\n**Q1: Experiment on ImageNet for higher impact.**\n\n**A1:** In Section 4.2, we conduct the experiments on ImageNet to further demonstrate the effectiveness of our approach on larger datasets. As depicted in the table below (Table 2 in the manuscript), TGeo-KD consistently outperforms all competing baselines. Compared with the best baseline WLS-KD [1], TGeo-KD exhibits the performance improvement of 1.10% when the teacher (ResNet-34) and student (ResNet-18) share the same architecture style. In a hetero-architecture KD experiment with ResNet-50 and MobileNetV1 as teacher and student respectively, our method realizes an improvement of 0.94%.\n\n*Table: Top-1 and Top-5 classification accuracy on ImageNet. We re-implemented the methods denoted by \\* and used the author-provided or author-verified results for the others.*\n\n*Teacher: ResNet-34 \u2192 Student: ResNet-18*\n\n| Method| Top-1 ACC| Top-5 ACC|\n|:-:|:-:|:-:|\n|Teacher|73.31|91.42|\n|Student|69.75|89.07|\n|AT|71.03|90.04|\n|NST|70.29|89.53|\n|FSP|70.58|89.61|\n|RKD|70.40|89.78|\n|Overhaul|71.03|90.15|\n|CRD|71.17|90.13|\n|Vanilla KD|70.67|90.04|\n|ANL-KD\\*|71.83 \u00b10.22|90.21 \u00b10.26|\n|ADA-KD\\*|71.96 \u00b10.17|90.45 \u00b10.21|\n|WLS-KD| 72.04*|*90.70*|\n|RW-KD\\*|70.62 \u00b10.22|89.76 \u00b10.15|\n|**TGeo-KD**|**72.89 \u00b10.15**|**91.80 \u00b10.04**|\n\n*Teacher: ResNet-50 \u2192 Student: MobileNetV1*\n\n|Method|Top-1 ACC|Top-5 ACC|\n|:-:|:-:|:-:|\n|Teacher|76.16|92.87|\n|Student|68.87|88.76|\n|AT|70.18|89.68|\n|FT|69.88|89.50|\n|AB|68.89|88.71|\n|RKD|68.50|88.32|\n|Overhaul|71.33|90.33|\n|CRD|69.07|88.94|\n|Vanilla KD|70.49|89.92|\n|ANL-KD\\*|70.40\u00b10.15|89.25\u00b10.22|\n|ADA-KD\\*|71.08\u00b10.24|90.17\u00b10.16|\n|WLS-KD|*71.52*|*90.34*|\n|RW-KD\\*|70.15\u00b10.16|89.40 \u00b10.19|\n|**TGeo-KD**|**72.46\u00b10.14**|**90.95 \u00b10.17**|\n\n**Q2: Other tasks and impact.**\n\n**A2:** While existing knowledge distillation works have demonstrated success in image classification tasks, their applications in real-world industrial systems, including cyber-physical systems and recommender systems, still remain limited. Hence,  to illustrate the broad applicability of our approach across diverse application scenarios, we conduct extensive experiments spanning three tasks: CIFAR-100 and ImageNet for image classification, HIL for attack detection in cyber-physical systems, and Criteo for click-through prediction in recommender systems. \n\nMoreover, the selection of three tasks considers the representation of diverse domains characterized by different data natures. CIFAR-100 and ImageNet serve as widely recognized benchmarks for image-based knowledge distillation. HIL, as the representative of time series data, captures the dynamics of real-world industrial systems, thus presenting unique challenges different from image datasets [1-3]. Criteo is vital for its reflection of human behavior through its vast collection of feature values and click feedback for display ads, offering a distinct challenge relative to the others [4-6]. \n\nIn addition to the experiments included in the current manuscript, we conduct additional experiments on DomainNet dataset [7], to demonstrate the generalization ability of our method in the Out-of-Distribution Detection (OOD) task. DomainNet [7] is a domain adaptation dataset with six domains (including Clipart, Real, Sketch, Infograph, Painting, and Quickdraw) and 0.6 million images distributed across 345 categories. In the experiment setup, we adopt a standard leave-one-domain-out manner, and train our student (teacher: ResNet-50 and student: ResNet-18) on the training set of the source domains and evaluate the trained student on all images of the held-out target domain. All results are reported in terms of average classification accuracy (with standard deviation) over 5 repeated runs. As reported in the table below (Table 8 in the manuscript), our TGeo-KD can outperform all the relevant KD-based baseline methods. We have also added the experimental results in Appendix A.3 of the manuscript. \n\n*Table: Classification accuracy (\\%) on DomainNet.*\n\n|Method|Clipart|Real|Sketch|Infograph|Painting|Quickdraw|Avg|\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|Vanilla KD|50.6 \u00b10.2| 55.1 \u00b10.3 | 40.7 \u00b10.3 | 17.9 \u00b10.2 | 42.5 \u00b10.4 | 9.8 \u00b10.3  | 34.3 \u00b10.3 |\n|ANL-KD|52.5 \u00b10.4| 57.0 \u00b10.3 | 41.9 \u00b10.3 | 19.6 \u00b10.2 | 44.6 \u00b10.3 | 11.3 \u00b10.3 | 37.8 \u00b10.3 |\n|ADA-KD|53.6 \u00b10.2| 57.9 \u00b10.4 | 42.3 \u00b10.3 | 20.5 \u00b10.2 | 45.1 \u00b10.3 | 12.4 \u00b10.4 | 38.7 \u00b10.4 |\n|WLS-KD|53.1 \u00b10.4 | 57.7 \u00b10.3 | 42.8 \u00b10.2 | 21.1 \u00b10.1 | 45.3 \u00b10.2 | 12.0 \u00b10.2 | 38.5 \u00b10.3 |\n|RW-KD|51.3 \u00b10.3| 56.2 \u00b10.3 | 41.2 \u00b10.2 | 18.8 \u00b10.3 | 43.7 \u00b10.2 | 10.6 \u00b10.3 | 37.1 \u00b10.2 |\n|TGeo-KD|**55.2** \u00b10.3 | **59.3** \u00b10.4 | **44.6** \u00b10.1 | **21.7** \u00b10.3 | **46.9** \u00b10.3 | **14.1** \u00b10.3 | **40.2** \u00b10.3 |"
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700412981422,
                "cdate": 1700412981422,
                "tmdate": 1700412981422,
                "mdate": 1700412981422,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "gSJSRQjiX1",
                "forum": "OZitfSXpdT",
                "replyto": "3uCcfEcuFS",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q3: Performance comparison with additional baselines.**\n\n**A3:** We conduct a comparative analysis between our proposed TGeo-KD and the two baselines (i.e., DKD [8] and SR-KD [9]) using CIFAR-100 and ImageNet, as illustrated in the tables below. The baseline results marked with * are obtained through our re-implementation of both student and teacher networks, and the average classification accuracy  (with standard deviation) are calculated over 5 repeated runs. For the remaining baseline results, we utilize the results provided or verified by these two baselines [8,9]. The best performance is bold.\n\nTo demonstrate the significance of improvement, we conduct a statistical t-test, calculating t-scores calculated based on the top-1 classification accuracy of our TGeo-KD and the baselines. Although DKD [8] (with teacher: ResNet-32x4, student: ShuffleNetV2) and SR-KD [9] (with teacher: ResNet-50, student: MobileNetV1) showcase marginal improvements on CIFAR-100 and ImageNet, our computed t-scores consistently exceed the threshold value $t_{0.05,5}$ when employing the remaining network architectures. This result indicates the acceptance of the alternative hypothesis at a statistical significance level of 5.0%, and supports the conclusion that TGeo-KD consistently demonstrates a notable performance enhancement.\n\n\n*Table: Top-1 classification accuracy (\\%) on CIFAR-100 dataset.*\n| Teacher| WRN-40-2 | ResNet-56 | ResNet-110 | ResNet-110 | ResNet-32x4 | ResNet-32x4 | ResNet-32x4 | WRN-40-2 |\n|:---------------:|:----------:|:-----------:|:------------:|:------------:|:-------------:|:-------------:|:-------------:|:----------:|\n| Student       | WRN-40-1 | ResNet-20 | ResNet-32  | ResNet-20  | ResNet-8x4  | ShuffleNetV1| ShuffleNetV2| ShuffleNetV1|\n| DKD           | 74.81    | 71.91     | 74.11      | 72.24*     | 76.32       | 76.45       | **77.07**       | 76.70    |\n| SR-KD         | 74.75    | 71.44     | 73.80      | 71.57      | 75.92       | 75.66       | 76.40       | 76.61    |\n| **TGeo-KD**       | **75.43**| **72.98** | **75.09**  | **73.55**  | **77.27**   | **76.83**   | 76.89   | **77.05**|\n\n*Table: Top-1 classification accuracy (\\%) on ImageNet dataset.*\n| Network architecture | Teacher: ResNet-34; Student: ResNet-18 | Teacher: ResNet-34; Student: ResNet-18 | Teacher: ResNet-50; Student: MobileNetV1 |  Teacher: ResNet-50; Student: MobileNetV1     |\n|:-:|:-----------:|:---------------:|:----------------:|:--------------:|\n|Method|Top-1 ACC|Top-5 ACC|Top-1 ACC|Top-5 ACC|\n|DKD|71.70|   90.41   |71.87*|   90.09*  |\n|SR-KD|71.73|   90.60   |**72.49**|   90.92   |\n|**TGeo-KD**|**72.89**|   **91.80**   |72.46|   **90.95**   |\n\n\n**Q4: Definition of outliers (i.e., in ImageNet and CIFAR).**\n\n**A4:** In Section 4.4, we generate outliers by introducing synthetic Gaussian noise as additional training samples following the setting outlined in the studies [10,11,12]. In the context of Gaussian noise outliers, each RGB value for every pixel is sampled from an independent and identically distributed Gaussian distribution with a mean of 0.5 and unit variance, and each pixel value is clipped to the range $[0, 1]$.\n\nRef:\n* [1] Pan et al. \u201cDeveloping a Hybrid Intrusion Detection System Using Data Mining for Power Systems.\" Trans Smart Grid, 2015.\n* [2] Adhikari et al. \u201cApplying Non-Nested Generalized Exemplars Classification for Cyber-Power Event and Intrusion Detection.\u201d Trans Smart Grid, 2018.\n* [3] Hu et al. \"Reinforcement Learning-Based Adaptive Feature Boosting for Smart Grid Intrusion Detection.\" Trans Smart Grid, 2023.\n* [4] Shan et al. \"Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features\". KDD, 2016.\n* [5] Juan et al. \"Field-aware Factorization Machines for CTR Prediction.\" RecSys, 2016.\n* [6] Zhu et al. \"Ensembled CTR Prediction via Knowledge Distillation.\" CIKM, 2020.\n* [7] Peng et al. \u201cMoment matching for multi-source domain adaptation.\u201d ICCV, 2019.\n* [8] Zhao et al. \u201cDecoupled knowledge distillation.\u201d CVPR, 2022\n* [9] Yang et al. \u201cKnowledge distillation via softmax regression representation learning.\u201d ICLR, 2021. \n* [10] Hendrycks et al. \u201cA baseline for detecting misclassified and out-of-distribution examples in neural networks.\u201d ICLR, 2016.\n* [11] Liang et al. \u201cEnhancing the reliability of out-of-distribution image detection in neural networks.\u201d ICLR, 2018. \n* [12] Vyas et al. \u201cOut-of-Distribution Detection Using an Ensemble of Self Supervised Leave-out Classifiers.\u201d ECCV, 2018."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700412988183,
                "cdate": 1700412988183,
                "tmdate": 1700414504792,
                "mdate": 1700414504792,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "SRPIb4DiMi",
            "forum": "OZitfSXpdT",
            "replyto": "OZitfSXpdT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission288/Reviewer_Ur13"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission288/Reviewer_Ur13"
            ],
            "content": {
                "summary": {
                    "value": "This paper discusses the concept of knowledge distillation (KD) and introduces a new method called TGeo-KD for determining sample-wise knowledge fusion ratios in KD. The traditional approach to determining fusion ratios in KD involves using a fixed value for all samples or gradually decreasing the ratio. The authors argue that considering the discrepancy between the student's and teacher's predictions (ST discrepancy) is crucial in determining the fusion ratio. They propose TGeo-KD, which leverages the trilateral geometry among the signals from the student, teacher, and ground truth to model the fusion process. Experiments conducted on CIFAR-100 dataset demonstrate the effectiveness of TGeo-KD compared to other methods. The main contributions of TGeo-KD include its use of trilateral geometry, mitigation of outliers, and superior performance across different tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1.\tThe paper introduces a novel method called TGeo-KD for determining sample-wise knowledge fusion ratios in knowledge distillation. This method leverages trilateral geometry and captures the geometric relations between the signals from the student, teacher, and ground truth. By introducing this new method, the article contributes to the existing body of research in knowledge distillation.\n2.\tThe article emphasizes that TGeo-KD is versatile and adaptable to different architectures and model sizes. This implies that the proposed method can be applied to a wide range of machine learning tasks and scenarios. The ability to apply TGeo-KD to different models and architectures enhances its practical utility and makes it a valuable contribution to the field of knowledge distillation.\n3.\tTGeo-KD leverages trilateral geometry at both intra-sample and inter-sample levels, which helps in mitigating the impact of outliers in the training samples. Outliers are samples that deviate significantly from the majority of the dataset and can negatively affect the learning process. By incorporating the trilateral geometry and considering the ST discrepancy, TGeo-KD provides a robust approach that is less sensitive to outliers, resulting in more stable and reliable knowledge transfer."
                },
                "weaknesses": {
                    "value": "Complexity and Computational Cost: The TGeo-KD method proposed in the article leverages trilateral geometry and introduces a neural network to learn the fusion ratios. This suggests that the method may have a higher computational cost compared to simpler knowledge distillation techniques. Implementing and training the neural network for determining fusion ratios may require additional computational resources and time, which could be a potential drawback, especially in resource-constrained environments.\n\nThe proposed TGeo-KD leverages trilateral geometry and captures the geometric relations between the signals from the student, teacher, and ground truth. However, I think it lacks more sufficient theoretical proof."
                },
                "questions": {
                    "value": "Please see the weakness."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission288/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698980836920,
            "cdate": 1698980836920,
            "tmdate": 1699635954651,
            "mdate": 1699635954651,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "sl5iy5Kism",
                "forum": "OZitfSXpdT",
                "replyto": "SRPIb4DiMi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "We appreciate your time and feedback. We would also appreciate your agreement on the novelty, effectiveness, robustness, and adaptability of our method. Our reply to your questions is as follows.\n\n**Q1: Complexity and computational cost.**\n\n**A1:** Thanks for the comments. We put the computational comparison in Appendix A.4 as shown in Table 15. In the experiment, we compare the computational cost of our proposed TGeo-KD with the baselines including vanilla KD [1], ANL-KD [2], ADA-KD [3], and WLS-KD [4]. We run experiments on CIFAR-100, and report the mean training time (in seconds) on a batch of 128 images per iteration. The student network is ResNet-32. The experiment is conducted on one NVIDIA RTX-3090 GPU. As shown in the table below (Table 15 in the manuscript), our method has little additional training time, making this method useful in practice. \n\n*Table: Mean training time (in seconds) on a batch for CIFAR-100 per iteration.*\n| Vanilla-KD | ANL-KD | ADA-KD | WLS-KD | TGeo-KD (Ours) |\n|:------------:|:--------:|:--------:|:--------:|:----------------:|\n| 0.095      | 0.095  | 0.101  | 0.097  | 0.097          |\n\nThe reason why our method does not significantly increase processing time can be attributed to the additional neural network $f(\\cdot)$ we employ, which is merely a 2-layer MLP as outlined in Section 4.5. Specifically, \n\\begin{aligned}\n\\alpha_i:=f_{\\omega}(\\Delta_i)=\\text{sigmoid}\\bigg(\\mathbf{W}_2\\cdot \\Big(\\text{relu}(\\mathbf{W}_1\\cdot \\Delta_i +  \\mathbf{b}_1)\\Big) + \\mathbf{b}_2\\bigg),\n\\end{aligned}\n\nwhere $\\mathbf{W}_1\\in\\mathbb{R}^{h\\times s}$, $\\mathbf{W}_2\\in\\mathbb{R}^h$, $\\mathbf{b}_1\\in\\mathbb{R}^h$, and $\\mathbf{b}_2\\in\\mathbb{R}$ are the learnable parameters $\\omega$, $h$ is the size of the hidden layer, and $s$ is the size of $\\Delta_i$. In practice, we set $h\\in\\{16, 32, 64\\}$, and $s=9*C$ (i.e., $C$ is the number of classes in the dataset) if $\\Delta_i$ is defined as Eq. (10). Compared to the larger scale of the teacher and student models (e.g., ResNet-50 has 50 layers with over 25.6 million parameters), the relative size of this MLP is quite minimal. Consequently, the added time due to training this additional network is almost negligible. \n\n**Q2: Lack more sufficient theoretical proof.**\n\n**A2:** We appreciate your valuable feedback on the theoretical proof of our research. We would like to note that the key findings and contributions of this work revolve around empirical findings. Developing a theoretical proof for KD is challenging in general (even for the most influential works in the literature [1,2,5,6,7]), but could definitely be a direction for our future work. The only work we are aware of is [4], which presents a bias-variance perspective for KD. However, there are still several obstacles to adopting the results in [4] for TGeo-KD, as they do not account for the trilateral geometry in the data, which is the central element in our research. On the other hand, we note the recent work on the generalization bounds of triplet learning [8], which could be exploited to analyze trilateral geometry in TGeo-KD. Given the constraints of the limited rebuttal time, it is currently challenging for us to develop a thorough theoretical proof. We plan to address this as part of our future work.\n\n\nRef:\n* [1] Hinton et al. \u201cDistilling the knowledge in a neural network.\u201d NeurIPS, 2014.\n* [2] Clark et al. \u201cBAM! Born-Again Multi-Task Networks for Natural Language Understanding.\u201d ACL, 2019.\n* [3] Lukasik et al. \u201cTeacher\u2019s pet: understanding and mitigating biases in distillation.\u201d TMLR, 2022. \n* [4] Zhou et al. \u201cRethinking soft labels for knowledge distillation: A bias-variance tradeoff perspective.\u201d ICLR, 2021.\n* [5] Li et al. \u201cCurriculum Temperature for Knowledge Distillation.\u201d AAAI, 2023.\n* [6] Beyer et al. \u201cKnowledge distillation: A good teacher is patient and consistent.\u201d CVPR, 2022.\n* [7] Huang et al. \u201cKnowledge Distillation from A Stronger Teacher.\u201d NeurIPS, 2022.\n* [8] Chen et al. \u201cOn the Stability and Generalization of Triplet Learning.\u201d AAAI, 2023."
                    }
                },
                "number": 1,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700412365780,
                "cdate": 1700412365780,
                "tmdate": 1700412365780,
                "mdate": 1700412365780,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "x8KQDDB4XX",
                "forum": "OZitfSXpdT",
                "replyto": "SRPIb4DiMi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Reviewer_Ur13"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Reviewer_Ur13"
                ],
                "content": {
                    "title": {
                        "value": "Re: Response"
                    },
                    "comment": {
                        "value": "Thanks for authors' reponses to my questions. After reading the authors' responses and other reviewers' comments, some of my concerns have been addressed. However, I remain unconvinced by the theoretical aspect. In the Introduction section of the manuscript, the authors exclusively presented one experimental case to illustrate its core motivation. I anticipate encountering additional theoretical support for this motivation. It is crucial to ascertain whether the claim holds true when applied to a different dataset, as it currently lacks comprehensive validation. In addition, based on Table 1 and 2, it is evident that the proposed method yields slight gains, intensifying skepticism regarding the underlying motivation of this work."
                    }
                },
                "number": 18,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701344325,
                "cdate": 1700701344325,
                "tmdate": 1700701967771,
                "mdate": 1700701967771,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "a18yFZGerD",
                "forum": "OZitfSXpdT",
                "replyto": "SRPIb4DiMi",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission288/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1: Lack of sufficient theoretical support.**\n\n**A1:** We thank you for your continued engagement with the theoretical aspects of our research. In fact, we have been focusing on the theoretical development of our method. Eventually, we realized that by exploiting the notion of *performance gap* introduced by recent work [1], indeed, we can investigate the connections between teacher and ground truth, and how they affect student learning in our TGeo-KD. \n\nSpecifically, given $\\mathcal{D}$ and $f_\\omega$, let $\\theta_{\\text{KD}}$ and $\\theta_{\\text{GT}}$, respectively, be the minimizers of $J_{\\text{KD}}  \\triangleq \\frac{1}{N}\\sum_{i=1}^N f_{\\omega}(\\Delta_i)\\mathcal{L}^{\\text{KD}}_i$ and\n\n$J_{\\text{GT}} \\triangleq\\frac{1}{N}\\sum_{i=1}^N (1-f_{\\omega}(\\Delta_i))\\mathcal{L}^{\\text{GT}}_i$. \n\nThen, we can define the *performance gap* for TGeo-KD as\n\\begin{align}\n      \\nabla = \\nabla_{\\text{KD}} + \\nabla_{\\text{GT}},\n\\end{align}\n\nwhere $\\nabla_{\\text{KD}} = J_{\\text{KD}}(\\theta_{\\text{GT}})-J_{\\text{KD}}(\\theta_{\\text{KD}})$ and $J_{\\text{GT}}(\\theta_{\\text{KD}})-J_{\\text{GT}}(\\theta_{\\text{GT}})$. \nNote that:\n\n1. $J_{\\text{KD}}$ and $J_{\\text{GT}}$ are both  *weighted* objective functions where the weights are determined  by $f_\\omega$. In addition, $\\theta_{\\text{KD}}$ and $\\theta_{\\text{GT}}$ are the minimizers of  $J_{\\text{KD}}$ and $J_{\\text{GT}}$. Therefore, given the dataset $\\mathcal{D}$, $\\nabla$ is essentially a function of $f_\\omega$.\n2. Intuitively, if the labels predicted by the teacher model are quite different from the ground truth (i.e., a misleading teacher), one can expect that $\\theta_{\\text{KD}}$ and $\\theta_{\\text{GT}}$ will be quite different. As a result, by definition, $\\theta_{\\text{KD}}$ and $\\theta_{\\text{GT}}$ (hence $\\nabla$) will be large. In other words, it essentially captures the relationship between the teacher's predictions and the ground truth.\n\nLet $\\theta^*$ be the minimizer of the inner objective function of TGeo-KD (i.e., Eq. (5) in the manuscript). Then, given the definition of $\\nabla$, we can prove that the generalization error $\\mathbb{E}[\\mathcal{L}(\\theta^*)]$ can be upper bounded by\n\\begin{align}\n       \\mathbb{E}[\\mathcal{L}(\\theta^*)]  & \\le \\mathcal{J} (\\theta^*;\\omega)    + \\mathcal{O}\\left(\\left(\\frac{\\frac{\\gamma N}{2}+ \\sum_{i=1}^N f_{\\omega}^2(\\Delta_i) + \\sum_{i=1}^N (1- f_{\\omega}(\\Delta_i))^2}{ N^2} + \\frac{\\gamma C}{2N}  B(\\omega)  \\right)\\sqrt{N}\\right),\n\\end{align}\n\nwhere we let ${N_{\\text{train}}} =N$ to simplify the notation, and $f_{\\omega}(\\Delta_i) \\le \\gamma, \\forall i = 1,\\dots,N$ is the upper bound of $f_{\\omega}(\\Delta_i)$, $C$ is a constant with respect to TGeo-KD. Moreover, $B(\\omega)$ can be upper bounded by\n\\begin{align}\n       B(\\omega) \\le \\mathcal{O}(\\sqrt{\\nabla + C'}),\n\\end{align}\n\nwhere $C'$ is a constant with respect to TGeo-KD.\n\nFrom the theoretical results, we have the following observations:\n\n1. $\\Gamma  = \\sum_{i=1}^N f_{\\omega}^2(\\Delta_i) + \\sum_{i=1}^N (1- f_{\\omega}(\\Delta_i))^2$. Note that $\\Gamma$ is maximized when $f_{\\omega} \\equiv 1 \\text{ or } 0$. This in fact reflects a common sense in KD: one should not always trust the teacher or even the ground truth.\n2. The upper bound of $B(\\omega)$ reveals the importance of $\\nabla$, and motivates how to control the tradeoff in trilateral relations. In particular, for a specific data point, when the teacher's prediction is wrong, one should obviously trust the ground truth more in order to obtain a better generalization performance. On the other hand, the teacher's prediction is correct but the student's and the teacher's predictions are quite different, its weight should be increased to reduce the performance gap (this can be seen by treating $\\theta_{\\text{KD}}$ and $\\theta_{\\text{GT}}$ as the surrogates of teacher and the ground truth), which is consistent with our empirical findings.\n3. On the other hand, directly minimizing the upper bound is not straightforward (due to the definition of performance gap). In [1], this issue is sidestepped by a boosting-based algorithm, while we formulate it as a bilevel minimization problem."
                    }
                },
                "number": 19,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission288/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700730198221,
                "cdate": 1700730198221,
                "tmdate": 1700730600074,
                "mdate": 1700730600074,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]