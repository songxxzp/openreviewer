[
    {
        "title": "Towards Relaxing the Unbiasedness Condition of Doubly Robust Estimators for Debiased Recommendation"
    },
    {
        "review": {
            "id": "vLx3wBfEyA",
            "forum": "e47RxA52sT",
            "replyto": "e47RxA52sT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9439/Reviewer_BXqD"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9439/Reviewer_BXqD"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a novel doubly robust estimator to address observational bias in collaborative filtering.\\\nIt focuses on the effectiveness of the method, particularly in handling inaccurate pseudo-labels. \\\nThe authors propose debiasing techniques with constraints on propensity scores, aiming to ensure unbiasedness when the pseudo labels deviate from the true labels with an arbitrary inductive bias. \\\nThe paper combines theoretical analysis and experimental evaluations to demonstrate the method's effectiveness in comparison to benchmark approaches."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "1. Comprehensive Background: The authors provide a well-explained introduction and extensive coverage of prior related work, enhancing the paper's accessibility to readers by providing context and a clear understanding of the research landscape.\n\n2. Novel and Effective Method: The proposed method effectively addresses the issue of pseudo-labels deviating from true values with specific inductive bias.\n\n3. Theoretical and Empirical Validation: The paper combines theoretical analysis with empirical results, covering both semi-synthetic and real-world datasets, demonstrating the method's technical soundness and its superior performance compared to existing approaches."
                },
                "weaknesses": {
                    "value": "1. Limited Motivation: The paper may lack novelty in the central idea. Is there any empirical evidence that existing pseudo-labeling suffers from user/item specific inductive bias? If users have an inductive bias in the training set, the user should have the exact inductive bias in the test set.\n\n2. Strong Assumptions: The assumptions regarding inductive biases for users and items might not be realistic. The paper assumes constant inductive biases for users across all items, which may not hold true in real-life scenarios. Users typically exhibit varying preferences for different items.\n\n3. Unclear Propensity Score Calculation: The paper lacks a clear description of how propensity scores were calculated. There is a need for a more detailed explanation."
                },
                "questions": {
                    "value": "1. Personally, I cannot understand the intuitive concept of the experiment with the synthetic dataset. Can you explain the intuition?\n2. Is there any empirical or theoretical evidence for the motivating inductive bias problem?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "NA"
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9439/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9439/Reviewer_BXqD",
                        "ICLR.cc/2024/Conference/Submission9439/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9439/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698152657381,
            "cdate": 1698152657381,
            "tmdate": 1699780121240,
            "mdate": 1699780121240,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "WNnrQaKE5w",
            "forum": "e47RxA52sT",
            "replyto": "e47RxA52sT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9439/Reviewer_aJVp"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9439/Reviewer_aJVp"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a new doubly robust estimator for the missing-not-at-random bias.\nThe authors propose constraints on propensity scores to handle pseudo-labels deviating from the true value with the user-specific bias.\nThey provide theoretical analysis and practical experiments, showing how their approach outperforms benchmark methods."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- the solution (a constrained propensity model) is simple yet effective.\n- the authors provide theoretical analyses on the unbiasedness and the variance of the proposed estimator."
                },
                "weaknesses": {
                    "value": "- the target problem is too specific and minor. The authors noted that UIDR can effectively alleviate the \"inaccurate pseudo-labeling problem\" in the previous DR estimators. However, they only treat the situation where the pseudo-labelings deviate from the true labels with arbitrary user-specific inductive bias. This assumption looks quite unrealistic as the user-specific inductive bias is assumed to be equivalent for every item.\n- the proposed procedure is not well-motivated. The authors put constraints on the propensity model, not the imputation model, in order to tackle the inaccurate imputation model. If the imputation model is inaccurate the straightforward remedy would be either adjusting the imputation model itself or designing a new loss function robust to the inaccurate imputed errors. If we adjust the propensity model for the imputation model, the accuracy of the propensity model can be harmed."
                },
                "questions": {
                    "value": "- please refer to weaknesses.\n- ex) If we adjust the propensity model for the imputation model, how does the accuracy of the propensity model become?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "5: marginally below the acceptance threshold"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9439/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698653766981,
            "cdate": 1698653766981,
            "tmdate": 1699637188928,
            "mdate": 1699637188928,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "Hgp5C0xIsr",
            "forum": "e47RxA52sT",
            "replyto": "e47RxA52sT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9439/Reviewer_uhbY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9439/Reviewer_uhbY"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents a study on the challenges and potential solutions associated with debiasing the recommender system models due to the sampling selection bias in the process of data collection. The authors propose several novel doubly robust estimators that are unbiased.\nThese estimators are unbiased for arbitrary user-specific, item-specific inductive bias, and even both. Authors also theoretically prove these estimators\u2019 unbiasedness. Besides, they propose a propensity reconstruction learning approach that adaptively updates the constraint weights to meet the constraints of the proposed UIDR estimator."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "(1) The authors introduce a series of innovative double robustness (DR) estimators through a rigorous theoretical framework. These estimators maintain their unbiased nature even when pseudo labelings diverge from the true labels, accommodating arbitrary and unknown biases specific to users, items, or a combination thereof. This represents a significant stride in addressing user-specific and item-specific inductive biases, showcasing the adaptability and robustness of the proposed methods.\n\n(2) In a further extension of their work, the authors present a principled propensity reconstruction learning strategy, which adeptly utilizes an attention mechanism to adaptively update the constraint weights. This approach not only enhances the adaptability of the model but also ensures that the variance of the DR estimators remains within controllable and manageable bounds. This aspect of the work underscores the authors\u2019 commitment to developing robust and reliable estimators, contributing to the stability and efficacy of the proposed methods.\n\n(3) The paper\u2019s empirical validation is robust, encompassing semi-synthetic experiments that attest to the effectiveness of the proposed methods in scenarios involving arbitrary user-specific and item-specific inductive biases. This is a notable achievement, as previous methodologies have fallen short in providing unbiased estimates of the ideal loss under these conditions. Additionally, the authors extend their validation to real-world contexts, conducting comprehensive experiments across three real-world datasets. These experiments serve to highlight the tangible advantages and superior performance of the proposed methods, solidifying the paper\u2019s contributions to the field."
                },
                "weaknesses": {
                    "value": "(1) While the theoretical foundation appears robust, there is a potential concern regarding the complexity and practicality of implementing such estimators in real-world scenarios when we have large U and large I. The paper could benefit from a more detailed discussion on the potential challenges and limitations associated with these novel DR estimators, providing a more balanced and critical perspective.\n\n(2) The introduction of a principled propensity reconstruction learning approach, utilizing an attention mechanism to adaptively update constraint weights, is indeed a novel contribution. However, the claim that the variance of the DR estimators is highly controllable and manageable warrants a more rigorous scrutiny. Can we see any tradeoff between the bias and variance, since sometimes we want to minimize the MSE in the ML community when you mentioned controllable and manageable."
                },
                "questions": {
                    "value": "1. In section 2, it seems that $r_{u,i}$ in [0,1] rather in R, which is the rating/\n\n2. After corollary 1, \u201cthe biases of the proposed DR estimators are still strictly smaller than the previous DR\u201d , Is this toy example realistic? Could you please show a real example here?\n\n3. For the optimization problem, do we have a constraint that $\\tilde{p}$ < 1? \n\n4. What is A? What is b? What is $s_{u}$ and $t_{I}$? How do we learn it? Why $s_{u}$ has been applied tanh but $t_i$ is not been applied?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission9439/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9439/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission9439/Reviewer_uhbY"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9439/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698811157413,
            "cdate": 1698811157413,
            "tmdate": 1699637188816,
            "mdate": 1699637188816,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    },
    {
        "review": {
            "id": "aeDlr3xxQq",
            "forum": "e47RxA52sT",
            "replyto": "e47RxA52sT",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission9439/Reviewer_d1UZ"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission9439/Reviewer_d1UZ"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes User-DR, Iten-DR, and User-Item-DR for unbiased recommendation. The proposed methods have both strong theoretical guarantees and improvement in comparison with the baselines."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "1. Strong theoretical guarantee on the proposed method\n2. The experimental studies are solid. I would like to point out that a ~10% improvement in NDCG@5 is very significant for unbiased recommendation. Note that the machine learning model is not changed in this paper. To be more accurate, only the debiased method is different from the baselines if I understand correctly!"
                },
                "weaknesses": {
                    "value": "1. Some baselines are lacking introduction. For example, the best baseline, ESCM-DR, is not introduced in detail.\n2. The running time (or time complexity) is lacking in analysis in the paper. I think this paper can be improved if ESCM-DR is slower than the proposed algorithms.\n3. The evaluation matrics, AUC, NDCG, and F1, are missing clear definitions (can be in the appendix)."
                },
                "questions": {
                    "value": "1. Can the authors provide some detailed explanations for ECSM-DR and Multi-DR?\n2. Any record of the running time (or time complexity) can be provided?\n3. Can the authors provide a rigid definition for F1 measure?\n4. Can the authors also provide the experimental results similar to Table 3 for NDCG and F1 @ other values in the appendix? At least for Coar and music datasets, Top-1 should be also an important measure."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission9439/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1699145727178,
            "cdate": 1699145727178,
            "tmdate": 1699637188694,
            "mdate": 1699637188694,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": []
    }
]