[
    {
        "title": "InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models"
    },
    {
        "review": {
            "id": "HYNetLQHgX",
            "forum": "PYwYYwsbSo",
            "replyto": "PYwYYwsbSo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3882/Reviewer_FwK3"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3882/Reviewer_FwK3"
            ],
            "content": {
                "summary": {
                    "value": "The paper presents an innovative approach to identifying the \"optimal\" instruction for large language models with the aim of improving generative quality. This work falls under the burgeoning area of prompt search methods, which have gained significant attention recently, exemplified by methods such as APE, RLPrompt etc. Unlike conventional methods that optimize discrete instructions, the authors propose optimizing a low-dimensional \"soft prompt\" using dimensionality reduction. The optimized soft prompt is applied to an open-source Lifelong Learning Model (LLM) to generate instructions for a black-box LLM. The optimization process is iterative, involving zero-shot evaluation of the black-box LLM's performance, which is then used in a Bayesian optimization scheme to refine the soft prompts. This iterative process continues until convergence. Experimental results on the BBH benchmark show that the proposed method yields superior performance across all 32 tasks."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed methodology is both innovative and well-explained, making a valuable contribution to the area of prompt optimization in large language models.\n- The empirical results are compelling, demonstrating superior performance across all 32 tasks on the BBH benchmark.\n- The use of Uniform as a comparative baseline effectively underscores the benefits of the proposed iterative Bayesian Optimization (BO) process."
                },
                "weaknesses": {
                    "value": "- The paper could benefit from a broader evaluation scope. Considering additional tasks such as reasoning QA GSM8K, machine translation, or summarization could provide a more comprehensive view of the method's effectiveness.\n- The inclusion of only two comparative baselines, APE and Uniform, limits the robustness of the evaluation. Expanding the set of comparative baselines could provide a more holistic understanding of the method's performance relative to existing work. For example, RLprompt and Autoprompt are also two good prompt search methods.\n- The paper presents a puzzling result related to APE's performance, which is reported to have only a 0.04 accuracy in Figure 1. Upon closer inspection, it becomes apparent that the original APE experiments were based on instructgpt, where the prediction probability could be obtained. While this paper employs the more powerful Turbo 3.5 API, which cannot access the prediction  probability. Thus I think the comparison here is not fair enough, as APE is a much weaker version than the original paper. This discrepancy introduces confusion and could affect the perceived validity of the comparative results.  This drawback again highlights a more fair comparison is required, e.g., other prompt search baselines are needed. Also, what about the comparison with zero-shot COT, 'Please Think step by step'? \n- There is ambiguity in the claim about the method being applicable for zero-shot evaluation. While it's true that the proposed method employs a black-box LLM API for zero-shot generation, the Bayesian Optimization (BO) process requires labeled data. This seems to contradict the zero-shot claim and may constitute an overstatement."
                },
                "questions": {
                    "value": "- I wonder why the results of APE are so weak in Figure 1."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3882/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3882/Reviewer_FwK3",
                        "ICLR.cc/2024/Conference/Submission3882/Senior_Area_Chairs"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3882/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698730513024,
            "cdate": 1698730513024,
            "tmdate": 1700631271023,
            "mdate": 1700631271023,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "xhx71PSZTP",
                "forum": "PYwYYwsbSo",
                "replyto": "HYNetLQHgX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** The paper could benefit from a broader evaluation scope, e.g., GSM8k, machine translation\n\n**A1:** Thanks for your suggestion! We add new experiments of GSM8K, AQUA, and SVAMP by evaluating the zero-shot performance. Following [1], the reasoning template is designed as `I have some instruction examples for solving school math problems. Instruction: Let\u2019s figure it out! Instruction: Let\u2019s solve the problem. Instruction: Let\u2019s think step by step. Write your new instruction that is different from the examples to solve the school math problems. Instruction:` The results are reported in the table below:\n|Dataset| Method | Instruction | Results |\n|---| ---    | ---        | ---|\n|GSM8k| CoT    | Let's think step by step | 0.718 |\n|   | Ours   | Let's use the instruction to solve the problem | 0.743|\n|AQUA| CoT    | Let's think step by step | 0.511 |\n|   | Ours   | Let's break down the problem | 0.543|\n|SVAMP| CoT    | Let's think step by step | 0.763 |\n|   | Ours   | Let's use the brain | 0.795|\n\n[1] USE YOUR INSTINCT: INSTRUCTION OPTIMIZATION USING NEURAL BANDITS COUPLED WITH TRANSFORMERS. https://arxiv.org/abs/2310.02905"
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3882/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700246367476,
                "cdate": 1700246367476,
                "tmdate": 1700246428804,
                "mdate": 1700246428804,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "A6FGRsO06G",
                "forum": "PYwYYwsbSo",
                "replyto": "HYNetLQHgX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q2:** Comparison with other prompt search methods, e.g., RLprompt.\n\n**A2:** We discussed the key difference with the RLprompt in our related work section: [2] (RLprompt) relies on RL to optimize hard prompts while InstructZero optimizes an instruction in the output space of an open-source model $g(\\cdot)$ **without RL** by BO of a soft prompt to g(\u00b7). Moreover, the instructions found by our method are all fluent while the instructions found by RLprompt are not, e.g., in Yelp Review (a text classification task), RLprompt found `StaffAreaFocusHardware Advisory` as their best prompt. Hence, InstructZero is a better pipeline to optimize human-readable instructions, which is more challenging than the task of RLprompt.\n\n**Q3:** There is ambiguity in the claim about the method being applicable for zero-shot evaluation. \n\n**A3:** Thank you for your feedback! We did include a few labeled data as input demos for the open-source models during instruction optimization. However, the inference and evaluation of the optimized instructions on the black-box LLMs are zero-shot. Hence, the application of the optimized instructions is indeed zero-shot and it does not overclaim. We will make this clear in the polished manuscript. \n\n\n\n\n[2] RLprompt: Optimizing Discrete Text Prompts with Reinforcement Learning. https://arxiv.org/pdf/2205.12548.pdf"
                    }
                },
                "number": 8,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3882/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700246413158,
                "cdate": 1700246413158,
                "tmdate": 1700246443356,
                "mdate": 1700246443356,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XrzdGSVnCX",
                "forum": "PYwYYwsbSo",
                "replyto": "HYNetLQHgX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe haven't heard from you since sending you our rebuttal. Since we are approaching the last day of the reviewer-author discussion, it would be really nice of you to confirm if your initial concerns (most of them are clarification questions) were successfully addressed by our rebuttal. We are looking forward to your feedback and we kindly expect that you can raise the score if all your main concerns have been resolved.\n\nThanks!\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3882/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700529462177,
                "cdate": 1700529462177,
                "tmdate": 1700529462177,
                "mdate": 1700529462177,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "CX0xTo5IyI",
                "forum": "PYwYYwsbSo",
                "replyto": "XrzdGSVnCX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3882/Reviewer_FwK3"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3882/Reviewer_FwK3"
                ],
                "content": {
                    "title": {
                        "value": "After reading the rebuttal"
                    },
                    "comment": {
                        "value": "I would like to extend my sincere appreciation to the authors for their efforts in addressing the concerns raised during the rebuttal process. I am pleased to note that most of my concerns have been adequately addressed. However, I still have reservations regarding the weak score of APE, and I also observed that there was no response to the W3 concern. It's possible that I may have overlooked pertinent information or misunderstood the issue at hand.\n\nAfter careful consideration, I have decided to marginally increase my score to 6."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3882/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700631248394,
                "cdate": 1700631248394,
                "tmdate": 1700631248394,
                "mdate": 1700631248394,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "fKL7QT1PCT",
            "forum": "PYwYYwsbSo",
            "replyto": "PYwYYwsbSo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3882/Reviewer_4arY"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3882/Reviewer_4arY"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes a method to optimize the instructions for black-box large language models. The proposed method uses an open-source LLM to convert a soft prompt to an instruction, and then uses the instruction as input to the black-box LLM. Bayesian optimization is then used to optimize the soft prompt, which can iteratively propose new soft prompts and instructions to be evaluated by the black-box LLM."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "- The proposed method of using another open-source LLM to help convert a soft prompt to an instruction and then using the instruction as input to the black-box LLM is an interesting and intuitive idea. \n- The graphical illustrations in Figure 2 and 3 are nice and helpful for understanding.\n- The results in Figure 4 indeed show that the proposed method improve over APE and Uniform."
                },
                "weaknesses": {
                    "value": "- One overall observation from the experimental results which concerns me is that it seems that APE does not consistently perform better than Uniform? Both Figure 4 and Figure 1 seem to suggest this, for example, in Figure 1, the improvement over APE seems to be larger than over Uniform. This is an unexpected observation and I think should be explained, because it may suggest that performances of APE might be underestimated in the experiments here.\n- I have some questions and concerns about the instruction-coupled kernel. First of all, it seems that to calculate this kernel between a pair of input soft prompts, you need to have the evaluated scores for both soft prompts (correct me if I'm wrong)? If this is the case, then when you calculate the vector $\\boldsymbol{k}$ in equations 4 and 5, this instruction-coupled kernel cannot be used to calculate these kernel values and therefore these kernel values will simply use the normal squared exponential or matern kernel? In this case, I wonder how much this instruction-coupled kernel actually helps the performance of the Bayesian optimization, because the vector $\\boldsymbol{k}$, which directly measures the distance between a new soft prompt and other previously evaluated soft prompts and therefore has a huge influence on the uncertainty measure, cannot make use of it. I see that you have an ablation study in Table 4 to show the effect of using the instruction-coupled kernel, but why did you only show the comparison for a small number of selected tasks? I think to see whether this kernel is actually useful, it's important to fairly run this ablation study in all tasks and make an overall comparison.\n- About the ablation study (Section 4.3), it looks like the scores \"w/o Manual\" is in general better than \"Manual\"? This is also puzzling because it implies that the meta-prompt used by APE may not be useful...\n- The proposed method InstructZero seems to only optimize the zero-shot performance of the instructions instead of few-shot performance. However, since you already have access to these input-output exemplars which are used as input to the open-source LLM, why don't you also use them as input to the black-box LLM to improve the performance? So this may bring into question how practical the experiments are.\n- (minor) Equations 4 and 5, it seems that the matrix $K$ is not explained."
                },
                "questions": {
                    "value": "My questions are listed under \"weaknesses\" above."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "3: reject, not good enough"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3882/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698831444964,
            "cdate": 1698831444964,
            "tmdate": 1699636346624,
            "mdate": 1699636346624,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "FNuHWuZtrg",
                "forum": "PYwYYwsbSo",
                "replyto": "fKL7QT1PCT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1** questions and concerns about the instruction-coupled kernel.\n\n**A1:** $\\mathbf K$ in Eq. (4)-(5) are computed using Eq. (9). It depends on both the soft prompts' similarity $l(\\cdot,\\cdot)$ and their generated instructions' similarity $s(\\cdot,\\cdot)$. Since its computation depends on the similarity between explored soft prompts $\\{p_1, ..., p_m\\}$ from previous iterations and their evaluation scores $\\{H(p_1), ..., H(p_m)\\}$, $K$ can be predetermined before computing Eq. (4)-(5). $k(p, p_i)$ and $k(p,p)$ of Eq. (4)-(5) only measure the kernel similarity in the soft prompt space using $l(\\cdot,\\cdot)$ so we do not need to evaluate every $p$'s performance during optimization. \n\n\nInstruction-coupled kernel $\\mathbf K$ aims to align the exploration in the soft prompt space (what the BO directly does in InstructZero) and the optimization of the textual instruction (which is the final goal). To this end, the kernel in BO is expected to reflect the similarity of the generated instructions for the target task. So we apply the instruction-coupled kernel in computing $\\mathbf K$. However, to compute $\\mathbf k$, we cannot afford to evaluate every soft prompt $p$'s generated instruction during the maximization of the acquisition function and its evaluation is not differentiable. So in practice we only apply the soft prompt space kernel $l(\\cdot,\\cdot)$ in computing $k(p, p_i)$ and $k(p,p)$ of Eq. (4)-(5).  \n\nIn all our experiments, the above approach performs promisingly and we haven't observed any degradation of using the kernel."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3882/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700246321179,
                "cdate": 1700246321179,
                "tmdate": 1700246321179,
                "mdate": 1700246321179,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "UrMpBYY6cL",
                "forum": "PYwYYwsbSo",
                "replyto": "fKL7QT1PCT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q2** \"w/o Manual\" is in general better than \"Manual\"? This is also puzzling because it implies that the meta-prompt used by APE may not be useful.\n**A2:** We agree that the meta-prompt used by APE may not be useful. The effectiveness of the meta-prompt may vary on models or tasks. For example, an effective meta-prompt for GPT-3, as in the experiments of the APE paper, may not be the best on other models.\n\n**Q3:** Why don't use the demos which have already been used for finding the instructions as the input to the black-box LLM to improve the performance?\n**A3:** For a fair comparison, we follow the APE pipeline, which only uses these input-output examplars for instruction inductions and conducts zero-shot evaluations of the induced instructions."
                    }
                },
                "number": 6,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3882/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700246344007,
                "cdate": 1700246344007,
                "tmdate": 1700246344007,
                "mdate": 1700246344007,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "Cv34Lz7Nbp",
                "forum": "PYwYYwsbSo",
                "replyto": "fKL7QT1PCT",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "Dear Reviewer,\n\nWe haven't heard from you since sending you our rebuttal. Since we are approaching the last day of the reviewer-author discussion, it would be really nice of you to confirm if your initial concerns (most of them are clarification questions) were successfully addressed by our rebuttal. We are looking forward to your feedback and we kindly expect that you can raise the score if all your main concerns have been resolved.\n\nThanks!\n\nBest regards,\n\nAuthors"
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3882/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700529468926,
                "cdate": 1700529468926,
                "tmdate": 1700529468926,
                "mdate": 1700529468926,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "FvvblGVMIX",
            "forum": "PYwYYwsbSo",
            "replyto": "PYwYYwsbSo",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission3882/Reviewer_6Tou"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission3882/Reviewer_6Tou"
            ],
            "content": {
                "summary": {
                    "value": "This paper proposes to use Bayesian optimization to learn an instruction with an open-source LLM so that the instruction improves the zero-shot results of a black-box LLM. Since instructions are discrete, this work instead iteratively learns a small soft prompt which then gets decoded as an instruction. Each updated instruction is evaluated on the black-box LLM whose training accuracy is used to find a better soft prompt."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "4 excellent"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "This is an interesting direction toward automating prompt engineering for API models, and shows strong results."
                },
                "weaknesses": {
                    "value": "It would be equally interesting to see qualitative analysis of the errors and various failures modes by the method and the different components used for optimization (e.g. open-source/black-box LLMs)."
                },
                "questions": {
                    "value": "Some of the similarity metrics are chosen because black-box models don't necessarily return the log-probs. An ablation could have been run where an open-source model is used for both instruction proposal and loss evaluation. Then, we have access to log-probs and/or gradient and will have a better understanding of how much performance we are losing. Could be interesting, not saying this should have been run."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "value": "Yes",
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission3882/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3882/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission3882/Reviewer_6Tou"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission3882/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698886341371,
            "cdate": 1698886341371,
            "tmdate": 1699636346558,
            "mdate": 1699636346558,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "wj3KHEZs1x",
                "forum": "PYwYYwsbSo",
                "replyto": "FvvblGVMIX",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission3882/Authors"
                ],
                "content": {
                    "comment": {
                        "value": "**Q1:** Some of the similarity metrics are chosen because black-box models don't necessarily return the log-probs. An interesting study could be using an open-source model for both instruction proposal and loss evaluation\n\n**A1:** Thanks for your suggestions! We will continue to polish our work as you suggested."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission3882/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700246272883,
                "cdate": 1700246272883,
                "tmdate": 1700246272883,
                "mdate": 1700246272883,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]