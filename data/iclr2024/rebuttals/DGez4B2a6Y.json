[
    {
        "title": "A Plug-and-Play Image Registration Network"
    },
    {
        "review": {
            "id": "Scb8Xg1MY9",
            "forum": "DGez4B2a6Y",
            "replyto": "DGez4B2a6Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5810/Reviewer_UpRR"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5810/Reviewer_UpRR"
            ],
            "content": {
                "summary": {
                    "value": "The paper introduces a new deformable image registration (DIR) method called Plug-and-play Image Registration Network (PIRATE). PIRATE offers a new approach to DIR by integrating explicit data fidelity and a CNN prior. The paper also presents an extended version, PIRATE+, that fine-tunes the CNN prior using deep equilibrium models (DEQ). Both methods are validated on the OASIS and CANDI datasets, with results indicating state-of-the-art performance in DIR."
                },
                "soundness": {
                    "value": "4 excellent"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "4 excellent"
                },
                "strengths": {
                    "value": "- Deformable image registration is a challenging task in medical image analysis, and the authors' approach of using a plug-and-play method to address this challenge is commendable.\n\n- There is a comprehensive coverage of related work, which provides a solid foundation and context for the proposed method.\n\n- The introduction of learned denoisers for regularizing the registration fields and the use of DEQ to fine-tune the regularizer within PnP iterations are innovative contributions.\n\n- The extensive validation on two widely used datasets, OASIS and CANDI, highlights the robustness and general applicability of the proposed methods.\n\n- The qualitative visual results presented in the paper convincingly demonstrate the superiority of PIRATE and PIRATE+ compared to existing deep learning and iterative methods."
                },
                "weaknesses": {
                    "value": "- The incremental improvements in results, especially in the second decimal place, raise concerns about the practical implications of such minor improvements, particularly for downstream tasks, especially that the proposed method is an iterative optimization-based approach that significantly increases inference time compared to deep learning based methods.\n\n- The paper makes heavy use of acronyms, which affects readability. Notably, the acronym \"DU\" is mentioned without a clear definition.\n\n- While the paper's focus on brain MRI datasets is appreciated, it would have been beneficial to see the adaptability of PIRATE and PIRATE+ to other anatomies and imaging modalities."
                },
                "questions": {
                    "value": "- How do the minor improvements in quantitative results translate to real-world applications, especially considering the potentially longer inference time of the iterative optimization-based approach?\n\n- Is registration performed on the full 3D scan, or are 2D slices of roughly pre-aligned images used?\n\n- How does PIRATE and PIRATE+ compare in terms of computational efficiency and scalability?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Reviewer_UpRR"
                    ]
                }
            },
            "number": 1,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5810/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698606449246,
            "cdate": 1698606449246,
            "tmdate": 1700694473841,
            "mdate": 1700694473841,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "cocMWfOI1P",
                "forum": "DGez4B2a6Y",
                "replyto": "Scb8Xg1MY9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer UpRR"
                    },
                    "comment": {
                        "value": "Thanks for your feedback on our work. Please see below for our point-by-point response to your comments.\n\n>1. (Weakness) The incremental improvements in results, especially in the second decimal place, raise concerns about the practical implications of such minor improvements, particularly for downstream tasks, especially that the proposed method is an iterative optimization-based approach that significantly increases inference time compared to deep learning based methods.  / (Q1) How do the minor improvements in quantitative results translate to real-world applications, especially considering the potentially longer inference time of the iterative optimization-based approach?\n\nWe would like to highlight that PIRATE+ can gain noticeable improvement (more than 3% improvement in Dice score) than DL base methods (VoxelMorph, SYMNet, and GraDIRN). Compared to another iterative method, NODEO, PIRATE+ achieved slightly better results with  50% less inference time. Prompted by your comments, we also presented the best and the worst cases of registration results in Figure 2 and Figure 12, respectively. Note how PIRATE+ can gain visual improvement than the baseline, especially for small anatomical structures in the segmentation mask, in both the cases.\n\n>2. (Weakness) The paper makes heavy use of acronyms, which affects readability. Notably, the acronym \"DU\" is mentioned without a clear definition.\n\nPrompted by your comment, the revised manuscript listed all acronyms and corresponding full names in Table 7.\n\n>3. (Weakness) While the paper's focus on brain MRI datasets is appreciated, it would have been beneficial to see the adaptability of PIRATE and PIRATE+ to other anatomies and imaging modalities.\n\nPrompted by your comment, we conducted additional experiments on the suggested EMPIRE10 lung CT dataset. The revised manuscript reports the numerical result in Table 4 and visual results in Figure 6 and 7. These results showed that PIRATE and PIRATE+ also had better performance than other baselines on the new lung CT dataset.\n\n>4. (Q2) Is registration performed on the full 3D scan, or are 2D slices of roughly pre-aligned images used?\n\nWe performed 3D registration: Both PIRATE and PIRATE+ performed on full 3D scans. All figures in the manuscript show a 2D slice of the registered 3D volumes.\n\n>5. (Q3) How does PIRATE and PIRATE+ compare in terms of computational efficiency and scalability?\n\nPrompted by your comment, we tested the computational efficiency and scalability of PIRATE and PIRATE+ in Table 6 and Figure 11. Table 6 shows that PIRATE+ has higher computational and memory complexity than PIRATE. Figure 11 shows that PIRATE+ and PIRATE has similar scalability in terms of time and memory cost for inference."
                    }
                },
                "number": 3,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700592436505,
                "cdate": 1700592436505,
                "tmdate": 1700592436505,
                "mdate": 1700592436505,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "XVUjskrfOL",
                "forum": "DGez4B2a6Y",
                "replyto": "Scb8Xg1MY9",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to Reviewer UpRR"
                    },
                    "comment": {
                        "value": "Dear Reviewer UpRR, thank you again for your positive comments on our paper. Please let know if there is anything else we can address that would help to improve your evaluation of our paper."
                    }
                },
                "number": 10,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700691779273,
                "cdate": 1700691779273,
                "tmdate": 1700691779273,
                "mdate": 1700691779273,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "awxmH6m92g",
                "forum": "DGez4B2a6Y",
                "replyto": "XVUjskrfOL",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Reviewer_UpRR"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Reviewer_UpRR"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks to the authors for their detailed and insightful response to the concerns I raised. After thoroughly considering your explanations and reflecting on the input from other reviews, I have decided to increase my original score."
                    }
                },
                "number": 11,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700694511613,
                "cdate": 1700694511613,
                "tmdate": 1700694511613,
                "mdate": 1700694511613,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "ULznLZV5sl",
            "forum": "DGez4B2a6Y",
            "replyto": "DGez4B2a6Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5810/Reviewer_3727"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5810/Reviewer_3727"
            ],
            "content": {
                "summary": {
                    "value": "The paper addresses the problem of deformable (non-rigid) image registration in the context of biomedical image analysis. In particular, it proposes two methods (PIRATE and PIRATE+) for the regularisation of the deformation field. In contrast to existing deep learning approaches to image registration, the approach presented here explicitly integrates a data-fidelity penalty as well as a CNN prior (this is pre-trained and acts as regularizer for the deformation field). The authors argue that this improves the fidelity between the registered image and the reference image. The second approach, PIRATE+, is similar to this but uses a CNN prior that is trained using deep equilibrium models."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The proposed methods (PIRATE and PIRATE+) are novel methodological contributions which is positive. Additionally, the proposed framework is compared to a number of different methods, including DL and non-DL methods, which is very good. This also includes the best-performing method from recent comparative studies (Mok and Chung, CVPR 2020, MICCAI 2020). The results reported outperform this method in terms of registration accuracy. Another strength of the paper is the careful review of the state-of-the-art in the field. This is well done and comprehensive, allowing the reader to place the proposed work in the context of the SOTA."
                },
                "weaknesses": {
                    "value": "The weaknesses are mainly related to the evaluation of the proposed framework:\n\n- The methods compared in the paper use very different loss or cost functions as well as different models for the parameterization of the deformation field. This makes the papers' comparison of the registration accuracy in terms of voxels with negative Jacobian very difficult to come across methods. Registration accuracy measured in terms of Dice is more meaningful. At the same time, it would have been good if the authors had used some additional non-brain datasets which have landmarks and thus allow the calculation of quantities such as the target registration error. One such dataset is from the EMPIRE10 challenge...\n\n- The run-time of the proposed framework is significantly higher than those of other DL methods. This is a significant disadvantage for clinical applications."
                },
                "questions": {
                    "value": "- The paper proposes two methods, PIRATE and PIRATE+. I am a bit unclear on what are the conclusions: Is PIRATE+ is better than PIRATE? When should PIRATE be used? When should PIRATE+ be used?\n\n- How are the parameters in the other registration methods chosen, especially in the context of trading off registration accuracy and regularisation of the deformation field?\n\n- The run-time of the proposed framework is significantly higher than those of other DL methods. What are the reasons for this?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "details_of_ethics_concerns": {
                    "value": "No ethics concerns"
                },
                "rating": {
                    "value": "8: accept, good paper"
                },
                "confidence": {
                    "value": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
                },
                "code_of_conduct": {
                    "value": "Yes"
                }
            },
            "number": 2,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5810/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698665634190,
            "cdate": 1698665634190,
            "tmdate": 1699636612528,
            "mdate": 1699636612528,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "1v69cyjmeK",
                "forum": "DGez4B2a6Y",
                "replyto": "ULznLZV5sl",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer 3727"
                    },
                    "comment": {
                        "value": "Thanks for your feedback on our work. Please see below for our point-by-point response to your comments.\n\n>1. (Weakness) The methods compared in the paper use very different loss or cost functions as well as different models for the parameterization of the deformation field. This makes the papers' comparison of the registration accuracy in terms of voxels with negative Jacobian very difficult to come across methods. Registration accuracy measured in terms of Dice is more meaningful. At the same time, it would have been good if the authors had used some additional non-brain datasets which have landmarks and thus allow the calculation of quantities such as the target registration error. One such dataset is from the EMPIRE10 challenge...\n\nPrompted by your comment, we conducted additional experiments on the suggested EMPIRE10 lung CT dataset. The revised manuscript reports the numerical result in Table 4 and visual results in Figure 6 and 7. These results show that PIRATE and PIRATE+ can maintain better performance than other baselines on the new lung CT dataset.\n\n>2. (Weakness) The run-time of the proposed framework is significantly higher than those of other DL methods. This is a significant disadvantage for clinical applications.  / (Q3) The run-time of the proposed framework is significantly higher than those of other DL methods. What are the reasons for this?\n\nThe inference time of PIRATE and PIRATE+ are longer than other DL based methods (VoxelMorph, SYMNet, and GraDIRN) due to their iterative scheme. However, our results show that PIRATE+ can gain noticeable improvement (more than 3% improvement in Dice score) than those DL methods. Moreover, the testing time of PIRATE and PRIATE+ (around 40 seconds per 3D volume) is still negligible in clinical applications when real-time registration is not needed. One such application is to generate aligned image pairs required for training image translation models. Note also that our approach does not focus on real-time clinical application at the current stage.\n\n>3. (Q1) The paper proposes two methods, PIRATE and PIRATE+. I am a bit unclear on what are the conclusions: Is PIRATE+ is better than PIRATE? When should PIRATE be used? When should PIRATE+ be used?\n\nOur results show that PIRATE+ outperforms PIRATE with a designated iterative algorithm when trained to optimize the task-specific algorithmic loss. The choice between PIRATE and PIRATE+ depends on the availability of training datasets and trade-off between performance and training complexity. In PIRATE+, one needs pairs of MRI data for training and to optimize a sophisticated DEQ loss related to a specific registration task. On the other hand, PIRATE only requires a set of registration fields, and the training loss corresponds to a simple regression task. The revised manuscript also reported the training complexity of PIRATE and PIRATE+ in Table 6.\n\n>4. (Q2) How are the parameters in the other registration methods chosen, especially in the context of trading off registration accuracy and regularisation of the deformation field?\n\nWe used the official codes of other registration baselines with the suggested parameters (parameters on brain datasets). We retrained all models on our datasets to make fair comparisons."
                    }
                },
                "number": 2,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700592306951,
                "cdate": 1700592306951,
                "tmdate": 1700592306951,
                "mdate": 1700592306951,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "VY0yL2TihC",
            "forum": "DGez4B2a6Y",
            "replyto": "DGez4B2a6Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5810/Reviewer_yfCW"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5810/Reviewer_yfCW"
            ],
            "content": {
                "summary": {
                    "value": "They proposed a new DIR method which is the plug-and-play approach that trains a CNN-based denoiser on the registration field. With\nthis denoiser as a regularizer within iterative methods, deep equilibrium learning is used as a fixed point iterator. The authors use a pre-trained denoiser for such regularization problems. The proposed method achieved the best performances on OASIS & CANDI datasets with reasonable qualitative results corresponding to quantitative results."
                },
                "soundness": {
                    "value": "2 fair"
                },
                "presentation": {
                    "value": "2 fair"
                },
                "contribution": {
                    "value": "2 fair"
                },
                "strengths": {
                    "value": "+ The proposed method used the DEQ approach for iterative registrations. The adapting approach is unique and reasonable. Their training loss looks going down well on the datasets.\n+ DEQ approach successfully addressed registration problems with PnP(plug-and-play) method with appealing gain in Tables 1 & 2."
                },
                "weaknesses": {
                    "value": "+ I didn't understand the motivation of using pre-trained denoisor for regularizations. Why isn't the trainable denoiser used for this task?\n+ No ablation studies about the necessity of the usage of a pre-trained model\n+ Less analysis on the DEQ model : I would like to see the convergence of the number of function evaluation(NFE) along with the training iterations.\n+ In general, the result section is short of significant experiments to support their claim. For example, Figure 3 is a single instance analysis rather group analysis.\n+ Generalization needs to be validated with group analysis."
                },
                "questions": {
                    "value": "+ What is the corner case for the proposed method?\n+ Memory consumption needs to be reported according to fixed size of datasets."
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Reviewer_yfCW"
                    ]
                }
            },
            "number": 3,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5810/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698764413311,
            "cdate": 1698764413311,
            "tmdate": 1700690995109,
            "mdate": 1700690995109,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "C664jXQ5Cr",
                "forum": "DGez4B2a6Y",
                "replyto": "VY0yL2TihC",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer yfCW"
                    },
                    "comment": {
                        "value": "Thanks for your feedback on our work. Please see below for our point-by-point response to your comments.\n\n>1. (Weakness) I didn't understand the motivation of using pre-trained denoisor for regularizations. Why isn't the trainable denoiser used for this task? No ablation studies about the necessity of the usage of a pre-trained model.\n\nMotivation of using pre-trained denoiser: The recent literature has shown the potential of training neural network denoisers to model the statistical distribution of high-dimensional data (e.g., denoising diffusion models and plug-and-play priors). Our work is the first to adopt this idea for registration by training a **denoiser prior** over the registration fields. The revised manuscript has clarified the choice of using denoiser prior for image registration.\n\nWhy not trainable denoiser: We would like to highlight that we did use trainable denoiser in PIRATE+. In PIRATE+, we train the denoiser on a dataset by using the loss specific to the registration task computed using the registration field, the warped image and the fixed image.\n\n>2. (Weakness) Less analysis on the DEQ model : I would like to see the convergence of the number of function evaluation(NFE) along with the training iterations.\n\nPrompted by your comment, we tested NFE across training iterations in DEQ. The results are shown in **Figure 13 in the supplement**. Figure 13 shows that the NFE converges during the training process. \n\n>3. (Weakness) In general, the result section is short of significant experiments to support their claim. For example, Figure 3 is a single instance analysis rather than group analysis. Generalization needs to be validated with group analysis.\n\nWe would like to highlight that **we did conduct group analysis in Table 1, 2, and 3 in our original manuscript**. In those tables, we reported the mean and standard deviation values of the entire testing dataset, which consists of 100 pairs of 3D MRI volumes.\n\n>4. (Q1) What is the corner case for the proposed method?\n\nPrompted by your comment, the revised manuscript shows the best (with the most dice improvement, **not** absolute Dice value) and the worst case (with the least dice improvement) in Figure 2 and Figure 12, respectively. In both cases, PIRATE+ can gain better performance than other baseline models.\n\n>5. (Q2) Memory consumption needs to be reported according to fixed size of datasets.\n\nPrompted by your comment, the revised manuscript shows the memory consumption on both training and inference stages of PIRATE, PIRATE+ and other baselines in Table 6. Note that PIRATE and PIRATE+ has lower memory complexity compared to other DL baselines."
                    }
                },
                "number": 5,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700594200188,
                "cdate": 1700594200188,
                "tmdate": 1700594200188,
                "mdate": 1700594200188,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "SlmpbIjEPR",
                "forum": "DGez4B2a6Y",
                "replyto": "C664jXQ5Cr",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Reviewer_yfCW"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Reviewer_yfCW"
                ],
                "content": {
                    "comment": {
                        "value": "Thanks for the efforts to address previous queries. I believe major parts of mentioned queries are properly addressed, so I raised my score."
                    }
                },
                "number": 7,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700691049400,
                "cdate": 1700691049400,
                "tmdate": 1700691049400,
                "mdate": 1700691049400,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    },
    {
        "review": {
            "id": "k5hzZG4o6j",
            "forum": "DGez4B2a6Y",
            "replyto": "DGez4B2a6Y",
            "signatures": [
                "ICLR.cc/2024/Conference/Submission5810/Reviewer_kX3w"
            ],
            "nonreaders": [],
            "readers": [
                "everyone"
            ],
            "writers": [
                "ICLR.cc/2024/Conference",
                "ICLR.cc/2024/Conference/Submission5810/Reviewer_kX3w"
            ],
            "content": {
                "summary": {
                    "value": "This paper introduces a new deformable registration framework for medical imaging. Their main contribution is the inclusion of a \"plug and play\" prior into the registration framework. A novelty of the work is using a denoiser to specify priors over registration fields. They also propose an additional model (PIRATE+) that fine-tunes the CNN prior in PIRATE using deep equilibrium models (DEQ). The authors then evaluate their work on standard brain MRI datasets used in the registration literature."
                },
                "soundness": {
                    "value": "3 good"
                },
                "presentation": {
                    "value": "3 good"
                },
                "contribution": {
                    "value": "3 good"
                },
                "strengths": {
                    "value": "The paper seems to be the first at using plug-and-play priors for registration, which could be a useful contribution in this already rich space. \n\nThe work obtains good quantitative results on standard benchmarks for deformable medical image registration."
                },
                "weaknesses": {
                    "value": "My main issue is with the writing and presentation of this paper:\n\n- There was virtually no intuitive explanation of what plug-and-play does, why it is useful compared to other approaches, etc. Given that one of the reported contributions of the paper is to show that denoising priors can be used for registration, the lack of any explanation of why denoising is appropriate, how it works, etc. is quite conspicuous. \n\n- What is the main drawback with current deformable image registration models that this current approach is addressing? Why might plug and play be better than other forms of priors for registration? The introduction does not address this.\n\n- The methods section is poorly written, without high-level insights presented before details. For example, the methods starts immediately with the PIRATE iteration updates instead of presenting what the objective being optimized is, what the prior is capturing, etc. \n\n- It is unclear what issue PIRATE+ is trying to improve upon. The methods section simply says \"PIRATE+ uses DEQ to fine-tune the regularizer D in the PIRATE iteration by minimizing...\", but there was no explanation of why the regularizer might not be accurate in the first place.\n\n- The method section would benefit by using pointers back to Fig. 1 and explaining the various steps of that figure."
                },
                "questions": {
                    "value": "1. What advantages do you think plug and play priors offer for registration ?\n\n2. Why might denoising be appropriate as a prior for registration?\n\n3. I am not able to understand what PIRATE+ addressing? The methods says \"PIRATE+ fine-tunes the AWGN denoiser into a task-specific regularizer using DEQ\" but this is quite opaque to me. What does \"task-specific regularization\" mean in this case?\n\n4. Are there any limitations of the method compared to traditional CNN-based deformation models like VoxelMorph in terms of usability, training time, etc.?"
                },
                "flag_for_ethics_review": {
                    "value": [
                        "No ethics review needed."
                    ]
                },
                "rating": {
                    "value": "6: marginally above the acceptance threshold"
                },
                "confidence": {
                    "value": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
                },
                "code_of_conduct": {
                    "value": "Yes"
                },
                "first_time_reviewer": {
                    "readers": [
                        "ICLR.cc/2024/Conference/Program_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Senior_Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Area_Chairs",
                        "ICLR.cc/2024/Conference/Submission5810/Reviewer_kX3w"
                    ]
                }
            },
            "number": 4,
            "invitations": [
                "ICLR.cc/2024/Conference/Submission5810/-/Official_Review",
                "ICLR.cc/2024/Conference/-/Edit"
            ],
            "domain": "ICLR.cc/2024/Conference",
            "tcdate": 1698928163980,
            "cdate": 1698928163980,
            "tmdate": 1700701687582,
            "mdate": 1700701687582,
            "license": "CC BY 4.0",
            "version": 2
        },
        "responses": [
            {
                "id": "GD5w9lvi00",
                "forum": "DGez4B2a6Y",
                "replyto": "k5hzZG4o6j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Response to reviewer kX3w"
                    },
                    "comment": {
                        "value": "Thanks for your feedback on our work. Please see below for our point-by-point response to your comments.\n\n>1. (Weakness) There was virtually no intuitive explanation of what plug-and-play does, why it is useful compared to other approaches, etc. Given that one of the reported contributions of the paper is to show that denoising priors can be used for registration, the lack of any explanation of why denoising is appropriate, how it works, etc. is quite conspicuous. Why might denoising be appropriate as a prior for registration?  / (Q1) What advantages do you think plug and play priors offer for registration ? / (Q2) Why might denoising be appropriate as a prior for registration?\n\nThe recent literature has shown the potential of training neural network denoisers to model the statistical distribution of high-dimensional data (e.g., denoising diffusion models and plug-and-play priors). Our work is the first to adopt this idea for registration by training a **denoiser prior** over the registration fields. The revised manuscript has clarified the choice of using denoiser prior for image registration. Please also refer to our analysis in section 3.1.\n\n>2. (Weakness) What is the main drawback with current deformable image registration models that this current approach is addressing? Why might plug and play be better than other forms of priors for registration? The introduction does not address this. / (Q1) What advantages do you think plug and play priors offer for registration?\n\nPIRATE and PIRATE+ do not focus on addressing issues in existing DL methods. Our approach instead is a novel optimization method for image registration that leverages a CNN-based prior over registration fields. Our paper shows superior performance using the learned prior compared to handcrafted priors (such as smoothness), while also achieving the SOTA performance compared to the DL methods.\n\n>3. (Weakness) The methods section is poorly written, without high-level insights presented before details. For example, the methods starts immediately with the PIRATE iteration updates instead of presenting what the objective being optimized is, what the prior is capturing, etc. \n\nPrompted by your comment, we added high-level insights of PnP/Denoiser prior in the introduction. We also included the objective function in the method section of the revised manuscript as below.\n\t\nThe object function that PIRATE optimizes is formulated as a variation of (1)\n\n$\\pmb{\\hat{\\phi}} = \\arg \\mathop{\\min}\\limits_{\\pmb{\\phi}} \\lbrace g(\\pmb{f},\\pmb{\\phi} \\circ \\pmb{m}) + h(\\pmb{\\phi}) \\rbrace$\n\nwhere $h$ represents the regularizer consisting of an explicit smoothness constraint and the implicit denoising regularizer. The iteration of PIRATE can be expressed as\u2026\u2026..\n\n>4. (Weakness) The method section would benefit by using pointers back to Fig. 1 and explaining the various steps of that figure.\n\nWe added a pointer back to Fig. 1 in section 3 paragraph 1 of the revised manuscript.\n\n>5. (Weakness) It is unclear what issue PIRATE+ is trying to improve upon. The methods section simply says \"PIRATE+ uses DEQ to fine-tune the regularizer D in the PIRATE iteration by minimizing...\", but there was no explanation of why the regularizer might not be accurate in the first place. / (Q3) I am not able to understand what PIRATE+ addressing? The methods says \"PIRATE+ fine-tunes the AWGN denoiser into a task-specific regularizer using DEQ\" but this is quite opaque to me. What does \"task-specific regularization\" mean in this case?\n\nThe regularizer in PIRATE+ is learned by minimizing **the loss specific to the registration task computed using the registration field, the warped image and the fixed image**. On the other hand, the regularizer in PIRATE is learned by minimizing MMSE loss between denoised registration fields and noisy registration fields, without incorporating any specific information about registration tasks. For the specific task PIRATE+ is trained on, PIRATE+ can gain improved performance compared to PIRATE. The revised manuscript has highlighted this difference.\n\n>6. (Q4) Are there any limitations of the method compared to traditional CNN-based deformation models like VoxelMorph in terms of usability, training time, etc.?\n\nThe training time of PIRATE+ is longer than other traditional CNN-based methods. The additional training time comes from the fixed point iterations of PIRATE. However, our results show that PIRATE+ can gain noticeable improvement (more than 3% improvement in Dice score) than traditional CNN-based methods. The revised manuscript has clarified this limitation in the conclusion section."
                    }
                },
                "number": 4,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700593983490,
                "cdate": 1700593983490,
                "tmdate": 1700594222931,
                "mdate": 1700594222931,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "LW2vTVjf0W",
                "forum": "DGez4B2a6Y",
                "replyto": "k5hzZG4o6j",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Authors"
                ],
                "content": {
                    "title": {
                        "value": "Ending of the discussion period"
                    },
                    "comment": {
                        "value": "Dear Reviewer kX3w, as we are nearing the end of the discussion period, please let us know if there is anything else we can address to improve your evaluation of our paper."
                    }
                },
                "number": 9,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700691606762,
                "cdate": 1700691606762,
                "tmdate": 1700691606762,
                "mdate": 1700691606762,
                "license": "CC BY 4.0",
                "version": 2
            },
            {
                "id": "smnVjEUecx",
                "forum": "DGez4B2a6Y",
                "replyto": "LW2vTVjf0W",
                "signatures": [
                    "ICLR.cc/2024/Conference/Submission5810/Reviewer_kX3w"
                ],
                "readers": [
                    "everyone"
                ],
                "writers": [
                    "ICLR.cc/2024/Conference",
                    "ICLR.cc/2024/Conference/Submission5810/Reviewer_kX3w"
                ],
                "content": {
                    "title": {
                        "value": "Revised Score"
                    },
                    "comment": {
                        "value": "Thanks for the clarifications. I have increased my score accordingly."
                    }
                },
                "number": 13,
                "invitations": [
                    "ICLR.cc/2024/Conference/Submission5810/-/Official_Comment"
                ],
                "domain": "ICLR.cc/2024/Conference",
                "tcdate": 1700701784227,
                "cdate": 1700701784227,
                "tmdate": 1700701784227,
                "mdate": 1700701784227,
                "license": "CC BY 4.0",
                "version": 2
            }
        ]
    }
]